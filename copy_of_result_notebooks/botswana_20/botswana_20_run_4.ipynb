{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependancy Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:12.687179Z",
     "iopub.status.busy": "2025-05-08T19:17:12.687179Z",
     "iopub.status.idle": "2025-05-08T19:17:12.691683Z",
     "shell.execute_reply": "2025-05-08T19:17:12.691179Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:12.694695Z",
     "iopub.status.busy": "2025-05-08T19:17:12.693695Z",
     "iopub.status.idle": "2025-05-08T19:17:14.798036Z",
     "shell.execute_reply": "2025-05-08T19:17:14.798036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-metric-learning in c:\\users\\vella\\anaconda3\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.5.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (2.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (4.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vella\\anaconda3\\lib\\site-packages (from tqdm->pytorch-metric-learning) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:14.801286Z",
     "iopub.status.busy": "2025-05-08T19:17:14.800287Z",
     "iopub.status.idle": "2025-05-08T19:17:18.167994Z",
     "shell.execute_reply": "2025-05-08T19:17:18.167994Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nbformat\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "from torch.amp import autocast, GradScaler\n",
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:18.171006Z",
     "iopub.status.busy": "2025-05-08T19:17:18.170004Z",
     "iopub.status.idle": "2025-05-08T19:17:18.186059Z",
     "shell.execute_reply": "2025-05-08T19:17:18.186059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:18.188065Z",
     "iopub.status.busy": "2025-05-08T19:17:18.188065Z",
     "iopub.status.idle": "2025-05-08T19:17:19.111739Z",
     "shell.execute_reply": "2025-05-08T19:17:19.111739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: (1476, 256)\n",
      "Hypercube shape: (1476, 256, 145)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dir = r\"C:\\Users\\vella\\Documents\\GitHub\\FYP2425_LOCAL\\FYP_DATASET\"\n",
    "\n",
    "gt_files = 'Botswana_gt.mat'\n",
    "data_files = 'Botswana.mat'\n",
    "label_files = 'Botswana_gt'\n",
    "hypercube_files = 'Botswana'\n",
    "\n",
    "def extract_Features():\n",
    "    gt_file = os.path.join(dataset_dir, gt_files)\n",
    "    data_file = os.path.join(dataset_dir, data_files)\n",
    "\n",
    "    gt = sio.loadmat(gt_file)\n",
    "    labels = gt[label_files]\n",
    "\n",
    "    data = sio.loadmat(data_file)\n",
    "    hypercube = data[hypercube_files]\n",
    "    #scaling the data in place and setting to float32 to reduce memory usage\n",
    "    max_value = np.max(hypercube)\n",
    "    hypercube = (hypercube / max_value).astype(np.float32)\n",
    "\n",
    "\n",
    "    #shapes of loaded data\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Hypercube shape: {hypercube.shape}\")\n",
    "\n",
    "    #visualisation of label map and a given band of hyperspectral data\n",
    "    plt.figure()\n",
    "    plt.imshow(labels)\n",
    "    plt.title('Labels')\n",
    "\n",
    "    band = 101\n",
    "    plt.figure()\n",
    "    plt.imshow(hypercube[:,:,band])\n",
    "    plt.title(f'Hyperspectral Band {band}')\n",
    "    plt.show()\n",
    "\n",
    "    return hypercube, labels\n",
    "\n",
    "hypercube, labels = extract_Features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:19.114747Z",
     "iopub.status.busy": "2025-05-08T19:17:19.114747Z",
     "iopub.status.idle": "2025-05-08T19:17:19.120104Z",
     "shell.execute_reply": "2025-05-08T19:17:19.120104Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_windows(data, labels, window_size):\n",
    "    extract_windows_save_dir = 'extracted_windows_labels'\n",
    "    if not os.path.exists(extract_windows_save_dir):\n",
    "        os.makedirs(extract_windows_save_dir)\n",
    "        print(f\"Created directory: {extract_windows_save_dir}\")\n",
    "\n",
    "    margin = window_size // 2\n",
    "    padded_data = np.pad(data, ((margin, margin), (margin, margin), (0, 0)), mode='constant')\n",
    "    padded_labels = np.pad(labels, ((margin, margin), (margin, margin)), mode='constant')\n",
    "\n",
    "    X_windows = []  #extracted windows\n",
    "    y_labels = []   #corresponding labels\n",
    "\n",
    "    print(\"Starting window extraction...\")\n",
    "    for i in range(margin, padded_data.shape[0] - margin):\n",
    "        for j in range(margin, padded_data.shape[1] - margin):\n",
    "            window = padded_data[i-margin:i+margin+1, j-margin:j+margin+1, :]\n",
    "            label = padded_labels[i, j]\n",
    "\n",
    "            if label != 0:\n",
    "                #print('ignoring label 0 (background)')\n",
    "                X_windows.append(window)\n",
    "                y_labels.append(label)\n",
    "\n",
    "    #convertying to numpy arrays\n",
    "    X_windows = np.array(X_windows)\n",
    "    y_labels = np.array(y_labels)\n",
    "\n",
    "    #saving extracted windows and labels\n",
    "    windows_file = os.path.join(extract_windows_save_dir, 'extracted_windows.npy')\n",
    "    labels_file = os.path.join(extract_windows_save_dir, 'extracted_labels.npy')\n",
    "\n",
    "    np.save(windows_file, X_windows)\n",
    "    np.save(labels_file, y_labels)\n",
    "\n",
    "    print(f\"Saved extracted windows to: {windows_file}\")\n",
    "    print(f\"Saved corresponding labels to: {labels_file}\")\n",
    "    print(f\"\\nTotal windows extracted: {len(X_windows)}\")\n",
    "    print(f\"Extracted windows shape: {X_windows.shape}\")\n",
    "    print(f\"Corresponding labels shape: {y_labels.shape}\")\n",
    "\n",
    "    return X_windows, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:19.123638Z",
     "iopub.status.busy": "2025-05-08T19:17:19.122638Z",
     "iopub.status.idle": "2025-05-08T19:17:20.017603Z",
     "shell.execute_reply": "2025-05-08T19:17:20.017603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: extracted_windows_labels\n",
      "Starting window extraction...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved extracted windows to: extracted_windows_labels\\extracted_windows.npy\n",
      "Saved corresponding labels to: extracted_windows_labels\\extracted_labels.npy\n",
      "\n",
      "Total windows extracted: 3248\n",
      "Extracted windows shape: (3248, 5, 5, 145)\n",
      "Corresponding labels shape: (3248,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "\n",
    "X_windows, y_labels = extract_windows(hypercube, labels, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:20.020608Z",
     "iopub.status.busy": "2025-05-08T19:17:20.020608Z",
     "iopub.status.idle": "2025-05-08T19:17:20.028836Z",
     "shell.execute_reply": "2025-05-08T19:17:20.028370Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_samples(X_windows, y_labels, samples_per_class):\n",
    "    \n",
    "    indices_save_dir = 'indices'\n",
    "    if not os.path.exists(indices_save_dir):\n",
    "        os.makedirs(indices_save_dir)\n",
    "        print(f\"Created directory: {indices_save_dir}\")\n",
    "    \n",
    "    #get unique classes\n",
    "    classes = np.unique(y_labels)\n",
    "    print(f\"Unique classes found as: {classes}\")\n",
    "\n",
    "    #init lists\n",
    "    X_sampled = [] #to store training samples\n",
    "    y_sampled = [] #to store training labels\n",
    "\n",
    "    X_val = [] # to store validation samples\n",
    "    y_val = [] # to store validation labels\n",
    "\n",
    "    selected_indices_total = [] #to store indices of selected training and validation samples\n",
    "    validation_selected = [] #temp storage for validation indices\n",
    "    validation_total = [] #to store all validation indices\n",
    "\n",
    "    print(\"\\n == STARTING SAMPLING PROCESS ==\")\n",
    "    for cls in classes:\n",
    "        if cls == 0:\n",
    "            print(f\"!! SKIPPING CLASS 0 !!\")\n",
    "            continue\n",
    "\n",
    "        #getting the indices for the current class:\n",
    "        class_indices = np.where(y_labels == cls)[0]\n",
    "        print(f\"Class: {cls}: Found {len(class_indices)} samples\")\n",
    "\n",
    "        # shuffle class-specific indices to ensure randomness\n",
    "        np.random.shuffle(class_indices)\n",
    "        print(f\"Shuffled class indices for class '{cls}'\")\n",
    "\n",
    "        #select 'samples_per_class' samples for training\n",
    "        selected_indices = class_indices[:samples_per_class]\n",
    "        #selecting 5 samples for validation\n",
    "        validation_selected = class_indices[samples_per_class:samples_per_class+5]\n",
    "\n",
    "        print(f\"Selected {len(selected_indices)} training samples and {len(validation_selected)} validation samples for class '{cls}'\\n\")\n",
    "\n",
    "        #store selected indices for training and validation\n",
    "        selected_indices_total.extend(selected_indices)\n",
    "        validation_total.extend(validation_selected)\n",
    "\n",
    "        # appending the selected samples and their labels to the lists\n",
    "        X_sampled.append(X_windows[selected_indices])\n",
    "        y_sampled.append(y_labels[selected_indices])\n",
    "\n",
    "        X_val.append(X_windows[validation_selected])\n",
    "        y_val.append(y_labels[validation_selected])\n",
    "\n",
    "    #concat the sampled arrays for training\n",
    "    X_train = np.vstack(X_sampled)\n",
    "    y_train = np.hstack(y_sampled)\n",
    "\n",
    "    # shift labels to start from 0\n",
    "    y_train = y_train - 1\n",
    "\n",
    "    print(f\"\\n -- Training set created with: \\n\\t{X_train.shape[0]} samples\\n\\tshape {X_train.shape} --\")\n",
    "\n",
    "    #concat the sampled arrays for validation\n",
    "    X_val = np.vstack(X_val)\n",
    "    y_val = np.hstack(y_val)\n",
    "    y_val = y_val - 1\n",
    "\n",
    "    print(f\"\\n -- Validation set created with: \\n\\t{X_val.shape[0]} samples\\n\\tshape {X_val.shape} --\")\n",
    "\n",
    "    #create the test set from the remaining data (i.e. that which is not selected for training or validation)\n",
    "    selected_indices_total.extend(validation_total)\n",
    "\n",
    "    #getting indices not in the training or val sets\n",
    "    test_indices = np.setdiff1d(np.arange(X_windows.shape[0]), selected_indices_total)\n",
    "    X_test = X_windows[test_indices]\n",
    "    y_test = y_labels[test_indices]\n",
    "    y_test = y_test - 1\n",
    "\n",
    "    print(f\"\\n -- Test set created with: \\n\\t{X_test.shape[0]} samples\\n\\tshape {X_test.shape} --\\n\")\n",
    "\n",
    "    # Save the datasets to the 'datasets' folder\n",
    "    np.save(os.path.join(indices_save_dir, 'X_train.npy'), X_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_train.npy'), y_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_val.npy'), X_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_val.npy'), y_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_test.npy'), X_test)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_test.npy'), y_test)\n",
    "\n",
    "    print(f\"\\nAll datasets saved to the '{indices_save_dir}' folder.\")\n",
    "\n",
    "    #return the training, val, test sets + selected indices\n",
    "    return X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:20.030844Z",
     "iopub.status.busy": "2025-05-08T19:17:20.030844Z",
     "iopub.status.idle": "2025-05-08T19:17:20.235155Z",
     "shell.execute_reply": "2025-05-08T19:17:20.234652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: indices\n",
      "Unique classes found as: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      " == STARTING SAMPLING PROCESS ==\n",
      "Class: 1: Found 270 samples\n",
      "Shuffled class indices for class '1'\n",
      "Selected 20 training samples and 5 validation samples for class '1'\n",
      "\n",
      "Class: 2: Found 101 samples\n",
      "Shuffled class indices for class '2'\n",
      "Selected 20 training samples and 5 validation samples for class '2'\n",
      "\n",
      "Class: 3: Found 251 samples\n",
      "Shuffled class indices for class '3'\n",
      "Selected 20 training samples and 5 validation samples for class '3'\n",
      "\n",
      "Class: 4: Found 215 samples\n",
      "Shuffled class indices for class '4'\n",
      "Selected 20 training samples and 5 validation samples for class '4'\n",
      "\n",
      "Class: 5: Found 269 samples\n",
      "Shuffled class indices for class '5'\n",
      "Selected 20 training samples and 5 validation samples for class '5'\n",
      "\n",
      "Class: 6: Found 269 samples\n",
      "Shuffled class indices for class '6'\n",
      "Selected 20 training samples and 5 validation samples for class '6'\n",
      "\n",
      "Class: 7: Found 259 samples\n",
      "Shuffled class indices for class '7'\n",
      "Selected 20 training samples and 5 validation samples for class '7'\n",
      "\n",
      "Class: 8: Found 203 samples\n",
      "Shuffled class indices for class '8'\n",
      "Selected 20 training samples and 5 validation samples for class '8'\n",
      "\n",
      "Class: 9: Found 314 samples\n",
      "Shuffled class indices for class '9'\n",
      "Selected 20 training samples and 5 validation samples for class '9'\n",
      "\n",
      "Class: 10: Found 248 samples\n",
      "Shuffled class indices for class '10'\n",
      "Selected 20 training samples and 5 validation samples for class '10'\n",
      "\n",
      "Class: 11: Found 305 samples\n",
      "Shuffled class indices for class '11'\n",
      "Selected 20 training samples and 5 validation samples for class '11'\n",
      "\n",
      "Class: 12: Found 181 samples\n",
      "Shuffled class indices for class '12'\n",
      "Selected 20 training samples and 5 validation samples for class '12'\n",
      "\n",
      "Class: 13: Found 268 samples\n",
      "Shuffled class indices for class '13'\n",
      "Selected 20 training samples and 5 validation samples for class '13'\n",
      "\n",
      "Class: 14: Found 95 samples\n",
      "Shuffled class indices for class '14'\n",
      "Selected 20 training samples and 5 validation samples for class '14'\n",
      "\n",
      "\n",
      " -- Training set created with: \n",
      "\t280 samples\n",
      "\tshape (280, 5, 5, 145) --\n",
      "\n",
      " -- Validation set created with: \n",
      "\t70 samples\n",
      "\tshape (70, 5, 5, 145) --\n",
      "\n",
      " -- Test set created with: \n",
      "\t2898 samples\n",
      "\tshape (2898, 5, 5, 145) --\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All datasets saved to the 'indices' folder.\n",
      "(280, 5, 5, 145)\n",
      "(70, 5, 5, 145)\n",
      "(2898, 5, 5, 145)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total = get_samples(X_windows, y_labels, 20)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:20.237159Z",
     "iopub.status.busy": "2025-05-08T19:17:20.237159Z",
     "iopub.status.idle": "2025-05-08T19:17:20.241071Z",
     "shell.execute_reply": "2025-05-08T19:17:20.241071Z"
    }
   },
   "outputs": [],
   "source": [
    "class HyperspectralDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (numpy.ndarray): Hyperspectral data of shape (num_samples, height, width, num_bands).\n",
    "            y (numpy.ndarray): Labels of shape (num_samples,).\n",
    "        \"\"\"\n",
    "        #converting to pytorch tensor\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:20.243584Z",
     "iopub.status.busy": "2025-05-08T19:17:20.243584Z",
     "iopub.status.idle": "2025-05-08T19:17:20.304934Z",
     "shell.execute_reply": "2025-05-08T19:17:20.304934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 2 applied\n",
      "DataLoaders created successfully!\n",
      "Training batch size: 280\n",
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20}\n"
     ]
    }
   ],
   "source": [
    "#loading the saved datasets\n",
    "X_train = np.load('indices/X_train.npy')\n",
    "y_train = np.load('indices/y_train.npy')\n",
    "X_val = np.load('indices/X_val.npy')\n",
    "y_val = np.load('indices/y_val.npy')\n",
    "X_test = np.load('indices/X_test.npy')\n",
    "y_test = np.load('indices/y_test.npy')\n",
    "\n",
    "\n",
    "#creating pytorch datasets\n",
    "train_dataset = HyperspectralDataset(X_train, y_train)\n",
    "val_dataset = HyperspectralDataset(X_val, y_val)\n",
    "test_dataset = HyperspectralDataset(X_test, y_test)\n",
    "\n",
    "m = 20\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "#theoretical batch size calc\n",
    "required_batch_size = m * num_classes  # 10 * 9 = 90\n",
    "\n",
    "#ensuring batch size doesn't exceed training set size\n",
    "if required_batch_size > len(train_dataset):\n",
    "    #case 1: not enough samples - reduce m proportionally\n",
    "    print(\"Case 1 applied\")\n",
    "    max_possible_m = len(train_dataset) // num_classes\n",
    "    m = max(1, max_possible_m)\n",
    "    batch_size_train = m * num_classes\n",
    "else:\n",
    "    #case 2: use full batch size\n",
    "    print(\"Case 2 applied\")\n",
    "    batch_size_train = required_batch_size\n",
    "\n",
    "sampler = MPerClassSampler(labels = y_train, m=m, batch_size = batch_size_train, length_before_new_iter = len(train_dataset))\n",
    "\n",
    "#dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size_train, sampler=sampler)\n",
    "\n",
    "batch_size = 256\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")\n",
    "\n",
    "#class dist in first batch\n",
    "for X_batch, y_batch in train_loader:\n",
    "    unique, counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(f\"Training batch size: {batch_size_train}\")\n",
    "    print(\"Class distribution in batch:\", dict(zip(unique, counts)))\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating directory for saving model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:20.307939Z",
     "iopub.status.busy": "2025-05-08T19:17:20.307939Z",
     "iopub.status.idle": "2025-05-08T19:17:20.313598Z",
     "shell.execute_reply": "2025-05-08T19:17:20.313598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dir: model_predictions\n"
     ]
    }
   ],
   "source": [
    "predictions_dir = 'model_predictions'\n",
    "os.makedirs(predictions_dir, exist_ok=True)\n",
    "print(f\"Created dir: {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset splits and Dataloaders for unsupervised tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:20.316604Z",
     "iopub.status.busy": "2025-05-08T19:17:20.316604Z",
     "iopub.status.idle": "2025-05-08T19:17:20.332226Z",
     "shell.execute_reply": "2025-05-08T19:17:20.331709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2598, 5, 5, 145)\n",
      "Validation data shape: (650, 5, 5, 145)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = train_test_split(X_windows, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:20.334233Z",
     "iopub.status.busy": "2025-05-08T19:17:20.334233Z",
     "iopub.status.idle": "2025-05-08T19:17:20.338855Z",
     "shell.execute_reply": "2025-05-08T19:17:20.338341Z"
    }
   },
   "outputs": [],
   "source": [
    "class UnsupervisedDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)  #converting to pytorch tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:20.340860Z",
     "iopub.status.busy": "2025-05-08T19:17:20.340860Z",
     "iopub.status.idle": "2025-05-08T19:17:20.348537Z",
     "shell.execute_reply": "2025-05-08T19:17:20.348537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "#creating datasets for unsupervised task\n",
    "unsup_train_dataset = UnsupervisedDataset(X_train)\n",
    "unsup_val_dataset = UnsupervisedDataset(X_val)\n",
    "\n",
    "#dataloaders for unsupervised task\n",
    "batch_size = 64\n",
    "train_loader_cae = DataLoader(unsup_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader_cae = DataLoader(unsup_val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:20.351541Z",
     "iopub.status.busy": "2025-05-08T19:17:20.350542Z",
     "iopub.status.idle": "2025-05-08T19:17:20.354577Z",
     "shell.execute_reply": "2025-05-08T19:17:20.354577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    }
   ],
   "source": [
    "window_num_channels = X_windows.shape[3]\n",
    "print(window_num_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:20.356651Z",
     "iopub.status.busy": "2025-05-08T19:17:20.356651Z",
     "iopub.status.idle": "2025-05-08T19:17:20.362661Z",
     "shell.execute_reply": "2025-05-08T19:17:20.362661Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncode(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.1):\n",
    "        super(ConvAutoEncode, self).__init__()\n",
    "\n",
    "        #encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            #Block 1\n",
    "            nn.Conv2d(window_num_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            #Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            #Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(64, window_num_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:20.364974Z",
     "iopub.status.busy": "2025-05-08T19:17:20.364974Z",
     "iopub.status.idle": "2025-05-08T19:17:42.422552Z",
     "shell.execute_reply": "2025-05-08T19:17:42.422552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1/41], Loss: 0.2201, PSNR: -8.0472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Training Loss: 0.2103, PSNR: -8.6582\n",
      "\t[Val]   Batch [1/11] Loss: 0.2049, PSNR: -6.1532\n",
      "\t[Val]   Batch [10/11] Loss: 0.2051, PSNR: -8.3920\n",
      "Epoch [1/50] Validation Loss: 0.2049, PSNR: -8.0841\n",
      "\n",
      "LOG: Epoch [2/50]\n",
      "\t Training Batch [1/41], Loss: 0.1942, PSNR: -7.5039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Training Loss: 0.1879, PSNR: -8.3105\n",
      "\t[Val]   Batch [1/11] Loss: 0.1764, PSNR: -5.5014\n",
      "\t[Val]   Batch [10/11] Loss: 0.1767, PSNR: -7.7444\n",
      "Epoch [2/50] Validation Loss: 0.1764, PSNR: -7.4338\n",
      "\n",
      "LOG: Epoch [3/50]\n",
      "\t Training Batch [1/41], Loss: 0.1742, PSNR: -7.0308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Training Loss: 0.1665, PSNR: -7.7164\n",
      "\t[Val]   Batch [1/11] Loss: 0.1534, PSNR: -4.8940\n",
      "\t[Val]   Batch [10/11] Loss: 0.1532, PSNR: -7.1258\n",
      "Epoch [3/50] Validation Loss: 0.1532, PSNR: -6.8208\n",
      "\n",
      "LOG: Epoch [4/50]\n",
      "\t Training Batch [1/41], Loss: 0.1539, PSNR: -8.4965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] Training Loss: 0.1461, PSNR: -7.0568\n",
      "\t[Val]   Batch [1/11] Loss: 0.1292, PSNR: -4.1483\n",
      "\t[Val]   Batch [10/11] Loss: 0.1293, PSNR: -6.3889\n",
      "Epoch [4/50] Validation Loss: 0.1293, PSNR: -6.0830\n",
      "\n",
      "LOG: Epoch [5/50]\n",
      "\t Training Batch [1/41], Loss: 0.1332, PSNR: -5.5984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] Training Loss: 0.1268, PSNR: -6.6234\n",
      "\t[Val]   Batch [1/11] Loss: 0.1128, PSNR: -3.5594\n",
      "\t[Val]   Batch [10/11] Loss: 0.1129, PSNR: -5.7999\n",
      "Epoch [5/50] Validation Loss: 0.1129, PSNR: -5.4938\n",
      "\n",
      "LOG: Epoch [6/50]\n",
      "\t Training Batch [1/41], Loss: 0.1145, PSNR: -7.0459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] Training Loss: 0.1096, PSNR: -5.9577\n",
      "\t[Val]   Batch [1/11] Loss: 0.0963, PSNR: -2.8724\n",
      "\t[Val]   Batch [10/11] Loss: 0.0963, PSNR: -5.1112\n",
      "Epoch [6/50] Validation Loss: 0.0963, PSNR: -4.8051\n",
      "\n",
      "LOG: Epoch [7/50]\n",
      "\t Training Batch [1/41], Loss: 0.0996, PSNR: -5.8699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] Training Loss: 0.0943, PSNR: -5.3235\n",
      "\t[Val]   Batch [1/11] Loss: 0.0838, PSNR: -2.2715\n",
      "\t[Val]   Batch [10/11] Loss: 0.0839, PSNR: -4.5093\n",
      "Epoch [7/50] Validation Loss: 0.0839, PSNR: -4.2035\n",
      "\n",
      "LOG: Epoch [8/50]\n",
      "\t Training Batch [1/41], Loss: 0.0845, PSNR: -6.0427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] Training Loss: 0.0811, PSNR: -4.5629\n",
      "\t[Val]   Batch [1/11] Loss: 0.0722, PSNR: -1.6233\n",
      "\t[Val]   Batch [10/11] Loss: 0.0722, PSNR: -3.8611\n",
      "Epoch [8/50] Validation Loss: 0.0722, PSNR: -3.5554\n",
      "\n",
      "LOG: Epoch [9/50]\n",
      "\t Training Batch [1/41], Loss: 0.0741, PSNR: -5.6699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] Training Loss: 0.0700, PSNR: -4.0259\n",
      "\t[Val]   Batch [1/11] Loss: 0.0632, PSNR: -1.0435\n",
      "\t[Val]   Batch [10/11] Loss: 0.0632, PSNR: -3.2813\n",
      "Epoch [9/50] Validation Loss: 0.0632, PSNR: -2.9756\n",
      "\n",
      "LOG: Epoch [10/50]\n",
      "\t Training Batch [1/41], Loss: 0.0641, PSNR: -5.3280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] Training Loss: 0.0606, PSNR: -3.3588\n",
      "\t[Val]   Batch [1/11] Loss: 0.0556, PSNR: -0.4898\n",
      "\t[Val]   Batch [10/11] Loss: 0.0557, PSNR: -2.7290\n",
      "Epoch [10/50] Validation Loss: 0.0556, PSNR: -2.4218\n",
      "\n",
      "LOG: Epoch [11/50]\n",
      "\t Training Batch [1/41], Loss: 0.0557, PSNR: -1.8139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] Training Loss: 0.0528, PSNR: -2.7160\n",
      "\t[Val]   Batch [1/11] Loss: 0.0487, PSNR: 0.0835\n",
      "\t[Val]   Batch [10/11] Loss: 0.0488, PSNR: -2.1562\n",
      "Epoch [11/50] Validation Loss: 0.0487, PSNR: -1.8476\n",
      "\n",
      "LOG: Epoch [12/50]\n",
      "\t Training Batch [1/41], Loss: 0.0484, PSNR: -2.6877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] Training Loss: 0.0463, PSNR: -2.3506\n",
      "\t[Val]   Batch [1/11] Loss: 0.0432, PSNR: 0.6124\n",
      "\t[Val]   Batch [10/11] Loss: 0.0432, PSNR: -1.6258\n",
      "Epoch [12/50] Validation Loss: 0.0432, PSNR: -1.3189\n",
      "\n",
      "LOG: Epoch [13/50]\n",
      "\t Training Batch [1/41], Loss: 0.0420, PSNR: -2.2136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50] Training Loss: 0.0409, PSNR: -1.6465\n",
      "\t[Val]   Batch [1/11] Loss: 0.0386, PSNR: 1.1007\n",
      "\t[Val]   Batch [10/11] Loss: 0.0386, PSNR: -1.1373\n",
      "Epoch [13/50] Validation Loss: 0.0386, PSNR: -0.8307\n",
      "\n",
      "LOG: Epoch [14/50]\n",
      "\t Training Batch [1/41], Loss: 0.0378, PSNR: 1.1853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50] Training Loss: 0.0364, PSNR: -1.0343\n",
      "\t[Val]   Batch [1/11] Loss: 0.0345, PSNR: 1.5910\n",
      "\t[Val]   Batch [10/11] Loss: 0.0345, PSNR: -0.6472\n",
      "Epoch [14/50] Validation Loss: 0.0344, PSNR: -0.3396\n",
      "\n",
      "LOG: Epoch [15/50]\n",
      "\t Training Batch [1/41], Loss: 0.0343, PSNR: -1.8177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50] Training Loss: 0.0325, PSNR: -0.8027\n",
      "\t[Val]   Batch [1/11] Loss: 0.0313, PSNR: 2.0123\n",
      "\t[Val]   Batch [10/11] Loss: 0.0313, PSNR: -0.2265\n",
      "Epoch [15/50] Validation Loss: 0.0313, PSNR: 0.0807\n",
      "\n",
      "LOG: Epoch [16/50]\n",
      "\t Training Batch [1/41], Loss: 0.0298, PSNR: 2.2271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] Training Loss: 0.0293, PSNR: 0.0391\n",
      "\t[Val]   Batch [1/11] Loss: 0.0280, PSNR: 2.4949\n",
      "\t[Val]   Batch [10/11] Loss: 0.0280, PSNR: 0.2553\n",
      "Epoch [16/50] Validation Loss: 0.0280, PSNR: 0.5630\n",
      "\n",
      "LOG: Epoch [17/50]\n",
      "\t Training Batch [1/41], Loss: 0.0274, PSNR: 0.3521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50] Training Loss: 0.0266, PSNR: 0.4037\n",
      "\t[Val]   Batch [1/11] Loss: 0.0255, PSNR: 2.9013\n",
      "\t[Val]   Batch [10/11] Loss: 0.0255, PSNR: 0.6594\n",
      "Epoch [17/50] Validation Loss: 0.0255, PSNR: 0.9690\n",
      "\n",
      "LOG: Epoch [18/50]\n",
      "\t Training Batch [1/41], Loss: 0.0254, PSNR: -1.5647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50] Training Loss: 0.0242, PSNR: 0.5871\n",
      "\t[Val]   Batch [1/11] Loss: 0.0236, PSNR: 3.2413\n",
      "\t[Val]   Batch [10/11] Loss: 0.0236, PSNR: 0.9987\n",
      "Epoch [18/50] Validation Loss: 0.0236, PSNR: 1.3083\n",
      "\n",
      "LOG: Epoch [19/50]\n",
      "\t Training Batch [1/41], Loss: 0.0225, PSNR: 0.5926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50] Training Loss: 0.0221, PSNR: 0.9211\n",
      "\t[Val]   Batch [1/11] Loss: 0.0214, PSNR: 3.6564\n",
      "\t[Val]   Batch [10/11] Loss: 0.0214, PSNR: 1.4150\n",
      "Epoch [19/50] Validation Loss: 0.0214, PSNR: 1.7243\n",
      "\n",
      "LOG: Epoch [20/50]\n",
      "\t Training Batch [1/41], Loss: 0.0207, PSNR: 2.2290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50] Training Loss: 0.0203, PSNR: 1.4266\n",
      "\t[Val]   Batch [1/11] Loss: 0.0198, PSNR: 3.9980\n",
      "\t[Val]   Batch [10/11] Loss: 0.0198, PSNR: 1.7577\n",
      "Epoch [20/50] Validation Loss: 0.0198, PSNR: 2.0670\n",
      "\n",
      "LOG: Epoch [21/50]\n",
      "\t Training Batch [1/41], Loss: 0.0193, PSNR: 0.1773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50] Training Loss: 0.0187, PSNR: 1.7228\n",
      "\t[Val]   Batch [1/11] Loss: 0.0184, PSNR: 4.3046\n",
      "\t[Val]   Batch [10/11] Loss: 0.0185, PSNR: 2.0639\n",
      "Epoch [21/50] Validation Loss: 0.0184, PSNR: 2.3726\n",
      "\n",
      "LOG: Epoch [22/50]\n",
      "\t Training Batch [1/41], Loss: 0.0174, PSNR: 0.1063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50] Training Loss: 0.0173, PSNR: 2.1186\n",
      "\t[Val]   Batch [1/11] Loss: 0.0170, PSNR: 4.6565\n",
      "\t[Val]   Batch [10/11] Loss: 0.0170, PSNR: 2.4154\n",
      "Epoch [22/50] Validation Loss: 0.0170, PSNR: 2.7249\n",
      "\n",
      "LOG: Epoch [23/50]\n",
      "\t Training Batch [1/41], Loss: 0.0168, PSNR: 2.4812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50] Training Loss: 0.0160, PSNR: 2.4227\n",
      "\t[Val]   Batch [1/11] Loss: 0.0158, PSNR: 4.9769\n",
      "\t[Val]   Batch [10/11] Loss: 0.0158, PSNR: 2.7349\n",
      "Epoch [23/50] Validation Loss: 0.0158, PSNR: 3.0463\n",
      "\n",
      "LOG: Epoch [24/50]\n",
      "\t Training Batch [1/41], Loss: 0.0157, PSNR: 0.2233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50] Training Loss: 0.0150, PSNR: 2.6323\n",
      "\t[Val]   Batch [1/11] Loss: 0.0148, PSNR: 5.2649\n",
      "\t[Val]   Batch [10/11] Loss: 0.0148, PSNR: 3.0235\n",
      "Epoch [24/50] Validation Loss: 0.0148, PSNR: 3.3343\n",
      "\n",
      "LOG: Epoch [25/50]\n",
      "\t Training Batch [1/41], Loss: 0.0140, PSNR: 2.0922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50] Training Loss: 0.0139, PSNR: 2.9413\n",
      "\t[Val]   Batch [1/11] Loss: 0.0137, PSNR: 5.6046\n",
      "\t[Val]   Batch [10/11] Loss: 0.0137, PSNR: 3.3638\n",
      "Epoch [25/50] Validation Loss: 0.0137, PSNR: 3.6740\n",
      "\n",
      "LOG: Epoch [26/50]\n",
      "\t Training Batch [1/41], Loss: 0.0129, PSNR: 3.0579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50] Training Loss: 0.0130, PSNR: 3.4192\n",
      "\t[Val]   Batch [1/11] Loss: 0.0128, PSNR: 5.8774\n",
      "\t[Val]   Batch [10/11] Loss: 0.0129, PSNR: 3.6357\n",
      "Epoch [26/50] Validation Loss: 0.0128, PSNR: 3.9467\n",
      "\n",
      "LOG: Epoch [27/50]\n",
      "\t Training Batch [1/41], Loss: 0.0119, PSNR: 3.2519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50] Training Loss: 0.0122, PSNR: 3.6150\n",
      "\t[Val]   Batch [1/11] Loss: 0.0121, PSNR: 6.1403\n",
      "\t[Val]   Batch [10/11] Loss: 0.0121, PSNR: 3.8998\n",
      "Epoch [27/50] Validation Loss: 0.0121, PSNR: 4.2094\n",
      "\n",
      "LOG: Epoch [28/50]\n",
      "\t Training Batch [1/41], Loss: 0.0120, PSNR: 1.9373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50] Training Loss: 0.0114, PSNR: 3.6190\n",
      "\t[Val]   Batch [1/11] Loss: 0.0113, PSNR: 6.4170\n",
      "\t[Val]   Batch [10/11] Loss: 0.0114, PSNR: 4.1766\n",
      "Epoch [28/50] Validation Loss: 0.0113, PSNR: 4.4867\n",
      "\n",
      "LOG: Epoch [29/50]\n",
      "\t Training Batch [1/41], Loss: 0.0109, PSNR: 6.5952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50] Training Loss: 0.0107, PSNR: 3.9804\n",
      "\t[Val]   Batch [1/11] Loss: 0.0106, PSNR: 6.6895\n",
      "\t[Val]   Batch [10/11] Loss: 0.0107, PSNR: 4.4489\n",
      "Epoch [29/50] Validation Loss: 0.0106, PSNR: 4.7594\n",
      "\n",
      "LOG: Epoch [30/50]\n",
      "\t Training Batch [1/41], Loss: 0.0101, PSNR: 4.9964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50] Training Loss: 0.0101, PSNR: 4.3849\n",
      "\t[Val]   Batch [1/11] Loss: 0.0101, PSNR: 6.9391\n",
      "\t[Val]   Batch [10/11] Loss: 0.0101, PSNR: 4.6989\n",
      "Epoch [30/50] Validation Loss: 0.0101, PSNR: 5.0096\n",
      "\n",
      "LOG: Epoch [31/50]\n",
      "\t Training Batch [1/41], Loss: 0.0097, PSNR: 3.6579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50] Training Loss: 0.0095, PSNR: 4.6827\n",
      "\t[Val]   Batch [1/11] Loss: 0.0095, PSNR: 7.2005\n",
      "\t[Val]   Batch [10/11] Loss: 0.0095, PSNR: 4.9610\n",
      "Epoch [31/50] Validation Loss: 0.0095, PSNR: 5.2718\n",
      "\n",
      "LOG: Epoch [32/50]\n",
      "\t Training Batch [1/41], Loss: 0.0093, PSNR: 3.0606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50] Training Loss: 0.0090, PSNR: 5.0399\n",
      "\t[Val]   Batch [1/11] Loss: 0.0090, PSNR: 7.4172\n",
      "\t[Val]   Batch [10/11] Loss: 0.0090, PSNR: 5.1771\n",
      "Epoch [32/50] Validation Loss: 0.0090, PSNR: 5.4883\n",
      "\n",
      "LOG: Epoch [33/50]\n",
      "\t Training Batch [1/41], Loss: 0.0085, PSNR: 6.0074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50] Training Loss: 0.0085, PSNR: 5.0189\n",
      "\t[Val]   Batch [1/11] Loss: 0.0085, PSNR: 7.6632\n",
      "\t[Val]   Batch [10/11] Loss: 0.0085, PSNR: 5.4218\n",
      "Epoch [33/50] Validation Loss: 0.0085, PSNR: 5.7340\n",
      "\n",
      "LOG: Epoch [34/50]\n",
      "\t Training Batch [1/41], Loss: 0.0081, PSNR: 4.9293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50] Training Loss: 0.0080, PSNR: 5.5188\n",
      "\t[Val]   Batch [1/11] Loss: 0.0080, PSNR: 7.9105\n",
      "\t[Val]   Batch [10/11] Loss: 0.0080, PSNR: 5.6693\n",
      "Epoch [34/50] Validation Loss: 0.0080, PSNR: 5.9825\n",
      "\n",
      "LOG: Epoch [35/50]\n",
      "\t Training Batch [1/41], Loss: 0.0078, PSNR: 6.1076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50] Training Loss: 0.0076, PSNR: 5.7336\n",
      "\t[Val]   Batch [1/11] Loss: 0.0077, PSNR: 8.1120\n",
      "\t[Val]   Batch [10/11] Loss: 0.0077, PSNR: 5.8721\n",
      "Epoch [35/50] Validation Loss: 0.0077, PSNR: 6.1827\n",
      "\n",
      "LOG: Epoch [36/50]\n",
      "\t Training Batch [1/41], Loss: 0.0072, PSNR: 4.1399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50] Training Loss: 0.0072, PSNR: 5.9327\n",
      "\t[Val]   Batch [1/11] Loss: 0.0073, PSNR: 8.3592\n",
      "\t[Val]   Batch [10/11] Loss: 0.0073, PSNR: 6.1201\n",
      "Epoch [36/50] Validation Loss: 0.0072, PSNR: 6.4319\n",
      "\n",
      "LOG: Epoch [37/50]\n",
      "\t Training Batch [1/41], Loss: 0.0073, PSNR: 4.7612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50] Training Loss: 0.0069, PSNR: 6.0397\n",
      "\t[Val]   Batch [1/11] Loss: 0.0069, PSNR: 8.5663\n",
      "\t[Val]   Batch [10/11] Loss: 0.0069, PSNR: 6.3272\n",
      "Epoch [37/50] Validation Loss: 0.0069, PSNR: 6.6385\n",
      "\n",
      "LOG: Epoch [38/50]\n",
      "\t Training Batch [1/41], Loss: 0.0069, PSNR: 4.3760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50] Training Loss: 0.0066, PSNR: 6.2608\n",
      "\t[Val]   Batch [1/11] Loss: 0.0066, PSNR: 8.7978\n",
      "\t[Val]   Batch [10/11] Loss: 0.0066, PSNR: 6.5595\n",
      "Epoch [38/50] Validation Loss: 0.0065, PSNR: 6.8705\n",
      "\n",
      "LOG: Epoch [39/50]\n",
      "\t Training Batch [1/41], Loss: 0.0063, PSNR: 6.5219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50] Training Loss: 0.0062, PSNR: 6.7366\n",
      "\t[Val]   Batch [1/11] Loss: 0.0063, PSNR: 8.9975\n",
      "\t[Val]   Batch [10/11] Loss: 0.0063, PSNR: 6.7600\n",
      "Epoch [39/50] Validation Loss: 0.0063, PSNR: 7.0714\n",
      "\n",
      "LOG: Epoch [40/50]\n",
      "\t Training Batch [1/41], Loss: 0.0060, PSNR: 7.8385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50] Training Loss: 0.0060, PSNR: 6.7871\n",
      "\t[Val]   Batch [1/11] Loss: 0.0060, PSNR: 9.1790\n",
      "\t[Val]   Batch [10/11] Loss: 0.0060, PSNR: 6.9416\n",
      "Epoch [40/50] Validation Loss: 0.0060, PSNR: 7.2518\n",
      "\n",
      "LOG: Epoch [41/50]\n",
      "\t Training Batch [1/41], Loss: 0.0056, PSNR: 8.1610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50] Training Loss: 0.0057, PSNR: 6.9757\n",
      "\t[Val]   Batch [1/11] Loss: 0.0057, PSNR: 9.3702\n",
      "\t[Val]   Batch [10/11] Loss: 0.0057, PSNR: 7.1324\n",
      "Epoch [41/50] Validation Loss: 0.0057, PSNR: 7.4429\n",
      "\n",
      "LOG: Epoch [42/50]\n",
      "\t Training Batch [1/41], Loss: 0.0054, PSNR: 6.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50] Training Loss: 0.0055, PSNR: 7.0373\n",
      "\t[Val]   Batch [1/11] Loss: 0.0055, PSNR: 9.5434\n",
      "\t[Val]   Batch [10/11] Loss: 0.0055, PSNR: 7.3062\n",
      "Epoch [42/50] Validation Loss: 0.0055, PSNR: 7.6159\n",
      "\n",
      "LOG: Epoch [43/50]\n",
      "\t Training Batch [1/41], Loss: 0.0053, PSNR: 7.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50] Training Loss: 0.0052, PSNR: 7.2300\n",
      "\t[Val]   Batch [1/11] Loss: 0.0052, PSNR: 9.7731\n",
      "\t[Val]   Batch [10/11] Loss: 0.0052, PSNR: 7.5347\n",
      "Epoch [43/50] Validation Loss: 0.0052, PSNR: 7.8468\n",
      "\n",
      "LOG: Epoch [44/50]\n",
      "\t Training Batch [1/41], Loss: 0.0049, PSNR: 6.7649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50] Training Loss: 0.0050, PSNR: 7.4572\n",
      "\t[Val]   Batch [1/11] Loss: 0.0050, PSNR: 9.9607\n",
      "\t[Val]   Batch [10/11] Loss: 0.0050, PSNR: 7.7213\n",
      "Epoch [44/50] Validation Loss: 0.0050, PSNR: 8.0341\n",
      "\n",
      "LOG: Epoch [45/50]\n",
      "\t Training Batch [1/41], Loss: 0.0047, PSNR: 7.3052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50] Training Loss: 0.0048, PSNR: 7.8116\n",
      "\t[Val]   Batch [1/11] Loss: 0.0048, PSNR: 10.1345\n",
      "\t[Val]   Batch [10/11] Loss: 0.0048, PSNR: 7.8953\n",
      "Epoch [45/50] Validation Loss: 0.0048, PSNR: 8.2069\n",
      "\n",
      "LOG: Epoch [46/50]\n",
      "\t Training Batch [1/41], Loss: 0.0049, PSNR: 5.6319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50] Training Loss: 0.0046, PSNR: 7.7643\n",
      "\t[Val]   Batch [1/11] Loss: 0.0046, PSNR: 10.3100\n",
      "\t[Val]   Batch [10/11] Loss: 0.0046, PSNR: 8.0719\n",
      "Epoch [46/50] Validation Loss: 0.0046, PSNR: 8.3826\n",
      "\n",
      "LOG: Epoch [47/50]\n",
      "\t Training Batch [1/41], Loss: 0.0045, PSNR: 6.8432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50] Training Loss: 0.0044, PSNR: 8.1570\n",
      "\t[Val]   Batch [1/11] Loss: 0.0045, PSNR: 10.4687\n",
      "\t[Val]   Batch [10/11] Loss: 0.0045, PSNR: 8.2300\n",
      "Epoch [47/50] Validation Loss: 0.0045, PSNR: 8.5414\n",
      "\n",
      "LOG: Epoch [48/50]\n",
      "\t Training Batch [1/41], Loss: 0.0041, PSNR: 8.4146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50] Training Loss: 0.0042, PSNR: 8.1045\n",
      "\t[Val]   Batch [1/11] Loss: 0.0043, PSNR: 10.6754\n",
      "\t[Val]   Batch [10/11] Loss: 0.0043, PSNR: 8.4366\n",
      "Epoch [48/50] Validation Loss: 0.0042, PSNR: 8.7493\n",
      "\n",
      "LOG: Epoch [49/50]\n",
      "\t Training Batch [1/41], Loss: 0.0042, PSNR: 7.8858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50] Training Loss: 0.0041, PSNR: 8.3739\n",
      "\t[Val]   Batch [1/11] Loss: 0.0041, PSNR: 10.8189\n",
      "\t[Val]   Batch [10/11] Loss: 0.0041, PSNR: 8.5814\n",
      "Epoch [49/50] Validation Loss: 0.0041, PSNR: 8.8922\n",
      "\n",
      "LOG: Epoch [50/50]\n",
      "\t Training Batch [1/41], Loss: 0.0040, PSNR: 9.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50] Training Loss: 0.0039, PSNR: 8.6274\n",
      "\t[Val]   Batch [1/11] Loss: 0.0039, PSNR: 11.0156\n",
      "\t[Val]   Batch [10/11] Loss: 0.0039, PSNR: 8.7795\n",
      "Epoch [50/50] Validation Loss: 0.0039, PSNR: 9.0891\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_cae = ConvAutoEncode()\n",
    "criterion_cae = nn.MSELoss()\n",
    "optimizer_cae = optim.Adam(model_cae.parameters(), lr=0.0001)\n",
    "\n",
    "#parameters for CAE\n",
    "num_epochs_cae = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_cae = model_cae.to(device)\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 3  # number of epochs to wait for improvement\n",
    "tolerance = 1e-4\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "#grad accumulation parameters\n",
    "accumulation_steps = 8 \n",
    "\n",
    "# for loss and metrics tracking\n",
    "autoencoder_epoch_losses_cae = []\n",
    "validation_epoch_losses_cae = []\n",
    "train_psnr = []\n",
    "val_psnr = []\n",
    "\n",
    "psnr = PeakSignalNoiseRatio().to(device)\n",
    "\n",
    "# mixed precision training\n",
    "scaler = GradScaler()  # Gradient scaler for mixed precision\n",
    "\n",
    "for epoch in range(num_epochs_cae):\n",
    "    # training\n",
    "    model_cae.train()\n",
    "    running_loss = 0.0\n",
    "    running_psnr = 0.0\n",
    "\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs_cae}]\")\n",
    "\n",
    "    optimizer_cae.zero_grad()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader_cae):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "        # mixed precision forward pass\n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            _, decoded = model_cae(data)\n",
    "            loss = criterion_cae(decoded, data) / accumulation_steps\n",
    "\n",
    "            with torch.no_grad():\n",
    "                nan_in_out = torch.isnan(decoded).any().item()\n",
    "                inf_in_out = torch.isinf(decoded).any().item()\n",
    "\n",
    "        #backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        loss_value = loss.item() * accumulation_steps\n",
    "        running_loss += loss_value\n",
    "\n",
    "        psnr_value = psnr(decoded, data).item()\n",
    "        running_psnr += psnr_value\n",
    "\n",
    "\n",
    "        # performing optimizer step and reset gradients after `accumulation_steps` batches\n",
    "        if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader_cae):\n",
    "            scaler.step(optimizer_cae)\n",
    "            scaler.update()\n",
    "            optimizer_cae.zero_grad()\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 200 == 0:\n",
    "            print(\n",
    "    f\"\\t Training Batch [{batch_idx + 1}/{len(train_loader_cae)}], \"\n",
    "    f\"Loss: {loss_value:.4f}, PSNR: {psnr_value:.4f}\"\n",
    ")\n",
    "\n",
    "\n",
    "        #delete intermediate variables and clear GPU cache\n",
    "        del data, decoded, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    #compute average metrics for the epoch\n",
    "    avg_train_loss = running_loss / len(train_loader_cae)\n",
    "    avg_train_psnr = running_psnr / len(train_loader_cae)\n",
    "\n",
    "    autoencoder_epoch_losses_cae.append(avg_train_loss)\n",
    "    train_psnr.append(avg_train_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Training Loss: {avg_train_loss:.4f}, PSNR: {avg_train_psnr:.4f}\")\n",
    "\n",
    "    #clear GPU cache after training\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    #validation\n",
    "    model_cae.eval()\n",
    "    validation_loss = 0.0\n",
    "    val_psnr_epoch = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(val_loader_cae):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # Mixed precision forward pass for validation\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                _, decoded = model_cae(data)\n",
    "                loss = criterion_cae(decoded, data)\n",
    "\n",
    "            validation_loss += loss.item()\n",
    "            val_psnr_epoch += psnr(decoded, data).item()\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                loss_val = loss.item()\n",
    "                psnr_val = psnr(decoded, data).item()\n",
    "                print(\n",
    "                    f\"\\t[Val]   Batch [{batch_idx + 1}/{len(val_loader_cae)}] \"\n",
    "                    f\"Loss: {loss_val:.4f}, PSNR: {psnr_val:.4f}\"\n",
    "                )\n",
    "\n",
    "            del data, decoded, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # average validation metrics for the epoch\n",
    "    avg_val_loss = validation_loss / len(val_loader_cae)\n",
    "    avg_val_psnr = val_psnr_epoch / len(val_loader_cae)\n",
    "\n",
    "    validation_epoch_losses_cae.append(avg_val_loss)\n",
    "    val_psnr.append(avg_val_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Validation Loss: {avg_val_loss:.4f}, PSNR: {avg_val_psnr:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss < best_val_loss - tolerance:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0  # Reset counter\n",
    "        #best model checkpoint\n",
    "        #torch.save(model_cae.state_dict(), 'best_model_cae.pth')\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "#plot for training and validation loss trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(autoencoder_epoch_losses_cae) + 1), autoencoder_epoch_losses_cae, marker='o', label=\"Training Loss\")\n",
    "plt.plot(range(1, len(validation_epoch_losses_cae) + 1), validation_epoch_losses_cae, marker='x', label=\"Validation Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#plot for PSNR trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_psnr) + 1), train_psnr, marker='o', label=\"Training PSNR\")\n",
    "plt.plot(range(1, len(val_psnr) + 1), val_psnr, marker='x', label=\"Validation PSNR\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('PSNR Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the encoder section of CAE as feature extractor to generate compact representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:42.424677Z",
     "iopub.status.busy": "2025-05-08T19:17:42.424677Z",
     "iopub.status.idle": "2025-05-08T19:17:42.570579Z",
     "shell.execute_reply": "2025-05-08T19:17:42.570579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting representations for the train dataset...\n",
      "    Processed batch 1/1 for train dataset.\n",
      "Completed encoding for the train dataset.\n",
      "\n",
      "Extracting representations for the val dataset...\n",
      "    Processed batch 1/1 for val dataset.\n",
      "Completed encoding for the val dataset.\n",
      "\n",
      "Extracting representations for the test dataset...\n",
      "    Processed batch 1/12 for test dataset.\n",
      "Completed encoding for the test dataset.\n",
      "Feature extraction completed for all subsets.\n"
     ]
    }
   ],
   "source": [
    "#dir to save encoded representations\n",
    "encoded_dir = 'encoded_representations'\n",
    "os.makedirs(encoded_dir, exist_ok=True)\n",
    "\n",
    "loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "model_cae.eval()\n",
    "\n",
    "# Feature extraction\n",
    "with torch.no_grad():\n",
    "    for subset_name, loader in loaders.items():\n",
    "        print(f\"\\nExtracting representations for the {subset_name} dataset...\")\n",
    "\n",
    "        # dir for the given subset's encoded features\n",
    "        subset_encoded_dir = os.path.join(encoded_dir, subset_name)\n",
    "        os.makedirs(subset_encoded_dir, exist_ok=True)\n",
    "\n",
    "        for batch_idx, (data, labels) in enumerate(loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # passing data through the encoder to obtain representations\n",
    "            encoded_features, _ = model_cae(data)  # latent representation\n",
    "\n",
    "            # moving to CPU and convert to NumPy\n",
    "            encoded_features = encoded_features.cpu().numpy()  \n",
    "            labels = labels.cpu().numpy() \n",
    "\n",
    "            #saving the encoded features and labels\n",
    "            np.save(os.path.join(subset_encoded_dir, f'encoded_batch_{batch_idx}.npy'), encoded_features)\n",
    "            np.save(os.path.join(subset_encoded_dir, f'labels_batch_{batch_idx}.npy'), labels)\n",
    "\n",
    "            if batch_idx % 1 == 0 and subset_name != 'test':\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "            elif subset_name == 'test' and batch_idx % 100 == 0:  # Log less frequently for the test set\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed encoding for the {subset_name} dataset.\")\n",
    "\n",
    "print(\"Feature extraction completed for all subsets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-To-End CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:42.573608Z",
     "iopub.status.busy": "2025-05-08T19:17:42.573608Z",
     "iopub.status.idle": "2025-05-08T19:17:42.578091Z",
     "shell.execute_reply": "2025-05-08T19:17:42.578091Z"
    }
   },
   "outputs": [],
   "source": [
    "class hyperspectralCNN(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(hyperspectralCNN, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #fully connected layers for classification\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),  #3D to 1D vector for input to FC layers\n",
    "            nn.Linear(16 * 2 * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:42.580097Z",
     "iopub.status.busy": "2025-05-08T19:17:42.580097Z",
     "iopub.status.idle": "2025-05-08T19:17:50.170531Z",
     "shell.execute_reply": "2025-05-08T19:17:50.170531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] completed, Average Training Loss: 2.6464\n",
      "    Validation Batch [1/1], Loss: 2.6432\n",
      "Validation Loss: 2.6432, Validation Accuracy: 7.14%\n",
      "Validation loss improved from inf to 2.6432. Saving model...\n",
      "\n",
      "LOG: Epoch [2/1000] - Training\n",
      "Epoch [2/1000] completed, Average Training Loss: 2.6023\n",
      "    Validation Batch [1/1], Loss: 2.6432\n",
      "Validation Loss: 2.6432, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [3/1000] - Training\n",
      "Epoch [3/1000] completed, Average Training Loss: 2.5779\n",
      "    Validation Batch [1/1], Loss: 2.6432\n",
      "Validation Loss: 2.6432, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6432 to 2.6432. Saving model...\n",
      "\n",
      "LOG: Epoch [4/1000] - Training\n",
      "Epoch [4/1000] completed, Average Training Loss: 2.5596\n",
      "    Validation Batch [1/1], Loss: 2.6432\n",
      "Validation Loss: 2.6432, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6432 to 2.6432. Saving model...\n",
      "\n",
      "LOG: Epoch [5/1000] - Training\n",
      "Epoch [5/1000] completed, Average Training Loss: 2.5443\n",
      "    Validation Batch [1/1], Loss: 2.6431\n",
      "Validation Loss: 2.6431, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6432 to 2.6431. Saving model...\n",
      "\n",
      "LOG: Epoch [6/1000] - Training\n",
      "Epoch [6/1000] completed, Average Training Loss: 2.5222\n",
      "    Validation Batch [1/1], Loss: 2.6431\n",
      "Validation Loss: 2.6431, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6431 to 2.6431. Saving model...\n",
      "\n",
      "LOG: Epoch [7/1000] - Training\n",
      "Epoch [7/1000] completed, Average Training Loss: 2.5081\n",
      "    Validation Batch [1/1], Loss: 2.6430\n",
      "Validation Loss: 2.6430, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6431 to 2.6430. Saving model...\n",
      "\n",
      "LOG: Epoch [8/1000] - Training\n",
      "Epoch [8/1000] completed, Average Training Loss: 2.4884\n",
      "    Validation Batch [1/1], Loss: 2.6429\n",
      "Validation Loss: 2.6429, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6430 to 2.6429. Saving model...\n",
      "\n",
      "LOG: Epoch [9/1000] - Training\n",
      "Epoch [9/1000] completed, Average Training Loss: 2.4741\n",
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6429 to 2.6428. Saving model...\n",
      "\n",
      "LOG: Epoch [10/1000] - Training\n",
      "Epoch [10/1000] completed, Average Training Loss: 2.4579\n",
      "    Validation Batch [1/1], Loss: 2.6427\n",
      "Validation Loss: 2.6427, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6428 to 2.6427. Saving model...\n",
      "\n",
      "LOG: Epoch [11/1000] - Training\n",
      "Epoch [11/1000] completed, Average Training Loss: 2.4437\n",
      "    Validation Batch [1/1], Loss: 2.6425\n",
      "Validation Loss: 2.6425, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6427 to 2.6425. Saving model...\n",
      "\n",
      "LOG: Epoch [12/1000] - Training\n",
      "Epoch [12/1000] completed, Average Training Loss: 2.4279\n",
      "    Validation Batch [1/1], Loss: 2.6424\n",
      "Validation Loss: 2.6424, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6425 to 2.6424. Saving model...\n",
      "\n",
      "LOG: Epoch [13/1000] - Training\n",
      "Epoch [13/1000] completed, Average Training Loss: 2.4153\n",
      "    Validation Batch [1/1], Loss: 2.6422\n",
      "Validation Loss: 2.6422, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6424 to 2.6422. Saving model...\n",
      "\n",
      "LOG: Epoch [14/1000] - Training\n",
      "Epoch [14/1000] completed, Average Training Loss: 2.4045\n",
      "    Validation Batch [1/1], Loss: 2.6421\n",
      "Validation Loss: 2.6421, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6422 to 2.6421. Saving model...\n",
      "\n",
      "LOG: Epoch [15/1000] - Training\n",
      "Epoch [15/1000] completed, Average Training Loss: 2.3894\n",
      "    Validation Batch [1/1], Loss: 2.6419\n",
      "Validation Loss: 2.6419, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6421 to 2.6419. Saving model...\n",
      "\n",
      "LOG: Epoch [16/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/1000] completed, Average Training Loss: 2.3790\n",
      "    Validation Batch [1/1], Loss: 2.6418\n",
      "Validation Loss: 2.6418, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6419 to 2.6418. Saving model...\n",
      "\n",
      "LOG: Epoch [17/1000] - Training\n",
      "Epoch [17/1000] completed, Average Training Loss: 2.3693\n",
      "    Validation Batch [1/1], Loss: 2.6416\n",
      "Validation Loss: 2.6416, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6418 to 2.6416. Saving model...\n",
      "\n",
      "LOG: Epoch [18/1000] - Training\n",
      "Epoch [18/1000] completed, Average Training Loss: 2.3460\n",
      "    Validation Batch [1/1], Loss: 2.6415\n",
      "Validation Loss: 2.6415, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6416 to 2.6415. Saving model...\n",
      "\n",
      "LOG: Epoch [19/1000] - Training\n",
      "Epoch [19/1000] completed, Average Training Loss: 2.3363\n",
      "    Validation Batch [1/1], Loss: 2.6414\n",
      "Validation Loss: 2.6414, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6415 to 2.6414. Saving model...\n",
      "\n",
      "LOG: Epoch [20/1000] - Training\n",
      "Epoch [20/1000] completed, Average Training Loss: 2.3333\n",
      "    Validation Batch [1/1], Loss: 2.6413\n",
      "Validation Loss: 2.6413, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6414 to 2.6413. Saving model...\n",
      "\n",
      "LOG: Epoch [21/1000] - Training\n",
      "Epoch [21/1000] completed, Average Training Loss: 2.3158\n",
      "    Validation Batch [1/1], Loss: 2.6410\n",
      "Validation Loss: 2.6410, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6413 to 2.6410. Saving model...\n",
      "\n",
      "LOG: Epoch [22/1000] - Training\n",
      "Epoch [22/1000] completed, Average Training Loss: 2.2953\n",
      "    Validation Batch [1/1], Loss: 2.6408\n",
      "Validation Loss: 2.6408, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6410 to 2.6408. Saving model...\n",
      "\n",
      "LOG: Epoch [23/1000] - Training\n",
      "Epoch [23/1000] completed, Average Training Loss: 2.2830\n",
      "    Validation Batch [1/1], Loss: 2.6406\n",
      "Validation Loss: 2.6406, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6408 to 2.6406. Saving model...\n",
      "\n",
      "LOG: Epoch [24/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/1000] completed, Average Training Loss: 2.2761\n",
      "    Validation Batch [1/1], Loss: 2.6404\n",
      "Validation Loss: 2.6404, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6406 to 2.6404. Saving model...\n",
      "\n",
      "LOG: Epoch [25/1000] - Training\n",
      "Epoch [25/1000] completed, Average Training Loss: 2.2492\n",
      "    Validation Batch [1/1], Loss: 2.6402\n",
      "Validation Loss: 2.6402, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6404 to 2.6402. Saving model...\n",
      "\n",
      "LOG: Epoch [26/1000] - Training\n",
      "Epoch [26/1000] completed, Average Training Loss: 2.2433\n",
      "    Validation Batch [1/1], Loss: 2.6399\n",
      "Validation Loss: 2.6399, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6402 to 2.6399. Saving model...\n",
      "\n",
      "LOG: Epoch [27/1000] - Training\n",
      "Epoch [27/1000] completed, Average Training Loss: 2.2203\n",
      "    Validation Batch [1/1], Loss: 2.6398\n",
      "Validation Loss: 2.6398, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6399 to 2.6398. Saving model...\n",
      "\n",
      "LOG: Epoch [28/1000] - Training\n",
      "Epoch [28/1000] completed, Average Training Loss: 2.2237\n",
      "    Validation Batch [1/1], Loss: 2.6397\n",
      "Validation Loss: 2.6397, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6398 to 2.6397. Saving model...\n",
      "\n",
      "LOG: Epoch [29/1000] - Training\n",
      "Epoch [29/1000] completed, Average Training Loss: 2.1925\n",
      "    Validation Batch [1/1], Loss: 2.6395\n",
      "Validation Loss: 2.6395, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6397 to 2.6395. Saving model...\n",
      "\n",
      "LOG: Epoch [30/1000] - Training\n",
      "Epoch [30/1000] completed, Average Training Loss: 2.1980\n",
      "    Validation Batch [1/1], Loss: 2.6393\n",
      "Validation Loss: 2.6393, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6395 to 2.6393. Saving model...\n",
      "\n",
      "LOG: Epoch [31/1000] - Training\n",
      "Epoch [31/1000] completed, Average Training Loss: 2.1849\n",
      "    Validation Batch [1/1], Loss: 2.6386\n",
      "Validation Loss: 2.6386, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6393 to 2.6386. Saving model...\n",
      "\n",
      "LOG: Epoch [32/1000] - Training\n",
      "Epoch [32/1000] completed, Average Training Loss: 2.1660\n",
      "    Validation Batch [1/1], Loss: 2.6382\n",
      "Validation Loss: 2.6382, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6386 to 2.6382. Saving model...\n",
      "\n",
      "LOG: Epoch [33/1000] - Training\n",
      "Epoch [33/1000] completed, Average Training Loss: 2.1650\n",
      "    Validation Batch [1/1], Loss: 2.6378\n",
      "Validation Loss: 2.6378, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6382 to 2.6378. Saving model...\n",
      "\n",
      "LOG: Epoch [34/1000] - Training\n",
      "Epoch [34/1000] completed, Average Training Loss: 2.1390\n",
      "    Validation Batch [1/1], Loss: 2.6373\n",
      "Validation Loss: 2.6373, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6378 to 2.6373. Saving model...\n",
      "\n",
      "LOG: Epoch [35/1000] - Training\n",
      "Epoch [35/1000] completed, Average Training Loss: 2.1516\n",
      "    Validation Batch [1/1], Loss: 2.6367\n",
      "Validation Loss: 2.6367, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6373 to 2.6367. Saving model...\n",
      "\n",
      "LOG: Epoch [36/1000] - Training\n",
      "Epoch [36/1000] completed, Average Training Loss: 2.1349\n",
      "    Validation Batch [1/1], Loss: 2.6361\n",
      "Validation Loss: 2.6361, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6367 to 2.6361. Saving model...\n",
      "\n",
      "LOG: Epoch [37/1000] - Training\n",
      "Epoch [37/1000] completed, Average Training Loss: 2.1145\n",
      "    Validation Batch [1/1], Loss: 2.6356\n",
      "Validation Loss: 2.6356, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6361 to 2.6356. Saving model...\n",
      "\n",
      "LOG: Epoch [38/1000] - Training\n",
      "Epoch [38/1000] completed, Average Training Loss: 2.0925\n",
      "    Validation Batch [1/1], Loss: 2.6352\n",
      "Validation Loss: 2.6352, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6356 to 2.6352. Saving model...\n",
      "\n",
      "LOG: Epoch [39/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/1000] completed, Average Training Loss: 2.0824\n",
      "    Validation Batch [1/1], Loss: 2.6348\n",
      "Validation Loss: 2.6348, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6352 to 2.6348. Saving model...\n",
      "\n",
      "LOG: Epoch [40/1000] - Training\n",
      "Epoch [40/1000] completed, Average Training Loss: 2.0698\n",
      "    Validation Batch [1/1], Loss: 2.6341\n",
      "Validation Loss: 2.6341, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6348 to 2.6341. Saving model...\n",
      "\n",
      "LOG: Epoch [41/1000] - Training\n",
      "Epoch [41/1000] completed, Average Training Loss: 2.0572\n",
      "    Validation Batch [1/1], Loss: 2.6333\n",
      "Validation Loss: 2.6333, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6341 to 2.6333. Saving model...\n",
      "\n",
      "LOG: Epoch [42/1000] - Training\n",
      "Epoch [42/1000] completed, Average Training Loss: 2.0449\n",
      "    Validation Batch [1/1], Loss: 2.6320\n",
      "Validation Loss: 2.6320, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6333 to 2.6320. Saving model...\n",
      "\n",
      "LOG: Epoch [43/1000] - Training\n",
      "Epoch [43/1000] completed, Average Training Loss: 2.0321\n",
      "    Validation Batch [1/1], Loss: 2.6306\n",
      "Validation Loss: 2.6306, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6320 to 2.6306. Saving model...\n",
      "\n",
      "LOG: Epoch [44/1000] - Training\n",
      "Epoch [44/1000] completed, Average Training Loss: 2.0240\n",
      "    Validation Batch [1/1], Loss: 2.6289\n",
      "Validation Loss: 2.6289, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6306 to 2.6289. Saving model...\n",
      "\n",
      "LOG: Epoch [45/1000] - Training\n",
      "Epoch [45/1000] completed, Average Training Loss: 2.0326\n",
      "    Validation Batch [1/1], Loss: 2.6271\n",
      "Validation Loss: 2.6271, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6289 to 2.6271. Saving model...\n",
      "\n",
      "LOG: Epoch [46/1000] - Training\n",
      "Epoch [46/1000] completed, Average Training Loss: 2.0168\n",
      "    Validation Batch [1/1], Loss: 2.6255\n",
      "Validation Loss: 2.6255, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6271 to 2.6255. Saving model...\n",
      "\n",
      "LOG: Epoch [47/1000] - Training\n",
      "Epoch [47/1000] completed, Average Training Loss: 1.9952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 2.6237\n",
      "Validation Loss: 2.6237, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6255 to 2.6237. Saving model...\n",
      "\n",
      "LOG: Epoch [48/1000] - Training\n",
      "Epoch [48/1000] completed, Average Training Loss: 1.9843\n",
      "    Validation Batch [1/1], Loss: 2.6214\n",
      "Validation Loss: 2.6214, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6237 to 2.6214. Saving model...\n",
      "\n",
      "LOG: Epoch [49/1000] - Training\n",
      "Epoch [49/1000] completed, Average Training Loss: 1.9891\n",
      "    Validation Batch [1/1], Loss: 2.6186\n",
      "Validation Loss: 2.6186, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6214 to 2.6186. Saving model...\n",
      "\n",
      "LOG: Epoch [50/1000] - Training\n",
      "Epoch [50/1000] completed, Average Training Loss: 1.9627\n",
      "    Validation Batch [1/1], Loss: 2.6156\n",
      "Validation Loss: 2.6156, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6186 to 2.6156. Saving model...\n",
      "\n",
      "LOG: Epoch [51/1000] - Training\n",
      "Epoch [51/1000] completed, Average Training Loss: 1.9378\n",
      "    Validation Batch [1/1], Loss: 2.6117\n",
      "Validation Loss: 2.6117, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6156 to 2.6117. Saving model...\n",
      "\n",
      "LOG: Epoch [52/1000] - Training\n",
      "Epoch [52/1000] completed, Average Training Loss: 1.9452\n",
      "    Validation Batch [1/1], Loss: 2.6070\n",
      "Validation Loss: 2.6070, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6117 to 2.6070. Saving model...\n",
      "\n",
      "LOG: Epoch [53/1000] - Training\n",
      "Epoch [53/1000] completed, Average Training Loss: 1.9238\n",
      "    Validation Batch [1/1], Loss: 2.6014\n",
      "Validation Loss: 2.6014, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6070 to 2.6014. Saving model...\n",
      "\n",
      "LOG: Epoch [54/1000] - Training\n",
      "Epoch [54/1000] completed, Average Training Loss: 1.9284\n",
      "    Validation Batch [1/1], Loss: 2.5952\n",
      "Validation Loss: 2.5952, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6014 to 2.5952. Saving model...\n",
      "\n",
      "LOG: Epoch [55/1000] - Training\n",
      "Epoch [55/1000] completed, Average Training Loss: 1.9104\n",
      "    Validation Batch [1/1], Loss: 2.5881\n",
      "Validation Loss: 2.5881, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.5952 to 2.5881. Saving model...\n",
      "\n",
      "LOG: Epoch [56/1000] - Training\n",
      "Epoch [56/1000] completed, Average Training Loss: 1.8849\n",
      "    Validation Batch [1/1], Loss: 2.5785\n",
      "Validation Loss: 2.5785, Validation Accuracy: 8.57%\n",
      "Validation loss improved from 2.5881 to 2.5785. Saving model...\n",
      "\n",
      "LOG: Epoch [57/1000] - Training\n",
      "Epoch [57/1000] completed, Average Training Loss: 1.9083\n",
      "    Validation Batch [1/1], Loss: 2.5673\n",
      "Validation Loss: 2.5673, Validation Accuracy: 10.00%\n",
      "Validation loss improved from 2.5785 to 2.5673. Saving model...\n",
      "\n",
      "LOG: Epoch [58/1000] - Training\n",
      "Epoch [58/1000] completed, Average Training Loss: 1.8746\n",
      "    Validation Batch [1/1], Loss: 2.5561\n",
      "Validation Loss: 2.5561, Validation Accuracy: 10.00%\n",
      "Validation loss improved from 2.5673 to 2.5561. Saving model...\n",
      "\n",
      "LOG: Epoch [59/1000] - Training\n",
      "Epoch [59/1000] completed, Average Training Loss: 1.8968\n",
      "    Validation Batch [1/1], Loss: 2.5460\n",
      "Validation Loss: 2.5460, Validation Accuracy: 10.00%\n",
      "Validation loss improved from 2.5561 to 2.5460. Saving model...\n",
      "\n",
      "LOG: Epoch [60/1000] - Training\n",
      "Epoch [60/1000] completed, Average Training Loss: 1.8584\n",
      "    Validation Batch [1/1], Loss: 2.5335\n",
      "Validation Loss: 2.5335, Validation Accuracy: 12.86%\n",
      "Validation loss improved from 2.5460 to 2.5335. Saving model...\n",
      "\n",
      "LOG: Epoch [61/1000] - Training\n",
      "Epoch [61/1000] completed, Average Training Loss: 1.8722\n",
      "    Validation Batch [1/1], Loss: 2.5195\n",
      "Validation Loss: 2.5195, Validation Accuracy: 12.86%\n",
      "Validation loss improved from 2.5335 to 2.5195. Saving model...\n",
      "\n",
      "LOG: Epoch [62/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/1000] completed, Average Training Loss: 1.8366\n",
      "    Validation Batch [1/1], Loss: 2.5040\n",
      "Validation Loss: 2.5040, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.5195 to 2.5040. Saving model...\n",
      "\n",
      "LOG: Epoch [63/1000] - Training\n",
      "Epoch [63/1000] completed, Average Training Loss: 1.8151\n",
      "    Validation Batch [1/1], Loss: 2.4887\n",
      "Validation Loss: 2.4887, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.5040 to 2.4887. Saving model...\n",
      "\n",
      "LOG: Epoch [64/1000] - Training\n",
      "Epoch [64/1000] completed, Average Training Loss: 1.8299\n",
      "    Validation Batch [1/1], Loss: 2.4714\n",
      "Validation Loss: 2.4714, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.4887 to 2.4714. Saving model...\n",
      "\n",
      "LOG: Epoch [65/1000] - Training\n",
      "Epoch [65/1000] completed, Average Training Loss: 1.8187\n",
      "    Validation Batch [1/1], Loss: 2.4572\n",
      "Validation Loss: 2.4572, Validation Accuracy: 17.14%\n",
      "Validation loss improved from 2.4714 to 2.4572. Saving model...\n",
      "\n",
      "LOG: Epoch [66/1000] - Training\n",
      "Epoch [66/1000] completed, Average Training Loss: 1.8145\n",
      "    Validation Batch [1/1], Loss: 2.4412\n",
      "Validation Loss: 2.4412, Validation Accuracy: 18.57%\n",
      "Validation loss improved from 2.4572 to 2.4412. Saving model...\n",
      "\n",
      "LOG: Epoch [67/1000] - Training\n",
      "Epoch [67/1000] completed, Average Training Loss: 1.7905\n",
      "    Validation Batch [1/1], Loss: 2.4175\n",
      "Validation Loss: 2.4175, Validation Accuracy: 22.86%\n",
      "Validation loss improved from 2.4412 to 2.4175. Saving model...\n",
      "\n",
      "LOG: Epoch [68/1000] - Training\n",
      "Epoch [68/1000] completed, Average Training Loss: 1.7910\n",
      "    Validation Batch [1/1], Loss: 2.3920\n",
      "Validation Loss: 2.3920, Validation Accuracy: 25.71%\n",
      "Validation loss improved from 2.4175 to 2.3920. Saving model...\n",
      "\n",
      "LOG: Epoch [69/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/1000] completed, Average Training Loss: 1.7669\n",
      "    Validation Batch [1/1], Loss: 2.3666\n",
      "Validation Loss: 2.3666, Validation Accuracy: 34.29%\n",
      "Validation loss improved from 2.3920 to 2.3666. Saving model...\n",
      "\n",
      "LOG: Epoch [70/1000] - Training\n",
      "Epoch [70/1000] completed, Average Training Loss: 1.7813\n",
      "    Validation Batch [1/1], Loss: 2.3465\n",
      "Validation Loss: 2.3465, Validation Accuracy: 38.57%\n",
      "Validation loss improved from 2.3666 to 2.3465. Saving model...\n",
      "\n",
      "LOG: Epoch [71/1000] - Training\n",
      "Epoch [71/1000] completed, Average Training Loss: 1.7584\n",
      "    Validation Batch [1/1], Loss: 2.3303\n",
      "Validation Loss: 2.3303, Validation Accuracy: 44.29%\n",
      "Validation loss improved from 2.3465 to 2.3303. Saving model...\n",
      "\n",
      "LOG: Epoch [72/1000] - Training\n",
      "Epoch [72/1000] completed, Average Training Loss: 1.7519\n",
      "    Validation Batch [1/1], Loss: 2.3032\n",
      "Validation Loss: 2.3032, Validation Accuracy: 44.29%\n",
      "Validation loss improved from 2.3303 to 2.3032. Saving model...\n",
      "\n",
      "LOG: Epoch [73/1000] - Training\n",
      "Epoch [73/1000] completed, Average Training Loss: 1.7228\n",
      "    Validation Batch [1/1], Loss: 2.2650\n",
      "Validation Loss: 2.2650, Validation Accuracy: 44.29%\n",
      "Validation loss improved from 2.3032 to 2.2650. Saving model...\n",
      "\n",
      "LOG: Epoch [74/1000] - Training\n",
      "Epoch [74/1000] completed, Average Training Loss: 1.7330\n",
      "    Validation Batch [1/1], Loss: 2.2294\n",
      "Validation Loss: 2.2294, Validation Accuracy: 47.14%\n",
      "Validation loss improved from 2.2650 to 2.2294. Saving model...\n",
      "\n",
      "LOG: Epoch [75/1000] - Training\n",
      "Epoch [75/1000] completed, Average Training Loss: 1.7069\n",
      "    Validation Batch [1/1], Loss: 2.2014\n",
      "Validation Loss: 2.2014, Validation Accuracy: 48.57%\n",
      "Validation loss improved from 2.2294 to 2.2014. Saving model...\n",
      "\n",
      "LOG: Epoch [76/1000] - Training\n",
      "Epoch [76/1000] completed, Average Training Loss: 1.7515\n",
      "    Validation Batch [1/1], Loss: 2.1781\n",
      "Validation Loss: 2.1781, Validation Accuracy: 50.00%\n",
      "Validation loss improved from 2.2014 to 2.1781. Saving model...\n",
      "\n",
      "LOG: Epoch [77/1000] - Training\n",
      "Epoch [77/1000] completed, Average Training Loss: 1.6991\n",
      "    Validation Batch [1/1], Loss: 2.1568\n",
      "Validation Loss: 2.1568, Validation Accuracy: 48.57%\n",
      "Validation loss improved from 2.1781 to 2.1568. Saving model...\n",
      "\n",
      "LOG: Epoch [78/1000] - Training\n",
      "Epoch [78/1000] completed, Average Training Loss: 1.6688\n",
      "    Validation Batch [1/1], Loss: 2.1269\n",
      "Validation Loss: 2.1269, Validation Accuracy: 50.00%\n",
      "Validation loss improved from 2.1568 to 2.1269. Saving model...\n",
      "\n",
      "LOG: Epoch [79/1000] - Training\n",
      "Epoch [79/1000] completed, Average Training Loss: 1.6770\n",
      "    Validation Batch [1/1], Loss: 2.0846\n",
      "Validation Loss: 2.0846, Validation Accuracy: 54.29%\n",
      "Validation loss improved from 2.1269 to 2.0846. Saving model...\n",
      "\n",
      "LOG: Epoch [80/1000] - Training\n",
      "Epoch [80/1000] completed, Average Training Loss: 1.6860\n",
      "    Validation Batch [1/1], Loss: 2.0544\n",
      "Validation Loss: 2.0544, Validation Accuracy: 58.57%\n",
      "Validation loss improved from 2.0846 to 2.0544. Saving model...\n",
      "\n",
      "LOG: Epoch [81/1000] - Training\n",
      "Epoch [81/1000] completed, Average Training Loss: 1.6762\n",
      "    Validation Batch [1/1], Loss: 2.0318\n",
      "Validation Loss: 2.0318, Validation Accuracy: 55.71%\n",
      "Validation loss improved from 2.0544 to 2.0318. Saving model...\n",
      "\n",
      "LOG: Epoch [82/1000] - Training\n",
      "Epoch [82/1000] completed, Average Training Loss: 1.6358\n",
      "    Validation Batch [1/1], Loss: 2.0015\n",
      "Validation Loss: 2.0015, Validation Accuracy: 55.71%\n",
      "Validation loss improved from 2.0318 to 2.0015. Saving model...\n",
      "\n",
      "LOG: Epoch [83/1000] - Training\n",
      "Epoch [83/1000] completed, Average Training Loss: 1.6536\n",
      "    Validation Batch [1/1], Loss: 1.9463\n",
      "Validation Loss: 1.9463, Validation Accuracy: 58.57%\n",
      "Validation loss improved from 2.0015 to 1.9463. Saving model...\n",
      "\n",
      "LOG: Epoch [84/1000] - Training\n",
      "Epoch [84/1000] completed, Average Training Loss: 1.6506\n",
      "    Validation Batch [1/1], Loss: 1.9072\n",
      "Validation Loss: 1.9072, Validation Accuracy: 60.00%\n",
      "Validation loss improved from 1.9463 to 1.9072. Saving model...\n",
      "\n",
      "LOG: Epoch [85/1000] - Training\n",
      "Epoch [85/1000] completed, Average Training Loss: 1.6356\n",
      "    Validation Batch [1/1], Loss: 1.8859\n",
      "Validation Loss: 1.8859, Validation Accuracy: 58.57%\n",
      "Validation loss improved from 1.9072 to 1.8859. Saving model...\n",
      "\n",
      "LOG: Epoch [86/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/1000] completed, Average Training Loss: 1.6102\n",
      "    Validation Batch [1/1], Loss: 1.8682\n",
      "Validation Loss: 1.8682, Validation Accuracy: 58.57%\n",
      "Validation loss improved from 1.8859 to 1.8682. Saving model...\n",
      "\n",
      "LOG: Epoch [87/1000] - Training\n",
      "Epoch [87/1000] completed, Average Training Loss: 1.6090\n",
      "    Validation Batch [1/1], Loss: 1.8507\n",
      "Validation Loss: 1.8507, Validation Accuracy: 60.00%\n",
      "Validation loss improved from 1.8682 to 1.8507. Saving model...\n",
      "\n",
      "LOG: Epoch [88/1000] - Training\n",
      "Epoch [88/1000] completed, Average Training Loss: 1.6267\n",
      "    Validation Batch [1/1], Loss: 1.8180\n",
      "Validation Loss: 1.8180, Validation Accuracy: 61.43%\n",
      "Validation loss improved from 1.8507 to 1.8180. Saving model...\n",
      "\n",
      "LOG: Epoch [89/1000] - Training\n",
      "Epoch [89/1000] completed, Average Training Loss: 1.5670\n",
      "    Validation Batch [1/1], Loss: 1.7818\n",
      "Validation Loss: 1.7818, Validation Accuracy: 62.86%\n",
      "Validation loss improved from 1.8180 to 1.7818. Saving model...\n",
      "\n",
      "LOG: Epoch [90/1000] - Training\n",
      "Epoch [90/1000] completed, Average Training Loss: 1.5967\n",
      "    Validation Batch [1/1], Loss: 1.7607\n",
      "Validation Loss: 1.7607, Validation Accuracy: 62.86%\n",
      "Validation loss improved from 1.7818 to 1.7607. Saving model...\n",
      "\n",
      "LOG: Epoch [91/1000] - Training\n",
      "Epoch [91/1000] completed, Average Training Loss: 1.5567\n",
      "    Validation Batch [1/1], Loss: 1.7520\n",
      "Validation Loss: 1.7520, Validation Accuracy: 58.57%\n",
      "Validation loss improved from 1.7607 to 1.7520. Saving model...\n",
      "\n",
      "LOG: Epoch [92/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/1000] completed, Average Training Loss: 1.5793\n",
      "    Validation Batch [1/1], Loss: 1.7236\n",
      "Validation Loss: 1.7236, Validation Accuracy: 61.43%\n",
      "Validation loss improved from 1.7520 to 1.7236. Saving model...\n",
      "\n",
      "LOG: Epoch [93/1000] - Training\n",
      "Epoch [93/1000] completed, Average Training Loss: 1.5506\n",
      "    Validation Batch [1/1], Loss: 1.6885\n",
      "Validation Loss: 1.6885, Validation Accuracy: 68.57%\n",
      "Validation loss improved from 1.7236 to 1.6885. Saving model...\n",
      "\n",
      "LOG: Epoch [94/1000] - Training\n",
      "Epoch [94/1000] completed, Average Training Loss: 1.5757\n",
      "    Validation Batch [1/1], Loss: 1.6620\n",
      "Validation Loss: 1.6620, Validation Accuracy: 70.00%\n",
      "Validation loss improved from 1.6885 to 1.6620. Saving model...\n",
      "\n",
      "LOG: Epoch [95/1000] - Training\n",
      "Epoch [95/1000] completed, Average Training Loss: 1.5543\n",
      "    Validation Batch [1/1], Loss: 1.6488\n",
      "Validation Loss: 1.6488, Validation Accuracy: 71.43%\n",
      "Validation loss improved from 1.6620 to 1.6488. Saving model...\n",
      "\n",
      "LOG: Epoch [96/1000] - Training\n",
      "Epoch [96/1000] completed, Average Training Loss: 1.5319\n",
      "    Validation Batch [1/1], Loss: 1.6343\n",
      "Validation Loss: 1.6343, Validation Accuracy: 70.00%\n",
      "Validation loss improved from 1.6488 to 1.6343. Saving model...\n",
      "\n",
      "LOG: Epoch [97/1000] - Training\n",
      "Epoch [97/1000] completed, Average Training Loss: 1.5339\n",
      "    Validation Batch [1/1], Loss: 1.6164\n",
      "Validation Loss: 1.6164, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.6343 to 1.6164. Saving model...\n",
      "\n",
      "LOG: Epoch [98/1000] - Training\n",
      "Epoch [98/1000] completed, Average Training Loss: 1.5314\n",
      "    Validation Batch [1/1], Loss: 1.6072\n",
      "Validation Loss: 1.6072, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.6164 to 1.6072. Saving model...\n",
      "\n",
      "LOG: Epoch [99/1000] - Training\n",
      "Epoch [99/1000] completed, Average Training Loss: 1.5276\n",
      "    Validation Batch [1/1], Loss: 1.5834\n",
      "Validation Loss: 1.5834, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.6072 to 1.5834. Saving model...\n",
      "\n",
      "LOG: Epoch [100/1000] - Training\n",
      "Epoch [100/1000] completed, Average Training Loss: 1.4937\n",
      "    Validation Batch [1/1], Loss: 1.5602\n",
      "Validation Loss: 1.5602, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.5834 to 1.5602. Saving model...\n",
      "\n",
      "LOG: Epoch [101/1000] - Training\n",
      "Epoch [101/1000] completed, Average Training Loss: 1.5095\n",
      "    Validation Batch [1/1], Loss: 1.5474\n",
      "Validation Loss: 1.5474, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.5602 to 1.5474. Saving model...\n",
      "\n",
      "LOG: Epoch [102/1000] - Training\n",
      "Epoch [102/1000] completed, Average Training Loss: 1.4834\n",
      "    Validation Batch [1/1], Loss: 1.5391\n",
      "Validation Loss: 1.5391, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.5474 to 1.5391. Saving model...\n",
      "\n",
      "LOG: Epoch [103/1000] - Training\n",
      "Epoch [103/1000] completed, Average Training Loss: 1.4801\n",
      "    Validation Batch [1/1], Loss: 1.5248\n",
      "Validation Loss: 1.5248, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.5391 to 1.5248. Saving model...\n",
      "\n",
      "LOG: Epoch [104/1000] - Training\n",
      "Epoch [104/1000] completed, Average Training Loss: 1.4989\n",
      "    Validation Batch [1/1], Loss: 1.5041\n",
      "Validation Loss: 1.5041, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.5248 to 1.5041. Saving model...\n",
      "\n",
      "LOG: Epoch [105/1000] - Training\n",
      "Epoch [105/1000] completed, Average Training Loss: 1.4877\n",
      "    Validation Batch [1/1], Loss: 1.4967\n",
      "Validation Loss: 1.4967, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.5041 to 1.4967. Saving model...\n",
      "\n",
      "LOG: Epoch [106/1000] - Training\n",
      "Epoch [106/1000] completed, Average Training Loss: 1.4671\n",
      "    Validation Batch [1/1], Loss: 1.4985\n",
      "Validation Loss: 1.4985, Validation Accuracy: 74.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [107/1000] - Training\n",
      "Epoch [107/1000] completed, Average Training Loss: 1.4557\n",
      "    Validation Batch [1/1], Loss: 1.4974\n",
      "Validation Loss: 1.4974, Validation Accuracy: 74.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [108/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [108/1000] completed, Average Training Loss: 1.4332\n",
      "    Validation Batch [1/1], Loss: 1.4829\n",
      "Validation Loss: 1.4829, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.4967 to 1.4829. Saving model...\n",
      "\n",
      "LOG: Epoch [109/1000] - Training\n",
      "Epoch [109/1000] completed, Average Training Loss: 1.4389\n",
      "    Validation Batch [1/1], Loss: 1.4803\n",
      "Validation Loss: 1.4803, Validation Accuracy: 71.43%\n",
      "Validation loss improved from 1.4829 to 1.4803. Saving model...\n",
      "\n",
      "LOG: Epoch [110/1000] - Training\n",
      "Epoch [110/1000] completed, Average Training Loss: 1.4218\n",
      "    Validation Batch [1/1], Loss: 1.4651\n",
      "Validation Loss: 1.4651, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.4803 to 1.4651. Saving model...\n",
      "\n",
      "LOG: Epoch [111/1000] - Training\n",
      "Epoch [111/1000] completed, Average Training Loss: 1.4068\n",
      "    Validation Batch [1/1], Loss: 1.4459\n",
      "Validation Loss: 1.4459, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.4651 to 1.4459. Saving model...\n",
      "\n",
      "LOG: Epoch [112/1000] - Training\n",
      "Epoch [112/1000] completed, Average Training Loss: 1.4037\n",
      "    Validation Batch [1/1], Loss: 1.4329\n",
      "Validation Loss: 1.4329, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.4459 to 1.4329. Saving model...\n",
      "\n",
      "LOG: Epoch [113/1000] - Training\n",
      "Epoch [113/1000] completed, Average Training Loss: 1.3701\n",
      "    Validation Batch [1/1], Loss: 1.4267\n",
      "Validation Loss: 1.4267, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.4329 to 1.4267. Saving model...\n",
      "\n",
      "LOG: Epoch [114/1000] - Training\n",
      "Epoch [114/1000] completed, Average Training Loss: 1.3849\n",
      "    Validation Batch [1/1], Loss: 1.4159\n",
      "Validation Loss: 1.4159, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.4267 to 1.4159. Saving model...\n",
      "\n",
      "LOG: Epoch [115/1000] - Training\n",
      "Epoch [115/1000] completed, Average Training Loss: 1.3728\n",
      "    Validation Batch [1/1], Loss: 1.3981\n",
      "Validation Loss: 1.3981, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.4159 to 1.3981. Saving model...\n",
      "\n",
      "LOG: Epoch [116/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [116/1000] completed, Average Training Loss: 1.3710\n",
      "    Validation Batch [1/1], Loss: 1.3837\n",
      "Validation Loss: 1.3837, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.3981 to 1.3837. Saving model...\n",
      "\n",
      "LOG: Epoch [117/1000] - Training\n",
      "Epoch [117/1000] completed, Average Training Loss: 1.3697\n",
      "    Validation Batch [1/1], Loss: 1.3817\n",
      "Validation Loss: 1.3817, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.3837 to 1.3817. Saving model...\n",
      "\n",
      "LOG: Epoch [118/1000] - Training\n",
      "Epoch [118/1000] completed, Average Training Loss: 1.3450\n",
      "    Validation Batch [1/1], Loss: 1.3860\n",
      "Validation Loss: 1.3860, Validation Accuracy: 80.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [119/1000] - Training\n",
      "Epoch [119/1000] completed, Average Training Loss: 1.3578\n",
      "    Validation Batch [1/1], Loss: 1.3795\n",
      "Validation Loss: 1.3795, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.3817 to 1.3795. Saving model...\n",
      "\n",
      "LOG: Epoch [120/1000] - Training\n",
      "Epoch [120/1000] completed, Average Training Loss: 1.3359\n",
      "    Validation Batch [1/1], Loss: 1.3665\n",
      "Validation Loss: 1.3665, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.3795 to 1.3665. Saving model...\n",
      "\n",
      "LOG: Epoch [121/1000] - Training\n",
      "Epoch [121/1000] completed, Average Training Loss: 1.3572\n",
      "    Validation Batch [1/1], Loss: 1.3521\n",
      "Validation Loss: 1.3521, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.3665 to 1.3521. Saving model...\n",
      "\n",
      "LOG: Epoch [122/1000] - Training\n",
      "Epoch [122/1000] completed, Average Training Loss: 1.3209\n",
      "    Validation Batch [1/1], Loss: 1.3365\n",
      "Validation Loss: 1.3365, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.3521 to 1.3365. Saving model...\n",
      "\n",
      "LOG: Epoch [123/1000] - Training\n",
      "Epoch [123/1000] completed, Average Training Loss: 1.3140\n",
      "    Validation Batch [1/1], Loss: 1.3297\n",
      "Validation Loss: 1.3297, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.3365 to 1.3297. Saving model...\n",
      "\n",
      "LOG: Epoch [124/1000] - Training\n",
      "Epoch [124/1000] completed, Average Training Loss: 1.3020\n",
      "    Validation Batch [1/1], Loss: 1.3274\n",
      "Validation Loss: 1.3274, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.3297 to 1.3274. Saving model...\n",
      "\n",
      "LOG: Epoch [125/1000] - Training\n",
      "Epoch [125/1000] completed, Average Training Loss: 1.2765\n",
      "    Validation Batch [1/1], Loss: 1.3152\n",
      "Validation Loss: 1.3152, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 1.3274 to 1.3152. Saving model...\n",
      "\n",
      "LOG: Epoch [126/1000] - Training\n",
      "Epoch [126/1000] completed, Average Training Loss: 1.2727\n",
      "    Validation Batch [1/1], Loss: 1.3047\n",
      "Validation Loss: 1.3047, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.3152 to 1.3047. Saving model...\n",
      "\n",
      "LOG: Epoch [127/1000] - Training\n",
      "Epoch [127/1000] completed, Average Training Loss: 1.2767\n",
      "    Validation Batch [1/1], Loss: 1.3057\n",
      "Validation Loss: 1.3057, Validation Accuracy: 80.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [128/1000] - Training\n",
      "Epoch [128/1000] completed, Average Training Loss: 1.2804\n",
      "    Validation Batch [1/1], Loss: 1.3017\n",
      "Validation Loss: 1.3017, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 1.3047 to 1.3017. Saving model...\n",
      "\n",
      "LOG: Epoch [129/1000] - Training\n",
      "Epoch [129/1000] completed, Average Training Loss: 1.2489\n",
      "    Validation Batch [1/1], Loss: 1.2987\n",
      "Validation Loss: 1.2987, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.3017 to 1.2987. Saving model...\n",
      "\n",
      "LOG: Epoch [130/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [130/1000] completed, Average Training Loss: 1.2565\n",
      "    Validation Batch [1/1], Loss: 1.2828\n",
      "Validation Loss: 1.2828, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.2987 to 1.2828. Saving model...\n",
      "\n",
      "LOG: Epoch [131/1000] - Training\n",
      "Epoch [131/1000] completed, Average Training Loss: 1.2405\n",
      "    Validation Batch [1/1], Loss: 1.2712\n",
      "Validation Loss: 1.2712, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.2828 to 1.2712. Saving model...\n",
      "\n",
      "LOG: Epoch [132/1000] - Training\n",
      "Epoch [132/1000] completed, Average Training Loss: 1.2367\n",
      "    Validation Batch [1/1], Loss: 1.2676\n",
      "Validation Loss: 1.2676, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 1.2712 to 1.2676. Saving model...\n",
      "\n",
      "LOG: Epoch [133/1000] - Training\n",
      "Epoch [133/1000] completed, Average Training Loss: 1.2389\n",
      "    Validation Batch [1/1], Loss: 1.2720\n",
      "Validation Loss: 1.2720, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [134/1000] - Training\n",
      "Epoch [134/1000] completed, Average Training Loss: 1.2409\n",
      "    Validation Batch [1/1], Loss: 1.2585\n",
      "Validation Loss: 1.2585, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.2676 to 1.2585. Saving model...\n",
      "\n",
      "LOG: Epoch [135/1000] - Training\n",
      "Epoch [135/1000] completed, Average Training Loss: 1.2138\n",
      "    Validation Batch [1/1], Loss: 1.2476\n",
      "Validation Loss: 1.2476, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.2585 to 1.2476. Saving model...\n",
      "\n",
      "LOG: Epoch [136/1000] - Training\n",
      "Epoch [136/1000] completed, Average Training Loss: 1.2508\n",
      "    Validation Batch [1/1], Loss: 1.2287\n",
      "Validation Loss: 1.2287, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.2476 to 1.2287. Saving model...\n",
      "\n",
      "LOG: Epoch [137/1000] - Training\n",
      "Epoch [137/1000] completed, Average Training Loss: 1.2207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 1.2254\n",
      "Validation Loss: 1.2254, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.2287 to 1.2254. Saving model...\n",
      "\n",
      "LOG: Epoch [138/1000] - Training\n",
      "Epoch [138/1000] completed, Average Training Loss: 1.1913\n",
      "    Validation Batch [1/1], Loss: 1.2250\n",
      "Validation Loss: 1.2250, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.2254 to 1.2250. Saving model...\n",
      "\n",
      "LOG: Epoch [139/1000] - Training\n",
      "Epoch [139/1000] completed, Average Training Loss: 1.2137\n",
      "    Validation Batch [1/1], Loss: 1.2366\n",
      "Validation Loss: 1.2366, Validation Accuracy: 81.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [140/1000] - Training\n",
      "Epoch [140/1000] completed, Average Training Loss: 1.1986\n",
      "    Validation Batch [1/1], Loss: 1.2221\n",
      "Validation Loss: 1.2221, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 1.2250 to 1.2221. Saving model...\n",
      "\n",
      "LOG: Epoch [141/1000] - Training\n",
      "Epoch [141/1000] completed, Average Training Loss: 1.1624\n",
      "    Validation Batch [1/1], Loss: 1.2075\n",
      "Validation Loss: 1.2075, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.2221 to 1.2075. Saving model...\n",
      "\n",
      "LOG: Epoch [142/1000] - Training\n",
      "Epoch [142/1000] completed, Average Training Loss: 1.1652\n",
      "    Validation Batch [1/1], Loss: 1.1927\n",
      "Validation Loss: 1.1927, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.2075 to 1.1927. Saving model...\n",
      "\n",
      "LOG: Epoch [143/1000] - Training\n",
      "Epoch [143/1000] completed, Average Training Loss: 1.1641\n",
      "    Validation Batch [1/1], Loss: 1.1997\n",
      "Validation Loss: 1.1997, Validation Accuracy: 81.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [144/1000] - Training\n",
      "Epoch [144/1000] completed, Average Training Loss: 1.1453\n",
      "    Validation Batch [1/1], Loss: 1.1894\n",
      "Validation Loss: 1.1894, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.1927 to 1.1894. Saving model...\n",
      "\n",
      "LOG: Epoch [145/1000] - Training\n",
      "Epoch [145/1000] completed, Average Training Loss: 1.1529\n",
      "    Validation Batch [1/1], Loss: 1.1727\n",
      "Validation Loss: 1.1727, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.1894 to 1.1727. Saving model...\n",
      "\n",
      "LOG: Epoch [146/1000] - Training\n",
      "Epoch [146/1000] completed, Average Training Loss: 1.1481\n",
      "    Validation Batch [1/1], Loss: 1.1738\n",
      "Validation Loss: 1.1738, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [147/1000] - Training\n",
      "Epoch [147/1000] completed, Average Training Loss: 1.1231\n",
      "    Validation Batch [1/1], Loss: 1.1705\n",
      "Validation Loss: 1.1705, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.1727 to 1.1705. Saving model...\n",
      "\n",
      "LOG: Epoch [148/1000] - Training\n",
      "Epoch [148/1000] completed, Average Training Loss: 1.1096\n",
      "    Validation Batch [1/1], Loss: 1.1643\n",
      "Validation Loss: 1.1643, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 1.1705 to 1.1643. Saving model...\n",
      "\n",
      "LOG: Epoch [149/1000] - Training\n",
      "Epoch [149/1000] completed, Average Training Loss: 1.1217\n",
      "    Validation Batch [1/1], Loss: 1.1494\n",
      "Validation Loss: 1.1494, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.1643 to 1.1494. Saving model...\n",
      "\n",
      "LOG: Epoch [150/1000] - Training\n",
      "Epoch [150/1000] completed, Average Training Loss: 1.1300\n",
      "    Validation Batch [1/1], Loss: 1.1364\n",
      "Validation Loss: 1.1364, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.1494 to 1.1364. Saving model...\n",
      "\n",
      "LOG: Epoch [151/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [151/1000] completed, Average Training Loss: 1.1012\n",
      "    Validation Batch [1/1], Loss: 1.1331\n",
      "Validation Loss: 1.1331, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.1364 to 1.1331. Saving model...\n",
      "\n",
      "LOG: Epoch [152/1000] - Training\n",
      "Epoch [152/1000] completed, Average Training Loss: 1.0875\n",
      "    Validation Batch [1/1], Loss: 1.1385\n",
      "Validation Loss: 1.1385, Validation Accuracy: 84.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [153/1000] - Training\n",
      "Epoch [153/1000] completed, Average Training Loss: 1.0756\n",
      "    Validation Batch [1/1], Loss: 1.1199\n",
      "Validation Loss: 1.1199, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.1331 to 1.1199. Saving model...\n",
      "\n",
      "LOG: Epoch [154/1000] - Training\n",
      "Epoch [154/1000] completed, Average Training Loss: 1.0699\n",
      "    Validation Batch [1/1], Loss: 1.1050\n",
      "Validation Loss: 1.1050, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.1199 to 1.1050. Saving model...\n",
      "\n",
      "LOG: Epoch [155/1000] - Training\n",
      "Epoch [155/1000] completed, Average Training Loss: 1.0688\n",
      "    Validation Batch [1/1], Loss: 1.0890\n",
      "Validation Loss: 1.0890, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.1050 to 1.0890. Saving model...\n",
      "\n",
      "LOG: Epoch [156/1000] - Training\n",
      "Epoch [156/1000] completed, Average Training Loss: 1.0969\n",
      "    Validation Batch [1/1], Loss: 1.0801\n",
      "Validation Loss: 1.0801, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.0890 to 1.0801. Saving model...\n",
      "\n",
      "LOG: Epoch [157/1000] - Training\n",
      "Epoch [157/1000] completed, Average Training Loss: 1.0532\n",
      "    Validation Batch [1/1], Loss: 1.0869\n",
      "Validation Loss: 1.0869, Validation Accuracy: 85.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [158/1000] - Training\n",
      "Epoch [158/1000] completed, Average Training Loss: 1.0398\n",
      "    Validation Batch [1/1], Loss: 1.0849\n",
      "Validation Loss: 1.0849, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [159/1000] - Training\n",
      "Epoch [159/1000] completed, Average Training Loss: 1.0639\n",
      "    Validation Batch [1/1], Loss: 1.0783\n",
      "Validation Loss: 1.0783, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.0801 to 1.0783. Saving model...\n",
      "\n",
      "LOG: Epoch [160/1000] - Training\n",
      "Epoch [160/1000] completed, Average Training Loss: 1.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 1.0680\n",
      "Validation Loss: 1.0680, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.0783 to 1.0680. Saving model...\n",
      "\n",
      "LOG: Epoch [161/1000] - Training\n",
      "Epoch [161/1000] completed, Average Training Loss: 1.0443\n",
      "    Validation Batch [1/1], Loss: 1.0651\n",
      "Validation Loss: 1.0651, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.0680 to 1.0651. Saving model...\n",
      "\n",
      "LOG: Epoch [162/1000] - Training\n",
      "Epoch [162/1000] completed, Average Training Loss: 1.0109\n",
      "    Validation Batch [1/1], Loss: 1.0569\n",
      "Validation Loss: 1.0569, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.0651 to 1.0569. Saving model...\n",
      "\n",
      "LOG: Epoch [163/1000] - Training\n",
      "Epoch [163/1000] completed, Average Training Loss: 1.0054\n",
      "    Validation Batch [1/1], Loss: 1.0362\n",
      "Validation Loss: 1.0362, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 1.0569 to 1.0362. Saving model...\n",
      "\n",
      "LOG: Epoch [164/1000] - Training\n",
      "Epoch [164/1000] completed, Average Training Loss: 1.0032\n",
      "    Validation Batch [1/1], Loss: 1.0300\n",
      "Validation Loss: 1.0300, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 1.0362 to 1.0300. Saving model...\n",
      "\n",
      "LOG: Epoch [165/1000] - Training\n",
      "Epoch [165/1000] completed, Average Training Loss: 0.9839\n",
      "    Validation Batch [1/1], Loss: 1.0276\n",
      "Validation Loss: 1.0276, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 1.0300 to 1.0276. Saving model...\n",
      "\n",
      "LOG: Epoch [166/1000] - Training\n",
      "Epoch [166/1000] completed, Average Training Loss: 0.9617\n",
      "    Validation Batch [1/1], Loss: 1.0250\n",
      "Validation Loss: 1.0250, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.0276 to 1.0250. Saving model...\n",
      "\n",
      "LOG: Epoch [167/1000] - Training\n",
      "Epoch [167/1000] completed, Average Training Loss: 0.9590\n",
      "    Validation Batch [1/1], Loss: 1.0134\n",
      "Validation Loss: 1.0134, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.0250 to 1.0134. Saving model...\n",
      "\n",
      "LOG: Epoch [168/1000] - Training\n",
      "Epoch [168/1000] completed, Average Training Loss: 0.9525\n",
      "    Validation Batch [1/1], Loss: 0.9961\n",
      "Validation Loss: 0.9961, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 1.0134 to 0.9961. Saving model...\n",
      "\n",
      "LOG: Epoch [169/1000] - Training\n",
      "Epoch [169/1000] completed, Average Training Loss: 0.9753\n",
      "    Validation Batch [1/1], Loss: 0.9834\n",
      "Validation Loss: 0.9834, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.9961 to 0.9834. Saving model...\n",
      "\n",
      "LOG: Epoch [170/1000] - Training\n",
      "Epoch [170/1000] completed, Average Training Loss: 0.9934\n",
      "    Validation Batch [1/1], Loss: 0.9883\n",
      "Validation Loss: 0.9883, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [171/1000] - Training\n",
      "Epoch [171/1000] completed, Average Training Loss: 0.9605\n",
      "    Validation Batch [1/1], Loss: 0.9904\n",
      "Validation Loss: 0.9904, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [172/1000] - Training\n",
      "Epoch [172/1000] completed, Average Training Loss: 0.9427\n",
      "    Validation Batch [1/1], Loss: 0.9769\n",
      "Validation Loss: 0.9769, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.9834 to 0.9769. Saving model...\n",
      "\n",
      "LOG: Epoch [173/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [173/1000] completed, Average Training Loss: 0.9403\n",
      "    Validation Batch [1/1], Loss: 0.9672\n",
      "Validation Loss: 0.9672, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.9769 to 0.9672. Saving model...\n",
      "\n",
      "LOG: Epoch [174/1000] - Training\n",
      "Epoch [174/1000] completed, Average Training Loss: 0.9424\n",
      "    Validation Batch [1/1], Loss: 0.9668\n",
      "Validation Loss: 0.9668, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.9672 to 0.9668. Saving model...\n",
      "\n",
      "LOG: Epoch [175/1000] - Training\n",
      "Epoch [175/1000] completed, Average Training Loss: 0.9234\n",
      "    Validation Batch [1/1], Loss: 0.9677\n",
      "Validation Loss: 0.9677, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [176/1000] - Training\n",
      "Epoch [176/1000] completed, Average Training Loss: 0.8971\n",
      "    Validation Batch [1/1], Loss: 0.9531\n",
      "Validation Loss: 0.9531, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.9668 to 0.9531. Saving model...\n",
      "\n",
      "LOG: Epoch [177/1000] - Training\n",
      "Epoch [177/1000] completed, Average Training Loss: 0.8931\n",
      "    Validation Batch [1/1], Loss: 0.9426\n",
      "Validation Loss: 0.9426, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.9531 to 0.9426. Saving model...\n",
      "\n",
      "LOG: Epoch [178/1000] - Training\n",
      "Epoch [178/1000] completed, Average Training Loss: 0.9092\n",
      "    Validation Batch [1/1], Loss: 0.9217\n",
      "Validation Loss: 0.9217, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.9426 to 0.9217. Saving model...\n",
      "\n",
      "LOG: Epoch [179/1000] - Training\n",
      "Epoch [179/1000] completed, Average Training Loss: 0.8865\n",
      "    Validation Batch [1/1], Loss: 0.9275\n",
      "Validation Loss: 0.9275, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [180/1000] - Training\n",
      "Epoch [180/1000] completed, Average Training Loss: 0.8807\n",
      "    Validation Batch [1/1], Loss: 0.9286\n",
      "Validation Loss: 0.9286, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [181/1000] - Training\n",
      "Epoch [181/1000] completed, Average Training Loss: 0.9028\n",
      "    Validation Batch [1/1], Loss: 0.9141\n",
      "Validation Loss: 0.9141, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.9217 to 0.9141. Saving model...\n",
      "\n",
      "LOG: Epoch [182/1000] - Training\n",
      "Epoch [182/1000] completed, Average Training Loss: 0.8760\n",
      "    Validation Batch [1/1], Loss: 0.9125\n",
      "Validation Loss: 0.9125, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.9141 to 0.9125. Saving model...\n",
      "\n",
      "LOG: Epoch [183/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [183/1000] completed, Average Training Loss: 0.8801\n",
      "    Validation Batch [1/1], Loss: 0.9068\n",
      "Validation Loss: 0.9068, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.9125 to 0.9068. Saving model...\n",
      "\n",
      "LOG: Epoch [184/1000] - Training\n",
      "Epoch [184/1000] completed, Average Training Loss: 0.8649\n",
      "    Validation Batch [1/1], Loss: 0.8852\n",
      "Validation Loss: 0.8852, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.9068 to 0.8852. Saving model...\n",
      "\n",
      "LOG: Epoch [185/1000] - Training\n",
      "Epoch [185/1000] completed, Average Training Loss: 0.8726\n",
      "    Validation Batch [1/1], Loss: 0.8809\n",
      "Validation Loss: 0.8809, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.8852 to 0.8809. Saving model...\n",
      "\n",
      "LOG: Epoch [186/1000] - Training\n",
      "Epoch [186/1000] completed, Average Training Loss: 0.8485\n",
      "    Validation Batch [1/1], Loss: 0.8707\n",
      "Validation Loss: 0.8707, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.8809 to 0.8707. Saving model...\n",
      "\n",
      "LOG: Epoch [187/1000] - Training\n",
      "Epoch [187/1000] completed, Average Training Loss: 0.8390\n",
      "    Validation Batch [1/1], Loss: 0.8734\n",
      "Validation Loss: 0.8734, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [188/1000] - Training\n",
      "Epoch [188/1000] completed, Average Training Loss: 0.8502\n",
      "    Validation Batch [1/1], Loss: 0.8641\n",
      "Validation Loss: 0.8641, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.8707 to 0.8641. Saving model...\n",
      "\n",
      "LOG: Epoch [189/1000] - Training\n",
      "Epoch [189/1000] completed, Average Training Loss: 0.8445\n",
      "    Validation Batch [1/1], Loss: 0.8595\n",
      "Validation Loss: 0.8595, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.8641 to 0.8595. Saving model...\n",
      "\n",
      "LOG: Epoch [190/1000] - Training\n",
      "Epoch [190/1000] completed, Average Training Loss: 0.8702\n",
      "    Validation Batch [1/1], Loss: 0.8501\n",
      "Validation Loss: 0.8501, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.8595 to 0.8501. Saving model...\n",
      "\n",
      "LOG: Epoch [191/1000] - Training\n",
      "Epoch [191/1000] completed, Average Training Loss: 0.8161\n",
      "    Validation Batch [1/1], Loss: 0.8429\n",
      "Validation Loss: 0.8429, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.8501 to 0.8429. Saving model...\n",
      "\n",
      "LOG: Epoch [192/1000] - Training\n",
      "Epoch [192/1000] completed, Average Training Loss: 0.8113\n",
      "    Validation Batch [1/1], Loss: 0.8385\n",
      "Validation Loss: 0.8385, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.8429 to 0.8385. Saving model...\n",
      "\n",
      "LOG: Epoch [193/1000] - Training\n",
      "Epoch [193/1000] completed, Average Training Loss: 0.8037\n",
      "    Validation Batch [1/1], Loss: 0.8306\n",
      "Validation Loss: 0.8306, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.8385 to 0.8306. Saving model...\n",
      "\n",
      "LOG: Epoch [194/1000] - Training\n",
      "Epoch [194/1000] completed, Average Training Loss: 0.8093\n",
      "    Validation Batch [1/1], Loss: 0.8188\n",
      "Validation Loss: 0.8188, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.8306 to 0.8188. Saving model...\n",
      "\n",
      "LOG: Epoch [195/1000] - Training\n",
      "Epoch [195/1000] completed, Average Training Loss: 0.7867\n",
      "    Validation Batch [1/1], Loss: 0.8091\n",
      "Validation Loss: 0.8091, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.8188 to 0.8091. Saving model...\n",
      "\n",
      "LOG: Epoch [196/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [196/1000] completed, Average Training Loss: 0.7821\n",
      "    Validation Batch [1/1], Loss: 0.8116\n",
      "Validation Loss: 0.8116, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [197/1000] - Training\n",
      "Epoch [197/1000] completed, Average Training Loss: 0.7616\n",
      "    Validation Batch [1/1], Loss: 0.8115\n",
      "Validation Loss: 0.8115, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [198/1000] - Training\n",
      "Epoch [198/1000] completed, Average Training Loss: 0.7570\n",
      "    Validation Batch [1/1], Loss: 0.7995\n",
      "Validation Loss: 0.7995, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.8091 to 0.7995. Saving model...\n",
      "\n",
      "LOG: Epoch [199/1000] - Training\n",
      "Epoch [199/1000] completed, Average Training Loss: 0.7531\n",
      "    Validation Batch [1/1], Loss: 0.7873\n",
      "Validation Loss: 0.7873, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.7995 to 0.7873. Saving model...\n",
      "\n",
      "LOG: Epoch [200/1000] - Training\n",
      "Epoch [200/1000] completed, Average Training Loss: 0.7735\n",
      "    Validation Batch [1/1], Loss: 0.7827\n",
      "Validation Loss: 0.7827, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.7873 to 0.7827. Saving model...\n",
      "\n",
      "LOG: Epoch [201/1000] - Training\n",
      "Epoch [201/1000] completed, Average Training Loss: 0.7315\n",
      "    Validation Batch [1/1], Loss: 0.7916\n",
      "Validation Loss: 0.7916, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [202/1000] - Training\n",
      "Epoch [202/1000] completed, Average Training Loss: 0.7403\n",
      "    Validation Batch [1/1], Loss: 0.7924\n",
      "Validation Loss: 0.7924, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [203/1000] - Training\n",
      "Epoch [203/1000] completed, Average Training Loss: 0.7404\n",
      "    Validation Batch [1/1], Loss: 0.7863\n",
      "Validation Loss: 0.7863, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [204/1000] - Training\n",
      "Epoch [204/1000] completed, Average Training Loss: 0.7445\n",
      "    Validation Batch [1/1], Loss: 0.7670\n",
      "Validation Loss: 0.7670, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.7827 to 0.7670. Saving model...\n",
      "\n",
      "LOG: Epoch [205/1000] - Training\n",
      "Epoch [205/1000] completed, Average Training Loss: 0.7212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.7521\n",
      "Validation Loss: 0.7521, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.7670 to 0.7521. Saving model...\n",
      "\n",
      "LOG: Epoch [206/1000] - Training\n",
      "Epoch [206/1000] completed, Average Training Loss: 0.7085\n",
      "    Validation Batch [1/1], Loss: 0.7438\n",
      "Validation Loss: 0.7438, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.7521 to 0.7438. Saving model...\n",
      "\n",
      "LOG: Epoch [207/1000] - Training\n",
      "Epoch [207/1000] completed, Average Training Loss: 0.7219\n",
      "    Validation Batch [1/1], Loss: 0.7399\n",
      "Validation Loss: 0.7399, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.7438 to 0.7399. Saving model...\n",
      "\n",
      "LOG: Epoch [208/1000] - Training\n",
      "Epoch [208/1000] completed, Average Training Loss: 0.6911\n",
      "    Validation Batch [1/1], Loss: 0.7318\n",
      "Validation Loss: 0.7318, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.7399 to 0.7318. Saving model...\n",
      "\n",
      "LOG: Epoch [209/1000] - Training\n",
      "Epoch [209/1000] completed, Average Training Loss: 0.7063\n",
      "    Validation Batch [1/1], Loss: 0.7229\n",
      "Validation Loss: 0.7229, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.7318 to 0.7229. Saving model...\n",
      "\n",
      "LOG: Epoch [210/1000] - Training\n",
      "Epoch [210/1000] completed, Average Training Loss: 0.6932\n",
      "    Validation Batch [1/1], Loss: 0.7152\n",
      "Validation Loss: 0.7152, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.7229 to 0.7152. Saving model...\n",
      "\n",
      "LOG: Epoch [211/1000] - Training\n",
      "Epoch [211/1000] completed, Average Training Loss: 0.7132\n",
      "    Validation Batch [1/1], Loss: 0.7146\n",
      "Validation Loss: 0.7146, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.7152 to 0.7146. Saving model...\n",
      "\n",
      "LOG: Epoch [212/1000] - Training\n",
      "Epoch [212/1000] completed, Average Training Loss: 0.6732\n",
      "    Validation Batch [1/1], Loss: 0.7038\n",
      "Validation Loss: 0.7038, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.7146 to 0.7038. Saving model...\n",
      "\n",
      "LOG: Epoch [213/1000] - Training\n",
      "Epoch [213/1000] completed, Average Training Loss: 0.6649\n",
      "    Validation Batch [1/1], Loss: 0.6915\n",
      "Validation Loss: 0.6915, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.7038 to 0.6915. Saving model...\n",
      "\n",
      "LOG: Epoch [214/1000] - Training\n",
      "Epoch [214/1000] completed, Average Training Loss: 0.6802\n",
      "    Validation Batch [1/1], Loss: 0.6821\n",
      "Validation Loss: 0.6821, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6915 to 0.6821. Saving model...\n",
      "\n",
      "LOG: Epoch [215/1000] - Training\n",
      "Epoch [215/1000] completed, Average Training Loss: 0.6740\n",
      "    Validation Batch [1/1], Loss: 0.6910\n",
      "Validation Loss: 0.6910, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [216/1000] - Training\n",
      "Epoch [216/1000] completed, Average Training Loss: 0.6575\n",
      "    Validation Batch [1/1], Loss: 0.6887\n",
      "Validation Loss: 0.6887, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [217/1000] - Training\n",
      "Epoch [217/1000] completed, Average Training Loss: 0.6531\n",
      "    Validation Batch [1/1], Loss: 0.6799\n",
      "Validation Loss: 0.6799, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6821 to 0.6799. Saving model...\n",
      "\n",
      "LOG: Epoch [218/1000] - Training\n",
      "Epoch [218/1000] completed, Average Training Loss: 0.6371\n",
      "    Validation Batch [1/1], Loss: 0.6717\n",
      "Validation Loss: 0.6717, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6799 to 0.6717. Saving model...\n",
      "\n",
      "LOG: Epoch [219/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [219/1000] completed, Average Training Loss: 0.6276\n",
      "    Validation Batch [1/1], Loss: 0.6605\n",
      "Validation Loss: 0.6605, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6717 to 0.6605. Saving model...\n",
      "\n",
      "LOG: Epoch [220/1000] - Training\n",
      "Epoch [220/1000] completed, Average Training Loss: 0.6343\n",
      "    Validation Batch [1/1], Loss: 0.6582\n",
      "Validation Loss: 0.6582, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.6605 to 0.6582. Saving model...\n",
      "\n",
      "LOG: Epoch [221/1000] - Training\n",
      "Epoch [221/1000] completed, Average Training Loss: 0.6171\n",
      "    Validation Batch [1/1], Loss: 0.6522\n",
      "Validation Loss: 0.6522, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.6582 to 0.6522. Saving model...\n",
      "\n",
      "LOG: Epoch [222/1000] - Training\n",
      "Epoch [222/1000] completed, Average Training Loss: 0.6112\n",
      "    Validation Batch [1/1], Loss: 0.6478\n",
      "Validation Loss: 0.6478, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6522 to 0.6478. Saving model...\n",
      "\n",
      "LOG: Epoch [223/1000] - Training\n",
      "Epoch [223/1000] completed, Average Training Loss: 0.6369\n",
      "    Validation Batch [1/1], Loss: 0.6467\n",
      "Validation Loss: 0.6467, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6478 to 0.6467. Saving model...\n",
      "\n",
      "LOG: Epoch [224/1000] - Training\n",
      "Epoch [224/1000] completed, Average Training Loss: 0.6188\n",
      "    Validation Batch [1/1], Loss: 0.6422\n",
      "Validation Loss: 0.6422, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6467 to 0.6422. Saving model...\n",
      "\n",
      "LOG: Epoch [225/1000] - Training\n",
      "Epoch [225/1000] completed, Average Training Loss: 0.6174\n",
      "    Validation Batch [1/1], Loss: 0.6336\n",
      "Validation Loss: 0.6336, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6422 to 0.6336. Saving model...\n",
      "\n",
      "LOG: Epoch [226/1000] - Training\n",
      "Epoch [226/1000] completed, Average Training Loss: 0.6156\n",
      "    Validation Batch [1/1], Loss: 0.6190\n",
      "Validation Loss: 0.6190, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6336 to 0.6190. Saving model...\n",
      "\n",
      "LOG: Epoch [227/1000] - Training\n",
      "Epoch [227/1000] completed, Average Training Loss: 0.6102\n",
      "    Validation Batch [1/1], Loss: 0.6125\n",
      "Validation Loss: 0.6125, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6190 to 0.6125. Saving model...\n",
      "\n",
      "LOG: Epoch [228/1000] - Training\n",
      "Epoch [228/1000] completed, Average Training Loss: 0.5726\n",
      "    Validation Batch [1/1], Loss: 0.6086\n",
      "Validation Loss: 0.6086, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.6125 to 0.6086. Saving model...\n",
      "\n",
      "LOG: Epoch [229/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [229/1000] completed, Average Training Loss: 0.5697\n",
      "    Validation Batch [1/1], Loss: 0.6060\n",
      "Validation Loss: 0.6060, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.6086 to 0.6060. Saving model...\n",
      "\n",
      "LOG: Epoch [230/1000] - Training\n",
      "Epoch [230/1000] completed, Average Training Loss: 0.5656\n",
      "    Validation Batch [1/1], Loss: 0.6033\n",
      "Validation Loss: 0.6033, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6060 to 0.6033. Saving model...\n",
      "\n",
      "LOG: Epoch [231/1000] - Training\n",
      "Epoch [231/1000] completed, Average Training Loss: 0.5812\n",
      "    Validation Batch [1/1], Loss: 0.6021\n",
      "Validation Loss: 0.6021, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6033 to 0.6021. Saving model...\n",
      "\n",
      "LOG: Epoch [232/1000] - Training\n",
      "Epoch [232/1000] completed, Average Training Loss: 0.5868\n",
      "    Validation Batch [1/1], Loss: 0.5960\n",
      "Validation Loss: 0.5960, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6021 to 0.5960. Saving model...\n",
      "\n",
      "LOG: Epoch [233/1000] - Training\n",
      "Epoch [233/1000] completed, Average Training Loss: 0.6018\n",
      "    Validation Batch [1/1], Loss: 0.5903\n",
      "Validation Loss: 0.5903, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5960 to 0.5903. Saving model...\n",
      "\n",
      "LOG: Epoch [234/1000] - Training\n",
      "Epoch [234/1000] completed, Average Training Loss: 0.5773\n",
      "    Validation Batch [1/1], Loss: 0.5861\n",
      "Validation Loss: 0.5861, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5903 to 0.5861. Saving model...\n",
      "\n",
      "LOG: Epoch [235/1000] - Training\n",
      "Epoch [235/1000] completed, Average Training Loss: 0.5716\n",
      "    Validation Batch [1/1], Loss: 0.5793\n",
      "Validation Loss: 0.5793, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5861 to 0.5793. Saving model...\n",
      "\n",
      "LOG: Epoch [236/1000] - Training\n",
      "Epoch [236/1000] completed, Average Training Loss: 0.5445\n",
      "    Validation Batch [1/1], Loss: 0.5748\n",
      "Validation Loss: 0.5748, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5793 to 0.5748. Saving model...\n",
      "\n",
      "LOG: Epoch [237/1000] - Training\n",
      "Epoch [237/1000] completed, Average Training Loss: 0.5239\n",
      "    Validation Batch [1/1], Loss: 0.5741\n",
      "Validation Loss: 0.5741, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.5748 to 0.5741. Saving model...\n",
      "\n",
      "LOG: Epoch [238/1000] - Training\n",
      "Epoch [238/1000] completed, Average Training Loss: 0.5491\n",
      "    Validation Batch [1/1], Loss: 0.5663\n",
      "Validation Loss: 0.5663, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.5741 to 0.5663. Saving model...\n",
      "\n",
      "LOG: Epoch [239/1000] - Training\n",
      "Epoch [239/1000] completed, Average Training Loss: 0.5596\n",
      "    Validation Batch [1/1], Loss: 0.5578\n",
      "Validation Loss: 0.5578, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5663 to 0.5578. Saving model...\n",
      "\n",
      "LOG: Epoch [240/1000] - Training\n",
      "Epoch [240/1000] completed, Average Training Loss: 0.5382\n",
      "    Validation Batch [1/1], Loss: 0.5479\n",
      "Validation Loss: 0.5479, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5578 to 0.5479. Saving model...\n",
      "\n",
      "LOG: Epoch [241/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [241/1000] completed, Average Training Loss: 0.5479\n",
      "    Validation Batch [1/1], Loss: 0.5407\n",
      "Validation Loss: 0.5407, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5479 to 0.5407. Saving model...\n",
      "\n",
      "LOG: Epoch [242/1000] - Training\n",
      "Epoch [242/1000] completed, Average Training Loss: 0.5235\n",
      "    Validation Batch [1/1], Loss: 0.5345\n",
      "Validation Loss: 0.5345, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5407 to 0.5345. Saving model...\n",
      "\n",
      "LOG: Epoch [243/1000] - Training\n",
      "Epoch [243/1000] completed, Average Training Loss: 0.5134\n",
      "    Validation Batch [1/1], Loss: 0.5349\n",
      "Validation Loss: 0.5349, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [244/1000] - Training\n",
      "Epoch [244/1000] completed, Average Training Loss: 0.5162\n",
      "    Validation Batch [1/1], Loss: 0.5315\n",
      "Validation Loss: 0.5315, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5345 to 0.5315. Saving model...\n",
      "\n",
      "LOG: Epoch [245/1000] - Training\n",
      "Epoch [245/1000] completed, Average Training Loss: 0.5128\n",
      "    Validation Batch [1/1], Loss: 0.5307\n",
      "Validation Loss: 0.5307, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5315 to 0.5307. Saving model...\n",
      "\n",
      "LOG: Epoch [246/1000] - Training\n",
      "Epoch [246/1000] completed, Average Training Loss: 0.5212\n",
      "    Validation Batch [1/1], Loss: 0.5290\n",
      "Validation Loss: 0.5290, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5307 to 0.5290. Saving model...\n",
      "\n",
      "LOG: Epoch [247/1000] - Training\n",
      "Epoch [247/1000] completed, Average Training Loss: 0.4679\n",
      "    Validation Batch [1/1], Loss: 0.5259\n",
      "Validation Loss: 0.5259, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5290 to 0.5259. Saving model...\n",
      "\n",
      "LOG: Epoch [248/1000] - Training\n",
      "Epoch [248/1000] completed, Average Training Loss: 0.5304\n",
      "    Validation Batch [1/1], Loss: 0.5185\n",
      "Validation Loss: 0.5185, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5259 to 0.5185. Saving model...\n",
      "\n",
      "LOG: Epoch [249/1000] - Training\n",
      "Epoch [249/1000] completed, Average Training Loss: 0.4848\n",
      "    Validation Batch [1/1], Loss: 0.5103\n",
      "Validation Loss: 0.5103, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5185 to 0.5103. Saving model...\n",
      "\n",
      "LOG: Epoch [250/1000] - Training\n",
      "Epoch [250/1000] completed, Average Training Loss: 0.4791\n",
      "    Validation Batch [1/1], Loss: 0.5108\n",
      "Validation Loss: 0.5108, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [251/1000] - Training\n",
      "Epoch [251/1000] completed, Average Training Loss: 0.5025\n",
      "    Validation Batch [1/1], Loss: 0.4999\n",
      "Validation Loss: 0.4999, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5103 to 0.4999. Saving model...\n",
      "\n",
      "LOG: Epoch [252/1000] - Training\n",
      "Epoch [252/1000] completed, Average Training Loss: 0.4555\n",
      "    Validation Batch [1/1], Loss: 0.4999\n",
      "Validation Loss: 0.4999, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4999 to 0.4999. Saving model...\n",
      "\n",
      "LOG: Epoch [253/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [253/1000] completed, Average Training Loss: 0.4862\n",
      "    Validation Batch [1/1], Loss: 0.4897\n",
      "Validation Loss: 0.4897, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4999 to 0.4897. Saving model...\n",
      "\n",
      "LOG: Epoch [254/1000] - Training\n",
      "Epoch [254/1000] completed, Average Training Loss: 0.4699\n",
      "    Validation Batch [1/1], Loss: 0.4811\n",
      "Validation Loss: 0.4811, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4897 to 0.4811. Saving model...\n",
      "\n",
      "LOG: Epoch [255/1000] - Training\n",
      "Epoch [255/1000] completed, Average Training Loss: 0.4461\n",
      "    Validation Batch [1/1], Loss: 0.4766\n",
      "Validation Loss: 0.4766, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4811 to 0.4766. Saving model...\n",
      "\n",
      "LOG: Epoch [256/1000] - Training\n",
      "Epoch [256/1000] completed, Average Training Loss: 0.4623\n",
      "    Validation Batch [1/1], Loss: 0.4795\n",
      "Validation Loss: 0.4795, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [257/1000] - Training\n",
      "Epoch [257/1000] completed, Average Training Loss: 0.4676\n",
      "    Validation Batch [1/1], Loss: 0.4751\n",
      "Validation Loss: 0.4751, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4766 to 0.4751. Saving model...\n",
      "\n",
      "LOG: Epoch [258/1000] - Training\n",
      "Epoch [258/1000] completed, Average Training Loss: 0.4634\n",
      "    Validation Batch [1/1], Loss: 0.4696\n",
      "Validation Loss: 0.4696, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4751 to 0.4696. Saving model...\n",
      "\n",
      "LOG: Epoch [259/1000] - Training\n",
      "Epoch [259/1000] completed, Average Training Loss: 0.4313\n",
      "    Validation Batch [1/1], Loss: 0.4730\n",
      "Validation Loss: 0.4730, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [260/1000] - Training\n",
      "Epoch [260/1000] completed, Average Training Loss: 0.4442\n",
      "    Validation Batch [1/1], Loss: 0.4696\n",
      "Validation Loss: 0.4696, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.4696 to 0.4696. Saving model...\n",
      "\n",
      "LOG: Epoch [261/1000] - Training\n",
      "Epoch [261/1000] completed, Average Training Loss: 0.4220\n",
      "    Validation Batch [1/1], Loss: 0.4622\n",
      "Validation Loss: 0.4622, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4696 to 0.4622. Saving model...\n",
      "\n",
      "LOG: Epoch [262/1000] - Training\n",
      "Epoch [262/1000] completed, Average Training Loss: 0.4479\n",
      "    Validation Batch [1/1], Loss: 0.4592\n",
      "Validation Loss: 0.4592, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4622 to 0.4592. Saving model...\n",
      "\n",
      "LOG: Epoch [263/1000] - Training\n",
      "Epoch [263/1000] completed, Average Training Loss: 0.4294\n",
      "    Validation Batch [1/1], Loss: 0.4553\n",
      "Validation Loss: 0.4553, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4592 to 0.4553. Saving model...\n",
      "\n",
      "LOG: Epoch [264/1000] - Training\n",
      "Epoch [264/1000] completed, Average Training Loss: 0.4475\n",
      "    Validation Batch [1/1], Loss: 0.4565\n",
      "Validation Loss: 0.4565, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [265/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [265/1000] completed, Average Training Loss: 0.4093\n",
      "    Validation Batch [1/1], Loss: 0.4423\n",
      "Validation Loss: 0.4423, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4553 to 0.4423. Saving model...\n",
      "\n",
      "LOG: Epoch [266/1000] - Training\n",
      "Epoch [266/1000] completed, Average Training Loss: 0.4270\n",
      "    Validation Batch [1/1], Loss: 0.4461\n",
      "Validation Loss: 0.4461, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [267/1000] - Training\n",
      "Epoch [267/1000] completed, Average Training Loss: 0.3911\n",
      "    Validation Batch [1/1], Loss: 0.4435\n",
      "Validation Loss: 0.4435, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [268/1000] - Training\n",
      "Epoch [268/1000] completed, Average Training Loss: 0.4104\n",
      "    Validation Batch [1/1], Loss: 0.4303\n",
      "Validation Loss: 0.4303, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4423 to 0.4303. Saving model...\n",
      "\n",
      "LOG: Epoch [269/1000] - Training\n",
      "Epoch [269/1000] completed, Average Training Loss: 0.4088\n",
      "    Validation Batch [1/1], Loss: 0.4302\n",
      "Validation Loss: 0.4302, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.4303 to 0.4302. Saving model...\n",
      "\n",
      "LOG: Epoch [270/1000] - Training\n",
      "Epoch [270/1000] completed, Average Training Loss: 0.3875\n",
      "    Validation Batch [1/1], Loss: 0.4194\n",
      "Validation Loss: 0.4194, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4302 to 0.4194. Saving model...\n",
      "\n",
      "LOG: Epoch [271/1000] - Training\n",
      "Epoch [271/1000] completed, Average Training Loss: 0.4167\n",
      "    Validation Batch [1/1], Loss: 0.4192\n",
      "Validation Loss: 0.4192, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4194 to 0.4192. Saving model...\n",
      "\n",
      "LOG: Epoch [272/1000] - Training\n",
      "Epoch [272/1000] completed, Average Training Loss: 0.3968\n",
      "    Validation Batch [1/1], Loss: 0.4089\n",
      "Validation Loss: 0.4089, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4192 to 0.4089. Saving model...\n",
      "\n",
      "LOG: Epoch [273/1000] - Training\n",
      "Epoch [273/1000] completed, Average Training Loss: 0.3930\n",
      "    Validation Batch [1/1], Loss: 0.4015\n",
      "Validation Loss: 0.4015, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4089 to 0.4015. Saving model...\n",
      "\n",
      "LOG: Epoch [274/1000] - Training\n",
      "Epoch [274/1000] completed, Average Training Loss: 0.3670\n",
      "    Validation Batch [1/1], Loss: 0.4013\n",
      "Validation Loss: 0.4013, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4015 to 0.4013. Saving model...\n",
      "\n",
      "LOG: Epoch [275/1000] - Training\n",
      "Epoch [275/1000] completed, Average Training Loss: 0.4070\n",
      "    Validation Batch [1/1], Loss: 0.4150\n",
      "Validation Loss: 0.4150, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [276/1000] - Training\n",
      "Epoch [276/1000] completed, Average Training Loss: 0.3851\n",
      "    Validation Batch [1/1], Loss: 0.4149\n",
      "Validation Loss: 0.4149, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [277/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [277/1000] completed, Average Training Loss: 0.3759\n",
      "    Validation Batch [1/1], Loss: 0.3998\n",
      "Validation Loss: 0.3998, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4013 to 0.3998. Saving model...\n",
      "\n",
      "LOG: Epoch [278/1000] - Training\n",
      "Epoch [278/1000] completed, Average Training Loss: 0.3689\n",
      "    Validation Batch [1/1], Loss: 0.3948\n",
      "Validation Loss: 0.3948, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3998 to 0.3948. Saving model...\n",
      "\n",
      "LOG: Epoch [279/1000] - Training\n",
      "Epoch [279/1000] completed, Average Training Loss: 0.3822\n",
      "    Validation Batch [1/1], Loss: 0.3973\n",
      "Validation Loss: 0.3973, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [280/1000] - Training\n",
      "Epoch [280/1000] completed, Average Training Loss: 0.3707\n",
      "    Validation Batch [1/1], Loss: 0.4025\n",
      "Validation Loss: 0.4025, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [281/1000] - Training\n",
      "Epoch [281/1000] completed, Average Training Loss: 0.3840\n",
      "    Validation Batch [1/1], Loss: 0.4011\n",
      "Validation Loss: 0.4011, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [282/1000] - Training\n",
      "Epoch [282/1000] completed, Average Training Loss: 0.3611\n",
      "    Validation Batch [1/1], Loss: 0.3924\n",
      "Validation Loss: 0.3924, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3948 to 0.3924. Saving model...\n",
      "\n",
      "LOG: Epoch [283/1000] - Training\n",
      "Epoch [283/1000] completed, Average Training Loss: 0.3840\n",
      "    Validation Batch [1/1], Loss: 0.3835\n",
      "Validation Loss: 0.3835, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3924 to 0.3835. Saving model...\n",
      "\n",
      "LOG: Epoch [284/1000] - Training\n",
      "Epoch [284/1000] completed, Average Training Loss: 0.3467\n",
      "    Validation Batch [1/1], Loss: 0.3836\n",
      "Validation Loss: 0.3836, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [285/1000] - Training\n",
      "Epoch [285/1000] completed, Average Training Loss: 0.3826\n",
      "    Validation Batch [1/1], Loss: 0.3755\n",
      "Validation Loss: 0.3755, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3835 to 0.3755. Saving model...\n",
      "\n",
      "LOG: Epoch [286/1000] - Training\n",
      "Epoch [286/1000] completed, Average Training Loss: 0.3453\n",
      "    Validation Batch [1/1], Loss: 0.3773\n",
      "Validation Loss: 0.3773, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [287/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [287/1000] completed, Average Training Loss: 0.3649\n",
      "    Validation Batch [1/1], Loss: 0.3733\n",
      "Validation Loss: 0.3733, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3755 to 0.3733. Saving model...\n",
      "\n",
      "LOG: Epoch [288/1000] - Training\n",
      "Epoch [288/1000] completed, Average Training Loss: 0.3582\n",
      "    Validation Batch [1/1], Loss: 0.3746\n",
      "Validation Loss: 0.3746, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [289/1000] - Training\n",
      "Epoch [289/1000] completed, Average Training Loss: 0.3337\n",
      "    Validation Batch [1/1], Loss: 0.3651\n",
      "Validation Loss: 0.3651, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3733 to 0.3651. Saving model...\n",
      "\n",
      "LOG: Epoch [290/1000] - Training\n",
      "Epoch [290/1000] completed, Average Training Loss: 0.3475\n",
      "    Validation Batch [1/1], Loss: 0.3592\n",
      "Validation Loss: 0.3592, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.3651 to 0.3592. Saving model...\n",
      "\n",
      "LOG: Epoch [291/1000] - Training\n",
      "Epoch [291/1000] completed, Average Training Loss: 0.3579\n",
      "    Validation Batch [1/1], Loss: 0.3524\n",
      "Validation Loss: 0.3524, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3592 to 0.3524. Saving model...\n",
      "\n",
      "LOG: Epoch [292/1000] - Training\n",
      "Epoch [292/1000] completed, Average Training Loss: 0.3336\n",
      "    Validation Batch [1/1], Loss: 0.3594\n",
      "Validation Loss: 0.3594, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [293/1000] - Training\n",
      "Epoch [293/1000] completed, Average Training Loss: 0.3388\n",
      "    Validation Batch [1/1], Loss: 0.3571\n",
      "Validation Loss: 0.3571, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [294/1000] - Training\n",
      "Epoch [294/1000] completed, Average Training Loss: 0.3173\n",
      "    Validation Batch [1/1], Loss: 0.3448\n",
      "Validation Loss: 0.3448, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3524 to 0.3448. Saving model...\n",
      "\n",
      "LOG: Epoch [295/1000] - Training\n",
      "Epoch [295/1000] completed, Average Training Loss: 0.3362\n",
      "    Validation Batch [1/1], Loss: 0.3410\n",
      "Validation Loss: 0.3410, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3448 to 0.3410. Saving model...\n",
      "\n",
      "LOG: Epoch [296/1000] - Training\n",
      "Epoch [296/1000] completed, Average Training Loss: 0.2946\n",
      "    Validation Batch [1/1], Loss: 0.3363\n",
      "Validation Loss: 0.3363, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3410 to 0.3363. Saving model...\n",
      "\n",
      "LOG: Epoch [297/1000] - Training\n",
      "Epoch [297/1000] completed, Average Training Loss: 0.3338\n",
      "    Validation Batch [1/1], Loss: 0.3405\n",
      "Validation Loss: 0.3405, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [298/1000] - Training\n",
      "Epoch [298/1000] completed, Average Training Loss: 0.3200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.3422\n",
      "Validation Loss: 0.3422, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [299/1000] - Training\n",
      "Epoch [299/1000] completed, Average Training Loss: 0.3171\n",
      "    Validation Batch [1/1], Loss: 0.3480\n",
      "Validation Loss: 0.3480, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [300/1000] - Training\n",
      "Epoch [300/1000] completed, Average Training Loss: 0.3204\n",
      "    Validation Batch [1/1], Loss: 0.3598\n",
      "Validation Loss: 0.3598, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [301/1000] - Training\n",
      "Epoch [301/1000] completed, Average Training Loss: 0.3136\n",
      "    Validation Batch [1/1], Loss: 0.3411\n",
      "Validation Loss: 0.3411, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [302/1000] - Training\n",
      "Epoch [302/1000] completed, Average Training Loss: 0.3310\n",
      "    Validation Batch [1/1], Loss: 0.3288\n",
      "Validation Loss: 0.3288, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3363 to 0.3288. Saving model...\n",
      "\n",
      "LOG: Epoch [303/1000] - Training\n",
      "Epoch [303/1000] completed, Average Training Loss: 0.3045\n",
      "    Validation Batch [1/1], Loss: 0.3268\n",
      "Validation Loss: 0.3268, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3288 to 0.3268. Saving model...\n",
      "\n",
      "LOG: Epoch [304/1000] - Training\n",
      "Epoch [304/1000] completed, Average Training Loss: 0.2668\n",
      "    Validation Batch [1/1], Loss: 0.3201\n",
      "Validation Loss: 0.3201, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3268 to 0.3201. Saving model...\n",
      "\n",
      "LOG: Epoch [305/1000] - Training\n",
      "Epoch [305/1000] completed, Average Training Loss: 0.2813\n",
      "    Validation Batch [1/1], Loss: 0.3247\n",
      "Validation Loss: 0.3247, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [306/1000] - Training\n",
      "Epoch [306/1000] completed, Average Training Loss: 0.2959\n",
      "    Validation Batch [1/1], Loss: 0.3451\n",
      "Validation Loss: 0.3451, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [307/1000] - Training\n",
      "Epoch [307/1000] completed, Average Training Loss: 0.2725\n",
      "    Validation Batch [1/1], Loss: 0.3334\n",
      "Validation Loss: 0.3334, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [308/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [308/1000] completed, Average Training Loss: 0.2820\n",
      "    Validation Batch [1/1], Loss: 0.3191\n",
      "Validation Loss: 0.3191, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3201 to 0.3191. Saving model...\n",
      "\n",
      "LOG: Epoch [309/1000] - Training\n",
      "Epoch [309/1000] completed, Average Training Loss: 0.2764\n",
      "    Validation Batch [1/1], Loss: 0.3135\n",
      "Validation Loss: 0.3135, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3191 to 0.3135. Saving model...\n",
      "\n",
      "LOG: Epoch [310/1000] - Training\n",
      "Epoch [310/1000] completed, Average Training Loss: 0.2967\n",
      "    Validation Batch [1/1], Loss: 0.3091\n",
      "Validation Loss: 0.3091, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3135 to 0.3091. Saving model...\n",
      "\n",
      "LOG: Epoch [311/1000] - Training\n",
      "Epoch [311/1000] completed, Average Training Loss: 0.2964\n",
      "    Validation Batch [1/1], Loss: 0.3203\n",
      "Validation Loss: 0.3203, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [312/1000] - Training\n",
      "Epoch [312/1000] completed, Average Training Loss: 0.2961\n",
      "    Validation Batch [1/1], Loss: 0.3273\n",
      "Validation Loss: 0.3273, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [313/1000] - Training\n",
      "Epoch [313/1000] completed, Average Training Loss: 0.2824\n",
      "    Validation Batch [1/1], Loss: 0.3061\n",
      "Validation Loss: 0.3061, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3091 to 0.3061. Saving model...\n",
      "\n",
      "LOG: Epoch [314/1000] - Training\n",
      "Epoch [314/1000] completed, Average Training Loss: 0.2733\n",
      "    Validation Batch [1/1], Loss: 0.2962\n",
      "Validation Loss: 0.2962, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3061 to 0.2962. Saving model...\n",
      "\n",
      "LOG: Epoch [315/1000] - Training\n",
      "Epoch [315/1000] completed, Average Training Loss: 0.2660\n",
      "    Validation Batch [1/1], Loss: 0.3037\n",
      "Validation Loss: 0.3037, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [316/1000] - Training\n",
      "Epoch [316/1000] completed, Average Training Loss: 0.2953\n",
      "    Validation Batch [1/1], Loss: 0.3249\n",
      "Validation Loss: 0.3249, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [317/1000] - Training\n",
      "Epoch [317/1000] completed, Average Training Loss: 0.2601\n",
      "    Validation Batch [1/1], Loss: 0.3380\n",
      "Validation Loss: 0.3380, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [318/1000] - Training\n",
      "Epoch [318/1000] completed, Average Training Loss: 0.2653\n",
      "    Validation Batch [1/1], Loss: 0.3202\n",
      "Validation Loss: 0.3202, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [319/1000] - Training\n",
      "Epoch [319/1000] completed, Average Training Loss: 0.2754\n",
      "    Validation Batch [1/1], Loss: 0.2978\n",
      "Validation Loss: 0.2978, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [320/1000] - Training\n",
      "Epoch [320/1000] completed, Average Training Loss: 0.2567\n",
      "    Validation Batch [1/1], Loss: 0.2890\n",
      "Validation Loss: 0.2890, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2962 to 0.2890. Saving model...\n",
      "\n",
      "LOG: Epoch [321/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [321/1000] completed, Average Training Loss: 0.2709\n",
      "    Validation Batch [1/1], Loss: 0.2844\n",
      "Validation Loss: 0.2844, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2890 to 0.2844. Saving model...\n",
      "\n",
      "LOG: Epoch [322/1000] - Training\n",
      "Epoch [322/1000] completed, Average Training Loss: 0.2637\n",
      "    Validation Batch [1/1], Loss: 0.2852\n",
      "Validation Loss: 0.2852, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [323/1000] - Training\n",
      "Epoch [323/1000] completed, Average Training Loss: 0.2566\n",
      "    Validation Batch [1/1], Loss: 0.2889\n",
      "Validation Loss: 0.2889, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [324/1000] - Training\n",
      "Epoch [324/1000] completed, Average Training Loss: 0.2712\n",
      "    Validation Batch [1/1], Loss: 0.2763\n",
      "Validation Loss: 0.2763, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2844 to 0.2763. Saving model...\n",
      "\n",
      "LOG: Epoch [325/1000] - Training\n",
      "Epoch [325/1000] completed, Average Training Loss: 0.2693\n",
      "    Validation Batch [1/1], Loss: 0.2722\n",
      "Validation Loss: 0.2722, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2763 to 0.2722. Saving model...\n",
      "\n",
      "LOG: Epoch [326/1000] - Training\n",
      "Epoch [326/1000] completed, Average Training Loss: 0.2578\n",
      "    Validation Batch [1/1], Loss: 0.2724\n",
      "Validation Loss: 0.2724, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [327/1000] - Training\n",
      "Epoch [327/1000] completed, Average Training Loss: 0.2469\n",
      "    Validation Batch [1/1], Loss: 0.2750\n",
      "Validation Loss: 0.2750, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [328/1000] - Training\n",
      "Epoch [328/1000] completed, Average Training Loss: 0.2598\n",
      "    Validation Batch [1/1], Loss: 0.2779\n",
      "Validation Loss: 0.2779, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [329/1000] - Training\n",
      "Epoch [329/1000] completed, Average Training Loss: 0.2273\n",
      "    Validation Batch [1/1], Loss: 0.2799\n",
      "Validation Loss: 0.2799, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [330/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [330/1000] completed, Average Training Loss: 0.2281\n",
      "    Validation Batch [1/1], Loss: 0.2797\n",
      "Validation Loss: 0.2797, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [331/1000] - Training\n",
      "Epoch [331/1000] completed, Average Training Loss: 0.2298\n",
      "    Validation Batch [1/1], Loss: 0.2742\n",
      "Validation Loss: 0.2742, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [332/1000] - Training\n",
      "Epoch [332/1000] completed, Average Training Loss: 0.2462\n",
      "    Validation Batch [1/1], Loss: 0.2659\n",
      "Validation Loss: 0.2659, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2722 to 0.2659. Saving model...\n",
      "\n",
      "LOG: Epoch [333/1000] - Training\n",
      "Epoch [333/1000] completed, Average Training Loss: 0.2627\n",
      "    Validation Batch [1/1], Loss: 0.2622\n",
      "Validation Loss: 0.2622, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2659 to 0.2622. Saving model...\n",
      "\n",
      "LOG: Epoch [334/1000] - Training\n",
      "Epoch [334/1000] completed, Average Training Loss: 0.2249\n",
      "    Validation Batch [1/1], Loss: 0.2609\n",
      "Validation Loss: 0.2609, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2622 to 0.2609. Saving model...\n",
      "\n",
      "LOG: Epoch [335/1000] - Training\n",
      "Epoch [335/1000] completed, Average Training Loss: 0.2492\n",
      "    Validation Batch [1/1], Loss: 0.2714\n",
      "Validation Loss: 0.2714, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [336/1000] - Training\n",
      "Epoch [336/1000] completed, Average Training Loss: 0.2175\n",
      "    Validation Batch [1/1], Loss: 0.2718\n",
      "Validation Loss: 0.2718, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [337/1000] - Training\n",
      "Epoch [337/1000] completed, Average Training Loss: 0.2444\n",
      "    Validation Batch [1/1], Loss: 0.2621\n",
      "Validation Loss: 0.2621, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [338/1000] - Training\n",
      "Epoch [338/1000] completed, Average Training Loss: 0.2281\n",
      "    Validation Batch [1/1], Loss: 0.2571\n",
      "Validation Loss: 0.2571, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2609 to 0.2571. Saving model...\n",
      "\n",
      "LOG: Epoch [339/1000] - Training\n",
      "Epoch [339/1000] completed, Average Training Loss: 0.2237\n",
      "    Validation Batch [1/1], Loss: 0.2584\n",
      "Validation Loss: 0.2584, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [340/1000] - Training\n",
      "Epoch [340/1000] completed, Average Training Loss: 0.2276\n",
      "    Validation Batch [1/1], Loss: 0.2625\n",
      "Validation Loss: 0.2625, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [341/1000] - Training\n",
      "Epoch [341/1000] completed, Average Training Loss: 0.2326\n",
      "    Validation Batch [1/1], Loss: 0.2646\n",
      "Validation Loss: 0.2646, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [342/1000] - Training\n",
      "Epoch [342/1000] completed, Average Training Loss: 0.2053\n",
      "    Validation Batch [1/1], Loss: 0.2569\n",
      "Validation Loss: 0.2569, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2571 to 0.2569. Saving model...\n",
      "\n",
      "LOG: Epoch [343/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [343/1000] completed, Average Training Loss: 0.2269\n",
      "    Validation Batch [1/1], Loss: 0.2508\n",
      "Validation Loss: 0.2508, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2569 to 0.2508. Saving model...\n",
      "\n",
      "LOG: Epoch [344/1000] - Training\n",
      "Epoch [344/1000] completed, Average Training Loss: 0.2242\n",
      "    Validation Batch [1/1], Loss: 0.2485\n",
      "Validation Loss: 0.2485, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2508 to 0.2485. Saving model...\n",
      "\n",
      "LOG: Epoch [345/1000] - Training\n",
      "Epoch [345/1000] completed, Average Training Loss: 0.2285\n",
      "    Validation Batch [1/1], Loss: 0.2511\n",
      "Validation Loss: 0.2511, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [346/1000] - Training\n",
      "Epoch [346/1000] completed, Average Training Loss: 0.2038\n",
      "    Validation Batch [1/1], Loss: 0.2500\n",
      "Validation Loss: 0.2500, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [347/1000] - Training\n",
      "Epoch [347/1000] completed, Average Training Loss: 0.2242\n",
      "    Validation Batch [1/1], Loss: 0.2383\n",
      "Validation Loss: 0.2383, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2485 to 0.2383. Saving model...\n",
      "\n",
      "LOG: Epoch [348/1000] - Training\n",
      "Epoch [348/1000] completed, Average Training Loss: 0.2216\n",
      "    Validation Batch [1/1], Loss: 0.2399\n",
      "Validation Loss: 0.2399, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [349/1000] - Training\n",
      "Epoch [349/1000] completed, Average Training Loss: 0.2003\n",
      "    Validation Batch [1/1], Loss: 0.2435\n",
      "Validation Loss: 0.2435, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [350/1000] - Training\n",
      "Epoch [350/1000] completed, Average Training Loss: 0.2280\n",
      "    Validation Batch [1/1], Loss: 0.2506\n",
      "Validation Loss: 0.2506, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [351/1000] - Training\n",
      "Epoch [351/1000] completed, Average Training Loss: 0.2037\n",
      "    Validation Batch [1/1], Loss: 0.2535\n",
      "Validation Loss: 0.2535, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [352/1000] - Training\n",
      "Epoch [352/1000] completed, Average Training Loss: 0.2085\n",
      "    Validation Batch [1/1], Loss: 0.2430\n",
      "Validation Loss: 0.2430, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [353/1000] - Training\n",
      "Epoch [353/1000] completed, Average Training Loss: 0.1977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.2362\n",
      "Validation Loss: 0.2362, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2383 to 0.2362. Saving model...\n",
      "\n",
      "LOG: Epoch [354/1000] - Training\n",
      "Epoch [354/1000] completed, Average Training Loss: 0.2187\n",
      "    Validation Batch [1/1], Loss: 0.2358\n",
      "Validation Loss: 0.2358, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2362 to 0.2358. Saving model...\n",
      "\n",
      "LOG: Epoch [355/1000] - Training\n",
      "Epoch [355/1000] completed, Average Training Loss: 0.2076\n",
      "    Validation Batch [1/1], Loss: 0.2336\n",
      "Validation Loss: 0.2336, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2358 to 0.2336. Saving model...\n",
      "\n",
      "LOG: Epoch [356/1000] - Training\n",
      "Epoch [356/1000] completed, Average Training Loss: 0.2020\n",
      "    Validation Batch [1/1], Loss: 0.2340\n",
      "Validation Loss: 0.2340, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [357/1000] - Training\n",
      "Epoch [357/1000] completed, Average Training Loss: 0.2021\n",
      "    Validation Batch [1/1], Loss: 0.2406\n",
      "Validation Loss: 0.2406, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [358/1000] - Training\n",
      "Epoch [358/1000] completed, Average Training Loss: 0.2037\n",
      "    Validation Batch [1/1], Loss: 0.2527\n",
      "Validation Loss: 0.2527, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [359/1000] - Training\n",
      "Epoch [359/1000] completed, Average Training Loss: 0.2066\n",
      "    Validation Batch [1/1], Loss: 0.2664\n",
      "Validation Loss: 0.2664, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [360/1000] - Training\n",
      "Epoch [360/1000] completed, Average Training Loss: 0.1795\n",
      "    Validation Batch [1/1], Loss: 0.2619\n",
      "Validation Loss: 0.2619, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [361/1000] - Training\n",
      "Epoch [361/1000] completed, Average Training Loss: 0.1839\n",
      "    Validation Batch [1/1], Loss: 0.2439\n",
      "Validation Loss: 0.2439, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [362/1000] - Training\n",
      "Epoch [362/1000] completed, Average Training Loss: 0.1822\n",
      "    Validation Batch [1/1], Loss: 0.2343\n",
      "Validation Loss: 0.2343, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [363/1000] - Training\n",
      "Epoch [363/1000] completed, Average Training Loss: 0.1815\n",
      "    Validation Batch [1/1], Loss: 0.2285\n",
      "Validation Loss: 0.2285, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2336 to 0.2285. Saving model...\n",
      "\n",
      "LOG: Epoch [364/1000] - Training\n",
      "Epoch [364/1000] completed, Average Training Loss: 0.1883\n",
      "    Validation Batch [1/1], Loss: 0.2337\n",
      "Validation Loss: 0.2337, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [365/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [365/1000] completed, Average Training Loss: 0.1892\n",
      "    Validation Batch [1/1], Loss: 0.2461\n",
      "Validation Loss: 0.2461, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [366/1000] - Training\n",
      "Epoch [366/1000] completed, Average Training Loss: 0.1817\n",
      "    Validation Batch [1/1], Loss: 0.2474\n",
      "Validation Loss: 0.2474, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [367/1000] - Training\n",
      "Epoch [367/1000] completed, Average Training Loss: 0.1871\n",
      "    Validation Batch [1/1], Loss: 0.2324\n",
      "Validation Loss: 0.2324, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [368/1000] - Training\n",
      "Epoch [368/1000] completed, Average Training Loss: 0.1974\n",
      "    Validation Batch [1/1], Loss: 0.2143\n",
      "Validation Loss: 0.2143, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2285 to 0.2143. Saving model...\n",
      "\n",
      "LOG: Epoch [369/1000] - Training\n",
      "Epoch [369/1000] completed, Average Training Loss: 0.2007\n",
      "    Validation Batch [1/1], Loss: 0.2073\n",
      "Validation Loss: 0.2073, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2143 to 0.2073. Saving model...\n",
      "\n",
      "LOG: Epoch [370/1000] - Training\n",
      "Epoch [370/1000] completed, Average Training Loss: 0.1957\n",
      "    Validation Batch [1/1], Loss: 0.2044\n",
      "Validation Loss: 0.2044, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2073 to 0.2044. Saving model...\n",
      "\n",
      "LOG: Epoch [371/1000] - Training\n",
      "Epoch [371/1000] completed, Average Training Loss: 0.1688\n",
      "    Validation Batch [1/1], Loss: 0.2159\n",
      "Validation Loss: 0.2159, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [372/1000] - Training\n",
      "Epoch [372/1000] completed, Average Training Loss: 0.1955\n",
      "    Validation Batch [1/1], Loss: 0.2356\n",
      "Validation Loss: 0.2356, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [373/1000] - Training\n",
      "Epoch [373/1000] completed, Average Training Loss: 0.1797\n",
      "    Validation Batch [1/1], Loss: 0.2414\n",
      "Validation Loss: 0.2414, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [374/1000] - Training\n",
      "Epoch [374/1000] completed, Average Training Loss: 0.1725\n",
      "    Validation Batch [1/1], Loss: 0.2333\n",
      "Validation Loss: 0.2333, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [375/1000] - Training\n",
      "Epoch [375/1000] completed, Average Training Loss: 0.1755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.2206\n",
      "Validation Loss: 0.2206, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [376/1000] - Training\n",
      "Epoch [376/1000] completed, Average Training Loss: 0.1902\n",
      "    Validation Batch [1/1], Loss: 0.2072\n",
      "Validation Loss: 0.2072, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [377/1000] - Training\n",
      "Epoch [377/1000] completed, Average Training Loss: 0.1640\n",
      "    Validation Batch [1/1], Loss: 0.2016\n",
      "Validation Loss: 0.2016, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2044 to 0.2016. Saving model...\n",
      "\n",
      "LOG: Epoch [378/1000] - Training\n",
      "Epoch [378/1000] completed, Average Training Loss: 0.1684\n",
      "    Validation Batch [1/1], Loss: 0.2061\n",
      "Validation Loss: 0.2061, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [379/1000] - Training\n",
      "Epoch [379/1000] completed, Average Training Loss: 0.1808\n",
      "    Validation Batch [1/1], Loss: 0.2125\n",
      "Validation Loss: 0.2125, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [380/1000] - Training\n",
      "Epoch [380/1000] completed, Average Training Loss: 0.1826\n",
      "    Validation Batch [1/1], Loss: 0.2177\n",
      "Validation Loss: 0.2177, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [381/1000] - Training\n",
      "Epoch [381/1000] completed, Average Training Loss: 0.1700\n",
      "    Validation Batch [1/1], Loss: 0.2182\n",
      "Validation Loss: 0.2182, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [382/1000] - Training\n",
      "Epoch [382/1000] completed, Average Training Loss: 0.1611\n",
      "    Validation Batch [1/1], Loss: 0.2047\n",
      "Validation Loss: 0.2047, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [383/1000] - Training\n",
      "Epoch [383/1000] completed, Average Training Loss: 0.1582\n",
      "    Validation Batch [1/1], Loss: 0.2011\n",
      "Validation Loss: 0.2011, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2016 to 0.2011. Saving model...\n",
      "\n",
      "LOG: Epoch [384/1000] - Training\n",
      "Epoch [384/1000] completed, Average Training Loss: 0.1644\n",
      "    Validation Batch [1/1], Loss: 0.2050\n",
      "Validation Loss: 0.2050, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [385/1000] - Training\n",
      "Epoch [385/1000] completed, Average Training Loss: 0.1751\n",
      "    Validation Batch [1/1], Loss: 0.2036\n",
      "Validation Loss: 0.2036, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [386/1000] - Training\n",
      "Epoch [386/1000] completed, Average Training Loss: 0.1625\n",
      "    Validation Batch [1/1], Loss: 0.2133\n",
      "Validation Loss: 0.2133, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [387/1000] - Training\n",
      "Epoch [387/1000] completed, Average Training Loss: 0.1561\n",
      "    Validation Batch [1/1], Loss: 0.2142\n",
      "Validation Loss: 0.2142, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [388/1000] - Training\n",
      "Epoch [388/1000] completed, Average Training Loss: 0.1546\n",
      "    Validation Batch [1/1], Loss: 0.2105\n",
      "Validation Loss: 0.2105, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [389/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [389/1000] completed, Average Training Loss: 0.1620\n",
      "    Validation Batch [1/1], Loss: 0.2093\n",
      "Validation Loss: 0.2093, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [390/1000] - Training\n",
      "Epoch [390/1000] completed, Average Training Loss: 0.1480\n",
      "    Validation Batch [1/1], Loss: 0.2021\n",
      "Validation Loss: 0.2021, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [391/1000] - Training\n",
      "Epoch [391/1000] completed, Average Training Loss: 0.1467\n",
      "    Validation Batch [1/1], Loss: 0.1895\n",
      "Validation Loss: 0.1895, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.2011 to 0.1895. Saving model...\n",
      "\n",
      "LOG: Epoch [392/1000] - Training\n",
      "Epoch [392/1000] completed, Average Training Loss: 0.1555\n",
      "    Validation Batch [1/1], Loss: 0.1902\n",
      "Validation Loss: 0.1902, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [393/1000] - Training\n",
      "Epoch [393/1000] completed, Average Training Loss: 0.1565\n",
      "    Validation Batch [1/1], Loss: 0.2044\n",
      "Validation Loss: 0.2044, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [394/1000] - Training\n",
      "Epoch [394/1000] completed, Average Training Loss: 0.1447\n",
      "    Validation Batch [1/1], Loss: 0.2146\n",
      "Validation Loss: 0.2146, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [395/1000] - Training\n",
      "Epoch [395/1000] completed, Average Training Loss: 0.1719\n",
      "    Validation Batch [1/1], Loss: 0.1942\n",
      "Validation Loss: 0.1942, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [396/1000] - Training\n",
      "Epoch [396/1000] completed, Average Training Loss: 0.1545\n",
      "    Validation Batch [1/1], Loss: 0.1878\n",
      "Validation Loss: 0.1878, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1895 to 0.1878. Saving model...\n",
      "\n",
      "LOG: Epoch [397/1000] - Training\n",
      "Epoch [397/1000] completed, Average Training Loss: 0.1527\n",
      "    Validation Batch [1/1], Loss: 0.1838\n",
      "Validation Loss: 0.1838, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1878 to 0.1838. Saving model...\n",
      "\n",
      "LOG: Epoch [398/1000] - Training\n",
      "Epoch [398/1000] completed, Average Training Loss: 0.1679\n",
      "    Validation Batch [1/1], Loss: 0.1778\n",
      "Validation Loss: 0.1778, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1838 to 0.1778. Saving model...\n",
      "\n",
      "LOG: Epoch [399/1000] - Training\n",
      "Epoch [399/1000] completed, Average Training Loss: 0.1470\n",
      "    Validation Batch [1/1], Loss: 0.1916\n",
      "Validation Loss: 0.1916, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [400/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [400/1000] completed, Average Training Loss: 0.1474\n",
      "    Validation Batch [1/1], Loss: 0.1972\n",
      "Validation Loss: 0.1972, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [401/1000] - Training\n",
      "Epoch [401/1000] completed, Average Training Loss: 0.1481\n",
      "    Validation Batch [1/1], Loss: 0.1891\n",
      "Validation Loss: 0.1891, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [402/1000] - Training\n",
      "Epoch [402/1000] completed, Average Training Loss: 0.1627\n",
      "    Validation Batch [1/1], Loss: 0.1929\n",
      "Validation Loss: 0.1929, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [403/1000] - Training\n",
      "Epoch [403/1000] completed, Average Training Loss: 0.1391\n",
      "    Validation Batch [1/1], Loss: 0.2085\n",
      "Validation Loss: 0.2085, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [404/1000] - Training\n",
      "Epoch [404/1000] completed, Average Training Loss: 0.1486\n",
      "    Validation Batch [1/1], Loss: 0.2174\n",
      "Validation Loss: 0.2174, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [405/1000] - Training\n",
      "Epoch [405/1000] completed, Average Training Loss: 0.1319\n",
      "    Validation Batch [1/1], Loss: 0.2152\n",
      "Validation Loss: 0.2152, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [406/1000] - Training\n",
      "Epoch [406/1000] completed, Average Training Loss: 0.1409\n",
      "    Validation Batch [1/1], Loss: 0.2123\n",
      "Validation Loss: 0.2123, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [407/1000] - Training\n",
      "Epoch [407/1000] completed, Average Training Loss: 0.1321\n",
      "    Validation Batch [1/1], Loss: 0.1969\n",
      "Validation Loss: 0.1969, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [408/1000] - Training\n",
      "Epoch [408/1000] completed, Average Training Loss: 0.1413\n",
      "    Validation Batch [1/1], Loss: 0.1776\n",
      "Validation Loss: 0.1776, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1778 to 0.1776. Saving model...\n",
      "\n",
      "LOG: Epoch [409/1000] - Training\n",
      "Epoch [409/1000] completed, Average Training Loss: 0.1514\n",
      "    Validation Batch [1/1], Loss: 0.1758\n",
      "Validation Loss: 0.1758, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1776 to 0.1758. Saving model...\n",
      "\n",
      "LOG: Epoch [410/1000] - Training\n",
      "Epoch [410/1000] completed, Average Training Loss: 0.1314\n",
      "    Validation Batch [1/1], Loss: 0.1788\n",
      "Validation Loss: 0.1788, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [411/1000] - Training\n",
      "Epoch [411/1000] completed, Average Training Loss: 0.1390\n",
      "    Validation Batch [1/1], Loss: 0.1751\n",
      "Validation Loss: 0.1751, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1758 to 0.1751. Saving model...\n",
      "\n",
      "LOG: Epoch [412/1000] - Training\n",
      "Epoch [412/1000] completed, Average Training Loss: 0.1348\n",
      "    Validation Batch [1/1], Loss: 0.1746\n",
      "Validation Loss: 0.1746, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1751 to 0.1746. Saving model...\n",
      "\n",
      "LOG: Epoch [413/1000] - Training\n",
      "Epoch [413/1000] completed, Average Training Loss: 0.1573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1722\n",
      "Validation Loss: 0.1722, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1746 to 0.1722. Saving model...\n",
      "\n",
      "LOG: Epoch [414/1000] - Training\n",
      "Epoch [414/1000] completed, Average Training Loss: 0.1314\n",
      "    Validation Batch [1/1], Loss: 0.1766\n",
      "Validation Loss: 0.1766, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [415/1000] - Training\n",
      "Epoch [415/1000] completed, Average Training Loss: 0.1320\n",
      "    Validation Batch [1/1], Loss: 0.1855\n",
      "Validation Loss: 0.1855, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [416/1000] - Training\n",
      "Epoch [416/1000] completed, Average Training Loss: 0.1296\n",
      "    Validation Batch [1/1], Loss: 0.1889\n",
      "Validation Loss: 0.1889, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [417/1000] - Training\n",
      "Epoch [417/1000] completed, Average Training Loss: 0.1338\n",
      "    Validation Batch [1/1], Loss: 0.1787\n",
      "Validation Loss: 0.1787, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [418/1000] - Training\n",
      "Epoch [418/1000] completed, Average Training Loss: 0.1380\n",
      "    Validation Batch [1/1], Loss: 0.1668\n",
      "Validation Loss: 0.1668, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1722 to 0.1668. Saving model...\n",
      "\n",
      "LOG: Epoch [419/1000] - Training\n",
      "Epoch [419/1000] completed, Average Training Loss: 0.1323\n",
      "    Validation Batch [1/1], Loss: 0.1654\n",
      "Validation Loss: 0.1654, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1668 to 0.1654. Saving model...\n",
      "\n",
      "LOG: Epoch [420/1000] - Training\n",
      "Epoch [420/1000] completed, Average Training Loss: 0.1416\n",
      "    Validation Batch [1/1], Loss: 0.1654\n",
      "Validation Loss: 0.1654, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [421/1000] - Training\n",
      "Epoch [421/1000] completed, Average Training Loss: 0.1394\n",
      "    Validation Batch [1/1], Loss: 0.1754\n",
      "Validation Loss: 0.1754, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [422/1000] - Training\n",
      "Epoch [422/1000] completed, Average Training Loss: 0.1232\n",
      "    Validation Batch [1/1], Loss: 0.1944\n",
      "Validation Loss: 0.1944, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [423/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [423/1000] completed, Average Training Loss: 0.1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1909\n",
      "Validation Loss: 0.1909, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [424/1000] - Training\n",
      "Epoch [424/1000] completed, Average Training Loss: 0.1325\n",
      "    Validation Batch [1/1], Loss: 0.1652\n",
      "Validation Loss: 0.1652, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1654 to 0.1652. Saving model...\n",
      "\n",
      "LOG: Epoch [425/1000] - Training\n",
      "Epoch [425/1000] completed, Average Training Loss: 0.1273\n",
      "    Validation Batch [1/1], Loss: 0.1594\n",
      "Validation Loss: 0.1594, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1652 to 0.1594. Saving model...\n",
      "\n",
      "LOG: Epoch [426/1000] - Training\n",
      "Epoch [426/1000] completed, Average Training Loss: 0.1236\n",
      "    Validation Batch [1/1], Loss: 0.1671\n",
      "Validation Loss: 0.1671, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [427/1000] - Training\n",
      "Epoch [427/1000] completed, Average Training Loss: 0.1248\n",
      "    Validation Batch [1/1], Loss: 0.1706\n",
      "Validation Loss: 0.1706, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [428/1000] - Training\n",
      "Epoch [428/1000] completed, Average Training Loss: 0.1291\n",
      "    Validation Batch [1/1], Loss: 0.1838\n",
      "Validation Loss: 0.1838, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [429/1000] - Training\n",
      "Epoch [429/1000] completed, Average Training Loss: 0.1187\n",
      "    Validation Batch [1/1], Loss: 0.1996\n",
      "Validation Loss: 0.1996, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [430/1000] - Training\n",
      "Epoch [430/1000] completed, Average Training Loss: 0.1113\n",
      "    Validation Batch [1/1], Loss: 0.1802\n",
      "Validation Loss: 0.1802, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [431/1000] - Training\n",
      "Epoch [431/1000] completed, Average Training Loss: 0.1147\n",
      "    Validation Batch [1/1], Loss: 0.1590\n",
      "Validation Loss: 0.1590, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1594 to 0.1590. Saving model...\n",
      "\n",
      "LOG: Epoch [432/1000] - Training\n",
      "Epoch [432/1000] completed, Average Training Loss: 0.1084\n",
      "    Validation Batch [1/1], Loss: 0.1453\n",
      "Validation Loss: 0.1453, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1590 to 0.1453. Saving model...\n",
      "\n",
      "LOG: Epoch [433/1000] - Training\n",
      "Epoch [433/1000] completed, Average Training Loss: 0.1228\n",
      "    Validation Batch [1/1], Loss: 0.1421\n",
      "Validation Loss: 0.1421, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1453 to 0.1421. Saving model...\n",
      "\n",
      "LOG: Epoch [434/1000] - Training\n",
      "Epoch [434/1000] completed, Average Training Loss: 0.1362\n",
      "    Validation Batch [1/1], Loss: 0.1446\n",
      "Validation Loss: 0.1446, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [435/1000] - Training\n",
      "Epoch [435/1000] completed, Average Training Loss: 0.1107\n",
      "    Validation Batch [1/1], Loss: 0.1537\n",
      "Validation Loss: 0.1537, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [436/1000] - Training\n",
      "Epoch [436/1000] completed, Average Training Loss: 0.1234\n",
      "    Validation Batch [1/1], Loss: 0.1709\n",
      "Validation Loss: 0.1709, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [437/1000] - Training\n",
      "Epoch [437/1000] completed, Average Training Loss: 0.1164\n",
      "    Validation Batch [1/1], Loss: 0.1776\n",
      "Validation Loss: 0.1776, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [438/1000] - Training\n",
      "Epoch [438/1000] completed, Average Training Loss: 0.1178\n",
      "    Validation Batch [1/1], Loss: 0.1631\n",
      "Validation Loss: 0.1631, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [439/1000] - Training\n",
      "Epoch [439/1000] completed, Average Training Loss: 0.1113\n",
      "    Validation Batch [1/1], Loss: 0.1530\n",
      "Validation Loss: 0.1530, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [440/1000] - Training\n",
      "Epoch [440/1000] completed, Average Training Loss: 0.1217\n",
      "    Validation Batch [1/1], Loss: 0.1485\n",
      "Validation Loss: 0.1485, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [441/1000] - Training\n",
      "Epoch [441/1000] completed, Average Training Loss: 0.1056\n",
      "    Validation Batch [1/1], Loss: 0.1525\n",
      "Validation Loss: 0.1525, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [442/1000] - Training\n",
      "Epoch [442/1000] completed, Average Training Loss: 0.1129\n",
      "    Validation Batch [1/1], Loss: 0.1561\n",
      "Validation Loss: 0.1561, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [443/1000] - Training\n",
      "Epoch [443/1000] completed, Average Training Loss: 0.1100\n",
      "    Validation Batch [1/1], Loss: 0.1621\n",
      "Validation Loss: 0.1621, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [444/1000] - Training\n",
      "Epoch [444/1000] completed, Average Training Loss: 0.1154\n",
      "    Validation Batch [1/1], Loss: 0.1589\n",
      "Validation Loss: 0.1589, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [445/1000] - Training\n",
      "Epoch [445/1000] completed, Average Training Loss: 0.1235\n",
      "    Validation Batch [1/1], Loss: 0.1488\n",
      "Validation Loss: 0.1488, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [446/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [446/1000] completed, Average Training Loss: 0.1085\n",
      "    Validation Batch [1/1], Loss: 0.1484\n",
      "Validation Loss: 0.1484, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [447/1000] - Training\n",
      "Epoch [447/1000] completed, Average Training Loss: 0.1192\n",
      "    Validation Batch [1/1], Loss: 0.1522\n",
      "Validation Loss: 0.1522, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [448/1000] - Training\n",
      "Epoch [448/1000] completed, Average Training Loss: 0.1150\n",
      "    Validation Batch [1/1], Loss: 0.1580\n",
      "Validation Loss: 0.1580, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [449/1000] - Training\n",
      "Epoch [449/1000] completed, Average Training Loss: 0.0995\n",
      "    Validation Batch [1/1], Loss: 0.1671\n",
      "Validation Loss: 0.1671, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [450/1000] - Training\n",
      "Epoch [450/1000] completed, Average Training Loss: 0.1081\n",
      "    Validation Batch [1/1], Loss: 0.1809\n",
      "Validation Loss: 0.1809, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [451/1000] - Training\n",
      "Epoch [451/1000] completed, Average Training Loss: 0.1061\n",
      "    Validation Batch [1/1], Loss: 0.1852\n",
      "Validation Loss: 0.1852, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [452/1000] - Training\n",
      "Epoch [452/1000] completed, Average Training Loss: 0.1042\n",
      "    Validation Batch [1/1], Loss: 0.1740\n",
      "Validation Loss: 0.1740, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [453/1000] - Training\n",
      "Epoch [453/1000] completed, Average Training Loss: 0.1018\n",
      "    Validation Batch [1/1], Loss: 0.1555\n",
      "Validation Loss: 0.1555, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [454/1000] - Training\n",
      "Epoch [454/1000] completed, Average Training Loss: 0.1021\n",
      "    Validation Batch [1/1], Loss: 0.1442\n",
      "Validation Loss: 0.1442, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [455/1000] - Training\n",
      "Epoch [455/1000] completed, Average Training Loss: 0.0909\n",
      "    Validation Batch [1/1], Loss: 0.1376\n",
      "Validation Loss: 0.1376, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1421 to 0.1376. Saving model...\n",
      "\n",
      "LOG: Epoch [456/1000] - Training\n",
      "Epoch [456/1000] completed, Average Training Loss: 0.1093\n",
      "    Validation Batch [1/1], Loss: 0.1435\n",
      "Validation Loss: 0.1435, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [457/1000] - Training\n",
      "Epoch [457/1000] completed, Average Training Loss: 0.1070\n",
      "    Validation Batch [1/1], Loss: 0.1634\n",
      "Validation Loss: 0.1634, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [458/1000] - Training\n",
      "Epoch [458/1000] completed, Average Training Loss: 0.0923\n",
      "    Validation Batch [1/1], Loss: 0.1783\n",
      "Validation Loss: 0.1783, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [459/1000] - Training\n",
      "Epoch [459/1000] completed, Average Training Loss: 0.1016\n",
      "    Validation Batch [1/1], Loss: 0.1834\n",
      "Validation Loss: 0.1834, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [460/1000] - Training\n",
      "Epoch [460/1000] completed, Average Training Loss: 0.0976\n",
      "    Validation Batch [1/1], Loss: 0.1698\n",
      "Validation Loss: 0.1698, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [461/1000] - Training\n",
      "Epoch [461/1000] completed, Average Training Loss: 0.1162\n",
      "    Validation Batch [1/1], Loss: 0.1456\n",
      "Validation Loss: 0.1456, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [462/1000] - Training\n",
      "Epoch [462/1000] completed, Average Training Loss: 0.1155\n",
      "    Validation Batch [1/1], Loss: 0.1462\n",
      "Validation Loss: 0.1462, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [463/1000] - Training\n",
      "Epoch [463/1000] completed, Average Training Loss: 0.1015\n",
      "    Validation Batch [1/1], Loss: 0.1464\n",
      "Validation Loss: 0.1464, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [464/1000] - Training\n",
      "Epoch [464/1000] completed, Average Training Loss: 0.1100\n",
      "    Validation Batch [1/1], Loss: 0.1432\n",
      "Validation Loss: 0.1432, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [465/1000] - Training\n",
      "Epoch [465/1000] completed, Average Training Loss: 0.1045\n",
      "    Validation Batch [1/1], Loss: 0.1548\n",
      "Validation Loss: 0.1548, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [466/1000] - Training\n",
      "Epoch [466/1000] completed, Average Training Loss: 0.1030\n",
      "    Validation Batch [1/1], Loss: 0.1777\n",
      "Validation Loss: 0.1777, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [467/1000] - Training\n",
      "Epoch [467/1000] completed, Average Training Loss: 0.0941\n",
      "    Validation Batch [1/1], Loss: 0.1867\n",
      "Validation Loss: 0.1867, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [468/1000] - Training\n",
      "Epoch [468/1000] completed, Average Training Loss: 0.1095\n",
      "    Validation Batch [1/1], Loss: 0.1795\n",
      "Validation Loss: 0.1795, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [469/1000] - Training\n",
      "Epoch [469/1000] completed, Average Training Loss: 0.1062\n",
      "    Validation Batch [1/1], Loss: 0.1601\n",
      "Validation Loss: 0.1601, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [470/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [470/1000] completed, Average Training Loss: 0.1057\n",
      "    Validation Batch [1/1], Loss: 0.1443\n",
      "Validation Loss: 0.1443, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [471/1000] - Training\n",
      "Epoch [471/1000] completed, Average Training Loss: 0.1012\n",
      "    Validation Batch [1/1], Loss: 0.1341\n",
      "Validation Loss: 0.1341, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1376 to 0.1341. Saving model...\n",
      "\n",
      "LOG: Epoch [472/1000] - Training\n",
      "Epoch [472/1000] completed, Average Training Loss: 0.1056\n",
      "    Validation Batch [1/1], Loss: 0.1288\n",
      "Validation Loss: 0.1288, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1341 to 0.1288. Saving model...\n",
      "\n",
      "LOG: Epoch [473/1000] - Training\n",
      "Epoch [473/1000] completed, Average Training Loss: 0.0952\n",
      "    Validation Batch [1/1], Loss: 0.1340\n",
      "Validation Loss: 0.1340, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [474/1000] - Training\n",
      "Epoch [474/1000] completed, Average Training Loss: 0.0892\n",
      "    Validation Batch [1/1], Loss: 0.1471\n",
      "Validation Loss: 0.1471, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [475/1000] - Training\n",
      "Epoch [475/1000] completed, Average Training Loss: 0.1004\n",
      "    Validation Batch [1/1], Loss: 0.1486\n",
      "Validation Loss: 0.1486, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [476/1000] - Training\n",
      "Epoch [476/1000] completed, Average Training Loss: 0.1033\n",
      "    Validation Batch [1/1], Loss: 0.1455\n",
      "Validation Loss: 0.1455, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [477/1000] - Training\n",
      "Epoch [477/1000] completed, Average Training Loss: 0.0987\n",
      "    Validation Batch [1/1], Loss: 0.1334\n",
      "Validation Loss: 0.1334, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [478/1000] - Training\n",
      "Epoch [478/1000] completed, Average Training Loss: 0.0987\n",
      "    Validation Batch [1/1], Loss: 0.1286\n",
      "Validation Loss: 0.1286, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1288 to 0.1286. Saving model...\n",
      "\n",
      "LOG: Epoch [479/1000] - Training\n",
      "Epoch [479/1000] completed, Average Training Loss: 0.0903\n",
      "    Validation Batch [1/1], Loss: 0.1280\n",
      "Validation Loss: 0.1280, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1286 to 0.1280. Saving model...\n",
      "\n",
      "LOG: Epoch [480/1000] - Training\n",
      "Epoch [480/1000] completed, Average Training Loss: 0.0991\n",
      "    Validation Batch [1/1], Loss: 0.1345\n",
      "Validation Loss: 0.1345, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [481/1000] - Training\n",
      "Epoch [481/1000] completed, Average Training Loss: 0.1002\n",
      "    Validation Batch [1/1], Loss: 0.1398\n",
      "Validation Loss: 0.1398, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [482/1000] - Training\n",
      "Epoch [482/1000] completed, Average Training Loss: 0.1024\n",
      "    Validation Batch [1/1], Loss: 0.1337\n",
      "Validation Loss: 0.1337, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [483/1000] - Training\n",
      "Epoch [483/1000] completed, Average Training Loss: 0.0857\n",
      "    Validation Batch [1/1], Loss: 0.1294\n",
      "Validation Loss: 0.1294, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [484/1000] - Training\n",
      "Epoch [484/1000] completed, Average Training Loss: 0.1056\n",
      "    Validation Batch [1/1], Loss: 0.1297\n",
      "Validation Loss: 0.1297, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [485/1000] - Training\n",
      "Epoch [485/1000] completed, Average Training Loss: 0.0897\n",
      "    Validation Batch [1/1], Loss: 0.1301\n",
      "Validation Loss: 0.1301, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [486/1000] - Training\n",
      "Epoch [486/1000] completed, Average Training Loss: 0.0871\n",
      "    Validation Batch [1/1], Loss: 0.1246\n",
      "Validation Loss: 0.1246, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1280 to 0.1246. Saving model...\n",
      "\n",
      "LOG: Epoch [487/1000] - Training\n",
      "Epoch [487/1000] completed, Average Training Loss: 0.0911\n",
      "    Validation Batch [1/1], Loss: 0.1131\n",
      "Validation Loss: 0.1131, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1246 to 0.1131. Saving model...\n",
      "\n",
      "LOG: Epoch [488/1000] - Training\n",
      "Epoch [488/1000] completed, Average Training Loss: 0.0984\n",
      "    Validation Batch [1/1], Loss: 0.1078\n",
      "Validation Loss: 0.1078, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1131 to 0.1078. Saving model...\n",
      "\n",
      "LOG: Epoch [489/1000] - Training\n",
      "Epoch [489/1000] completed, Average Training Loss: 0.0912\n",
      "    Validation Batch [1/1], Loss: 0.1093\n",
      "Validation Loss: 0.1093, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [490/1000] - Training\n",
      "Epoch [490/1000] completed, Average Training Loss: 0.0918\n",
      "    Validation Batch [1/1], Loss: 0.1151\n",
      "Validation Loss: 0.1151, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [491/1000] - Training\n",
      "Epoch [491/1000] completed, Average Training Loss: 0.0933\n",
      "    Validation Batch [1/1], Loss: 0.1248\n",
      "Validation Loss: 0.1248, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [492/1000] - Training\n",
      "Epoch [492/1000] completed, Average Training Loss: 0.0831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1383\n",
      "Validation Loss: 0.1383, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [493/1000] - Training\n",
      "Epoch [493/1000] completed, Average Training Loss: 0.0814\n",
      "    Validation Batch [1/1], Loss: 0.1426\n",
      "Validation Loss: 0.1426, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [494/1000] - Training\n",
      "Epoch [494/1000] completed, Average Training Loss: 0.0790\n",
      "    Validation Batch [1/1], Loss: 0.1407\n",
      "Validation Loss: 0.1407, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [495/1000] - Training\n",
      "Epoch [495/1000] completed, Average Training Loss: 0.0989\n",
      "    Validation Batch [1/1], Loss: 0.1269\n",
      "Validation Loss: 0.1269, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [496/1000] - Training\n",
      "Epoch [496/1000] completed, Average Training Loss: 0.0846\n",
      "    Validation Batch [1/1], Loss: 0.1152\n",
      "Validation Loss: 0.1152, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [497/1000] - Training\n",
      "Epoch [497/1000] completed, Average Training Loss: 0.0807\n",
      "    Validation Batch [1/1], Loss: 0.1154\n",
      "Validation Loss: 0.1154, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [498/1000] - Training\n",
      "Epoch [498/1000] completed, Average Training Loss: 0.0815\n",
      "    Validation Batch [1/1], Loss: 0.1250\n",
      "Validation Loss: 0.1250, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [499/1000] - Training\n",
      "Epoch [499/1000] completed, Average Training Loss: 0.0776\n",
      "    Validation Batch [1/1], Loss: 0.1421\n",
      "Validation Loss: 0.1421, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [500/1000] - Training\n",
      "Epoch [500/1000] completed, Average Training Loss: 0.0931\n",
      "    Validation Batch [1/1], Loss: 0.1514\n",
      "Validation Loss: 0.1514, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [501/1000] - Training\n",
      "Epoch [501/1000] completed, Average Training Loss: 0.0865\n",
      "    Validation Batch [1/1], Loss: 0.1556\n",
      "Validation Loss: 0.1556, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [502/1000] - Training\n",
      "Epoch [502/1000] completed, Average Training Loss: 0.0850\n",
      "    Validation Batch [1/1], Loss: 0.1437\n",
      "Validation Loss: 0.1437, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [503/1000] - Training\n",
      "Epoch [503/1000] completed, Average Training Loss: 0.0773\n",
      "    Validation Batch [1/1], Loss: 0.1209\n",
      "Validation Loss: 0.1209, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [504/1000] - Training\n",
      "Epoch [504/1000] completed, Average Training Loss: 0.0772\n",
      "    Validation Batch [1/1], Loss: 0.1077\n",
      "Validation Loss: 0.1077, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1078 to 0.1077. Saving model...\n",
      "\n",
      "LOG: Epoch [505/1000] - Training\n",
      "Epoch [505/1000] completed, Average Training Loss: 0.0822\n",
      "    Validation Batch [1/1], Loss: 0.1049\n",
      "Validation Loss: 0.1049, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1077 to 0.1049. Saving model...\n",
      "\n",
      "LOG: Epoch [506/1000] - Training\n",
      "Epoch [506/1000] completed, Average Training Loss: 0.0834\n",
      "    Validation Batch [1/1], Loss: 0.1051\n",
      "Validation Loss: 0.1051, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [507/1000] - Training\n",
      "Epoch [507/1000] completed, Average Training Loss: 0.0876\n",
      "    Validation Batch [1/1], Loss: 0.1106\n",
      "Validation Loss: 0.1106, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [508/1000] - Training\n",
      "Epoch [508/1000] completed, Average Training Loss: 0.0818\n",
      "    Validation Batch [1/1], Loss: 0.1211\n",
      "Validation Loss: 0.1211, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [509/1000] - Training\n",
      "Epoch [509/1000] completed, Average Training Loss: 0.0743\n",
      "    Validation Batch [1/1], Loss: 0.1267\n",
      "Validation Loss: 0.1267, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [510/1000] - Training\n",
      "Epoch [510/1000] completed, Average Training Loss: 0.0722\n",
      "    Validation Batch [1/1], Loss: 0.1448\n",
      "Validation Loss: 0.1448, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [511/1000] - Training\n",
      "Epoch [511/1000] completed, Average Training Loss: 0.0840\n",
      "    Validation Batch [1/1], Loss: 0.1539\n",
      "Validation Loss: 0.1539, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [512/1000] - Training\n",
      "Epoch [512/1000] completed, Average Training Loss: 0.0715\n",
      "    Validation Batch [1/1], Loss: 0.1481\n",
      "Validation Loss: 0.1481, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [513/1000] - Training\n",
      "Epoch [513/1000] completed, Average Training Loss: 0.0758\n",
      "    Validation Batch [1/1], Loss: 0.1193\n",
      "Validation Loss: 0.1193, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [514/1000] - Training\n",
      "Epoch [514/1000] completed, Average Training Loss: 0.0778\n",
      "    Validation Batch [1/1], Loss: 0.1036\n",
      "Validation Loss: 0.1036, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1049 to 0.1036. Saving model...\n",
      "\n",
      "LOG: Epoch [515/1000] - Training\n",
      "Epoch [515/1000] completed, Average Training Loss: 0.0690\n",
      "    Validation Batch [1/1], Loss: 0.1050\n",
      "Validation Loss: 0.1050, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [516/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [516/1000] completed, Average Training Loss: 0.0736\n",
      "    Validation Batch [1/1], Loss: 0.1121\n",
      "Validation Loss: 0.1121, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [517/1000] - Training\n",
      "Epoch [517/1000] completed, Average Training Loss: 0.0862\n",
      "    Validation Batch [1/1], Loss: 0.1193\n",
      "Validation Loss: 0.1193, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [518/1000] - Training\n",
      "Epoch [518/1000] completed, Average Training Loss: 0.0652\n",
      "    Validation Batch [1/1], Loss: 0.1314\n",
      "Validation Loss: 0.1314, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [519/1000] - Training\n",
      "Epoch [519/1000] completed, Average Training Loss: 0.0722\n",
      "    Validation Batch [1/1], Loss: 0.1380\n",
      "Validation Loss: 0.1380, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [520/1000] - Training\n",
      "Epoch [520/1000] completed, Average Training Loss: 0.0761\n",
      "    Validation Batch [1/1], Loss: 0.1382\n",
      "Validation Loss: 0.1382, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [521/1000] - Training\n",
      "Epoch [521/1000] completed, Average Training Loss: 0.0726\n",
      "    Validation Batch [1/1], Loss: 0.1366\n",
      "Validation Loss: 0.1366, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [522/1000] - Training\n",
      "Epoch [522/1000] completed, Average Training Loss: 0.0681\n",
      "    Validation Batch [1/1], Loss: 0.1283\n",
      "Validation Loss: 0.1283, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [523/1000] - Training\n",
      "Epoch [523/1000] completed, Average Training Loss: 0.0690\n",
      "    Validation Batch [1/1], Loss: 0.1193\n",
      "Validation Loss: 0.1193, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [524/1000] - Training\n",
      "Epoch [524/1000] completed, Average Training Loss: 0.0638\n",
      "    Validation Batch [1/1], Loss: 0.1224\n",
      "Validation Loss: 0.1224, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [525/1000] - Training\n",
      "Epoch [525/1000] completed, Average Training Loss: 0.0687\n",
      "    Validation Batch [1/1], Loss: 0.1224\n",
      "Validation Loss: 0.1224, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [526/1000] - Training\n",
      "Epoch [526/1000] completed, Average Training Loss: 0.0710\n",
      "    Validation Batch [1/1], Loss: 0.1167\n",
      "Validation Loss: 0.1167, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [527/1000] - Training\n",
      "Epoch [527/1000] completed, Average Training Loss: 0.0707\n",
      "    Validation Batch [1/1], Loss: 0.1174\n",
      "Validation Loss: 0.1174, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [528/1000] - Training\n",
      "Epoch [528/1000] completed, Average Training Loss: 0.0707\n",
      "    Validation Batch [1/1], Loss: 0.1165\n",
      "Validation Loss: 0.1165, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [529/1000] - Training\n",
      "Epoch [529/1000] completed, Average Training Loss: 0.0782\n",
      "    Validation Batch [1/1], Loss: 0.1083\n",
      "Validation Loss: 0.1083, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [530/1000] - Training\n",
      "Epoch [530/1000] completed, Average Training Loss: 0.0762\n",
      "    Validation Batch [1/1], Loss: 0.1011\n",
      "Validation Loss: 0.1011, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1036 to 0.1011. Saving model...\n",
      "\n",
      "LOG: Epoch [531/1000] - Training\n",
      "Epoch [531/1000] completed, Average Training Loss: 0.0636\n",
      "    Validation Batch [1/1], Loss: 0.0976\n",
      "Validation Loss: 0.0976, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.1011 to 0.0976. Saving model...\n",
      "\n",
      "LOG: Epoch [532/1000] - Training\n",
      "Epoch [532/1000] completed, Average Training Loss: 0.0712\n",
      "    Validation Batch [1/1], Loss: 0.0979\n",
      "Validation Loss: 0.0979, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [533/1000] - Training\n",
      "Epoch [533/1000] completed, Average Training Loss: 0.0657\n",
      "    Validation Batch [1/1], Loss: 0.1029\n",
      "Validation Loss: 0.1029, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [534/1000] - Training\n",
      "Epoch [534/1000] completed, Average Training Loss: 0.0716\n",
      "    Validation Batch [1/1], Loss: 0.1195\n",
      "Validation Loss: 0.1195, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [535/1000] - Training\n",
      "Epoch [535/1000] completed, Average Training Loss: 0.0755\n",
      "    Validation Batch [1/1], Loss: 0.1459\n",
      "Validation Loss: 0.1459, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [536/1000] - Training\n",
      "Epoch [536/1000] completed, Average Training Loss: 0.0786\n",
      "    Validation Batch [1/1], Loss: 0.1675\n",
      "Validation Loss: 0.1675, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [537/1000] - Training\n",
      "Epoch [537/1000] completed, Average Training Loss: 0.0669\n",
      "    Validation Batch [1/1], Loss: 0.1663\n",
      "Validation Loss: 0.1663, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [538/1000] - Training\n",
      "Epoch [538/1000] completed, Average Training Loss: 0.0725\n",
      "    Validation Batch [1/1], Loss: 0.1467\n",
      "Validation Loss: 0.1467, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [539/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [539/1000] completed, Average Training Loss: 0.0750\n",
      "    Validation Batch [1/1], Loss: 0.1221\n",
      "Validation Loss: 0.1221, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [540/1000] - Training\n",
      "Epoch [540/1000] completed, Average Training Loss: 0.0716\n",
      "    Validation Batch [1/1], Loss: 0.1101\n",
      "Validation Loss: 0.1101, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [541/1000] - Training\n",
      "Epoch [541/1000] completed, Average Training Loss: 0.0688\n",
      "    Validation Batch [1/1], Loss: 0.1004\n",
      "Validation Loss: 0.1004, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [542/1000] - Training\n",
      "Epoch [542/1000] completed, Average Training Loss: 0.0675\n",
      "    Validation Batch [1/1], Loss: 0.0970\n",
      "Validation Loss: 0.0970, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0976 to 0.0970. Saving model...\n",
      "\n",
      "LOG: Epoch [543/1000] - Training\n",
      "Epoch [543/1000] completed, Average Training Loss: 0.0664\n",
      "    Validation Batch [1/1], Loss: 0.1142\n",
      "Validation Loss: 0.1142, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [544/1000] - Training\n",
      "Epoch [544/1000] completed, Average Training Loss: 0.0644\n",
      "    Validation Batch [1/1], Loss: 0.1275\n",
      "Validation Loss: 0.1275, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [545/1000] - Training\n",
      "Epoch [545/1000] completed, Average Training Loss: 0.0684\n",
      "    Validation Batch [1/1], Loss: 0.1226\n",
      "Validation Loss: 0.1226, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [546/1000] - Training\n",
      "Epoch [546/1000] completed, Average Training Loss: 0.0709\n",
      "    Validation Batch [1/1], Loss: 0.1116\n",
      "Validation Loss: 0.1116, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [547/1000] - Training\n",
      "Epoch [547/1000] completed, Average Training Loss: 0.0722\n",
      "    Validation Batch [1/1], Loss: 0.1083\n",
      "Validation Loss: 0.1083, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [548/1000] - Training\n",
      "Epoch [548/1000] completed, Average Training Loss: 0.0665\n",
      "    Validation Batch [1/1], Loss: 0.1147\n",
      "Validation Loss: 0.1147, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [549/1000] - Training\n",
      "Epoch [549/1000] completed, Average Training Loss: 0.0684\n",
      "    Validation Batch [1/1], Loss: 0.1274\n",
      "Validation Loss: 0.1274, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [550/1000] - Training\n",
      "Epoch [550/1000] completed, Average Training Loss: 0.0635\n",
      "    Validation Batch [1/1], Loss: 0.1224\n",
      "Validation Loss: 0.1224, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [551/1000] - Training\n",
      "Epoch [551/1000] completed, Average Training Loss: 0.0641\n",
      "    Validation Batch [1/1], Loss: 0.1151\n",
      "Validation Loss: 0.1151, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [552/1000] - Training\n",
      "Epoch [552/1000] completed, Average Training Loss: 0.0626\n",
      "    Validation Batch [1/1], Loss: 0.1111\n",
      "Validation Loss: 0.1111, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [553/1000] - Training\n",
      "Epoch [553/1000] completed, Average Training Loss: 0.0604\n",
      "    Validation Batch [1/1], Loss: 0.1134\n",
      "Validation Loss: 0.1134, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [554/1000] - Training\n",
      "Epoch [554/1000] completed, Average Training Loss: 0.0746\n",
      "    Validation Batch [1/1], Loss: 0.1016\n",
      "Validation Loss: 0.1016, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [555/1000] - Training\n",
      "Epoch [555/1000] completed, Average Training Loss: 0.0555\n",
      "    Validation Batch [1/1], Loss: 0.1026\n",
      "Validation Loss: 0.1026, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [556/1000] - Training\n",
      "Epoch [556/1000] completed, Average Training Loss: 0.0598\n",
      "    Validation Batch [1/1], Loss: 0.1152\n",
      "Validation Loss: 0.1152, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [557/1000] - Training\n",
      "Epoch [557/1000] completed, Average Training Loss: 0.0605\n",
      "    Validation Batch [1/1], Loss: 0.1256\n",
      "Validation Loss: 0.1256, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [558/1000] - Training\n",
      "Epoch [558/1000] completed, Average Training Loss: 0.0606\n",
      "    Validation Batch [1/1], Loss: 0.1236\n",
      "Validation Loss: 0.1236, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [559/1000] - Training\n",
      "Epoch [559/1000] completed, Average Training Loss: 0.0639\n",
      "    Validation Batch [1/1], Loss: 0.1130\n",
      "Validation Loss: 0.1130, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [560/1000] - Training\n",
      "Epoch [560/1000] completed, Average Training Loss: 0.0696\n",
      "    Validation Batch [1/1], Loss: 0.1034\n",
      "Validation Loss: 0.1034, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [561/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [561/1000] completed, Average Training Loss: 0.0621\n",
      "    Validation Batch [1/1], Loss: 0.1015\n",
      "Validation Loss: 0.1015, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [562/1000] - Training\n",
      "Epoch [562/1000] completed, Average Training Loss: 0.0659\n",
      "    Validation Batch [1/1], Loss: 0.1105\n",
      "Validation Loss: 0.1105, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [563/1000] - Training\n",
      "Epoch [563/1000] completed, Average Training Loss: 0.0627\n",
      "    Validation Batch [1/1], Loss: 0.1107\n",
      "Validation Loss: 0.1107, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [564/1000] - Training\n",
      "Epoch [564/1000] completed, Average Training Loss: 0.0666\n",
      "    Validation Batch [1/1], Loss: 0.1123\n",
      "Validation Loss: 0.1123, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [565/1000] - Training\n",
      "Epoch [565/1000] completed, Average Training Loss: 0.0603\n",
      "    Validation Batch [1/1], Loss: 0.1275\n",
      "Validation Loss: 0.1275, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [566/1000] - Training\n",
      "Epoch [566/1000] completed, Average Training Loss: 0.0581\n",
      "    Validation Batch [1/1], Loss: 0.1363\n",
      "Validation Loss: 0.1363, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [567/1000] - Training\n",
      "Epoch [567/1000] completed, Average Training Loss: 0.0658\n",
      "    Validation Batch [1/1], Loss: 0.1265\n",
      "Validation Loss: 0.1265, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [568/1000] - Training\n",
      "Epoch [568/1000] completed, Average Training Loss: 0.0586\n",
      "    Validation Batch [1/1], Loss: 0.1136\n",
      "Validation Loss: 0.1136, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [569/1000] - Training\n",
      "Epoch [569/1000] completed, Average Training Loss: 0.0601\n",
      "    Validation Batch [1/1], Loss: 0.1074\n",
      "Validation Loss: 0.1074, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [570/1000] - Training\n",
      "Epoch [570/1000] completed, Average Training Loss: 0.0625\n",
      "    Validation Batch [1/1], Loss: 0.0967\n",
      "Validation Loss: 0.0967, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0970 to 0.0967. Saving model...\n",
      "\n",
      "LOG: Epoch [571/1000] - Training\n",
      "Epoch [571/1000] completed, Average Training Loss: 0.0561\n",
      "    Validation Batch [1/1], Loss: 0.0899\n",
      "Validation Loss: 0.0899, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0967 to 0.0899. Saving model...\n",
      "\n",
      "LOG: Epoch [572/1000] - Training\n",
      "Epoch [572/1000] completed, Average Training Loss: 0.0593\n",
      "    Validation Batch [1/1], Loss: 0.0996\n",
      "Validation Loss: 0.0996, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [573/1000] - Training\n",
      "Epoch [573/1000] completed, Average Training Loss: 0.0595\n",
      "    Validation Batch [1/1], Loss: 0.1081\n",
      "Validation Loss: 0.1081, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [574/1000] - Training\n",
      "Epoch [574/1000] completed, Average Training Loss: 0.0462\n",
      "    Validation Batch [1/1], Loss: 0.1104\n",
      "Validation Loss: 0.1104, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [575/1000] - Training\n",
      "Epoch [575/1000] completed, Average Training Loss: 0.0645\n",
      "    Validation Batch [1/1], Loss: 0.1091\n",
      "Validation Loss: 0.1091, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [576/1000] - Training\n",
      "Epoch [576/1000] completed, Average Training Loss: 0.0617\n",
      "    Validation Batch [1/1], Loss: 0.1066\n",
      "Validation Loss: 0.1066, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [577/1000] - Training\n",
      "Epoch [577/1000] completed, Average Training Loss: 0.0609\n",
      "    Validation Batch [1/1], Loss: 0.1051\n",
      "Validation Loss: 0.1051, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [578/1000] - Training\n",
      "Epoch [578/1000] completed, Average Training Loss: 0.0565\n",
      "    Validation Batch [1/1], Loss: 0.0951\n",
      "Validation Loss: 0.0951, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [579/1000] - Training\n",
      "Epoch [579/1000] completed, Average Training Loss: 0.0554\n",
      "    Validation Batch [1/1], Loss: 0.0963\n",
      "Validation Loss: 0.0963, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [580/1000] - Training\n",
      "Epoch [580/1000] completed, Average Training Loss: 0.0574\n",
      "    Validation Batch [1/1], Loss: 0.0971\n",
      "Validation Loss: 0.0971, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [581/1000] - Training\n",
      "Epoch [581/1000] completed, Average Training Loss: 0.0577\n",
      "    Validation Batch [1/1], Loss: 0.0955\n",
      "Validation Loss: 0.0955, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [582/1000] - Training\n",
      "Epoch [582/1000] completed, Average Training Loss: 0.0530\n",
      "    Validation Batch [1/1], Loss: 0.0914\n",
      "Validation Loss: 0.0914, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [583/1000] - Training\n",
      "Epoch [583/1000] completed, Average Training Loss: 0.0521\n",
      "    Validation Batch [1/1], Loss: 0.0942\n",
      "Validation Loss: 0.0942, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [584/1000] - Training\n",
      "Epoch [584/1000] completed, Average Training Loss: 0.0662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1022\n",
      "Validation Loss: 0.1022, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [585/1000] - Training\n",
      "Epoch [585/1000] completed, Average Training Loss: 0.0570\n",
      "    Validation Batch [1/1], Loss: 0.1007\n",
      "Validation Loss: 0.1007, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [586/1000] - Training\n",
      "Epoch [586/1000] completed, Average Training Loss: 0.0727\n",
      "    Validation Batch [1/1], Loss: 0.0989\n",
      "Validation Loss: 0.0989, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [587/1000] - Training\n",
      "Epoch [587/1000] completed, Average Training Loss: 0.0622\n",
      "    Validation Batch [1/1], Loss: 0.1020\n",
      "Validation Loss: 0.1020, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [588/1000] - Training\n",
      "Epoch [588/1000] completed, Average Training Loss: 0.0662\n",
      "    Validation Batch [1/1], Loss: 0.1023\n",
      "Validation Loss: 0.1023, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [589/1000] - Training\n",
      "Epoch [589/1000] completed, Average Training Loss: 0.0482\n",
      "    Validation Batch [1/1], Loss: 0.0975\n",
      "Validation Loss: 0.0975, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [590/1000] - Training\n",
      "Epoch [590/1000] completed, Average Training Loss: 0.0636\n",
      "    Validation Batch [1/1], Loss: 0.0865\n",
      "Validation Loss: 0.0865, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0899 to 0.0865. Saving model...\n",
      "\n",
      "LOG: Epoch [591/1000] - Training\n",
      "Epoch [591/1000] completed, Average Training Loss: 0.0438\n",
      "    Validation Batch [1/1], Loss: 0.0835\n",
      "Validation Loss: 0.0835, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0865 to 0.0835. Saving model...\n",
      "\n",
      "LOG: Epoch [592/1000] - Training\n",
      "Epoch [592/1000] completed, Average Training Loss: 0.0646\n",
      "    Validation Batch [1/1], Loss: 0.0870\n",
      "Validation Loss: 0.0870, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [593/1000] - Training\n",
      "Epoch [593/1000] completed, Average Training Loss: 0.0555\n",
      "    Validation Batch [1/1], Loss: 0.0901\n",
      "Validation Loss: 0.0901, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [594/1000] - Training\n",
      "Epoch [594/1000] completed, Average Training Loss: 0.0601\n",
      "    Validation Batch [1/1], Loss: 0.0961\n",
      "Validation Loss: 0.0961, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [595/1000] - Training\n",
      "Epoch [595/1000] completed, Average Training Loss: 0.0639\n",
      "    Validation Batch [1/1], Loss: 0.1102\n",
      "Validation Loss: 0.1102, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [596/1000] - Training\n",
      "Epoch [596/1000] completed, Average Training Loss: 0.0620\n",
      "    Validation Batch [1/1], Loss: 0.1359\n",
      "Validation Loss: 0.1359, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [597/1000] - Training\n",
      "Epoch [597/1000] completed, Average Training Loss: 0.0567\n",
      "    Validation Batch [1/1], Loss: 0.1541\n",
      "Validation Loss: 0.1541, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [598/1000] - Training\n",
      "Epoch [598/1000] completed, Average Training Loss: 0.0438\n",
      "    Validation Batch [1/1], Loss: 0.1563\n",
      "Validation Loss: 0.1563, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [599/1000] - Training\n",
      "Epoch [599/1000] completed, Average Training Loss: 0.0539\n",
      "    Validation Batch [1/1], Loss: 0.1380\n",
      "Validation Loss: 0.1380, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [600/1000] - Training\n",
      "Epoch [600/1000] completed, Average Training Loss: 0.0465\n",
      "    Validation Batch [1/1], Loss: 0.1137\n",
      "Validation Loss: 0.1137, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [601/1000] - Training\n",
      "Epoch [601/1000] completed, Average Training Loss: 0.0576\n",
      "    Validation Batch [1/1], Loss: 0.0997\n",
      "Validation Loss: 0.0997, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [602/1000] - Training\n",
      "Epoch [602/1000] completed, Average Training Loss: 0.0667\n",
      "    Validation Batch [1/1], Loss: 0.0983\n",
      "Validation Loss: 0.0983, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [603/1000] - Training\n",
      "Epoch [603/1000] completed, Average Training Loss: 0.0573\n",
      "    Validation Batch [1/1], Loss: 0.1044\n",
      "Validation Loss: 0.1044, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [604/1000] - Training\n",
      "Epoch [604/1000] completed, Average Training Loss: 0.0405\n",
      "    Validation Batch [1/1], Loss: 0.1110\n",
      "Validation Loss: 0.1110, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [605/1000] - Training\n",
      "Epoch [605/1000] completed, Average Training Loss: 0.0473\n",
      "    Validation Batch [1/1], Loss: 0.1102\n",
      "Validation Loss: 0.1102, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [606/1000] - Training\n",
      "Epoch [606/1000] completed, Average Training Loss: 0.0473\n",
      "    Validation Batch [1/1], Loss: 0.1011\n",
      "Validation Loss: 0.1011, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [607/1000] - Training\n",
      "Epoch [607/1000] completed, Average Training Loss: 0.0465\n",
      "    Validation Batch [1/1], Loss: 0.0933\n",
      "Validation Loss: 0.0933, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [608/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [608/1000] completed, Average Training Loss: 0.0564\n",
      "    Validation Batch [1/1], Loss: 0.0876\n",
      "Validation Loss: 0.0876, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [609/1000] - Training\n",
      "Epoch [609/1000] completed, Average Training Loss: 0.0495\n",
      "    Validation Batch [1/1], Loss: 0.0864\n",
      "Validation Loss: 0.0864, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [610/1000] - Training\n",
      "Epoch [610/1000] completed, Average Training Loss: 0.0485\n",
      "    Validation Batch [1/1], Loss: 0.0857\n",
      "Validation Loss: 0.0857, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [611/1000] - Training\n",
      "Epoch [611/1000] completed, Average Training Loss: 0.0443\n",
      "    Validation Batch [1/1], Loss: 0.0856\n",
      "Validation Loss: 0.0856, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [612/1000] - Training\n",
      "Epoch [612/1000] completed, Average Training Loss: 0.0452\n",
      "    Validation Batch [1/1], Loss: 0.0894\n",
      "Validation Loss: 0.0894, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [613/1000] - Training\n",
      "Epoch [613/1000] completed, Average Training Loss: 0.0518\n",
      "    Validation Batch [1/1], Loss: 0.0969\n",
      "Validation Loss: 0.0969, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [614/1000] - Training\n",
      "Epoch [614/1000] completed, Average Training Loss: 0.0623\n",
      "    Validation Batch [1/1], Loss: 0.1143\n",
      "Validation Loss: 0.1143, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [615/1000] - Training\n",
      "Epoch [615/1000] completed, Average Training Loss: 0.0555\n",
      "    Validation Batch [1/1], Loss: 0.1285\n",
      "Validation Loss: 0.1285, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [616/1000] - Training\n",
      "Epoch [616/1000] completed, Average Training Loss: 0.0422\n",
      "    Validation Batch [1/1], Loss: 0.1310\n",
      "Validation Loss: 0.1310, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [617/1000] - Training\n",
      "Epoch [617/1000] completed, Average Training Loss: 0.0539\n",
      "    Validation Batch [1/1], Loss: 0.1315\n",
      "Validation Loss: 0.1315, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [618/1000] - Training\n",
      "Epoch [618/1000] completed, Average Training Loss: 0.0539\n",
      "    Validation Batch [1/1], Loss: 0.1158\n",
      "Validation Loss: 0.1158, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [619/1000] - Training\n",
      "Epoch [619/1000] completed, Average Training Loss: 0.0438\n",
      "    Validation Batch [1/1], Loss: 0.0946\n",
      "Validation Loss: 0.0946, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [620/1000] - Training\n",
      "Epoch [620/1000] completed, Average Training Loss: 0.0481\n",
      "    Validation Batch [1/1], Loss: 0.0825\n",
      "Validation Loss: 0.0825, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0835 to 0.0825. Saving model...\n",
      "\n",
      "LOG: Epoch [621/1000] - Training\n",
      "Epoch [621/1000] completed, Average Training Loss: 0.0564\n",
      "    Validation Batch [1/1], Loss: 0.0782\n",
      "Validation Loss: 0.0782, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0825 to 0.0782. Saving model...\n",
      "\n",
      "LOG: Epoch [622/1000] - Training\n",
      "Epoch [622/1000] completed, Average Training Loss: 0.0456\n",
      "    Validation Batch [1/1], Loss: 0.0765\n",
      "Validation Loss: 0.0765, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0782 to 0.0765. Saving model...\n",
      "\n",
      "LOG: Epoch [623/1000] - Training\n",
      "Epoch [623/1000] completed, Average Training Loss: 0.0502\n",
      "    Validation Batch [1/1], Loss: 0.0780\n",
      "Validation Loss: 0.0780, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [624/1000] - Training\n",
      "Epoch [624/1000] completed, Average Training Loss: 0.0558\n",
      "    Validation Batch [1/1], Loss: 0.0867\n",
      "Validation Loss: 0.0867, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [625/1000] - Training\n",
      "Epoch [625/1000] completed, Average Training Loss: 0.0404\n",
      "    Validation Batch [1/1], Loss: 0.0998\n",
      "Validation Loss: 0.0998, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [626/1000] - Training\n",
      "Epoch [626/1000] completed, Average Training Loss: 0.0509\n",
      "    Validation Batch [1/1], Loss: 0.1099\n",
      "Validation Loss: 0.1099, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [627/1000] - Training\n",
      "Epoch [627/1000] completed, Average Training Loss: 0.0467\n",
      "    Validation Batch [1/1], Loss: 0.1109\n",
      "Validation Loss: 0.1109, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [628/1000] - Training\n",
      "Epoch [628/1000] completed, Average Training Loss: 0.0497\n",
      "    Validation Batch [1/1], Loss: 0.0871\n",
      "Validation Loss: 0.0871, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [629/1000] - Training\n",
      "Epoch [629/1000] completed, Average Training Loss: 0.0545\n",
      "    Validation Batch [1/1], Loss: 0.0720\n",
      "Validation Loss: 0.0720, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0765 to 0.0720. Saving model...\n",
      "\n",
      "LOG: Epoch [630/1000] - Training\n",
      "Epoch [630/1000] completed, Average Training Loss: 0.0428\n",
      "    Validation Batch [1/1], Loss: 0.0787\n",
      "Validation Loss: 0.0787, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [631/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [631/1000] completed, Average Training Loss: 0.0462\n",
      "    Validation Batch [1/1], Loss: 0.1017\n",
      "Validation Loss: 0.1017, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [632/1000] - Training\n",
      "Epoch [632/1000] completed, Average Training Loss: 0.0387\n",
      "    Validation Batch [1/1], Loss: 0.1074\n",
      "Validation Loss: 0.1074, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [633/1000] - Training\n",
      "Epoch [633/1000] completed, Average Training Loss: 0.0426\n",
      "    Validation Batch [1/1], Loss: 0.1078\n",
      "Validation Loss: 0.1078, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [634/1000] - Training\n",
      "Epoch [634/1000] completed, Average Training Loss: 0.0524\n",
      "    Validation Batch [1/1], Loss: 0.1093\n",
      "Validation Loss: 0.1093, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [635/1000] - Training\n",
      "Epoch [635/1000] completed, Average Training Loss: 0.0411\n",
      "    Validation Batch [1/1], Loss: 0.1039\n",
      "Validation Loss: 0.1039, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [636/1000] - Training\n",
      "Epoch [636/1000] completed, Average Training Loss: 0.0390\n",
      "    Validation Batch [1/1], Loss: 0.0972\n",
      "Validation Loss: 0.0972, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [637/1000] - Training\n",
      "Epoch [637/1000] completed, Average Training Loss: 0.0448\n",
      "    Validation Batch [1/1], Loss: 0.0844\n",
      "Validation Loss: 0.0844, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [638/1000] - Training\n",
      "Epoch [638/1000] completed, Average Training Loss: 0.0420\n",
      "    Validation Batch [1/1], Loss: 0.0717\n",
      "Validation Loss: 0.0717, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0720 to 0.0717. Saving model...\n",
      "\n",
      "LOG: Epoch [639/1000] - Training\n",
      "Epoch [639/1000] completed, Average Training Loss: 0.0485\n",
      "    Validation Batch [1/1], Loss: 0.0706\n",
      "Validation Loss: 0.0706, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0717 to 0.0706. Saving model...\n",
      "\n",
      "LOG: Epoch [640/1000] - Training\n",
      "Epoch [640/1000] completed, Average Training Loss: 0.0427\n",
      "    Validation Batch [1/1], Loss: 0.0825\n",
      "Validation Loss: 0.0825, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [641/1000] - Training\n",
      "Epoch [641/1000] completed, Average Training Loss: 0.0503\n",
      "    Validation Batch [1/1], Loss: 0.0944\n",
      "Validation Loss: 0.0944, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [642/1000] - Training\n",
      "Epoch [642/1000] completed, Average Training Loss: 0.0421\n",
      "    Validation Batch [1/1], Loss: 0.1039\n",
      "Validation Loss: 0.1039, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [643/1000] - Training\n",
      "Epoch [643/1000] completed, Average Training Loss: 0.0491\n",
      "    Validation Batch [1/1], Loss: 0.1043\n",
      "Validation Loss: 0.1043, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [644/1000] - Training\n",
      "Epoch [644/1000] completed, Average Training Loss: 0.0386\n",
      "    Validation Batch [1/1], Loss: 0.1154\n",
      "Validation Loss: 0.1154, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [645/1000] - Training\n",
      "Epoch [645/1000] completed, Average Training Loss: 0.0441\n",
      "    Validation Batch [1/1], Loss: 0.1252\n",
      "Validation Loss: 0.1252, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [646/1000] - Training\n",
      "Epoch [646/1000] completed, Average Training Loss: 0.0411\n",
      "    Validation Batch [1/1], Loss: 0.1138\n",
      "Validation Loss: 0.1138, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [647/1000] - Training\n",
      "Epoch [647/1000] completed, Average Training Loss: 0.0427\n",
      "    Validation Batch [1/1], Loss: 0.0998\n",
      "Validation Loss: 0.0998, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [648/1000] - Training\n",
      "Epoch [648/1000] completed, Average Training Loss: 0.0431\n",
      "    Validation Batch [1/1], Loss: 0.0969\n",
      "Validation Loss: 0.0969, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [649/1000] - Training\n",
      "Epoch [649/1000] completed, Average Training Loss: 0.0486\n",
      "    Validation Batch [1/1], Loss: 0.0963\n",
      "Validation Loss: 0.0963, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [650/1000] - Training\n",
      "Epoch [650/1000] completed, Average Training Loss: 0.0427\n",
      "    Validation Batch [1/1], Loss: 0.0969\n",
      "Validation Loss: 0.0969, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [651/1000] - Training\n",
      "Epoch [651/1000] completed, Average Training Loss: 0.0426\n",
      "    Validation Batch [1/1], Loss: 0.1018\n",
      "Validation Loss: 0.1018, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [652/1000] - Training\n",
      "Epoch [652/1000] completed, Average Training Loss: 0.0351\n",
      "    Validation Batch [1/1], Loss: 0.1115\n",
      "Validation Loss: 0.1115, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [653/1000] - Training\n",
      "Epoch [653/1000] completed, Average Training Loss: 0.0418\n",
      "    Validation Batch [1/1], Loss: 0.1335\n",
      "Validation Loss: 0.1335, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [654/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [654/1000] completed, Average Training Loss: 0.0394\n",
      "    Validation Batch [1/1], Loss: 0.1648\n",
      "Validation Loss: 0.1648, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [655/1000] - Training\n",
      "Epoch [655/1000] completed, Average Training Loss: 0.0452\n",
      "    Validation Batch [1/1], Loss: 0.1809\n",
      "Validation Loss: 0.1809, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [656/1000] - Training\n",
      "Epoch [656/1000] completed, Average Training Loss: 0.0408\n",
      "    Validation Batch [1/1], Loss: 0.1782\n",
      "Validation Loss: 0.1782, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [657/1000] - Training\n",
      "Epoch [657/1000] completed, Average Training Loss: 0.0465\n",
      "    Validation Batch [1/1], Loss: 0.1562\n",
      "Validation Loss: 0.1562, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [658/1000] - Training\n",
      "Epoch [658/1000] completed, Average Training Loss: 0.0516\n",
      "    Validation Batch [1/1], Loss: 0.1262\n",
      "Validation Loss: 0.1262, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [659/1000] - Training\n",
      "Epoch [659/1000] completed, Average Training Loss: 0.0448\n",
      "    Validation Batch [1/1], Loss: 0.0880\n",
      "Validation Loss: 0.0880, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [660/1000] - Training\n",
      "Epoch [660/1000] completed, Average Training Loss: 0.0406\n",
      "    Validation Batch [1/1], Loss: 0.0692\n",
      "Validation Loss: 0.0692, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0706 to 0.0692. Saving model...\n",
      "\n",
      "LOG: Epoch [661/1000] - Training\n",
      "Epoch [661/1000] completed, Average Training Loss: 0.0424\n",
      "    Validation Batch [1/1], Loss: 0.0620\n",
      "Validation Loss: 0.0620, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0692 to 0.0620. Saving model...\n",
      "\n",
      "LOG: Epoch [662/1000] - Training\n",
      "Epoch [662/1000] completed, Average Training Loss: 0.0432\n",
      "    Validation Batch [1/1], Loss: 0.0619\n",
      "Validation Loss: 0.0619, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.0620 to 0.0619. Saving model...\n",
      "\n",
      "LOG: Epoch [663/1000] - Training\n",
      "Epoch [663/1000] completed, Average Training Loss: 0.0427\n",
      "    Validation Batch [1/1], Loss: 0.0702\n",
      "Validation Loss: 0.0702, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [664/1000] - Training\n",
      "Epoch [664/1000] completed, Average Training Loss: 0.0424\n",
      "    Validation Batch [1/1], Loss: 0.0903\n",
      "Validation Loss: 0.0903, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [665/1000] - Training\n",
      "Epoch [665/1000] completed, Average Training Loss: 0.0477\n",
      "    Validation Batch [1/1], Loss: 0.1131\n",
      "Validation Loss: 0.1131, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [666/1000] - Training\n",
      "Epoch [666/1000] completed, Average Training Loss: 0.0433\n",
      "    Validation Batch [1/1], Loss: 0.1311\n",
      "Validation Loss: 0.1311, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [667/1000] - Training\n",
      "Epoch [667/1000] completed, Average Training Loss: 0.0445\n",
      "    Validation Batch [1/1], Loss: 0.1267\n",
      "Validation Loss: 0.1267, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [668/1000] - Training\n",
      "Epoch [668/1000] completed, Average Training Loss: 0.0517\n",
      "    Validation Batch [1/1], Loss: 0.0936\n",
      "Validation Loss: 0.0936, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [669/1000] - Training\n",
      "Epoch [669/1000] completed, Average Training Loss: 0.0506\n",
      "    Validation Batch [1/1], Loss: 0.0714\n",
      "Validation Loss: 0.0714, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [670/1000] - Training\n",
      "Epoch [670/1000] completed, Average Training Loss: 0.0473\n",
      "    Validation Batch [1/1], Loss: 0.0642\n",
      "Validation Loss: 0.0642, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [671/1000] - Training\n",
      "Epoch [671/1000] completed, Average Training Loss: 0.0362\n",
      "    Validation Batch [1/1], Loss: 0.0643\n",
      "Validation Loss: 0.0643, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [672/1000] - Training\n",
      "Epoch [672/1000] completed, Average Training Loss: 0.0378\n",
      "    Validation Batch [1/1], Loss: 0.0710\n",
      "Validation Loss: 0.0710, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [673/1000] - Training\n",
      "Epoch [673/1000] completed, Average Training Loss: 0.0378\n",
      "    Validation Batch [1/1], Loss: 0.0928\n",
      "Validation Loss: 0.0928, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [674/1000] - Training\n",
      "Epoch [674/1000] completed, Average Training Loss: 0.0437\n",
      "    Validation Batch [1/1], Loss: 0.1233\n",
      "Validation Loss: 0.1233, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [675/1000] - Training\n",
      "Epoch [675/1000] completed, Average Training Loss: 0.0426\n",
      "    Validation Batch [1/1], Loss: 0.1495\n",
      "Validation Loss: 0.1495, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [676/1000] - Training\n",
      "Epoch [676/1000] completed, Average Training Loss: 0.0376\n",
      "    Validation Batch [1/1], Loss: 0.1584\n",
      "Validation Loss: 0.1584, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [677/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [677/1000] completed, Average Training Loss: 0.0455\n",
      "    Validation Batch [1/1], Loss: 0.1473\n",
      "Validation Loss: 0.1473, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [678/1000] - Training\n",
      "Epoch [678/1000] completed, Average Training Loss: 0.0448\n",
      "    Validation Batch [1/1], Loss: 0.1236\n",
      "Validation Loss: 0.1236, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [679/1000] - Training\n",
      "Epoch [679/1000] completed, Average Training Loss: 0.0435\n",
      "    Validation Batch [1/1], Loss: 0.0931\n",
      "Validation Loss: 0.0931, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [680/1000] - Training\n",
      "Epoch [680/1000] completed, Average Training Loss: 0.0359\n",
      "    Validation Batch [1/1], Loss: 0.0800\n",
      "Validation Loss: 0.0800, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [681/1000] - Training\n",
      "Epoch [681/1000] completed, Average Training Loss: 0.0398\n",
      "    Validation Batch [1/1], Loss: 0.0757\n",
      "Validation Loss: 0.0757, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [682/1000] - Training\n",
      "Epoch [682/1000] completed, Average Training Loss: 0.0375\n",
      "    Validation Batch [1/1], Loss: 0.0751\n",
      "Validation Loss: 0.0751, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [683/1000] - Training\n",
      "Epoch [683/1000] completed, Average Training Loss: 0.0414\n",
      "    Validation Batch [1/1], Loss: 0.0807\n",
      "Validation Loss: 0.0807, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [684/1000] - Training\n",
      "Epoch [684/1000] completed, Average Training Loss: 0.0372\n",
      "    Validation Batch [1/1], Loss: 0.0909\n",
      "Validation Loss: 0.0909, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [685/1000] - Training\n",
      "Epoch [685/1000] completed, Average Training Loss: 0.0357\n",
      "    Validation Batch [1/1], Loss: 0.1036\n",
      "Validation Loss: 0.1036, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [686/1000] - Training\n",
      "Epoch [686/1000] completed, Average Training Loss: 0.0333\n",
      "    Validation Batch [1/1], Loss: 0.1147\n",
      "Validation Loss: 0.1147, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [687/1000] - Training\n",
      "Epoch [687/1000] completed, Average Training Loss: 0.0392\n",
      "    Validation Batch [1/1], Loss: 0.1260\n",
      "Validation Loss: 0.1260, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [688/1000] - Training\n",
      "Epoch [688/1000] completed, Average Training Loss: 0.0325\n",
      "    Validation Batch [1/1], Loss: 0.1188\n",
      "Validation Loss: 0.1188, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [689/1000] - Training\n",
      "Epoch [689/1000] completed, Average Training Loss: 0.0461\n",
      "    Validation Batch [1/1], Loss: 0.1087\n",
      "Validation Loss: 0.1087, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [690/1000] - Training\n",
      "Epoch [690/1000] completed, Average Training Loss: 0.0408\n",
      "    Validation Batch [1/1], Loss: 0.1071\n",
      "Validation Loss: 0.1071, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [691/1000] - Training\n",
      "Epoch [691/1000] completed, Average Training Loss: 0.0390\n",
      "    Validation Batch [1/1], Loss: 0.1175\n",
      "Validation Loss: 0.1175, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [692/1000] - Training\n",
      "Epoch [692/1000] completed, Average Training Loss: 0.0364\n",
      "    Validation Batch [1/1], Loss: 0.1160\n",
      "Validation Loss: 0.1160, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [693/1000] - Training\n",
      "Epoch [693/1000] completed, Average Training Loss: 0.0344\n",
      "    Validation Batch [1/1], Loss: 0.1026\n",
      "Validation Loss: 0.1026, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [694/1000] - Training\n",
      "Epoch [694/1000] completed, Average Training Loss: 0.0396\n",
      "    Validation Batch [1/1], Loss: 0.0884\n",
      "Validation Loss: 0.0884, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [695/1000] - Training\n",
      "Epoch [695/1000] completed, Average Training Loss: 0.0383\n",
      "    Validation Batch [1/1], Loss: 0.0799\n",
      "Validation Loss: 0.0799, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [696/1000] - Training\n",
      "Epoch [696/1000] completed, Average Training Loss: 0.0521\n",
      "    Validation Batch [1/1], Loss: 0.0730\n",
      "Validation Loss: 0.0730, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [697/1000] - Training\n",
      "Epoch [697/1000] completed, Average Training Loss: 0.0371\n",
      "    Validation Batch [1/1], Loss: 0.0772\n",
      "Validation Loss: 0.0772, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [698/1000] - Training\n",
      "Epoch [698/1000] completed, Average Training Loss: 0.0321\n",
      "    Validation Batch [1/1], Loss: 0.0790\n",
      "Validation Loss: 0.0790, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [699/1000] - Training\n",
      "Epoch [699/1000] completed, Average Training Loss: 0.0348\n",
      "    Validation Batch [1/1], Loss: 0.0796\n",
      "Validation Loss: 0.0796, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [700/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [700/1000] completed, Average Training Loss: 0.0350\n",
      "    Validation Batch [1/1], Loss: 0.0962\n",
      "Validation Loss: 0.0962, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [701/1000] - Training\n",
      "Epoch [701/1000] completed, Average Training Loss: 0.0380\n",
      "    Validation Batch [1/1], Loss: 0.1248\n",
      "Validation Loss: 0.1248, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [702/1000] - Training\n",
      "Epoch [702/1000] completed, Average Training Loss: 0.0366\n",
      "    Validation Batch [1/1], Loss: 0.1413\n",
      "Validation Loss: 0.1413, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [703/1000] - Training\n",
      "Epoch [703/1000] completed, Average Training Loss: 0.0372\n",
      "    Validation Batch [1/1], Loss: 0.1303\n",
      "Validation Loss: 0.1303, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [704/1000] - Training\n",
      "Epoch [704/1000] completed, Average Training Loss: 0.0450\n",
      "    Validation Batch [1/1], Loss: 0.0954\n",
      "Validation Loss: 0.0954, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [705/1000] - Training\n",
      "Epoch [705/1000] completed, Average Training Loss: 0.0369\n",
      "    Validation Batch [1/1], Loss: 0.0833\n",
      "Validation Loss: 0.0833, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [706/1000] - Training\n",
      "Epoch [706/1000] completed, Average Training Loss: 0.0392\n",
      "    Validation Batch [1/1], Loss: 0.0839\n",
      "Validation Loss: 0.0839, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [707/1000] - Training\n",
      "Epoch [707/1000] completed, Average Training Loss: 0.0314\n",
      "    Validation Batch [1/1], Loss: 0.0824\n",
      "Validation Loss: 0.0824, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [708/1000] - Training\n",
      "Epoch [708/1000] completed, Average Training Loss: 0.0457\n",
      "    Validation Batch [1/1], Loss: 0.0755\n",
      "Validation Loss: 0.0755, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [709/1000] - Training\n",
      "Epoch [709/1000] completed, Average Training Loss: 0.0368\n",
      "    Validation Batch [1/1], Loss: 0.0643\n",
      "Validation Loss: 0.0643, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [710/1000] - Training\n",
      "Epoch [710/1000] completed, Average Training Loss: 0.0375\n",
      "    Validation Batch [1/1], Loss: 0.0645\n",
      "Validation Loss: 0.0645, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [711/1000] - Training\n",
      "Epoch [711/1000] completed, Average Training Loss: 0.0368\n",
      "    Validation Batch [1/1], Loss: 0.0700\n",
      "Validation Loss: 0.0700, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [712/1000] - Training\n",
      "Epoch [712/1000] completed, Average Training Loss: 0.0363\n",
      "    Validation Batch [1/1], Loss: 0.0792\n",
      "Validation Loss: 0.0792, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [713/1000] - Training\n",
      "Epoch [713/1000] completed, Average Training Loss: 0.0367\n",
      "    Validation Batch [1/1], Loss: 0.0807\n",
      "Validation Loss: 0.0807, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [714/1000] - Training\n",
      "Epoch [714/1000] completed, Average Training Loss: 0.0503\n",
      "    Validation Batch [1/1], Loss: 0.0787\n",
      "Validation Loss: 0.0787, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [715/1000] - Training\n",
      "Epoch [715/1000] completed, Average Training Loss: 0.0320\n",
      "    Validation Batch [1/1], Loss: 0.0755\n",
      "Validation Loss: 0.0755, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [716/1000] - Training\n",
      "Epoch [716/1000] completed, Average Training Loss: 0.0403\n",
      "    Validation Batch [1/1], Loss: 0.0767\n",
      "Validation Loss: 0.0767, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [717/1000] - Training\n",
      "Epoch [717/1000] completed, Average Training Loss: 0.0425\n",
      "    Validation Batch [1/1], Loss: 0.0803\n",
      "Validation Loss: 0.0803, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [718/1000] - Training\n",
      "Epoch [718/1000] completed, Average Training Loss: 0.0363\n",
      "    Validation Batch [1/1], Loss: 0.0897\n",
      "Validation Loss: 0.0897, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [719/1000] - Training\n",
      "Epoch [719/1000] completed, Average Training Loss: 0.0304\n",
      "    Validation Batch [1/1], Loss: 0.0952\n",
      "Validation Loss: 0.0952, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [720/1000] - Training\n",
      "Epoch [720/1000] completed, Average Training Loss: 0.0385\n",
      "    Validation Batch [1/1], Loss: 0.0889\n",
      "Validation Loss: 0.0889, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [721/1000] - Training\n",
      "Epoch [721/1000] completed, Average Training Loss: 0.0288\n",
      "    Validation Batch [1/1], Loss: 0.0838\n",
      "Validation Loss: 0.0838, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [722/1000] - Training\n",
      "Epoch [722/1000] completed, Average Training Loss: 0.0268\n",
      "    Validation Batch [1/1], Loss: 0.0795\n",
      "Validation Loss: 0.0795, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [723/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [723/1000] completed, Average Training Loss: 0.0373\n",
      "    Validation Batch [1/1], Loss: 0.0782\n",
      "Validation Loss: 0.0782, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [724/1000] - Training\n",
      "Epoch [724/1000] completed, Average Training Loss: 0.0314\n",
      "    Validation Batch [1/1], Loss: 0.0904\n",
      "Validation Loss: 0.0904, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [725/1000] - Training\n",
      "Epoch [725/1000] completed, Average Training Loss: 0.0278\n",
      "    Validation Batch [1/1], Loss: 0.1178\n",
      "Validation Loss: 0.1178, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [726/1000] - Training\n",
      "Epoch [726/1000] completed, Average Training Loss: 0.0280\n",
      "    Validation Batch [1/1], Loss: 0.1447\n",
      "Validation Loss: 0.1447, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [727/1000] - Training\n",
      "Epoch [727/1000] completed, Average Training Loss: 0.0315\n",
      "    Validation Batch [1/1], Loss: 0.1600\n",
      "Validation Loss: 0.1600, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [728/1000] - Training\n",
      "Epoch [728/1000] completed, Average Training Loss: 0.0342\n",
      "    Validation Batch [1/1], Loss: 0.1384\n",
      "Validation Loss: 0.1384, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [729/1000] - Training\n",
      "Epoch [729/1000] completed, Average Training Loss: 0.0272\n",
      "    Validation Batch [1/1], Loss: 0.1195\n",
      "Validation Loss: 0.1195, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [730/1000] - Training\n",
      "Epoch [730/1000] completed, Average Training Loss: 0.0402\n",
      "    Validation Batch [1/1], Loss: 0.0945\n",
      "Validation Loss: 0.0945, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [731/1000] - Training\n",
      "Epoch [731/1000] completed, Average Training Loss: 0.0349\n",
      "    Validation Batch [1/1], Loss: 0.0798\n",
      "Validation Loss: 0.0798, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [732/1000] - Training\n",
      "Epoch [732/1000] completed, Average Training Loss: 0.0322\n",
      "    Validation Batch [1/1], Loss: 0.0745\n",
      "Validation Loss: 0.0745, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [733/1000] - Training\n",
      "Epoch [733/1000] completed, Average Training Loss: 0.0278\n",
      "    Validation Batch [1/1], Loss: 0.0719\n",
      "Validation Loss: 0.0719, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [734/1000] - Training\n",
      "Epoch [734/1000] completed, Average Training Loss: 0.0321\n",
      "    Validation Batch [1/1], Loss: 0.0746\n",
      "Validation Loss: 0.0746, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [735/1000] - Training\n",
      "Epoch [735/1000] completed, Average Training Loss: 0.0324\n",
      "    Validation Batch [1/1], Loss: 0.0801\n",
      "Validation Loss: 0.0801, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [736/1000] - Training\n",
      "Epoch [736/1000] completed, Average Training Loss: 0.0288\n",
      "    Validation Batch [1/1], Loss: 0.0838\n",
      "Validation Loss: 0.0838, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [737/1000] - Training\n",
      "Epoch [737/1000] completed, Average Training Loss: 0.0305\n",
      "    Validation Batch [1/1], Loss: 0.0854\n",
      "Validation Loss: 0.0854, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [738/1000] - Training\n",
      "Epoch [738/1000] completed, Average Training Loss: 0.0321\n",
      "    Validation Batch [1/1], Loss: 0.0896\n",
      "Validation Loss: 0.0896, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [739/1000] - Training\n",
      "Epoch [739/1000] completed, Average Training Loss: 0.0327\n",
      "    Validation Batch [1/1], Loss: 0.1036\n",
      "Validation Loss: 0.1036, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [740/1000] - Training\n",
      "Epoch [740/1000] completed, Average Training Loss: 0.0318\n",
      "    Validation Batch [1/1], Loss: 0.1040\n",
      "Validation Loss: 0.1040, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [741/1000] - Training\n",
      "Epoch [741/1000] completed, Average Training Loss: 0.0346\n",
      "    Validation Batch [1/1], Loss: 0.0941\n",
      "Validation Loss: 0.0941, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [742/1000] - Training\n",
      "Epoch [742/1000] completed, Average Training Loss: 0.0336\n",
      "    Validation Batch [1/1], Loss: 0.0843\n",
      "Validation Loss: 0.0843, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [743/1000] - Training\n",
      "Epoch [743/1000] completed, Average Training Loss: 0.0324\n",
      "    Validation Batch [1/1], Loss: 0.0728\n",
      "Validation Loss: 0.0728, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [744/1000] - Training\n",
      "Epoch [744/1000] completed, Average Training Loss: 0.0308\n",
      "    Validation Batch [1/1], Loss: 0.0705\n",
      "Validation Loss: 0.0705, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [745/1000] - Training\n",
      "Epoch [745/1000] completed, Average Training Loss: 0.0302\n",
      "    Validation Batch [1/1], Loss: 0.0794\n",
      "Validation Loss: 0.0794, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [746/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [746/1000] completed, Average Training Loss: 0.0359\n",
      "    Validation Batch [1/1], Loss: 0.0966\n",
      "Validation Loss: 0.0966, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [747/1000] - Training\n",
      "Epoch [747/1000] completed, Average Training Loss: 0.0286\n",
      "    Validation Batch [1/1], Loss: 0.1141\n",
      "Validation Loss: 0.1141, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [748/1000] - Training\n",
      "Epoch [748/1000] completed, Average Training Loss: 0.0336\n",
      "    Validation Batch [1/1], Loss: 0.1222\n",
      "Validation Loss: 0.1222, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [749/1000] - Training\n",
      "Epoch [749/1000] completed, Average Training Loss: 0.0284\n",
      "    Validation Batch [1/1], Loss: 0.1195\n",
      "Validation Loss: 0.1195, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [750/1000] - Training\n",
      "Epoch [750/1000] completed, Average Training Loss: 0.0321\n",
      "    Validation Batch [1/1], Loss: 0.1076\n",
      "Validation Loss: 0.1076, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [751/1000] - Training\n",
      "Epoch [751/1000] completed, Average Training Loss: 0.0364\n",
      "    Validation Batch [1/1], Loss: 0.1061\n",
      "Validation Loss: 0.1061, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [752/1000] - Training\n",
      "Epoch [752/1000] completed, Average Training Loss: 0.0293\n",
      "    Validation Batch [1/1], Loss: 0.1135\n",
      "Validation Loss: 0.1135, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [753/1000] - Training\n",
      "Epoch [753/1000] completed, Average Training Loss: 0.0287\n",
      "    Validation Batch [1/1], Loss: 0.1197\n",
      "Validation Loss: 0.1197, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [754/1000] - Training\n",
      "Epoch [754/1000] completed, Average Training Loss: 0.0292\n",
      "    Validation Batch [1/1], Loss: 0.1178\n",
      "Validation Loss: 0.1178, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 92/100\n",
      "\n",
      "LOG: Epoch [755/1000] - Training\n",
      "Epoch [755/1000] completed, Average Training Loss: 0.0331\n",
      "    Validation Batch [1/1], Loss: 0.1083\n",
      "Validation Loss: 0.1083, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 93/100\n",
      "\n",
      "LOG: Epoch [756/1000] - Training\n",
      "Epoch [756/1000] completed, Average Training Loss: 0.0313\n",
      "    Validation Batch [1/1], Loss: 0.1102\n",
      "Validation Loss: 0.1102, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 94/100\n",
      "\n",
      "LOG: Epoch [757/1000] - Training\n",
      "Epoch [757/1000] completed, Average Training Loss: 0.0336\n",
      "    Validation Batch [1/1], Loss: 0.1136\n",
      "Validation Loss: 0.1136, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 95/100\n",
      "\n",
      "LOG: Epoch [758/1000] - Training\n",
      "Epoch [758/1000] completed, Average Training Loss: 0.0294\n",
      "    Validation Batch [1/1], Loss: 0.1136\n",
      "Validation Loss: 0.1136, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 96/100\n",
      "\n",
      "LOG: Epoch [759/1000] - Training\n",
      "Epoch [759/1000] completed, Average Training Loss: 0.0374\n",
      "    Validation Batch [1/1], Loss: 0.1060\n",
      "Validation Loss: 0.1060, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 97/100\n",
      "\n",
      "LOG: Epoch [760/1000] - Training\n",
      "Epoch [760/1000] completed, Average Training Loss: 0.0306\n",
      "    Validation Batch [1/1], Loss: 0.0937\n",
      "Validation Loss: 0.0937, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 98/100\n",
      "\n",
      "LOG: Epoch [761/1000] - Training\n",
      "Epoch [761/1000] completed, Average Training Loss: 0.0335\n",
      "    Validation Batch [1/1], Loss: 0.0729\n",
      "Validation Loss: 0.0729, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 99/100\n",
      "\n",
      "LOG: Epoch [762/1000] - Training\n",
      "Epoch [762/1000] completed, Average Training Loss: 0.0321\n",
      "    Validation Batch [1/1], Loss: 0.0622\n",
      "Validation Loss: 0.0622, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 100/100\n",
      "Early stopping triggered at epoch 762. No improvement for 100 epochs.\n",
      "Loading the best model weights...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on the test set...\n",
      "    Test Batch [1/12], Loss: 0.0209\n",
      "\n",
      "Final Test Loss: 0.1051, Test Accuracy: 97.03%\n",
      "Saved E2E CNN predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "#init the model, CrossEntropy loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#getting unique labels from entire dataset (train, validation, test)\n",
    "all_labels = []\n",
    "for loader in [train_loader, val_loader, test_loader]:\n",
    "    for _, labels in loader:\n",
    "        all_labels.extend(labels.tolist())\n",
    "all_labels = np.unique(all_labels)\n",
    "\n",
    "# init model with correct number of classes\n",
    "num_classes = len(all_labels)\n",
    "model = hyperspectralCNN(input_channels=window_num_channels, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#lists to store losses and accuracies\n",
    "classification_epoch_losses = []\n",
    "validation_epoch_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 100\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "best_model_weights = None\n",
    "\n",
    "#training loop + validation with early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    # TRAINING\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs}] - Training\")\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2) \n",
    "        target = target.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        # backward pass + optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accum loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"    Training Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store average training loss per epoch\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    classification_epoch_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] completed, Average Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "            target = target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # accu calculation\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Validation Batch [{batch_idx + 1}/{len(val_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store validation metrics\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    validation_epoch_losses.append(avg_val_loss)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss <= best_val_loss:\n",
    "        print(f\"Validation loss improved from {best_val_loss:.4f} to {avg_val_loss:.4f}. Saving model...\")\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        best_model_weights = model.state_dict()\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {epochs_without_improvement}/{patience}\")\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "# loading the best model weights\n",
    "if best_model_weights is not None:\n",
    "    print(\"Loading the best model weights...\")\n",
    "    model.load_state_dict(best_model_weights)\n",
    "\n",
    "completed_epochs = len(classification_epoch_losses)\n",
    "\n",
    "# plot for loss and accuracy trends over epochs\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), classification_epoch_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, completed_epochs + 1), validation_epoch_losses, label=\"Validation Loss\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), val_accuracies, label=\"Validation Accuracy\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Validation Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#test Set Evaluation\n",
    "print(\"\\nEvaluating on the test set...\")\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "e2ecnn_test_predictions = []\n",
    "e2ecnn_test_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "        target = target.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        #accuracy calc\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "        e2ecnn_test_predictions.extend(predicted.cpu().numpy())\n",
    "        e2ecnn_test_true_labels.extend(target.cpu().numpy())\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 1000 == 0:\n",
    "            print(f\"    Test Batch [{batch_idx + 1}/{len(test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "#calc + print test metrics\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"\\nFinal Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Convert to numpy arrays and save\n",
    "e2e_test_predictions = np.array(e2ecnn_test_predictions)\n",
    "e2e_test_true_labels = np.array(e2ecnn_test_true_labels)\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_predictions.npy'), e2e_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_true_labels.npy'), e2e_test_true_labels)\n",
    "print(f\"Saved E2E CNN predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:50.173037Z",
     "iopub.status.busy": "2025-05-08T19:17:50.173037Z",
     "iopub.status.idle": "2025-05-08T19:17:50.257253Z",
     "shell.execute_reply": "2025-05-08T19:17:50.257253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'e2ecnn_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'e2ecnn_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/12 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'e2ecnn_representations\\test'.\n",
      "E2E CNN representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the cnn representations\n",
    "e2ecnn_rep_dir = \"e2ecnn_representations\"\n",
    "os.makedirs(e2ecnn_rep_dir, exist_ok=True)\n",
    "\n",
    "e2ecnn_loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for e2ecnn_split_name, e2ecnn_loader in e2ecnn_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {e2ecnn_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        e2ecnn_split_dir = os.path.join(e2ecnn_rep_dir, e2ecnn_split_name)\n",
    "        os.makedirs(e2ecnn_split_dir, exist_ok=True)\n",
    "\n",
    "        # processing the data batch-wise\n",
    "        for e2ecnn_batch_idx, (e2ecnn_vectors, e2ecnn_labels) in enumerate(e2ecnn_loader):\n",
    "            e2ecnn_vectors = e2ecnn_vectors.permute(0, 3, 1, 2) \n",
    "            e2ecnn_vectors = e2ecnn_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            e2ecnn_projections = model(e2ecnn_vectors)\n",
    "\n",
    "            # converting projections and labels to np arrays\n",
    "            e2ecnn_projections_np = e2ecnn_projections.cpu().numpy()\n",
    "            e2ecnn_labels_np = e2ecnn_labels.cpu().numpy()\n",
    "\n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_encoded_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_projections_np)\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_labels_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_labels_np)\n",
    "\n",
    "            if (e2ecnn_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {e2ecnn_batch_idx + 1}/{len(e2ecnn_loader)} for {e2ecnn_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {e2ecnn_split_name} dataset. Representations saved in '{e2ecnn_split_dir}'.\")\n",
    "\n",
    "print(\"E2E CNN representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:50.260371Z",
     "iopub.status.busy": "2025-05-08T19:17:50.260371Z",
     "iopub.status.idle": "2025-05-08T19:17:50.264948Z",
     "shell.execute_reply": "2025-05-08T19:17:50.264948Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_cnn_reps_and_labels(split_dir):\n",
    "    #gather all the cnn_encoded_batch npy files in sorted order\n",
    "    cnn_rep_files = sorted(glob.glob(os.path.join(split_dir, \"cnn_encoded_batch_*.npy\")))\n",
    "\n",
    "    cnn_all_reps = []\n",
    "    cnn_all_labels = []\n",
    "\n",
    "    for cnn_rep_file in cnn_rep_files:\n",
    "        #deriving label filenames\n",
    "        cnn_label_file = cnn_rep_file.replace(\"cnn_encoded_batch_\", \"cnn_labels_batch_\")\n",
    "\n",
    "        cnn_reps = np.load(cnn_rep_file)\n",
    "        cnn_labels = np.load(cnn_label_file)\n",
    "\n",
    "        cnn_all_reps.append(cnn_reps)\n",
    "        cnn_all_labels.append(cnn_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    cnn_all_reps = np.concatenate(cnn_all_reps, axis = 0)\n",
    "    cnn_all_labels = np.concatenate(cnn_all_labels, axis = 0)\n",
    "\n",
    "    return cnn_all_reps, cnn_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:50.267953Z",
     "iopub.status.busy": "2025-05-08T19:17:50.266954Z",
     "iopub.status.idle": "2025-05-08T19:17:50.408166Z",
     "shell.execute_reply": "2025-05-08T19:17:50.408166Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_train_dir = os.path.join(\"e2ecnn_representations\", \"train\")\n",
    "cnn_val_dir   = os.path.join(\"e2ecnn_representations\", \"val\")\n",
    "cnn_test_dir  = os.path.join(\"e2ecnn_representations\", \"test\")\n",
    "\n",
    "cnn_train_reps, cnn_train_labels = load_cnn_reps_and_labels(cnn_train_dir)\n",
    "cnn_val_reps, cnn_val_labels = load_cnn_reps_and_labels(cnn_val_dir)\n",
    "cnn_test_reps, cnn_test_labels = load_cnn_reps_and_labels(cnn_test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:50.411172Z",
     "iopub.status.busy": "2025-05-08T19:17:50.410170Z",
     "iopub.status.idle": "2025-05-08T19:17:50.415143Z",
     "shell.execute_reply": "2025-05-08T19:17:50.415143Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_encoded_data(encoded_dir):\n",
    "    print(f\"LOG: Loading encoded data (representations) from {encoded_dir}...\")\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    #iter through batches\n",
    "    for filename in sorted(os.listdir(encoded_dir)):\n",
    "        if filename.startswith('encoded_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load the features\n",
    "            features = np.load(os.path.join(encoded_dir, filename))\n",
    "            features_flat = features.reshape(features.shape[0], -1) #flatten features for LRM\n",
    "            features_list.append(features_flat)\n",
    "        \n",
    "        elif filename.startswith('labels_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load labels\n",
    "            labels = np.load(os.path.join(encoded_dir, filename))\n",
    "            labels_list.append(labels)\n",
    "\n",
    "    #concat all batches into a single array\n",
    "    encoded_features = np.vstack(features_list)\n",
    "    encoded_labels = np.hstack(labels_list)\n",
    "\n",
    "    print(f\"LOG: Loaded {encoded_features.shape[0]} samples with {encoded_features.shape[1]} features each\")\n",
    "    print(f\"LOG: Labels shape: {encoded_labels.shape}\")\n",
    "\n",
    "    return encoded_features, encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:50.418149Z",
     "iopub.status.busy": "2025-05-08T19:17:50.417151Z",
     "iopub.status.idle": "2025-05-08T19:17:50.599800Z",
     "shell.execute_reply": "2025-05-08T19:17:50.599800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 280 samples with 64 features each\n",
      "LOG: Labels shape: (280,)\n",
      "\n",
      "Loading validation data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "\n",
      "Loading test data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2898 samples with 64 features each\n",
      "LOG: Labels shape: (2898,)\n",
      "\n",
      "LOG: Training features shape: (280, 64), Training labels shape: (280,)\n",
      "LOG: Validation features shape: (70, 64), Validation labels shape: (70,)\n",
      "LOG: Test features shape: (2898, 64), Test labels shape: (2898,)\n",
      "\n",
      "LOG: Training Logistic Regression model...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 80.00%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       0.83      1.00      0.91         5\n",
      "           2       0.80      0.80      0.80         5\n",
      "           3       1.00      0.80      0.89         5\n",
      "           4       1.00      0.40      0.57         5\n",
      "           5       0.20      0.20      0.20         5\n",
      "           6       0.83      1.00      0.91         5\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       0.43      0.60      0.50         5\n",
      "           9       0.67      0.80      0.73         5\n",
      "          10       0.83      1.00      0.91         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      0.60      0.75         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.80        70\n",
      "   macro avg       0.83      0.80      0.80        70\n",
      "weighted avg       0.83      0.80      0.80        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 77.29%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       245\n",
      "           1       0.43      1.00      0.60        76\n",
      "           2       0.85      0.82      0.83       226\n",
      "           3       0.76      0.99      0.86       190\n",
      "           4       0.93      0.41      0.57       244\n",
      "           5       0.50      0.29      0.37       244\n",
      "           6       0.82      0.91      0.86       234\n",
      "           7       0.88      0.76      0.82       178\n",
      "           8       0.64      0.63      0.63       289\n",
      "           9       0.68      0.89      0.77       223\n",
      "          10       0.87      0.92      0.89       280\n",
      "          11       0.84      0.99      0.91       156\n",
      "          12       0.79      0.70      0.74       243\n",
      "          13       0.89      0.91      0.90        70\n",
      "\n",
      "    accuracy                           0.77      2898\n",
      "   macro avg       0.78      0.80      0.77      2898\n",
      "weighted avg       0.78      0.77      0.76      2898\n",
      "\n",
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "lrm_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "lrm_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "lrm_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "print(\"\\nLoading training data for LRM...\")\n",
    "lrm_train_features, lrm_train_labels = load_encoded_data(lrm_encoded_train_dir)\n",
    "\n",
    "print(\"\\nLoading validation data for LRM...\")\n",
    "lrm_val_features, lrm_val_labels = load_encoded_data(lrm_encoded_val_dir)\n",
    "\n",
    "print(\"\\nLoading test data for LRM...\")\n",
    "lrm_test_features, lrm_test_labels = load_encoded_data(lrm_encoded_test_dir)\n",
    "\n",
    "#verify shapes\n",
    "print(f\"\\nLOG: Training features shape: {lrm_train_features.shape}, Training labels shape: {lrm_train_labels.shape}\")\n",
    "print(f\"LOG: Validation features shape: {lrm_val_features.shape}, Validation labels shape: {lrm_val_labels.shape}\")\n",
    "print(f\"LOG: Test features shape: {lrm_test_features.shape}, Test labels shape: {lrm_test_labels.shape}\")\n",
    "\n",
    "print(\"\\nLOG: Training Logistic Regression model...\")\n",
    "logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight = 'balanced')\n",
    "logistic_clf.fit(lrm_train_features, lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "#eval on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "lrm_val_predictions = logistic_clf.predict(lrm_val_features)\n",
    "lrm_val_accuracy = accuracy_score(lrm_val_labels, lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(lrm_val_labels, lrm_val_predictions))\n",
    "\n",
    "#eval on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "lrm_test_predictions = logistic_clf.predict(lrm_test_features)\n",
    "lrm_test_accuracy = accuracy_score(lrm_test_labels, lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(lrm_test_labels, lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_predictions.npy'), lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_true_labels.npy'), lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying CAE Embeddings with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:50.603315Z",
     "iopub.status.busy": "2025-05-08T19:17:50.603315Z",
     "iopub.status.idle": "2025-05-08T19:17:50.607321Z",
     "shell.execute_reply": "2025-05-08T19:17:50.607321Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:50.609326Z",
     "iopub.status.busy": "2025-05-08T19:17:50.609326Z",
     "iopub.status.idle": "2025-05-08T19:17:50.618845Z",
     "shell.execute_reply": "2025-05-08T19:17:50.618845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 280 samples with 64 features each\n",
      "LOG: Labels shape: (280,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2898 samples with 64 features each\n",
      "LOG: Labels shape: (2898,)\n",
      "Train reps shape: (280, 64)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 64)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 64)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "cae_mlp_train_dir = os.path.join(\"encoded_representations\", \"train\")\n",
    "cae_mlp_val_dir   = os.path.join(\"encoded_representations\", \"val\")\n",
    "cae_mlp_test_dir  = os.path.join(\"encoded_representations\", \"test\")\n",
    "\n",
    "cae_mlp_train_reps, cae_mlp_train_labels = load_encoded_data(cae_mlp_train_dir)\n",
    "cae_mlp_val_reps, cae_mlp_val_labels = load_encoded_data(cae_mlp_val_dir)\n",
    "cae_mlp_test_reps, cae_mlp_test_labels = load_encoded_data(cae_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",cae_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", cae_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", cae_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", cae_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", cae_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", cae_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:50.620860Z",
     "iopub.status.busy": "2025-05-08T19:17:50.620860Z",
     "iopub.status.idle": "2025-05-08T19:17:50.625790Z",
     "shell.execute_reply": "2025-05-08T19:17:50.625790Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "cae_mlp_train_embeddings_torch = torch.tensor(cae_mlp_train_reps, dtype=torch.float32)\n",
    "cae_mlp_train_labels_torch = torch.tensor(cae_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_val_embeddings_torch = torch.tensor(cae_mlp_val_reps, dtype=torch.float32)\n",
    "cae_mlp_val_labels_torch = torch.tensor(cae_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_test_embeddings_torch = torch.tensor(cae_mlp_test_reps, dtype=torch.float32)\n",
    "cae_mlp_test_labels_torch = torch.tensor(cae_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "cae_mlp_train_dataset = TensorDataset(cae_mlp_train_embeddings_torch, cae_mlp_train_labels_torch)\n",
    "cae_mlp_val_dataset = TensorDataset(cae_mlp_val_embeddings_torch, cae_mlp_val_labels_torch)\n",
    "cae_mlp_test_dataset = TensorDataset(cae_mlp_test_embeddings_torch, cae_mlp_test_labels_torch)\n",
    "\n",
    "cae_mlp_batch_size = 64\n",
    "cae_mlp_train_loader = DataLoader(cae_mlp_train_dataset, batch_size=cae_mlp_batch_size, shuffle=True)\n",
    "cae_mlp_val_loader = DataLoader(cae_mlp_val_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n",
    "cae_mlp_test_loader = DataLoader(cae_mlp_test_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:50.628795Z",
     "iopub.status.busy": "2025-05-08T19:17:50.628795Z",
     "iopub.status.idle": "2025-05-08T19:18:02.219851Z",
     "shell.execute_reply": "2025-05-08T19:18:02.219179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.7112  |  Val Loss: 2.6455\n",
      "Validation loss improved from inf to 2.6455.\n",
      "[Epoch 2/1000] Train Loss: 2.6415  |  Val Loss: 2.6244\n",
      "Validation loss improved from 2.6455 to 2.6244.\n",
      "[Epoch 3/1000] Train Loss: 2.6220  |  Val Loss: 2.6109\n",
      "Validation loss improved from 2.6244 to 2.6109.\n",
      "[Epoch 4/1000] Train Loss: 2.6101  |  Val Loss: 2.6004\n",
      "Validation loss improved from 2.6109 to 2.6004.\n",
      "[Epoch 5/1000] Train Loss: 2.5981  |  Val Loss: 2.5918\n",
      "Validation loss improved from 2.6004 to 2.5918.\n",
      "[Epoch 6/1000] Train Loss: 2.5906  |  Val Loss: 2.5827\n",
      "Validation loss improved from 2.5918 to 2.5827.\n",
      "[Epoch 7/1000] Train Loss: 2.5830  |  Val Loss: 2.5729\n",
      "Validation loss improved from 2.5827 to 2.5729.\n",
      "[Epoch 8/1000] Train Loss: 2.5689  |  Val Loss: 2.5641\n",
      "Validation loss improved from 2.5729 to 2.5641.\n",
      "[Epoch 9/1000] Train Loss: 2.5602  |  Val Loss: 2.5506\n",
      "Validation loss improved from 2.5641 to 2.5506.\n",
      "[Epoch 10/1000] Train Loss: 2.5475  |  Val Loss: 2.5359\n",
      "Validation loss improved from 2.5506 to 2.5359.\n",
      "[Epoch 11/1000] Train Loss: 2.5332  |  Val Loss: 2.5213\n",
      "Validation loss improved from 2.5359 to 2.5213.\n",
      "[Epoch 12/1000] Train Loss: 2.5190  |  Val Loss: 2.5049\n",
      "Validation loss improved from 2.5213 to 2.5049.\n",
      "[Epoch 13/1000] Train Loss: 2.4991  |  Val Loss: 2.4907\n",
      "Validation loss improved from 2.5049 to 2.4907.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/1000] Train Loss: 2.4841  |  Val Loss: 2.4683\n",
      "Validation loss improved from 2.4907 to 2.4683.\n",
      "[Epoch 15/1000] Train Loss: 2.4606  |  Val Loss: 2.4457\n",
      "Validation loss improved from 2.4683 to 2.4457.\n",
      "[Epoch 16/1000] Train Loss: 2.4348  |  Val Loss: 2.4235\n",
      "Validation loss improved from 2.4457 to 2.4235.\n",
      "[Epoch 17/1000] Train Loss: 2.4178  |  Val Loss: 2.4010\n",
      "Validation loss improved from 2.4235 to 2.4010.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/1000] Train Loss: 2.3878  |  Val Loss: 2.3745\n",
      "Validation loss improved from 2.4010 to 2.3745.\n",
      "[Epoch 19/1000] Train Loss: 2.3637  |  Val Loss: 2.3665\n",
      "Validation loss improved from 2.3745 to 2.3665.\n",
      "[Epoch 20/1000] Train Loss: 2.3522  |  Val Loss: 2.3414\n",
      "Validation loss improved from 2.3665 to 2.3414.\n",
      "[Epoch 21/1000] Train Loss: 2.3237  |  Val Loss: 2.2962\n",
      "Validation loss improved from 2.3414 to 2.2962.\n",
      "[Epoch 22/1000] Train Loss: 2.2923  |  Val Loss: 2.2752\n",
      "Validation loss improved from 2.2962 to 2.2752.\n",
      "[Epoch 23/1000] Train Loss: 2.2713  |  Val Loss: 2.2626\n",
      "Validation loss improved from 2.2752 to 2.2626.\n",
      "[Epoch 24/1000] Train Loss: 2.2493  |  Val Loss: 2.2518\n",
      "Validation loss improved from 2.2626 to 2.2518.\n",
      "[Epoch 25/1000] Train Loss: 2.2349  |  Val Loss: 2.2007\n",
      "Validation loss improved from 2.2518 to 2.2007.\n",
      "[Epoch 26/1000] Train Loss: 2.1785  |  Val Loss: 2.1656\n",
      "Validation loss improved from 2.2007 to 2.1656.\n",
      "[Epoch 27/1000] Train Loss: 2.1520  |  Val Loss: 2.1317\n",
      "Validation loss improved from 2.1656 to 2.1317.\n",
      "[Epoch 28/1000] Train Loss: 2.1211  |  Val Loss: 2.1019\n",
      "Validation loss improved from 2.1317 to 2.1019.\n",
      "[Epoch 29/1000] Train Loss: 2.0830  |  Val Loss: 2.0662\n",
      "Validation loss improved from 2.1019 to 2.0662.\n",
      "[Epoch 30/1000] Train Loss: 2.0490  |  Val Loss: 2.0333\n",
      "Validation loss improved from 2.0662 to 2.0333.\n",
      "[Epoch 31/1000] Train Loss: 2.0134  |  Val Loss: 2.0143\n",
      "Validation loss improved from 2.0333 to 2.0143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32/1000] Train Loss: 1.9919  |  Val Loss: 1.9597\n",
      "Validation loss improved from 2.0143 to 1.9597.\n",
      "[Epoch 33/1000] Train Loss: 1.9533  |  Val Loss: 1.9426\n",
      "Validation loss improved from 1.9597 to 1.9426.\n",
      "[Epoch 34/1000] Train Loss: 1.9194  |  Val Loss: 1.9448\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 35/1000] Train Loss: 1.9010  |  Val Loss: 1.8699\n",
      "Validation loss improved from 1.9426 to 1.8699.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36/1000] Train Loss: 1.8636  |  Val Loss: 1.8276\n",
      "Validation loss improved from 1.8699 to 1.8276.\n",
      "[Epoch 37/1000] Train Loss: 1.8191  |  Val Loss: 1.8018\n",
      "Validation loss improved from 1.8276 to 1.8018.\n",
      "[Epoch 38/1000] Train Loss: 1.7944  |  Val Loss: 1.7819\n",
      "Validation loss improved from 1.8018 to 1.7819.\n",
      "[Epoch 39/1000] Train Loss: 1.7665  |  Val Loss: 1.7479\n",
      "Validation loss improved from 1.7819 to 1.7479.\n",
      "[Epoch 40/1000] Train Loss: 1.7374  |  Val Loss: 1.7306\n",
      "Validation loss improved from 1.7479 to 1.7306.\n",
      "[Epoch 41/1000] Train Loss: 1.7097  |  Val Loss: 1.7010\n",
      "Validation loss improved from 1.7306 to 1.7010.\n",
      "[Epoch 42/1000] Train Loss: 1.6869  |  Val Loss: 1.6776\n",
      "Validation loss improved from 1.7010 to 1.6776.\n",
      "[Epoch 43/1000] Train Loss: 1.6614  |  Val Loss: 1.6557\n",
      "Validation loss improved from 1.6776 to 1.6557.\n",
      "[Epoch 44/1000] Train Loss: 1.6403  |  Val Loss: 1.6316\n",
      "Validation loss improved from 1.6557 to 1.6316.\n",
      "[Epoch 45/1000] Train Loss: 1.6156  |  Val Loss: 1.6130\n",
      "Validation loss improved from 1.6316 to 1.6130.\n",
      "[Epoch 46/1000] Train Loss: 1.6031  |  Val Loss: 1.5895\n",
      "Validation loss improved from 1.6130 to 1.5895.\n",
      "[Epoch 47/1000] Train Loss: 1.5757  |  Val Loss: 1.5755\n",
      "Validation loss improved from 1.5895 to 1.5755.\n",
      "[Epoch 48/1000] Train Loss: 1.5718  |  Val Loss: 1.5593\n",
      "Validation loss improved from 1.5755 to 1.5593.\n",
      "[Epoch 49/1000] Train Loss: 1.5473  |  Val Loss: 1.5713\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 50/1000] Train Loss: 1.5446  |  Val Loss: 1.5314\n",
      "Validation loss improved from 1.5593 to 1.5314.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 51/1000] Train Loss: 1.5177  |  Val Loss: 1.5272\n",
      "Validation loss improved from 1.5314 to 1.5272.\n",
      "[Epoch 52/1000] Train Loss: 1.5089  |  Val Loss: 1.5291\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 53/1000] Train Loss: 1.5022  |  Val Loss: 1.4930\n",
      "Validation loss improved from 1.5272 to 1.4930.\n",
      "[Epoch 54/1000] Train Loss: 1.5015  |  Val Loss: 1.5468\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 55/1000] Train Loss: 1.5142  |  Val Loss: 1.4839\n",
      "Validation loss improved from 1.4930 to 1.4839.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 56/1000] Train Loss: 1.4675  |  Val Loss: 1.5128\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 57/1000] Train Loss: 1.4800  |  Val Loss: 1.5337\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 58/1000] Train Loss: 1.5025  |  Val Loss: 1.4452\n",
      "Validation loss improved from 1.4839 to 1.4452.\n",
      "[Epoch 59/1000] Train Loss: 1.4573  |  Val Loss: 1.4913\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 60/1000] Train Loss: 1.4593  |  Val Loss: 1.4441\n",
      "Validation loss improved from 1.4452 to 1.4441.\n",
      "[Epoch 61/1000] Train Loss: 1.4289  |  Val Loss: 1.4290\n",
      "Validation loss improved from 1.4441 to 1.4290.\n",
      "[Epoch 62/1000] Train Loss: 1.3986  |  Val Loss: 1.4097\n",
      "Validation loss improved from 1.4290 to 1.4097.\n",
      "[Epoch 63/1000] Train Loss: 1.3891  |  Val Loss: 1.4146\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 64/1000] Train Loss: 1.3985  |  Val Loss: 1.4080\n",
      "Validation loss improved from 1.4097 to 1.4080.\n",
      "[Epoch 65/1000] Train Loss: 1.3769  |  Val Loss: 1.3958\n",
      "Validation loss improved from 1.4080 to 1.3958.\n",
      "[Epoch 66/1000] Train Loss: 1.3660  |  Val Loss: 1.3923\n",
      "Validation loss improved from 1.3958 to 1.3923.\n",
      "[Epoch 67/1000] Train Loss: 1.3630  |  Val Loss: 1.3946\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 68/1000] Train Loss: 1.3626  |  Val Loss: 1.3762\n",
      "Validation loss improved from 1.3923 to 1.3762.\n",
      "[Epoch 69/1000] Train Loss: 1.3448  |  Val Loss: 1.3757\n",
      "Validation loss improved from 1.3762 to 1.3757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 70/1000] Train Loss: 1.3423  |  Val Loss: 1.3669\n",
      "Validation loss improved from 1.3757 to 1.3669.\n",
      "[Epoch 71/1000] Train Loss: 1.3432  |  Val Loss: 1.3658\n",
      "Validation loss improved from 1.3669 to 1.3658.\n",
      "[Epoch 72/1000] Train Loss: 1.3368  |  Val Loss: 1.3564\n",
      "Validation loss improved from 1.3658 to 1.3564.\n",
      "[Epoch 73/1000] Train Loss: 1.3244  |  Val Loss: 1.3500\n",
      "Validation loss improved from 1.3564 to 1.3500.\n",
      "[Epoch 74/1000] Train Loss: 1.3150  |  Val Loss: 1.3478\n",
      "Validation loss improved from 1.3500 to 1.3478.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 75/1000] Train Loss: 1.3078  |  Val Loss: 1.3663\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 76/1000] Train Loss: 1.3219  |  Val Loss: 1.3452\n",
      "Validation loss improved from 1.3478 to 1.3452.\n",
      "[Epoch 77/1000] Train Loss: 1.3246  |  Val Loss: 1.4060\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 78/1000] Train Loss: 1.3518  |  Val Loss: 1.3472\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 79/1000] Train Loss: 1.2966  |  Val Loss: 1.3243\n",
      "Validation loss improved from 1.3452 to 1.3243.\n",
      "[Epoch 80/1000] Train Loss: 1.3036  |  Val Loss: 1.3177\n",
      "Validation loss improved from 1.3243 to 1.3177.\n",
      "[Epoch 81/1000] Train Loss: 1.3035  |  Val Loss: 1.3442\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 82/1000] Train Loss: 1.2937  |  Val Loss: 1.3187\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 83/1000] Train Loss: 1.2983  |  Val Loss: 1.3097\n",
      "Validation loss improved from 1.3177 to 1.3097.\n",
      "[Epoch 84/1000] Train Loss: 1.2688  |  Val Loss: 1.3050\n",
      "Validation loss improved from 1.3097 to 1.3050.\n",
      "[Epoch 85/1000] Train Loss: 1.2669  |  Val Loss: 1.3067\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 86/1000] Train Loss: 1.2630  |  Val Loss: 1.3012\n",
      "Validation loss improved from 1.3050 to 1.3012.\n",
      "[Epoch 87/1000] Train Loss: 1.2562  |  Val Loss: 1.2950\n",
      "Validation loss improved from 1.3012 to 1.2950.\n",
      "[Epoch 88/1000] Train Loss: 1.2546  |  Val Loss: 1.3048\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 89/1000] Train Loss: 1.2749  |  Val Loss: 1.2873\n",
      "Validation loss improved from 1.2950 to 1.2873.\n",
      "[Epoch 90/1000] Train Loss: 1.2477  |  Val Loss: 1.3172\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 91/1000] Train Loss: 1.2529  |  Val Loss: 1.2865\n",
      "Validation loss improved from 1.2873 to 1.2865.\n",
      "[Epoch 92/1000] Train Loss: 1.2530  |  Val Loss: 1.2788\n",
      "Validation loss improved from 1.2865 to 1.2788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 93/1000] Train Loss: 1.2581  |  Val Loss: 1.2833\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 94/1000] Train Loss: 1.2452  |  Val Loss: 1.2788\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 95/1000] Train Loss: 1.2411  |  Val Loss: 1.2771\n",
      "Validation loss improved from 1.2788 to 1.2771.\n",
      "[Epoch 96/1000] Train Loss: 1.2320  |  Val Loss: 1.2702\n",
      "Validation loss improved from 1.2771 to 1.2702.\n",
      "[Epoch 97/1000] Train Loss: 1.2418  |  Val Loss: 1.2753\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 98/1000] Train Loss: 1.2282  |  Val Loss: 1.2983\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 99/1000] Train Loss: 1.2507  |  Val Loss: 1.2703\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 100/1000] Train Loss: 1.2286  |  Val Loss: 1.3808\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 101/1000] Train Loss: 1.2905  |  Val Loss: 1.2567\n",
      "Validation loss improved from 1.2702 to 1.2567.\n",
      "[Epoch 102/1000] Train Loss: 1.2406  |  Val Loss: 1.2549\n",
      "Validation loss improved from 1.2567 to 1.2549.\n",
      "[Epoch 103/1000] Train Loss: 1.2091  |  Val Loss: 1.2593\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 104/1000] Train Loss: 1.2106  |  Val Loss: 1.2731\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 105/1000] Train Loss: 1.2160  |  Val Loss: 1.2641\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 106/1000] Train Loss: 1.2025  |  Val Loss: 1.2481\n",
      "Validation loss improved from 1.2549 to 1.2481.\n",
      "[Epoch 107/1000] Train Loss: 1.2115  |  Val Loss: 1.2437\n",
      "Validation loss improved from 1.2481 to 1.2437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 108/1000] Train Loss: 1.1958  |  Val Loss: 1.2737\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 109/1000] Train Loss: 1.2149  |  Val Loss: 1.2566\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 110/1000] Train Loss: 1.2061  |  Val Loss: 1.2394\n",
      "Validation loss improved from 1.2437 to 1.2394.\n",
      "[Epoch 111/1000] Train Loss: 1.2005  |  Val Loss: 1.2481\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 112/1000] Train Loss: 1.1992  |  Val Loss: 1.2419\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 113/1000] Train Loss: 1.1964  |  Val Loss: 1.2711\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 114/1000] Train Loss: 1.2009  |  Val Loss: 1.2328\n",
      "Validation loss improved from 1.2394 to 1.2328.\n",
      "[Epoch 115/1000] Train Loss: 1.2099  |  Val Loss: 1.2909\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 116/1000] Train Loss: 1.2230  |  Val Loss: 1.2310\n",
      "Validation loss improved from 1.2328 to 1.2310.\n",
      "[Epoch 117/1000] Train Loss: 1.2110  |  Val Loss: 1.2536\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 118/1000] Train Loss: 1.1995  |  Val Loss: 1.2644\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 119/1000] Train Loss: 1.2027  |  Val Loss: 1.3004\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 120/1000] Train Loss: 1.2399  |  Val Loss: 1.2606\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 121/1000] Train Loss: 1.2411  |  Val Loss: 1.2585\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 122/1000] Train Loss: 1.1975  |  Val Loss: 1.2551\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 123/1000] Train Loss: 1.1985  |  Val Loss: 1.2250\n",
      "Validation loss improved from 1.2310 to 1.2250.\n",
      "[Epoch 124/1000] Train Loss: 1.1864  |  Val Loss: 1.2216\n",
      "Validation loss improved from 1.2250 to 1.2216.\n",
      "[Epoch 125/1000] Train Loss: 1.1747  |  Val Loss: 1.2171\n",
      "Validation loss improved from 1.2216 to 1.2171.\n",
      "[Epoch 126/1000] Train Loss: 1.1830  |  Val Loss: 1.2573\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 127/1000] Train Loss: 1.1859  |  Val Loss: 1.2101\n",
      "Validation loss improved from 1.2171 to 1.2101.\n",
      "[Epoch 128/1000] Train Loss: 1.1666  |  Val Loss: 1.2199\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 129/1000] Train Loss: 1.1727  |  Val Loss: 1.2718\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 130/1000] Train Loss: 1.1966  |  Val Loss: 1.2147\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 131/1000] Train Loss: 1.1929  |  Val Loss: 1.2697\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 132/1000] Train Loss: 1.2066  |  Val Loss: 1.2046\n",
      "Validation loss improved from 1.2101 to 1.2046.\n",
      "[Epoch 133/1000] Train Loss: 1.1553  |  Val Loss: 1.2134\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 134/1000] Train Loss: 1.1573  |  Val Loss: 1.2101\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 135/1000] Train Loss: 1.1583  |  Val Loss: 1.2353\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 136/1000] Train Loss: 1.1733  |  Val Loss: 1.2151\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 137/1000] Train Loss: 1.1673  |  Val Loss: 1.2026\n",
      "Validation loss improved from 1.2046 to 1.2026.\n",
      "[Epoch 138/1000] Train Loss: 1.1567  |  Val Loss: 1.2030\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 139/1000] Train Loss: 1.1573  |  Val Loss: 1.2365\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 140/1000] Train Loss: 1.1678  |  Val Loss: 1.2050\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 141/1000] Train Loss: 1.1543  |  Val Loss: 1.2518\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 142/1000] Train Loss: 1.1909  |  Val Loss: 1.2167\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 143/1000] Train Loss: 1.1755  |  Val Loss: 1.2226\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 144/1000] Train Loss: 1.1616  |  Val Loss: 1.2471\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 145/1000] Train Loss: 1.1647  |  Val Loss: 1.1956\n",
      "Validation loss improved from 1.2026 to 1.1956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 146/1000] Train Loss: 1.1579  |  Val Loss: 1.2116\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 147/1000] Train Loss: 1.1626  |  Val Loss: 1.2183\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 148/1000] Train Loss: 1.1546  |  Val Loss: 1.2150\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 149/1000] Train Loss: 1.1652  |  Val Loss: 1.2524\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 150/1000] Train Loss: 1.1969  |  Val Loss: 1.1927\n",
      "Validation loss improved from 1.1956 to 1.1927.\n",
      "[Epoch 151/1000] Train Loss: 1.1929  |  Val Loss: 1.2931\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 152/1000] Train Loss: 1.2099  |  Val Loss: 1.1998\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 153/1000] Train Loss: 1.1624  |  Val Loss: 1.2385\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 154/1000] Train Loss: 1.1783  |  Val Loss: 1.2090\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 155/1000] Train Loss: 1.1874  |  Val Loss: 1.2647\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 156/1000] Train Loss: 1.1865  |  Val Loss: 1.1827\n",
      "Validation loss improved from 1.1927 to 1.1827.\n",
      "[Epoch 157/1000] Train Loss: 1.1356  |  Val Loss: 1.1942\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 158/1000] Train Loss: 1.1882  |  Val Loss: 1.2075\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 159/1000] Train Loss: 1.1369  |  Val Loss: 1.1795\n",
      "Validation loss improved from 1.1827 to 1.1795.\n",
      "[Epoch 160/1000] Train Loss: 1.1520  |  Val Loss: 1.1912\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 161/1000] Train Loss: 1.1520  |  Val Loss: 1.1791\n",
      "Validation loss improved from 1.1795 to 1.1791.\n",
      "[Epoch 162/1000] Train Loss: 1.1367  |  Val Loss: 1.1907\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 163/1000] Train Loss: 1.1508  |  Val Loss: 1.2216\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 164/1000] Train Loss: 1.1418  |  Val Loss: 1.2472\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 165/1000] Train Loss: 1.1637  |  Val Loss: 1.1939\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 166/1000] Train Loss: 1.1959  |  Val Loss: 1.2898\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 167/1000] Train Loss: 1.1952  |  Val Loss: 1.2115\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 168/1000] Train Loss: 1.1564  |  Val Loss: 1.1982\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 169/1000] Train Loss: 1.1351  |  Val Loss: 1.2289\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 170/1000] Train Loss: 1.1624  |  Val Loss: 1.1970\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 171/1000] Train Loss: 1.1425  |  Val Loss: 1.1803\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 172/1000] Train Loss: 1.1285  |  Val Loss: 1.1772\n",
      "Validation loss improved from 1.1791 to 1.1772.\n",
      "[Epoch 173/1000] Train Loss: 1.1276  |  Val Loss: 1.1824\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 174/1000] Train Loss: 1.1237  |  Val Loss: 1.1836\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 175/1000] Train Loss: 1.1303  |  Val Loss: 1.1807\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 176/1000] Train Loss: 1.1382  |  Val Loss: 1.1731\n",
      "Validation loss improved from 1.1772 to 1.1731.\n",
      "[Epoch 177/1000] Train Loss: 1.1167  |  Val Loss: 1.1820\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 178/1000] Train Loss: 1.1157  |  Val Loss: 1.1723\n",
      "Validation loss improved from 1.1731 to 1.1723.\n",
      "[Epoch 179/1000] Train Loss: 1.1325  |  Val Loss: 1.1811\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 180/1000] Train Loss: 1.1274  |  Val Loss: 1.2247\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 181/1000] Train Loss: 1.1374  |  Val Loss: 1.2064\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 182/1000] Train Loss: 1.1577  |  Val Loss: 1.2140\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 183/1000] Train Loss: 1.1593  |  Val Loss: 1.3039\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 184/1000] Train Loss: 1.2137  |  Val Loss: 1.1676\n",
      "Validation loss improved from 1.1723 to 1.1676.\n",
      "[Epoch 185/1000] Train Loss: 1.1246  |  Val Loss: 1.1743\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 186/1000] Train Loss: 1.1389  |  Val Loss: 1.1668\n",
      "Validation loss improved from 1.1676 to 1.1668.\n",
      "[Epoch 187/1000] Train Loss: 1.1445  |  Val Loss: 1.2415\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 188/1000] Train Loss: 1.1445  |  Val Loss: 1.1719\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 189/1000] Train Loss: 1.1418  |  Val Loss: 1.2118\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 190/1000] Train Loss: 1.1505  |  Val Loss: 1.2341\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 191/1000] Train Loss: 1.1461  |  Val Loss: 1.1748\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 192/1000] Train Loss: 1.1114  |  Val Loss: 1.1894\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 193/1000] Train Loss: 1.1190  |  Val Loss: 1.1917\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 194/1000] Train Loss: 1.1010  |  Val Loss: 1.2584\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 195/1000] Train Loss: 1.1513  |  Val Loss: 1.1998\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 196/1000] Train Loss: 1.1228  |  Val Loss: 1.1621\n",
      "Validation loss improved from 1.1668 to 1.1621.\n",
      "[Epoch 197/1000] Train Loss: 1.1138  |  Val Loss: 1.1624\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 198/1000] Train Loss: 1.1157  |  Val Loss: 1.1785\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 199/1000] Train Loss: 1.1203  |  Val Loss: 1.1842\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 200/1000] Train Loss: 1.1077  |  Val Loss: 1.1717\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 201/1000] Train Loss: 1.1106  |  Val Loss: 1.1832\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 202/1000] Train Loss: 1.1093  |  Val Loss: 1.2206\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 203/1000] Train Loss: 1.1396  |  Val Loss: 1.1734\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 204/1000] Train Loss: 1.1074  |  Val Loss: 1.1545\n",
      "Validation loss improved from 1.1621 to 1.1545.\n",
      "[Epoch 205/1000] Train Loss: 1.1092  |  Val Loss: 1.1566\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 206/1000] Train Loss: 1.1211  |  Val Loss: 1.1753\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 207/1000] Train Loss: 1.1171  |  Val Loss: 1.1616\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 208/1000] Train Loss: 1.1210  |  Val Loss: 1.1999\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 209/1000] Train Loss: 1.1319  |  Val Loss: 1.1752\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 210/1000] Train Loss: 1.1148  |  Val Loss: 1.1556\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 211/1000] Train Loss: 1.0990  |  Val Loss: 1.1499\n",
      "Validation loss improved from 1.1545 to 1.1499.\n",
      "[Epoch 212/1000] Train Loss: 1.1062  |  Val Loss: 1.1636\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 213/1000] Train Loss: 1.1238  |  Val Loss: 1.1569\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 214/1000] Train Loss: 1.1063  |  Val Loss: 1.1628\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 215/1000] Train Loss: 1.1001  |  Val Loss: 1.1593\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 216/1000] Train Loss: 1.1016  |  Val Loss: 1.1612\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 217/1000] Train Loss: 1.0965  |  Val Loss: 1.1648\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 218/1000] Train Loss: 1.1223  |  Val Loss: 1.1669\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 219/1000] Train Loss: 1.1085  |  Val Loss: 1.1725\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 220/1000] Train Loss: 1.1132  |  Val Loss: 1.2060\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 221/1000] Train Loss: 1.1215  |  Val Loss: 1.2464\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 222/1000] Train Loss: 1.1701  |  Val Loss: 1.1539\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 223/1000] Train Loss: 1.1219  |  Val Loss: 1.1748\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 224/1000] Train Loss: 1.1445  |  Val Loss: 1.1604\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 225/1000] Train Loss: 1.1180  |  Val Loss: 1.1755\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 226/1000] Train Loss: 1.1188  |  Val Loss: 1.1680\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 227/1000] Train Loss: 1.1230  |  Val Loss: 1.2023\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 228/1000] Train Loss: 1.1117  |  Val Loss: 1.1578\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 229/1000] Train Loss: 1.1002  |  Val Loss: 1.1570\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 230/1000] Train Loss: 1.0905  |  Val Loss: 1.1584\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 231/1000] Train Loss: 1.0882  |  Val Loss: 1.1747\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 232/1000] Train Loss: 1.1150  |  Val Loss: 1.1667\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 233/1000] Train Loss: 1.0979  |  Val Loss: 1.1714\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 234/1000] Train Loss: 1.1274  |  Val Loss: 1.1615\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 235/1000] Train Loss: 1.1532  |  Val Loss: 1.2789\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 236/1000] Train Loss: 1.1520  |  Val Loss: 1.2477\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 237/1000] Train Loss: 1.1447  |  Val Loss: 1.1640\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 238/1000] Train Loss: 1.1144  |  Val Loss: 1.2123\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 239/1000] Train Loss: 1.1700  |  Val Loss: 1.1585\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 240/1000] Train Loss: 1.1059  |  Val Loss: 1.1843\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 241/1000] Train Loss: 1.1238  |  Val Loss: 1.1802\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 242/1000] Train Loss: 1.1240  |  Val Loss: 1.1527\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 243/1000] Train Loss: 1.1123  |  Val Loss: 1.1649\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 244/1000] Train Loss: 1.1050  |  Val Loss: 1.1679\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 245/1000] Train Loss: 1.1201  |  Val Loss: 1.2216\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 246/1000] Train Loss: 1.1243  |  Val Loss: 1.1520\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 247/1000] Train Loss: 1.0924  |  Val Loss: 1.1458\n",
      "Validation loss improved from 1.1499 to 1.1458.\n",
      "[Epoch 248/1000] Train Loss: 1.0993  |  Val Loss: 1.1444\n",
      "Validation loss improved from 1.1458 to 1.1444.\n",
      "[Epoch 249/1000] Train Loss: 1.0898  |  Val Loss: 1.1520\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 250/1000] Train Loss: 1.0847  |  Val Loss: 1.1603\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 251/1000] Train Loss: 1.0873  |  Val Loss: 1.1495\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 252/1000] Train Loss: 1.0784  |  Val Loss: 1.2104\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 253/1000] Train Loss: 1.1310  |  Val Loss: 1.1479\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 254/1000] Train Loss: 1.0792  |  Val Loss: 1.1746\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 255/1000] Train Loss: 1.0841  |  Val Loss: 1.2003\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 256/1000] Train Loss: 1.1093  |  Val Loss: 1.1640\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 257/1000] Train Loss: 1.1042  |  Val Loss: 1.1528\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 258/1000] Train Loss: 1.0847  |  Val Loss: 1.1379\n",
      "Validation loss improved from 1.1444 to 1.1379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 259/1000] Train Loss: 1.0908  |  Val Loss: 1.1384\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 260/1000] Train Loss: 1.0843  |  Val Loss: 1.1415\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 261/1000] Train Loss: 1.0834  |  Val Loss: 1.1665\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 262/1000] Train Loss: 1.1093  |  Val Loss: 1.1454\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 263/1000] Train Loss: 1.0858  |  Val Loss: 1.1489\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 264/1000] Train Loss: 1.0972  |  Val Loss: 1.1529\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 265/1000] Train Loss: 1.0983  |  Val Loss: 1.1416\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 266/1000] Train Loss: 1.0948  |  Val Loss: 1.1792\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 267/1000] Train Loss: 1.0925  |  Val Loss: 1.1525\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 268/1000] Train Loss: 1.0912  |  Val Loss: 1.1512\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 269/1000] Train Loss: 1.1038  |  Val Loss: 1.1495\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 270/1000] Train Loss: 1.0914  |  Val Loss: 1.1526\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 271/1000] Train Loss: 1.1285  |  Val Loss: 1.1556\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 272/1000] Train Loss: 1.0859  |  Val Loss: 1.1480\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 273/1000] Train Loss: 1.0846  |  Val Loss: 1.1746\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 274/1000] Train Loss: 1.0846  |  Val Loss: 1.1584\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 275/1000] Train Loss: 1.0877  |  Val Loss: 1.1482\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 276/1000] Train Loss: 1.0846  |  Val Loss: 1.1653\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 277/1000] Train Loss: 1.1041  |  Val Loss: 1.1989\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 278/1000] Train Loss: 1.1003  |  Val Loss: 1.1469\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 279/1000] Train Loss: 1.0861  |  Val Loss: 1.1944\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 280/1000] Train Loss: 1.0940  |  Val Loss: 1.1507\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 281/1000] Train Loss: 1.1075  |  Val Loss: 1.1516\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 282/1000] Train Loss: 1.0999  |  Val Loss: 1.1511\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 283/1000] Train Loss: 1.0936  |  Val Loss: 1.1353\n",
      "Validation loss improved from 1.1379 to 1.1353.\n",
      "[Epoch 284/1000] Train Loss: 1.0664  |  Val Loss: 1.1391\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 285/1000] Train Loss: 1.0812  |  Val Loss: 1.1430\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 286/1000] Train Loss: 1.0834  |  Val Loss: 1.1721\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 287/1000] Train Loss: 1.0860  |  Val Loss: 1.1878\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 288/1000] Train Loss: 1.0867  |  Val Loss: 1.2859\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 289/1000] Train Loss: 1.1609  |  Val Loss: 1.1397\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 290/1000] Train Loss: 1.1337  |  Val Loss: 1.2117\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 291/1000] Train Loss: 1.1089  |  Val Loss: 1.2402\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 292/1000] Train Loss: 1.1456  |  Val Loss: 1.1359\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 293/1000] Train Loss: 1.0715  |  Val Loss: 1.1424\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 294/1000] Train Loss: 1.0894  |  Val Loss: 1.1521\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 295/1000] Train Loss: 1.0727  |  Val Loss: 1.1469\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 296/1000] Train Loss: 1.0747  |  Val Loss: 1.1492\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 297/1000] Train Loss: 1.0781  |  Val Loss: 1.1324\n",
      "Validation loss improved from 1.1353 to 1.1324.\n",
      "[Epoch 298/1000] Train Loss: 1.1125  |  Val Loss: 1.3075\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 299/1000] Train Loss: 1.1654  |  Val Loss: 1.2709\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 300/1000] Train Loss: 1.1492  |  Val Loss: 1.1596\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 301/1000] Train Loss: 1.1141  |  Val Loss: 1.1530\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 302/1000] Train Loss: 1.1115  |  Val Loss: 1.1925\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 303/1000] Train Loss: 1.1103  |  Val Loss: 1.1373\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 304/1000] Train Loss: 1.1060  |  Val Loss: 1.1670\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 305/1000] Train Loss: 1.0802  |  Val Loss: 1.1522\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 306/1000] Train Loss: 1.0915  |  Val Loss: 1.1547\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 307/1000] Train Loss: 1.1013  |  Val Loss: 1.1730\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 308/1000] Train Loss: 1.0914  |  Val Loss: 1.1843\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 309/1000] Train Loss: 1.0781  |  Val Loss: 1.2410\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 310/1000] Train Loss: 1.1420  |  Val Loss: 1.1341\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 311/1000] Train Loss: 1.1138  |  Val Loss: 1.2300\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 312/1000] Train Loss: 1.1193  |  Val Loss: 1.1856\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 313/1000] Train Loss: 1.1035  |  Val Loss: 1.1343\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 314/1000] Train Loss: 1.0745  |  Val Loss: 1.1417\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 315/1000] Train Loss: 1.0687  |  Val Loss: 1.1354\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 316/1000] Train Loss: 1.0685  |  Val Loss: 1.1267\n",
      "Validation loss improved from 1.1324 to 1.1267.\n",
      "[Epoch 317/1000] Train Loss: 1.0665  |  Val Loss: 1.1400\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 318/1000] Train Loss: 1.0902  |  Val Loss: 1.1307\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 319/1000] Train Loss: 1.0749  |  Val Loss: 1.1477\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 320/1000] Train Loss: 1.0782  |  Val Loss: 1.1553\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 321/1000] Train Loss: 1.0786  |  Val Loss: 1.1424\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 322/1000] Train Loss: 1.0596  |  Val Loss: 1.1425\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 323/1000] Train Loss: 1.0706  |  Val Loss: 1.1351\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 324/1000] Train Loss: 1.0700  |  Val Loss: 1.1308\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 325/1000] Train Loss: 1.0546  |  Val Loss: 1.1864\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 326/1000] Train Loss: 1.1221  |  Val Loss: 1.2805\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 327/1000] Train Loss: 1.0957  |  Val Loss: 1.1603\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 328/1000] Train Loss: 1.0755  |  Val Loss: 1.1340\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 329/1000] Train Loss: 1.0848  |  Val Loss: 1.1469\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 330/1000] Train Loss: 1.0785  |  Val Loss: 1.1521\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 331/1000] Train Loss: 1.0855  |  Val Loss: 1.1248\n",
      "Validation loss improved from 1.1267 to 1.1248.\n",
      "[Epoch 332/1000] Train Loss: 1.1429  |  Val Loss: 1.2317\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 333/1000] Train Loss: 1.1729  |  Val Loss: 1.1854\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 334/1000] Train Loss: 1.1231  |  Val Loss: 1.1325\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 335/1000] Train Loss: 1.0896  |  Val Loss: 1.1727\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 336/1000] Train Loss: 1.0950  |  Val Loss: 1.1249\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 337/1000] Train Loss: 1.0889  |  Val Loss: 1.1299\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 338/1000] Train Loss: 1.1006  |  Val Loss: 1.1470\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 339/1000] Train Loss: 1.0841  |  Val Loss: 1.1391\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 340/1000] Train Loss: 1.0671  |  Val Loss: 1.1421\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 341/1000] Train Loss: 1.0788  |  Val Loss: 1.1624\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 342/1000] Train Loss: 1.0780  |  Val Loss: 1.1265\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 343/1000] Train Loss: 1.0740  |  Val Loss: 1.1516\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 344/1000] Train Loss: 1.0942  |  Val Loss: 1.1636\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 345/1000] Train Loss: 1.0666  |  Val Loss: 1.1345\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 346/1000] Train Loss: 1.0637  |  Val Loss: 1.1383\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 347/1000] Train Loss: 1.0706  |  Val Loss: 1.1315\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 348/1000] Train Loss: 1.0614  |  Val Loss: 1.1307\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 349/1000] Train Loss: 1.0576  |  Val Loss: 1.1294\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 350/1000] Train Loss: 1.0620  |  Val Loss: 1.1264\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 351/1000] Train Loss: 1.0554  |  Val Loss: 1.1272\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 352/1000] Train Loss: 1.0524  |  Val Loss: 1.1259\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 353/1000] Train Loss: 1.0635  |  Val Loss: 1.1416\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 354/1000] Train Loss: 1.0672  |  Val Loss: 1.1215\n",
      "Validation loss improved from 1.1248 to 1.1215.\n",
      "[Epoch 355/1000] Train Loss: 1.0608  |  Val Loss: 1.1401\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 356/1000] Train Loss: 1.0580  |  Val Loss: 1.1412\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 357/1000] Train Loss: 1.0590  |  Val Loss: 1.1397\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 358/1000] Train Loss: 1.0593  |  Val Loss: 1.1286\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 359/1000] Train Loss: 1.0731  |  Val Loss: 1.1822\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 360/1000] Train Loss: 1.0661  |  Val Loss: 1.2089\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 361/1000] Train Loss: 1.0811  |  Val Loss: 1.2002\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 362/1000] Train Loss: 1.0954  |  Val Loss: 1.1291\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 363/1000] Train Loss: 1.1029  |  Val Loss: 1.1606\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 364/1000] Train Loss: 1.0845  |  Val Loss: 1.1799\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 365/1000] Train Loss: 1.0874  |  Val Loss: 1.1223\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 366/1000] Train Loss: 1.0700  |  Val Loss: 1.1218\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 367/1000] Train Loss: 1.0521  |  Val Loss: 1.1224\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 368/1000] Train Loss: 1.0537  |  Val Loss: 1.1646\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 369/1000] Train Loss: 1.0844  |  Val Loss: 1.1314\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 370/1000] Train Loss: 1.0653  |  Val Loss: 1.1182\n",
      "Validation loss improved from 1.1215 to 1.1182.\n",
      "[Epoch 371/1000] Train Loss: 1.0694  |  Val Loss: 1.1234\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 372/1000] Train Loss: 1.0521  |  Val Loss: 1.1243\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 373/1000] Train Loss: 1.0563  |  Val Loss: 1.1264\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 374/1000] Train Loss: 1.0629  |  Val Loss: 1.1223\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 375/1000] Train Loss: 1.0638  |  Val Loss: 1.1319\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 376/1000] Train Loss: 1.0573  |  Val Loss: 1.1406\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 377/1000] Train Loss: 1.0661  |  Val Loss: 1.1424\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 378/1000] Train Loss: 1.0512  |  Val Loss: 1.1241\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 379/1000] Train Loss: 1.0600  |  Val Loss: 1.1280\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 380/1000] Train Loss: 1.0719  |  Val Loss: 1.1273\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 381/1000] Train Loss: 1.0714  |  Val Loss: 1.1570\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 382/1000] Train Loss: 1.0686  |  Val Loss: 1.1503\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 383/1000] Train Loss: 1.0785  |  Val Loss: 1.1235\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 384/1000] Train Loss: 1.0626  |  Val Loss: 1.1443\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 385/1000] Train Loss: 1.0560  |  Val Loss: 1.1244\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 386/1000] Train Loss: 1.0435  |  Val Loss: 1.1269\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 387/1000] Train Loss: 1.0620  |  Val Loss: 1.1338\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 388/1000] Train Loss: 1.0853  |  Val Loss: 1.1584\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 389/1000] Train Loss: 1.0722  |  Val Loss: 1.1239\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 390/1000] Train Loss: 1.0502  |  Val Loss: 1.1277\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 391/1000] Train Loss: 1.0470  |  Val Loss: 1.1347\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 392/1000] Train Loss: 1.0616  |  Val Loss: 1.2204\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 393/1000] Train Loss: 1.0701  |  Val Loss: 1.1562\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 394/1000] Train Loss: 1.0875  |  Val Loss: 1.1178\n",
      "Validation loss improved from 1.1182 to 1.1178.\n",
      "[Epoch 395/1000] Train Loss: 1.0674  |  Val Loss: 1.1368\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 396/1000] Train Loss: 1.0491  |  Val Loss: 1.2325\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 397/1000] Train Loss: 1.1045  |  Val Loss: 1.1247\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 398/1000] Train Loss: 1.0917  |  Val Loss: 1.1338\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 399/1000] Train Loss: 1.0533  |  Val Loss: 1.1674\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 400/1000] Train Loss: 1.0653  |  Val Loss: 1.1600\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 401/1000] Train Loss: 1.0796  |  Val Loss: 1.1304\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 402/1000] Train Loss: 1.0693  |  Val Loss: 1.1629\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 403/1000] Train Loss: 1.0734  |  Val Loss: 1.1148\n",
      "Validation loss improved from 1.1178 to 1.1148.\n",
      "[Epoch 404/1000] Train Loss: 1.0437  |  Val Loss: 1.1063\n",
      "Validation loss improved from 1.1148 to 1.1063.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 405/1000] Train Loss: 1.0405  |  Val Loss: 1.1061\n",
      "Validation loss improved from 1.1063 to 1.1061.\n",
      "[Epoch 406/1000] Train Loss: 1.0479  |  Val Loss: 1.1649\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 407/1000] Train Loss: 1.0946  |  Val Loss: 1.1421\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 408/1000] Train Loss: 1.0472  |  Val Loss: 1.1471\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 409/1000] Train Loss: 1.0725  |  Val Loss: 1.2819\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 410/1000] Train Loss: 1.1359  |  Val Loss: 1.1333\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 411/1000] Train Loss: 1.1002  |  Val Loss: 1.1724\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 412/1000] Train Loss: 1.0990  |  Val Loss: 1.1860\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 413/1000] Train Loss: 1.0858  |  Val Loss: 1.1344\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 414/1000] Train Loss: 1.0746  |  Val Loss: 1.1244\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 415/1000] Train Loss: 1.0568  |  Val Loss: 1.1515\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 416/1000] Train Loss: 1.0802  |  Val Loss: 1.1719\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 417/1000] Train Loss: 1.0830  |  Val Loss: 1.1280\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 418/1000] Train Loss: 1.0725  |  Val Loss: 1.2143\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 419/1000] Train Loss: 1.0933  |  Val Loss: 1.1419\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 420/1000] Train Loss: 1.0954  |  Val Loss: 1.1492\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 421/1000] Train Loss: 1.0800  |  Val Loss: 1.2969\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 422/1000] Train Loss: 1.1614  |  Val Loss: 1.1249\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 423/1000] Train Loss: 1.0652  |  Val Loss: 1.1354\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 424/1000] Train Loss: 1.0516  |  Val Loss: 1.1656\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 425/1000] Train Loss: 1.0490  |  Val Loss: 1.2162\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 426/1000] Train Loss: 1.0962  |  Val Loss: 1.2433\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 427/1000] Train Loss: 1.1277  |  Val Loss: 1.1102\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 428/1000] Train Loss: 1.0783  |  Val Loss: 1.1444\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 429/1000] Train Loss: 1.0647  |  Val Loss: 1.1506\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 430/1000] Train Loss: 1.0462  |  Val Loss: 1.1297\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 431/1000] Train Loss: 1.0402  |  Val Loss: 1.1351\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 432/1000] Train Loss: 1.0486  |  Val Loss: 1.1298\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 433/1000] Train Loss: 1.0571  |  Val Loss: 1.1620\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 434/1000] Train Loss: 1.0767  |  Val Loss: 1.1240\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 435/1000] Train Loss: 1.0569  |  Val Loss: 1.1380\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 436/1000] Train Loss: 1.0731  |  Val Loss: 1.1872\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 437/1000] Train Loss: 1.0866  |  Val Loss: 1.1394\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 438/1000] Train Loss: 1.0562  |  Val Loss: 1.1176\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 439/1000] Train Loss: 1.0698  |  Val Loss: 1.1501\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 440/1000] Train Loss: 1.0551  |  Val Loss: 1.1255\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 441/1000] Train Loss: 1.0689  |  Val Loss: 1.1588\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 442/1000] Train Loss: 1.0718  |  Val Loss: 1.1347\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 443/1000] Train Loss: 1.0382  |  Val Loss: 1.1150\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 444/1000] Train Loss: 1.0560  |  Val Loss: 1.1154\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 445/1000] Train Loss: 1.0362  |  Val Loss: 1.1182\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 446/1000] Train Loss: 1.0470  |  Val Loss: 1.1383\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 447/1000] Train Loss: 1.0576  |  Val Loss: 1.1283\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 448/1000] Train Loss: 1.0362  |  Val Loss: 1.1232\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 449/1000] Train Loss: 1.0413  |  Val Loss: 1.1297\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 450/1000] Train Loss: 1.0503  |  Val Loss: 1.1872\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 451/1000] Train Loss: 1.1069  |  Val Loss: 1.1129\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 452/1000] Train Loss: 1.0973  |  Val Loss: 1.2636\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 453/1000] Train Loss: 1.1199  |  Val Loss: 1.1691\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 454/1000] Train Loss: 1.0831  |  Val Loss: 1.1064\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 455/1000] Train Loss: 1.1052  |  Val Loss: 1.2217\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 456/1000] Train Loss: 1.1290  |  Val Loss: 1.1296\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 457/1000] Train Loss: 1.0544  |  Val Loss: 1.1138\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 458/1000] Train Loss: 1.0464  |  Val Loss: 1.1131\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 459/1000] Train Loss: 1.0644  |  Val Loss: 1.1201\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 460/1000] Train Loss: 1.0463  |  Val Loss: 1.1085\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 461/1000] Train Loss: 1.0450  |  Val Loss: 1.1206\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 462/1000] Train Loss: 1.0322  |  Val Loss: 1.1093\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 463/1000] Train Loss: 1.0463  |  Val Loss: 1.1063\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 464/1000] Train Loss: 1.0336  |  Val Loss: 1.1118\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 465/1000] Train Loss: 1.0534  |  Val Loss: 1.1836\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 466/1000] Train Loss: 1.0901  |  Val Loss: 1.1342\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 467/1000] Train Loss: 1.0473  |  Val Loss: 1.1150\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 468/1000] Train Loss: 1.0370  |  Val Loss: 1.1284\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 469/1000] Train Loss: 1.0595  |  Val Loss: 1.1179\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 470/1000] Train Loss: 1.0399  |  Val Loss: 1.0965\n",
      "Validation loss improved from 1.1061 to 1.0965.\n",
      "[Epoch 471/1000] Train Loss: 1.0489  |  Val Loss: 1.1093\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 472/1000] Train Loss: 1.0528  |  Val Loss: 1.1078\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 473/1000] Train Loss: 1.0588  |  Val Loss: 1.1218\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 474/1000] Train Loss: 1.0349  |  Val Loss: 1.1146\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 475/1000] Train Loss: 1.0428  |  Val Loss: 1.1386\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 476/1000] Train Loss: 1.0462  |  Val Loss: 1.1709\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 477/1000] Train Loss: 1.0500  |  Val Loss: 1.1161\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 478/1000] Train Loss: 1.0436  |  Val Loss: 1.1068\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 479/1000] Train Loss: 1.0649  |  Val Loss: 1.1030\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 480/1000] Train Loss: 1.0371  |  Val Loss: 1.1268\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 481/1000] Train Loss: 1.0679  |  Val Loss: 1.1113\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 482/1000] Train Loss: 1.0346  |  Val Loss: 1.1006\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 483/1000] Train Loss: 1.0255  |  Val Loss: 1.1157\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 484/1000] Train Loss: 1.0289  |  Val Loss: 1.1133\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 485/1000] Train Loss: 1.0487  |  Val Loss: 1.1648\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 486/1000] Train Loss: 1.0697  |  Val Loss: 1.1382\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 487/1000] Train Loss: 1.0502  |  Val Loss: 1.1084\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 488/1000] Train Loss: 1.0450  |  Val Loss: 1.1749\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 489/1000] Train Loss: 1.0642  |  Val Loss: 1.1694\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 490/1000] Train Loss: 1.0775  |  Val Loss: 1.1128\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 491/1000] Train Loss: 1.0367  |  Val Loss: 1.1048\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 492/1000] Train Loss: 1.0222  |  Val Loss: 1.1140\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 493/1000] Train Loss: 1.0316  |  Val Loss: 1.1228\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 494/1000] Train Loss: 1.0325  |  Val Loss: 1.1210\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 495/1000] Train Loss: 1.0334  |  Val Loss: 1.1274\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 496/1000] Train Loss: 1.0654  |  Val Loss: 1.1243\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 497/1000] Train Loss: 1.0453  |  Val Loss: 1.1155\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 498/1000] Train Loss: 1.0306  |  Val Loss: 1.1051\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 499/1000] Train Loss: 1.0181  |  Val Loss: 1.1128\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 500/1000] Train Loss: 1.0215  |  Val Loss: 1.1311\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 501/1000] Train Loss: 1.0318  |  Val Loss: 1.1066\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 502/1000] Train Loss: 1.0217  |  Val Loss: 1.1110\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 503/1000] Train Loss: 1.0227  |  Val Loss: 1.1349\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 504/1000] Train Loss: 1.0483  |  Val Loss: 1.1699\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 505/1000] Train Loss: 1.0429  |  Val Loss: 1.1688\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 506/1000] Train Loss: 1.0503  |  Val Loss: 1.1292\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 507/1000] Train Loss: 1.0246  |  Val Loss: 1.0979\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 508/1000] Train Loss: 1.0393  |  Val Loss: 1.1230\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 509/1000] Train Loss: 1.0407  |  Val Loss: 1.1266\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 510/1000] Train Loss: 1.0339  |  Val Loss: 1.0954\n",
      "Validation loss improved from 1.0965 to 1.0954.\n",
      "[Epoch 511/1000] Train Loss: 1.0340  |  Val Loss: 1.1684\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 512/1000] Train Loss: 1.0670  |  Val Loss: 1.2048\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 513/1000] Train Loss: 1.0801  |  Val Loss: 1.1204\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 514/1000] Train Loss: 1.0408  |  Val Loss: 1.1287\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 515/1000] Train Loss: 1.0511  |  Val Loss: 1.2267\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 516/1000] Train Loss: 1.0522  |  Val Loss: 1.1647\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 517/1000] Train Loss: 1.0553  |  Val Loss: 1.1049\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 518/1000] Train Loss: 1.0324  |  Val Loss: 1.1145\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 519/1000] Train Loss: 1.0350  |  Val Loss: 1.1245\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 520/1000] Train Loss: 1.0609  |  Val Loss: 1.1058\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 521/1000] Train Loss: 1.0482  |  Val Loss: 1.1993\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 522/1000] Train Loss: 1.0633  |  Val Loss: 1.1124\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 523/1000] Train Loss: 1.0552  |  Val Loss: 1.1034\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 524/1000] Train Loss: 1.0540  |  Val Loss: 1.1069\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 525/1000] Train Loss: 1.0216  |  Val Loss: 1.0790\n",
      "Validation loss improved from 1.0954 to 1.0790.\n",
      "[Epoch 526/1000] Train Loss: 1.0215  |  Val Loss: 1.0931\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 527/1000] Train Loss: 1.0146  |  Val Loss: 1.1255\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 528/1000] Train Loss: 1.0431  |  Val Loss: 1.1828\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 529/1000] Train Loss: 1.0490  |  Val Loss: 1.1241\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 530/1000] Train Loss: 1.0476  |  Val Loss: 1.0944\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 531/1000] Train Loss: 1.0269  |  Val Loss: 1.1061\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 532/1000] Train Loss: 1.0210  |  Val Loss: 1.1140\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 533/1000] Train Loss: 1.0310  |  Val Loss: 1.0971\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 534/1000] Train Loss: 1.0376  |  Val Loss: 1.1362\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 535/1000] Train Loss: 1.0476  |  Val Loss: 1.2567\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 536/1000] Train Loss: 1.0905  |  Val Loss: 1.1250\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 537/1000] Train Loss: 1.0384  |  Val Loss: 1.1100\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 538/1000] Train Loss: 1.0413  |  Val Loss: 1.1594\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 539/1000] Train Loss: 1.0512  |  Val Loss: 1.0944\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 540/1000] Train Loss: 1.0298  |  Val Loss: 1.1072\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 541/1000] Train Loss: 1.0240  |  Val Loss: 1.0935\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 542/1000] Train Loss: 1.0177  |  Val Loss: 1.1362\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 543/1000] Train Loss: 1.0177  |  Val Loss: 1.2218\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 544/1000] Train Loss: 1.0703  |  Val Loss: 1.1023\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 545/1000] Train Loss: 1.0281  |  Val Loss: 1.1046\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 546/1000] Train Loss: 1.0477  |  Val Loss: 1.1291\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 547/1000] Train Loss: 1.0422  |  Val Loss: 1.0910\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 548/1000] Train Loss: 1.0198  |  Val Loss: 1.1546\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 549/1000] Train Loss: 1.0693  |  Val Loss: 1.1471\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 550/1000] Train Loss: 1.0494  |  Val Loss: 1.1110\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 551/1000] Train Loss: 1.0151  |  Val Loss: 1.0912\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 552/1000] Train Loss: 1.0134  |  Val Loss: 1.0815\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 553/1000] Train Loss: 1.0187  |  Val Loss: 1.0904\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 554/1000] Train Loss: 1.0450  |  Val Loss: 1.1544\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 555/1000] Train Loss: 1.0455  |  Val Loss: 1.0765\n",
      "Validation loss improved from 1.0790 to 1.0765.\n",
      "[Epoch 556/1000] Train Loss: 1.0345  |  Val Loss: 1.0912\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 557/1000] Train Loss: 1.0208  |  Val Loss: 1.1057\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 558/1000] Train Loss: 1.0134  |  Val Loss: 1.0788\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 559/1000] Train Loss: 1.0142  |  Val Loss: 1.1142\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 560/1000] Train Loss: 1.0174  |  Val Loss: 1.1231\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 561/1000] Train Loss: 1.0179  |  Val Loss: 1.1189\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 562/1000] Train Loss: 1.0566  |  Val Loss: 1.0906\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 563/1000] Train Loss: 1.0241  |  Val Loss: 1.1415\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 564/1000] Train Loss: 1.0164  |  Val Loss: 1.1320\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 565/1000] Train Loss: 1.0245  |  Val Loss: 1.0867\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 566/1000] Train Loss: 1.0488  |  Val Loss: 1.1058\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 567/1000] Train Loss: 1.0089  |  Val Loss: 1.0829\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 568/1000] Train Loss: 1.0192  |  Val Loss: 1.0893\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 569/1000] Train Loss: 1.0285  |  Val Loss: 1.1018\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 570/1000] Train Loss: 1.0050  |  Val Loss: 1.0924\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 571/1000] Train Loss: 1.0164  |  Val Loss: 1.0812\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 572/1000] Train Loss: 1.0064  |  Val Loss: 1.0858\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 573/1000] Train Loss: 1.0101  |  Val Loss: 1.1375\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 574/1000] Train Loss: 1.0317  |  Val Loss: 1.1081\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 575/1000] Train Loss: 1.0190  |  Val Loss: 1.0840\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 576/1000] Train Loss: 1.0365  |  Val Loss: 1.1352\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 577/1000] Train Loss: 1.0475  |  Val Loss: 1.1338\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 578/1000] Train Loss: 1.0342  |  Val Loss: 1.0776\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 579/1000] Train Loss: 1.0320  |  Val Loss: 1.1375\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 580/1000] Train Loss: 1.0595  |  Val Loss: 1.0947\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 581/1000] Train Loss: 1.1007  |  Val Loss: 1.1375\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 582/1000] Train Loss: 1.0756  |  Val Loss: 1.0909\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 583/1000] Train Loss: 1.0242  |  Val Loss: 1.0903\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 584/1000] Train Loss: 1.0115  |  Val Loss: 1.1107\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 585/1000] Train Loss: 1.0253  |  Val Loss: 1.0962\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 586/1000] Train Loss: 1.0130  |  Val Loss: 1.1125\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 587/1000] Train Loss: 1.0165  |  Val Loss: 1.1315\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 588/1000] Train Loss: 1.0306  |  Val Loss: 1.0933\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 589/1000] Train Loss: 1.0242  |  Val Loss: 1.1021\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 590/1000] Train Loss: 1.0184  |  Val Loss: 1.1131\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 591/1000] Train Loss: 1.0110  |  Val Loss: 1.0806\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 592/1000] Train Loss: 1.0145  |  Val Loss: 1.0790\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 593/1000] Train Loss: 1.0186  |  Val Loss: 1.0896\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 594/1000] Train Loss: 1.0024  |  Val Loss: 1.1418\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 595/1000] Train Loss: 1.0756  |  Val Loss: 1.1506\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 596/1000] Train Loss: 1.0184  |  Val Loss: 1.1911\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 597/1000] Train Loss: 1.0331  |  Val Loss: 1.1085\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 598/1000] Train Loss: 1.0520  |  Val Loss: 1.0846\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 599/1000] Train Loss: 1.0202  |  Val Loss: 1.1082\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 600/1000] Train Loss: 1.0101  |  Val Loss: 1.0709\n",
      "Validation loss improved from 1.0765 to 1.0709.\n",
      "[Epoch 601/1000] Train Loss: 1.0026  |  Val Loss: 1.0850\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 602/1000] Train Loss: 1.0021  |  Val Loss: 1.0859\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 603/1000] Train Loss: 0.9996  |  Val Loss: 1.1335\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 604/1000] Train Loss: 1.0119  |  Val Loss: 1.1172\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 605/1000] Train Loss: 1.0059  |  Val Loss: 1.0814\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 606/1000] Train Loss: 0.9967  |  Val Loss: 1.1023\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 607/1000] Train Loss: 1.0056  |  Val Loss: 1.0801\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 608/1000] Train Loss: 0.9924  |  Val Loss: 1.0679\n",
      "Validation loss improved from 1.0709 to 1.0679.\n",
      "[Epoch 609/1000] Train Loss: 0.9974  |  Val Loss: 1.0704\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 610/1000] Train Loss: 0.9998  |  Val Loss: 1.0722\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 611/1000] Train Loss: 0.9936  |  Val Loss: 1.0737\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 612/1000] Train Loss: 0.9972  |  Val Loss: 1.1026\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 613/1000] Train Loss: 1.0051  |  Val Loss: 1.1319\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 614/1000] Train Loss: 0.9944  |  Val Loss: 1.1304\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 615/1000] Train Loss: 1.0217  |  Val Loss: 1.0602\n",
      "Validation loss improved from 1.0679 to 1.0602.\n",
      "[Epoch 616/1000] Train Loss: 1.0127  |  Val Loss: 1.1231\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 617/1000] Train Loss: 1.0261  |  Val Loss: 1.0738\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 618/1000] Train Loss: 1.0113  |  Val Loss: 1.0939\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 619/1000] Train Loss: 1.0246  |  Val Loss: 1.1248\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 620/1000] Train Loss: 1.0131  |  Val Loss: 1.0710\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 621/1000] Train Loss: 1.0154  |  Val Loss: 1.1358\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 622/1000] Train Loss: 1.0378  |  Val Loss: 1.1054\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 623/1000] Train Loss: 1.0382  |  Val Loss: 1.0880\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 624/1000] Train Loss: 1.0035  |  Val Loss: 1.0741\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 625/1000] Train Loss: 1.0056  |  Val Loss: 1.0554\n",
      "Validation loss improved from 1.0602 to 1.0554.\n",
      "[Epoch 626/1000] Train Loss: 0.9838  |  Val Loss: 1.0956\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 627/1000] Train Loss: 0.9985  |  Val Loss: 1.1009\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 628/1000] Train Loss: 0.9944  |  Val Loss: 1.0995\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 629/1000] Train Loss: 1.0116  |  Val Loss: 1.1804\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 630/1000] Train Loss: 1.0776  |  Val Loss: 1.0930\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 631/1000] Train Loss: 1.0406  |  Val Loss: 1.0989\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 632/1000] Train Loss: 1.0485  |  Val Loss: 1.3584\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 633/1000] Train Loss: 1.1243  |  Val Loss: 1.1423\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 634/1000] Train Loss: 1.0704  |  Val Loss: 1.0891\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 635/1000] Train Loss: 1.0067  |  Val Loss: 1.0907\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 636/1000] Train Loss: 1.0077  |  Val Loss: 1.0918\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 637/1000] Train Loss: 0.9973  |  Val Loss: 1.0785\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 638/1000] Train Loss: 0.9954  |  Val Loss: 1.0749\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 639/1000] Train Loss: 1.0023  |  Val Loss: 1.0670\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 640/1000] Train Loss: 0.9846  |  Val Loss: 1.0629\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 641/1000] Train Loss: 0.9980  |  Val Loss: 1.0677\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 642/1000] Train Loss: 0.9835  |  Val Loss: 1.0890\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 643/1000] Train Loss: 0.9935  |  Val Loss: 1.0740\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 644/1000] Train Loss: 0.9913  |  Val Loss: 1.1052\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 645/1000] Train Loss: 0.9958  |  Val Loss: 1.0683\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 646/1000] Train Loss: 1.0001  |  Val Loss: 1.0939\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 647/1000] Train Loss: 0.9952  |  Val Loss: 1.0953\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 648/1000] Train Loss: 0.9890  |  Val Loss: 1.0661\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 649/1000] Train Loss: 0.9784  |  Val Loss: 1.0676\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 650/1000] Train Loss: 0.9771  |  Val Loss: 1.1327\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 651/1000] Train Loss: 1.0167  |  Val Loss: 1.0711\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 652/1000] Train Loss: 0.9841  |  Val Loss: 1.0600\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 653/1000] Train Loss: 0.9741  |  Val Loss: 1.0801\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 654/1000] Train Loss: 0.9857  |  Val Loss: 1.0536\n",
      "Validation loss improved from 1.0554 to 1.0536.\n",
      "[Epoch 655/1000] Train Loss: 0.9769  |  Val Loss: 1.0694\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 656/1000] Train Loss: 0.9783  |  Val Loss: 1.0738\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 657/1000] Train Loss: 0.9717  |  Val Loss: 1.0654\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 658/1000] Train Loss: 0.9753  |  Val Loss: 1.1225\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 659/1000] Train Loss: 1.0056  |  Val Loss: 1.1314\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 660/1000] Train Loss: 1.0076  |  Val Loss: 1.0850\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 661/1000] Train Loss: 0.9905  |  Val Loss: 1.0629\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 662/1000] Train Loss: 0.9799  |  Val Loss: 1.0588\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 663/1000] Train Loss: 0.9748  |  Val Loss: 1.1159\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 664/1000] Train Loss: 1.0403  |  Val Loss: 1.0637\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 665/1000] Train Loss: 0.9997  |  Val Loss: 1.0970\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 666/1000] Train Loss: 0.9833  |  Val Loss: 1.0601\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 667/1000] Train Loss: 0.9937  |  Val Loss: 1.0702\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 668/1000] Train Loss: 1.0055  |  Val Loss: 1.1502\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 669/1000] Train Loss: 1.0690  |  Val Loss: 1.2269\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 670/1000] Train Loss: 1.0648  |  Val Loss: 1.0631\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 671/1000] Train Loss: 1.0667  |  Val Loss: 1.0959\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 672/1000] Train Loss: 1.0055  |  Val Loss: 1.0906\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 673/1000] Train Loss: 0.9900  |  Val Loss: 1.0794\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 674/1000] Train Loss: 1.0117  |  Val Loss: 1.0732\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 675/1000] Train Loss: 0.9774  |  Val Loss: 1.0523\n",
      "Validation loss improved from 1.0536 to 1.0523.\n",
      "[Epoch 676/1000] Train Loss: 0.9893  |  Val Loss: 1.0429\n",
      "Validation loss improved from 1.0523 to 1.0429.\n",
      "[Epoch 677/1000] Train Loss: 0.9671  |  Val Loss: 1.0677\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 678/1000] Train Loss: 1.0135  |  Val Loss: 1.1422\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 679/1000] Train Loss: 0.9952  |  Val Loss: 1.0856\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 680/1000] Train Loss: 0.9943  |  Val Loss: 1.0756\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 681/1000] Train Loss: 0.9865  |  Val Loss: 1.0534\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 682/1000] Train Loss: 0.9691  |  Val Loss: 1.0796\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 683/1000] Train Loss: 0.9918  |  Val Loss: 1.0986\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 684/1000] Train Loss: 0.9851  |  Val Loss: 1.0599\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 685/1000] Train Loss: 0.9632  |  Val Loss: 1.0496\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 686/1000] Train Loss: 0.9944  |  Val Loss: 1.0914\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 687/1000] Train Loss: 0.9770  |  Val Loss: 1.0861\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 688/1000] Train Loss: 0.9801  |  Val Loss: 1.0506\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 689/1000] Train Loss: 0.9567  |  Val Loss: 1.0737\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 690/1000] Train Loss: 0.9903  |  Val Loss: 1.0290\n",
      "Validation loss improved from 1.0429 to 1.0290.\n",
      "[Epoch 691/1000] Train Loss: 0.9859  |  Val Loss: 1.0705\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 692/1000] Train Loss: 0.9606  |  Val Loss: 1.0509\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 693/1000] Train Loss: 0.9698  |  Val Loss: 1.0577\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 694/1000] Train Loss: 0.9749  |  Val Loss: 1.0756\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 695/1000] Train Loss: 0.9795  |  Val Loss: 1.0645\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 696/1000] Train Loss: 0.9903  |  Val Loss: 1.0523\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 697/1000] Train Loss: 0.9544  |  Val Loss: 1.0582\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 698/1000] Train Loss: 0.9947  |  Val Loss: 1.0888\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 699/1000] Train Loss: 1.0137  |  Val Loss: 1.0878\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 700/1000] Train Loss: 0.9712  |  Val Loss: 1.0577\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 701/1000] Train Loss: 0.9720  |  Val Loss: 1.0302\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 702/1000] Train Loss: 0.9736  |  Val Loss: 1.0639\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 703/1000] Train Loss: 0.9618  |  Val Loss: 1.1568\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 704/1000] Train Loss: 1.0364  |  Val Loss: 1.0585\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 705/1000] Train Loss: 1.0008  |  Val Loss: 1.0640\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 706/1000] Train Loss: 0.9929  |  Val Loss: 1.0403\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 707/1000] Train Loss: 0.9574  |  Val Loss: 1.0324\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 708/1000] Train Loss: 0.9573  |  Val Loss: 1.0808\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 709/1000] Train Loss: 0.9672  |  Val Loss: 1.0360\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 710/1000] Train Loss: 0.9783  |  Val Loss: 1.0779\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 711/1000] Train Loss: 0.9836  |  Val Loss: 1.0525\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 712/1000] Train Loss: 0.9669  |  Val Loss: 1.0308\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 713/1000] Train Loss: 0.9591  |  Val Loss: 1.0882\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 714/1000] Train Loss: 0.9692  |  Val Loss: 1.0267\n",
      "Validation loss improved from 1.0290 to 1.0267.\n",
      "[Epoch 715/1000] Train Loss: 0.9785  |  Val Loss: 1.1670\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 716/1000] Train Loss: 1.0549  |  Val Loss: 1.0815\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 717/1000] Train Loss: 1.0082  |  Val Loss: 1.0329\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 718/1000] Train Loss: 0.9889  |  Val Loss: 1.0657\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 719/1000] Train Loss: 0.9662  |  Val Loss: 1.1012\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 720/1000] Train Loss: 0.9884  |  Val Loss: 1.0517\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 721/1000] Train Loss: 0.9678  |  Val Loss: 1.0381\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 722/1000] Train Loss: 0.9659  |  Val Loss: 1.0130\n",
      "Validation loss improved from 1.0267 to 1.0130.\n",
      "[Epoch 723/1000] Train Loss: 0.9660  |  Val Loss: 1.0142\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 724/1000] Train Loss: 0.9565  |  Val Loss: 1.0496\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 725/1000] Train Loss: 0.9610  |  Val Loss: 1.0360\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 726/1000] Train Loss: 0.9808  |  Val Loss: 1.0853\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 727/1000] Train Loss: 0.9734  |  Val Loss: 1.0760\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 728/1000] Train Loss: 0.9886  |  Val Loss: 1.0689\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 729/1000] Train Loss: 1.0285  |  Val Loss: 1.0689\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 730/1000] Train Loss: 0.9778  |  Val Loss: 1.0558\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 731/1000] Train Loss: 0.9882  |  Val Loss: 1.2483\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 732/1000] Train Loss: 1.0476  |  Val Loss: 1.1897\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 733/1000] Train Loss: 1.0129  |  Val Loss: 1.1608\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 734/1000] Train Loss: 1.0248  |  Val Loss: 1.0152\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 735/1000] Train Loss: 1.0098  |  Val Loss: 1.0181\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 736/1000] Train Loss: 0.9731  |  Val Loss: 1.0321\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 737/1000] Train Loss: 0.9763  |  Val Loss: 1.0262\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 738/1000] Train Loss: 0.9633  |  Val Loss: 1.0368\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 739/1000] Train Loss: 0.9630  |  Val Loss: 1.0478\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 740/1000] Train Loss: 0.9485  |  Val Loss: 1.0201\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 741/1000] Train Loss: 0.9486  |  Val Loss: 1.0511\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 742/1000] Train Loss: 0.9517  |  Val Loss: 1.0169\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 743/1000] Train Loss: 0.9435  |  Val Loss: 1.0367\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 744/1000] Train Loss: 0.9519  |  Val Loss: 1.0168\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 745/1000] Train Loss: 0.9446  |  Val Loss: 1.0534\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 746/1000] Train Loss: 0.9775  |  Val Loss: 1.0253\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 747/1000] Train Loss: 0.9451  |  Val Loss: 1.0178\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 748/1000] Train Loss: 0.9369  |  Val Loss: 1.0414\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 749/1000] Train Loss: 0.9566  |  Val Loss: 1.0343\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 750/1000] Train Loss: 0.9520  |  Val Loss: 1.0090\n",
      "Validation loss improved from 1.0130 to 1.0090.\n",
      "[Epoch 751/1000] Train Loss: 0.9422  |  Val Loss: 1.0176\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 752/1000] Train Loss: 0.9366  |  Val Loss: 1.0725\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 753/1000] Train Loss: 0.9613  |  Val Loss: 1.0854\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 754/1000] Train Loss: 0.9738  |  Val Loss: 1.0092\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 755/1000] Train Loss: 0.9388  |  Val Loss: 1.0165\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 756/1000] Train Loss: 0.9478  |  Val Loss: 1.0642\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 757/1000] Train Loss: 0.9772  |  Val Loss: 1.1054\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 758/1000] Train Loss: 0.9872  |  Val Loss: 1.0080\n",
      "Validation loss improved from 1.0090 to 1.0080.\n",
      "[Epoch 759/1000] Train Loss: 0.9829  |  Val Loss: 1.0494\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 760/1000] Train Loss: 0.9419  |  Val Loss: 1.1442\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 761/1000] Train Loss: 1.0187  |  Val Loss: 1.0838\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 762/1000] Train Loss: 0.9403  |  Val Loss: 1.0971\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 763/1000] Train Loss: 0.9800  |  Val Loss: 1.0166\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 764/1000] Train Loss: 0.9463  |  Val Loss: 1.0307\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 765/1000] Train Loss: 0.9289  |  Val Loss: 1.0229\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 766/1000] Train Loss: 0.9339  |  Val Loss: 1.0913\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 767/1000] Train Loss: 0.9693  |  Val Loss: 1.2106\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 768/1000] Train Loss: 1.0257  |  Val Loss: 1.0326\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 769/1000] Train Loss: 0.9401  |  Val Loss: 1.0089\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 770/1000] Train Loss: 0.9231  |  Val Loss: 0.9927\n",
      "Validation loss improved from 1.0080 to 0.9927.\n",
      "[Epoch 771/1000] Train Loss: 0.9251  |  Val Loss: 1.0158\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 772/1000] Train Loss: 0.9404  |  Val Loss: 1.0264\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 773/1000] Train Loss: 0.9528  |  Val Loss: 1.0242\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 774/1000] Train Loss: 0.9618  |  Val Loss: 1.0269\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 775/1000] Train Loss: 0.9458  |  Val Loss: 1.0001\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 776/1000] Train Loss: 0.9479  |  Val Loss: 1.0294\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 777/1000] Train Loss: 0.9384  |  Val Loss: 1.0225\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 778/1000] Train Loss: 0.9379  |  Val Loss: 0.9855\n",
      "Validation loss improved from 0.9927 to 0.9855.\n",
      "[Epoch 779/1000] Train Loss: 0.9212  |  Val Loss: 1.0052\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 780/1000] Train Loss: 0.9217  |  Val Loss: 0.9978\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 781/1000] Train Loss: 0.9172  |  Val Loss: 0.9979\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 782/1000] Train Loss: 0.9195  |  Val Loss: 1.0520\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 783/1000] Train Loss: 0.9397  |  Val Loss: 0.9903\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 784/1000] Train Loss: 0.9387  |  Val Loss: 1.0089\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 785/1000] Train Loss: 0.9255  |  Val Loss: 0.9977\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 786/1000] Train Loss: 0.9219  |  Val Loss: 1.0246\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 787/1000] Train Loss: 0.9224  |  Val Loss: 1.0367\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 788/1000] Train Loss: 0.9334  |  Val Loss: 1.0000\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 789/1000] Train Loss: 0.9137  |  Val Loss: 0.9902\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 790/1000] Train Loss: 0.9229  |  Val Loss: 1.0177\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 791/1000] Train Loss: 0.9604  |  Val Loss: 1.0450\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 792/1000] Train Loss: 0.9295  |  Val Loss: 0.9934\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 793/1000] Train Loss: 0.9375  |  Val Loss: 1.0173\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 794/1000] Train Loss: 0.9222  |  Val Loss: 0.9808\n",
      "Validation loss improved from 0.9855 to 0.9808.\n",
      "[Epoch 795/1000] Train Loss: 0.9199  |  Val Loss: 0.9811\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 796/1000] Train Loss: 0.9119  |  Val Loss: 0.9797\n",
      "Validation loss improved from 0.9808 to 0.9797.\n",
      "[Epoch 797/1000] Train Loss: 0.9168  |  Val Loss: 0.9695\n",
      "Validation loss improved from 0.9797 to 0.9695.\n",
      "[Epoch 798/1000] Train Loss: 0.9165  |  Val Loss: 0.9942\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 799/1000] Train Loss: 0.9309  |  Val Loss: 1.0075\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 800/1000] Train Loss: 0.9205  |  Val Loss: 0.9984\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 801/1000] Train Loss: 0.9133  |  Val Loss: 0.9981\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 802/1000] Train Loss: 0.9132  |  Val Loss: 0.9794\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 803/1000] Train Loss: 0.9166  |  Val Loss: 1.0424\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 804/1000] Train Loss: 0.9399  |  Val Loss: 1.0728\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 805/1000] Train Loss: 0.9568  |  Val Loss: 1.0227\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 806/1000] Train Loss: 0.9713  |  Val Loss: 1.0344\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 807/1000] Train Loss: 0.9495  |  Val Loss: 1.0491\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 808/1000] Train Loss: 0.9446  |  Val Loss: 0.9982\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 809/1000] Train Loss: 0.9286  |  Val Loss: 1.0034\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 810/1000] Train Loss: 0.9451  |  Val Loss: 1.0381\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 811/1000] Train Loss: 0.9388  |  Val Loss: 0.9831\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 812/1000] Train Loss: 0.9153  |  Val Loss: 0.9879\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 813/1000] Train Loss: 0.9138  |  Val Loss: 1.0150\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 814/1000] Train Loss: 0.9185  |  Val Loss: 0.9635\n",
      "Validation loss improved from 0.9695 to 0.9635.\n",
      "[Epoch 815/1000] Train Loss: 0.9295  |  Val Loss: 1.0209\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 816/1000] Train Loss: 0.9473  |  Val Loss: 0.9764\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 817/1000] Train Loss: 0.9455  |  Val Loss: 1.0570\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 818/1000] Train Loss: 0.9388  |  Val Loss: 1.0231\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 819/1000] Train Loss: 0.9109  |  Val Loss: 1.0066\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 820/1000] Train Loss: 0.9491  |  Val Loss: 1.0726\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 821/1000] Train Loss: 0.9789  |  Val Loss: 1.0244\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 822/1000] Train Loss: 0.9519  |  Val Loss: 0.9770\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 823/1000] Train Loss: 0.9241  |  Val Loss: 0.9847\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 824/1000] Train Loss: 0.9197  |  Val Loss: 1.0110\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 825/1000] Train Loss: 0.9178  |  Val Loss: 0.9844\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 826/1000] Train Loss: 0.8988  |  Val Loss: 0.9618\n",
      "Validation loss improved from 0.9635 to 0.9618.\n",
      "[Epoch 827/1000] Train Loss: 0.8953  |  Val Loss: 0.9484\n",
      "Validation loss improved from 0.9618 to 0.9484.\n",
      "[Epoch 828/1000] Train Loss: 0.8953  |  Val Loss: 0.9679\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 829/1000] Train Loss: 0.8953  |  Val Loss: 0.9668\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 830/1000] Train Loss: 0.9131  |  Val Loss: 1.0590\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 831/1000] Train Loss: 0.9328  |  Val Loss: 1.1171\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 832/1000] Train Loss: 0.9332  |  Val Loss: 0.9771\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 833/1000] Train Loss: 0.8972  |  Val Loss: 0.9789\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 834/1000] Train Loss: 0.8928  |  Val Loss: 0.9627\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 835/1000] Train Loss: 0.8919  |  Val Loss: 0.9744\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 836/1000] Train Loss: 0.8896  |  Val Loss: 0.9539\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 837/1000] Train Loss: 0.8900  |  Val Loss: 0.9829\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 838/1000] Train Loss: 0.8906  |  Val Loss: 0.9613\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 839/1000] Train Loss: 0.9087  |  Val Loss: 1.0125\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 840/1000] Train Loss: 0.8965  |  Val Loss: 0.9702\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 841/1000] Train Loss: 0.9053  |  Val Loss: 0.9776\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 842/1000] Train Loss: 0.9012  |  Val Loss: 1.0062\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 843/1000] Train Loss: 0.9256  |  Val Loss: 0.9656\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 844/1000] Train Loss: 0.9125  |  Val Loss: 0.9903\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 845/1000] Train Loss: 0.9239  |  Val Loss: 0.9604\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 846/1000] Train Loss: 0.9138  |  Val Loss: 1.0092\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 847/1000] Train Loss: 0.9149  |  Val Loss: 0.9669\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 848/1000] Train Loss: 0.9045  |  Val Loss: 1.0316\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 849/1000] Train Loss: 0.9691  |  Val Loss: 1.1148\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 850/1000] Train Loss: 0.9457  |  Val Loss: 1.0814\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 851/1000] Train Loss: 0.9226  |  Val Loss: 1.0050\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 852/1000] Train Loss: 0.8975  |  Val Loss: 0.9882\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 853/1000] Train Loss: 0.8808  |  Val Loss: 0.9774\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 854/1000] Train Loss: 0.8822  |  Val Loss: 0.9498\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 855/1000] Train Loss: 0.8885  |  Val Loss: 0.9805\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 856/1000] Train Loss: 0.8873  |  Val Loss: 1.0245\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 857/1000] Train Loss: 0.9019  |  Val Loss: 0.9945\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 858/1000] Train Loss: 0.9143  |  Val Loss: 0.9730\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 859/1000] Train Loss: 0.9222  |  Val Loss: 1.0920\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 860/1000] Train Loss: 0.9797  |  Val Loss: 1.2177\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 861/1000] Train Loss: 0.9711  |  Val Loss: 1.0744\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 862/1000] Train Loss: 0.9806  |  Val Loss: 0.9486\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 863/1000] Train Loss: 0.9289  |  Val Loss: 1.0774\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 864/1000] Train Loss: 0.9616  |  Val Loss: 1.0880\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 865/1000] Train Loss: 0.9573  |  Val Loss: 1.0083\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 866/1000] Train Loss: 0.9149  |  Val Loss: 0.9773\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 867/1000] Train Loss: 0.8967  |  Val Loss: 0.9830\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 868/1000] Train Loss: 0.8991  |  Val Loss: 0.9667\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 869/1000] Train Loss: 0.9008  |  Val Loss: 0.9328\n",
      "Validation loss improved from 0.9484 to 0.9328.\n",
      "[Epoch 870/1000] Train Loss: 0.8849  |  Val Loss: 0.9453\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 871/1000] Train Loss: 0.8876  |  Val Loss: 0.9520\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 872/1000] Train Loss: 0.8806  |  Val Loss: 0.9556\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 873/1000] Train Loss: 0.8795  |  Val Loss: 0.9527\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 874/1000] Train Loss: 0.8934  |  Val Loss: 1.0015\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 875/1000] Train Loss: 0.8979  |  Val Loss: 0.9341\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 876/1000] Train Loss: 0.8824  |  Val Loss: 0.9373\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 877/1000] Train Loss: 0.8769  |  Val Loss: 0.9502\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 878/1000] Train Loss: 0.8989  |  Val Loss: 1.0019\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 879/1000] Train Loss: 0.8833  |  Val Loss: 0.9649\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 880/1000] Train Loss: 0.8735  |  Val Loss: 0.9516\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 881/1000] Train Loss: 0.8766  |  Val Loss: 0.9814\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 882/1000] Train Loss: 0.8864  |  Val Loss: 0.9426\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 883/1000] Train Loss: 0.8799  |  Val Loss: 0.9614\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 884/1000] Train Loss: 0.8633  |  Val Loss: 0.9882\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 885/1000] Train Loss: 0.8945  |  Val Loss: 0.9548\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 886/1000] Train Loss: 0.8690  |  Val Loss: 0.9404\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 887/1000] Train Loss: 0.8658  |  Val Loss: 0.9749\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 888/1000] Train Loss: 0.8708  |  Val Loss: 0.9453\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 889/1000] Train Loss: 0.8681  |  Val Loss: 0.9830\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 890/1000] Train Loss: 0.8969  |  Val Loss: 0.9640\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 891/1000] Train Loss: 0.8811  |  Val Loss: 0.9475\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 892/1000] Train Loss: 0.8596  |  Val Loss: 0.9521\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 893/1000] Train Loss: 0.8899  |  Val Loss: 0.9532\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 894/1000] Train Loss: 0.8859  |  Val Loss: 0.9650\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 895/1000] Train Loss: 0.8860  |  Val Loss: 0.9389\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 896/1000] Train Loss: 0.9017  |  Val Loss: 0.9589\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 897/1000] Train Loss: 0.8743  |  Val Loss: 0.9409\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 898/1000] Train Loss: 0.8674  |  Val Loss: 0.9610\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 899/1000] Train Loss: 0.8669  |  Val Loss: 0.9684\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 900/1000] Train Loss: 0.8864  |  Val Loss: 0.9332\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 901/1000] Train Loss: 0.8641  |  Val Loss: 0.9527\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 902/1000] Train Loss: 0.8757  |  Val Loss: 0.9686\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 903/1000] Train Loss: 0.8914  |  Val Loss: 0.9562\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 904/1000] Train Loss: 0.8834  |  Val Loss: 0.9408\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 905/1000] Train Loss: 0.8766  |  Val Loss: 0.9798\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 906/1000] Train Loss: 0.8714  |  Val Loss: 0.9391\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 907/1000] Train Loss: 0.8663  |  Val Loss: 0.9538\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 908/1000] Train Loss: 0.8525  |  Val Loss: 0.9472\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 909/1000] Train Loss: 0.8804  |  Val Loss: 1.0085\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 910/1000] Train Loss: 0.9078  |  Val Loss: 0.9534\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 911/1000] Train Loss: 0.8497  |  Val Loss: 0.9639\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 912/1000] Train Loss: 0.8805  |  Val Loss: 0.9712\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 913/1000] Train Loss: 0.8555  |  Val Loss: 0.9559\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 914/1000] Train Loss: 0.8781  |  Val Loss: 0.9774\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 915/1000] Train Loss: 0.9030  |  Val Loss: 0.9810\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 916/1000] Train Loss: 0.9529  |  Val Loss: 1.0084\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 917/1000] Train Loss: 0.9355  |  Val Loss: 1.0598\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 918/1000] Train Loss: 0.9909  |  Val Loss: 1.3403\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 919/1000] Train Loss: 1.0715  |  Val Loss: 1.1460\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 920/1000] Train Loss: 0.9837  |  Val Loss: 0.9864\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 921/1000] Train Loss: 0.9238  |  Val Loss: 0.9563\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 922/1000] Train Loss: 0.8699  |  Val Loss: 0.9491\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 923/1000] Train Loss: 0.8687  |  Val Loss: 0.9470\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 924/1000] Train Loss: 0.8621  |  Val Loss: 0.9318\n",
      "Validation loss improved from 0.9328 to 0.9318.\n",
      "[Epoch 925/1000] Train Loss: 0.8816  |  Val Loss: 0.9409\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 926/1000] Train Loss: 0.8780  |  Val Loss: 1.0250\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 927/1000] Train Loss: 0.8698  |  Val Loss: 0.9925\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 928/1000] Train Loss: 0.8958  |  Val Loss: 0.9334\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 929/1000] Train Loss: 0.8601  |  Val Loss: 0.9603\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 930/1000] Train Loss: 0.8627  |  Val Loss: 0.9192\n",
      "Validation loss improved from 0.9318 to 0.9192.\n",
      "[Epoch 931/1000] Train Loss: 0.8439  |  Val Loss: 0.9253\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 932/1000] Train Loss: 0.8767  |  Val Loss: 1.0492\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 933/1000] Train Loss: 0.8952  |  Val Loss: 0.9388\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 934/1000] Train Loss: 0.8649  |  Val Loss: 0.9522\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 935/1000] Train Loss: 0.8665  |  Val Loss: 0.9605\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 936/1000] Train Loss: 0.8636  |  Val Loss: 0.9124\n",
      "Validation loss improved from 0.9192 to 0.9124.\n",
      "[Epoch 937/1000] Train Loss: 0.8612  |  Val Loss: 0.9248\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 938/1000] Train Loss: 0.8700  |  Val Loss: 0.9298\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 939/1000] Train Loss: 0.8601  |  Val Loss: 1.0141\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 940/1000] Train Loss: 0.8955  |  Val Loss: 0.9293\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 941/1000] Train Loss: 0.8769  |  Val Loss: 0.9869\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 942/1000] Train Loss: 0.8583  |  Val Loss: 0.9342\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 943/1000] Train Loss: 0.8554  |  Val Loss: 0.9452\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 944/1000] Train Loss: 0.9255  |  Val Loss: 1.0262\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 945/1000] Train Loss: 0.9069  |  Val Loss: 1.0070\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 946/1000] Train Loss: 0.9266  |  Val Loss: 0.9264\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 947/1000] Train Loss: 0.9151  |  Val Loss: 1.0204\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 948/1000] Train Loss: 0.8720  |  Val Loss: 1.0045\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 949/1000] Train Loss: 0.9025  |  Val Loss: 0.9705\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 950/1000] Train Loss: 0.9244  |  Val Loss: 0.9959\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 951/1000] Train Loss: 0.9000  |  Val Loss: 1.0939\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 952/1000] Train Loss: 0.9202  |  Val Loss: 1.0317\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 953/1000] Train Loss: 0.8991  |  Val Loss: 0.9217\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 954/1000] Train Loss: 0.8604  |  Val Loss: 0.9821\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 955/1000] Train Loss: 0.8852  |  Val Loss: 1.0232\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 956/1000] Train Loss: 0.9226  |  Val Loss: 0.9644\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 957/1000] Train Loss: 0.8871  |  Val Loss: 0.9060\n",
      "Validation loss improved from 0.9124 to 0.9060.\n",
      "[Epoch 958/1000] Train Loss: 0.9152  |  Val Loss: 1.0185\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 959/1000] Train Loss: 0.8701  |  Val Loss: 0.9384\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 960/1000] Train Loss: 0.8519  |  Val Loss: 0.9289\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 961/1000] Train Loss: 0.8457  |  Val Loss: 0.9183\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 962/1000] Train Loss: 0.8503  |  Val Loss: 0.9329\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 963/1000] Train Loss: 0.8506  |  Val Loss: 0.9211\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 964/1000] Train Loss: 0.8475  |  Val Loss: 0.9060\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 965/1000] Train Loss: 0.8435  |  Val Loss: 0.9148\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 966/1000] Train Loss: 0.8385  |  Val Loss: 0.9448\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 967/1000] Train Loss: 0.8375  |  Val Loss: 0.9083\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 968/1000] Train Loss: 0.8275  |  Val Loss: 0.8923\n",
      "Validation loss improved from 0.9060 to 0.8923.\n",
      "[Epoch 969/1000] Train Loss: 0.8309  |  Val Loss: 0.9256\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 970/1000] Train Loss: 0.8410  |  Val Loss: 0.9388\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 971/1000] Train Loss: 0.8357  |  Val Loss: 0.9720\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 972/1000] Train Loss: 0.8624  |  Val Loss: 0.9207\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 973/1000] Train Loss: 0.8447  |  Val Loss: 0.9052\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 974/1000] Train Loss: 0.8322  |  Val Loss: 0.9014\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 975/1000] Train Loss: 0.8233  |  Val Loss: 0.9094\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 976/1000] Train Loss: 0.8358  |  Val Loss: 0.8968\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 977/1000] Train Loss: 0.8310  |  Val Loss: 0.9243\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 978/1000] Train Loss: 0.8288  |  Val Loss: 0.9110\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 979/1000] Train Loss: 0.8325  |  Val Loss: 0.9521\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 980/1000] Train Loss: 0.8405  |  Val Loss: 0.9366\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 981/1000] Train Loss: 0.8541  |  Val Loss: 0.9571\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 982/1000] Train Loss: 0.9425  |  Val Loss: 0.9985\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 983/1000] Train Loss: 0.9389  |  Val Loss: 0.9829\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 984/1000] Train Loss: 0.9626  |  Val Loss: 1.1794\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 985/1000] Train Loss: 0.9446  |  Val Loss: 1.0475\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 986/1000] Train Loss: 0.9423  |  Val Loss: 0.9433\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 987/1000] Train Loss: 0.8849  |  Val Loss: 0.9230\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 988/1000] Train Loss: 0.8693  |  Val Loss: 0.9397\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 989/1000] Train Loss: 0.8423  |  Val Loss: 0.8977\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 990/1000] Train Loss: 0.8258  |  Val Loss: 0.9070\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 991/1000] Train Loss: 0.8147  |  Val Loss: 0.9115\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 992/1000] Train Loss: 0.8352  |  Val Loss: 0.8912\n",
      "Validation loss improved from 0.8923 to 0.8912.\n",
      "[Epoch 993/1000] Train Loss: 0.8310  |  Val Loss: 0.9099\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 994/1000] Train Loss: 0.8251  |  Val Loss: 0.9034\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 995/1000] Train Loss: 0.8254  |  Val Loss: 0.8918\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 996/1000] Train Loss: 0.8172  |  Val Loss: 0.8885\n",
      "Validation loss improved from 0.8912 to 0.8885.\n",
      "[Epoch 997/1000] Train Loss: 0.8498  |  Val Loss: 0.9189\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 998/1000] Train Loss: 0.8294  |  Val Loss: 0.8882\n",
      "Validation loss improved from 0.8885 to 0.8882.\n",
      "[Epoch 999/1000] Train Loss: 0.8265  |  Val Loss: 0.9482\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 1000/1000] Train Loss: 0.8693  |  Val Loss: 0.9908\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_input_dim = cae_mlp_train_reps.shape[1]\n",
    "cae_mlp_num_classes = len(torch.unique(cae_mlp_train_labels_torch))\n",
    "cae_mlp_model = MLPClassifier(cae_mlp_input_dim, cae_mlp_num_classes).to(device)\n",
    "\n",
    "cae_mlp_criterion = nn.CrossEntropyLoss()\n",
    "cae_mlp_optimizer = optim.Adam(cae_mlp_model.parameters(), lr=1e-3)\n",
    "\n",
    "cae_mlp_num_epochs = 1000\n",
    "cae_mlp_patience = 100\n",
    "\n",
    "cae_mlp_train_losses = []\n",
    "cae_mlp_val_losses = []\n",
    "\n",
    "cae_mlp_best_val_loss = float('inf')\n",
    "cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for cae_mlp_epoch in range(cae_mlp_num_epochs):\n",
    "    # Training\n",
    "    cae_mlp_model.train()\n",
    "    cae_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for cae_mlp_embeddings_batch, cae_mlp_labels_batch in cae_mlp_train_loader:\n",
    "        cae_mlp_embeddings_batch = cae_mlp_embeddings_batch.to(device)\n",
    "        cae_mlp_labels_batch = cae_mlp_labels_batch.to(device)\n",
    "        \n",
    "        cae_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        cae_mlp_outputs = cae_mlp_model(cae_mlp_embeddings_batch)\n",
    "        cae_mlp_loss = cae_mlp_criterion(cae_mlp_outputs, cae_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        cae_mlp_loss.backward()\n",
    "        cae_mlp_optimizer.step()\n",
    "        \n",
    "        cae_mlp_train_running_loss += cae_mlp_loss.item() * cae_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    cae_mlp_epoch_train_loss = cae_mlp_train_running_loss / len(cae_mlp_train_loader.dataset)\n",
    "    cae_mlp_train_losses.append(cae_mlp_epoch_train_loss)\n",
    "\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    cae_mlp_model.eval()\n",
    "    cae_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for cae_mlp_val_embeddings_batch, cae_mlp_val_labels_batch in cae_mlp_val_loader:\n",
    "            cae_mlp_val_embeddings_batch = cae_mlp_val_embeddings_batch.to(device)\n",
    "            cae_mlp_val_labels_batch = cae_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            cae_mlp_val_outputs = cae_mlp_model(cae_mlp_val_embeddings_batch)\n",
    "            cae_mlp_val_loss = cae_mlp_criterion(cae_mlp_val_outputs, cae_mlp_val_labels_batch)\n",
    "\n",
    "            cae_mlp_val_running_loss += cae_mlp_val_loss.item() * cae_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    cae_mlp_epoch_val_loss = cae_mlp_val_running_loss / len(cae_mlp_val_loader.dataset)\n",
    "    cae_mlp_val_losses.append(cae_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {cae_mlp_epoch+1}/{cae_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {cae_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {cae_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "\n",
    "    if cae_mlp_epoch_val_loss < cae_mlp_best_val_loss:\n",
    "        # improvement, reset patience\n",
    "        print(f\"Validation loss improved from {cae_mlp_best_val_loss:.4f} to {cae_mlp_epoch_val_loss:.4f}.\")\n",
    "        cae_mlp_best_val_loss = cae_mlp_epoch_val_loss\n",
    "        cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        cae_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {cae_mlp_epochs_without_improvement}/{cae_mlp_patience}\")\n",
    "        \n",
    "        if cae_mlp_epochs_without_improvement >= cae_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {cae_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {cae_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(cae_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(cae_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:02.222361Z",
     "iopub.status.busy": "2025-05-08T19:18:02.222361Z",
     "iopub.status.idle": "2025-05-08T19:18:02.384454Z",
     "shell.execute_reply": "2025-05-08T19:18:02.384454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CAE+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 1.1621 | Test Accuracy: 52.24%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_model.eval()\n",
    "\n",
    "cae_mlp_test_running_loss = 0.0\n",
    "cae_mlp_test_correct = 0\n",
    "cae_mlp_all_predictions = []\n",
    "cae_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cae_mlp_test_embeddings_batch, cae_mlp_test_labels_batch in cae_mlp_test_loader:\n",
    "        cae_mlp_test_embeddings_batch = cae_mlp_test_embeddings_batch.to(device)\n",
    "        cae_mlp_test_labels_batch = cae_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        cae_mlp_test_outputs = cae_mlp_model(cae_mlp_test_embeddings_batch)\n",
    "        \n",
    "        cae_mlp_test_loss_batch = cae_mlp_criterion(cae_mlp_test_outputs, cae_mlp_test_labels_batch)\n",
    "        cae_mlp_test_running_loss += cae_mlp_test_loss_batch.item() * cae_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, cae_mlp_test_predicted = torch.max(cae_mlp_test_outputs, dim=1)\n",
    "        cae_mlp_test_correct += (cae_mlp_test_predicted == cae_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        #saving predictions for conf matrix\n",
    "        cae_mlp_all_predictions.extend(cae_mlp_test_predicted.cpu().numpy())\n",
    "        cae_mlp_all_true_labels.extend(cae_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_predictions.npy'), np.array(cae_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_true_labels.npy'), np.array(cae_mlp_all_true_labels))\n",
    "print(f\"Saved CAE+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "cae_mlp_epoch_test_loss = cae_mlp_test_running_loss / len(cae_mlp_test_loader.dataset)\n",
    "cae_mlp_test_accuracy = cae_mlp_test_correct / len(cae_mlp_test_loader.dataset)\n",
    "\n",
    "cae_mlp_test_accuracy_pct = cae_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {cae_mlp_epoch_test_loss:.4f} | Test Accuracy: {cae_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "cae_mlp_num_epochs_run = len(cae_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         [cae_mlp_epoch_test_loss]*cae_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical SCL with Cosine Similarity (Supervised Contrastive Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:02.386460Z",
     "iopub.status.busy": "2025-05-08T19:18:02.386460Z",
     "iopub.status.idle": "2025-05-08T19:18:02.395507Z",
     "shell.execute_reply": "2025-05-08T19:18:02.395507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 280 samples with 64 features each\n",
      "LOG: Labels shape: (280,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2898 samples with 64 features each\n",
      "LOG: Labels shape: (2898,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (280, 64), \n",
      "Train labels shape: (280,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (70, 64), \n",
      "Val labels shape: (70,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (2898, 64), \n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "tscl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "tscl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "tscl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "tscl_train_embeddings, tscl_train_labels = load_encoded_data(tscl_encoded_train_dir)\n",
    "tscl_val_embeddings, tscl_val_labels = load_encoded_data(tscl_encoded_val_dir)\n",
    "tscl_test_embeddings, tscl_test_labels = load_encoded_data(tscl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {tscl_train_embeddings.shape}, \\nTrain labels shape: {tscl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {tscl_val_embeddings.shape}, \\nVal labels shape: {tscl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {tscl_test_embeddings.shape}, \\nTest labels shape: {tscl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:02.397512Z",
     "iopub.status.busy": "2025-05-08T19:18:02.397512Z",
     "iopub.status.idle": "2025-05-08T19:18:02.407455Z",
     "shell.execute_reply": "2025-05-08T19:18:02.407455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20}\n",
      "Training batch size: 280\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "tscl_train_embeddings = tscl_train_embeddings.reshape(tscl_train_embeddings.shape[0], -1)\n",
    "tscl_val_embeddings = tscl_val_embeddings.reshape(tscl_val_embeddings.shape[0], -1)\n",
    "tscl_test_embeddings = tscl_test_embeddings.reshape(tscl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "tscl_train_mean = np.mean(tscl_train_embeddings, axis=0)\n",
    "tscl_train_std = np.std(tscl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "tscl_train_embeddings = (tscl_train_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_val_embeddings = (tscl_val_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_test_embeddings = (tscl_test_embeddings - tscl_train_mean) / tscl_train_std\n",
    "\n",
    "tscl_train_dataset = TensorDataset(torch.tensor(tscl_train_embeddings, dtype=torch.float32), torch.tensor(tscl_train_labels, dtype=torch.long))\n",
    "tscl_val_dataset = TensorDataset(torch.tensor(tscl_val_embeddings, dtype=torch.float32), torch.tensor(tscl_val_labels, dtype=torch.long))\n",
    "tscl_test_dataset = TensorDataset(torch.tensor(tscl_test_embeddings, dtype=torch.float32), torch.tensor(tscl_test_labels, dtype=torch.long))\n",
    "\n",
    "tscl_m = 20\n",
    "tscl_num_classes = len(np.unique(tscl_train_labels))\n",
    "\n",
    "# Calculate theoretical required batch size\n",
    "tscl_required_batch_size = tscl_m * tscl_num_classes\n",
    "\n",
    "# Ensure batch size doesn't exceed training set size\n",
    "if tscl_required_batch_size > len(tscl_train_dataset):\n",
    "    #case 1: Not enough samples - reduce m proportionally\n",
    "    tscl_max_possible_m = len(tscl_train_dataset) // tscl_num_classes\n",
    "    tscl_m = max(1, tscl_max_possible_m)  # Ensure m >= 1\n",
    "    tscl_batch_size_train = tscl_m * tscl_num_classes\n",
    "else:\n",
    "    #case 2: Use full batch size\n",
    "    tscl_batch_size_train = tscl_required_batch_size\n",
    "\n",
    "tscl_sampler = MPerClassSampler(labels = tscl_train_labels, m = tscl_m, batch_size = tscl_batch_size_train, length_before_new_iter=len(tscl_train_dataset))\n",
    "tscl_train_loader = DataLoader(tscl_train_dataset, batch_size=tscl_batch_size_train, sampler=tscl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "tscl_dataloader_bs = 256\n",
    "tscl_val_loader = DataLoader(tscl_val_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "tscl_test_loader = DataLoader(tscl_test_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for tscl_X_batch, tscl_y_batch in tscl_train_loader:\n",
    "    tscl_unique, tscl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(tscl_unique, tscl_counts)))\n",
    "    print(f\"Training batch size: {tscl_batch_size_train}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:02.410460Z",
     "iopub.status.busy": "2025-05-08T19:18:02.409459Z",
     "iopub.status.idle": "2025-05-08T19:18:02.414966Z",
     "shell.execute_reply": "2025-05-08T19:18:02.414966Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature = 0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        #normalize feat vectors\n",
    "        features = F.normalize(features, p=2, dim = 1)\n",
    "\n",
    "        #compute cosine simi matrix\n",
    "        similarity_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "\n",
    "        #create a mask for +ve pairs - i.e. same class\n",
    "        labels = labels.unsqueeze(1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(features.device)\n",
    "\n",
    "        #loss computation\n",
    "        exp_sim = torch.exp(similarity_matrix)\n",
    "        log_prob = similarity_matrix - torch.log(exp_sim.sum(dim = 1, keepdim=True))\n",
    "\n",
    "        #mask out diagonal - i.e. self similarity\n",
    "        mask_self = torch.eye(mask.shape[0], dtype = torch.bool).to(features.device)\n",
    "        mask = mask * (~mask_self)\n",
    "\n",
    "        #handling edge cases when there is no +ve pair\n",
    "        mask_pos_pairs = mask.sum(dim=1)\n",
    "        mask_pos_pairs = torch.where(mask_pos_pairs < 1e-6, 1, mask_pos_pairs)\n",
    "\n",
    "        loss = -(mask * log_prob).sum(dim=1) / mask_pos_pairs\n",
    "\n",
    "        return loss.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:02.416971Z",
     "iopub.status.busy": "2025-05-08T19:18:02.416971Z",
     "iopub.status.idle": "2025-05-08T19:18:02.421146Z",
     "shell.execute_reply": "2025-05-08T19:18:02.421146Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128), #expects input of shape (batch_size, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #flattening input tensor\n",
    "        #x = x.view(x.size(0), -1)  #reshaping -> (batch_size, channels * height * width)\n",
    "        projections = self.projection_head(x)\n",
    "        return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:02.423681Z",
     "iopub.status.busy": "2025-05-08T19:18:02.423681Z",
     "iopub.status.idle": "2025-05-08T19:18:14.767890Z",
     "shell.execute_reply": "2025-05-08T19:18:14.767890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 8.5188\n",
      "Epoch [1/2000], Avg Train Loss: 8.5188\n",
      "Epoch [1/2000], Avg Val Loss: 3.4108\n",
      "Validation loss improved from inf to 3.4108. Saving model...\n",
      "\n",
      "LOG: Epoch [2/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.3631\n",
      "Epoch [2/2000], Avg Train Loss: 8.3631\n",
      "Epoch [2/2000], Avg Val Loss: 3.3985\n",
      "Validation loss improved from 3.4108 to 3.3985. Saving model...\n",
      "\n",
      "LOG: Epoch [3/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.3216\n",
      "Epoch [3/2000], Avg Train Loss: 8.3216\n",
      "Epoch [3/2000], Avg Val Loss: 3.3866\n",
      "Validation loss improved from 3.3985 to 3.3866. Saving model...\n",
      "\n",
      "LOG: Epoch [4/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.2011\n",
      "Epoch [4/2000], Avg Train Loss: 8.2011\n",
      "Epoch [4/2000], Avg Val Loss: 3.3754\n",
      "Validation loss improved from 3.3866 to 3.3754. Saving model...\n",
      "\n",
      "LOG: Epoch [5/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.2828\n",
      "Epoch [5/2000], Avg Train Loss: 8.2828\n",
      "Epoch [5/2000], Avg Val Loss: 3.3649\n",
      "Validation loss improved from 3.3754 to 3.3649. Saving model...\n",
      "\n",
      "LOG: Epoch [6/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.0844\n",
      "Epoch [6/2000], Avg Train Loss: 8.0844\n",
      "Epoch [6/2000], Avg Val Loss: 3.3551\n",
      "Validation loss improved from 3.3649 to 3.3551. Saving model...\n",
      "\n",
      "LOG: Epoch [7/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.0300\n",
      "Epoch [7/2000], Avg Train Loss: 8.0300\n",
      "Epoch [7/2000], Avg Val Loss: 3.3460\n",
      "Validation loss improved from 3.3551 to 3.3460. Saving model...\n",
      "\n",
      "LOG: Epoch [8/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.9423\n",
      "Epoch [8/2000], Avg Train Loss: 7.9423\n",
      "Epoch [8/2000], Avg Val Loss: 3.3372\n",
      "Validation loss improved from 3.3460 to 3.3372. Saving model...\n",
      "\n",
      "LOG: Epoch [9/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.5977\n",
      "Epoch [9/2000], Avg Train Loss: 7.5977\n",
      "Epoch [9/2000], Avg Val Loss: 3.3289\n",
      "Validation loss improved from 3.3372 to 3.3289. Saving model...\n",
      "\n",
      "LOG: Epoch [10/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.7324\n",
      "Epoch [10/2000], Avg Train Loss: 7.7324\n",
      "Epoch [10/2000], Avg Val Loss: 3.3212\n",
      "Validation loss improved from 3.3289 to 3.3212. Saving model...\n",
      "\n",
      "LOG: Epoch [11/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.7688\n",
      "Epoch [11/2000], Avg Train Loss: 7.7688\n",
      "Epoch [11/2000], Avg Val Loss: 3.3140\n",
      "Validation loss improved from 3.3212 to 3.3140. Saving model...\n",
      "\n",
      "LOG: Epoch [12/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.6216\n",
      "Epoch [12/2000], Avg Train Loss: 7.6216\n",
      "Epoch [12/2000], Avg Val Loss: 3.3073\n",
      "Validation loss improved from 3.3140 to 3.3073. Saving model...\n",
      "\n",
      "LOG: Epoch [13/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.5854\n",
      "Epoch [13/2000], Avg Train Loss: 7.5854\n",
      "Epoch [13/2000], Avg Val Loss: 3.3011\n",
      "Validation loss improved from 3.3073 to 3.3011. Saving model...\n",
      "\n",
      "LOG: Epoch [14/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.4886\n",
      "Epoch [14/2000], Avg Train Loss: 7.4886\n",
      "Epoch [14/2000], Avg Val Loss: 3.2952\n",
      "Validation loss improved from 3.3011 to 3.2952. Saving model...\n",
      "\n",
      "LOG: Epoch [15/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.4486\n",
      "Epoch [15/2000], Avg Train Loss: 7.4486\n",
      "Epoch [15/2000], Avg Val Loss: 3.2897\n",
      "Validation loss improved from 3.2952 to 3.2897. Saving model...\n",
      "\n",
      "LOG: Epoch [16/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 7.3446\n",
      "Epoch [16/2000], Avg Train Loss: 7.3446\n",
      "Epoch [16/2000], Avg Val Loss: 3.2845\n",
      "Validation loss improved from 3.2897 to 3.2845. Saving model...\n",
      "\n",
      "LOG: Epoch [17/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.2863\n",
      "Epoch [17/2000], Avg Train Loss: 7.2863\n",
      "Epoch [17/2000], Avg Val Loss: 3.2797\n",
      "Validation loss improved from 3.2845 to 3.2797. Saving model...\n",
      "\n",
      "LOG: Epoch [18/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.2034\n",
      "Epoch [18/2000], Avg Train Loss: 7.2034\n",
      "Epoch [18/2000], Avg Val Loss: 3.2753\n",
      "Validation loss improved from 3.2797 to 3.2753. Saving model...\n",
      "\n",
      "LOG: Epoch [19/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.2537\n",
      "Epoch [19/2000], Avg Train Loss: 7.2537\n",
      "Epoch [19/2000], Avg Val Loss: 3.2711\n",
      "Validation loss improved from 3.2753 to 3.2711. Saving model...\n",
      "\n",
      "LOG: Epoch [20/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.1358\n",
      "Epoch [20/2000], Avg Train Loss: 7.1358\n",
      "Epoch [20/2000], Avg Val Loss: 3.2671\n",
      "Validation loss improved from 3.2711 to 3.2671. Saving model...\n",
      "\n",
      "LOG: Epoch [21/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.1194\n",
      "Epoch [21/2000], Avg Train Loss: 7.1194\n",
      "Epoch [21/2000], Avg Val Loss: 3.2633\n",
      "Validation loss improved from 3.2671 to 3.2633. Saving model...\n",
      "\n",
      "LOG: Epoch [22/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.0737\n",
      "Epoch [22/2000], Avg Train Loss: 7.0737\n",
      "Epoch [22/2000], Avg Val Loss: 3.2598\n",
      "Validation loss improved from 3.2633 to 3.2598. Saving model...\n",
      "\n",
      "LOG: Epoch [23/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.1580\n",
      "Epoch [23/2000], Avg Train Loss: 7.1580\n",
      "Epoch [23/2000], Avg Val Loss: 3.2566\n",
      "Validation loss improved from 3.2598 to 3.2566. Saving model...\n",
      "\n",
      "LOG: Epoch [24/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 6.9958\n",
      "Epoch [24/2000], Avg Train Loss: 6.9958\n",
      "Epoch [24/2000], Avg Val Loss: 3.2537\n",
      "Validation loss improved from 3.2566 to 3.2537. Saving model...\n",
      "\n",
      "LOG: Epoch [25/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.7288\n",
      "Epoch [25/2000], Avg Train Loss: 6.7288\n",
      "Epoch [25/2000], Avg Val Loss: 3.2510\n",
      "Validation loss improved from 3.2537 to 3.2510. Saving model...\n",
      "\n",
      "LOG: Epoch [26/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.7764\n",
      "Epoch [26/2000], Avg Train Loss: 6.7764\n",
      "Epoch [26/2000], Avg Val Loss: 3.2486\n",
      "Validation loss improved from 3.2510 to 3.2486. Saving model...\n",
      "\n",
      "LOG: Epoch [27/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.7655\n",
      "Epoch [27/2000], Avg Train Loss: 6.7655\n",
      "Epoch [27/2000], Avg Val Loss: 3.2463\n",
      "Validation loss improved from 3.2486 to 3.2463. Saving model...\n",
      "\n",
      "LOG: Epoch [28/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.7516\n",
      "Epoch [28/2000], Avg Train Loss: 6.7516\n",
      "Epoch [28/2000], Avg Val Loss: 3.2442\n",
      "Validation loss improved from 3.2463 to 3.2442. Saving model...\n",
      "\n",
      "LOG: Epoch [29/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6758\n",
      "Epoch [29/2000], Avg Train Loss: 6.6758\n",
      "Epoch [29/2000], Avg Val Loss: 3.2422\n",
      "Validation loss improved from 3.2442 to 3.2422. Saving model...\n",
      "\n",
      "LOG: Epoch [30/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6261\n",
      "Epoch [30/2000], Avg Train Loss: 6.6261\n",
      "Epoch [30/2000], Avg Val Loss: 3.2405\n",
      "Validation loss improved from 3.2422 to 3.2405. Saving model...\n",
      "\n",
      "LOG: Epoch [31/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.5513\n",
      "Epoch [31/2000], Avg Train Loss: 6.5513\n",
      "Epoch [31/2000], Avg Val Loss: 3.2388\n",
      "Validation loss improved from 3.2405 to 3.2388. Saving model...\n",
      "\n",
      "LOG: Epoch [32/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.5245\n",
      "Epoch [32/2000], Avg Train Loss: 6.5245\n",
      "Epoch [32/2000], Avg Val Loss: 3.2373\n",
      "Validation loss improved from 3.2388 to 3.2373. Saving model...\n",
      "\n",
      "LOG: Epoch [33/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.4332\n",
      "Epoch [33/2000], Avg Train Loss: 6.4332\n",
      "Epoch [33/2000], Avg Val Loss: 3.2360\n",
      "Validation loss improved from 3.2373 to 3.2360. Saving model...\n",
      "\n",
      "LOG: Epoch [34/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3624\n",
      "Epoch [34/2000], Avg Train Loss: 6.3624\n",
      "Epoch [34/2000], Avg Val Loss: 3.2347\n",
      "Validation loss improved from 3.2360 to 3.2347. Saving model...\n",
      "\n",
      "LOG: Epoch [35/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3020\n",
      "Epoch [35/2000], Avg Train Loss: 6.3020\n",
      "Epoch [35/2000], Avg Val Loss: 3.2336\n",
      "Validation loss improved from 3.2347 to 3.2336. Saving model...\n",
      "\n",
      "LOG: Epoch [36/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3264\n",
      "Epoch [36/2000], Avg Train Loss: 6.3264\n",
      "Epoch [36/2000], Avg Val Loss: 3.2325\n",
      "Validation loss improved from 3.2336 to 3.2325. Saving model...\n",
      "\n",
      "LOG: Epoch [37/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 6.2968\n",
      "Epoch [37/2000], Avg Train Loss: 6.2968\n",
      "Epoch [37/2000], Avg Val Loss: 3.2316\n",
      "Validation loss improved from 3.2325 to 3.2316. Saving model...\n",
      "\n",
      "LOG: Epoch [38/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2943\n",
      "Epoch [38/2000], Avg Train Loss: 6.2943\n",
      "Epoch [38/2000], Avg Val Loss: 3.2307\n",
      "Validation loss improved from 3.2316 to 3.2307. Saving model...\n",
      "\n",
      "LOG: Epoch [39/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1303\n",
      "Epoch [39/2000], Avg Train Loss: 6.1303\n",
      "Epoch [39/2000], Avg Val Loss: 3.2299\n",
      "Validation loss improved from 3.2307 to 3.2299. Saving model...\n",
      "\n",
      "LOG: Epoch [40/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2772\n",
      "Epoch [40/2000], Avg Train Loss: 6.2772\n",
      "Epoch [40/2000], Avg Val Loss: 3.2291\n",
      "Validation loss improved from 3.2299 to 3.2291. Saving model...\n",
      "\n",
      "LOG: Epoch [41/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1906\n",
      "Epoch [41/2000], Avg Train Loss: 6.1906\n",
      "Epoch [41/2000], Avg Val Loss: 3.2285\n",
      "Validation loss improved from 3.2291 to 3.2285. Saving model...\n",
      "\n",
      "LOG: Epoch [42/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1535\n",
      "Epoch [42/2000], Avg Train Loss: 6.1535\n",
      "Epoch [42/2000], Avg Val Loss: 3.2278\n",
      "Validation loss improved from 3.2285 to 3.2278. Saving model...\n",
      "\n",
      "LOG: Epoch [43/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0267\n",
      "Epoch [43/2000], Avg Train Loss: 6.0267\n",
      "Epoch [43/2000], Avg Val Loss: 3.2272\n",
      "Validation loss improved from 3.2278 to 3.2272. Saving model...\n",
      "\n",
      "LOG: Epoch [44/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1201\n",
      "Epoch [44/2000], Avg Train Loss: 6.1201\n",
      "Epoch [44/2000], Avg Val Loss: 3.2266\n",
      "Validation loss improved from 3.2272 to 3.2266. Saving model...\n",
      "\n",
      "LOG: Epoch [45/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1031\n",
      "Epoch [45/2000], Avg Train Loss: 6.1031\n",
      "Epoch [45/2000], Avg Val Loss: 3.2260\n",
      "Validation loss improved from 3.2266 to 3.2260. Saving model...\n",
      "\n",
      "LOG: Epoch [46/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9994\n",
      "Epoch [46/2000], Avg Train Loss: 5.9994\n",
      "Epoch [46/2000], Avg Val Loss: 3.2255\n",
      "Validation loss improved from 3.2260 to 3.2255. Saving model...\n",
      "\n",
      "LOG: Epoch [47/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0370\n",
      "Epoch [47/2000], Avg Train Loss: 6.0370\n",
      "Epoch [47/2000], Avg Val Loss: 3.2251\n",
      "Validation loss improved from 3.2255 to 3.2251. Saving model...\n",
      "\n",
      "LOG: Epoch [48/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9747\n",
      "Epoch [48/2000], Avg Train Loss: 5.9747\n",
      "Epoch [48/2000], Avg Val Loss: 3.2248\n",
      "Validation loss improved from 3.2251 to 3.2248. Saving model...\n",
      "\n",
      "LOG: Epoch [49/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9105\n",
      "Epoch [49/2000], Avg Train Loss: 5.9105\n",
      "Epoch [49/2000], Avg Val Loss: 3.2244\n",
      "Validation loss improved from 3.2248 to 3.2244. Saving model...\n",
      "\n",
      "LOG: Epoch [50/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8684\n",
      "Epoch [50/2000], Avg Train Loss: 5.8684\n",
      "Epoch [50/2000], Avg Val Loss: 3.2240\n",
      "Validation loss improved from 3.2244 to 3.2240. Saving model...\n",
      "\n",
      "LOG: Epoch [51/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9357\n",
      "Epoch [51/2000], Avg Train Loss: 5.9357\n",
      "Epoch [51/2000], Avg Val Loss: 3.2237\n",
      "Validation loss improved from 3.2240 to 3.2237. Saving model...\n",
      "\n",
      "LOG: Epoch [52/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9124\n",
      "Epoch [52/2000], Avg Train Loss: 5.9124\n",
      "Epoch [52/2000], Avg Val Loss: 3.2234\n",
      "Validation loss improved from 3.2237 to 3.2234. Saving model...\n",
      "\n",
      "LOG: Epoch [53/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7189\n",
      "Epoch [53/2000], Avg Train Loss: 5.7189\n",
      "Epoch [53/2000], Avg Val Loss: 3.2231\n",
      "Validation loss improved from 3.2234 to 3.2231. Saving model...\n",
      "\n",
      "LOG: Epoch [54/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.6939\n",
      "Epoch [54/2000], Avg Train Loss: 5.6939\n",
      "Epoch [54/2000], Avg Val Loss: 3.2228\n",
      "Validation loss improved from 3.2231 to 3.2228. Saving model...\n",
      "\n",
      "LOG: Epoch [55/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7171\n",
      "Epoch [55/2000], Avg Train Loss: 5.7171\n",
      "Epoch [55/2000], Avg Val Loss: 3.2225\n",
      "Validation loss improved from 3.2228 to 3.2225. Saving model...\n",
      "\n",
      "LOG: Epoch [56/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7833\n",
      "Epoch [56/2000], Avg Train Loss: 5.7833\n",
      "Epoch [56/2000], Avg Val Loss: 3.2222\n",
      "Validation loss improved from 3.2225 to 3.2222. Saving model...\n",
      "\n",
      "LOG: Epoch [57/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6918\n",
      "Epoch [57/2000], Avg Train Loss: 5.6918\n",
      "Epoch [57/2000], Avg Val Loss: 3.2219\n",
      "Validation loss improved from 3.2222 to 3.2219. Saving model...\n",
      "\n",
      "LOG: Epoch [58/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7495\n",
      "Epoch [58/2000], Avg Train Loss: 5.7495\n",
      "Epoch [58/2000], Avg Val Loss: 3.2217\n",
      "Validation loss improved from 3.2219 to 3.2217. Saving model...\n",
      "\n",
      "LOG: Epoch [59/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6836\n",
      "Epoch [59/2000], Avg Train Loss: 5.6836\n",
      "Epoch [59/2000], Avg Val Loss: 3.2214\n",
      "Validation loss improved from 3.2217 to 3.2214. Saving model...\n",
      "\n",
      "LOG: Epoch [60/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6528\n",
      "Epoch [60/2000], Avg Train Loss: 5.6528\n",
      "Epoch [60/2000], Avg Val Loss: 3.2212\n",
      "Validation loss improved from 3.2214 to 3.2212. Saving model...\n",
      "\n",
      "LOG: Epoch [61/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6556\n",
      "Epoch [61/2000], Avg Train Loss: 5.6556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/2000], Avg Val Loss: 3.2209\n",
      "Validation loss improved from 3.2212 to 3.2209. Saving model...\n",
      "\n",
      "LOG: Epoch [62/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6276\n",
      "Epoch [62/2000], Avg Train Loss: 5.6276\n",
      "Epoch [62/2000], Avg Val Loss: 3.2207\n",
      "Validation loss improved from 3.2209 to 3.2207. Saving model...\n",
      "\n",
      "LOG: Epoch [63/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6364\n",
      "Epoch [63/2000], Avg Train Loss: 5.6364\n",
      "Epoch [63/2000], Avg Val Loss: 3.2205\n",
      "Validation loss improved from 3.2207 to 3.2205. Saving model...\n",
      "\n",
      "LOG: Epoch [64/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6329\n",
      "Epoch [64/2000], Avg Train Loss: 5.6329\n",
      "Epoch [64/2000], Avg Val Loss: 3.2202\n",
      "Validation loss improved from 3.2205 to 3.2202. Saving model...\n",
      "\n",
      "LOG: Epoch [65/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6025\n",
      "Epoch [65/2000], Avg Train Loss: 5.6025\n",
      "Epoch [65/2000], Avg Val Loss: 3.2199\n",
      "Validation loss improved from 3.2202 to 3.2199. Saving model...\n",
      "\n",
      "LOG: Epoch [66/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5684\n",
      "Epoch [66/2000], Avg Train Loss: 5.5684\n",
      "Epoch [66/2000], Avg Val Loss: 3.2196\n",
      "Validation loss improved from 3.2199 to 3.2196. Saving model...\n",
      "\n",
      "LOG: Epoch [67/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5689\n",
      "Epoch [67/2000], Avg Train Loss: 5.5689\n",
      "Epoch [67/2000], Avg Val Loss: 3.2193\n",
      "Validation loss improved from 3.2196 to 3.2193. Saving model...\n",
      "\n",
      "LOG: Epoch [68/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5444\n",
      "Epoch [68/2000], Avg Train Loss: 5.5444\n",
      "Epoch [68/2000], Avg Val Loss: 3.2189\n",
      "Validation loss improved from 3.2193 to 3.2189. Saving model...\n",
      "\n",
      "LOG: Epoch [69/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4815\n",
      "Epoch [69/2000], Avg Train Loss: 5.4815\n",
      "Epoch [69/2000], Avg Val Loss: 3.2186\n",
      "Validation loss improved from 3.2189 to 3.2186. Saving model...\n",
      "\n",
      "LOG: Epoch [70/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4817\n",
      "Epoch [70/2000], Avg Train Loss: 5.4817\n",
      "Epoch [70/2000], Avg Val Loss: 3.2182\n",
      "Validation loss improved from 3.2186 to 3.2182. Saving model...\n",
      "\n",
      "LOG: Epoch [71/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4626\n",
      "Epoch [71/2000], Avg Train Loss: 5.4626\n",
      "Epoch [71/2000], Avg Val Loss: 3.2178\n",
      "Validation loss improved from 3.2182 to 3.2178. Saving model...\n",
      "\n",
      "LOG: Epoch [72/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4425\n",
      "Epoch [72/2000], Avg Train Loss: 5.4425\n",
      "Epoch [72/2000], Avg Val Loss: 3.2174\n",
      "Validation loss improved from 3.2178 to 3.2174. Saving model...\n",
      "\n",
      "LOG: Epoch [73/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5353\n",
      "Epoch [73/2000], Avg Train Loss: 5.5353\n",
      "Epoch [73/2000], Avg Val Loss: 3.2171\n",
      "Validation loss improved from 3.2174 to 3.2171. Saving model...\n",
      "\n",
      "LOG: Epoch [74/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.4543\n",
      "Epoch [74/2000], Avg Train Loss: 5.4543\n",
      "Epoch [74/2000], Avg Val Loss: 3.2167\n",
      "Validation loss improved from 3.2171 to 3.2167. Saving model...\n",
      "\n",
      "LOG: Epoch [75/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4874\n",
      "Epoch [75/2000], Avg Train Loss: 5.4874\n",
      "Epoch [75/2000], Avg Val Loss: 3.2164\n",
      "Validation loss improved from 3.2167 to 3.2164. Saving model...\n",
      "\n",
      "LOG: Epoch [76/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4418\n",
      "Epoch [76/2000], Avg Train Loss: 5.4418\n",
      "Epoch [76/2000], Avg Val Loss: 3.2160\n",
      "Validation loss improved from 3.2164 to 3.2160. Saving model...\n",
      "\n",
      "LOG: Epoch [77/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4379\n",
      "Epoch [77/2000], Avg Train Loss: 5.4379\n",
      "Epoch [77/2000], Avg Val Loss: 3.2156\n",
      "Validation loss improved from 3.2160 to 3.2156. Saving model...\n",
      "\n",
      "LOG: Epoch [78/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3468\n",
      "Epoch [78/2000], Avg Train Loss: 5.3468\n",
      "Epoch [78/2000], Avg Val Loss: 3.2153\n",
      "Validation loss improved from 3.2156 to 3.2153. Saving model...\n",
      "\n",
      "LOG: Epoch [79/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3708\n",
      "Epoch [79/2000], Avg Train Loss: 5.3708\n",
      "Epoch [79/2000], Avg Val Loss: 3.2149\n",
      "Validation loss improved from 3.2153 to 3.2149. Saving model...\n",
      "\n",
      "LOG: Epoch [80/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3185\n",
      "Epoch [80/2000], Avg Train Loss: 5.3185\n",
      "Epoch [80/2000], Avg Val Loss: 3.2144\n",
      "Validation loss improved from 3.2149 to 3.2144. Saving model...\n",
      "\n",
      "LOG: Epoch [81/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4127\n",
      "Epoch [81/2000], Avg Train Loss: 5.4127\n",
      "Epoch [81/2000], Avg Val Loss: 3.2140\n",
      "Validation loss improved from 3.2144 to 3.2140. Saving model...\n",
      "\n",
      "LOG: Epoch [82/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3374\n",
      "Epoch [82/2000], Avg Train Loss: 5.3374\n",
      "Epoch [82/2000], Avg Val Loss: 3.2135\n",
      "Validation loss improved from 3.2140 to 3.2135. Saving model...\n",
      "\n",
      "LOG: Epoch [83/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3783\n",
      "Epoch [83/2000], Avg Train Loss: 5.3783\n",
      "Epoch [83/2000], Avg Val Loss: 3.2131\n",
      "Validation loss improved from 3.2135 to 3.2131. Saving model...\n",
      "\n",
      "LOG: Epoch [84/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3352\n",
      "Epoch [84/2000], Avg Train Loss: 5.3352\n",
      "Epoch [84/2000], Avg Val Loss: 3.2127\n",
      "Validation loss improved from 3.2131 to 3.2127. Saving model...\n",
      "\n",
      "LOG: Epoch [85/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3965\n",
      "Epoch [85/2000], Avg Train Loss: 5.3965\n",
      "Epoch [85/2000], Avg Val Loss: 3.2122\n",
      "Validation loss improved from 3.2127 to 3.2122. Saving model...\n",
      "\n",
      "LOG: Epoch [86/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3209\n",
      "Epoch [86/2000], Avg Train Loss: 5.3209\n",
      "Epoch [86/2000], Avg Val Loss: 3.2118\n",
      "Validation loss improved from 3.2122 to 3.2118. Saving model...\n",
      "\n",
      "LOG: Epoch [87/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3308\n",
      "Epoch [87/2000], Avg Train Loss: 5.3308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/2000], Avg Val Loss: 3.2114\n",
      "Validation loss improved from 3.2118 to 3.2114. Saving model...\n",
      "\n",
      "LOG: Epoch [88/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3530\n",
      "Epoch [88/2000], Avg Train Loss: 5.3530\n",
      "Epoch [88/2000], Avg Val Loss: 3.2109\n",
      "Validation loss improved from 3.2114 to 3.2109. Saving model...\n",
      "\n",
      "LOG: Epoch [89/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3286\n",
      "Epoch [89/2000], Avg Train Loss: 5.3286\n",
      "Epoch [89/2000], Avg Val Loss: 3.2105\n",
      "Validation loss improved from 3.2109 to 3.2105. Saving model...\n",
      "\n",
      "LOG: Epoch [90/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2957\n",
      "Epoch [90/2000], Avg Train Loss: 5.2957\n",
      "Epoch [90/2000], Avg Val Loss: 3.2101\n",
      "Validation loss improved from 3.2105 to 3.2101. Saving model...\n",
      "\n",
      "LOG: Epoch [91/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2618\n",
      "Epoch [91/2000], Avg Train Loss: 5.2618\n",
      "Epoch [91/2000], Avg Val Loss: 3.2097\n",
      "Validation loss improved from 3.2101 to 3.2097. Saving model...\n",
      "\n",
      "LOG: Epoch [92/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2561\n",
      "Epoch [92/2000], Avg Train Loss: 5.2561\n",
      "Epoch [92/2000], Avg Val Loss: 3.2092\n",
      "Validation loss improved from 3.2097 to 3.2092. Saving model...\n",
      "\n",
      "LOG: Epoch [93/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2581\n",
      "Epoch [93/2000], Avg Train Loss: 5.2581\n",
      "Epoch [93/2000], Avg Val Loss: 3.2087\n",
      "Validation loss improved from 3.2092 to 3.2087. Saving model...\n",
      "\n",
      "LOG: Epoch [94/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2599\n",
      "Epoch [94/2000], Avg Train Loss: 5.2599\n",
      "Epoch [94/2000], Avg Val Loss: 3.2083\n",
      "Validation loss improved from 3.2087 to 3.2083. Saving model...\n",
      "\n",
      "LOG: Epoch [95/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2613\n",
      "Epoch [95/2000], Avg Train Loss: 5.2613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/2000], Avg Val Loss: 3.2078\n",
      "Validation loss improved from 3.2083 to 3.2078. Saving model...\n",
      "\n",
      "LOG: Epoch [96/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2785\n",
      "Epoch [96/2000], Avg Train Loss: 5.2785\n",
      "Epoch [96/2000], Avg Val Loss: 3.2073\n",
      "Validation loss improved from 3.2078 to 3.2073. Saving model...\n",
      "\n",
      "LOG: Epoch [97/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2291\n",
      "Epoch [97/2000], Avg Train Loss: 5.2291\n",
      "Epoch [97/2000], Avg Val Loss: 3.2068\n",
      "Validation loss improved from 3.2073 to 3.2068. Saving model...\n",
      "\n",
      "LOG: Epoch [98/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1821\n",
      "Epoch [98/2000], Avg Train Loss: 5.1821\n",
      "Epoch [98/2000], Avg Val Loss: 3.2063\n",
      "Validation loss improved from 3.2068 to 3.2063. Saving model...\n",
      "\n",
      "LOG: Epoch [99/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2521\n",
      "Epoch [99/2000], Avg Train Loss: 5.2521\n",
      "Epoch [99/2000], Avg Val Loss: 3.2058\n",
      "Validation loss improved from 3.2063 to 3.2058. Saving model...\n",
      "\n",
      "LOG: Epoch [100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2074\n",
      "Epoch [100/2000], Avg Train Loss: 5.2074\n",
      "Epoch [100/2000], Avg Val Loss: 3.2052\n",
      "Validation loss improved from 3.2058 to 3.2052. Saving model...\n",
      "\n",
      "LOG: Epoch [101/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2108\n",
      "Epoch [101/2000], Avg Train Loss: 5.2108\n",
      "Epoch [101/2000], Avg Val Loss: 3.2047\n",
      "Validation loss improved from 3.2052 to 3.2047. Saving model...\n",
      "\n",
      "LOG: Epoch [102/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1535\n",
      "Epoch [102/2000], Avg Train Loss: 5.1535\n",
      "Epoch [102/2000], Avg Val Loss: 3.2041\n",
      "Validation loss improved from 3.2047 to 3.2041. Saving model...\n",
      "\n",
      "LOG: Epoch [103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1888\n",
      "Epoch [103/2000], Avg Train Loss: 5.1888\n",
      "Epoch [103/2000], Avg Val Loss: 3.2035\n",
      "Validation loss improved from 3.2041 to 3.2035. Saving model...\n",
      "\n",
      "LOG: Epoch [104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1655\n",
      "Epoch [104/2000], Avg Train Loss: 5.1655\n",
      "Epoch [104/2000], Avg Val Loss: 3.2029\n",
      "Validation loss improved from 3.2035 to 3.2029. Saving model...\n",
      "\n",
      "LOG: Epoch [105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1421\n",
      "Epoch [105/2000], Avg Train Loss: 5.1421\n",
      "Epoch [105/2000], Avg Val Loss: 3.2022\n",
      "Validation loss improved from 3.2029 to 3.2022. Saving model...\n",
      "\n",
      "LOG: Epoch [106/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.1526\n",
      "Epoch [106/2000], Avg Train Loss: 5.1526\n",
      "Epoch [106/2000], Avg Val Loss: 3.2016\n",
      "Validation loss improved from 3.2022 to 3.2016. Saving model...\n",
      "\n",
      "LOG: Epoch [107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1719\n",
      "Epoch [107/2000], Avg Train Loss: 5.1719\n",
      "Epoch [107/2000], Avg Val Loss: 3.2009\n",
      "Validation loss improved from 3.2016 to 3.2009. Saving model...\n",
      "\n",
      "LOG: Epoch [108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1173\n",
      "Epoch [108/2000], Avg Train Loss: 5.1173\n",
      "Epoch [108/2000], Avg Val Loss: 3.2002\n",
      "Validation loss improved from 3.2009 to 3.2002. Saving model...\n",
      "\n",
      "LOG: Epoch [109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1761\n",
      "Epoch [109/2000], Avg Train Loss: 5.1761\n",
      "Epoch [109/2000], Avg Val Loss: 3.1995\n",
      "Validation loss improved from 3.2002 to 3.1995. Saving model...\n",
      "\n",
      "LOG: Epoch [110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1546\n",
      "Epoch [110/2000], Avg Train Loss: 5.1546\n",
      "Epoch [110/2000], Avg Val Loss: 3.1988\n",
      "Validation loss improved from 3.1995 to 3.1988. Saving model...\n",
      "\n",
      "LOG: Epoch [111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1582\n",
      "Epoch [111/2000], Avg Train Loss: 5.1582\n",
      "Epoch [111/2000], Avg Val Loss: 3.1981\n",
      "Validation loss improved from 3.1988 to 3.1981. Saving model...\n",
      "\n",
      "LOG: Epoch [112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1830\n",
      "Epoch [112/2000], Avg Train Loss: 5.1830\n",
      "Epoch [112/2000], Avg Val Loss: 3.1974\n",
      "Validation loss improved from 3.1981 to 3.1974. Saving model...\n",
      "\n",
      "LOG: Epoch [113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1181\n",
      "Epoch [113/2000], Avg Train Loss: 5.1181\n",
      "Epoch [113/2000], Avg Val Loss: 3.1967\n",
      "Validation loss improved from 3.1974 to 3.1967. Saving model...\n",
      "\n",
      "LOG: Epoch [114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1485\n",
      "Epoch [114/2000], Avg Train Loss: 5.1485\n",
      "Epoch [114/2000], Avg Val Loss: 3.1959\n",
      "Validation loss improved from 3.1967 to 3.1959. Saving model...\n",
      "\n",
      "LOG: Epoch [115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1450\n",
      "Epoch [115/2000], Avg Train Loss: 5.1450\n",
      "Epoch [115/2000], Avg Val Loss: 3.1952\n",
      "Validation loss improved from 3.1959 to 3.1952. Saving model...\n",
      "\n",
      "LOG: Epoch [116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1171\n",
      "Epoch [116/2000], Avg Train Loss: 5.1171\n",
      "Epoch [116/2000], Avg Val Loss: 3.1944\n",
      "Validation loss improved from 3.1952 to 3.1944. Saving model...\n",
      "\n",
      "LOG: Epoch [117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0955\n",
      "Epoch [117/2000], Avg Train Loss: 5.0955\n",
      "Epoch [117/2000], Avg Val Loss: 3.1936\n",
      "Validation loss improved from 3.1944 to 3.1936. Saving model...\n",
      "\n",
      "LOG: Epoch [118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1185\n",
      "Epoch [118/2000], Avg Train Loss: 5.1185\n",
      "Epoch [118/2000], Avg Val Loss: 3.1928\n",
      "Validation loss improved from 3.1936 to 3.1928. Saving model...\n",
      "\n",
      "LOG: Epoch [119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1047\n",
      "Epoch [119/2000], Avg Train Loss: 5.1047\n",
      "Epoch [119/2000], Avg Val Loss: 3.1920\n",
      "Validation loss improved from 3.1928 to 3.1920. Saving model...\n",
      "\n",
      "LOG: Epoch [120/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1121\n",
      "Epoch [120/2000], Avg Train Loss: 5.1121\n",
      "Epoch [120/2000], Avg Val Loss: 3.1913\n",
      "Validation loss improved from 3.1920 to 3.1913. Saving model...\n",
      "\n",
      "LOG: Epoch [121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0575\n",
      "Epoch [121/2000], Avg Train Loss: 5.0575\n",
      "Epoch [121/2000], Avg Val Loss: 3.1905\n",
      "Validation loss improved from 3.1913 to 3.1905. Saving model...\n",
      "\n",
      "LOG: Epoch [122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0568\n",
      "Epoch [122/2000], Avg Train Loss: 5.0568\n",
      "Epoch [122/2000], Avg Val Loss: 3.1897\n",
      "Validation loss improved from 3.1905 to 3.1897. Saving model...\n",
      "\n",
      "LOG: Epoch [123/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.1125\n",
      "Epoch [123/2000], Avg Train Loss: 5.1125\n",
      "Epoch [123/2000], Avg Val Loss: 3.1889\n",
      "Validation loss improved from 3.1897 to 3.1889. Saving model...\n",
      "\n",
      "LOG: Epoch [124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0672\n",
      "Epoch [124/2000], Avg Train Loss: 5.0672\n",
      "Epoch [124/2000], Avg Val Loss: 3.1881\n",
      "Validation loss improved from 3.1889 to 3.1881. Saving model...\n",
      "\n",
      "LOG: Epoch [125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0941\n",
      "Epoch [125/2000], Avg Train Loss: 5.0941\n",
      "Epoch [125/2000], Avg Val Loss: 3.1873\n",
      "Validation loss improved from 3.1881 to 3.1873. Saving model...\n",
      "\n",
      "LOG: Epoch [126/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0516\n",
      "Epoch [126/2000], Avg Train Loss: 5.0516\n",
      "Epoch [126/2000], Avg Val Loss: 3.1865\n",
      "Validation loss improved from 3.1873 to 3.1865. Saving model...\n",
      "\n",
      "LOG: Epoch [127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0427\n",
      "Epoch [127/2000], Avg Train Loss: 5.0427\n",
      "Epoch [127/2000], Avg Val Loss: 3.1856\n",
      "Validation loss improved from 3.1865 to 3.1856. Saving model...\n",
      "\n",
      "LOG: Epoch [128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0219\n",
      "Epoch [128/2000], Avg Train Loss: 5.0219\n",
      "Epoch [128/2000], Avg Val Loss: 3.1847\n",
      "Validation loss improved from 3.1856 to 3.1847. Saving model...\n",
      "\n",
      "LOG: Epoch [129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0267\n",
      "Epoch [129/2000], Avg Train Loss: 5.0267\n",
      "Epoch [129/2000], Avg Val Loss: 3.1839\n",
      "Validation loss improved from 3.1847 to 3.1839. Saving model...\n",
      "\n",
      "LOG: Epoch [130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0587\n",
      "Epoch [130/2000], Avg Train Loss: 5.0587\n",
      "Epoch [130/2000], Avg Val Loss: 3.1830\n",
      "Validation loss improved from 3.1839 to 3.1830. Saving model...\n",
      "\n",
      "LOG: Epoch [131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0379\n",
      "Epoch [131/2000], Avg Train Loss: 5.0379\n",
      "Epoch [131/2000], Avg Val Loss: 3.1821\n",
      "Validation loss improved from 3.1830 to 3.1821. Saving model...\n",
      "\n",
      "LOG: Epoch [132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0566\n",
      "Epoch [132/2000], Avg Train Loss: 5.0566\n",
      "Epoch [132/2000], Avg Val Loss: 3.1813\n",
      "Validation loss improved from 3.1821 to 3.1813. Saving model...\n",
      "\n",
      "LOG: Epoch [133/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.0285\n",
      "Epoch [133/2000], Avg Train Loss: 5.0285\n",
      "Epoch [133/2000], Avg Val Loss: 3.1804\n",
      "Validation loss improved from 3.1813 to 3.1804. Saving model...\n",
      "\n",
      "LOG: Epoch [134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0142\n",
      "Epoch [134/2000], Avg Train Loss: 5.0142\n",
      "Epoch [134/2000], Avg Val Loss: 3.1795\n",
      "Validation loss improved from 3.1804 to 3.1795. Saving model...\n",
      "\n",
      "LOG: Epoch [135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0732\n",
      "Epoch [135/2000], Avg Train Loss: 5.0732\n",
      "Epoch [135/2000], Avg Val Loss: 3.1786\n",
      "Validation loss improved from 3.1795 to 3.1786. Saving model...\n",
      "\n",
      "LOG: Epoch [136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0365\n",
      "Epoch [136/2000], Avg Train Loss: 5.0365\n",
      "Epoch [136/2000], Avg Val Loss: 3.1777\n",
      "Validation loss improved from 3.1786 to 3.1777. Saving model...\n",
      "\n",
      "LOG: Epoch [137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9818\n",
      "Epoch [137/2000], Avg Train Loss: 4.9818\n",
      "Epoch [137/2000], Avg Val Loss: 3.1767\n",
      "Validation loss improved from 3.1777 to 3.1767. Saving model...\n",
      "\n",
      "LOG: Epoch [138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9946\n",
      "Epoch [138/2000], Avg Train Loss: 4.9946\n",
      "Epoch [138/2000], Avg Val Loss: 3.1758\n",
      "Validation loss improved from 3.1767 to 3.1758. Saving model...\n",
      "\n",
      "LOG: Epoch [139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0127\n",
      "Epoch [139/2000], Avg Train Loss: 5.0127\n",
      "Epoch [139/2000], Avg Val Loss: 3.1749\n",
      "Validation loss improved from 3.1758 to 3.1749. Saving model...\n",
      "\n",
      "LOG: Epoch [140/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9980\n",
      "Epoch [140/2000], Avg Train Loss: 4.9980\n",
      "Epoch [140/2000], Avg Val Loss: 3.1740\n",
      "Validation loss improved from 3.1749 to 3.1740. Saving model...\n",
      "\n",
      "LOG: Epoch [141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0395\n",
      "Epoch [141/2000], Avg Train Loss: 5.0395\n",
      "Epoch [141/2000], Avg Val Loss: 3.1731\n",
      "Validation loss improved from 3.1740 to 3.1731. Saving model...\n",
      "\n",
      "LOG: Epoch [142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9542\n",
      "Epoch [142/2000], Avg Train Loss: 4.9542\n",
      "Epoch [142/2000], Avg Val Loss: 3.1721\n",
      "Validation loss improved from 3.1731 to 3.1721. Saving model...\n",
      "\n",
      "LOG: Epoch [143/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.0360\n",
      "Epoch [143/2000], Avg Train Loss: 5.0360\n",
      "Epoch [143/2000], Avg Val Loss: 3.1712\n",
      "Validation loss improved from 3.1721 to 3.1712. Saving model...\n",
      "\n",
      "LOG: Epoch [144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9900\n",
      "Epoch [144/2000], Avg Train Loss: 4.9900\n",
      "Epoch [144/2000], Avg Val Loss: 3.1703\n",
      "Validation loss improved from 3.1712 to 3.1703. Saving model...\n",
      "\n",
      "LOG: Epoch [145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0387\n",
      "Epoch [145/2000], Avg Train Loss: 5.0387\n",
      "Epoch [145/2000], Avg Val Loss: 3.1694\n",
      "Validation loss improved from 3.1703 to 3.1694. Saving model...\n",
      "\n",
      "LOG: Epoch [146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9623\n",
      "Epoch [146/2000], Avg Train Loss: 4.9623\n",
      "Epoch [146/2000], Avg Val Loss: 3.1684\n",
      "Validation loss improved from 3.1694 to 3.1684. Saving model...\n",
      "\n",
      "LOG: Epoch [147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9732\n",
      "Epoch [147/2000], Avg Train Loss: 4.9732\n",
      "Epoch [147/2000], Avg Val Loss: 3.1675\n",
      "Validation loss improved from 3.1684 to 3.1675. Saving model...\n",
      "\n",
      "LOG: Epoch [148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9897\n",
      "Epoch [148/2000], Avg Train Loss: 4.9897\n",
      "Epoch [148/2000], Avg Val Loss: 3.1665\n",
      "Validation loss improved from 3.1675 to 3.1665. Saving model...\n",
      "\n",
      "LOG: Epoch [149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9433\n",
      "Epoch [149/2000], Avg Train Loss: 4.9433\n",
      "Epoch [149/2000], Avg Val Loss: 3.1656\n",
      "Validation loss improved from 3.1665 to 3.1656. Saving model...\n",
      "\n",
      "LOG: Epoch [150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0009\n",
      "Epoch [150/2000], Avg Train Loss: 5.0009\n",
      "Epoch [150/2000], Avg Val Loss: 3.1647\n",
      "Validation loss improved from 3.1656 to 3.1647. Saving model...\n",
      "\n",
      "LOG: Epoch [151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0017\n",
      "Epoch [151/2000], Avg Train Loss: 5.0017\n",
      "Epoch [151/2000], Avg Val Loss: 3.1638\n",
      "Validation loss improved from 3.1647 to 3.1638. Saving model...\n",
      "\n",
      "LOG: Epoch [152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9567\n",
      "Epoch [152/2000], Avg Train Loss: 4.9567\n",
      "Epoch [152/2000], Avg Val Loss: 3.1629\n",
      "Validation loss improved from 3.1638 to 3.1629. Saving model...\n",
      "\n",
      "LOG: Epoch [153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0082\n",
      "Epoch [153/2000], Avg Train Loss: 5.0082\n",
      "Epoch [153/2000], Avg Val Loss: 3.1620\n",
      "Validation loss improved from 3.1629 to 3.1620. Saving model...\n",
      "\n",
      "LOG: Epoch [154/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0149\n",
      "Epoch [154/2000], Avg Train Loss: 5.0149\n",
      "Epoch [154/2000], Avg Val Loss: 3.1610\n",
      "Validation loss improved from 3.1620 to 3.1610. Saving model...\n",
      "\n",
      "LOG: Epoch [155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9822\n",
      "Epoch [155/2000], Avg Train Loss: 4.9822\n",
      "Epoch [155/2000], Avg Val Loss: 3.1601\n",
      "Validation loss improved from 3.1610 to 3.1601. Saving model...\n",
      "\n",
      "LOG: Epoch [156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9729\n",
      "Epoch [156/2000], Avg Train Loss: 4.9729\n",
      "Epoch [156/2000], Avg Val Loss: 3.1592\n",
      "Validation loss improved from 3.1601 to 3.1592. Saving model...\n",
      "\n",
      "LOG: Epoch [157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0090\n",
      "Epoch [157/2000], Avg Train Loss: 5.0090\n",
      "Epoch [157/2000], Avg Val Loss: 3.1583\n",
      "Validation loss improved from 3.1592 to 3.1583. Saving model...\n",
      "\n",
      "LOG: Epoch [158/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.9592\n",
      "Epoch [158/2000], Avg Train Loss: 4.9592\n",
      "Epoch [158/2000], Avg Val Loss: 3.1573\n",
      "Validation loss improved from 3.1583 to 3.1573. Saving model...\n",
      "\n",
      "LOG: Epoch [159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9659\n",
      "Epoch [159/2000], Avg Train Loss: 4.9659\n",
      "Epoch [159/2000], Avg Val Loss: 3.1564\n",
      "Validation loss improved from 3.1573 to 3.1564. Saving model...\n",
      "\n",
      "LOG: Epoch [160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9358\n",
      "Epoch [160/2000], Avg Train Loss: 4.9358\n",
      "Epoch [160/2000], Avg Val Loss: 3.1554\n",
      "Validation loss improved from 3.1564 to 3.1554. Saving model...\n",
      "\n",
      "LOG: Epoch [161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9063\n",
      "Epoch [161/2000], Avg Train Loss: 4.9063\n",
      "Epoch [161/2000], Avg Val Loss: 3.1545\n",
      "Validation loss improved from 3.1554 to 3.1545. Saving model...\n",
      "\n",
      "LOG: Epoch [162/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9527\n",
      "Epoch [162/2000], Avg Train Loss: 4.9527\n",
      "Epoch [162/2000], Avg Val Loss: 3.1536\n",
      "Validation loss improved from 3.1545 to 3.1536. Saving model...\n",
      "\n",
      "LOG: Epoch [163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9063\n",
      "Epoch [163/2000], Avg Train Loss: 4.9063\n",
      "Epoch [163/2000], Avg Val Loss: 3.1526\n",
      "Validation loss improved from 3.1536 to 3.1526. Saving model...\n",
      "\n",
      "LOG: Epoch [164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9436\n",
      "Epoch [164/2000], Avg Train Loss: 4.9436\n",
      "Epoch [164/2000], Avg Val Loss: 3.1517\n",
      "Validation loss improved from 3.1526 to 3.1517. Saving model...\n",
      "\n",
      "LOG: Epoch [165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9106\n",
      "Epoch [165/2000], Avg Train Loss: 4.9106\n",
      "Epoch [165/2000], Avg Val Loss: 3.1507\n",
      "Validation loss improved from 3.1517 to 3.1507. Saving model...\n",
      "\n",
      "LOG: Epoch [166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9252\n",
      "Epoch [166/2000], Avg Train Loss: 4.9252\n",
      "Epoch [166/2000], Avg Val Loss: 3.1497\n",
      "Validation loss improved from 3.1507 to 3.1497. Saving model...\n",
      "\n",
      "LOG: Epoch [167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9319\n",
      "Epoch [167/2000], Avg Train Loss: 4.9319\n",
      "Epoch [167/2000], Avg Val Loss: 3.1488\n",
      "Validation loss improved from 3.1497 to 3.1488. Saving model...\n",
      "\n",
      "LOG: Epoch [168/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.8831\n",
      "Epoch [168/2000], Avg Train Loss: 4.8831\n",
      "Epoch [168/2000], Avg Val Loss: 3.1478\n",
      "Validation loss improved from 3.1488 to 3.1478. Saving model...\n",
      "\n",
      "LOG: Epoch [169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9139\n",
      "Epoch [169/2000], Avg Train Loss: 4.9139\n",
      "Epoch [169/2000], Avg Val Loss: 3.1468\n",
      "Validation loss improved from 3.1478 to 3.1468. Saving model...\n",
      "\n",
      "LOG: Epoch [170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8665\n",
      "Epoch [170/2000], Avg Train Loss: 4.8665\n",
      "Epoch [170/2000], Avg Val Loss: 3.1458\n",
      "Validation loss improved from 3.1468 to 3.1458. Saving model...\n",
      "\n",
      "LOG: Epoch [171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9067\n",
      "Epoch [171/2000], Avg Train Loss: 4.9067\n",
      "Epoch [171/2000], Avg Val Loss: 3.1448\n",
      "Validation loss improved from 3.1458 to 3.1448. Saving model...\n",
      "\n",
      "LOG: Epoch [172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9257\n",
      "Epoch [172/2000], Avg Train Loss: 4.9257\n",
      "Epoch [172/2000], Avg Val Loss: 3.1437\n",
      "Validation loss improved from 3.1448 to 3.1437. Saving model...\n",
      "\n",
      "LOG: Epoch [173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9181\n",
      "Epoch [173/2000], Avg Train Loss: 4.9181\n",
      "Epoch [173/2000], Avg Val Loss: 3.1427\n",
      "Validation loss improved from 3.1437 to 3.1427. Saving model...\n",
      "\n",
      "LOG: Epoch [174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8988\n",
      "Epoch [174/2000], Avg Train Loss: 4.8988\n",
      "Epoch [174/2000], Avg Val Loss: 3.1417\n",
      "Validation loss improved from 3.1427 to 3.1417. Saving model...\n",
      "\n",
      "LOG: Epoch [175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8883\n",
      "Epoch [175/2000], Avg Train Loss: 4.8883\n",
      "Epoch [175/2000], Avg Val Loss: 3.1407\n",
      "Validation loss improved from 3.1417 to 3.1407. Saving model...\n",
      "\n",
      "LOG: Epoch [176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8439\n",
      "Epoch [176/2000], Avg Train Loss: 4.8439\n",
      "Epoch [176/2000], Avg Val Loss: 3.1397\n",
      "Validation loss improved from 3.1407 to 3.1397. Saving model...\n",
      "\n",
      "LOG: Epoch [177/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.8962\n",
      "Epoch [177/2000], Avg Train Loss: 4.8962\n",
      "Epoch [177/2000], Avg Val Loss: 3.1387\n",
      "Validation loss improved from 3.1397 to 3.1387. Saving model...\n",
      "\n",
      "LOG: Epoch [178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9316\n",
      "Epoch [178/2000], Avg Train Loss: 4.9316\n",
      "Epoch [178/2000], Avg Val Loss: 3.1377\n",
      "Validation loss improved from 3.1387 to 3.1377. Saving model...\n",
      "\n",
      "LOG: Epoch [179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8820\n",
      "Epoch [179/2000], Avg Train Loss: 4.8820\n",
      "Epoch [179/2000], Avg Val Loss: 3.1366\n",
      "Validation loss improved from 3.1377 to 3.1366. Saving model...\n",
      "\n",
      "LOG: Epoch [180/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8926\n",
      "Epoch [180/2000], Avg Train Loss: 4.8926\n",
      "Epoch [180/2000], Avg Val Loss: 3.1356\n",
      "Validation loss improved from 3.1366 to 3.1356. Saving model...\n",
      "\n",
      "LOG: Epoch [181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8378\n",
      "Epoch [181/2000], Avg Train Loss: 4.8378\n",
      "Epoch [181/2000], Avg Val Loss: 3.1346\n",
      "Validation loss improved from 3.1356 to 3.1346. Saving model...\n",
      "\n",
      "LOG: Epoch [182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9122\n",
      "Epoch [182/2000], Avg Train Loss: 4.9122\n",
      "Epoch [182/2000], Avg Val Loss: 3.1335\n",
      "Validation loss improved from 3.1346 to 3.1335. Saving model...\n",
      "\n",
      "LOG: Epoch [183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8914\n",
      "Epoch [183/2000], Avg Train Loss: 4.8914\n",
      "Epoch [183/2000], Avg Val Loss: 3.1325\n",
      "Validation loss improved from 3.1335 to 3.1325. Saving model...\n",
      "\n",
      "LOG: Epoch [184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8797\n",
      "Epoch [184/2000], Avg Train Loss: 4.8797\n",
      "Epoch [184/2000], Avg Val Loss: 3.1316\n",
      "Validation loss improved from 3.1325 to 3.1316. Saving model...\n",
      "\n",
      "LOG: Epoch [185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8346\n",
      "Epoch [185/2000], Avg Train Loss: 4.8346\n",
      "Epoch [185/2000], Avg Val Loss: 3.1305\n",
      "Validation loss improved from 3.1316 to 3.1305. Saving model...\n",
      "\n",
      "LOG: Epoch [186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8281\n",
      "Epoch [186/2000], Avg Train Loss: 4.8281\n",
      "Epoch [186/2000], Avg Val Loss: 3.1295\n",
      "Validation loss improved from 3.1305 to 3.1295. Saving model...\n",
      "\n",
      "LOG: Epoch [187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8567\n",
      "Epoch [187/2000], Avg Train Loss: 4.8567\n",
      "Epoch [187/2000], Avg Val Loss: 3.1285\n",
      "Validation loss improved from 3.1295 to 3.1285. Saving model...\n",
      "\n",
      "LOG: Epoch [188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8565\n",
      "Epoch [188/2000], Avg Train Loss: 4.8565\n",
      "Epoch [188/2000], Avg Val Loss: 3.1275\n",
      "Validation loss improved from 3.1285 to 3.1275. Saving model...\n",
      "\n",
      "LOG: Epoch [189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8839\n",
      "Epoch [189/2000], Avg Train Loss: 4.8839\n",
      "Epoch [189/2000], Avg Val Loss: 3.1266\n",
      "Validation loss improved from 3.1275 to 3.1266. Saving model...\n",
      "\n",
      "LOG: Epoch [190/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.8340\n",
      "Epoch [190/2000], Avg Train Loss: 4.8340\n",
      "Epoch [190/2000], Avg Val Loss: 3.1256\n",
      "Validation loss improved from 3.1266 to 3.1256. Saving model...\n",
      "\n",
      "LOG: Epoch [191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8788\n",
      "Epoch [191/2000], Avg Train Loss: 4.8788\n",
      "Epoch [191/2000], Avg Val Loss: 3.1246\n",
      "Validation loss improved from 3.1256 to 3.1246. Saving model...\n",
      "\n",
      "LOG: Epoch [192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8905\n",
      "Epoch [192/2000], Avg Train Loss: 4.8905\n",
      "Epoch [192/2000], Avg Val Loss: 3.1236\n",
      "Validation loss improved from 3.1246 to 3.1236. Saving model...\n",
      "\n",
      "LOG: Epoch [193/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8119\n",
      "Epoch [193/2000], Avg Train Loss: 4.8119\n",
      "Epoch [193/2000], Avg Val Loss: 3.1227\n",
      "Validation loss improved from 3.1236 to 3.1227. Saving model...\n",
      "\n",
      "LOG: Epoch [194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8654\n",
      "Epoch [194/2000], Avg Train Loss: 4.8654\n",
      "Epoch [194/2000], Avg Val Loss: 3.1217\n",
      "Validation loss improved from 3.1227 to 3.1217. Saving model...\n",
      "\n",
      "LOG: Epoch [195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7990\n",
      "Epoch [195/2000], Avg Train Loss: 4.7990\n",
      "Epoch [195/2000], Avg Val Loss: 3.1207\n",
      "Validation loss improved from 3.1217 to 3.1207. Saving model...\n",
      "\n",
      "LOG: Epoch [196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8065\n",
      "Epoch [196/2000], Avg Train Loss: 4.8065\n",
      "Epoch [196/2000], Avg Val Loss: 3.1197\n",
      "Validation loss improved from 3.1207 to 3.1197. Saving model...\n",
      "\n",
      "LOG: Epoch [197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8411\n",
      "Epoch [197/2000], Avg Train Loss: 4.8411\n",
      "Epoch [197/2000], Avg Val Loss: 3.1187\n",
      "Validation loss improved from 3.1197 to 3.1187. Saving model...\n",
      "\n",
      "LOG: Epoch [198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8024\n",
      "Epoch [198/2000], Avg Train Loss: 4.8024\n",
      "Epoch [198/2000], Avg Val Loss: 3.1176\n",
      "Validation loss improved from 3.1187 to 3.1176. Saving model...\n",
      "\n",
      "LOG: Epoch [199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8162\n",
      "Epoch [199/2000], Avg Train Loss: 4.8162\n",
      "Epoch [199/2000], Avg Val Loss: 3.1166\n",
      "Validation loss improved from 3.1176 to 3.1166. Saving model...\n",
      "\n",
      "LOG: Epoch [200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8148\n",
      "Epoch [200/2000], Avg Train Loss: 4.8148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/2000], Avg Val Loss: 3.1156\n",
      "Validation loss improved from 3.1166 to 3.1156. Saving model...\n",
      "\n",
      "LOG: Epoch [201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8205\n",
      "Epoch [201/2000], Avg Train Loss: 4.8205\n",
      "Epoch [201/2000], Avg Val Loss: 3.1145\n",
      "Validation loss improved from 3.1156 to 3.1145. Saving model...\n",
      "\n",
      "LOG: Epoch [202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7977\n",
      "Epoch [202/2000], Avg Train Loss: 4.7977\n",
      "Epoch [202/2000], Avg Val Loss: 3.1135\n",
      "Validation loss improved from 3.1145 to 3.1135. Saving model...\n",
      "\n",
      "LOG: Epoch [203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8203\n",
      "Epoch [203/2000], Avg Train Loss: 4.8203\n",
      "Epoch [203/2000], Avg Val Loss: 3.1125\n",
      "Validation loss improved from 3.1135 to 3.1125. Saving model...\n",
      "\n",
      "LOG: Epoch [204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7953\n",
      "Epoch [204/2000], Avg Train Loss: 4.7953\n",
      "Epoch [204/2000], Avg Val Loss: 3.1115\n",
      "Validation loss improved from 3.1125 to 3.1115. Saving model...\n",
      "\n",
      "LOG: Epoch [205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8267\n",
      "Epoch [205/2000], Avg Train Loss: 4.8267\n",
      "Epoch [205/2000], Avg Val Loss: 3.1105\n",
      "Validation loss improved from 3.1115 to 3.1105. Saving model...\n",
      "\n",
      "LOG: Epoch [206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7888\n",
      "Epoch [206/2000], Avg Train Loss: 4.7888\n",
      "Epoch [206/2000], Avg Val Loss: 3.1095\n",
      "Validation loss improved from 3.1105 to 3.1095. Saving model...\n",
      "\n",
      "LOG: Epoch [207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8431\n",
      "Epoch [207/2000], Avg Train Loss: 4.8431\n",
      "Epoch [207/2000], Avg Val Loss: 3.1086\n",
      "Validation loss improved from 3.1095 to 3.1086. Saving model...\n",
      "\n",
      "LOG: Epoch [208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7768\n",
      "Epoch [208/2000], Avg Train Loss: 4.7768\n",
      "Epoch [208/2000], Avg Val Loss: 3.1076\n",
      "Validation loss improved from 3.1086 to 3.1076. Saving model...\n",
      "\n",
      "LOG: Epoch [209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8341\n",
      "Epoch [209/2000], Avg Train Loss: 4.8341\n",
      "Epoch [209/2000], Avg Val Loss: 3.1066\n",
      "Validation loss improved from 3.1076 to 3.1066. Saving model...\n",
      "\n",
      "LOG: Epoch [210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8378\n",
      "Epoch [210/2000], Avg Train Loss: 4.8378\n",
      "Epoch [210/2000], Avg Val Loss: 3.1057\n",
      "Validation loss improved from 3.1066 to 3.1057. Saving model...\n",
      "\n",
      "LOG: Epoch [211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8005\n",
      "Epoch [211/2000], Avg Train Loss: 4.8005\n",
      "Epoch [211/2000], Avg Val Loss: 3.1047\n",
      "Validation loss improved from 3.1057 to 3.1047. Saving model...\n",
      "\n",
      "LOG: Epoch [212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8107\n",
      "Epoch [212/2000], Avg Train Loss: 4.8107\n",
      "Epoch [212/2000], Avg Val Loss: 3.1038\n",
      "Validation loss improved from 3.1047 to 3.1038. Saving model...\n",
      "\n",
      "LOG: Epoch [213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8012\n",
      "Epoch [213/2000], Avg Train Loss: 4.8012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [213/2000], Avg Val Loss: 3.1028\n",
      "Validation loss improved from 3.1038 to 3.1028. Saving model...\n",
      "\n",
      "LOG: Epoch [214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7960\n",
      "Epoch [214/2000], Avg Train Loss: 4.7960\n",
      "Epoch [214/2000], Avg Val Loss: 3.1019\n",
      "Validation loss improved from 3.1028 to 3.1019. Saving model...\n",
      "\n",
      "LOG: Epoch [215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7840\n",
      "Epoch [215/2000], Avg Train Loss: 4.7840\n",
      "Epoch [215/2000], Avg Val Loss: 3.1009\n",
      "Validation loss improved from 3.1019 to 3.1009. Saving model...\n",
      "\n",
      "LOG: Epoch [216/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7868\n",
      "Epoch [216/2000], Avg Train Loss: 4.7868\n",
      "Epoch [216/2000], Avg Val Loss: 3.1000\n",
      "Validation loss improved from 3.1009 to 3.1000. Saving model...\n",
      "\n",
      "LOG: Epoch [217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7615\n",
      "Epoch [217/2000], Avg Train Loss: 4.7615\n",
      "Epoch [217/2000], Avg Val Loss: 3.0990\n",
      "Validation loss improved from 3.1000 to 3.0990. Saving model...\n",
      "\n",
      "LOG: Epoch [218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8496\n",
      "Epoch [218/2000], Avg Train Loss: 4.8496\n",
      "Epoch [218/2000], Avg Val Loss: 3.0981\n",
      "Validation loss improved from 3.0990 to 3.0981. Saving model...\n",
      "\n",
      "LOG: Epoch [219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7868\n",
      "Epoch [219/2000], Avg Train Loss: 4.7868\n",
      "Epoch [219/2000], Avg Val Loss: 3.0971\n",
      "Validation loss improved from 3.0981 to 3.0971. Saving model...\n",
      "\n",
      "LOG: Epoch [220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8098\n",
      "Epoch [220/2000], Avg Train Loss: 4.8098\n",
      "Epoch [220/2000], Avg Val Loss: 3.0962\n",
      "Validation loss improved from 3.0971 to 3.0962. Saving model...\n",
      "\n",
      "LOG: Epoch [221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7452\n",
      "Epoch [221/2000], Avg Train Loss: 4.7452\n",
      "Epoch [221/2000], Avg Val Loss: 3.0952\n",
      "Validation loss improved from 3.0962 to 3.0952. Saving model...\n",
      "\n",
      "LOG: Epoch [222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7839\n",
      "Epoch [222/2000], Avg Train Loss: 4.7839\n",
      "Epoch [222/2000], Avg Val Loss: 3.0943\n",
      "Validation loss improved from 3.0952 to 3.0943. Saving model...\n",
      "\n",
      "LOG: Epoch [223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7724\n",
      "Epoch [223/2000], Avg Train Loss: 4.7724\n",
      "Epoch [223/2000], Avg Val Loss: 3.0934\n",
      "Validation loss improved from 3.0943 to 3.0934. Saving model...\n",
      "\n",
      "LOG: Epoch [224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7986\n",
      "Epoch [224/2000], Avg Train Loss: 4.7986\n",
      "Epoch [224/2000], Avg Val Loss: 3.0924\n",
      "Validation loss improved from 3.0934 to 3.0924. Saving model...\n",
      "\n",
      "LOG: Epoch [225/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.7976\n",
      "Epoch [225/2000], Avg Train Loss: 4.7976\n",
      "Epoch [225/2000], Avg Val Loss: 3.0915\n",
      "Validation loss improved from 3.0924 to 3.0915. Saving model...\n",
      "\n",
      "LOG: Epoch [226/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7636\n",
      "Epoch [226/2000], Avg Train Loss: 4.7636\n",
      "Epoch [226/2000], Avg Val Loss: 3.0906\n",
      "Validation loss improved from 3.0915 to 3.0906. Saving model...\n",
      "\n",
      "LOG: Epoch [227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7725\n",
      "Epoch [227/2000], Avg Train Loss: 4.7725\n",
      "Epoch [227/2000], Avg Val Loss: 3.0897\n",
      "Validation loss improved from 3.0906 to 3.0897. Saving model...\n",
      "\n",
      "LOG: Epoch [228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7685\n",
      "Epoch [228/2000], Avg Train Loss: 4.7685\n",
      "Epoch [228/2000], Avg Val Loss: 3.0888\n",
      "Validation loss improved from 3.0897 to 3.0888. Saving model...\n",
      "\n",
      "LOG: Epoch [229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8366\n",
      "Epoch [229/2000], Avg Train Loss: 4.8366\n",
      "Epoch [229/2000], Avg Val Loss: 3.0880\n",
      "Validation loss improved from 3.0888 to 3.0880. Saving model...\n",
      "\n",
      "LOG: Epoch [230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7391\n",
      "Epoch [230/2000], Avg Train Loss: 4.7391\n",
      "Epoch [230/2000], Avg Val Loss: 3.0871\n",
      "Validation loss improved from 3.0880 to 3.0871. Saving model...\n",
      "\n",
      "LOG: Epoch [231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7734\n",
      "Epoch [231/2000], Avg Train Loss: 4.7734\n",
      "Epoch [231/2000], Avg Val Loss: 3.0862\n",
      "Validation loss improved from 3.0871 to 3.0862. Saving model...\n",
      "\n",
      "LOG: Epoch [232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7009\n",
      "Epoch [232/2000], Avg Train Loss: 4.7009\n",
      "Epoch [232/2000], Avg Val Loss: 3.0853\n",
      "Validation loss improved from 3.0862 to 3.0853. Saving model...\n",
      "\n",
      "LOG: Epoch [233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7685\n",
      "Epoch [233/2000], Avg Train Loss: 4.7685\n",
      "Epoch [233/2000], Avg Val Loss: 3.0844\n",
      "Validation loss improved from 3.0853 to 3.0844. Saving model...\n",
      "\n",
      "LOG: Epoch [234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7362\n",
      "Epoch [234/2000], Avg Train Loss: 4.7362\n",
      "Epoch [234/2000], Avg Val Loss: 3.0835\n",
      "Validation loss improved from 3.0844 to 3.0835. Saving model...\n",
      "\n",
      "LOG: Epoch [235/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7867\n",
      "Epoch [235/2000], Avg Train Loss: 4.7867\n",
      "Epoch [235/2000], Avg Val Loss: 3.0826\n",
      "Validation loss improved from 3.0835 to 3.0826. Saving model...\n",
      "\n",
      "LOG: Epoch [236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7522\n",
      "Epoch [236/2000], Avg Train Loss: 4.7522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [236/2000], Avg Val Loss: 3.0817\n",
      "Validation loss improved from 3.0826 to 3.0817. Saving model...\n",
      "\n",
      "LOG: Epoch [237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7513\n",
      "Epoch [237/2000], Avg Train Loss: 4.7513\n",
      "Epoch [237/2000], Avg Val Loss: 3.0808\n",
      "Validation loss improved from 3.0817 to 3.0808. Saving model...\n",
      "\n",
      "LOG: Epoch [238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7216\n",
      "Epoch [238/2000], Avg Train Loss: 4.7216\n",
      "Epoch [238/2000], Avg Val Loss: 3.0799\n",
      "Validation loss improved from 3.0808 to 3.0799. Saving model...\n",
      "\n",
      "LOG: Epoch [239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7406\n",
      "Epoch [239/2000], Avg Train Loss: 4.7406\n",
      "Epoch [239/2000], Avg Val Loss: 3.0791\n",
      "Validation loss improved from 3.0799 to 3.0791. Saving model...\n",
      "\n",
      "LOG: Epoch [240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7399\n",
      "Epoch [240/2000], Avg Train Loss: 4.7399\n",
      "Epoch [240/2000], Avg Val Loss: 3.0782\n",
      "Validation loss improved from 3.0791 to 3.0782. Saving model...\n",
      "\n",
      "LOG: Epoch [241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7365\n",
      "Epoch [241/2000], Avg Train Loss: 4.7365\n",
      "Epoch [241/2000], Avg Val Loss: 3.0773\n",
      "Validation loss improved from 3.0782 to 3.0773. Saving model...\n",
      "\n",
      "LOG: Epoch [242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7619\n",
      "Epoch [242/2000], Avg Train Loss: 4.7619\n",
      "Epoch [242/2000], Avg Val Loss: 3.0764\n",
      "Validation loss improved from 3.0773 to 3.0764. Saving model...\n",
      "\n",
      "LOG: Epoch [243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7635\n",
      "Epoch [243/2000], Avg Train Loss: 4.7635\n",
      "Epoch [243/2000], Avg Val Loss: 3.0756\n",
      "Validation loss improved from 3.0764 to 3.0756. Saving model...\n",
      "\n",
      "LOG: Epoch [244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7409\n",
      "Epoch [244/2000], Avg Train Loss: 4.7409\n",
      "Epoch [244/2000], Avg Val Loss: 3.0747\n",
      "Validation loss improved from 3.0756 to 3.0747. Saving model...\n",
      "\n",
      "LOG: Epoch [245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7169\n",
      "Epoch [245/2000], Avg Train Loss: 4.7169\n",
      "Epoch [245/2000], Avg Val Loss: 3.0739\n",
      "Validation loss improved from 3.0747 to 3.0739. Saving model...\n",
      "\n",
      "LOG: Epoch [246/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7364\n",
      "Epoch [246/2000], Avg Train Loss: 4.7364\n",
      "Epoch [246/2000], Avg Val Loss: 3.0730\n",
      "Validation loss improved from 3.0739 to 3.0730. Saving model...\n",
      "\n",
      "LOG: Epoch [247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7178\n",
      "Epoch [247/2000], Avg Train Loss: 4.7178\n",
      "Epoch [247/2000], Avg Val Loss: 3.0722\n",
      "Validation loss improved from 3.0730 to 3.0722. Saving model...\n",
      "\n",
      "LOG: Epoch [248/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7316\n",
      "Epoch [248/2000], Avg Train Loss: 4.7316\n",
      "Epoch [248/2000], Avg Val Loss: 3.0713\n",
      "Validation loss improved from 3.0722 to 3.0713. Saving model...\n",
      "\n",
      "LOG: Epoch [249/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.6918\n",
      "Epoch [249/2000], Avg Train Loss: 4.6918\n",
      "Epoch [249/2000], Avg Val Loss: 3.0705\n",
      "Validation loss improved from 3.0713 to 3.0705. Saving model...\n",
      "\n",
      "LOG: Epoch [250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7367\n",
      "Epoch [250/2000], Avg Train Loss: 4.7367\n",
      "Epoch [250/2000], Avg Val Loss: 3.0696\n",
      "Validation loss improved from 3.0705 to 3.0696. Saving model...\n",
      "\n",
      "LOG: Epoch [251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7513\n",
      "Epoch [251/2000], Avg Train Loss: 4.7513\n",
      "Epoch [251/2000], Avg Val Loss: 3.0688\n",
      "Validation loss improved from 3.0696 to 3.0688. Saving model...\n",
      "\n",
      "LOG: Epoch [252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7157\n",
      "Epoch [252/2000], Avg Train Loss: 4.7157\n",
      "Epoch [252/2000], Avg Val Loss: 3.0680\n",
      "Validation loss improved from 3.0688 to 3.0680. Saving model...\n",
      "\n",
      "LOG: Epoch [253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7434\n",
      "Epoch [253/2000], Avg Train Loss: 4.7434\n",
      "Epoch [253/2000], Avg Val Loss: 3.0672\n",
      "Validation loss improved from 3.0680 to 3.0672. Saving model...\n",
      "\n",
      "LOG: Epoch [254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7227\n",
      "Epoch [254/2000], Avg Train Loss: 4.7227\n",
      "Epoch [254/2000], Avg Val Loss: 3.0664\n",
      "Validation loss improved from 3.0672 to 3.0664. Saving model...\n",
      "\n",
      "LOG: Epoch [255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6957\n",
      "Epoch [255/2000], Avg Train Loss: 4.6957\n",
      "Epoch [255/2000], Avg Val Loss: 3.0656\n",
      "Validation loss improved from 3.0664 to 3.0656. Saving model...\n",
      "\n",
      "LOG: Epoch [256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7224\n",
      "Epoch [256/2000], Avg Train Loss: 4.7224\n",
      "Epoch [256/2000], Avg Val Loss: 3.0648\n",
      "Validation loss improved from 3.0656 to 3.0648. Saving model...\n",
      "\n",
      "LOG: Epoch [257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6792\n",
      "Epoch [257/2000], Avg Train Loss: 4.6792\n",
      "Epoch [257/2000], Avg Val Loss: 3.0640\n",
      "Validation loss improved from 3.0648 to 3.0640. Saving model...\n",
      "\n",
      "LOG: Epoch [258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7265\n",
      "Epoch [258/2000], Avg Train Loss: 4.7265\n",
      "Epoch [258/2000], Avg Val Loss: 3.0632\n",
      "Validation loss improved from 3.0640 to 3.0632. Saving model...\n",
      "\n",
      "LOG: Epoch [259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7044\n",
      "Epoch [259/2000], Avg Train Loss: 4.7044\n",
      "Epoch [259/2000], Avg Val Loss: 3.0624\n",
      "Validation loss improved from 3.0632 to 3.0624. Saving model...\n",
      "\n",
      "LOG: Epoch [260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7243\n",
      "Epoch [260/2000], Avg Train Loss: 4.7243\n",
      "Epoch [260/2000], Avg Val Loss: 3.0616\n",
      "Validation loss improved from 3.0624 to 3.0616. Saving model...\n",
      "\n",
      "LOG: Epoch [261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6758\n",
      "Epoch [261/2000], Avg Train Loss: 4.6758\n",
      "Epoch [261/2000], Avg Val Loss: 3.0608\n",
      "Validation loss improved from 3.0616 to 3.0608. Saving model...\n",
      "\n",
      "LOG: Epoch [262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6905\n",
      "Epoch [262/2000], Avg Train Loss: 4.6905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [262/2000], Avg Val Loss: 3.0601\n",
      "Validation loss improved from 3.0608 to 3.0601. Saving model...\n",
      "\n",
      "LOG: Epoch [263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6739\n",
      "Epoch [263/2000], Avg Train Loss: 4.6739\n",
      "Epoch [263/2000], Avg Val Loss: 3.0593\n",
      "Validation loss improved from 3.0601 to 3.0593. Saving model...\n",
      "\n",
      "LOG: Epoch [264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6938\n",
      "Epoch [264/2000], Avg Train Loss: 4.6938\n",
      "Epoch [264/2000], Avg Val Loss: 3.0585\n",
      "Validation loss improved from 3.0593 to 3.0585. Saving model...\n",
      "\n",
      "LOG: Epoch [265/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6741\n",
      "Epoch [265/2000], Avg Train Loss: 4.6741\n",
      "Epoch [265/2000], Avg Val Loss: 3.0577\n",
      "Validation loss improved from 3.0585 to 3.0577. Saving model...\n",
      "\n",
      "LOG: Epoch [266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6696\n",
      "Epoch [266/2000], Avg Train Loss: 4.6696\n",
      "Epoch [266/2000], Avg Val Loss: 3.0569\n",
      "Validation loss improved from 3.0577 to 3.0569. Saving model...\n",
      "\n",
      "LOG: Epoch [267/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6802\n",
      "Epoch [267/2000], Avg Train Loss: 4.6802\n",
      "Epoch [267/2000], Avg Val Loss: 3.0560\n",
      "Validation loss improved from 3.0569 to 3.0560. Saving model...\n",
      "\n",
      "LOG: Epoch [268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6797\n",
      "Epoch [268/2000], Avg Train Loss: 4.6797\n",
      "Epoch [268/2000], Avg Val Loss: 3.0552\n",
      "Validation loss improved from 3.0560 to 3.0552. Saving model...\n",
      "\n",
      "LOG: Epoch [269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7077\n",
      "Epoch [269/2000], Avg Train Loss: 4.7077\n",
      "Epoch [269/2000], Avg Val Loss: 3.0544\n",
      "Validation loss improved from 3.0552 to 3.0544. Saving model...\n",
      "\n",
      "LOG: Epoch [270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6493\n",
      "Epoch [270/2000], Avg Train Loss: 4.6493\n",
      "Epoch [270/2000], Avg Val Loss: 3.0536\n",
      "Validation loss improved from 3.0544 to 3.0536. Saving model...\n",
      "\n",
      "LOG: Epoch [271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7220\n",
      "Epoch [271/2000], Avg Train Loss: 4.7220\n",
      "Epoch [271/2000], Avg Val Loss: 3.0528\n",
      "Validation loss improved from 3.0536 to 3.0528. Saving model...\n",
      "\n",
      "LOG: Epoch [272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6942\n",
      "Epoch [272/2000], Avg Train Loss: 4.6942\n",
      "Epoch [272/2000], Avg Val Loss: 3.0520\n",
      "Validation loss improved from 3.0528 to 3.0520. Saving model...\n",
      "\n",
      "LOG: Epoch [273/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.6690\n",
      "Epoch [273/2000], Avg Train Loss: 4.6690\n",
      "Epoch [273/2000], Avg Val Loss: 3.0512\n",
      "Validation loss improved from 3.0520 to 3.0512. Saving model...\n",
      "\n",
      "LOG: Epoch [274/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6865\n",
      "Epoch [274/2000], Avg Train Loss: 4.6865\n",
      "Epoch [274/2000], Avg Val Loss: 3.0504\n",
      "Validation loss improved from 3.0512 to 3.0504. Saving model...\n",
      "\n",
      "LOG: Epoch [275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6561\n",
      "Epoch [275/2000], Avg Train Loss: 4.6561\n",
      "Epoch [275/2000], Avg Val Loss: 3.0496\n",
      "Validation loss improved from 3.0504 to 3.0496. Saving model...\n",
      "\n",
      "LOG: Epoch [276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6442\n",
      "Epoch [276/2000], Avg Train Loss: 4.6442\n",
      "Epoch [276/2000], Avg Val Loss: 3.0488\n",
      "Validation loss improved from 3.0496 to 3.0488. Saving model...\n",
      "\n",
      "LOG: Epoch [277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6685\n",
      "Epoch [277/2000], Avg Train Loss: 4.6685\n",
      "Epoch [277/2000], Avg Val Loss: 3.0480\n",
      "Validation loss improved from 3.0488 to 3.0480. Saving model...\n",
      "\n",
      "LOG: Epoch [278/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6756\n",
      "Epoch [278/2000], Avg Train Loss: 4.6756\n",
      "Epoch [278/2000], Avg Val Loss: 3.0472\n",
      "Validation loss improved from 3.0480 to 3.0472. Saving model...\n",
      "\n",
      "LOG: Epoch [279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6314\n",
      "Epoch [279/2000], Avg Train Loss: 4.6314\n",
      "Epoch [279/2000], Avg Val Loss: 3.0464\n",
      "Validation loss improved from 3.0472 to 3.0464. Saving model...\n",
      "\n",
      "LOG: Epoch [280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7027\n",
      "Epoch [280/2000], Avg Train Loss: 4.7027\n",
      "Epoch [280/2000], Avg Val Loss: 3.0456\n",
      "Validation loss improved from 3.0464 to 3.0456. Saving model...\n",
      "\n",
      "LOG: Epoch [281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6505\n",
      "Epoch [281/2000], Avg Train Loss: 4.6505\n",
      "Epoch [281/2000], Avg Val Loss: 3.0448\n",
      "Validation loss improved from 3.0456 to 3.0448. Saving model...\n",
      "\n",
      "LOG: Epoch [282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6853\n",
      "Epoch [282/2000], Avg Train Loss: 4.6853\n",
      "Epoch [282/2000], Avg Val Loss: 3.0440\n",
      "Validation loss improved from 3.0448 to 3.0440. Saving model...\n",
      "\n",
      "LOG: Epoch [283/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.6566\n",
      "Epoch [283/2000], Avg Train Loss: 4.6566\n",
      "Epoch [283/2000], Avg Val Loss: 3.0433\n",
      "Validation loss improved from 3.0440 to 3.0433. Saving model...\n",
      "\n",
      "LOG: Epoch [284/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6297\n",
      "Epoch [284/2000], Avg Train Loss: 4.6297\n",
      "Epoch [284/2000], Avg Val Loss: 3.0425\n",
      "Validation loss improved from 3.0433 to 3.0425. Saving model...\n",
      "\n",
      "LOG: Epoch [285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6621\n",
      "Epoch [285/2000], Avg Train Loss: 4.6621\n",
      "Epoch [285/2000], Avg Val Loss: 3.0418\n",
      "Validation loss improved from 3.0425 to 3.0418. Saving model...\n",
      "\n",
      "LOG: Epoch [286/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6586\n",
      "Epoch [286/2000], Avg Train Loss: 4.6586\n",
      "Epoch [286/2000], Avg Val Loss: 3.0410\n",
      "Validation loss improved from 3.0418 to 3.0410. Saving model...\n",
      "\n",
      "LOG: Epoch [287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6556\n",
      "Epoch [287/2000], Avg Train Loss: 4.6556\n",
      "Epoch [287/2000], Avg Val Loss: 3.0403\n",
      "Validation loss improved from 3.0410 to 3.0403. Saving model...\n",
      "\n",
      "LOG: Epoch [288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6521\n",
      "Epoch [288/2000], Avg Train Loss: 4.6521\n",
      "Epoch [288/2000], Avg Val Loss: 3.0395\n",
      "Validation loss improved from 3.0403 to 3.0395. Saving model...\n",
      "\n",
      "LOG: Epoch [289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6415\n",
      "Epoch [289/2000], Avg Train Loss: 4.6415\n",
      "Epoch [289/2000], Avg Val Loss: 3.0387\n",
      "Validation loss improved from 3.0395 to 3.0387. Saving model...\n",
      "\n",
      "LOG: Epoch [290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6681\n",
      "Epoch [290/2000], Avg Train Loss: 4.6681\n",
      "Epoch [290/2000], Avg Val Loss: 3.0380\n",
      "Validation loss improved from 3.0387 to 3.0380. Saving model...\n",
      "\n",
      "LOG: Epoch [291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6596\n",
      "Epoch [291/2000], Avg Train Loss: 4.6596\n",
      "Epoch [291/2000], Avg Val Loss: 3.0372\n",
      "Validation loss improved from 3.0380 to 3.0372. Saving model...\n",
      "\n",
      "LOG: Epoch [292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6668\n",
      "Epoch [292/2000], Avg Train Loss: 4.6668\n",
      "Epoch [292/2000], Avg Val Loss: 3.0364\n",
      "Validation loss improved from 3.0372 to 3.0364. Saving model...\n",
      "\n",
      "LOG: Epoch [293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6558\n",
      "Epoch [293/2000], Avg Train Loss: 4.6558\n",
      "Epoch [293/2000], Avg Val Loss: 3.0356\n",
      "Validation loss improved from 3.0364 to 3.0356. Saving model...\n",
      "\n",
      "LOG: Epoch [294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6610\n",
      "Epoch [294/2000], Avg Train Loss: 4.6610\n",
      "Epoch [294/2000], Avg Val Loss: 3.0349\n",
      "Validation loss improved from 3.0356 to 3.0349. Saving model...\n",
      "\n",
      "LOG: Epoch [295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6435\n",
      "Epoch [295/2000], Avg Train Loss: 4.6435\n",
      "Epoch [295/2000], Avg Val Loss: 3.0341\n",
      "Validation loss improved from 3.0349 to 3.0341. Saving model...\n",
      "\n",
      "LOG: Epoch [296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6588\n",
      "Epoch [296/2000], Avg Train Loss: 4.6588\n",
      "Epoch [296/2000], Avg Val Loss: 3.0333\n",
      "Validation loss improved from 3.0341 to 3.0333. Saving model...\n",
      "\n",
      "LOG: Epoch [297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5939\n",
      "Epoch [297/2000], Avg Train Loss: 4.5939\n",
      "Epoch [297/2000], Avg Val Loss: 3.0325\n",
      "Validation loss improved from 3.0333 to 3.0325. Saving model...\n",
      "\n",
      "LOG: Epoch [298/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.6192\n",
      "Epoch [298/2000], Avg Train Loss: 4.6192\n",
      "Epoch [298/2000], Avg Val Loss: 3.0316\n",
      "Validation loss improved from 3.0325 to 3.0316. Saving model...\n",
      "\n",
      "LOG: Epoch [299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6199\n",
      "Epoch [299/2000], Avg Train Loss: 4.6199\n",
      "Epoch [299/2000], Avg Val Loss: 3.0308\n",
      "Validation loss improved from 3.0316 to 3.0308. Saving model...\n",
      "\n",
      "LOG: Epoch [300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6654\n",
      "Epoch [300/2000], Avg Train Loss: 4.6654\n",
      "Epoch [300/2000], Avg Val Loss: 3.0301\n",
      "Validation loss improved from 3.0308 to 3.0301. Saving model...\n",
      "\n",
      "LOG: Epoch [301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6402\n",
      "Epoch [301/2000], Avg Train Loss: 4.6402\n",
      "Epoch [301/2000], Avg Val Loss: 3.0293\n",
      "Validation loss improved from 3.0301 to 3.0293. Saving model...\n",
      "\n",
      "LOG: Epoch [302/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6556\n",
      "Epoch [302/2000], Avg Train Loss: 4.6556\n",
      "Epoch [302/2000], Avg Val Loss: 3.0285\n",
      "Validation loss improved from 3.0293 to 3.0285. Saving model...\n",
      "\n",
      "LOG: Epoch [303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6257\n",
      "Epoch [303/2000], Avg Train Loss: 4.6257\n",
      "Epoch [303/2000], Avg Val Loss: 3.0278\n",
      "Validation loss improved from 3.0285 to 3.0278. Saving model...\n",
      "\n",
      "LOG: Epoch [304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5814\n",
      "Epoch [304/2000], Avg Train Loss: 4.5814\n",
      "Epoch [304/2000], Avg Val Loss: 3.0270\n",
      "Validation loss improved from 3.0278 to 3.0270. Saving model...\n",
      "\n",
      "LOG: Epoch [305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6260\n",
      "Epoch [305/2000], Avg Train Loss: 4.6260\n",
      "Epoch [305/2000], Avg Val Loss: 3.0262\n",
      "Validation loss improved from 3.0270 to 3.0262. Saving model...\n",
      "\n",
      "LOG: Epoch [306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6451\n",
      "Epoch [306/2000], Avg Train Loss: 4.6451\n",
      "Epoch [306/2000], Avg Val Loss: 3.0255\n",
      "Validation loss improved from 3.0262 to 3.0255. Saving model...\n",
      "\n",
      "LOG: Epoch [307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6161\n",
      "Epoch [307/2000], Avg Train Loss: 4.6161\n",
      "Epoch [307/2000], Avg Val Loss: 3.0247\n",
      "Validation loss improved from 3.0255 to 3.0247. Saving model...\n",
      "\n",
      "LOG: Epoch [308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6402\n",
      "Epoch [308/2000], Avg Train Loss: 4.6402\n",
      "Epoch [308/2000], Avg Val Loss: 3.0240\n",
      "Validation loss improved from 3.0247 to 3.0240. Saving model...\n",
      "\n",
      "LOG: Epoch [309/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.6454\n",
      "Epoch [309/2000], Avg Train Loss: 4.6454\n",
      "Epoch [309/2000], Avg Val Loss: 3.0232\n",
      "Validation loss improved from 3.0240 to 3.0232. Saving model...\n",
      "\n",
      "LOG: Epoch [310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6034\n",
      "Epoch [310/2000], Avg Train Loss: 4.6034\n",
      "Epoch [310/2000], Avg Val Loss: 3.0225\n",
      "Validation loss improved from 3.0232 to 3.0225. Saving model...\n",
      "\n",
      "LOG: Epoch [311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6049\n",
      "Epoch [311/2000], Avg Train Loss: 4.6049\n",
      "Epoch [311/2000], Avg Val Loss: 3.0217\n",
      "Validation loss improved from 3.0225 to 3.0217. Saving model...\n",
      "\n",
      "LOG: Epoch [312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6300\n",
      "Epoch [312/2000], Avg Train Loss: 4.6300\n",
      "Epoch [312/2000], Avg Val Loss: 3.0210\n",
      "Validation loss improved from 3.0217 to 3.0210. Saving model...\n",
      "\n",
      "LOG: Epoch [313/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6082\n",
      "Epoch [313/2000], Avg Train Loss: 4.6082\n",
      "Epoch [313/2000], Avg Val Loss: 3.0202\n",
      "Validation loss improved from 3.0210 to 3.0202. Saving model...\n",
      "\n",
      "LOG: Epoch [314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5938\n",
      "Epoch [314/2000], Avg Train Loss: 4.5938\n",
      "Epoch [314/2000], Avg Val Loss: 3.0194\n",
      "Validation loss improved from 3.0202 to 3.0194. Saving model...\n",
      "\n",
      "LOG: Epoch [315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5588\n",
      "Epoch [315/2000], Avg Train Loss: 4.5588\n",
      "Epoch [315/2000], Avg Val Loss: 3.0187\n",
      "Validation loss improved from 3.0194 to 3.0187. Saving model...\n",
      "\n",
      "LOG: Epoch [316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6301\n",
      "Epoch [316/2000], Avg Train Loss: 4.6301\n",
      "Epoch [316/2000], Avg Val Loss: 3.0179\n",
      "Validation loss improved from 3.0187 to 3.0179. Saving model...\n",
      "\n",
      "LOG: Epoch [317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6389\n",
      "Epoch [317/2000], Avg Train Loss: 4.6389\n",
      "Epoch [317/2000], Avg Val Loss: 3.0171\n",
      "Validation loss improved from 3.0179 to 3.0171. Saving model...\n",
      "\n",
      "LOG: Epoch [318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6140\n",
      "Epoch [318/2000], Avg Train Loss: 4.6140\n",
      "Epoch [318/2000], Avg Val Loss: 3.0164\n",
      "Validation loss improved from 3.0171 to 3.0164. Saving model...\n",
      "\n",
      "LOG: Epoch [319/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.6131\n",
      "Epoch [319/2000], Avg Train Loss: 4.6131\n",
      "Epoch [319/2000], Avg Val Loss: 3.0156\n",
      "Validation loss improved from 3.0164 to 3.0156. Saving model...\n",
      "\n",
      "LOG: Epoch [320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5998\n",
      "Epoch [320/2000], Avg Train Loss: 4.5998\n",
      "Epoch [320/2000], Avg Val Loss: 3.0149\n",
      "Validation loss improved from 3.0156 to 3.0149. Saving model...\n",
      "\n",
      "LOG: Epoch [321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6002\n",
      "Epoch [321/2000], Avg Train Loss: 4.6002\n",
      "Epoch [321/2000], Avg Val Loss: 3.0141\n",
      "Validation loss improved from 3.0149 to 3.0141. Saving model...\n",
      "\n",
      "LOG: Epoch [322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6157\n",
      "Epoch [322/2000], Avg Train Loss: 4.6157\n",
      "Epoch [322/2000], Avg Val Loss: 3.0134\n",
      "Validation loss improved from 3.0141 to 3.0134. Saving model...\n",
      "\n",
      "LOG: Epoch [323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5781\n",
      "Epoch [323/2000], Avg Train Loss: 4.5781\n",
      "Epoch [323/2000], Avg Val Loss: 3.0127\n",
      "Validation loss improved from 3.0134 to 3.0127. Saving model...\n",
      "\n",
      "LOG: Epoch [324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5869\n",
      "Epoch [324/2000], Avg Train Loss: 4.5869\n",
      "Epoch [324/2000], Avg Val Loss: 3.0120\n",
      "Validation loss improved from 3.0127 to 3.0120. Saving model...\n",
      "\n",
      "LOG: Epoch [325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5752\n",
      "Epoch [325/2000], Avg Train Loss: 4.5752\n",
      "Epoch [325/2000], Avg Val Loss: 3.0113\n",
      "Validation loss improved from 3.0120 to 3.0113. Saving model...\n",
      "\n",
      "LOG: Epoch [326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6128\n",
      "Epoch [326/2000], Avg Train Loss: 4.6128\n",
      "Epoch [326/2000], Avg Val Loss: 3.0106\n",
      "Validation loss improved from 3.0113 to 3.0106. Saving model...\n",
      "\n",
      "LOG: Epoch [327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5614\n",
      "Epoch [327/2000], Avg Train Loss: 4.5614\n",
      "Epoch [327/2000], Avg Val Loss: 3.0099\n",
      "Validation loss improved from 3.0106 to 3.0099. Saving model...\n",
      "\n",
      "LOG: Epoch [328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6261\n",
      "Epoch [328/2000], Avg Train Loss: 4.6261\n",
      "Epoch [328/2000], Avg Val Loss: 3.0093\n",
      "Validation loss improved from 3.0099 to 3.0093. Saving model...\n",
      "\n",
      "LOG: Epoch [329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6232\n",
      "Epoch [329/2000], Avg Train Loss: 4.6232\n",
      "Epoch [329/2000], Avg Val Loss: 3.0086\n",
      "Validation loss improved from 3.0093 to 3.0086. Saving model...\n",
      "\n",
      "LOG: Epoch [330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5856\n",
      "Epoch [330/2000], Avg Train Loss: 4.5856\n",
      "Epoch [330/2000], Avg Val Loss: 3.0079\n",
      "Validation loss improved from 3.0086 to 3.0079. Saving model...\n",
      "\n",
      "LOG: Epoch [331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6088\n",
      "Epoch [331/2000], Avg Train Loss: 4.6088\n",
      "Epoch [331/2000], Avg Val Loss: 3.0072\n",
      "Validation loss improved from 3.0079 to 3.0072. Saving model...\n",
      "\n",
      "LOG: Epoch [332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5912\n",
      "Epoch [332/2000], Avg Train Loss: 4.5912\n",
      "Epoch [332/2000], Avg Val Loss: 3.0065\n",
      "Validation loss improved from 3.0072 to 3.0065. Saving model...\n",
      "\n",
      "LOG: Epoch [333/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.5934\n",
      "Epoch [333/2000], Avg Train Loss: 4.5934\n",
      "Epoch [333/2000], Avg Val Loss: 3.0058\n",
      "Validation loss improved from 3.0065 to 3.0058. Saving model...\n",
      "\n",
      "LOG: Epoch [334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5901\n",
      "Epoch [334/2000], Avg Train Loss: 4.5901\n",
      "Epoch [334/2000], Avg Val Loss: 3.0051\n",
      "Validation loss improved from 3.0058 to 3.0051. Saving model...\n",
      "\n",
      "LOG: Epoch [335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5821\n",
      "Epoch [335/2000], Avg Train Loss: 4.5821\n",
      "Epoch [335/2000], Avg Val Loss: 3.0043\n",
      "Validation loss improved from 3.0051 to 3.0043. Saving model...\n",
      "\n",
      "LOG: Epoch [336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5897\n",
      "Epoch [336/2000], Avg Train Loss: 4.5897\n",
      "Epoch [336/2000], Avg Val Loss: 3.0036\n",
      "Validation loss improved from 3.0043 to 3.0036. Saving model...\n",
      "\n",
      "LOG: Epoch [337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5431\n",
      "Epoch [337/2000], Avg Train Loss: 4.5431\n",
      "Epoch [337/2000], Avg Val Loss: 3.0029\n",
      "Validation loss improved from 3.0036 to 3.0029. Saving model...\n",
      "\n",
      "LOG: Epoch [338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5674\n",
      "Epoch [338/2000], Avg Train Loss: 4.5674\n",
      "Epoch [338/2000], Avg Val Loss: 3.0022\n",
      "Validation loss improved from 3.0029 to 3.0022. Saving model...\n",
      "\n",
      "LOG: Epoch [339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6046\n",
      "Epoch [339/2000], Avg Train Loss: 4.6046\n",
      "Epoch [339/2000], Avg Val Loss: 3.0015\n",
      "Validation loss improved from 3.0022 to 3.0015. Saving model...\n",
      "\n",
      "LOG: Epoch [340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5764\n",
      "Epoch [340/2000], Avg Train Loss: 4.5764\n",
      "Epoch [340/2000], Avg Val Loss: 3.0008\n",
      "Validation loss improved from 3.0015 to 3.0008. Saving model...\n",
      "\n",
      "LOG: Epoch [341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5701\n",
      "Epoch [341/2000], Avg Train Loss: 4.5701\n",
      "Epoch [341/2000], Avg Val Loss: 3.0001\n",
      "Validation loss improved from 3.0008 to 3.0001. Saving model...\n",
      "\n",
      "LOG: Epoch [342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6074\n",
      "Epoch [342/2000], Avg Train Loss: 4.6074\n",
      "Epoch [342/2000], Avg Val Loss: 2.9993\n",
      "Validation loss improved from 3.0001 to 2.9993. Saving model...\n",
      "\n",
      "LOG: Epoch [343/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.5717\n",
      "Epoch [343/2000], Avg Train Loss: 4.5717\n",
      "Epoch [343/2000], Avg Val Loss: 2.9986\n",
      "Validation loss improved from 2.9993 to 2.9986. Saving model...\n",
      "\n",
      "LOG: Epoch [344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5396\n",
      "Epoch [344/2000], Avg Train Loss: 4.5396\n",
      "Epoch [344/2000], Avg Val Loss: 2.9979\n",
      "Validation loss improved from 2.9986 to 2.9979. Saving model...\n",
      "\n",
      "LOG: Epoch [345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5517\n",
      "Epoch [345/2000], Avg Train Loss: 4.5517\n",
      "Epoch [345/2000], Avg Val Loss: 2.9972\n",
      "Validation loss improved from 2.9979 to 2.9972. Saving model...\n",
      "\n",
      "LOG: Epoch [346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5818\n",
      "Epoch [346/2000], Avg Train Loss: 4.5818\n",
      "Epoch [346/2000], Avg Val Loss: 2.9965\n",
      "Validation loss improved from 2.9972 to 2.9965. Saving model...\n",
      "\n",
      "LOG: Epoch [347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5818\n",
      "Epoch [347/2000], Avg Train Loss: 4.5818\n",
      "Epoch [347/2000], Avg Val Loss: 2.9958\n",
      "Validation loss improved from 2.9965 to 2.9958. Saving model...\n",
      "\n",
      "LOG: Epoch [348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5498\n",
      "Epoch [348/2000], Avg Train Loss: 4.5498\n",
      "Epoch [348/2000], Avg Val Loss: 2.9951\n",
      "Validation loss improved from 2.9958 to 2.9951. Saving model...\n",
      "\n",
      "LOG: Epoch [349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5383\n",
      "Epoch [349/2000], Avg Train Loss: 4.5383\n",
      "Epoch [349/2000], Avg Val Loss: 2.9944\n",
      "Validation loss improved from 2.9951 to 2.9944. Saving model...\n",
      "\n",
      "LOG: Epoch [350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5246\n",
      "Epoch [350/2000], Avg Train Loss: 4.5246\n",
      "Epoch [350/2000], Avg Val Loss: 2.9938\n",
      "Validation loss improved from 2.9944 to 2.9938. Saving model...\n",
      "\n",
      "LOG: Epoch [351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5831\n",
      "Epoch [351/2000], Avg Train Loss: 4.5831\n",
      "Epoch [351/2000], Avg Val Loss: 2.9931\n",
      "Validation loss improved from 2.9938 to 2.9931. Saving model...\n",
      "\n",
      "LOG: Epoch [352/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.5465\n",
      "Epoch [352/2000], Avg Train Loss: 4.5465\n",
      "Epoch [352/2000], Avg Val Loss: 2.9925\n",
      "Validation loss improved from 2.9931 to 2.9925. Saving model...\n",
      "\n",
      "LOG: Epoch [353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5833\n",
      "Epoch [353/2000], Avg Train Loss: 4.5833\n",
      "Epoch [353/2000], Avg Val Loss: 2.9918\n",
      "Validation loss improved from 2.9925 to 2.9918. Saving model...\n",
      "\n",
      "LOG: Epoch [354/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5460\n",
      "Epoch [354/2000], Avg Train Loss: 4.5460\n",
      "Epoch [354/2000], Avg Val Loss: 2.9911\n",
      "Validation loss improved from 2.9918 to 2.9911. Saving model...\n",
      "\n",
      "LOG: Epoch [355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5471\n",
      "Epoch [355/2000], Avg Train Loss: 4.5471\n",
      "Epoch [355/2000], Avg Val Loss: 2.9905\n",
      "Validation loss improved from 2.9911 to 2.9905. Saving model...\n",
      "\n",
      "LOG: Epoch [356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5827\n",
      "Epoch [356/2000], Avg Train Loss: 4.5827\n",
      "Epoch [356/2000], Avg Val Loss: 2.9898\n",
      "Validation loss improved from 2.9905 to 2.9898. Saving model...\n",
      "\n",
      "LOG: Epoch [357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5705\n",
      "Epoch [357/2000], Avg Train Loss: 4.5705\n",
      "Epoch [357/2000], Avg Val Loss: 2.9891\n",
      "Validation loss improved from 2.9898 to 2.9891. Saving model...\n",
      "\n",
      "LOG: Epoch [358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5160\n",
      "Epoch [358/2000], Avg Train Loss: 4.5160\n",
      "Epoch [358/2000], Avg Val Loss: 2.9885\n",
      "Validation loss improved from 2.9891 to 2.9885. Saving model...\n",
      "\n",
      "LOG: Epoch [359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5265\n",
      "Epoch [359/2000], Avg Train Loss: 4.5265\n",
      "Epoch [359/2000], Avg Val Loss: 2.9878\n",
      "Validation loss improved from 2.9885 to 2.9878. Saving model...\n",
      "\n",
      "LOG: Epoch [360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5439\n",
      "Epoch [360/2000], Avg Train Loss: 4.5439\n",
      "Epoch [360/2000], Avg Val Loss: 2.9871\n",
      "Validation loss improved from 2.9878 to 2.9871. Saving model...\n",
      "\n",
      "LOG: Epoch [361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5550\n",
      "Epoch [361/2000], Avg Train Loss: 4.5550\n",
      "Epoch [361/2000], Avg Val Loss: 2.9865\n",
      "Validation loss improved from 2.9871 to 2.9865. Saving model...\n",
      "\n",
      "LOG: Epoch [362/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5602\n",
      "Epoch [362/2000], Avg Train Loss: 4.5602\n",
      "Epoch [362/2000], Avg Val Loss: 2.9858\n",
      "Validation loss improved from 2.9865 to 2.9858. Saving model...\n",
      "\n",
      "LOG: Epoch [363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5081\n",
      "Epoch [363/2000], Avg Train Loss: 4.5081\n",
      "Epoch [363/2000], Avg Val Loss: 2.9851\n",
      "Validation loss improved from 2.9858 to 2.9851. Saving model...\n",
      "\n",
      "LOG: Epoch [364/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5167\n",
      "Epoch [364/2000], Avg Train Loss: 4.5167\n",
      "Epoch [364/2000], Avg Val Loss: 2.9844\n",
      "Validation loss improved from 2.9851 to 2.9844. Saving model...\n",
      "\n",
      "LOG: Epoch [365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5235\n",
      "Epoch [365/2000], Avg Train Loss: 4.5235\n",
      "Epoch [365/2000], Avg Val Loss: 2.9836\n",
      "Validation loss improved from 2.9844 to 2.9836. Saving model...\n",
      "\n",
      "LOG: Epoch [366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5323\n",
      "Epoch [366/2000], Avg Train Loss: 4.5323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [366/2000], Avg Val Loss: 2.9829\n",
      "Validation loss improved from 2.9836 to 2.9829. Saving model...\n",
      "\n",
      "LOG: Epoch [367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5305\n",
      "Epoch [367/2000], Avg Train Loss: 4.5305\n",
      "Epoch [367/2000], Avg Val Loss: 2.9822\n",
      "Validation loss improved from 2.9829 to 2.9822. Saving model...\n",
      "\n",
      "LOG: Epoch [368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5533\n",
      "Epoch [368/2000], Avg Train Loss: 4.5533\n",
      "Epoch [368/2000], Avg Val Loss: 2.9814\n",
      "Validation loss improved from 2.9822 to 2.9814. Saving model...\n",
      "\n",
      "LOG: Epoch [369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5003\n",
      "Epoch [369/2000], Avg Train Loss: 4.5003\n",
      "Epoch [369/2000], Avg Val Loss: 2.9807\n",
      "Validation loss improved from 2.9814 to 2.9807. Saving model...\n",
      "\n",
      "LOG: Epoch [370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5336\n",
      "Epoch [370/2000], Avg Train Loss: 4.5336\n",
      "Epoch [370/2000], Avg Val Loss: 2.9799\n",
      "Validation loss improved from 2.9807 to 2.9799. Saving model...\n",
      "\n",
      "LOG: Epoch [371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5486\n",
      "Epoch [371/2000], Avg Train Loss: 4.5486\n",
      "Epoch [371/2000], Avg Val Loss: 2.9792\n",
      "Validation loss improved from 2.9799 to 2.9792. Saving model...\n",
      "\n",
      "LOG: Epoch [372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5010\n",
      "Epoch [372/2000], Avg Train Loss: 4.5010\n",
      "Epoch [372/2000], Avg Val Loss: 2.9785\n",
      "Validation loss improved from 2.9792 to 2.9785. Saving model...\n",
      "\n",
      "LOG: Epoch [373/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4980\n",
      "Epoch [373/2000], Avg Train Loss: 4.4980\n",
      "Epoch [373/2000], Avg Val Loss: 2.9778\n",
      "Validation loss improved from 2.9785 to 2.9778. Saving model...\n",
      "\n",
      "LOG: Epoch [374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5600\n",
      "Epoch [374/2000], Avg Train Loss: 4.5600\n",
      "Epoch [374/2000], Avg Val Loss: 2.9772\n",
      "Validation loss improved from 2.9778 to 2.9772. Saving model...\n",
      "\n",
      "LOG: Epoch [375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5118\n",
      "Epoch [375/2000], Avg Train Loss: 4.5118\n",
      "Epoch [375/2000], Avg Val Loss: 2.9765\n",
      "Validation loss improved from 2.9772 to 2.9765. Saving model...\n",
      "\n",
      "LOG: Epoch [376/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.5263\n",
      "Epoch [376/2000], Avg Train Loss: 4.5263\n",
      "Epoch [376/2000], Avg Val Loss: 2.9758\n",
      "Validation loss improved from 2.9765 to 2.9758. Saving model...\n",
      "\n",
      "LOG: Epoch [377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5235\n",
      "Epoch [377/2000], Avg Train Loss: 4.5235\n",
      "Epoch [377/2000], Avg Val Loss: 2.9752\n",
      "Validation loss improved from 2.9758 to 2.9752. Saving model...\n",
      "\n",
      "LOG: Epoch [378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5374\n",
      "Epoch [378/2000], Avg Train Loss: 4.5374\n",
      "Epoch [378/2000], Avg Val Loss: 2.9745\n",
      "Validation loss improved from 2.9752 to 2.9745. Saving model...\n",
      "\n",
      "LOG: Epoch [379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5526\n",
      "Epoch [379/2000], Avg Train Loss: 4.5526\n",
      "Epoch [379/2000], Avg Val Loss: 2.9738\n",
      "Validation loss improved from 2.9745 to 2.9738. Saving model...\n",
      "\n",
      "LOG: Epoch [380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5436\n",
      "Epoch [380/2000], Avg Train Loss: 4.5436\n",
      "Epoch [380/2000], Avg Val Loss: 2.9732\n",
      "Validation loss improved from 2.9738 to 2.9732. Saving model...\n",
      "\n",
      "LOG: Epoch [381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5027\n",
      "Epoch [381/2000], Avg Train Loss: 4.5027\n",
      "Epoch [381/2000], Avg Val Loss: 2.9726\n",
      "Validation loss improved from 2.9732 to 2.9726. Saving model...\n",
      "\n",
      "LOG: Epoch [382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5322\n",
      "Epoch [382/2000], Avg Train Loss: 4.5322\n",
      "Epoch [382/2000], Avg Val Loss: 2.9719\n",
      "Validation loss improved from 2.9726 to 2.9719. Saving model...\n",
      "\n",
      "LOG: Epoch [383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5265\n",
      "Epoch [383/2000], Avg Train Loss: 4.5265\n",
      "Epoch [383/2000], Avg Val Loss: 2.9713\n",
      "Validation loss improved from 2.9719 to 2.9713. Saving model...\n",
      "\n",
      "LOG: Epoch [384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4954\n",
      "Epoch [384/2000], Avg Train Loss: 4.4954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [384/2000], Avg Val Loss: 2.9706\n",
      "Validation loss improved from 2.9713 to 2.9706. Saving model...\n",
      "\n",
      "LOG: Epoch [385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4997\n",
      "Epoch [385/2000], Avg Train Loss: 4.4997\n",
      "Epoch [385/2000], Avg Val Loss: 2.9699\n",
      "Validation loss improved from 2.9706 to 2.9699. Saving model...\n",
      "\n",
      "LOG: Epoch [386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5280\n",
      "Epoch [386/2000], Avg Train Loss: 4.5280\n",
      "Epoch [386/2000], Avg Val Loss: 2.9692\n",
      "Validation loss improved from 2.9699 to 2.9692. Saving model...\n",
      "\n",
      "LOG: Epoch [387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5271\n",
      "Epoch [387/2000], Avg Train Loss: 4.5271\n",
      "Epoch [387/2000], Avg Val Loss: 2.9685\n",
      "Validation loss improved from 2.9692 to 2.9685. Saving model...\n",
      "\n",
      "LOG: Epoch [388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4638\n",
      "Epoch [388/2000], Avg Train Loss: 4.4638\n",
      "Epoch [388/2000], Avg Val Loss: 2.9678\n",
      "Validation loss improved from 2.9685 to 2.9678. Saving model...\n",
      "\n",
      "LOG: Epoch [389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5035\n",
      "Epoch [389/2000], Avg Train Loss: 4.5035\n",
      "Epoch [389/2000], Avg Val Loss: 2.9671\n",
      "Validation loss improved from 2.9678 to 2.9671. Saving model...\n",
      "\n",
      "LOG: Epoch [390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5250\n",
      "Epoch [390/2000], Avg Train Loss: 4.5250\n",
      "Epoch [390/2000], Avg Val Loss: 2.9665\n",
      "Validation loss improved from 2.9671 to 2.9665. Saving model...\n",
      "\n",
      "LOG: Epoch [391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5125\n",
      "Epoch [391/2000], Avg Train Loss: 4.5125\n",
      "Epoch [391/2000], Avg Val Loss: 2.9658\n",
      "Validation loss improved from 2.9665 to 2.9658. Saving model...\n",
      "\n",
      "LOG: Epoch [392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4851\n",
      "Epoch [392/2000], Avg Train Loss: 4.4851\n",
      "Epoch [392/2000], Avg Val Loss: 2.9651\n",
      "Validation loss improved from 2.9658 to 2.9651. Saving model...\n",
      "\n",
      "LOG: Epoch [393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5447\n",
      "Epoch [393/2000], Avg Train Loss: 4.5447\n",
      "Epoch [393/2000], Avg Val Loss: 2.9644\n",
      "Validation loss improved from 2.9651 to 2.9644. Saving model...\n",
      "\n",
      "LOG: Epoch [394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5207\n",
      "Epoch [394/2000], Avg Train Loss: 4.5207\n",
      "Epoch [394/2000], Avg Val Loss: 2.9637\n",
      "Validation loss improved from 2.9644 to 2.9637. Saving model...\n",
      "\n",
      "LOG: Epoch [395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5010\n",
      "Epoch [395/2000], Avg Train Loss: 4.5010\n",
      "Epoch [395/2000], Avg Val Loss: 2.9630\n",
      "Validation loss improved from 2.9637 to 2.9630. Saving model...\n",
      "\n",
      "LOG: Epoch [396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4761\n",
      "Epoch [396/2000], Avg Train Loss: 4.4761\n",
      "Epoch [396/2000], Avg Val Loss: 2.9623\n",
      "Validation loss improved from 2.9630 to 2.9623. Saving model...\n",
      "\n",
      "LOG: Epoch [397/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4908\n",
      "Epoch [397/2000], Avg Train Loss: 4.4908\n",
      "Epoch [397/2000], Avg Val Loss: 2.9616\n",
      "Validation loss improved from 2.9623 to 2.9616. Saving model...\n",
      "\n",
      "LOG: Epoch [398/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5075\n",
      "Epoch [398/2000], Avg Train Loss: 4.5075\n",
      "Epoch [398/2000], Avg Val Loss: 2.9608\n",
      "Validation loss improved from 2.9616 to 2.9608. Saving model...\n",
      "\n",
      "LOG: Epoch [399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4806\n",
      "Epoch [399/2000], Avg Train Loss: 4.4806\n",
      "Epoch [399/2000], Avg Val Loss: 2.9601\n",
      "Validation loss improved from 2.9608 to 2.9601. Saving model...\n",
      "\n",
      "LOG: Epoch [400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4896\n",
      "Epoch [400/2000], Avg Train Loss: 4.4896\n",
      "Epoch [400/2000], Avg Val Loss: 2.9593\n",
      "Validation loss improved from 2.9601 to 2.9593. Saving model...\n",
      "\n",
      "LOG: Epoch [401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4976\n",
      "Epoch [401/2000], Avg Train Loss: 4.4976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [401/2000], Avg Val Loss: 2.9585\n",
      "Validation loss improved from 2.9593 to 2.9585. Saving model...\n",
      "\n",
      "LOG: Epoch [402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4957\n",
      "Epoch [402/2000], Avg Train Loss: 4.4957\n",
      "Epoch [402/2000], Avg Val Loss: 2.9578\n",
      "Validation loss improved from 2.9585 to 2.9578. Saving model...\n",
      "\n",
      "LOG: Epoch [403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5354\n",
      "Epoch [403/2000], Avg Train Loss: 4.5354\n",
      "Epoch [403/2000], Avg Val Loss: 2.9570\n",
      "Validation loss improved from 2.9578 to 2.9570. Saving model...\n",
      "\n",
      "LOG: Epoch [404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4603\n",
      "Epoch [404/2000], Avg Train Loss: 4.4603\n",
      "Epoch [404/2000], Avg Val Loss: 2.9562\n",
      "Validation loss improved from 2.9570 to 2.9562. Saving model...\n",
      "\n",
      "LOG: Epoch [405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4896\n",
      "Epoch [405/2000], Avg Train Loss: 4.4896\n",
      "Epoch [405/2000], Avg Val Loss: 2.9554\n",
      "Validation loss improved from 2.9562 to 2.9554. Saving model...\n",
      "\n",
      "LOG: Epoch [406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4930\n",
      "Epoch [406/2000], Avg Train Loss: 4.4930\n",
      "Epoch [406/2000], Avg Val Loss: 2.9547\n",
      "Validation loss improved from 2.9554 to 2.9547. Saving model...\n",
      "\n",
      "LOG: Epoch [407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4794\n",
      "Epoch [407/2000], Avg Train Loss: 4.4794\n",
      "Epoch [407/2000], Avg Val Loss: 2.9539\n",
      "Validation loss improved from 2.9547 to 2.9539. Saving model...\n",
      "\n",
      "LOG: Epoch [408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4918\n",
      "Epoch [408/2000], Avg Train Loss: 4.4918\n",
      "Epoch [408/2000], Avg Val Loss: 2.9531\n",
      "Validation loss improved from 2.9539 to 2.9531. Saving model...\n",
      "\n",
      "LOG: Epoch [409/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.4672\n",
      "Epoch [409/2000], Avg Train Loss: 4.4672\n",
      "Epoch [409/2000], Avg Val Loss: 2.9523\n",
      "Validation loss improved from 2.9531 to 2.9523. Saving model...\n",
      "\n",
      "LOG: Epoch [410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4583\n",
      "Epoch [410/2000], Avg Train Loss: 4.4583\n",
      "Epoch [410/2000], Avg Val Loss: 2.9515\n",
      "Validation loss improved from 2.9523 to 2.9515. Saving model...\n",
      "\n",
      "LOG: Epoch [411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4760\n",
      "Epoch [411/2000], Avg Train Loss: 4.4760\n",
      "Epoch [411/2000], Avg Val Loss: 2.9508\n",
      "Validation loss improved from 2.9515 to 2.9508. Saving model...\n",
      "\n",
      "LOG: Epoch [412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4738\n",
      "Epoch [412/2000], Avg Train Loss: 4.4738\n",
      "Epoch [412/2000], Avg Val Loss: 2.9501\n",
      "Validation loss improved from 2.9508 to 2.9501. Saving model...\n",
      "\n",
      "LOG: Epoch [413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4451\n",
      "Epoch [413/2000], Avg Train Loss: 4.4451\n",
      "Epoch [413/2000], Avg Val Loss: 2.9493\n",
      "Validation loss improved from 2.9501 to 2.9493. Saving model...\n",
      "\n",
      "LOG: Epoch [414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4527\n",
      "Epoch [414/2000], Avg Train Loss: 4.4527\n",
      "Epoch [414/2000], Avg Val Loss: 2.9485\n",
      "Validation loss improved from 2.9493 to 2.9485. Saving model...\n",
      "\n",
      "LOG: Epoch [415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4763\n",
      "Epoch [415/2000], Avg Train Loss: 4.4763\n",
      "Epoch [415/2000], Avg Val Loss: 2.9477\n",
      "Validation loss improved from 2.9485 to 2.9477. Saving model...\n",
      "\n",
      "LOG: Epoch [416/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4877\n",
      "Epoch [416/2000], Avg Train Loss: 4.4877\n",
      "Epoch [416/2000], Avg Val Loss: 2.9469\n",
      "Validation loss improved from 2.9477 to 2.9469. Saving model...\n",
      "\n",
      "LOG: Epoch [417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4430\n",
      "Epoch [417/2000], Avg Train Loss: 4.4430\n",
      "Epoch [417/2000], Avg Val Loss: 2.9461\n",
      "Validation loss improved from 2.9469 to 2.9461. Saving model...\n",
      "\n",
      "LOG: Epoch [418/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4801\n",
      "Epoch [418/2000], Avg Train Loss: 4.4801\n",
      "Epoch [418/2000], Avg Val Loss: 2.9453\n",
      "Validation loss improved from 2.9461 to 2.9453. Saving model...\n",
      "\n",
      "LOG: Epoch [419/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.4375\n",
      "Epoch [419/2000], Avg Train Loss: 4.4375\n",
      "Epoch [419/2000], Avg Val Loss: 2.9446\n",
      "Validation loss improved from 2.9453 to 2.9446. Saving model...\n",
      "\n",
      "LOG: Epoch [420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4697\n",
      "Epoch [420/2000], Avg Train Loss: 4.4697\n",
      "Epoch [420/2000], Avg Val Loss: 2.9438\n",
      "Validation loss improved from 2.9446 to 2.9438. Saving model...\n",
      "\n",
      "LOG: Epoch [421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4450\n",
      "Epoch [421/2000], Avg Train Loss: 4.4450\n",
      "Epoch [421/2000], Avg Val Loss: 2.9430\n",
      "Validation loss improved from 2.9438 to 2.9430. Saving model...\n",
      "\n",
      "LOG: Epoch [422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4442\n",
      "Epoch [422/2000], Avg Train Loss: 4.4442\n",
      "Epoch [422/2000], Avg Val Loss: 2.9423\n",
      "Validation loss improved from 2.9430 to 2.9423. Saving model...\n",
      "\n",
      "LOG: Epoch [423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4717\n",
      "Epoch [423/2000], Avg Train Loss: 4.4717\n",
      "Epoch [423/2000], Avg Val Loss: 2.9415\n",
      "Validation loss improved from 2.9423 to 2.9415. Saving model...\n",
      "\n",
      "LOG: Epoch [424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4490\n",
      "Epoch [424/2000], Avg Train Loss: 4.4490\n",
      "Epoch [424/2000], Avg Val Loss: 2.9408\n",
      "Validation loss improved from 2.9415 to 2.9408. Saving model...\n",
      "\n",
      "LOG: Epoch [425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4877\n",
      "Epoch [425/2000], Avg Train Loss: 4.4877\n",
      "Epoch [425/2000], Avg Val Loss: 2.9400\n",
      "Validation loss improved from 2.9408 to 2.9400. Saving model...\n",
      "\n",
      "LOG: Epoch [426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4709\n",
      "Epoch [426/2000], Avg Train Loss: 4.4709\n",
      "Epoch [426/2000], Avg Val Loss: 2.9392\n",
      "Validation loss improved from 2.9400 to 2.9392. Saving model...\n",
      "\n",
      "LOG: Epoch [427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4587\n",
      "Epoch [427/2000], Avg Train Loss: 4.4587\n",
      "Epoch [427/2000], Avg Val Loss: 2.9385\n",
      "Validation loss improved from 2.9392 to 2.9385. Saving model...\n",
      "\n",
      "LOG: Epoch [428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4608\n",
      "Epoch [428/2000], Avg Train Loss: 4.4608\n",
      "Epoch [428/2000], Avg Val Loss: 2.9377\n",
      "Validation loss improved from 2.9385 to 2.9377. Saving model...\n",
      "\n",
      "LOG: Epoch [429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4496\n",
      "Epoch [429/2000], Avg Train Loss: 4.4496\n",
      "Epoch [429/2000], Avg Val Loss: 2.9369\n",
      "Validation loss improved from 2.9377 to 2.9369. Saving model...\n",
      "\n",
      "LOG: Epoch [430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4600\n",
      "Epoch [430/2000], Avg Train Loss: 4.4600\n",
      "Epoch [430/2000], Avg Val Loss: 2.9362\n",
      "Validation loss improved from 2.9369 to 2.9362. Saving model...\n",
      "\n",
      "LOG: Epoch [431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4787\n",
      "Epoch [431/2000], Avg Train Loss: 4.4787\n",
      "Epoch [431/2000], Avg Val Loss: 2.9354\n",
      "Validation loss improved from 2.9362 to 2.9354. Saving model...\n",
      "\n",
      "LOG: Epoch [432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4252\n",
      "Epoch [432/2000], Avg Train Loss: 4.4252\n",
      "Epoch [432/2000], Avg Val Loss: 2.9347\n",
      "Validation loss improved from 2.9354 to 2.9347. Saving model...\n",
      "\n",
      "LOG: Epoch [433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4649\n",
      "Epoch [433/2000], Avg Train Loss: 4.4649\n",
      "Epoch [433/2000], Avg Val Loss: 2.9339\n",
      "Validation loss improved from 2.9347 to 2.9339. Saving model...\n",
      "\n",
      "LOG: Epoch [434/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4501\n",
      "Epoch [434/2000], Avg Train Loss: 4.4501\n",
      "Epoch [434/2000], Avg Val Loss: 2.9332\n",
      "Validation loss improved from 2.9339 to 2.9332. Saving model...\n",
      "\n",
      "LOG: Epoch [435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4822\n",
      "Epoch [435/2000], Avg Train Loss: 4.4822\n",
      "Epoch [435/2000], Avg Val Loss: 2.9324\n",
      "Validation loss improved from 2.9332 to 2.9324. Saving model...\n",
      "\n",
      "LOG: Epoch [436/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4079\n",
      "Epoch [436/2000], Avg Train Loss: 4.4079\n",
      "Epoch [436/2000], Avg Val Loss: 2.9316\n",
      "Validation loss improved from 2.9324 to 2.9316. Saving model...\n",
      "\n",
      "LOG: Epoch [437/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.4471\n",
      "Epoch [437/2000], Avg Train Loss: 4.4471\n",
      "Epoch [437/2000], Avg Val Loss: 2.9308\n",
      "Validation loss improved from 2.9316 to 2.9308. Saving model...\n",
      "\n",
      "LOG: Epoch [438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4288\n",
      "Epoch [438/2000], Avg Train Loss: 4.4288\n",
      "Epoch [438/2000], Avg Val Loss: 2.9300\n",
      "Validation loss improved from 2.9308 to 2.9300. Saving model...\n",
      "\n",
      "LOG: Epoch [439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4280\n",
      "Epoch [439/2000], Avg Train Loss: 4.4280\n",
      "Epoch [439/2000], Avg Val Loss: 2.9292\n",
      "Validation loss improved from 2.9300 to 2.9292. Saving model...\n",
      "\n",
      "LOG: Epoch [440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4390\n",
      "Epoch [440/2000], Avg Train Loss: 4.4390\n",
      "Epoch [440/2000], Avg Val Loss: 2.9284\n",
      "Validation loss improved from 2.9292 to 2.9284. Saving model...\n",
      "\n",
      "LOG: Epoch [441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4286\n",
      "Epoch [441/2000], Avg Train Loss: 4.4286\n",
      "Epoch [441/2000], Avg Val Loss: 2.9276\n",
      "Validation loss improved from 2.9284 to 2.9276. Saving model...\n",
      "\n",
      "LOG: Epoch [442/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4179\n",
      "Epoch [442/2000], Avg Train Loss: 4.4179\n",
      "Epoch [442/2000], Avg Val Loss: 2.9267\n",
      "Validation loss improved from 2.9276 to 2.9267. Saving model...\n",
      "\n",
      "LOG: Epoch [443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4612\n",
      "Epoch [443/2000], Avg Train Loss: 4.4612\n",
      "Epoch [443/2000], Avg Val Loss: 2.9259\n",
      "Validation loss improved from 2.9267 to 2.9259. Saving model...\n",
      "\n",
      "LOG: Epoch [444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4464\n",
      "Epoch [444/2000], Avg Train Loss: 4.4464\n",
      "Epoch [444/2000], Avg Val Loss: 2.9252\n",
      "Validation loss improved from 2.9259 to 2.9252. Saving model...\n",
      "\n",
      "LOG: Epoch [445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4251\n",
      "Epoch [445/2000], Avg Train Loss: 4.4251\n",
      "Epoch [445/2000], Avg Val Loss: 2.9244\n",
      "Validation loss improved from 2.9252 to 2.9244. Saving model...\n",
      "\n",
      "LOG: Epoch [446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4155\n",
      "Epoch [446/2000], Avg Train Loss: 4.4155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [446/2000], Avg Val Loss: 2.9236\n",
      "Validation loss improved from 2.9244 to 2.9236. Saving model...\n",
      "\n",
      "LOG: Epoch [447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4101\n",
      "Epoch [447/2000], Avg Train Loss: 4.4101\n",
      "Epoch [447/2000], Avg Val Loss: 2.9228\n",
      "Validation loss improved from 2.9236 to 2.9228. Saving model...\n",
      "\n",
      "LOG: Epoch [448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3975\n",
      "Epoch [448/2000], Avg Train Loss: 4.3975\n",
      "Epoch [448/2000], Avg Val Loss: 2.9220\n",
      "Validation loss improved from 2.9228 to 2.9220. Saving model...\n",
      "\n",
      "LOG: Epoch [449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4154\n",
      "Epoch [449/2000], Avg Train Loss: 4.4154\n",
      "Epoch [449/2000], Avg Val Loss: 2.9212\n",
      "Validation loss improved from 2.9220 to 2.9212. Saving model...\n",
      "\n",
      "LOG: Epoch [450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4211\n",
      "Epoch [450/2000], Avg Train Loss: 4.4211\n",
      "Epoch [450/2000], Avg Val Loss: 2.9204\n",
      "Validation loss improved from 2.9212 to 2.9204. Saving model...\n",
      "\n",
      "LOG: Epoch [451/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4413\n",
      "Epoch [451/2000], Avg Train Loss: 4.4413\n",
      "Epoch [451/2000], Avg Val Loss: 2.9195\n",
      "Validation loss improved from 2.9204 to 2.9195. Saving model...\n",
      "\n",
      "LOG: Epoch [452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4321\n",
      "Epoch [452/2000], Avg Train Loss: 4.4321\n",
      "Epoch [452/2000], Avg Val Loss: 2.9187\n",
      "Validation loss improved from 2.9195 to 2.9187. Saving model...\n",
      "\n",
      "LOG: Epoch [453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4333\n",
      "Epoch [453/2000], Avg Train Loss: 4.4333\n",
      "Epoch [453/2000], Avg Val Loss: 2.9179\n",
      "Validation loss improved from 2.9187 to 2.9179. Saving model...\n",
      "\n",
      "LOG: Epoch [454/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.4001\n",
      "Epoch [454/2000], Avg Train Loss: 4.4001\n",
      "Epoch [454/2000], Avg Val Loss: 2.9171\n",
      "Validation loss improved from 2.9179 to 2.9171. Saving model...\n",
      "\n",
      "LOG: Epoch [455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4299\n",
      "Epoch [455/2000], Avg Train Loss: 4.4299\n",
      "Epoch [455/2000], Avg Val Loss: 2.9163\n",
      "Validation loss improved from 2.9171 to 2.9163. Saving model...\n",
      "\n",
      "LOG: Epoch [456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4255\n",
      "Epoch [456/2000], Avg Train Loss: 4.4255\n",
      "Epoch [456/2000], Avg Val Loss: 2.9155\n",
      "Validation loss improved from 2.9163 to 2.9155. Saving model...\n",
      "\n",
      "LOG: Epoch [457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4086\n",
      "Epoch [457/2000], Avg Train Loss: 4.4086\n",
      "Epoch [457/2000], Avg Val Loss: 2.9147\n",
      "Validation loss improved from 2.9155 to 2.9147. Saving model...\n",
      "\n",
      "LOG: Epoch [458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4395\n",
      "Epoch [458/2000], Avg Train Loss: 4.4395\n",
      "Epoch [458/2000], Avg Val Loss: 2.9139\n",
      "Validation loss improved from 2.9147 to 2.9139. Saving model...\n",
      "\n",
      "LOG: Epoch [459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4460\n",
      "Epoch [459/2000], Avg Train Loss: 4.4460\n",
      "Epoch [459/2000], Avg Val Loss: 2.9132\n",
      "Validation loss improved from 2.9139 to 2.9132. Saving model...\n",
      "\n",
      "LOG: Epoch [460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4153\n",
      "Epoch [460/2000], Avg Train Loss: 4.4153\n",
      "Epoch [460/2000], Avg Val Loss: 2.9124\n",
      "Validation loss improved from 2.9132 to 2.9124. Saving model...\n",
      "\n",
      "LOG: Epoch [461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3931\n",
      "Epoch [461/2000], Avg Train Loss: 4.3931\n",
      "Epoch [461/2000], Avg Val Loss: 2.9116\n",
      "Validation loss improved from 2.9124 to 2.9116. Saving model...\n",
      "\n",
      "LOG: Epoch [462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3840\n",
      "Epoch [462/2000], Avg Train Loss: 4.3840\n",
      "Epoch [462/2000], Avg Val Loss: 2.9108\n",
      "Validation loss improved from 2.9116 to 2.9108. Saving model...\n",
      "\n",
      "LOG: Epoch [463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3950\n",
      "Epoch [463/2000], Avg Train Loss: 4.3950\n",
      "Epoch [463/2000], Avg Val Loss: 2.9100\n",
      "Validation loss improved from 2.9108 to 2.9100. Saving model...\n",
      "\n",
      "LOG: Epoch [464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4262\n",
      "Epoch [464/2000], Avg Train Loss: 4.4262\n",
      "Epoch [464/2000], Avg Val Loss: 2.9091\n",
      "Validation loss improved from 2.9100 to 2.9091. Saving model...\n",
      "\n",
      "LOG: Epoch [465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4212\n",
      "Epoch [465/2000], Avg Train Loss: 4.4212\n",
      "Epoch [465/2000], Avg Val Loss: 2.9082\n",
      "Validation loss improved from 2.9091 to 2.9082. Saving model...\n",
      "\n",
      "LOG: Epoch [466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3675\n",
      "Epoch [466/2000], Avg Train Loss: 4.3675\n",
      "Epoch [466/2000], Avg Val Loss: 2.9073\n",
      "Validation loss improved from 2.9082 to 2.9073. Saving model...\n",
      "\n",
      "LOG: Epoch [467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3834\n",
      "Epoch [467/2000], Avg Train Loss: 4.3834\n",
      "Epoch [467/2000], Avg Val Loss: 2.9064\n",
      "Validation loss improved from 2.9073 to 2.9064. Saving model...\n",
      "\n",
      "LOG: Epoch [468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4189\n",
      "Epoch [468/2000], Avg Train Loss: 4.4189\n",
      "Epoch [468/2000], Avg Val Loss: 2.9055\n",
      "Validation loss improved from 2.9064 to 2.9055. Saving model...\n",
      "\n",
      "LOG: Epoch [469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4053\n",
      "Epoch [469/2000], Avg Train Loss: 4.4053\n",
      "Epoch [469/2000], Avg Val Loss: 2.9046\n",
      "Validation loss improved from 2.9055 to 2.9046. Saving model...\n",
      "\n",
      "LOG: Epoch [470/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3805\n",
      "Epoch [470/2000], Avg Train Loss: 4.3805\n",
      "Epoch [470/2000], Avg Val Loss: 2.9036\n",
      "Validation loss improved from 2.9046 to 2.9036. Saving model...\n",
      "\n",
      "LOG: Epoch [471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4043\n",
      "Epoch [471/2000], Avg Train Loss: 4.4043\n",
      "Epoch [471/2000], Avg Val Loss: 2.9027\n",
      "Validation loss improved from 2.9036 to 2.9027. Saving model...\n",
      "\n",
      "LOG: Epoch [472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4162\n",
      "Epoch [472/2000], Avg Train Loss: 4.4162\n",
      "Epoch [472/2000], Avg Val Loss: 2.9018\n",
      "Validation loss improved from 2.9027 to 2.9018. Saving model...\n",
      "\n",
      "LOG: Epoch [473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3634\n",
      "Epoch [473/2000], Avg Train Loss: 4.3634\n",
      "Epoch [473/2000], Avg Val Loss: 2.9009\n",
      "Validation loss improved from 2.9018 to 2.9009. Saving model...\n",
      "\n",
      "LOG: Epoch [474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4110\n",
      "Epoch [474/2000], Avg Train Loss: 4.4110\n",
      "Epoch [474/2000], Avg Val Loss: 2.8999\n",
      "Validation loss improved from 2.9009 to 2.8999. Saving model...\n",
      "\n",
      "LOG: Epoch [475/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3607\n",
      "Epoch [475/2000], Avg Train Loss: 4.3607\n",
      "Epoch [475/2000], Avg Val Loss: 2.8990\n",
      "Validation loss improved from 2.8999 to 2.8990. Saving model...\n",
      "\n",
      "LOG: Epoch [476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3852\n",
      "Epoch [476/2000], Avg Train Loss: 4.3852\n",
      "Epoch [476/2000], Avg Val Loss: 2.8980\n",
      "Validation loss improved from 2.8990 to 2.8980. Saving model...\n",
      "\n",
      "LOG: Epoch [477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3868\n",
      "Epoch [477/2000], Avg Train Loss: 4.3868\n",
      "Epoch [477/2000], Avg Val Loss: 2.8971\n",
      "Validation loss improved from 2.8980 to 2.8971. Saving model...\n",
      "\n",
      "LOG: Epoch [478/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3844\n",
      "Epoch [478/2000], Avg Train Loss: 4.3844\n",
      "Epoch [478/2000], Avg Val Loss: 2.8962\n",
      "Validation loss improved from 2.8971 to 2.8962. Saving model...\n",
      "\n",
      "LOG: Epoch [479/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3860\n",
      "Epoch [479/2000], Avg Train Loss: 4.3860\n",
      "Epoch [479/2000], Avg Val Loss: 2.8952\n",
      "Validation loss improved from 2.8962 to 2.8952. Saving model...\n",
      "\n",
      "LOG: Epoch [480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4268\n",
      "Epoch [480/2000], Avg Train Loss: 4.4268\n",
      "Epoch [480/2000], Avg Val Loss: 2.8943\n",
      "Validation loss improved from 2.8952 to 2.8943. Saving model...\n",
      "\n",
      "LOG: Epoch [481/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4028\n",
      "Epoch [481/2000], Avg Train Loss: 4.4028\n",
      "Epoch [481/2000], Avg Val Loss: 2.8934\n",
      "Validation loss improved from 2.8943 to 2.8934. Saving model...\n",
      "\n",
      "LOG: Epoch [482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3790\n",
      "Epoch [482/2000], Avg Train Loss: 4.3790\n",
      "Epoch [482/2000], Avg Val Loss: 2.8924\n",
      "Validation loss improved from 2.8934 to 2.8924. Saving model...\n",
      "\n",
      "LOG: Epoch [483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4028\n",
      "Epoch [483/2000], Avg Train Loss: 4.4028\n",
      "Epoch [483/2000], Avg Val Loss: 2.8914\n",
      "Validation loss improved from 2.8924 to 2.8914. Saving model...\n",
      "\n",
      "LOG: Epoch [484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3784\n",
      "Epoch [484/2000], Avg Train Loss: 4.3784\n",
      "Epoch [484/2000], Avg Val Loss: 2.8904\n",
      "Validation loss improved from 2.8914 to 2.8904. Saving model...\n",
      "\n",
      "LOG: Epoch [485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3692\n",
      "Epoch [485/2000], Avg Train Loss: 4.3692\n",
      "Epoch [485/2000], Avg Val Loss: 2.8895\n",
      "Validation loss improved from 2.8904 to 2.8895. Saving model...\n",
      "\n",
      "LOG: Epoch [486/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3901\n",
      "Epoch [486/2000], Avg Train Loss: 4.3901\n",
      "Epoch [486/2000], Avg Val Loss: 2.8885\n",
      "Validation loss improved from 2.8895 to 2.8885. Saving model...\n",
      "\n",
      "LOG: Epoch [487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3566\n",
      "Epoch [487/2000], Avg Train Loss: 4.3566\n",
      "Epoch [487/2000], Avg Val Loss: 2.8874\n",
      "Validation loss improved from 2.8885 to 2.8874. Saving model...\n",
      "\n",
      "LOG: Epoch [488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3751\n",
      "Epoch [488/2000], Avg Train Loss: 4.3751\n",
      "Epoch [488/2000], Avg Val Loss: 2.8865\n",
      "Validation loss improved from 2.8874 to 2.8865. Saving model...\n",
      "\n",
      "LOG: Epoch [489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3509\n",
      "Epoch [489/2000], Avg Train Loss: 4.3509\n",
      "Epoch [489/2000], Avg Val Loss: 2.8855\n",
      "Validation loss improved from 2.8865 to 2.8855. Saving model...\n",
      "\n",
      "LOG: Epoch [490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3801\n",
      "Epoch [490/2000], Avg Train Loss: 4.3801\n",
      "Epoch [490/2000], Avg Val Loss: 2.8845\n",
      "Validation loss improved from 2.8855 to 2.8845. Saving model...\n",
      "\n",
      "LOG: Epoch [491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3765\n",
      "Epoch [491/2000], Avg Train Loss: 4.3765\n",
      "Epoch [491/2000], Avg Val Loss: 2.8835\n",
      "Validation loss improved from 2.8845 to 2.8835. Saving model...\n",
      "\n",
      "LOG: Epoch [492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3658\n",
      "Epoch [492/2000], Avg Train Loss: 4.3658\n",
      "Epoch [492/2000], Avg Val Loss: 2.8825\n",
      "Validation loss improved from 2.8835 to 2.8825. Saving model...\n",
      "\n",
      "LOG: Epoch [493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3809\n",
      "Epoch [493/2000], Avg Train Loss: 4.3809\n",
      "Epoch [493/2000], Avg Val Loss: 2.8815\n",
      "Validation loss improved from 2.8825 to 2.8815. Saving model...\n",
      "\n",
      "LOG: Epoch [494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3772\n",
      "Epoch [494/2000], Avg Train Loss: 4.3772\n",
      "Epoch [494/2000], Avg Val Loss: 2.8805\n",
      "Validation loss improved from 2.8815 to 2.8805. Saving model...\n",
      "\n",
      "LOG: Epoch [495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3917\n",
      "Epoch [495/2000], Avg Train Loss: 4.3917\n",
      "Epoch [495/2000], Avg Val Loss: 2.8795\n",
      "Validation loss improved from 2.8805 to 2.8795. Saving model...\n",
      "\n",
      "LOG: Epoch [496/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3534\n",
      "Epoch [496/2000], Avg Train Loss: 4.3534\n",
      "Epoch [496/2000], Avg Val Loss: 2.8786\n",
      "Validation loss improved from 2.8795 to 2.8786. Saving model...\n",
      "\n",
      "LOG: Epoch [497/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3950\n",
      "Epoch [497/2000], Avg Train Loss: 4.3950\n",
      "Epoch [497/2000], Avg Val Loss: 2.8776\n",
      "Validation loss improved from 2.8786 to 2.8776. Saving model...\n",
      "\n",
      "LOG: Epoch [498/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3926\n",
      "Epoch [498/2000], Avg Train Loss: 4.3926\n",
      "Epoch [498/2000], Avg Val Loss: 2.8767\n",
      "Validation loss improved from 2.8776 to 2.8767. Saving model...\n",
      "\n",
      "LOG: Epoch [499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3722\n",
      "Epoch [499/2000], Avg Train Loss: 4.3722\n",
      "Epoch [499/2000], Avg Val Loss: 2.8757\n",
      "Validation loss improved from 2.8767 to 2.8757. Saving model...\n",
      "\n",
      "LOG: Epoch [500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3342\n",
      "Epoch [500/2000], Avg Train Loss: 4.3342\n",
      "Epoch [500/2000], Avg Val Loss: 2.8748\n",
      "Validation loss improved from 2.8757 to 2.8748. Saving model...\n",
      "\n",
      "LOG: Epoch [501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3618\n",
      "Epoch [501/2000], Avg Train Loss: 4.3618\n",
      "Epoch [501/2000], Avg Val Loss: 2.8738\n",
      "Validation loss improved from 2.8748 to 2.8738. Saving model...\n",
      "\n",
      "LOG: Epoch [502/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3356\n",
      "Epoch [502/2000], Avg Train Loss: 4.3356\n",
      "Epoch [502/2000], Avg Val Loss: 2.8728\n",
      "Validation loss improved from 2.8738 to 2.8728. Saving model...\n",
      "\n",
      "LOG: Epoch [503/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3451\n",
      "Epoch [503/2000], Avg Train Loss: 4.3451\n",
      "Epoch [503/2000], Avg Val Loss: 2.8717\n",
      "Validation loss improved from 2.8728 to 2.8717. Saving model...\n",
      "\n",
      "LOG: Epoch [504/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3809\n",
      "Epoch [504/2000], Avg Train Loss: 4.3809\n",
      "Epoch [504/2000], Avg Val Loss: 2.8707\n",
      "Validation loss improved from 2.8717 to 2.8707. Saving model...\n",
      "\n",
      "LOG: Epoch [505/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3505\n",
      "Epoch [505/2000], Avg Train Loss: 4.3505\n",
      "Epoch [505/2000], Avg Val Loss: 2.8697\n",
      "Validation loss improved from 2.8707 to 2.8697. Saving model...\n",
      "\n",
      "LOG: Epoch [506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3123\n",
      "Epoch [506/2000], Avg Train Loss: 4.3123\n",
      "Epoch [506/2000], Avg Val Loss: 2.8687\n",
      "Validation loss improved from 2.8697 to 2.8687. Saving model...\n",
      "\n",
      "LOG: Epoch [507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3579\n",
      "Epoch [507/2000], Avg Train Loss: 4.3579\n",
      "Epoch [507/2000], Avg Val Loss: 2.8677\n",
      "Validation loss improved from 2.8687 to 2.8677. Saving model...\n",
      "\n",
      "LOG: Epoch [508/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3597\n",
      "Epoch [508/2000], Avg Train Loss: 4.3597\n",
      "Epoch [508/2000], Avg Val Loss: 2.8667\n",
      "Validation loss improved from 2.8677 to 2.8667. Saving model...\n",
      "\n",
      "LOG: Epoch [509/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3441\n",
      "Epoch [509/2000], Avg Train Loss: 4.3441\n",
      "Epoch [509/2000], Avg Val Loss: 2.8657\n",
      "Validation loss improved from 2.8667 to 2.8657. Saving model...\n",
      "\n",
      "LOG: Epoch [510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3611\n",
      "Epoch [510/2000], Avg Train Loss: 4.3611\n",
      "Epoch [510/2000], Avg Val Loss: 2.8647\n",
      "Validation loss improved from 2.8657 to 2.8647. Saving model...\n",
      "\n",
      "LOG: Epoch [511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2827\n",
      "Epoch [511/2000], Avg Train Loss: 4.2827\n",
      "Epoch [511/2000], Avg Val Loss: 2.8637\n",
      "Validation loss improved from 2.8647 to 2.8637. Saving model...\n",
      "\n",
      "LOG: Epoch [512/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3979\n",
      "Epoch [512/2000], Avg Train Loss: 4.3979\n",
      "Epoch [512/2000], Avg Val Loss: 2.8627\n",
      "Validation loss improved from 2.8637 to 2.8627. Saving model...\n",
      "\n",
      "LOG: Epoch [513/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3401\n",
      "Epoch [513/2000], Avg Train Loss: 4.3401\n",
      "Epoch [513/2000], Avg Val Loss: 2.8617\n",
      "Validation loss improved from 2.8627 to 2.8617. Saving model...\n",
      "\n",
      "LOG: Epoch [514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3784\n",
      "Epoch [514/2000], Avg Train Loss: 4.3784\n",
      "Epoch [514/2000], Avg Val Loss: 2.8608\n",
      "Validation loss improved from 2.8617 to 2.8608. Saving model...\n",
      "\n",
      "LOG: Epoch [515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3150\n",
      "Epoch [515/2000], Avg Train Loss: 4.3150\n",
      "Epoch [515/2000], Avg Val Loss: 2.8598\n",
      "Validation loss improved from 2.8608 to 2.8598. Saving model...\n",
      "\n",
      "LOG: Epoch [516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3841\n",
      "Epoch [516/2000], Avg Train Loss: 4.3841\n",
      "Epoch [516/2000], Avg Val Loss: 2.8588\n",
      "Validation loss improved from 2.8598 to 2.8588. Saving model...\n",
      "\n",
      "LOG: Epoch [517/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3151\n",
      "Epoch [517/2000], Avg Train Loss: 4.3151\n",
      "Epoch [517/2000], Avg Val Loss: 2.8579\n",
      "Validation loss improved from 2.8588 to 2.8579. Saving model...\n",
      "\n",
      "LOG: Epoch [518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3327\n",
      "Epoch [518/2000], Avg Train Loss: 4.3327\n",
      "Epoch [518/2000], Avg Val Loss: 2.8569\n",
      "Validation loss improved from 2.8579 to 2.8569. Saving model...\n",
      "\n",
      "LOG: Epoch [519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3408\n",
      "Epoch [519/2000], Avg Train Loss: 4.3408\n",
      "Epoch [519/2000], Avg Val Loss: 2.8559\n",
      "Validation loss improved from 2.8569 to 2.8559. Saving model...\n",
      "\n",
      "LOG: Epoch [520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2996\n",
      "Epoch [520/2000], Avg Train Loss: 4.2996\n",
      "Epoch [520/2000], Avg Val Loss: 2.8549\n",
      "Validation loss improved from 2.8559 to 2.8549. Saving model...\n",
      "\n",
      "LOG: Epoch [521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3335\n",
      "Epoch [521/2000], Avg Train Loss: 4.3335\n",
      "Epoch [521/2000], Avg Val Loss: 2.8539\n",
      "Validation loss improved from 2.8549 to 2.8539. Saving model...\n",
      "\n",
      "LOG: Epoch [522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3360\n",
      "Epoch [522/2000], Avg Train Loss: 4.3360\n",
      "Epoch [522/2000], Avg Val Loss: 2.8529\n",
      "Validation loss improved from 2.8539 to 2.8529. Saving model...\n",
      "\n",
      "LOG: Epoch [523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3588\n",
      "Epoch [523/2000], Avg Train Loss: 4.3588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [523/2000], Avg Val Loss: 2.8520\n",
      "Validation loss improved from 2.8529 to 2.8520. Saving model...\n",
      "\n",
      "LOG: Epoch [524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3470\n",
      "Epoch [524/2000], Avg Train Loss: 4.3470\n",
      "Epoch [524/2000], Avg Val Loss: 2.8510\n",
      "Validation loss improved from 2.8520 to 2.8510. Saving model...\n",
      "\n",
      "LOG: Epoch [525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3067\n",
      "Epoch [525/2000], Avg Train Loss: 4.3067\n",
      "Epoch [525/2000], Avg Val Loss: 2.8501\n",
      "Validation loss improved from 2.8510 to 2.8501. Saving model...\n",
      "\n",
      "LOG: Epoch [526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3279\n",
      "Epoch [526/2000], Avg Train Loss: 4.3279\n",
      "Epoch [526/2000], Avg Val Loss: 2.8490\n",
      "Validation loss improved from 2.8501 to 2.8490. Saving model...\n",
      "\n",
      "LOG: Epoch [527/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3218\n",
      "Epoch [527/2000], Avg Train Loss: 4.3218\n",
      "Epoch [527/2000], Avg Val Loss: 2.8480\n",
      "Validation loss improved from 2.8490 to 2.8480. Saving model...\n",
      "\n",
      "LOG: Epoch [528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3198\n",
      "Epoch [528/2000], Avg Train Loss: 4.3198\n",
      "Epoch [528/2000], Avg Val Loss: 2.8469\n",
      "Validation loss improved from 2.8480 to 2.8469. Saving model...\n",
      "\n",
      "LOG: Epoch [529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3025\n",
      "Epoch [529/2000], Avg Train Loss: 4.3025\n",
      "Epoch [529/2000], Avg Val Loss: 2.8458\n",
      "Validation loss improved from 2.8469 to 2.8458. Saving model...\n",
      "\n",
      "LOG: Epoch [530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3142\n",
      "Epoch [530/2000], Avg Train Loss: 4.3142\n",
      "Epoch [530/2000], Avg Val Loss: 2.8447\n",
      "Validation loss improved from 2.8458 to 2.8447. Saving model...\n",
      "\n",
      "LOG: Epoch [531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3170\n",
      "Epoch [531/2000], Avg Train Loss: 4.3170\n",
      "Epoch [531/2000], Avg Val Loss: 2.8435\n",
      "Validation loss improved from 2.8447 to 2.8435. Saving model...\n",
      "\n",
      "LOG: Epoch [532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3131\n",
      "Epoch [532/2000], Avg Train Loss: 4.3131\n",
      "Epoch [532/2000], Avg Val Loss: 2.8424\n",
      "Validation loss improved from 2.8435 to 2.8424. Saving model...\n",
      "\n",
      "LOG: Epoch [533/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3268\n",
      "Epoch [533/2000], Avg Train Loss: 4.3268\n",
      "Epoch [533/2000], Avg Val Loss: 2.8413\n",
      "Validation loss improved from 2.8424 to 2.8413. Saving model...\n",
      "\n",
      "LOG: Epoch [534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3488\n",
      "Epoch [534/2000], Avg Train Loss: 4.3488\n",
      "Epoch [534/2000], Avg Val Loss: 2.8402\n",
      "Validation loss improved from 2.8413 to 2.8402. Saving model...\n",
      "\n",
      "LOG: Epoch [535/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2934\n",
      "Epoch [535/2000], Avg Train Loss: 4.2934\n",
      "Epoch [535/2000], Avg Val Loss: 2.8392\n",
      "Validation loss improved from 2.8402 to 2.8392. Saving model...\n",
      "\n",
      "LOG: Epoch [536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3484\n",
      "Epoch [536/2000], Avg Train Loss: 4.3484\n",
      "Epoch [536/2000], Avg Val Loss: 2.8381\n",
      "Validation loss improved from 2.8392 to 2.8381. Saving model...\n",
      "\n",
      "LOG: Epoch [537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3164\n",
      "Epoch [537/2000], Avg Train Loss: 4.3164\n",
      "Epoch [537/2000], Avg Val Loss: 2.8372\n",
      "Validation loss improved from 2.8381 to 2.8372. Saving model...\n",
      "\n",
      "LOG: Epoch [538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2856\n",
      "Epoch [538/2000], Avg Train Loss: 4.2856\n",
      "Epoch [538/2000], Avg Val Loss: 2.8362\n",
      "Validation loss improved from 2.8372 to 2.8362. Saving model...\n",
      "\n",
      "LOG: Epoch [539/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3369\n",
      "Epoch [539/2000], Avg Train Loss: 4.3369\n",
      "Epoch [539/2000], Avg Val Loss: 2.8352\n",
      "Validation loss improved from 2.8362 to 2.8352. Saving model...\n",
      "\n",
      "LOG: Epoch [540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2906\n",
      "Epoch [540/2000], Avg Train Loss: 4.2906\n",
      "Epoch [540/2000], Avg Val Loss: 2.8343\n",
      "Validation loss improved from 2.8352 to 2.8343. Saving model...\n",
      "\n",
      "LOG: Epoch [541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3068\n",
      "Epoch [541/2000], Avg Train Loss: 4.3068\n",
      "Epoch [541/2000], Avg Val Loss: 2.8332\n",
      "Validation loss improved from 2.8343 to 2.8332. Saving model...\n",
      "\n",
      "LOG: Epoch [542/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2532\n",
      "Epoch [542/2000], Avg Train Loss: 4.2532\n",
      "Epoch [542/2000], Avg Val Loss: 2.8322\n",
      "Validation loss improved from 2.8332 to 2.8322. Saving model...\n",
      "\n",
      "LOG: Epoch [543/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2812\n",
      "Epoch [543/2000], Avg Train Loss: 4.2812\n",
      "Epoch [543/2000], Avg Val Loss: 2.8311\n",
      "Validation loss improved from 2.8322 to 2.8311. Saving model...\n",
      "\n",
      "LOG: Epoch [544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2767\n",
      "Epoch [544/2000], Avg Train Loss: 4.2767\n",
      "Epoch [544/2000], Avg Val Loss: 2.8300\n",
      "Validation loss improved from 2.8311 to 2.8300. Saving model...\n",
      "\n",
      "LOG: Epoch [545/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2872\n",
      "Epoch [545/2000], Avg Train Loss: 4.2872\n",
      "Epoch [545/2000], Avg Val Loss: 2.8290\n",
      "Validation loss improved from 2.8300 to 2.8290. Saving model...\n",
      "\n",
      "LOG: Epoch [546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2956\n",
      "Epoch [546/2000], Avg Train Loss: 4.2956\n",
      "Epoch [546/2000], Avg Val Loss: 2.8279\n",
      "Validation loss improved from 2.8290 to 2.8279. Saving model...\n",
      "\n",
      "LOG: Epoch [547/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3092\n",
      "Epoch [547/2000], Avg Train Loss: 4.3092\n",
      "Epoch [547/2000], Avg Val Loss: 2.8267\n",
      "Validation loss improved from 2.8279 to 2.8267. Saving model...\n",
      "\n",
      "LOG: Epoch [548/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2524\n",
      "Epoch [548/2000], Avg Train Loss: 4.2524\n",
      "Epoch [548/2000], Avg Val Loss: 2.8255\n",
      "Validation loss improved from 2.8267 to 2.8255. Saving model...\n",
      "\n",
      "LOG: Epoch [549/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2829\n",
      "Epoch [549/2000], Avg Train Loss: 4.2829\n",
      "Epoch [549/2000], Avg Val Loss: 2.8243\n",
      "Validation loss improved from 2.8255 to 2.8243. Saving model...\n",
      "\n",
      "LOG: Epoch [550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2669\n",
      "Epoch [550/2000], Avg Train Loss: 4.2669\n",
      "Epoch [550/2000], Avg Val Loss: 2.8231\n",
      "Validation loss improved from 2.8243 to 2.8231. Saving model...\n",
      "\n",
      "LOG: Epoch [551/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2728\n",
      "Epoch [551/2000], Avg Train Loss: 4.2728\n",
      "Epoch [551/2000], Avg Val Loss: 2.8220\n",
      "Validation loss improved from 2.8231 to 2.8220. Saving model...\n",
      "\n",
      "LOG: Epoch [552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2706\n",
      "Epoch [552/2000], Avg Train Loss: 4.2706\n",
      "Epoch [552/2000], Avg Val Loss: 2.8208\n",
      "Validation loss improved from 2.8220 to 2.8208. Saving model...\n",
      "\n",
      "LOG: Epoch [553/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2901\n",
      "Epoch [553/2000], Avg Train Loss: 4.2901\n",
      "Epoch [553/2000], Avg Val Loss: 2.8197\n",
      "Validation loss improved from 2.8208 to 2.8197. Saving model...\n",
      "\n",
      "LOG: Epoch [554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2453\n",
      "Epoch [554/2000], Avg Train Loss: 4.2453\n",
      "Epoch [554/2000], Avg Val Loss: 2.8186\n",
      "Validation loss improved from 2.8197 to 2.8186. Saving model...\n",
      "\n",
      "LOG: Epoch [555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2914\n",
      "Epoch [555/2000], Avg Train Loss: 4.2914\n",
      "Epoch [555/2000], Avg Val Loss: 2.8175\n",
      "Validation loss improved from 2.8186 to 2.8175. Saving model...\n",
      "\n",
      "LOG: Epoch [556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2726\n",
      "Epoch [556/2000], Avg Train Loss: 4.2726\n",
      "Epoch [556/2000], Avg Val Loss: 2.8165\n",
      "Validation loss improved from 2.8175 to 2.8165. Saving model...\n",
      "\n",
      "LOG: Epoch [557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3051\n",
      "Epoch [557/2000], Avg Train Loss: 4.3051\n",
      "Epoch [557/2000], Avg Val Loss: 2.8155\n",
      "Validation loss improved from 2.8165 to 2.8155. Saving model...\n",
      "\n",
      "LOG: Epoch [558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2762\n",
      "Epoch [558/2000], Avg Train Loss: 4.2762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [558/2000], Avg Val Loss: 2.8145\n",
      "Validation loss improved from 2.8155 to 2.8145. Saving model...\n",
      "\n",
      "LOG: Epoch [559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2880\n",
      "Epoch [559/2000], Avg Train Loss: 4.2880\n",
      "Epoch [559/2000], Avg Val Loss: 2.8135\n",
      "Validation loss improved from 2.8145 to 2.8135. Saving model...\n",
      "\n",
      "LOG: Epoch [560/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2773\n",
      "Epoch [560/2000], Avg Train Loss: 4.2773\n",
      "Epoch [560/2000], Avg Val Loss: 2.8125\n",
      "Validation loss improved from 2.8135 to 2.8125. Saving model...\n",
      "\n",
      "LOG: Epoch [561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3014\n",
      "Epoch [561/2000], Avg Train Loss: 4.3014\n",
      "Epoch [561/2000], Avg Val Loss: 2.8115\n",
      "Validation loss improved from 2.8125 to 2.8115. Saving model...\n",
      "\n",
      "LOG: Epoch [562/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2689\n",
      "Epoch [562/2000], Avg Train Loss: 4.2689\n",
      "Epoch [562/2000], Avg Val Loss: 2.8105\n",
      "Validation loss improved from 2.8115 to 2.8105. Saving model...\n",
      "\n",
      "LOG: Epoch [563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2777\n",
      "Epoch [563/2000], Avg Train Loss: 4.2777\n",
      "Epoch [563/2000], Avg Val Loss: 2.8095\n",
      "Validation loss improved from 2.8105 to 2.8095. Saving model...\n",
      "\n",
      "LOG: Epoch [564/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2713\n",
      "Epoch [564/2000], Avg Train Loss: 4.2713\n",
      "Epoch [564/2000], Avg Val Loss: 2.8085\n",
      "Validation loss improved from 2.8095 to 2.8085. Saving model...\n",
      "\n",
      "LOG: Epoch [565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2710\n",
      "Epoch [565/2000], Avg Train Loss: 4.2710\n",
      "Epoch [565/2000], Avg Val Loss: 2.8074\n",
      "Validation loss improved from 2.8085 to 2.8074. Saving model...\n",
      "\n",
      "LOG: Epoch [566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2567\n",
      "Epoch [566/2000], Avg Train Loss: 4.2567\n",
      "Epoch [566/2000], Avg Val Loss: 2.8064\n",
      "Validation loss improved from 2.8074 to 2.8064. Saving model...\n",
      "\n",
      "LOG: Epoch [567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2392\n",
      "Epoch [567/2000], Avg Train Loss: 4.2392\n",
      "Epoch [567/2000], Avg Val Loss: 2.8053\n",
      "Validation loss improved from 2.8064 to 2.8053. Saving model...\n",
      "\n",
      "LOG: Epoch [568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2996\n",
      "Epoch [568/2000], Avg Train Loss: 4.2996\n",
      "Epoch [568/2000], Avg Val Loss: 2.8041\n",
      "Validation loss improved from 2.8053 to 2.8041. Saving model...\n",
      "\n",
      "LOG: Epoch [569/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2670\n",
      "Epoch [569/2000], Avg Train Loss: 4.2670\n",
      "Epoch [569/2000], Avg Val Loss: 2.8029\n",
      "Validation loss improved from 2.8041 to 2.8029. Saving model...\n",
      "\n",
      "LOG: Epoch [570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2942\n",
      "Epoch [570/2000], Avg Train Loss: 4.2942\n",
      "Epoch [570/2000], Avg Val Loss: 2.8018\n",
      "Validation loss improved from 2.8029 to 2.8018. Saving model...\n",
      "\n",
      "LOG: Epoch [571/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2619\n",
      "Epoch [571/2000], Avg Train Loss: 4.2619\n",
      "Epoch [571/2000], Avg Val Loss: 2.8007\n",
      "Validation loss improved from 2.8018 to 2.8007. Saving model...\n",
      "\n",
      "LOG: Epoch [572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2831\n",
      "Epoch [572/2000], Avg Train Loss: 4.2831\n",
      "Epoch [572/2000], Avg Val Loss: 2.7997\n",
      "Validation loss improved from 2.8007 to 2.7997. Saving model...\n",
      "\n",
      "LOG: Epoch [573/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2674\n",
      "Epoch [573/2000], Avg Train Loss: 4.2674\n",
      "Epoch [573/2000], Avg Val Loss: 2.7987\n",
      "Validation loss improved from 2.7997 to 2.7987. Saving model...\n",
      "\n",
      "LOG: Epoch [574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2417\n",
      "Epoch [574/2000], Avg Train Loss: 4.2417\n",
      "Epoch [574/2000], Avg Val Loss: 2.7977\n",
      "Validation loss improved from 2.7987 to 2.7977. Saving model...\n",
      "\n",
      "LOG: Epoch [575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3117\n",
      "Epoch [575/2000], Avg Train Loss: 4.3117\n",
      "Epoch [575/2000], Avg Val Loss: 2.7967\n",
      "Validation loss improved from 2.7977 to 2.7967. Saving model...\n",
      "\n",
      "LOG: Epoch [576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2705\n",
      "Epoch [576/2000], Avg Train Loss: 4.2705\n",
      "Epoch [576/2000], Avg Val Loss: 2.7958\n",
      "Validation loss improved from 2.7967 to 2.7958. Saving model...\n",
      "\n",
      "LOG: Epoch [577/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2952\n",
      "Epoch [577/2000], Avg Train Loss: 4.2952\n",
      "Epoch [577/2000], Avg Val Loss: 2.7948\n",
      "Validation loss improved from 2.7958 to 2.7948. Saving model...\n",
      "\n",
      "LOG: Epoch [578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2694\n",
      "Epoch [578/2000], Avg Train Loss: 4.2694\n",
      "Epoch [578/2000], Avg Val Loss: 2.7938\n",
      "Validation loss improved from 2.7948 to 2.7938. Saving model...\n",
      "\n",
      "LOG: Epoch [579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2723\n",
      "Epoch [579/2000], Avg Train Loss: 4.2723\n",
      "Epoch [579/2000], Avg Val Loss: 2.7927\n",
      "Validation loss improved from 2.7938 to 2.7927. Saving model...\n",
      "\n",
      "LOG: Epoch [580/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2454\n",
      "Epoch [580/2000], Avg Train Loss: 4.2454\n",
      "Epoch [580/2000], Avg Val Loss: 2.7917\n",
      "Validation loss improved from 2.7927 to 2.7917. Saving model...\n",
      "\n",
      "LOG: Epoch [581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2296\n",
      "Epoch [581/2000], Avg Train Loss: 4.2296\n",
      "Epoch [581/2000], Avg Val Loss: 2.7906\n",
      "Validation loss improved from 2.7917 to 2.7906. Saving model...\n",
      "\n",
      "LOG: Epoch [582/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2249\n",
      "Epoch [582/2000], Avg Train Loss: 4.2249\n",
      "Epoch [582/2000], Avg Val Loss: 2.7895\n",
      "Validation loss improved from 2.7906 to 2.7895. Saving model...\n",
      "\n",
      "LOG: Epoch [583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2700\n",
      "Epoch [583/2000], Avg Train Loss: 4.2700\n",
      "Epoch [583/2000], Avg Val Loss: 2.7884\n",
      "Validation loss improved from 2.7895 to 2.7884. Saving model...\n",
      "\n",
      "LOG: Epoch [584/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2654\n",
      "Epoch [584/2000], Avg Train Loss: 4.2654\n",
      "Epoch [584/2000], Avg Val Loss: 2.7874\n",
      "Validation loss improved from 2.7884 to 2.7874. Saving model...\n",
      "\n",
      "LOG: Epoch [585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2784\n",
      "Epoch [585/2000], Avg Train Loss: 4.2784\n",
      "Epoch [585/2000], Avg Val Loss: 2.7862\n",
      "Validation loss improved from 2.7874 to 2.7862. Saving model...\n",
      "\n",
      "LOG: Epoch [586/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2424\n",
      "Epoch [586/2000], Avg Train Loss: 4.2424\n",
      "Epoch [586/2000], Avg Val Loss: 2.7851\n",
      "Validation loss improved from 2.7862 to 2.7851. Saving model...\n",
      "\n",
      "LOG: Epoch [587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2615\n",
      "Epoch [587/2000], Avg Train Loss: 4.2615\n",
      "Epoch [587/2000], Avg Val Loss: 2.7839\n",
      "Validation loss improved from 2.7851 to 2.7839. Saving model...\n",
      "\n",
      "LOG: Epoch [588/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2565\n",
      "Epoch [588/2000], Avg Train Loss: 4.2565\n",
      "Epoch [588/2000], Avg Val Loss: 2.7828\n",
      "Validation loss improved from 2.7839 to 2.7828. Saving model...\n",
      "\n",
      "LOG: Epoch [589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2327\n",
      "Epoch [589/2000], Avg Train Loss: 4.2327\n",
      "Epoch [589/2000], Avg Val Loss: 2.7818\n",
      "Validation loss improved from 2.7828 to 2.7818. Saving model...\n",
      "\n",
      "LOG: Epoch [590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2226\n",
      "Epoch [590/2000], Avg Train Loss: 4.2226\n",
      "Epoch [590/2000], Avg Val Loss: 2.7806\n",
      "Validation loss improved from 2.7818 to 2.7806. Saving model...\n",
      "\n",
      "LOG: Epoch [591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2280\n",
      "Epoch [591/2000], Avg Train Loss: 4.2280\n",
      "Epoch [591/2000], Avg Val Loss: 2.7794\n",
      "Validation loss improved from 2.7806 to 2.7794. Saving model...\n",
      "\n",
      "LOG: Epoch [592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2812\n",
      "Epoch [592/2000], Avg Train Loss: 4.2812\n",
      "Epoch [592/2000], Avg Val Loss: 2.7783\n",
      "Validation loss improved from 2.7794 to 2.7783. Saving model...\n",
      "\n",
      "LOG: Epoch [593/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2413\n",
      "Epoch [593/2000], Avg Train Loss: 4.2413\n",
      "Epoch [593/2000], Avg Val Loss: 2.7771\n",
      "Validation loss improved from 2.7783 to 2.7771. Saving model...\n",
      "\n",
      "LOG: Epoch [594/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2590\n",
      "Epoch [594/2000], Avg Train Loss: 4.2590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [594/2000], Avg Val Loss: 2.7759\n",
      "Validation loss improved from 2.7771 to 2.7759. Saving model...\n",
      "\n",
      "LOG: Epoch [595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2528\n",
      "Epoch [595/2000], Avg Train Loss: 4.2528\n",
      "Epoch [595/2000], Avg Val Loss: 2.7748\n",
      "Validation loss improved from 2.7759 to 2.7748. Saving model...\n",
      "\n",
      "LOG: Epoch [596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2280\n",
      "Epoch [596/2000], Avg Train Loss: 4.2280\n",
      "Epoch [596/2000], Avg Val Loss: 2.7735\n",
      "Validation loss improved from 2.7748 to 2.7735. Saving model...\n",
      "\n",
      "LOG: Epoch [597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2181\n",
      "Epoch [597/2000], Avg Train Loss: 4.2181\n",
      "Epoch [597/2000], Avg Val Loss: 2.7723\n",
      "Validation loss improved from 2.7735 to 2.7723. Saving model...\n",
      "\n",
      "LOG: Epoch [598/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2404\n",
      "Epoch [598/2000], Avg Train Loss: 4.2404\n",
      "Epoch [598/2000], Avg Val Loss: 2.7710\n",
      "Validation loss improved from 2.7723 to 2.7710. Saving model...\n",
      "\n",
      "LOG: Epoch [599/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2213\n",
      "Epoch [599/2000], Avg Train Loss: 4.2213\n",
      "Epoch [599/2000], Avg Val Loss: 2.7698\n",
      "Validation loss improved from 2.7710 to 2.7698. Saving model...\n",
      "\n",
      "LOG: Epoch [600/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1956\n",
      "Epoch [600/2000], Avg Train Loss: 4.1956\n",
      "Epoch [600/2000], Avg Val Loss: 2.7685\n",
      "Validation loss improved from 2.7698 to 2.7685. Saving model...\n",
      "\n",
      "LOG: Epoch [601/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2541\n",
      "Epoch [601/2000], Avg Train Loss: 4.2541\n",
      "Epoch [601/2000], Avg Val Loss: 2.7672\n",
      "Validation loss improved from 2.7685 to 2.7672. Saving model...\n",
      "\n",
      "LOG: Epoch [602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2174\n",
      "Epoch [602/2000], Avg Train Loss: 4.2174\n",
      "Epoch [602/2000], Avg Val Loss: 2.7658\n",
      "Validation loss improved from 2.7672 to 2.7658. Saving model...\n",
      "\n",
      "LOG: Epoch [603/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2651\n",
      "Epoch [603/2000], Avg Train Loss: 4.2651\n",
      "Epoch [603/2000], Avg Val Loss: 2.7646\n",
      "Validation loss improved from 2.7658 to 2.7646. Saving model...\n",
      "\n",
      "LOG: Epoch [604/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2205\n",
      "Epoch [604/2000], Avg Train Loss: 4.2205\n",
      "Epoch [604/2000], Avg Val Loss: 2.7633\n",
      "Validation loss improved from 2.7646 to 2.7633. Saving model...\n",
      "\n",
      "LOG: Epoch [605/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2017\n",
      "Epoch [605/2000], Avg Train Loss: 4.2017\n",
      "Epoch [605/2000], Avg Val Loss: 2.7620\n",
      "Validation loss improved from 2.7633 to 2.7620. Saving model...\n",
      "\n",
      "LOG: Epoch [606/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2134\n",
      "Epoch [606/2000], Avg Train Loss: 4.2134\n",
      "Epoch [606/2000], Avg Val Loss: 2.7608\n",
      "Validation loss improved from 2.7620 to 2.7608. Saving model...\n",
      "\n",
      "LOG: Epoch [607/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2218\n",
      "Epoch [607/2000], Avg Train Loss: 4.2218\n",
      "Epoch [607/2000], Avg Val Loss: 2.7596\n",
      "Validation loss improved from 2.7608 to 2.7596. Saving model...\n",
      "\n",
      "LOG: Epoch [608/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1848\n",
      "Epoch [608/2000], Avg Train Loss: 4.1848\n",
      "Epoch [608/2000], Avg Val Loss: 2.7585\n",
      "Validation loss improved from 2.7596 to 2.7585. Saving model...\n",
      "\n",
      "LOG: Epoch [609/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2132\n",
      "Epoch [609/2000], Avg Train Loss: 4.2132\n",
      "Epoch [609/2000], Avg Val Loss: 2.7574\n",
      "Validation loss improved from 2.7585 to 2.7574. Saving model...\n",
      "\n",
      "LOG: Epoch [610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2036\n",
      "Epoch [610/2000], Avg Train Loss: 4.2036\n",
      "Epoch [610/2000], Avg Val Loss: 2.7564\n",
      "Validation loss improved from 2.7574 to 2.7564. Saving model...\n",
      "\n",
      "LOG: Epoch [611/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2365\n",
      "Epoch [611/2000], Avg Train Loss: 4.2365\n",
      "Epoch [611/2000], Avg Val Loss: 2.7554\n",
      "Validation loss improved from 2.7564 to 2.7554. Saving model...\n",
      "\n",
      "LOG: Epoch [612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1638\n",
      "Epoch [612/2000], Avg Train Loss: 4.1638\n",
      "Epoch [612/2000], Avg Val Loss: 2.7544\n",
      "Validation loss improved from 2.7554 to 2.7544. Saving model...\n",
      "\n",
      "LOG: Epoch [613/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1562\n",
      "Epoch [613/2000], Avg Train Loss: 4.1562\n",
      "Epoch [613/2000], Avg Val Loss: 2.7532\n",
      "Validation loss improved from 2.7544 to 2.7532. Saving model...\n",
      "\n",
      "LOG: Epoch [614/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1877\n",
      "Epoch [614/2000], Avg Train Loss: 4.1877\n",
      "Epoch [614/2000], Avg Val Loss: 2.7521\n",
      "Validation loss improved from 2.7532 to 2.7521. Saving model...\n",
      "\n",
      "LOG: Epoch [615/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2046\n",
      "Epoch [615/2000], Avg Train Loss: 4.2046\n",
      "Epoch [615/2000], Avg Val Loss: 2.7508\n",
      "Validation loss improved from 2.7521 to 2.7508. Saving model...\n",
      "\n",
      "LOG: Epoch [616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2348\n",
      "Epoch [616/2000], Avg Train Loss: 4.2348\n",
      "Epoch [616/2000], Avg Val Loss: 2.7496\n",
      "Validation loss improved from 2.7508 to 2.7496. Saving model...\n",
      "\n",
      "LOG: Epoch [617/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1887\n",
      "Epoch [617/2000], Avg Train Loss: 4.1887\n",
      "Epoch [617/2000], Avg Val Loss: 2.7484\n",
      "Validation loss improved from 2.7496 to 2.7484. Saving model...\n",
      "\n",
      "LOG: Epoch [618/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1944\n",
      "Epoch [618/2000], Avg Train Loss: 4.1944\n",
      "Epoch [618/2000], Avg Val Loss: 2.7472\n",
      "Validation loss improved from 2.7484 to 2.7472. Saving model...\n",
      "\n",
      "LOG: Epoch [619/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1991\n",
      "Epoch [619/2000], Avg Train Loss: 4.1991\n",
      "Epoch [619/2000], Avg Val Loss: 2.7459\n",
      "Validation loss improved from 2.7472 to 2.7459. Saving model...\n",
      "\n",
      "LOG: Epoch [620/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2375\n",
      "Epoch [620/2000], Avg Train Loss: 4.2375\n",
      "Epoch [620/2000], Avg Val Loss: 2.7446\n",
      "Validation loss improved from 2.7459 to 2.7446. Saving model...\n",
      "\n",
      "LOG: Epoch [621/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1842\n",
      "Epoch [621/2000], Avg Train Loss: 4.1842\n",
      "Epoch [621/2000], Avg Val Loss: 2.7432\n",
      "Validation loss improved from 2.7446 to 2.7432. Saving model...\n",
      "\n",
      "LOG: Epoch [622/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1898\n",
      "Epoch [622/2000], Avg Train Loss: 4.1898\n",
      "Epoch [622/2000], Avg Val Loss: 2.7418\n",
      "Validation loss improved from 2.7432 to 2.7418. Saving model...\n",
      "\n",
      "LOG: Epoch [623/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2170\n",
      "Epoch [623/2000], Avg Train Loss: 4.2170\n",
      "Epoch [623/2000], Avg Val Loss: 2.7403\n",
      "Validation loss improved from 2.7418 to 2.7403. Saving model...\n",
      "\n",
      "LOG: Epoch [624/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1625\n",
      "Epoch [624/2000], Avg Train Loss: 4.1625\n",
      "Epoch [624/2000], Avg Val Loss: 2.7388\n",
      "Validation loss improved from 2.7403 to 2.7388. Saving model...\n",
      "\n",
      "LOG: Epoch [625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1512\n",
      "Epoch [625/2000], Avg Train Loss: 4.1512\n",
      "Epoch [625/2000], Avg Val Loss: 2.7373\n",
      "Validation loss improved from 2.7388 to 2.7373. Saving model...\n",
      "\n",
      "LOG: Epoch [626/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1447\n",
      "Epoch [626/2000], Avg Train Loss: 4.1447\n",
      "Epoch [626/2000], Avg Val Loss: 2.7359\n",
      "Validation loss improved from 2.7373 to 2.7359. Saving model...\n",
      "\n",
      "LOG: Epoch [627/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1664\n",
      "Epoch [627/2000], Avg Train Loss: 4.1664\n",
      "Epoch [627/2000], Avg Val Loss: 2.7343\n",
      "Validation loss improved from 2.7359 to 2.7343. Saving model...\n",
      "\n",
      "LOG: Epoch [628/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1166\n",
      "Epoch [628/2000], Avg Train Loss: 4.1166\n",
      "Epoch [628/2000], Avg Val Loss: 2.7328\n",
      "Validation loss improved from 2.7343 to 2.7328. Saving model...\n",
      "\n",
      "LOG: Epoch [629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1436\n",
      "Epoch [629/2000], Avg Train Loss: 4.1436\n",
      "Epoch [629/2000], Avg Val Loss: 2.7313\n",
      "Validation loss improved from 2.7328 to 2.7313. Saving model...\n",
      "\n",
      "LOG: Epoch [630/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2095\n",
      "Epoch [630/2000], Avg Train Loss: 4.2095\n",
      "Epoch [630/2000], Avg Val Loss: 2.7298\n",
      "Validation loss improved from 2.7313 to 2.7298. Saving model...\n",
      "\n",
      "LOG: Epoch [631/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2258\n",
      "Epoch [631/2000], Avg Train Loss: 4.2258\n",
      "Epoch [631/2000], Avg Val Loss: 2.7283\n",
      "Validation loss improved from 2.7298 to 2.7283. Saving model...\n",
      "\n",
      "LOG: Epoch [632/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1895\n",
      "Epoch [632/2000], Avg Train Loss: 4.1895\n",
      "Epoch [632/2000], Avg Val Loss: 2.7269\n",
      "Validation loss improved from 2.7283 to 2.7269. Saving model...\n",
      "\n",
      "LOG: Epoch [633/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2057\n",
      "Epoch [633/2000], Avg Train Loss: 4.2057\n",
      "Epoch [633/2000], Avg Val Loss: 2.7255\n",
      "Validation loss improved from 2.7269 to 2.7255. Saving model...\n",
      "\n",
      "LOG: Epoch [634/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1686\n",
      "Epoch [634/2000], Avg Train Loss: 4.1686\n",
      "Epoch [634/2000], Avg Val Loss: 2.7241\n",
      "Validation loss improved from 2.7255 to 2.7241. Saving model...\n",
      "\n",
      "LOG: Epoch [635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1388\n",
      "Epoch [635/2000], Avg Train Loss: 4.1388\n",
      "Epoch [635/2000], Avg Val Loss: 2.7228\n",
      "Validation loss improved from 2.7241 to 2.7228. Saving model...\n",
      "\n",
      "LOG: Epoch [636/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1713\n",
      "Epoch [636/2000], Avg Train Loss: 4.1713\n",
      "Epoch [636/2000], Avg Val Loss: 2.7214\n",
      "Validation loss improved from 2.7228 to 2.7214. Saving model...\n",
      "\n",
      "LOG: Epoch [637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1492\n",
      "Epoch [637/2000], Avg Train Loss: 4.1492\n",
      "Epoch [637/2000], Avg Val Loss: 2.7200\n",
      "Validation loss improved from 2.7214 to 2.7200. Saving model...\n",
      "\n",
      "LOG: Epoch [638/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2033\n",
      "Epoch [638/2000], Avg Train Loss: 4.2033\n",
      "Epoch [638/2000], Avg Val Loss: 2.7186\n",
      "Validation loss improved from 2.7200 to 2.7186. Saving model...\n",
      "\n",
      "LOG: Epoch [639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1559\n",
      "Epoch [639/2000], Avg Train Loss: 4.1559\n",
      "Epoch [639/2000], Avg Val Loss: 2.7172\n",
      "Validation loss improved from 2.7186 to 2.7172. Saving model...\n",
      "\n",
      "LOG: Epoch [640/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1902\n",
      "Epoch [640/2000], Avg Train Loss: 4.1902\n",
      "Epoch [640/2000], Avg Val Loss: 2.7159\n",
      "Validation loss improved from 2.7172 to 2.7159. Saving model...\n",
      "\n",
      "LOG: Epoch [641/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1385\n",
      "Epoch [641/2000], Avg Train Loss: 4.1385\n",
      "Epoch [641/2000], Avg Val Loss: 2.7146\n",
      "Validation loss improved from 2.7159 to 2.7146. Saving model...\n",
      "\n",
      "LOG: Epoch [642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1503\n",
      "Epoch [642/2000], Avg Train Loss: 4.1503\n",
      "Epoch [642/2000], Avg Val Loss: 2.7134\n",
      "Validation loss improved from 2.7146 to 2.7134. Saving model...\n",
      "\n",
      "LOG: Epoch [643/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1574\n",
      "Epoch [643/2000], Avg Train Loss: 4.1574\n",
      "Epoch [643/2000], Avg Val Loss: 2.7122\n",
      "Validation loss improved from 2.7134 to 2.7122. Saving model...\n",
      "\n",
      "LOG: Epoch [644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2015\n",
      "Epoch [644/2000], Avg Train Loss: 4.2015\n",
      "Epoch [644/2000], Avg Val Loss: 2.7110\n",
      "Validation loss improved from 2.7122 to 2.7110. Saving model...\n",
      "\n",
      "LOG: Epoch [645/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1659\n",
      "Epoch [645/2000], Avg Train Loss: 4.1659\n",
      "Epoch [645/2000], Avg Val Loss: 2.7099\n",
      "Validation loss improved from 2.7110 to 2.7099. Saving model...\n",
      "\n",
      "LOG: Epoch [646/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1606\n",
      "Epoch [646/2000], Avg Train Loss: 4.1606\n",
      "Epoch [646/2000], Avg Val Loss: 2.7087\n",
      "Validation loss improved from 2.7099 to 2.7087. Saving model...\n",
      "\n",
      "LOG: Epoch [647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1514\n",
      "Epoch [647/2000], Avg Train Loss: 4.1514\n",
      "Epoch [647/2000], Avg Val Loss: 2.7076\n",
      "Validation loss improved from 2.7087 to 2.7076. Saving model...\n",
      "\n",
      "LOG: Epoch [648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1543\n",
      "Epoch [648/2000], Avg Train Loss: 4.1543\n",
      "Epoch [648/2000], Avg Val Loss: 2.7065\n",
      "Validation loss improved from 2.7076 to 2.7065. Saving model...\n",
      "\n",
      "LOG: Epoch [649/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1576\n",
      "Epoch [649/2000], Avg Train Loss: 4.1576\n",
      "Epoch [649/2000], Avg Val Loss: 2.7055\n",
      "Validation loss improved from 2.7065 to 2.7055. Saving model...\n",
      "\n",
      "LOG: Epoch [650/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1436\n",
      "Epoch [650/2000], Avg Train Loss: 4.1436\n",
      "Epoch [650/2000], Avg Val Loss: 2.7045\n",
      "Validation loss improved from 2.7055 to 2.7045. Saving model...\n",
      "\n",
      "LOG: Epoch [651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2053\n",
      "Epoch [651/2000], Avg Train Loss: 4.2053\n",
      "Epoch [651/2000], Avg Val Loss: 2.7035\n",
      "Validation loss improved from 2.7045 to 2.7035. Saving model...\n",
      "\n",
      "LOG: Epoch [652/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1354\n",
      "Epoch [652/2000], Avg Train Loss: 4.1354\n",
      "Epoch [652/2000], Avg Val Loss: 2.7024\n",
      "Validation loss improved from 2.7035 to 2.7024. Saving model...\n",
      "\n",
      "LOG: Epoch [653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1495\n",
      "Epoch [653/2000], Avg Train Loss: 4.1495\n",
      "Epoch [653/2000], Avg Val Loss: 2.7013\n",
      "Validation loss improved from 2.7024 to 2.7013. Saving model...\n",
      "\n",
      "LOG: Epoch [654/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1822\n",
      "Epoch [654/2000], Avg Train Loss: 4.1822\n",
      "Epoch [654/2000], Avg Val Loss: 2.7003\n",
      "Validation loss improved from 2.7013 to 2.7003. Saving model...\n",
      "\n",
      "LOG: Epoch [655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1642\n",
      "Epoch [655/2000], Avg Train Loss: 4.1642\n",
      "Epoch [655/2000], Avg Val Loss: 2.6992\n",
      "Validation loss improved from 2.7003 to 2.6992. Saving model...\n",
      "\n",
      "LOG: Epoch [656/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1343\n",
      "Epoch [656/2000], Avg Train Loss: 4.1343\n",
      "Epoch [656/2000], Avg Val Loss: 2.6981\n",
      "Validation loss improved from 2.6992 to 2.6981. Saving model...\n",
      "\n",
      "LOG: Epoch [657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1583\n",
      "Epoch [657/2000], Avg Train Loss: 4.1583\n",
      "Epoch [657/2000], Avg Val Loss: 2.6969\n",
      "Validation loss improved from 2.6981 to 2.6969. Saving model...\n",
      "\n",
      "LOG: Epoch [658/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1166\n",
      "Epoch [658/2000], Avg Train Loss: 4.1166\n",
      "Epoch [658/2000], Avg Val Loss: 2.6958\n",
      "Validation loss improved from 2.6969 to 2.6958. Saving model...\n",
      "\n",
      "LOG: Epoch [659/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1569\n",
      "Epoch [659/2000], Avg Train Loss: 4.1569\n",
      "Epoch [659/2000], Avg Val Loss: 2.6947\n",
      "Validation loss improved from 2.6958 to 2.6947. Saving model...\n",
      "\n",
      "LOG: Epoch [660/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1736\n",
      "Epoch [660/2000], Avg Train Loss: 4.1736\n",
      "Epoch [660/2000], Avg Val Loss: 2.6936\n",
      "Validation loss improved from 2.6947 to 2.6936. Saving model...\n",
      "\n",
      "LOG: Epoch [661/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0906\n",
      "Epoch [661/2000], Avg Train Loss: 4.0906\n",
      "Epoch [661/2000], Avg Val Loss: 2.6925\n",
      "Validation loss improved from 2.6936 to 2.6925. Saving model...\n",
      "\n",
      "LOG: Epoch [662/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0916\n",
      "Epoch [662/2000], Avg Train Loss: 4.0916\n",
      "Epoch [662/2000], Avg Val Loss: 2.6913\n",
      "Validation loss improved from 2.6925 to 2.6913. Saving model...\n",
      "\n",
      "LOG: Epoch [663/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1648\n",
      "Epoch [663/2000], Avg Train Loss: 4.1648\n",
      "Epoch [663/2000], Avg Val Loss: 2.6902\n",
      "Validation loss improved from 2.6913 to 2.6902. Saving model...\n",
      "\n",
      "LOG: Epoch [664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1211\n",
      "Epoch [664/2000], Avg Train Loss: 4.1211\n",
      "Epoch [664/2000], Avg Val Loss: 2.6890\n",
      "Validation loss improved from 2.6902 to 2.6890. Saving model...\n",
      "\n",
      "LOG: Epoch [665/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1239\n",
      "Epoch [665/2000], Avg Train Loss: 4.1239\n",
      "Epoch [665/2000], Avg Val Loss: 2.6878\n",
      "Validation loss improved from 2.6890 to 2.6878. Saving model...\n",
      "\n",
      "LOG: Epoch [666/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1576\n",
      "Epoch [666/2000], Avg Train Loss: 4.1576\n",
      "Epoch [666/2000], Avg Val Loss: 2.6868\n",
      "Validation loss improved from 2.6878 to 2.6868. Saving model...\n",
      "\n",
      "LOG: Epoch [667/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1562\n",
      "Epoch [667/2000], Avg Train Loss: 4.1562\n",
      "Epoch [667/2000], Avg Val Loss: 2.6857\n",
      "Validation loss improved from 2.6868 to 2.6857. Saving model...\n",
      "\n",
      "LOG: Epoch [668/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1201\n",
      "Epoch [668/2000], Avg Train Loss: 4.1201\n",
      "Epoch [668/2000], Avg Val Loss: 2.6847\n",
      "Validation loss improved from 2.6857 to 2.6847. Saving model...\n",
      "\n",
      "LOG: Epoch [669/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0839\n",
      "Epoch [669/2000], Avg Train Loss: 4.0839\n",
      "Epoch [669/2000], Avg Val Loss: 2.6835\n",
      "Validation loss improved from 2.6847 to 2.6835. Saving model...\n",
      "\n",
      "LOG: Epoch [670/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1002\n",
      "Epoch [670/2000], Avg Train Loss: 4.1002\n",
      "Epoch [670/2000], Avg Val Loss: 2.6824\n",
      "Validation loss improved from 2.6835 to 2.6824. Saving model...\n",
      "\n",
      "LOG: Epoch [671/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0740\n",
      "Epoch [671/2000], Avg Train Loss: 4.0740\n",
      "Epoch [671/2000], Avg Val Loss: 2.6812\n",
      "Validation loss improved from 2.6824 to 2.6812. Saving model...\n",
      "\n",
      "LOG: Epoch [672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0962\n",
      "Epoch [672/2000], Avg Train Loss: 4.0962\n",
      "Epoch [672/2000], Avg Val Loss: 2.6800\n",
      "Validation loss improved from 2.6812 to 2.6800. Saving model...\n",
      "\n",
      "LOG: Epoch [673/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1605\n",
      "Epoch [673/2000], Avg Train Loss: 4.1605\n",
      "Epoch [673/2000], Avg Val Loss: 2.6788\n",
      "Validation loss improved from 2.6800 to 2.6788. Saving model...\n",
      "\n",
      "LOG: Epoch [674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1190\n",
      "Epoch [674/2000], Avg Train Loss: 4.1190\n",
      "Epoch [674/2000], Avg Val Loss: 2.6776\n",
      "Validation loss improved from 2.6788 to 2.6776. Saving model...\n",
      "\n",
      "LOG: Epoch [675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1291\n",
      "Epoch [675/2000], Avg Train Loss: 4.1291\n",
      "Epoch [675/2000], Avg Val Loss: 2.6764\n",
      "Validation loss improved from 2.6776 to 2.6764. Saving model...\n",
      "\n",
      "LOG: Epoch [676/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0883\n",
      "Epoch [676/2000], Avg Train Loss: 4.0883\n",
      "Epoch [676/2000], Avg Val Loss: 2.6752\n",
      "Validation loss improved from 2.6764 to 2.6752. Saving model...\n",
      "\n",
      "LOG: Epoch [677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1533\n",
      "Epoch [677/2000], Avg Train Loss: 4.1533\n",
      "Epoch [677/2000], Avg Val Loss: 2.6740\n",
      "Validation loss improved from 2.6752 to 2.6740. Saving model...\n",
      "\n",
      "LOG: Epoch [678/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1326\n",
      "Epoch [678/2000], Avg Train Loss: 4.1326\n",
      "Epoch [678/2000], Avg Val Loss: 2.6728\n",
      "Validation loss improved from 2.6740 to 2.6728. Saving model...\n",
      "\n",
      "LOG: Epoch [679/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1011\n",
      "Epoch [679/2000], Avg Train Loss: 4.1011\n",
      "Epoch [679/2000], Avg Val Loss: 2.6716\n",
      "Validation loss improved from 2.6728 to 2.6716. Saving model...\n",
      "\n",
      "LOG: Epoch [680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1089\n",
      "Epoch [680/2000], Avg Train Loss: 4.1089\n",
      "Epoch [680/2000], Avg Val Loss: 2.6705\n",
      "Validation loss improved from 2.6716 to 2.6705. Saving model...\n",
      "\n",
      "LOG: Epoch [681/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0935\n",
      "Epoch [681/2000], Avg Train Loss: 4.0935\n",
      "Epoch [681/2000], Avg Val Loss: 2.6693\n",
      "Validation loss improved from 2.6705 to 2.6693. Saving model...\n",
      "\n",
      "LOG: Epoch [682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0529\n",
      "Epoch [682/2000], Avg Train Loss: 4.0529\n",
      "Epoch [682/2000], Avg Val Loss: 2.6682\n",
      "Validation loss improved from 2.6693 to 2.6682. Saving model...\n",
      "\n",
      "LOG: Epoch [683/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0887\n",
      "Epoch [683/2000], Avg Train Loss: 4.0887\n",
      "Epoch [683/2000], Avg Val Loss: 2.6671\n",
      "Validation loss improved from 2.6682 to 2.6671. Saving model...\n",
      "\n",
      "LOG: Epoch [684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1021\n",
      "Epoch [684/2000], Avg Train Loss: 4.1021\n",
      "Epoch [684/2000], Avg Val Loss: 2.6659\n",
      "Validation loss improved from 2.6671 to 2.6659. Saving model...\n",
      "\n",
      "LOG: Epoch [685/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1151\n",
      "Epoch [685/2000], Avg Train Loss: 4.1151\n",
      "Epoch [685/2000], Avg Val Loss: 2.6648\n",
      "Validation loss improved from 2.6659 to 2.6648. Saving model...\n",
      "\n",
      "LOG: Epoch [686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1187\n",
      "Epoch [686/2000], Avg Train Loss: 4.1187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [686/2000], Avg Val Loss: 2.6636\n",
      "Validation loss improved from 2.6648 to 2.6636. Saving model...\n",
      "\n",
      "LOG: Epoch [687/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1326\n",
      "Epoch [687/2000], Avg Train Loss: 4.1326\n",
      "Epoch [687/2000], Avg Val Loss: 2.6624\n",
      "Validation loss improved from 2.6636 to 2.6624. Saving model...\n",
      "\n",
      "LOG: Epoch [688/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1006\n",
      "Epoch [688/2000], Avg Train Loss: 4.1006\n",
      "Epoch [688/2000], Avg Val Loss: 2.6613\n",
      "Validation loss improved from 2.6624 to 2.6613. Saving model...\n",
      "\n",
      "LOG: Epoch [689/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0835\n",
      "Epoch [689/2000], Avg Train Loss: 4.0835\n",
      "Epoch [689/2000], Avg Val Loss: 2.6602\n",
      "Validation loss improved from 2.6613 to 2.6602. Saving model...\n",
      "\n",
      "LOG: Epoch [690/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1134\n",
      "Epoch [690/2000], Avg Train Loss: 4.1134\n",
      "Epoch [690/2000], Avg Val Loss: 2.6590\n",
      "Validation loss improved from 2.6602 to 2.6590. Saving model...\n",
      "\n",
      "LOG: Epoch [691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0737\n",
      "Epoch [691/2000], Avg Train Loss: 4.0737\n",
      "Epoch [691/2000], Avg Val Loss: 2.6580\n",
      "Validation loss improved from 2.6590 to 2.6580. Saving model...\n",
      "\n",
      "LOG: Epoch [692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1382\n",
      "Epoch [692/2000], Avg Train Loss: 4.1382\n",
      "Epoch [692/2000], Avg Val Loss: 2.6569\n",
      "Validation loss improved from 2.6580 to 2.6569. Saving model...\n",
      "\n",
      "LOG: Epoch [693/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0991\n",
      "Epoch [693/2000], Avg Train Loss: 4.0991\n",
      "Epoch [693/2000], Avg Val Loss: 2.6558\n",
      "Validation loss improved from 2.6569 to 2.6558. Saving model...\n",
      "\n",
      "LOG: Epoch [694/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0535\n",
      "Epoch [694/2000], Avg Train Loss: 4.0535\n",
      "Epoch [694/2000], Avg Val Loss: 2.6546\n",
      "Validation loss improved from 2.6558 to 2.6546. Saving model...\n",
      "\n",
      "LOG: Epoch [695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0660\n",
      "Epoch [695/2000], Avg Train Loss: 4.0660\n",
      "Epoch [695/2000], Avg Val Loss: 2.6534\n",
      "Validation loss improved from 2.6546 to 2.6534. Saving model...\n",
      "\n",
      "LOG: Epoch [696/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0770\n",
      "Epoch [696/2000], Avg Train Loss: 4.0770\n",
      "Epoch [696/2000], Avg Val Loss: 2.6522\n",
      "Validation loss improved from 2.6534 to 2.6522. Saving model...\n",
      "\n",
      "LOG: Epoch [697/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0996\n",
      "Epoch [697/2000], Avg Train Loss: 4.0996\n",
      "Epoch [697/2000], Avg Val Loss: 2.6510\n",
      "Validation loss improved from 2.6522 to 2.6510. Saving model...\n",
      "\n",
      "LOG: Epoch [698/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0924\n",
      "Epoch [698/2000], Avg Train Loss: 4.0924\n",
      "Epoch [698/2000], Avg Val Loss: 2.6498\n",
      "Validation loss improved from 2.6510 to 2.6498. Saving model...\n",
      "\n",
      "LOG: Epoch [699/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0820\n",
      "Epoch [699/2000], Avg Train Loss: 4.0820\n",
      "Epoch [699/2000], Avg Val Loss: 2.6486\n",
      "Validation loss improved from 2.6498 to 2.6486. Saving model...\n",
      "\n",
      "LOG: Epoch [700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1229\n",
      "Epoch [700/2000], Avg Train Loss: 4.1229\n",
      "Epoch [700/2000], Avg Val Loss: 2.6474\n",
      "Validation loss improved from 2.6486 to 2.6474. Saving model...\n",
      "\n",
      "LOG: Epoch [701/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0428\n",
      "Epoch [701/2000], Avg Train Loss: 4.0428\n",
      "Epoch [701/2000], Avg Val Loss: 2.6462\n",
      "Validation loss improved from 2.6474 to 2.6462. Saving model...\n",
      "\n",
      "LOG: Epoch [702/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0604\n",
      "Epoch [702/2000], Avg Train Loss: 4.0604\n",
      "Epoch [702/2000], Avg Val Loss: 2.6451\n",
      "Validation loss improved from 2.6462 to 2.6451. Saving model...\n",
      "\n",
      "LOG: Epoch [703/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0644\n",
      "Epoch [703/2000], Avg Train Loss: 4.0644\n",
      "Epoch [703/2000], Avg Val Loss: 2.6439\n",
      "Validation loss improved from 2.6451 to 2.6439. Saving model...\n",
      "\n",
      "LOG: Epoch [704/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0487\n",
      "Epoch [704/2000], Avg Train Loss: 4.0487\n",
      "Epoch [704/2000], Avg Val Loss: 2.6428\n",
      "Validation loss improved from 2.6439 to 2.6428. Saving model...\n",
      "\n",
      "LOG: Epoch [705/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0817\n",
      "Epoch [705/2000], Avg Train Loss: 4.0817\n",
      "Epoch [705/2000], Avg Val Loss: 2.6417\n",
      "Validation loss improved from 2.6428 to 2.6417. Saving model...\n",
      "\n",
      "LOG: Epoch [706/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1191\n",
      "Epoch [706/2000], Avg Train Loss: 4.1191\n",
      "Epoch [706/2000], Avg Val Loss: 2.6405\n",
      "Validation loss improved from 2.6417 to 2.6405. Saving model...\n",
      "\n",
      "LOG: Epoch [707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0589\n",
      "Epoch [707/2000], Avg Train Loss: 4.0589\n",
      "Epoch [707/2000], Avg Val Loss: 2.6394\n",
      "Validation loss improved from 2.6405 to 2.6394. Saving model...\n",
      "\n",
      "LOG: Epoch [708/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0380\n",
      "Epoch [708/2000], Avg Train Loss: 4.0380\n",
      "Epoch [708/2000], Avg Val Loss: 2.6381\n",
      "Validation loss improved from 2.6394 to 2.6381. Saving model...\n",
      "\n",
      "LOG: Epoch [709/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0879\n",
      "Epoch [709/2000], Avg Train Loss: 4.0879\n",
      "Epoch [709/2000], Avg Val Loss: 2.6368\n",
      "Validation loss improved from 2.6381 to 2.6368. Saving model...\n",
      "\n",
      "LOG: Epoch [710/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0987\n",
      "Epoch [710/2000], Avg Train Loss: 4.0987\n",
      "Epoch [710/2000], Avg Val Loss: 2.6355\n",
      "Validation loss improved from 2.6368 to 2.6355. Saving model...\n",
      "\n",
      "LOG: Epoch [711/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1036\n",
      "Epoch [711/2000], Avg Train Loss: 4.1036\n",
      "Epoch [711/2000], Avg Val Loss: 2.6343\n",
      "Validation loss improved from 2.6355 to 2.6343. Saving model...\n",
      "\n",
      "LOG: Epoch [712/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0659\n",
      "Epoch [712/2000], Avg Train Loss: 4.0659\n",
      "Epoch [712/2000], Avg Val Loss: 2.6332\n",
      "Validation loss improved from 2.6343 to 2.6332. Saving model...\n",
      "\n",
      "LOG: Epoch [713/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0640\n",
      "Epoch [713/2000], Avg Train Loss: 4.0640\n",
      "Epoch [713/2000], Avg Val Loss: 2.6322\n",
      "Validation loss improved from 2.6332 to 2.6322. Saving model...\n",
      "\n",
      "LOG: Epoch [714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0847\n",
      "Epoch [714/2000], Avg Train Loss: 4.0847\n",
      "Epoch [714/2000], Avg Val Loss: 2.6312\n",
      "Validation loss improved from 2.6322 to 2.6312. Saving model...\n",
      "\n",
      "LOG: Epoch [715/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1162\n",
      "Epoch [715/2000], Avg Train Loss: 4.1162\n",
      "Epoch [715/2000], Avg Val Loss: 2.6301\n",
      "Validation loss improved from 2.6312 to 2.6301. Saving model...\n",
      "\n",
      "LOG: Epoch [716/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0335\n",
      "Epoch [716/2000], Avg Train Loss: 4.0335\n",
      "Epoch [716/2000], Avg Val Loss: 2.6291\n",
      "Validation loss improved from 2.6301 to 2.6291. Saving model...\n",
      "\n",
      "LOG: Epoch [717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0479\n",
      "Epoch [717/2000], Avg Train Loss: 4.0479\n",
      "Epoch [717/2000], Avg Val Loss: 2.6281\n",
      "Validation loss improved from 2.6291 to 2.6281. Saving model...\n",
      "\n",
      "LOG: Epoch [718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0503\n",
      "Epoch [718/2000], Avg Train Loss: 4.0503\n",
      "Epoch [718/2000], Avg Val Loss: 2.6271\n",
      "Validation loss improved from 2.6281 to 2.6271. Saving model...\n",
      "\n",
      "LOG: Epoch [719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0463\n",
      "Epoch [719/2000], Avg Train Loss: 4.0463\n",
      "Epoch [719/2000], Avg Val Loss: 2.6261\n",
      "Validation loss improved from 2.6271 to 2.6261. Saving model...\n",
      "\n",
      "LOG: Epoch [720/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0831\n",
      "Epoch [720/2000], Avg Train Loss: 4.0831\n",
      "Epoch [720/2000], Avg Val Loss: 2.6251\n",
      "Validation loss improved from 2.6261 to 2.6251. Saving model...\n",
      "\n",
      "LOG: Epoch [721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1026\n",
      "Epoch [721/2000], Avg Train Loss: 4.1026\n",
      "Epoch [721/2000], Avg Val Loss: 2.6240\n",
      "Validation loss improved from 2.6251 to 2.6240. Saving model...\n",
      "\n",
      "LOG: Epoch [722/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0226\n",
      "Epoch [722/2000], Avg Train Loss: 4.0226\n",
      "Epoch [722/2000], Avg Val Loss: 2.6230\n",
      "Validation loss improved from 2.6240 to 2.6230. Saving model...\n",
      "\n",
      "LOG: Epoch [723/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0622\n",
      "Epoch [723/2000], Avg Train Loss: 4.0622\n",
      "Epoch [723/2000], Avg Val Loss: 2.6219\n",
      "Validation loss improved from 2.6230 to 2.6219. Saving model...\n",
      "\n",
      "LOG: Epoch [724/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0584\n",
      "Epoch [724/2000], Avg Train Loss: 4.0584\n",
      "Epoch [724/2000], Avg Val Loss: 2.6208\n",
      "Validation loss improved from 2.6219 to 2.6208. Saving model...\n",
      "\n",
      "LOG: Epoch [725/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0626\n",
      "Epoch [725/2000], Avg Train Loss: 4.0626\n",
      "Epoch [725/2000], Avg Val Loss: 2.6197\n",
      "Validation loss improved from 2.6208 to 2.6197. Saving model...\n",
      "\n",
      "LOG: Epoch [726/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0601\n",
      "Epoch [726/2000], Avg Train Loss: 4.0601\n",
      "Epoch [726/2000], Avg Val Loss: 2.6186\n",
      "Validation loss improved from 2.6197 to 2.6186. Saving model...\n",
      "\n",
      "LOG: Epoch [727/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0221\n",
      "Epoch [727/2000], Avg Train Loss: 4.0221\n",
      "Epoch [727/2000], Avg Val Loss: 2.6174\n",
      "Validation loss improved from 2.6186 to 2.6174. Saving model...\n",
      "\n",
      "LOG: Epoch [728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0247\n",
      "Epoch [728/2000], Avg Train Loss: 4.0247\n",
      "Epoch [728/2000], Avg Val Loss: 2.6162\n",
      "Validation loss improved from 2.6174 to 2.6162. Saving model...\n",
      "\n",
      "LOG: Epoch [729/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0575\n",
      "Epoch [729/2000], Avg Train Loss: 4.0575\n",
      "Epoch [729/2000], Avg Val Loss: 2.6150\n",
      "Validation loss improved from 2.6162 to 2.6150. Saving model...\n",
      "\n",
      "LOG: Epoch [730/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0024\n",
      "Epoch [730/2000], Avg Train Loss: 4.0024\n",
      "Epoch [730/2000], Avg Val Loss: 2.6138\n",
      "Validation loss improved from 2.6150 to 2.6138. Saving model...\n",
      "\n",
      "LOG: Epoch [731/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0370\n",
      "Epoch [731/2000], Avg Train Loss: 4.0370\n",
      "Epoch [731/2000], Avg Val Loss: 2.6126\n",
      "Validation loss improved from 2.6138 to 2.6126. Saving model...\n",
      "\n",
      "LOG: Epoch [732/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0484\n",
      "Epoch [732/2000], Avg Train Loss: 4.0484\n",
      "Epoch [732/2000], Avg Val Loss: 2.6113\n",
      "Validation loss improved from 2.6126 to 2.6113. Saving model...\n",
      "\n",
      "LOG: Epoch [733/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0356\n",
      "Epoch [733/2000], Avg Train Loss: 4.0356\n",
      "Epoch [733/2000], Avg Val Loss: 2.6101\n",
      "Validation loss improved from 2.6113 to 2.6101. Saving model...\n",
      "\n",
      "LOG: Epoch [734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0473\n",
      "Epoch [734/2000], Avg Train Loss: 4.0473\n",
      "Epoch [734/2000], Avg Val Loss: 2.6089\n",
      "Validation loss improved from 2.6101 to 2.6089. Saving model...\n",
      "\n",
      "LOG: Epoch [735/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0479\n",
      "Epoch [735/2000], Avg Train Loss: 4.0479\n",
      "Epoch [735/2000], Avg Val Loss: 2.6078\n",
      "Validation loss improved from 2.6089 to 2.6078. Saving model...\n",
      "\n",
      "LOG: Epoch [736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0236\n",
      "Epoch [736/2000], Avg Train Loss: 4.0236\n",
      "Epoch [736/2000], Avg Val Loss: 2.6067\n",
      "Validation loss improved from 2.6078 to 2.6067. Saving model...\n",
      "\n",
      "LOG: Epoch [737/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0140\n",
      "Epoch [737/2000], Avg Train Loss: 4.0140\n",
      "Epoch [737/2000], Avg Val Loss: 2.6056\n",
      "Validation loss improved from 2.6067 to 2.6056. Saving model...\n",
      "\n",
      "LOG: Epoch [738/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0240\n",
      "Epoch [738/2000], Avg Train Loss: 4.0240\n",
      "Epoch [738/2000], Avg Val Loss: 2.6046\n",
      "Validation loss improved from 2.6056 to 2.6046. Saving model...\n",
      "\n",
      "LOG: Epoch [739/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9958\n",
      "Epoch [739/2000], Avg Train Loss: 3.9958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [739/2000], Avg Val Loss: 2.6037\n",
      "Validation loss improved from 2.6046 to 2.6037. Saving model...\n",
      "\n",
      "LOG: Epoch [740/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9943\n",
      "Epoch [740/2000], Avg Train Loss: 3.9943\n",
      "Epoch [740/2000], Avg Val Loss: 2.6027\n",
      "Validation loss improved from 2.6037 to 2.6027. Saving model...\n",
      "\n",
      "LOG: Epoch [741/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0426\n",
      "Epoch [741/2000], Avg Train Loss: 4.0426\n",
      "Epoch [741/2000], Avg Val Loss: 2.6018\n",
      "Validation loss improved from 2.6027 to 2.6018. Saving model...\n",
      "\n",
      "LOG: Epoch [742/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0182\n",
      "Epoch [742/2000], Avg Train Loss: 4.0182\n",
      "Epoch [742/2000], Avg Val Loss: 2.6010\n",
      "Validation loss improved from 2.6018 to 2.6010. Saving model...\n",
      "\n",
      "LOG: Epoch [743/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0346\n",
      "Epoch [743/2000], Avg Train Loss: 4.0346\n",
      "Epoch [743/2000], Avg Val Loss: 2.6000\n",
      "Validation loss improved from 2.6010 to 2.6000. Saving model...\n",
      "\n",
      "LOG: Epoch [744/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0519\n",
      "Epoch [744/2000], Avg Train Loss: 4.0519\n",
      "Epoch [744/2000], Avg Val Loss: 2.5991\n",
      "Validation loss improved from 2.6000 to 2.5991. Saving model...\n",
      "\n",
      "LOG: Epoch [745/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0219\n",
      "Epoch [745/2000], Avg Train Loss: 4.0219\n",
      "Epoch [745/2000], Avg Val Loss: 2.5982\n",
      "Validation loss improved from 2.5991 to 2.5982. Saving model...\n",
      "\n",
      "LOG: Epoch [746/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9791\n",
      "Epoch [746/2000], Avg Train Loss: 3.9791\n",
      "Epoch [746/2000], Avg Val Loss: 2.5973\n",
      "Validation loss improved from 2.5982 to 2.5973. Saving model...\n",
      "\n",
      "LOG: Epoch [747/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0314\n",
      "Epoch [747/2000], Avg Train Loss: 4.0314\n",
      "Epoch [747/2000], Avg Val Loss: 2.5965\n",
      "Validation loss improved from 2.5973 to 2.5965. Saving model...\n",
      "\n",
      "LOG: Epoch [748/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9925\n",
      "Epoch [748/2000], Avg Train Loss: 3.9925\n",
      "Epoch [748/2000], Avg Val Loss: 2.5957\n",
      "Validation loss improved from 2.5965 to 2.5957. Saving model...\n",
      "\n",
      "LOG: Epoch [749/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9877\n",
      "Epoch [749/2000], Avg Train Loss: 3.9877\n",
      "Epoch [749/2000], Avg Val Loss: 2.5950\n",
      "Validation loss improved from 2.5957 to 2.5950. Saving model...\n",
      "\n",
      "LOG: Epoch [750/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0148\n",
      "Epoch [750/2000], Avg Train Loss: 4.0148\n",
      "Epoch [750/2000], Avg Val Loss: 2.5942\n",
      "Validation loss improved from 2.5950 to 2.5942. Saving model...\n",
      "\n",
      "LOG: Epoch [751/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0185\n",
      "Epoch [751/2000], Avg Train Loss: 4.0185\n",
      "Epoch [751/2000], Avg Val Loss: 2.5935\n",
      "Validation loss improved from 2.5942 to 2.5935. Saving model...\n",
      "\n",
      "LOG: Epoch [752/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0425\n",
      "Epoch [752/2000], Avg Train Loss: 4.0425\n",
      "Epoch [752/2000], Avg Val Loss: 2.5928\n",
      "Validation loss improved from 2.5935 to 2.5928. Saving model...\n",
      "\n",
      "LOG: Epoch [753/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9972\n",
      "Epoch [753/2000], Avg Train Loss: 3.9972\n",
      "Epoch [753/2000], Avg Val Loss: 2.5920\n",
      "Validation loss improved from 2.5928 to 2.5920. Saving model...\n",
      "\n",
      "LOG: Epoch [754/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0090\n",
      "Epoch [754/2000], Avg Train Loss: 4.0090\n",
      "Epoch [754/2000], Avg Val Loss: 2.5913\n",
      "Validation loss improved from 2.5920 to 2.5913. Saving model...\n",
      "\n",
      "LOG: Epoch [755/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9906\n",
      "Epoch [755/2000], Avg Train Loss: 3.9906\n",
      "Epoch [755/2000], Avg Val Loss: 2.5906\n",
      "Validation loss improved from 2.5913 to 2.5906. Saving model...\n",
      "\n",
      "LOG: Epoch [756/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0265\n",
      "Epoch [756/2000], Avg Train Loss: 4.0265\n",
      "Epoch [756/2000], Avg Val Loss: 2.5898\n",
      "Validation loss improved from 2.5906 to 2.5898. Saving model...\n",
      "\n",
      "LOG: Epoch [757/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0251\n",
      "Epoch [757/2000], Avg Train Loss: 4.0251\n",
      "Epoch [757/2000], Avg Val Loss: 2.5890\n",
      "Validation loss improved from 2.5898 to 2.5890. Saving model...\n",
      "\n",
      "LOG: Epoch [758/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0005\n",
      "Epoch [758/2000], Avg Train Loss: 4.0005\n",
      "Epoch [758/2000], Avg Val Loss: 2.5881\n",
      "Validation loss improved from 2.5890 to 2.5881. Saving model...\n",
      "\n",
      "LOG: Epoch [759/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0179\n",
      "Epoch [759/2000], Avg Train Loss: 4.0179\n",
      "Epoch [759/2000], Avg Val Loss: 2.5873\n",
      "Validation loss improved from 2.5881 to 2.5873. Saving model...\n",
      "\n",
      "LOG: Epoch [760/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0032\n",
      "Epoch [760/2000], Avg Train Loss: 4.0032\n",
      "Epoch [760/2000], Avg Val Loss: 2.5864\n",
      "Validation loss improved from 2.5873 to 2.5864. Saving model...\n",
      "\n",
      "LOG: Epoch [761/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0057\n",
      "Epoch [761/2000], Avg Train Loss: 4.0057\n",
      "Epoch [761/2000], Avg Val Loss: 2.5856\n",
      "Validation loss improved from 2.5864 to 2.5856. Saving model...\n",
      "\n",
      "LOG: Epoch [762/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0000\n",
      "Epoch [762/2000], Avg Train Loss: 4.0000\n",
      "Epoch [762/2000], Avg Val Loss: 2.5847\n",
      "Validation loss improved from 2.5856 to 2.5847. Saving model...\n",
      "\n",
      "LOG: Epoch [763/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0027\n",
      "Epoch [763/2000], Avg Train Loss: 4.0027\n",
      "Epoch [763/2000], Avg Val Loss: 2.5838\n",
      "Validation loss improved from 2.5847 to 2.5838. Saving model...\n",
      "\n",
      "LOG: Epoch [764/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0029\n",
      "Epoch [764/2000], Avg Train Loss: 4.0029\n",
      "Epoch [764/2000], Avg Val Loss: 2.5829\n",
      "Validation loss improved from 2.5838 to 2.5829. Saving model...\n",
      "\n",
      "LOG: Epoch [765/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0271\n",
      "Epoch [765/2000], Avg Train Loss: 4.0271\n",
      "Epoch [765/2000], Avg Val Loss: 2.5819\n",
      "Validation loss improved from 2.5829 to 2.5819. Saving model...\n",
      "\n",
      "LOG: Epoch [766/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9710\n",
      "Epoch [766/2000], Avg Train Loss: 3.9710\n",
      "Epoch [766/2000], Avg Val Loss: 2.5809\n",
      "Validation loss improved from 2.5819 to 2.5809. Saving model...\n",
      "\n",
      "LOG: Epoch [767/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0459\n",
      "Epoch [767/2000], Avg Train Loss: 4.0459\n",
      "Epoch [767/2000], Avg Val Loss: 2.5799\n",
      "Validation loss improved from 2.5809 to 2.5799. Saving model...\n",
      "\n",
      "LOG: Epoch [768/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9445\n",
      "Epoch [768/2000], Avg Train Loss: 3.9445\n",
      "Epoch [768/2000], Avg Val Loss: 2.5787\n",
      "Validation loss improved from 2.5799 to 2.5787. Saving model...\n",
      "\n",
      "LOG: Epoch [769/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9947\n",
      "Epoch [769/2000], Avg Train Loss: 3.9947\n",
      "Epoch [769/2000], Avg Val Loss: 2.5775\n",
      "Validation loss improved from 2.5787 to 2.5775. Saving model...\n",
      "\n",
      "LOG: Epoch [770/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0068\n",
      "Epoch [770/2000], Avg Train Loss: 4.0068\n",
      "Epoch [770/2000], Avg Val Loss: 2.5763\n",
      "Validation loss improved from 2.5775 to 2.5763. Saving model...\n",
      "\n",
      "LOG: Epoch [771/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9504\n",
      "Epoch [771/2000], Avg Train Loss: 3.9504\n",
      "Epoch [771/2000], Avg Val Loss: 2.5752\n",
      "Validation loss improved from 2.5763 to 2.5752. Saving model...\n",
      "\n",
      "LOG: Epoch [772/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9358\n",
      "Epoch [772/2000], Avg Train Loss: 3.9358\n",
      "Epoch [772/2000], Avg Val Loss: 2.5740\n",
      "Validation loss improved from 2.5752 to 2.5740. Saving model...\n",
      "\n",
      "LOG: Epoch [773/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9477\n",
      "Epoch [773/2000], Avg Train Loss: 3.9477\n",
      "Epoch [773/2000], Avg Val Loss: 2.5731\n",
      "Validation loss improved from 2.5740 to 2.5731. Saving model...\n",
      "\n",
      "LOG: Epoch [774/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0033\n",
      "Epoch [774/2000], Avg Train Loss: 4.0033\n",
      "Epoch [774/2000], Avg Val Loss: 2.5721\n",
      "Validation loss improved from 2.5731 to 2.5721. Saving model...\n",
      "\n",
      "LOG: Epoch [775/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9767\n",
      "Epoch [775/2000], Avg Train Loss: 3.9767\n",
      "Epoch [775/2000], Avg Val Loss: 2.5712\n",
      "Validation loss improved from 2.5721 to 2.5712. Saving model...\n",
      "\n",
      "LOG: Epoch [776/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9702\n",
      "Epoch [776/2000], Avg Train Loss: 3.9702\n",
      "Epoch [776/2000], Avg Val Loss: 2.5703\n",
      "Validation loss improved from 2.5712 to 2.5703. Saving model...\n",
      "\n",
      "LOG: Epoch [777/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9561\n",
      "Epoch [777/2000], Avg Train Loss: 3.9561\n",
      "Epoch [777/2000], Avg Val Loss: 2.5694\n",
      "Validation loss improved from 2.5703 to 2.5694. Saving model...\n",
      "\n",
      "LOG: Epoch [778/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9983\n",
      "Epoch [778/2000], Avg Train Loss: 3.9983\n",
      "Epoch [778/2000], Avg Val Loss: 2.5685\n",
      "Validation loss improved from 2.5694 to 2.5685. Saving model...\n",
      "\n",
      "LOG: Epoch [779/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9469\n",
      "Epoch [779/2000], Avg Train Loss: 3.9469\n",
      "Epoch [779/2000], Avg Val Loss: 2.5676\n",
      "Validation loss improved from 2.5685 to 2.5676. Saving model...\n",
      "\n",
      "LOG: Epoch [780/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0199\n",
      "Epoch [780/2000], Avg Train Loss: 4.0199\n",
      "Epoch [780/2000], Avg Val Loss: 2.5666\n",
      "Validation loss improved from 2.5676 to 2.5666. Saving model...\n",
      "\n",
      "LOG: Epoch [781/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9624\n",
      "Epoch [781/2000], Avg Train Loss: 3.9624\n",
      "Epoch [781/2000], Avg Val Loss: 2.5658\n",
      "Validation loss improved from 2.5666 to 2.5658. Saving model...\n",
      "\n",
      "LOG: Epoch [782/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0027\n",
      "Epoch [782/2000], Avg Train Loss: 4.0027\n",
      "Epoch [782/2000], Avg Val Loss: 2.5649\n",
      "Validation loss improved from 2.5658 to 2.5649. Saving model...\n",
      "\n",
      "LOG: Epoch [783/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0170\n",
      "Epoch [783/2000], Avg Train Loss: 4.0170\n",
      "Epoch [783/2000], Avg Val Loss: 2.5641\n",
      "Validation loss improved from 2.5649 to 2.5641. Saving model...\n",
      "\n",
      "LOG: Epoch [784/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0450\n",
      "Epoch [784/2000], Avg Train Loss: 4.0450\n",
      "Epoch [784/2000], Avg Val Loss: 2.5633\n",
      "Validation loss improved from 2.5641 to 2.5633. Saving model...\n",
      "\n",
      "LOG: Epoch [785/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9758\n",
      "Epoch [785/2000], Avg Train Loss: 3.9758\n",
      "Epoch [785/2000], Avg Val Loss: 2.5625\n",
      "Validation loss improved from 2.5633 to 2.5625. Saving model...\n",
      "\n",
      "LOG: Epoch [786/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9873\n",
      "Epoch [786/2000], Avg Train Loss: 3.9873\n",
      "Epoch [786/2000], Avg Val Loss: 2.5616\n",
      "Validation loss improved from 2.5625 to 2.5616. Saving model...\n",
      "\n",
      "LOG: Epoch [787/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0004\n",
      "Epoch [787/2000], Avg Train Loss: 4.0004\n",
      "Epoch [787/2000], Avg Val Loss: 2.5609\n",
      "Validation loss improved from 2.5616 to 2.5609. Saving model...\n",
      "\n",
      "LOG: Epoch [788/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9691\n",
      "Epoch [788/2000], Avg Train Loss: 3.9691\n",
      "Epoch [788/2000], Avg Val Loss: 2.5602\n",
      "Validation loss improved from 2.5609 to 2.5602. Saving model...\n",
      "\n",
      "LOG: Epoch [789/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9591\n",
      "Epoch [789/2000], Avg Train Loss: 3.9591\n",
      "Epoch [789/2000], Avg Val Loss: 2.5596\n",
      "Validation loss improved from 2.5602 to 2.5596. Saving model...\n",
      "\n",
      "LOG: Epoch [790/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9505\n",
      "Epoch [790/2000], Avg Train Loss: 3.9505\n",
      "Epoch [790/2000], Avg Val Loss: 2.5591\n",
      "Validation loss improved from 2.5596 to 2.5591. Saving model...\n",
      "\n",
      "LOG: Epoch [791/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9530\n",
      "Epoch [791/2000], Avg Train Loss: 3.9530\n",
      "Epoch [791/2000], Avg Val Loss: 2.5585\n",
      "Validation loss improved from 2.5591 to 2.5585. Saving model...\n",
      "\n",
      "LOG: Epoch [792/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0031\n",
      "Epoch [792/2000], Avg Train Loss: 4.0031\n",
      "Epoch [792/2000], Avg Val Loss: 2.5578\n",
      "Validation loss improved from 2.5585 to 2.5578. Saving model...\n",
      "\n",
      "LOG: Epoch [793/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9855\n",
      "Epoch [793/2000], Avg Train Loss: 3.9855\n",
      "Epoch [793/2000], Avg Val Loss: 2.5572\n",
      "Validation loss improved from 2.5578 to 2.5572. Saving model...\n",
      "\n",
      "LOG: Epoch [794/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9584\n",
      "Epoch [794/2000], Avg Train Loss: 3.9584\n",
      "Epoch [794/2000], Avg Val Loss: 2.5565\n",
      "Validation loss improved from 2.5572 to 2.5565. Saving model...\n",
      "\n",
      "LOG: Epoch [795/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9901\n",
      "Epoch [795/2000], Avg Train Loss: 3.9901\n",
      "Epoch [795/2000], Avg Val Loss: 2.5559\n",
      "Validation loss improved from 2.5565 to 2.5559. Saving model...\n",
      "\n",
      "LOG: Epoch [796/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9358\n",
      "Epoch [796/2000], Avg Train Loss: 3.9358\n",
      "Epoch [796/2000], Avg Val Loss: 2.5551\n",
      "Validation loss improved from 2.5559 to 2.5551. Saving model...\n",
      "\n",
      "LOG: Epoch [797/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9503\n",
      "Epoch [797/2000], Avg Train Loss: 3.9503\n",
      "Epoch [797/2000], Avg Val Loss: 2.5545\n",
      "Validation loss improved from 2.5551 to 2.5545. Saving model...\n",
      "\n",
      "LOG: Epoch [798/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9570\n",
      "Epoch [798/2000], Avg Train Loss: 3.9570\n",
      "Epoch [798/2000], Avg Val Loss: 2.5538\n",
      "Validation loss improved from 2.5545 to 2.5538. Saving model...\n",
      "\n",
      "LOG: Epoch [799/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9552\n",
      "Epoch [799/2000], Avg Train Loss: 3.9552\n",
      "Epoch [799/2000], Avg Val Loss: 2.5532\n",
      "Validation loss improved from 2.5538 to 2.5532. Saving model...\n",
      "\n",
      "LOG: Epoch [800/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9620\n",
      "Epoch [800/2000], Avg Train Loss: 3.9620\n",
      "Epoch [800/2000], Avg Val Loss: 2.5524\n",
      "Validation loss improved from 2.5532 to 2.5524. Saving model...\n",
      "\n",
      "LOG: Epoch [801/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9470\n",
      "Epoch [801/2000], Avg Train Loss: 3.9470\n",
      "Epoch [801/2000], Avg Val Loss: 2.5516\n",
      "Validation loss improved from 2.5524 to 2.5516. Saving model...\n",
      "\n",
      "LOG: Epoch [802/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9136\n",
      "Epoch [802/2000], Avg Train Loss: 3.9136\n",
      "Epoch [802/2000], Avg Val Loss: 2.5508\n",
      "Validation loss improved from 2.5516 to 2.5508. Saving model...\n",
      "\n",
      "LOG: Epoch [803/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9552\n",
      "Epoch [803/2000], Avg Train Loss: 3.9552\n",
      "Epoch [803/2000], Avg Val Loss: 2.5499\n",
      "Validation loss improved from 2.5508 to 2.5499. Saving model...\n",
      "\n",
      "LOG: Epoch [804/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9107\n",
      "Epoch [804/2000], Avg Train Loss: 3.9107\n",
      "Epoch [804/2000], Avg Val Loss: 2.5491\n",
      "Validation loss improved from 2.5499 to 2.5491. Saving model...\n",
      "\n",
      "LOG: Epoch [805/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9429\n",
      "Epoch [805/2000], Avg Train Loss: 3.9429\n",
      "Epoch [805/2000], Avg Val Loss: 2.5482\n",
      "Validation loss improved from 2.5491 to 2.5482. Saving model...\n",
      "\n",
      "LOG: Epoch [806/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9505\n",
      "Epoch [806/2000], Avg Train Loss: 3.9505\n",
      "Epoch [806/2000], Avg Val Loss: 2.5474\n",
      "Validation loss improved from 2.5482 to 2.5474. Saving model...\n",
      "\n",
      "LOG: Epoch [807/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9521\n",
      "Epoch [807/2000], Avg Train Loss: 3.9521\n",
      "Epoch [807/2000], Avg Val Loss: 2.5467\n",
      "Validation loss improved from 2.5474 to 2.5467. Saving model...\n",
      "\n",
      "LOG: Epoch [808/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9018\n",
      "Epoch [808/2000], Avg Train Loss: 3.9018\n",
      "Epoch [808/2000], Avg Val Loss: 2.5458\n",
      "Validation loss improved from 2.5467 to 2.5458. Saving model...\n",
      "\n",
      "LOG: Epoch [809/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9445\n",
      "Epoch [809/2000], Avg Train Loss: 3.9445\n",
      "Epoch [809/2000], Avg Val Loss: 2.5451\n",
      "Validation loss improved from 2.5458 to 2.5451. Saving model...\n",
      "\n",
      "LOG: Epoch [810/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9667\n",
      "Epoch [810/2000], Avg Train Loss: 3.9667\n",
      "Epoch [810/2000], Avg Val Loss: 2.5443\n",
      "Validation loss improved from 2.5451 to 2.5443. Saving model...\n",
      "\n",
      "LOG: Epoch [811/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9460\n",
      "Epoch [811/2000], Avg Train Loss: 3.9460\n",
      "Epoch [811/2000], Avg Val Loss: 2.5435\n",
      "Validation loss improved from 2.5443 to 2.5435. Saving model...\n",
      "\n",
      "LOG: Epoch [812/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9334\n",
      "Epoch [812/2000], Avg Train Loss: 3.9334\n",
      "Epoch [812/2000], Avg Val Loss: 2.5426\n",
      "Validation loss improved from 2.5435 to 2.5426. Saving model...\n",
      "\n",
      "LOG: Epoch [813/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9499\n",
      "Epoch [813/2000], Avg Train Loss: 3.9499\n",
      "Epoch [813/2000], Avg Val Loss: 2.5418\n",
      "Validation loss improved from 2.5426 to 2.5418. Saving model...\n",
      "\n",
      "LOG: Epoch [814/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9557\n",
      "Epoch [814/2000], Avg Train Loss: 3.9557\n",
      "Epoch [814/2000], Avg Val Loss: 2.5410\n",
      "Validation loss improved from 2.5418 to 2.5410. Saving model...\n",
      "\n",
      "LOG: Epoch [815/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9804\n",
      "Epoch [815/2000], Avg Train Loss: 3.9804\n",
      "Epoch [815/2000], Avg Val Loss: 2.5403\n",
      "Validation loss improved from 2.5410 to 2.5403. Saving model...\n",
      "\n",
      "LOG: Epoch [816/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9460\n",
      "Epoch [816/2000], Avg Train Loss: 3.9460\n",
      "Epoch [816/2000], Avg Val Loss: 2.5396\n",
      "Validation loss improved from 2.5403 to 2.5396. Saving model...\n",
      "\n",
      "LOG: Epoch [817/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9474\n",
      "Epoch [817/2000], Avg Train Loss: 3.9474\n",
      "Epoch [817/2000], Avg Val Loss: 2.5387\n",
      "Validation loss improved from 2.5396 to 2.5387. Saving model...\n",
      "\n",
      "LOG: Epoch [818/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9328\n",
      "Epoch [818/2000], Avg Train Loss: 3.9328\n",
      "Epoch [818/2000], Avg Val Loss: 2.5378\n",
      "Validation loss improved from 2.5387 to 2.5378. Saving model...\n",
      "\n",
      "LOG: Epoch [819/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9409\n",
      "Epoch [819/2000], Avg Train Loss: 3.9409\n",
      "Epoch [819/2000], Avg Val Loss: 2.5369\n",
      "Validation loss improved from 2.5378 to 2.5369. Saving model...\n",
      "\n",
      "LOG: Epoch [820/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8905\n",
      "Epoch [820/2000], Avg Train Loss: 3.8905\n",
      "Epoch [820/2000], Avg Val Loss: 2.5360\n",
      "Validation loss improved from 2.5369 to 2.5360. Saving model...\n",
      "\n",
      "LOG: Epoch [821/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8965\n",
      "Epoch [821/2000], Avg Train Loss: 3.8965\n",
      "Epoch [821/2000], Avg Val Loss: 2.5352\n",
      "Validation loss improved from 2.5360 to 2.5352. Saving model...\n",
      "\n",
      "LOG: Epoch [822/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9298\n",
      "Epoch [822/2000], Avg Train Loss: 3.9298\n",
      "Epoch [822/2000], Avg Val Loss: 2.5344\n",
      "Validation loss improved from 2.5352 to 2.5344. Saving model...\n",
      "\n",
      "LOG: Epoch [823/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9308\n",
      "Epoch [823/2000], Avg Train Loss: 3.9308\n",
      "Epoch [823/2000], Avg Val Loss: 2.5337\n",
      "Validation loss improved from 2.5344 to 2.5337. Saving model...\n",
      "\n",
      "LOG: Epoch [824/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9556\n",
      "Epoch [824/2000], Avg Train Loss: 3.9556\n",
      "Epoch [824/2000], Avg Val Loss: 2.5330\n",
      "Validation loss improved from 2.5337 to 2.5330. Saving model...\n",
      "\n",
      "LOG: Epoch [825/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9411\n",
      "Epoch [825/2000], Avg Train Loss: 3.9411\n",
      "Epoch [825/2000], Avg Val Loss: 2.5323\n",
      "Validation loss improved from 2.5330 to 2.5323. Saving model...\n",
      "\n",
      "LOG: Epoch [826/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9462\n",
      "Epoch [826/2000], Avg Train Loss: 3.9462\n",
      "Epoch [826/2000], Avg Val Loss: 2.5317\n",
      "Validation loss improved from 2.5323 to 2.5317. Saving model...\n",
      "\n",
      "LOG: Epoch [827/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8880\n",
      "Epoch [827/2000], Avg Train Loss: 3.8880\n",
      "Epoch [827/2000], Avg Val Loss: 2.5311\n",
      "Validation loss improved from 2.5317 to 2.5311. Saving model...\n",
      "\n",
      "LOG: Epoch [828/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9246\n",
      "Epoch [828/2000], Avg Train Loss: 3.9246\n",
      "Epoch [828/2000], Avg Val Loss: 2.5303\n",
      "Validation loss improved from 2.5311 to 2.5303. Saving model...\n",
      "\n",
      "LOG: Epoch [829/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9184\n",
      "Epoch [829/2000], Avg Train Loss: 3.9184\n",
      "Epoch [829/2000], Avg Val Loss: 2.5296\n",
      "Validation loss improved from 2.5303 to 2.5296. Saving model...\n",
      "\n",
      "LOG: Epoch [830/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9354\n",
      "Epoch [830/2000], Avg Train Loss: 3.9354\n",
      "Epoch [830/2000], Avg Val Loss: 2.5288\n",
      "Validation loss improved from 2.5296 to 2.5288. Saving model...\n",
      "\n",
      "LOG: Epoch [831/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9297\n",
      "Epoch [831/2000], Avg Train Loss: 3.9297\n",
      "Epoch [831/2000], Avg Val Loss: 2.5282\n",
      "Validation loss improved from 2.5288 to 2.5282. Saving model...\n",
      "\n",
      "LOG: Epoch [832/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8970\n",
      "Epoch [832/2000], Avg Train Loss: 3.8970\n",
      "Epoch [832/2000], Avg Val Loss: 2.5276\n",
      "Validation loss improved from 2.5282 to 2.5276. Saving model...\n",
      "\n",
      "LOG: Epoch [833/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8924\n",
      "Epoch [833/2000], Avg Train Loss: 3.8924\n",
      "Epoch [833/2000], Avg Val Loss: 2.5269\n",
      "Validation loss improved from 2.5276 to 2.5269. Saving model...\n",
      "\n",
      "LOG: Epoch [834/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9314\n",
      "Epoch [834/2000], Avg Train Loss: 3.9314\n",
      "Epoch [834/2000], Avg Val Loss: 2.5262\n",
      "Validation loss improved from 2.5269 to 2.5262. Saving model...\n",
      "\n",
      "LOG: Epoch [835/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8911\n",
      "Epoch [835/2000], Avg Train Loss: 3.8911\n",
      "Epoch [835/2000], Avg Val Loss: 2.5255\n",
      "Validation loss improved from 2.5262 to 2.5255. Saving model...\n",
      "\n",
      "LOG: Epoch [836/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9472\n",
      "Epoch [836/2000], Avg Train Loss: 3.9472\n",
      "Epoch [836/2000], Avg Val Loss: 2.5248\n",
      "Validation loss improved from 2.5255 to 2.5248. Saving model...\n",
      "\n",
      "LOG: Epoch [837/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9884\n",
      "Epoch [837/2000], Avg Train Loss: 3.9884\n",
      "Epoch [837/2000], Avg Val Loss: 2.5243\n",
      "Validation loss improved from 2.5248 to 2.5243. Saving model...\n",
      "\n",
      "LOG: Epoch [838/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9630\n",
      "Epoch [838/2000], Avg Train Loss: 3.9630\n",
      "Epoch [838/2000], Avg Val Loss: 2.5238\n",
      "Validation loss improved from 2.5243 to 2.5238. Saving model...\n",
      "\n",
      "LOG: Epoch [839/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9484\n",
      "Epoch [839/2000], Avg Train Loss: 3.9484\n",
      "Epoch [839/2000], Avg Val Loss: 2.5234\n",
      "Validation loss improved from 2.5238 to 2.5234. Saving model...\n",
      "\n",
      "LOG: Epoch [840/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9110\n",
      "Epoch [840/2000], Avg Train Loss: 3.9110\n",
      "Epoch [840/2000], Avg Val Loss: 2.5228\n",
      "Validation loss improved from 2.5234 to 2.5228. Saving model...\n",
      "\n",
      "LOG: Epoch [841/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8879\n",
      "Epoch [841/2000], Avg Train Loss: 3.8879\n",
      "Epoch [841/2000], Avg Val Loss: 2.5223\n",
      "Validation loss improved from 2.5228 to 2.5223. Saving model...\n",
      "\n",
      "LOG: Epoch [842/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8923\n",
      "Epoch [842/2000], Avg Train Loss: 3.8923\n",
      "Epoch [842/2000], Avg Val Loss: 2.5218\n",
      "Validation loss improved from 2.5223 to 2.5218. Saving model...\n",
      "\n",
      "LOG: Epoch [843/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8887\n",
      "Epoch [843/2000], Avg Train Loss: 3.8887\n",
      "Epoch [843/2000], Avg Val Loss: 2.5213\n",
      "Validation loss improved from 2.5218 to 2.5213. Saving model...\n",
      "\n",
      "LOG: Epoch [844/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9225\n",
      "Epoch [844/2000], Avg Train Loss: 3.9225\n",
      "Epoch [844/2000], Avg Val Loss: 2.5207\n",
      "Validation loss improved from 2.5213 to 2.5207. Saving model...\n",
      "\n",
      "LOG: Epoch [845/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8960\n",
      "Epoch [845/2000], Avg Train Loss: 3.8960\n",
      "Epoch [845/2000], Avg Val Loss: 2.5202\n",
      "Validation loss improved from 2.5207 to 2.5202. Saving model...\n",
      "\n",
      "LOG: Epoch [846/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8945\n",
      "Epoch [846/2000], Avg Train Loss: 3.8945\n",
      "Epoch [846/2000], Avg Val Loss: 2.5195\n",
      "Validation loss improved from 2.5202 to 2.5195. Saving model...\n",
      "\n",
      "LOG: Epoch [847/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9040\n",
      "Epoch [847/2000], Avg Train Loss: 3.9040\n",
      "Epoch [847/2000], Avg Val Loss: 2.5188\n",
      "Validation loss improved from 2.5195 to 2.5188. Saving model...\n",
      "\n",
      "LOG: Epoch [848/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9086\n",
      "Epoch [848/2000], Avg Train Loss: 3.9086\n",
      "Epoch [848/2000], Avg Val Loss: 2.5179\n",
      "Validation loss improved from 2.5188 to 2.5179. Saving model...\n",
      "\n",
      "LOG: Epoch [849/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9300\n",
      "Epoch [849/2000], Avg Train Loss: 3.9300\n",
      "Epoch [849/2000], Avg Val Loss: 2.5170\n",
      "Validation loss improved from 2.5179 to 2.5170. Saving model...\n",
      "\n",
      "LOG: Epoch [850/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8923\n",
      "Epoch [850/2000], Avg Train Loss: 3.8923\n",
      "Epoch [850/2000], Avg Val Loss: 2.5162\n",
      "Validation loss improved from 2.5170 to 2.5162. Saving model...\n",
      "\n",
      "LOG: Epoch [851/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9462\n",
      "Epoch [851/2000], Avg Train Loss: 3.9462\n",
      "Epoch [851/2000], Avg Val Loss: 2.5154\n",
      "Validation loss improved from 2.5162 to 2.5154. Saving model...\n",
      "\n",
      "LOG: Epoch [852/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9076\n",
      "Epoch [852/2000], Avg Train Loss: 3.9076\n",
      "Epoch [852/2000], Avg Val Loss: 2.5146\n",
      "Validation loss improved from 2.5154 to 2.5146. Saving model...\n",
      "\n",
      "LOG: Epoch [853/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8927\n",
      "Epoch [853/2000], Avg Train Loss: 3.8927\n",
      "Epoch [853/2000], Avg Val Loss: 2.5138\n",
      "Validation loss improved from 2.5146 to 2.5138. Saving model...\n",
      "\n",
      "LOG: Epoch [854/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9264\n",
      "Epoch [854/2000], Avg Train Loss: 3.9264\n",
      "Epoch [854/2000], Avg Val Loss: 2.5130\n",
      "Validation loss improved from 2.5138 to 2.5130. Saving model...\n",
      "\n",
      "LOG: Epoch [855/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8903\n",
      "Epoch [855/2000], Avg Train Loss: 3.8903\n",
      "Epoch [855/2000], Avg Val Loss: 2.5121\n",
      "Validation loss improved from 2.5130 to 2.5121. Saving model...\n",
      "\n",
      "LOG: Epoch [856/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8645\n",
      "Epoch [856/2000], Avg Train Loss: 3.8645\n",
      "Epoch [856/2000], Avg Val Loss: 2.5113\n",
      "Validation loss improved from 2.5121 to 2.5113. Saving model...\n",
      "\n",
      "LOG: Epoch [857/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8732\n",
      "Epoch [857/2000], Avg Train Loss: 3.8732\n",
      "Epoch [857/2000], Avg Val Loss: 2.5106\n",
      "Validation loss improved from 2.5113 to 2.5106. Saving model...\n",
      "\n",
      "LOG: Epoch [858/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8778\n",
      "Epoch [858/2000], Avg Train Loss: 3.8778\n",
      "Epoch [858/2000], Avg Val Loss: 2.5099\n",
      "Validation loss improved from 2.5106 to 2.5099. Saving model...\n",
      "\n",
      "LOG: Epoch [859/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9129\n",
      "Epoch [859/2000], Avg Train Loss: 3.9129\n",
      "Epoch [859/2000], Avg Val Loss: 2.5091\n",
      "Validation loss improved from 2.5099 to 2.5091. Saving model...\n",
      "\n",
      "LOG: Epoch [860/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9081\n",
      "Epoch [860/2000], Avg Train Loss: 3.9081\n",
      "Epoch [860/2000], Avg Val Loss: 2.5083\n",
      "Validation loss improved from 2.5091 to 2.5083. Saving model...\n",
      "\n",
      "LOG: Epoch [861/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8777\n",
      "Epoch [861/2000], Avg Train Loss: 3.8777\n",
      "Epoch [861/2000], Avg Val Loss: 2.5074\n",
      "Validation loss improved from 2.5083 to 2.5074. Saving model...\n",
      "\n",
      "LOG: Epoch [862/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9329\n",
      "Epoch [862/2000], Avg Train Loss: 3.9329\n",
      "Epoch [862/2000], Avg Val Loss: 2.5064\n",
      "Validation loss improved from 2.5074 to 2.5064. Saving model...\n",
      "\n",
      "LOG: Epoch [863/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8668\n",
      "Epoch [863/2000], Avg Train Loss: 3.8668\n",
      "Epoch [863/2000], Avg Val Loss: 2.5055\n",
      "Validation loss improved from 2.5064 to 2.5055. Saving model...\n",
      "\n",
      "LOG: Epoch [864/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8459\n",
      "Epoch [864/2000], Avg Train Loss: 3.8459\n",
      "Epoch [864/2000], Avg Val Loss: 2.5046\n",
      "Validation loss improved from 2.5055 to 2.5046. Saving model...\n",
      "\n",
      "LOG: Epoch [865/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9209\n",
      "Epoch [865/2000], Avg Train Loss: 3.9209\n",
      "Epoch [865/2000], Avg Val Loss: 2.5037\n",
      "Validation loss improved from 2.5046 to 2.5037. Saving model...\n",
      "\n",
      "LOG: Epoch [866/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8993\n",
      "Epoch [866/2000], Avg Train Loss: 3.8993\n",
      "Epoch [866/2000], Avg Val Loss: 2.5029\n",
      "Validation loss improved from 2.5037 to 2.5029. Saving model...\n",
      "\n",
      "LOG: Epoch [867/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8642\n",
      "Epoch [867/2000], Avg Train Loss: 3.8642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [867/2000], Avg Val Loss: 2.5022\n",
      "Validation loss improved from 2.5029 to 2.5022. Saving model...\n",
      "\n",
      "LOG: Epoch [868/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9061\n",
      "Epoch [868/2000], Avg Train Loss: 3.9061\n",
      "Epoch [868/2000], Avg Val Loss: 2.5015\n",
      "Validation loss improved from 2.5022 to 2.5015. Saving model...\n",
      "\n",
      "LOG: Epoch [869/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9162\n",
      "Epoch [869/2000], Avg Train Loss: 3.9162\n",
      "Epoch [869/2000], Avg Val Loss: 2.5009\n",
      "Validation loss improved from 2.5015 to 2.5009. Saving model...\n",
      "\n",
      "LOG: Epoch [870/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9000\n",
      "Epoch [870/2000], Avg Train Loss: 3.9000\n",
      "Epoch [870/2000], Avg Val Loss: 2.5003\n",
      "Validation loss improved from 2.5009 to 2.5003. Saving model...\n",
      "\n",
      "LOG: Epoch [871/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8635\n",
      "Epoch [871/2000], Avg Train Loss: 3.8635\n",
      "Epoch [871/2000], Avg Val Loss: 2.4997\n",
      "Validation loss improved from 2.5003 to 2.4997. Saving model...\n",
      "\n",
      "LOG: Epoch [872/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8918\n",
      "Epoch [872/2000], Avg Train Loss: 3.8918\n",
      "Epoch [872/2000], Avg Val Loss: 2.4992\n",
      "Validation loss improved from 2.4997 to 2.4992. Saving model...\n",
      "\n",
      "LOG: Epoch [873/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9021\n",
      "Epoch [873/2000], Avg Train Loss: 3.9021\n",
      "Epoch [873/2000], Avg Val Loss: 2.4987\n",
      "Validation loss improved from 2.4992 to 2.4987. Saving model...\n",
      "\n",
      "LOG: Epoch [874/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9008\n",
      "Epoch [874/2000], Avg Train Loss: 3.9008\n",
      "Epoch [874/2000], Avg Val Loss: 2.4983\n",
      "Validation loss improved from 2.4987 to 2.4983. Saving model...\n",
      "\n",
      "LOG: Epoch [875/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9056\n",
      "Epoch [875/2000], Avg Train Loss: 3.9056\n",
      "Epoch [875/2000], Avg Val Loss: 2.4977\n",
      "Validation loss improved from 2.4983 to 2.4977. Saving model...\n",
      "\n",
      "LOG: Epoch [876/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9106\n",
      "Epoch [876/2000], Avg Train Loss: 3.9106\n",
      "Epoch [876/2000], Avg Val Loss: 2.4973\n",
      "Validation loss improved from 2.4977 to 2.4973. Saving model...\n",
      "\n",
      "LOG: Epoch [877/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8499\n",
      "Epoch [877/2000], Avg Train Loss: 3.8499\n",
      "Epoch [877/2000], Avg Val Loss: 2.4968\n",
      "Validation loss improved from 2.4973 to 2.4968. Saving model...\n",
      "\n",
      "LOG: Epoch [878/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8997\n",
      "Epoch [878/2000], Avg Train Loss: 3.8997\n",
      "Epoch [878/2000], Avg Val Loss: 2.4962\n",
      "Validation loss improved from 2.4968 to 2.4962. Saving model...\n",
      "\n",
      "LOG: Epoch [879/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8867\n",
      "Epoch [879/2000], Avg Train Loss: 3.8867\n",
      "Epoch [879/2000], Avg Val Loss: 2.4956\n",
      "Validation loss improved from 2.4962 to 2.4956. Saving model...\n",
      "\n",
      "LOG: Epoch [880/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8309\n",
      "Epoch [880/2000], Avg Train Loss: 3.8309\n",
      "Epoch [880/2000], Avg Val Loss: 2.4949\n",
      "Validation loss improved from 2.4956 to 2.4949. Saving model...\n",
      "\n",
      "LOG: Epoch [881/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8672\n",
      "Epoch [881/2000], Avg Train Loss: 3.8672\n",
      "Epoch [881/2000], Avg Val Loss: 2.4943\n",
      "Validation loss improved from 2.4949 to 2.4943. Saving model...\n",
      "\n",
      "LOG: Epoch [882/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8821\n",
      "Epoch [882/2000], Avg Train Loss: 3.8821\n",
      "Epoch [882/2000], Avg Val Loss: 2.4937\n",
      "Validation loss improved from 2.4943 to 2.4937. Saving model...\n",
      "\n",
      "LOG: Epoch [883/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8486\n",
      "Epoch [883/2000], Avg Train Loss: 3.8486\n",
      "Epoch [883/2000], Avg Val Loss: 2.4931\n",
      "Validation loss improved from 2.4937 to 2.4931. Saving model...\n",
      "\n",
      "LOG: Epoch [884/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8428\n",
      "Epoch [884/2000], Avg Train Loss: 3.8428\n",
      "Epoch [884/2000], Avg Val Loss: 2.4927\n",
      "Validation loss improved from 2.4931 to 2.4927. Saving model...\n",
      "\n",
      "LOG: Epoch [885/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8703\n",
      "Epoch [885/2000], Avg Train Loss: 3.8703\n",
      "Epoch [885/2000], Avg Val Loss: 2.4921\n",
      "Validation loss improved from 2.4927 to 2.4921. Saving model...\n",
      "\n",
      "LOG: Epoch [886/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8979\n",
      "Epoch [886/2000], Avg Train Loss: 3.8979\n",
      "Epoch [886/2000], Avg Val Loss: 2.4917\n",
      "Validation loss improved from 2.4921 to 2.4917. Saving model...\n",
      "\n",
      "LOG: Epoch [887/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8517\n",
      "Epoch [887/2000], Avg Train Loss: 3.8517\n",
      "Epoch [887/2000], Avg Val Loss: 2.4912\n",
      "Validation loss improved from 2.4917 to 2.4912. Saving model...\n",
      "\n",
      "LOG: Epoch [888/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8473\n",
      "Epoch [888/2000], Avg Train Loss: 3.8473\n",
      "Epoch [888/2000], Avg Val Loss: 2.4907\n",
      "Validation loss improved from 2.4912 to 2.4907. Saving model...\n",
      "\n",
      "LOG: Epoch [889/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8314\n",
      "Epoch [889/2000], Avg Train Loss: 3.8314\n",
      "Epoch [889/2000], Avg Val Loss: 2.4902\n",
      "Validation loss improved from 2.4907 to 2.4902. Saving model...\n",
      "\n",
      "LOG: Epoch [890/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8853\n",
      "Epoch [890/2000], Avg Train Loss: 3.8853\n",
      "Epoch [890/2000], Avg Val Loss: 2.4895\n",
      "Validation loss improved from 2.4902 to 2.4895. Saving model...\n",
      "\n",
      "LOG: Epoch [891/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8232\n",
      "Epoch [891/2000], Avg Train Loss: 3.8232\n",
      "Epoch [891/2000], Avg Val Loss: 2.4889\n",
      "Validation loss improved from 2.4895 to 2.4889. Saving model...\n",
      "\n",
      "LOG: Epoch [892/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9047\n",
      "Epoch [892/2000], Avg Train Loss: 3.9047\n",
      "Epoch [892/2000], Avg Val Loss: 2.4883\n",
      "Validation loss improved from 2.4889 to 2.4883. Saving model...\n",
      "\n",
      "LOG: Epoch [893/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8550\n",
      "Epoch [893/2000], Avg Train Loss: 3.8550\n",
      "Epoch [893/2000], Avg Val Loss: 2.4876\n",
      "Validation loss improved from 2.4883 to 2.4876. Saving model...\n",
      "\n",
      "LOG: Epoch [894/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8816\n",
      "Epoch [894/2000], Avg Train Loss: 3.8816\n",
      "Epoch [894/2000], Avg Val Loss: 2.4870\n",
      "Validation loss improved from 2.4876 to 2.4870. Saving model...\n",
      "\n",
      "LOG: Epoch [895/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8687\n",
      "Epoch [895/2000], Avg Train Loss: 3.8687\n",
      "Epoch [895/2000], Avg Val Loss: 2.4863\n",
      "Validation loss improved from 2.4870 to 2.4863. Saving model...\n",
      "\n",
      "LOG: Epoch [896/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8083\n",
      "Epoch [896/2000], Avg Train Loss: 3.8083\n",
      "Epoch [896/2000], Avg Val Loss: 2.4857\n",
      "Validation loss improved from 2.4863 to 2.4857. Saving model...\n",
      "\n",
      "LOG: Epoch [897/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8960\n",
      "Epoch [897/2000], Avg Train Loss: 3.8960\n",
      "Epoch [897/2000], Avg Val Loss: 2.4850\n",
      "Validation loss improved from 2.4857 to 2.4850. Saving model...\n",
      "\n",
      "LOG: Epoch [898/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8413\n",
      "Epoch [898/2000], Avg Train Loss: 3.8413\n",
      "Epoch [898/2000], Avg Val Loss: 2.4843\n",
      "Validation loss improved from 2.4850 to 2.4843. Saving model...\n",
      "\n",
      "LOG: Epoch [899/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8707\n",
      "Epoch [899/2000], Avg Train Loss: 3.8707\n",
      "Epoch [899/2000], Avg Val Loss: 2.4836\n",
      "Validation loss improved from 2.4843 to 2.4836. Saving model...\n",
      "\n",
      "LOG: Epoch [900/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8503\n",
      "Epoch [900/2000], Avg Train Loss: 3.8503\n",
      "Epoch [900/2000], Avg Val Loss: 2.4829\n",
      "Validation loss improved from 2.4836 to 2.4829. Saving model...\n",
      "\n",
      "LOG: Epoch [901/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8470\n",
      "Epoch [901/2000], Avg Train Loss: 3.8470\n",
      "Epoch [901/2000], Avg Val Loss: 2.4822\n",
      "Validation loss improved from 2.4829 to 2.4822. Saving model...\n",
      "\n",
      "LOG: Epoch [902/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9085\n",
      "Epoch [902/2000], Avg Train Loss: 3.9085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [902/2000], Avg Val Loss: 2.4816\n",
      "Validation loss improved from 2.4822 to 2.4816. Saving model...\n",
      "\n",
      "LOG: Epoch [903/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8700\n",
      "Epoch [903/2000], Avg Train Loss: 3.8700\n",
      "Epoch [903/2000], Avg Val Loss: 2.4810\n",
      "Validation loss improved from 2.4816 to 2.4810. Saving model...\n",
      "\n",
      "LOG: Epoch [904/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8484\n",
      "Epoch [904/2000], Avg Train Loss: 3.8484\n",
      "Epoch [904/2000], Avg Val Loss: 2.4805\n",
      "Validation loss improved from 2.4810 to 2.4805. Saving model...\n",
      "\n",
      "LOG: Epoch [905/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8498\n",
      "Epoch [905/2000], Avg Train Loss: 3.8498\n",
      "Epoch [905/2000], Avg Val Loss: 2.4800\n",
      "Validation loss improved from 2.4805 to 2.4800. Saving model...\n",
      "\n",
      "LOG: Epoch [906/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8597\n",
      "Epoch [906/2000], Avg Train Loss: 3.8597\n",
      "Epoch [906/2000], Avg Val Loss: 2.4795\n",
      "Validation loss improved from 2.4800 to 2.4795. Saving model...\n",
      "\n",
      "LOG: Epoch [907/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8309\n",
      "Epoch [907/2000], Avg Train Loss: 3.8309\n",
      "Epoch [907/2000], Avg Val Loss: 2.4790\n",
      "Validation loss improved from 2.4795 to 2.4790. Saving model...\n",
      "\n",
      "LOG: Epoch [908/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8294\n",
      "Epoch [908/2000], Avg Train Loss: 3.8294\n",
      "Epoch [908/2000], Avg Val Loss: 2.4785\n",
      "Validation loss improved from 2.4790 to 2.4785. Saving model...\n",
      "\n",
      "LOG: Epoch [909/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8736\n",
      "Epoch [909/2000], Avg Train Loss: 3.8736\n",
      "Epoch [909/2000], Avg Val Loss: 2.4779\n",
      "Validation loss improved from 2.4785 to 2.4779. Saving model...\n",
      "\n",
      "LOG: Epoch [910/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8462\n",
      "Epoch [910/2000], Avg Train Loss: 3.8462\n",
      "Epoch [910/2000], Avg Val Loss: 2.4775\n",
      "Validation loss improved from 2.4779 to 2.4775. Saving model...\n",
      "\n",
      "LOG: Epoch [911/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8186\n",
      "Epoch [911/2000], Avg Train Loss: 3.8186\n",
      "Epoch [911/2000], Avg Val Loss: 2.4769\n",
      "Validation loss improved from 2.4775 to 2.4769. Saving model...\n",
      "\n",
      "LOG: Epoch [912/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8258\n",
      "Epoch [912/2000], Avg Train Loss: 3.8258\n",
      "Epoch [912/2000], Avg Val Loss: 2.4764\n",
      "Validation loss improved from 2.4769 to 2.4764. Saving model...\n",
      "\n",
      "LOG: Epoch [913/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8115\n",
      "Epoch [913/2000], Avg Train Loss: 3.8115\n",
      "Epoch [913/2000], Avg Val Loss: 2.4759\n",
      "Validation loss improved from 2.4764 to 2.4759. Saving model...\n",
      "\n",
      "LOG: Epoch [914/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8303\n",
      "Epoch [914/2000], Avg Train Loss: 3.8303\n",
      "Epoch [914/2000], Avg Val Loss: 2.4755\n",
      "Validation loss improved from 2.4759 to 2.4755. Saving model...\n",
      "\n",
      "LOG: Epoch [915/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8512\n",
      "Epoch [915/2000], Avg Train Loss: 3.8512\n",
      "Epoch [915/2000], Avg Val Loss: 2.4750\n",
      "Validation loss improved from 2.4755 to 2.4750. Saving model...\n",
      "\n",
      "LOG: Epoch [916/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8250\n",
      "Epoch [916/2000], Avg Train Loss: 3.8250\n",
      "Epoch [916/2000], Avg Val Loss: 2.4746\n",
      "Validation loss improved from 2.4750 to 2.4746. Saving model...\n",
      "\n",
      "LOG: Epoch [917/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8718\n",
      "Epoch [917/2000], Avg Train Loss: 3.8718\n",
      "Epoch [917/2000], Avg Val Loss: 2.4740\n",
      "Validation loss improved from 2.4746 to 2.4740. Saving model...\n",
      "\n",
      "LOG: Epoch [918/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8706\n",
      "Epoch [918/2000], Avg Train Loss: 3.8706\n",
      "Epoch [918/2000], Avg Val Loss: 2.4734\n",
      "Validation loss improved from 2.4740 to 2.4734. Saving model...\n",
      "\n",
      "LOG: Epoch [919/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8580\n",
      "Epoch [919/2000], Avg Train Loss: 3.8580\n",
      "Epoch [919/2000], Avg Val Loss: 2.4728\n",
      "Validation loss improved from 2.4734 to 2.4728. Saving model...\n",
      "\n",
      "LOG: Epoch [920/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7879\n",
      "Epoch [920/2000], Avg Train Loss: 3.7879\n",
      "Epoch [920/2000], Avg Val Loss: 2.4723\n",
      "Validation loss improved from 2.4728 to 2.4723. Saving model...\n",
      "\n",
      "LOG: Epoch [921/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8242\n",
      "Epoch [921/2000], Avg Train Loss: 3.8242\n",
      "Epoch [921/2000], Avg Val Loss: 2.4718\n",
      "Validation loss improved from 2.4723 to 2.4718. Saving model...\n",
      "\n",
      "LOG: Epoch [922/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8339\n",
      "Epoch [922/2000], Avg Train Loss: 3.8339\n",
      "Epoch [922/2000], Avg Val Loss: 2.4712\n",
      "Validation loss improved from 2.4718 to 2.4712. Saving model...\n",
      "\n",
      "LOG: Epoch [923/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8056\n",
      "Epoch [923/2000], Avg Train Loss: 3.8056\n",
      "Epoch [923/2000], Avg Val Loss: 2.4707\n",
      "Validation loss improved from 2.4712 to 2.4707. Saving model...\n",
      "\n",
      "LOG: Epoch [924/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8077\n",
      "Epoch [924/2000], Avg Train Loss: 3.8077\n",
      "Epoch [924/2000], Avg Val Loss: 2.4701\n",
      "Validation loss improved from 2.4707 to 2.4701. Saving model...\n",
      "\n",
      "LOG: Epoch [925/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8622\n",
      "Epoch [925/2000], Avg Train Loss: 3.8622\n",
      "Epoch [925/2000], Avg Val Loss: 2.4694\n",
      "Validation loss improved from 2.4701 to 2.4694. Saving model...\n",
      "\n",
      "LOG: Epoch [926/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7775\n",
      "Epoch [926/2000], Avg Train Loss: 3.7775\n",
      "Epoch [926/2000], Avg Val Loss: 2.4687\n",
      "Validation loss improved from 2.4694 to 2.4687. Saving model...\n",
      "\n",
      "LOG: Epoch [927/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8333\n",
      "Epoch [927/2000], Avg Train Loss: 3.8333\n",
      "Epoch [927/2000], Avg Val Loss: 2.4680\n",
      "Validation loss improved from 2.4687 to 2.4680. Saving model...\n",
      "\n",
      "LOG: Epoch [928/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8438\n",
      "Epoch [928/2000], Avg Train Loss: 3.8438\n",
      "Epoch [928/2000], Avg Val Loss: 2.4674\n",
      "Validation loss improved from 2.4680 to 2.4674. Saving model...\n",
      "\n",
      "LOG: Epoch [929/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8411\n",
      "Epoch [929/2000], Avg Train Loss: 3.8411\n",
      "Epoch [929/2000], Avg Val Loss: 2.4668\n",
      "Validation loss improved from 2.4674 to 2.4668. Saving model...\n",
      "\n",
      "LOG: Epoch [930/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8450\n",
      "Epoch [930/2000], Avg Train Loss: 3.8450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [930/2000], Avg Val Loss: 2.4661\n",
      "Validation loss improved from 2.4668 to 2.4661. Saving model...\n",
      "\n",
      "LOG: Epoch [931/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8413\n",
      "Epoch [931/2000], Avg Train Loss: 3.8413\n",
      "Epoch [931/2000], Avg Val Loss: 2.4656\n",
      "Validation loss improved from 2.4661 to 2.4656. Saving model...\n",
      "\n",
      "LOG: Epoch [932/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8344\n",
      "Epoch [932/2000], Avg Train Loss: 3.8344\n",
      "Epoch [932/2000], Avg Val Loss: 2.4650\n",
      "Validation loss improved from 2.4656 to 2.4650. Saving model...\n",
      "\n",
      "LOG: Epoch [933/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8398\n",
      "Epoch [933/2000], Avg Train Loss: 3.8398\n",
      "Epoch [933/2000], Avg Val Loss: 2.4646\n",
      "Validation loss improved from 2.4650 to 2.4646. Saving model...\n",
      "\n",
      "LOG: Epoch [934/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8424\n",
      "Epoch [934/2000], Avg Train Loss: 3.8424\n",
      "Epoch [934/2000], Avg Val Loss: 2.4641\n",
      "Validation loss improved from 2.4646 to 2.4641. Saving model...\n",
      "\n",
      "LOG: Epoch [935/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8052\n",
      "Epoch [935/2000], Avg Train Loss: 3.8052\n",
      "Epoch [935/2000], Avg Val Loss: 2.4637\n",
      "Validation loss improved from 2.4641 to 2.4637. Saving model...\n",
      "\n",
      "LOG: Epoch [936/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8030\n",
      "Epoch [936/2000], Avg Train Loss: 3.8030\n",
      "Epoch [936/2000], Avg Val Loss: 2.4634\n",
      "Validation loss improved from 2.4637 to 2.4634. Saving model...\n",
      "\n",
      "LOG: Epoch [937/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7659\n",
      "Epoch [937/2000], Avg Train Loss: 3.7659\n",
      "Epoch [937/2000], Avg Val Loss: 2.4630\n",
      "Validation loss improved from 2.4634 to 2.4630. Saving model...\n",
      "\n",
      "LOG: Epoch [938/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7913\n",
      "Epoch [938/2000], Avg Train Loss: 3.7913\n",
      "Epoch [938/2000], Avg Val Loss: 2.4625\n",
      "Validation loss improved from 2.4630 to 2.4625. Saving model...\n",
      "\n",
      "LOG: Epoch [939/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8463\n",
      "Epoch [939/2000], Avg Train Loss: 3.8463\n",
      "Epoch [939/2000], Avg Val Loss: 2.4621\n",
      "Validation loss improved from 2.4625 to 2.4621. Saving model...\n",
      "\n",
      "LOG: Epoch [940/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8020\n",
      "Epoch [940/2000], Avg Train Loss: 3.8020\n",
      "Epoch [940/2000], Avg Val Loss: 2.4617\n",
      "Validation loss improved from 2.4621 to 2.4617. Saving model...\n",
      "\n",
      "LOG: Epoch [941/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7875\n",
      "Epoch [941/2000], Avg Train Loss: 3.7875\n",
      "Epoch [941/2000], Avg Val Loss: 2.4612\n",
      "Validation loss improved from 2.4617 to 2.4612. Saving model...\n",
      "\n",
      "LOG: Epoch [942/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8029\n",
      "Epoch [942/2000], Avg Train Loss: 3.8029\n",
      "Epoch [942/2000], Avg Val Loss: 2.4606\n",
      "Validation loss improved from 2.4612 to 2.4606. Saving model...\n",
      "\n",
      "LOG: Epoch [943/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8327\n",
      "Epoch [943/2000], Avg Train Loss: 3.8327\n",
      "Epoch [943/2000], Avg Val Loss: 2.4601\n",
      "Validation loss improved from 2.4606 to 2.4601. Saving model...\n",
      "\n",
      "LOG: Epoch [944/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8159\n",
      "Epoch [944/2000], Avg Train Loss: 3.8159\n",
      "Epoch [944/2000], Avg Val Loss: 2.4597\n",
      "Validation loss improved from 2.4601 to 2.4597. Saving model...\n",
      "\n",
      "LOG: Epoch [945/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8110\n",
      "Epoch [945/2000], Avg Train Loss: 3.8110\n",
      "Epoch [945/2000], Avg Val Loss: 2.4594\n",
      "Validation loss improved from 2.4597 to 2.4594. Saving model...\n",
      "\n",
      "LOG: Epoch [946/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8517\n",
      "Epoch [946/2000], Avg Train Loss: 3.8517\n",
      "Epoch [946/2000], Avg Val Loss: 2.4592\n",
      "Validation loss improved from 2.4594 to 2.4592. Saving model...\n",
      "\n",
      "LOG: Epoch [947/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7995\n",
      "Epoch [947/2000], Avg Train Loss: 3.7995\n",
      "Epoch [947/2000], Avg Val Loss: 2.4592\n",
      "Validation loss improved from 2.4592 to 2.4592. Saving model...\n",
      "\n",
      "LOG: Epoch [948/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7461\n",
      "Epoch [948/2000], Avg Train Loss: 3.7461\n",
      "Epoch [948/2000], Avg Val Loss: 2.4591\n",
      "Validation loss improved from 2.4592 to 2.4591. Saving model...\n",
      "\n",
      "LOG: Epoch [949/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8216\n",
      "Epoch [949/2000], Avg Train Loss: 3.8216\n",
      "Epoch [949/2000], Avg Val Loss: 2.4589\n",
      "Validation loss improved from 2.4591 to 2.4589. Saving model...\n",
      "\n",
      "LOG: Epoch [950/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8223\n",
      "Epoch [950/2000], Avg Train Loss: 3.8223\n",
      "Epoch [950/2000], Avg Val Loss: 2.4588\n",
      "Validation loss improved from 2.4589 to 2.4588. Saving model...\n",
      "\n",
      "LOG: Epoch [951/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7919\n",
      "Epoch [951/2000], Avg Train Loss: 3.7919\n",
      "Epoch [951/2000], Avg Val Loss: 2.4585\n",
      "Validation loss improved from 2.4588 to 2.4585. Saving model...\n",
      "\n",
      "LOG: Epoch [952/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7877\n",
      "Epoch [952/2000], Avg Train Loss: 3.7877\n",
      "Epoch [952/2000], Avg Val Loss: 2.4583\n",
      "Validation loss improved from 2.4585 to 2.4583. Saving model...\n",
      "\n",
      "LOG: Epoch [953/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8026\n",
      "Epoch [953/2000], Avg Train Loss: 3.8026\n",
      "Epoch [953/2000], Avg Val Loss: 2.4579\n",
      "Validation loss improved from 2.4583 to 2.4579. Saving model...\n",
      "\n",
      "LOG: Epoch [954/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8244\n",
      "Epoch [954/2000], Avg Train Loss: 3.8244\n",
      "Epoch [954/2000], Avg Val Loss: 2.4576\n",
      "Validation loss improved from 2.4579 to 2.4576. Saving model...\n",
      "\n",
      "LOG: Epoch [955/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8084\n",
      "Epoch [955/2000], Avg Train Loss: 3.8084\n",
      "Epoch [955/2000], Avg Val Loss: 2.4572\n",
      "Validation loss improved from 2.4576 to 2.4572. Saving model...\n",
      "\n",
      "LOG: Epoch [956/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7783\n",
      "Epoch [956/2000], Avg Train Loss: 3.7783\n",
      "Epoch [956/2000], Avg Val Loss: 2.4568\n",
      "Validation loss improved from 2.4572 to 2.4568. Saving model...\n",
      "\n",
      "LOG: Epoch [957/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8319\n",
      "Epoch [957/2000], Avg Train Loss: 3.8319\n",
      "Epoch [957/2000], Avg Val Loss: 2.4565\n",
      "Validation loss improved from 2.4568 to 2.4565. Saving model...\n",
      "\n",
      "LOG: Epoch [958/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8138\n",
      "Epoch [958/2000], Avg Train Loss: 3.8138\n",
      "Epoch [958/2000], Avg Val Loss: 2.4563\n",
      "Validation loss improved from 2.4565 to 2.4563. Saving model...\n",
      "\n",
      "LOG: Epoch [959/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8347\n",
      "Epoch [959/2000], Avg Train Loss: 3.8347\n",
      "Epoch [959/2000], Avg Val Loss: 2.4560\n",
      "Validation loss improved from 2.4563 to 2.4560. Saving model...\n",
      "\n",
      "LOG: Epoch [960/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7762\n",
      "Epoch [960/2000], Avg Train Loss: 3.7762\n",
      "Epoch [960/2000], Avg Val Loss: 2.4557\n",
      "Validation loss improved from 2.4560 to 2.4557. Saving model...\n",
      "\n",
      "LOG: Epoch [961/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7678\n",
      "Epoch [961/2000], Avg Train Loss: 3.7678\n",
      "Epoch [961/2000], Avg Val Loss: 2.4552\n",
      "Validation loss improved from 2.4557 to 2.4552. Saving model...\n",
      "\n",
      "LOG: Epoch [962/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8128\n",
      "Epoch [962/2000], Avg Train Loss: 3.8128\n",
      "Epoch [962/2000], Avg Val Loss: 2.4547\n",
      "Validation loss improved from 2.4552 to 2.4547. Saving model...\n",
      "\n",
      "LOG: Epoch [963/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8508\n",
      "Epoch [963/2000], Avg Train Loss: 3.8508\n",
      "Epoch [963/2000], Avg Val Loss: 2.4541\n",
      "Validation loss improved from 2.4547 to 2.4541. Saving model...\n",
      "\n",
      "LOG: Epoch [964/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7623\n",
      "Epoch [964/2000], Avg Train Loss: 3.7623\n",
      "Epoch [964/2000], Avg Val Loss: 2.4536\n",
      "Validation loss improved from 2.4541 to 2.4536. Saving model...\n",
      "\n",
      "LOG: Epoch [965/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7813\n",
      "Epoch [965/2000], Avg Train Loss: 3.7813\n",
      "Epoch [965/2000], Avg Val Loss: 2.4530\n",
      "Validation loss improved from 2.4536 to 2.4530. Saving model...\n",
      "\n",
      "LOG: Epoch [966/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7991\n",
      "Epoch [966/2000], Avg Train Loss: 3.7991\n",
      "Epoch [966/2000], Avg Val Loss: 2.4525\n",
      "Validation loss improved from 2.4530 to 2.4525. Saving model...\n",
      "\n",
      "LOG: Epoch [967/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8246\n",
      "Epoch [967/2000], Avg Train Loss: 3.8246\n",
      "Epoch [967/2000], Avg Val Loss: 2.4519\n",
      "Validation loss improved from 2.4525 to 2.4519. Saving model...\n",
      "\n",
      "LOG: Epoch [968/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8424\n",
      "Epoch [968/2000], Avg Train Loss: 3.8424\n",
      "Epoch [968/2000], Avg Val Loss: 2.4513\n",
      "Validation loss improved from 2.4519 to 2.4513. Saving model...\n",
      "\n",
      "LOG: Epoch [969/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8375\n",
      "Epoch [969/2000], Avg Train Loss: 3.8375\n",
      "Epoch [969/2000], Avg Val Loss: 2.4508\n",
      "Validation loss improved from 2.4513 to 2.4508. Saving model...\n",
      "\n",
      "LOG: Epoch [970/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7610\n",
      "Epoch [970/2000], Avg Train Loss: 3.7610\n",
      "Epoch [970/2000], Avg Val Loss: 2.4503\n",
      "Validation loss improved from 2.4508 to 2.4503. Saving model...\n",
      "\n",
      "LOG: Epoch [971/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8170\n",
      "Epoch [971/2000], Avg Train Loss: 3.8170\n",
      "Epoch [971/2000], Avg Val Loss: 2.4497\n",
      "Validation loss improved from 2.4503 to 2.4497. Saving model...\n",
      "\n",
      "LOG: Epoch [972/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7816\n",
      "Epoch [972/2000], Avg Train Loss: 3.7816\n",
      "Epoch [972/2000], Avg Val Loss: 2.4491\n",
      "Validation loss improved from 2.4497 to 2.4491. Saving model...\n",
      "\n",
      "LOG: Epoch [973/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7811\n",
      "Epoch [973/2000], Avg Train Loss: 3.7811\n",
      "Epoch [973/2000], Avg Val Loss: 2.4485\n",
      "Validation loss improved from 2.4491 to 2.4485. Saving model...\n",
      "\n",
      "LOG: Epoch [974/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7820\n",
      "Epoch [974/2000], Avg Train Loss: 3.7820\n",
      "Epoch [974/2000], Avg Val Loss: 2.4478\n",
      "Validation loss improved from 2.4485 to 2.4478. Saving model...\n",
      "\n",
      "LOG: Epoch [975/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7378\n",
      "Epoch [975/2000], Avg Train Loss: 3.7378\n",
      "Epoch [975/2000], Avg Val Loss: 2.4472\n",
      "Validation loss improved from 2.4478 to 2.4472. Saving model...\n",
      "\n",
      "LOG: Epoch [976/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8342\n",
      "Epoch [976/2000], Avg Train Loss: 3.8342\n",
      "Epoch [976/2000], Avg Val Loss: 2.4466\n",
      "Validation loss improved from 2.4472 to 2.4466. Saving model...\n",
      "\n",
      "LOG: Epoch [977/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8147\n",
      "Epoch [977/2000], Avg Train Loss: 3.8147\n",
      "Epoch [977/2000], Avg Val Loss: 2.4459\n",
      "Validation loss improved from 2.4466 to 2.4459. Saving model...\n",
      "\n",
      "LOG: Epoch [978/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7754\n",
      "Epoch [978/2000], Avg Train Loss: 3.7754\n",
      "Epoch [978/2000], Avg Val Loss: 2.4452\n",
      "Validation loss improved from 2.4459 to 2.4452. Saving model...\n",
      "\n",
      "LOG: Epoch [979/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7674\n",
      "Epoch [979/2000], Avg Train Loss: 3.7674\n",
      "Epoch [979/2000], Avg Val Loss: 2.4446\n",
      "Validation loss improved from 2.4452 to 2.4446. Saving model...\n",
      "\n",
      "LOG: Epoch [980/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7948\n",
      "Epoch [980/2000], Avg Train Loss: 3.7948\n",
      "Epoch [980/2000], Avg Val Loss: 2.4439\n",
      "Validation loss improved from 2.4446 to 2.4439. Saving model...\n",
      "\n",
      "LOG: Epoch [981/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7932\n",
      "Epoch [981/2000], Avg Train Loss: 3.7932\n",
      "Epoch [981/2000], Avg Val Loss: 2.4432\n",
      "Validation loss improved from 2.4439 to 2.4432. Saving model...\n",
      "\n",
      "LOG: Epoch [982/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7907\n",
      "Epoch [982/2000], Avg Train Loss: 3.7907\n",
      "Epoch [982/2000], Avg Val Loss: 2.4425\n",
      "Validation loss improved from 2.4432 to 2.4425. Saving model...\n",
      "\n",
      "LOG: Epoch [983/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7547\n",
      "Epoch [983/2000], Avg Train Loss: 3.7547\n",
      "Epoch [983/2000], Avg Val Loss: 2.4419\n",
      "Validation loss improved from 2.4425 to 2.4419. Saving model...\n",
      "\n",
      "LOG: Epoch [984/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7878\n",
      "Epoch [984/2000], Avg Train Loss: 3.7878\n",
      "Epoch [984/2000], Avg Val Loss: 2.4412\n",
      "Validation loss improved from 2.4419 to 2.4412. Saving model...\n",
      "\n",
      "LOG: Epoch [985/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7517\n",
      "Epoch [985/2000], Avg Train Loss: 3.7517\n",
      "Epoch [985/2000], Avg Val Loss: 2.4405\n",
      "Validation loss improved from 2.4412 to 2.4405. Saving model...\n",
      "\n",
      "LOG: Epoch [986/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7983\n",
      "Epoch [986/2000], Avg Train Loss: 3.7983\n",
      "Epoch [986/2000], Avg Val Loss: 2.4401\n",
      "Validation loss improved from 2.4405 to 2.4401. Saving model...\n",
      "\n",
      "LOG: Epoch [987/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8036\n",
      "Epoch [987/2000], Avg Train Loss: 3.8036\n",
      "Epoch [987/2000], Avg Val Loss: 2.4397\n",
      "Validation loss improved from 2.4401 to 2.4397. Saving model...\n",
      "\n",
      "LOG: Epoch [988/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7853\n",
      "Epoch [988/2000], Avg Train Loss: 3.7853\n",
      "Epoch [988/2000], Avg Val Loss: 2.4392\n",
      "Validation loss improved from 2.4397 to 2.4392. Saving model...\n",
      "\n",
      "LOG: Epoch [989/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7812\n",
      "Epoch [989/2000], Avg Train Loss: 3.7812\n",
      "Epoch [989/2000], Avg Val Loss: 2.4387\n",
      "Validation loss improved from 2.4392 to 2.4387. Saving model...\n",
      "\n",
      "LOG: Epoch [990/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7581\n",
      "Epoch [990/2000], Avg Train Loss: 3.7581\n",
      "Epoch [990/2000], Avg Val Loss: 2.4381\n",
      "Validation loss improved from 2.4387 to 2.4381. Saving model...\n",
      "\n",
      "LOG: Epoch [991/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8089\n",
      "Epoch [991/2000], Avg Train Loss: 3.8089\n",
      "Epoch [991/2000], Avg Val Loss: 2.4379\n",
      "Validation loss improved from 2.4381 to 2.4379. Saving model...\n",
      "\n",
      "LOG: Epoch [992/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7673\n",
      "Epoch [992/2000], Avg Train Loss: 3.7673\n",
      "Epoch [992/2000], Avg Val Loss: 2.4376\n",
      "Validation loss improved from 2.4379 to 2.4376. Saving model...\n",
      "\n",
      "LOG: Epoch [993/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7699\n",
      "Epoch [993/2000], Avg Train Loss: 3.7699\n",
      "Epoch [993/2000], Avg Val Loss: 2.4372\n",
      "Validation loss improved from 2.4376 to 2.4372. Saving model...\n",
      "\n",
      "LOG: Epoch [994/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7716\n",
      "Epoch [994/2000], Avg Train Loss: 3.7716\n",
      "Epoch [994/2000], Avg Val Loss: 2.4368\n",
      "Validation loss improved from 2.4372 to 2.4368. Saving model...\n",
      "\n",
      "LOG: Epoch [995/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7667\n",
      "Epoch [995/2000], Avg Train Loss: 3.7667\n",
      "Epoch [995/2000], Avg Val Loss: 2.4363\n",
      "Validation loss improved from 2.4368 to 2.4363. Saving model...\n",
      "\n",
      "LOG: Epoch [996/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7179\n",
      "Epoch [996/2000], Avg Train Loss: 3.7179\n",
      "Epoch [996/2000], Avg Val Loss: 2.4358\n",
      "Validation loss improved from 2.4363 to 2.4358. Saving model...\n",
      "\n",
      "LOG: Epoch [997/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7733\n",
      "Epoch [997/2000], Avg Train Loss: 3.7733\n",
      "Epoch [997/2000], Avg Val Loss: 2.4352\n",
      "Validation loss improved from 2.4358 to 2.4352. Saving model...\n",
      "\n",
      "LOG: Epoch [998/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7674\n",
      "Epoch [998/2000], Avg Train Loss: 3.7674\n",
      "Epoch [998/2000], Avg Val Loss: 2.4347\n",
      "Validation loss improved from 2.4352 to 2.4347. Saving model...\n",
      "\n",
      "LOG: Epoch [999/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7737\n",
      "Epoch [999/2000], Avg Train Loss: 3.7737\n",
      "Epoch [999/2000], Avg Val Loss: 2.4342\n",
      "Validation loss improved from 2.4347 to 2.4342. Saving model...\n",
      "\n",
      "LOG: Epoch [1000/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7581\n",
      "Epoch [1000/2000], Avg Train Loss: 3.7581\n",
      "Epoch [1000/2000], Avg Val Loss: 2.4336\n",
      "Validation loss improved from 2.4342 to 2.4336. Saving model...\n",
      "\n",
      "LOG: Epoch [1001/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7585\n",
      "Epoch [1001/2000], Avg Train Loss: 3.7585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1001/2000], Avg Val Loss: 2.4329\n",
      "Validation loss improved from 2.4336 to 2.4329. Saving model...\n",
      "\n",
      "LOG: Epoch [1002/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7239\n",
      "Epoch [1002/2000], Avg Train Loss: 3.7239\n",
      "Epoch [1002/2000], Avg Val Loss: 2.4324\n",
      "Validation loss improved from 2.4329 to 2.4324. Saving model...\n",
      "\n",
      "LOG: Epoch [1003/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7713\n",
      "Epoch [1003/2000], Avg Train Loss: 3.7713\n",
      "Epoch [1003/2000], Avg Val Loss: 2.4318\n",
      "Validation loss improved from 2.4324 to 2.4318. Saving model...\n",
      "\n",
      "LOG: Epoch [1004/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7821\n",
      "Epoch [1004/2000], Avg Train Loss: 3.7821\n",
      "Epoch [1004/2000], Avg Val Loss: 2.4313\n",
      "Validation loss improved from 2.4318 to 2.4313. Saving model...\n",
      "\n",
      "LOG: Epoch [1005/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7443\n",
      "Epoch [1005/2000], Avg Train Loss: 3.7443\n",
      "Epoch [1005/2000], Avg Val Loss: 2.4309\n",
      "Validation loss improved from 2.4313 to 2.4309. Saving model...\n",
      "\n",
      "LOG: Epoch [1006/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7921\n",
      "Epoch [1006/2000], Avg Train Loss: 3.7921\n",
      "Epoch [1006/2000], Avg Val Loss: 2.4304\n",
      "Validation loss improved from 2.4309 to 2.4304. Saving model...\n",
      "\n",
      "LOG: Epoch [1007/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8116\n",
      "Epoch [1007/2000], Avg Train Loss: 3.8116\n",
      "Epoch [1007/2000], Avg Val Loss: 2.4299\n",
      "Validation loss improved from 2.4304 to 2.4299. Saving model...\n",
      "\n",
      "LOG: Epoch [1008/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7545\n",
      "Epoch [1008/2000], Avg Train Loss: 3.7545\n",
      "Epoch [1008/2000], Avg Val Loss: 2.4292\n",
      "Validation loss improved from 2.4299 to 2.4292. Saving model...\n",
      "\n",
      "LOG: Epoch [1009/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7668\n",
      "Epoch [1009/2000], Avg Train Loss: 3.7668\n",
      "Epoch [1009/2000], Avg Val Loss: 2.4285\n",
      "Validation loss improved from 2.4292 to 2.4285. Saving model...\n",
      "\n",
      "LOG: Epoch [1010/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7428\n",
      "Epoch [1010/2000], Avg Train Loss: 3.7428\n",
      "Epoch [1010/2000], Avg Val Loss: 2.4279\n",
      "Validation loss improved from 2.4285 to 2.4279. Saving model...\n",
      "\n",
      "LOG: Epoch [1011/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7406\n",
      "Epoch [1011/2000], Avg Train Loss: 3.7406\n",
      "Epoch [1011/2000], Avg Val Loss: 2.4274\n",
      "Validation loss improved from 2.4279 to 2.4274. Saving model...\n",
      "\n",
      "LOG: Epoch [1012/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7252\n",
      "Epoch [1012/2000], Avg Train Loss: 3.7252\n",
      "Epoch [1012/2000], Avg Val Loss: 2.4270\n",
      "Validation loss improved from 2.4274 to 2.4270. Saving model...\n",
      "\n",
      "LOG: Epoch [1013/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7577\n",
      "Epoch [1013/2000], Avg Train Loss: 3.7577\n",
      "Epoch [1013/2000], Avg Val Loss: 2.4268\n",
      "Validation loss improved from 2.4270 to 2.4268. Saving model...\n",
      "\n",
      "LOG: Epoch [1014/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7729\n",
      "Epoch [1014/2000], Avg Train Loss: 3.7729\n",
      "Epoch [1014/2000], Avg Val Loss: 2.4266\n",
      "Validation loss improved from 2.4268 to 2.4266. Saving model...\n",
      "\n",
      "LOG: Epoch [1015/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7757\n",
      "Epoch [1015/2000], Avg Train Loss: 3.7757\n",
      "Epoch [1015/2000], Avg Val Loss: 2.4264\n",
      "Validation loss improved from 2.4266 to 2.4264. Saving model...\n",
      "\n",
      "LOG: Epoch [1016/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7366\n",
      "Epoch [1016/2000], Avg Train Loss: 3.7366\n",
      "Epoch [1016/2000], Avg Val Loss: 2.4262\n",
      "Validation loss improved from 2.4264 to 2.4262. Saving model...\n",
      "\n",
      "LOG: Epoch [1017/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7745\n",
      "Epoch [1017/2000], Avg Train Loss: 3.7745\n",
      "Epoch [1017/2000], Avg Val Loss: 2.4260\n",
      "Validation loss improved from 2.4262 to 2.4260. Saving model...\n",
      "\n",
      "LOG: Epoch [1018/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7388\n",
      "Epoch [1018/2000], Avg Train Loss: 3.7388\n",
      "Epoch [1018/2000], Avg Val Loss: 2.4259\n",
      "Validation loss improved from 2.4260 to 2.4259. Saving model...\n",
      "\n",
      "LOG: Epoch [1019/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7871\n",
      "Epoch [1019/2000], Avg Train Loss: 3.7871\n",
      "Epoch [1019/2000], Avg Val Loss: 2.4258\n",
      "Validation loss improved from 2.4259 to 2.4258. Saving model...\n",
      "\n",
      "LOG: Epoch [1020/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7393\n",
      "Epoch [1020/2000], Avg Train Loss: 3.7393\n",
      "Epoch [1020/2000], Avg Val Loss: 2.4256\n",
      "Validation loss improved from 2.4258 to 2.4256. Saving model...\n",
      "\n",
      "LOG: Epoch [1021/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7540\n",
      "Epoch [1021/2000], Avg Train Loss: 3.7540\n",
      "Epoch [1021/2000], Avg Val Loss: 2.4255\n",
      "Validation loss improved from 2.4256 to 2.4255. Saving model...\n",
      "\n",
      "LOG: Epoch [1022/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7598\n",
      "Epoch [1022/2000], Avg Train Loss: 3.7598\n",
      "Epoch [1022/2000], Avg Val Loss: 2.4253\n",
      "Validation loss improved from 2.4255 to 2.4253. Saving model...\n",
      "\n",
      "LOG: Epoch [1023/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7587\n",
      "Epoch [1023/2000], Avg Train Loss: 3.7587\n",
      "Epoch [1023/2000], Avg Val Loss: 2.4253\n",
      "Validation loss improved from 2.4253 to 2.4253. Saving model...\n",
      "\n",
      "LOG: Epoch [1024/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7281\n",
      "Epoch [1024/2000], Avg Train Loss: 3.7281\n",
      "Epoch [1024/2000], Avg Val Loss: 2.4252\n",
      "Validation loss improved from 2.4253 to 2.4252. Saving model...\n",
      "\n",
      "LOG: Epoch [1025/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7413\n",
      "Epoch [1025/2000], Avg Train Loss: 3.7413\n",
      "Epoch [1025/2000], Avg Val Loss: 2.4249\n",
      "Validation loss improved from 2.4252 to 2.4249. Saving model...\n",
      "\n",
      "LOG: Epoch [1026/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7512\n",
      "Epoch [1026/2000], Avg Train Loss: 3.7512\n",
      "Epoch [1026/2000], Avg Val Loss: 2.4247\n",
      "Validation loss improved from 2.4249 to 2.4247. Saving model...\n",
      "\n",
      "LOG: Epoch [1027/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7841\n",
      "Epoch [1027/2000], Avg Train Loss: 3.7841\n",
      "Epoch [1027/2000], Avg Val Loss: 2.4246\n",
      "Validation loss improved from 2.4247 to 2.4246. Saving model...\n",
      "\n",
      "LOG: Epoch [1028/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7326\n",
      "Epoch [1028/2000], Avg Train Loss: 3.7326\n",
      "Epoch [1028/2000], Avg Val Loss: 2.4243\n",
      "Validation loss improved from 2.4246 to 2.4243. Saving model...\n",
      "\n",
      "LOG: Epoch [1029/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7199\n",
      "Epoch [1029/2000], Avg Train Loss: 3.7199\n",
      "Epoch [1029/2000], Avg Val Loss: 2.4239\n",
      "Validation loss improved from 2.4243 to 2.4239. Saving model...\n",
      "\n",
      "LOG: Epoch [1030/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7566\n",
      "Epoch [1030/2000], Avg Train Loss: 3.7566\n",
      "Epoch [1030/2000], Avg Val Loss: 2.4236\n",
      "Validation loss improved from 2.4239 to 2.4236. Saving model...\n",
      "\n",
      "LOG: Epoch [1031/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7772\n",
      "Epoch [1031/2000], Avg Train Loss: 3.7772\n",
      "Epoch [1031/2000], Avg Val Loss: 2.4233\n",
      "Validation loss improved from 2.4236 to 2.4233. Saving model...\n",
      "\n",
      "LOG: Epoch [1032/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7633\n",
      "Epoch [1032/2000], Avg Train Loss: 3.7633\n",
      "Epoch [1032/2000], Avg Val Loss: 2.4229\n",
      "Validation loss improved from 2.4233 to 2.4229. Saving model...\n",
      "\n",
      "LOG: Epoch [1033/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7405\n",
      "Epoch [1033/2000], Avg Train Loss: 3.7405\n",
      "Epoch [1033/2000], Avg Val Loss: 2.4225\n",
      "Validation loss improved from 2.4229 to 2.4225. Saving model...\n",
      "\n",
      "LOG: Epoch [1034/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7054\n",
      "Epoch [1034/2000], Avg Train Loss: 3.7054\n",
      "Epoch [1034/2000], Avg Val Loss: 2.4221\n",
      "Validation loss improved from 2.4225 to 2.4221. Saving model...\n",
      "\n",
      "LOG: Epoch [1035/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7211\n",
      "Epoch [1035/2000], Avg Train Loss: 3.7211\n",
      "Epoch [1035/2000], Avg Val Loss: 2.4215\n",
      "Validation loss improved from 2.4221 to 2.4215. Saving model...\n",
      "\n",
      "LOG: Epoch [1036/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7149\n",
      "Epoch [1036/2000], Avg Train Loss: 3.7149\n",
      "Epoch [1036/2000], Avg Val Loss: 2.4208\n",
      "Validation loss improved from 2.4215 to 2.4208. Saving model...\n",
      "\n",
      "LOG: Epoch [1037/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7261\n",
      "Epoch [1037/2000], Avg Train Loss: 3.7261\n",
      "Epoch [1037/2000], Avg Val Loss: 2.4201\n",
      "Validation loss improved from 2.4208 to 2.4201. Saving model...\n",
      "\n",
      "LOG: Epoch [1038/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7778\n",
      "Epoch [1038/2000], Avg Train Loss: 3.7778\n",
      "Epoch [1038/2000], Avg Val Loss: 2.4195\n",
      "Validation loss improved from 2.4201 to 2.4195. Saving model...\n",
      "\n",
      "LOG: Epoch [1039/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7593\n",
      "Epoch [1039/2000], Avg Train Loss: 3.7593\n",
      "Epoch [1039/2000], Avg Val Loss: 2.4189\n",
      "Validation loss improved from 2.4195 to 2.4189. Saving model...\n",
      "\n",
      "LOG: Epoch [1040/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7394\n",
      "Epoch [1040/2000], Avg Train Loss: 3.7394\n",
      "Epoch [1040/2000], Avg Val Loss: 2.4184\n",
      "Validation loss improved from 2.4189 to 2.4184. Saving model...\n",
      "\n",
      "LOG: Epoch [1041/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7404\n",
      "Epoch [1041/2000], Avg Train Loss: 3.7404\n",
      "Epoch [1041/2000], Avg Val Loss: 2.4180\n",
      "Validation loss improved from 2.4184 to 2.4180. Saving model...\n",
      "\n",
      "LOG: Epoch [1042/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6984\n",
      "Epoch [1042/2000], Avg Train Loss: 3.6984\n",
      "Epoch [1042/2000], Avg Val Loss: 2.4175\n",
      "Validation loss improved from 2.4180 to 2.4175. Saving model...\n",
      "\n",
      "LOG: Epoch [1043/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7244\n",
      "Epoch [1043/2000], Avg Train Loss: 3.7244\n",
      "Epoch [1043/2000], Avg Val Loss: 2.4171\n",
      "Validation loss improved from 2.4175 to 2.4171. Saving model...\n",
      "\n",
      "LOG: Epoch [1044/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7374\n",
      "Epoch [1044/2000], Avg Train Loss: 3.7374\n",
      "Epoch [1044/2000], Avg Val Loss: 2.4167\n",
      "Validation loss improved from 2.4171 to 2.4167. Saving model...\n",
      "\n",
      "LOG: Epoch [1045/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7490\n",
      "Epoch [1045/2000], Avg Train Loss: 3.7490\n",
      "Epoch [1045/2000], Avg Val Loss: 2.4162\n",
      "Validation loss improved from 2.4167 to 2.4162. Saving model...\n",
      "\n",
      "LOG: Epoch [1046/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7243\n",
      "Epoch [1046/2000], Avg Train Loss: 3.7243\n",
      "Epoch [1046/2000], Avg Val Loss: 2.4157\n",
      "Validation loss improved from 2.4162 to 2.4157. Saving model...\n",
      "\n",
      "LOG: Epoch [1047/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7181\n",
      "Epoch [1047/2000], Avg Train Loss: 3.7181\n",
      "Epoch [1047/2000], Avg Val Loss: 2.4153\n",
      "Validation loss improved from 2.4157 to 2.4153. Saving model...\n",
      "\n",
      "LOG: Epoch [1048/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7625\n",
      "Epoch [1048/2000], Avg Train Loss: 3.7625\n",
      "Epoch [1048/2000], Avg Val Loss: 2.4149\n",
      "Validation loss improved from 2.4153 to 2.4149. Saving model...\n",
      "\n",
      "LOG: Epoch [1049/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7124\n",
      "Epoch [1049/2000], Avg Train Loss: 3.7124\n",
      "Epoch [1049/2000], Avg Val Loss: 2.4146\n",
      "Validation loss improved from 2.4149 to 2.4146. Saving model...\n",
      "\n",
      "LOG: Epoch [1050/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7340\n",
      "Epoch [1050/2000], Avg Train Loss: 3.7340\n",
      "Epoch [1050/2000], Avg Val Loss: 2.4142\n",
      "Validation loss improved from 2.4146 to 2.4142. Saving model...\n",
      "\n",
      "LOG: Epoch [1051/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7425\n",
      "Epoch [1051/2000], Avg Train Loss: 3.7425\n",
      "Epoch [1051/2000], Avg Val Loss: 2.4137\n",
      "Validation loss improved from 2.4142 to 2.4137. Saving model...\n",
      "\n",
      "LOG: Epoch [1052/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7228\n",
      "Epoch [1052/2000], Avg Train Loss: 3.7228\n",
      "Epoch [1052/2000], Avg Val Loss: 2.4132\n",
      "Validation loss improved from 2.4137 to 2.4132. Saving model...\n",
      "\n",
      "LOG: Epoch [1053/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7276\n",
      "Epoch [1053/2000], Avg Train Loss: 3.7276\n",
      "Epoch [1053/2000], Avg Val Loss: 2.4127\n",
      "Validation loss improved from 2.4132 to 2.4127. Saving model...\n",
      "\n",
      "LOG: Epoch [1054/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7235\n",
      "Epoch [1054/2000], Avg Train Loss: 3.7235\n",
      "Epoch [1054/2000], Avg Val Loss: 2.4120\n",
      "Validation loss improved from 2.4127 to 2.4120. Saving model...\n",
      "\n",
      "LOG: Epoch [1055/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7239\n",
      "Epoch [1055/2000], Avg Train Loss: 3.7239\n",
      "Epoch [1055/2000], Avg Val Loss: 2.4114\n",
      "Validation loss improved from 2.4120 to 2.4114. Saving model...\n",
      "\n",
      "LOG: Epoch [1056/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7265\n",
      "Epoch [1056/2000], Avg Train Loss: 3.7265\n",
      "Epoch [1056/2000], Avg Val Loss: 2.4108\n",
      "Validation loss improved from 2.4114 to 2.4108. Saving model...\n",
      "\n",
      "LOG: Epoch [1057/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7277\n",
      "Epoch [1057/2000], Avg Train Loss: 3.7277\n",
      "Epoch [1057/2000], Avg Val Loss: 2.4102\n",
      "Validation loss improved from 2.4108 to 2.4102. Saving model...\n",
      "\n",
      "LOG: Epoch [1058/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7221\n",
      "Epoch [1058/2000], Avg Train Loss: 3.7221\n",
      "Epoch [1058/2000], Avg Val Loss: 2.4097\n",
      "Validation loss improved from 2.4102 to 2.4097. Saving model...\n",
      "\n",
      "LOG: Epoch [1059/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7098\n",
      "Epoch [1059/2000], Avg Train Loss: 3.7098\n",
      "Epoch [1059/2000], Avg Val Loss: 2.4092\n",
      "Validation loss improved from 2.4097 to 2.4092. Saving model...\n",
      "\n",
      "LOG: Epoch [1060/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7541\n",
      "Epoch [1060/2000], Avg Train Loss: 3.7541\n",
      "Epoch [1060/2000], Avg Val Loss: 2.4087\n",
      "Validation loss improved from 2.4092 to 2.4087. Saving model...\n",
      "\n",
      "LOG: Epoch [1061/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7128\n",
      "Epoch [1061/2000], Avg Train Loss: 3.7128\n",
      "Epoch [1061/2000], Avg Val Loss: 2.4083\n",
      "Validation loss improved from 2.4087 to 2.4083. Saving model...\n",
      "\n",
      "LOG: Epoch [1062/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6877\n",
      "Epoch [1062/2000], Avg Train Loss: 3.6877\n",
      "Epoch [1062/2000], Avg Val Loss: 2.4079\n",
      "Validation loss improved from 2.4083 to 2.4079. Saving model...\n",
      "\n",
      "LOG: Epoch [1063/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7838\n",
      "Epoch [1063/2000], Avg Train Loss: 3.7838\n",
      "Epoch [1063/2000], Avg Val Loss: 2.4075\n",
      "Validation loss improved from 2.4079 to 2.4075. Saving model...\n",
      "\n",
      "LOG: Epoch [1064/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7461\n",
      "Epoch [1064/2000], Avg Train Loss: 3.7461\n",
      "Epoch [1064/2000], Avg Val Loss: 2.4072\n",
      "Validation loss improved from 2.4075 to 2.4072. Saving model...\n",
      "\n",
      "LOG: Epoch [1065/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7302\n",
      "Epoch [1065/2000], Avg Train Loss: 3.7302\n",
      "Epoch [1065/2000], Avg Val Loss: 2.4070\n",
      "Validation loss improved from 2.4072 to 2.4070. Saving model...\n",
      "\n",
      "LOG: Epoch [1066/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7395\n",
      "Epoch [1066/2000], Avg Train Loss: 3.7395\n",
      "Epoch [1066/2000], Avg Val Loss: 2.4066\n",
      "Validation loss improved from 2.4070 to 2.4066. Saving model...\n",
      "\n",
      "LOG: Epoch [1067/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7162\n",
      "Epoch [1067/2000], Avg Train Loss: 3.7162\n",
      "Epoch [1067/2000], Avg Val Loss: 2.4062\n",
      "Validation loss improved from 2.4066 to 2.4062. Saving model...\n",
      "\n",
      "LOG: Epoch [1068/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7376\n",
      "Epoch [1068/2000], Avg Train Loss: 3.7376\n",
      "Epoch [1068/2000], Avg Val Loss: 2.4059\n",
      "Validation loss improved from 2.4062 to 2.4059. Saving model...\n",
      "\n",
      "LOG: Epoch [1069/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6879\n",
      "Epoch [1069/2000], Avg Train Loss: 3.6879\n",
      "Epoch [1069/2000], Avg Val Loss: 2.4055\n",
      "Validation loss improved from 2.4059 to 2.4055. Saving model...\n",
      "\n",
      "LOG: Epoch [1070/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7152\n",
      "Epoch [1070/2000], Avg Train Loss: 3.7152\n",
      "Epoch [1070/2000], Avg Val Loss: 2.4050\n",
      "Validation loss improved from 2.4055 to 2.4050. Saving model...\n",
      "\n",
      "LOG: Epoch [1071/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6729\n",
      "Epoch [1071/2000], Avg Train Loss: 3.6729\n",
      "Epoch [1071/2000], Avg Val Loss: 2.4046\n",
      "Validation loss improved from 2.4050 to 2.4046. Saving model...\n",
      "\n",
      "LOG: Epoch [1072/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7367\n",
      "Epoch [1072/2000], Avg Train Loss: 3.7367\n",
      "Epoch [1072/2000], Avg Val Loss: 2.4042\n",
      "Validation loss improved from 2.4046 to 2.4042. Saving model...\n",
      "\n",
      "LOG: Epoch [1073/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6938\n",
      "Epoch [1073/2000], Avg Train Loss: 3.6938\n",
      "Epoch [1073/2000], Avg Val Loss: 2.4039\n",
      "Validation loss improved from 2.4042 to 2.4039. Saving model...\n",
      "\n",
      "LOG: Epoch [1074/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6986\n",
      "Epoch [1074/2000], Avg Train Loss: 3.6986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1074/2000], Avg Val Loss: 2.4037\n",
      "Validation loss improved from 2.4039 to 2.4037. Saving model...\n",
      "\n",
      "LOG: Epoch [1075/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7494\n",
      "Epoch [1075/2000], Avg Train Loss: 3.7494\n",
      "Epoch [1075/2000], Avg Val Loss: 2.4036\n",
      "Validation loss improved from 2.4037 to 2.4036. Saving model...\n",
      "\n",
      "LOG: Epoch [1076/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7158\n",
      "Epoch [1076/2000], Avg Train Loss: 3.7158\n",
      "Epoch [1076/2000], Avg Val Loss: 2.4033\n",
      "Validation loss improved from 2.4036 to 2.4033. Saving model...\n",
      "\n",
      "LOG: Epoch [1077/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6649\n",
      "Epoch [1077/2000], Avg Train Loss: 3.6649\n",
      "Epoch [1077/2000], Avg Val Loss: 2.4028\n",
      "Validation loss improved from 2.4033 to 2.4028. Saving model...\n",
      "\n",
      "LOG: Epoch [1078/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7152\n",
      "Epoch [1078/2000], Avg Train Loss: 3.7152\n",
      "Epoch [1078/2000], Avg Val Loss: 2.4023\n",
      "Validation loss improved from 2.4028 to 2.4023. Saving model...\n",
      "\n",
      "LOG: Epoch [1079/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7040\n",
      "Epoch [1079/2000], Avg Train Loss: 3.7040\n",
      "Epoch [1079/2000], Avg Val Loss: 2.4018\n",
      "Validation loss improved from 2.4023 to 2.4018. Saving model...\n",
      "\n",
      "LOG: Epoch [1080/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6898\n",
      "Epoch [1080/2000], Avg Train Loss: 3.6898\n",
      "Epoch [1080/2000], Avg Val Loss: 2.4012\n",
      "Validation loss improved from 2.4018 to 2.4012. Saving model...\n",
      "\n",
      "LOG: Epoch [1081/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6856\n",
      "Epoch [1081/2000], Avg Train Loss: 3.6856\n",
      "Epoch [1081/2000], Avg Val Loss: 2.4004\n",
      "Validation loss improved from 2.4012 to 2.4004. Saving model...\n",
      "\n",
      "LOG: Epoch [1082/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7020\n",
      "Epoch [1082/2000], Avg Train Loss: 3.7020\n",
      "Epoch [1082/2000], Avg Val Loss: 2.3998\n",
      "Validation loss improved from 2.4004 to 2.3998. Saving model...\n",
      "\n",
      "LOG: Epoch [1083/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7162\n",
      "Epoch [1083/2000], Avg Train Loss: 3.7162\n",
      "Epoch [1083/2000], Avg Val Loss: 2.3992\n",
      "Validation loss improved from 2.3998 to 2.3992. Saving model...\n",
      "\n",
      "LOG: Epoch [1084/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6774\n",
      "Epoch [1084/2000], Avg Train Loss: 3.6774\n",
      "Epoch [1084/2000], Avg Val Loss: 2.3986\n",
      "Validation loss improved from 2.3992 to 2.3986. Saving model...\n",
      "\n",
      "LOG: Epoch [1085/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7346\n",
      "Epoch [1085/2000], Avg Train Loss: 3.7346\n",
      "Epoch [1085/2000], Avg Val Loss: 2.3980\n",
      "Validation loss improved from 2.3986 to 2.3980. Saving model...\n",
      "\n",
      "LOG: Epoch [1086/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6673\n",
      "Epoch [1086/2000], Avg Train Loss: 3.6673\n",
      "Epoch [1086/2000], Avg Val Loss: 2.3974\n",
      "Validation loss improved from 2.3980 to 2.3974. Saving model...\n",
      "\n",
      "LOG: Epoch [1087/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6706\n",
      "Epoch [1087/2000], Avg Train Loss: 3.6706\n",
      "Epoch [1087/2000], Avg Val Loss: 2.3969\n",
      "Validation loss improved from 2.3974 to 2.3969. Saving model...\n",
      "\n",
      "LOG: Epoch [1088/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7167\n",
      "Epoch [1088/2000], Avg Train Loss: 3.7167\n",
      "Epoch [1088/2000], Avg Val Loss: 2.3966\n",
      "Validation loss improved from 2.3969 to 2.3966. Saving model...\n",
      "\n",
      "LOG: Epoch [1089/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7096\n",
      "Epoch [1089/2000], Avg Train Loss: 3.7096\n",
      "Epoch [1089/2000], Avg Val Loss: 2.3965\n",
      "Validation loss improved from 2.3966 to 2.3965. Saving model...\n",
      "\n",
      "LOG: Epoch [1090/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6560\n",
      "Epoch [1090/2000], Avg Train Loss: 3.6560\n",
      "Epoch [1090/2000], Avg Val Loss: 2.3963\n",
      "Validation loss improved from 2.3965 to 2.3963. Saving model...\n",
      "\n",
      "LOG: Epoch [1091/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7247\n",
      "Epoch [1091/2000], Avg Train Loss: 3.7247\n",
      "Epoch [1091/2000], Avg Val Loss: 2.3962\n",
      "Validation loss improved from 2.3963 to 2.3962. Saving model...\n",
      "\n",
      "LOG: Epoch [1092/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7520\n",
      "Epoch [1092/2000], Avg Train Loss: 3.7520\n",
      "Epoch [1092/2000], Avg Val Loss: 2.3963\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1093/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7003\n",
      "Epoch [1093/2000], Avg Train Loss: 3.7003\n",
      "Epoch [1093/2000], Avg Val Loss: 2.3963\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1094/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7178\n",
      "Epoch [1094/2000], Avg Train Loss: 3.7178\n",
      "Epoch [1094/2000], Avg Val Loss: 2.3963\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1095/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6696\n",
      "Epoch [1095/2000], Avg Train Loss: 3.6696\n",
      "Epoch [1095/2000], Avg Val Loss: 2.3962\n",
      "Validation loss improved from 2.3962 to 2.3962. Saving model...\n",
      "\n",
      "LOG: Epoch [1096/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7336\n",
      "Epoch [1096/2000], Avg Train Loss: 3.7336\n",
      "Epoch [1096/2000], Avg Val Loss: 2.3962\n",
      "Validation loss improved from 2.3962 to 2.3962. Saving model...\n",
      "\n",
      "LOG: Epoch [1097/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7427\n",
      "Epoch [1097/2000], Avg Train Loss: 3.7427\n",
      "Epoch [1097/2000], Avg Val Loss: 2.3961\n",
      "Validation loss improved from 2.3962 to 2.3961. Saving model...\n",
      "\n",
      "LOG: Epoch [1098/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6915\n",
      "Epoch [1098/2000], Avg Train Loss: 3.6915\n",
      "Epoch [1098/2000], Avg Val Loss: 2.3959\n",
      "Validation loss improved from 2.3961 to 2.3959. Saving model...\n",
      "\n",
      "LOG: Epoch [1099/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6821\n",
      "Epoch [1099/2000], Avg Train Loss: 3.6821\n",
      "Epoch [1099/2000], Avg Val Loss: 2.3956\n",
      "Validation loss improved from 2.3959 to 2.3956. Saving model...\n",
      "\n",
      "LOG: Epoch [1100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7250\n",
      "Epoch [1100/2000], Avg Train Loss: 3.7250\n",
      "Epoch [1100/2000], Avg Val Loss: 2.3953\n",
      "Validation loss improved from 2.3956 to 2.3953. Saving model...\n",
      "\n",
      "LOG: Epoch [1101/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7024\n",
      "Epoch [1101/2000], Avg Train Loss: 3.7024\n",
      "Epoch [1101/2000], Avg Val Loss: 2.3950\n",
      "Validation loss improved from 2.3953 to 2.3950. Saving model...\n",
      "\n",
      "LOG: Epoch [1102/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7014\n",
      "Epoch [1102/2000], Avg Train Loss: 3.7014\n",
      "Epoch [1102/2000], Avg Val Loss: 2.3946\n",
      "Validation loss improved from 2.3950 to 2.3946. Saving model...\n",
      "\n",
      "LOG: Epoch [1103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7101\n",
      "Epoch [1103/2000], Avg Train Loss: 3.7101\n",
      "Epoch [1103/2000], Avg Val Loss: 2.3942\n",
      "Validation loss improved from 2.3946 to 2.3942. Saving model...\n",
      "\n",
      "LOG: Epoch [1104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6378\n",
      "Epoch [1104/2000], Avg Train Loss: 3.6378\n",
      "Epoch [1104/2000], Avg Val Loss: 2.3938\n",
      "Validation loss improved from 2.3942 to 2.3938. Saving model...\n",
      "\n",
      "LOG: Epoch [1105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7336\n",
      "Epoch [1105/2000], Avg Train Loss: 3.7336\n",
      "Epoch [1105/2000], Avg Val Loss: 2.3934\n",
      "Validation loss improved from 2.3938 to 2.3934. Saving model...\n",
      "\n",
      "LOG: Epoch [1106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7244\n",
      "Epoch [1106/2000], Avg Train Loss: 3.7244\n",
      "Epoch [1106/2000], Avg Val Loss: 2.3931\n",
      "Validation loss improved from 2.3934 to 2.3931. Saving model...\n",
      "\n",
      "LOG: Epoch [1107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6788\n",
      "Epoch [1107/2000], Avg Train Loss: 3.6788\n",
      "Epoch [1107/2000], Avg Val Loss: 2.3929\n",
      "Validation loss improved from 2.3931 to 2.3929. Saving model...\n",
      "\n",
      "LOG: Epoch [1108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6799\n",
      "Epoch [1108/2000], Avg Train Loss: 3.6799\n",
      "Epoch [1108/2000], Avg Val Loss: 2.3926\n",
      "Validation loss improved from 2.3929 to 2.3926. Saving model...\n",
      "\n",
      "LOG: Epoch [1109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6929\n",
      "Epoch [1109/2000], Avg Train Loss: 3.6929\n",
      "Epoch [1109/2000], Avg Val Loss: 2.3923\n",
      "Validation loss improved from 2.3926 to 2.3923. Saving model...\n",
      "\n",
      "LOG: Epoch [1110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7150\n",
      "Epoch [1110/2000], Avg Train Loss: 3.7150\n",
      "Epoch [1110/2000], Avg Val Loss: 2.3920\n",
      "Validation loss improved from 2.3923 to 2.3920. Saving model...\n",
      "\n",
      "LOG: Epoch [1111/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6849\n",
      "Epoch [1111/2000], Avg Train Loss: 3.6849\n",
      "Epoch [1111/2000], Avg Val Loss: 2.3916\n",
      "Validation loss improved from 2.3920 to 2.3916. Saving model...\n",
      "\n",
      "LOG: Epoch [1112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7388\n",
      "Epoch [1112/2000], Avg Train Loss: 3.7388\n",
      "Epoch [1112/2000], Avg Val Loss: 2.3912\n",
      "Validation loss improved from 2.3916 to 2.3912. Saving model...\n",
      "\n",
      "LOG: Epoch [1113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7087\n",
      "Epoch [1113/2000], Avg Train Loss: 3.7087\n",
      "Epoch [1113/2000], Avg Val Loss: 2.3909\n",
      "Validation loss improved from 2.3912 to 2.3909. Saving model...\n",
      "\n",
      "LOG: Epoch [1114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6874\n",
      "Epoch [1114/2000], Avg Train Loss: 3.6874\n",
      "Epoch [1114/2000], Avg Val Loss: 2.3905\n",
      "Validation loss improved from 2.3909 to 2.3905. Saving model...\n",
      "\n",
      "LOG: Epoch [1115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6787\n",
      "Epoch [1115/2000], Avg Train Loss: 3.6787\n",
      "Epoch [1115/2000], Avg Val Loss: 2.3902\n",
      "Validation loss improved from 2.3905 to 2.3902. Saving model...\n",
      "\n",
      "LOG: Epoch [1116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6414\n",
      "Epoch [1116/2000], Avg Train Loss: 3.6414\n",
      "Epoch [1116/2000], Avg Val Loss: 2.3898\n",
      "Validation loss improved from 2.3902 to 2.3898. Saving model...\n",
      "\n",
      "LOG: Epoch [1117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7077\n",
      "Epoch [1117/2000], Avg Train Loss: 3.7077\n",
      "Epoch [1117/2000], Avg Val Loss: 2.3896\n",
      "Validation loss improved from 2.3898 to 2.3896. Saving model...\n",
      "\n",
      "LOG: Epoch [1118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6872\n",
      "Epoch [1118/2000], Avg Train Loss: 3.6872\n",
      "Epoch [1118/2000], Avg Val Loss: 2.3894\n",
      "Validation loss improved from 2.3896 to 2.3894. Saving model...\n",
      "\n",
      "LOG: Epoch [1119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6706\n",
      "Epoch [1119/2000], Avg Train Loss: 3.6706\n",
      "Epoch [1119/2000], Avg Val Loss: 2.3891\n",
      "Validation loss improved from 2.3894 to 2.3891. Saving model...\n",
      "\n",
      "LOG: Epoch [1120/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6809\n",
      "Epoch [1120/2000], Avg Train Loss: 3.6809\n",
      "Epoch [1120/2000], Avg Val Loss: 2.3888\n",
      "Validation loss improved from 2.3891 to 2.3888. Saving model...\n",
      "\n",
      "LOG: Epoch [1121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6505\n",
      "Epoch [1121/2000], Avg Train Loss: 3.6505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1121/2000], Avg Val Loss: 2.3885\n",
      "Validation loss improved from 2.3888 to 2.3885. Saving model...\n",
      "\n",
      "LOG: Epoch [1122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6360\n",
      "Epoch [1122/2000], Avg Train Loss: 3.6360\n",
      "Epoch [1122/2000], Avg Val Loss: 2.3881\n",
      "Validation loss improved from 2.3885 to 2.3881. Saving model...\n",
      "\n",
      "LOG: Epoch [1123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6392\n",
      "Epoch [1123/2000], Avg Train Loss: 3.6392\n",
      "Epoch [1123/2000], Avg Val Loss: 2.3877\n",
      "Validation loss improved from 2.3881 to 2.3877. Saving model...\n",
      "\n",
      "LOG: Epoch [1124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6999\n",
      "Epoch [1124/2000], Avg Train Loss: 3.6999\n",
      "Epoch [1124/2000], Avg Val Loss: 2.3873\n",
      "Validation loss improved from 2.3877 to 2.3873. Saving model...\n",
      "\n",
      "LOG: Epoch [1125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7503\n",
      "Epoch [1125/2000], Avg Train Loss: 3.7503\n",
      "Epoch [1125/2000], Avg Val Loss: 2.3869\n",
      "Validation loss improved from 2.3873 to 2.3869. Saving model...\n",
      "\n",
      "LOG: Epoch [1126/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6557\n",
      "Epoch [1126/2000], Avg Train Loss: 3.6557\n",
      "Epoch [1126/2000], Avg Val Loss: 2.3865\n",
      "Validation loss improved from 2.3869 to 2.3865. Saving model...\n",
      "\n",
      "LOG: Epoch [1127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7063\n",
      "Epoch [1127/2000], Avg Train Loss: 3.7063\n",
      "Epoch [1127/2000], Avg Val Loss: 2.3861\n",
      "Validation loss improved from 2.3865 to 2.3861. Saving model...\n",
      "\n",
      "LOG: Epoch [1128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6843\n",
      "Epoch [1128/2000], Avg Train Loss: 3.6843\n",
      "Epoch [1128/2000], Avg Val Loss: 2.3858\n",
      "Validation loss improved from 2.3861 to 2.3858. Saving model...\n",
      "\n",
      "LOG: Epoch [1129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6418\n",
      "Epoch [1129/2000], Avg Train Loss: 3.6418\n",
      "Epoch [1129/2000], Avg Val Loss: 2.3856\n",
      "Validation loss improved from 2.3858 to 2.3856. Saving model...\n",
      "\n",
      "LOG: Epoch [1130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7148\n",
      "Epoch [1130/2000], Avg Train Loss: 3.7148\n",
      "Epoch [1130/2000], Avg Val Loss: 2.3854\n",
      "Validation loss improved from 2.3856 to 2.3854. Saving model...\n",
      "\n",
      "LOG: Epoch [1131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6816\n",
      "Epoch [1131/2000], Avg Train Loss: 3.6816\n",
      "Epoch [1131/2000], Avg Val Loss: 2.3852\n",
      "Validation loss improved from 2.3854 to 2.3852. Saving model...\n",
      "\n",
      "LOG: Epoch [1132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6541\n",
      "Epoch [1132/2000], Avg Train Loss: 3.6541\n",
      "Epoch [1132/2000], Avg Val Loss: 2.3848\n",
      "Validation loss improved from 2.3852 to 2.3848. Saving model...\n",
      "\n",
      "LOG: Epoch [1133/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6739\n",
      "Epoch [1133/2000], Avg Train Loss: 3.6739\n",
      "Epoch [1133/2000], Avg Val Loss: 2.3845\n",
      "Validation loss improved from 2.3848 to 2.3845. Saving model...\n",
      "\n",
      "LOG: Epoch [1134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6822\n",
      "Epoch [1134/2000], Avg Train Loss: 3.6822\n",
      "Epoch [1134/2000], Avg Val Loss: 2.3843\n",
      "Validation loss improved from 2.3845 to 2.3843. Saving model...\n",
      "\n",
      "LOG: Epoch [1135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6575\n",
      "Epoch [1135/2000], Avg Train Loss: 3.6575\n",
      "Epoch [1135/2000], Avg Val Loss: 2.3841\n",
      "Validation loss improved from 2.3843 to 2.3841. Saving model...\n",
      "\n",
      "LOG: Epoch [1136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6746\n",
      "Epoch [1136/2000], Avg Train Loss: 3.6746\n",
      "Epoch [1136/2000], Avg Val Loss: 2.3839\n",
      "Validation loss improved from 2.3841 to 2.3839. Saving model...\n",
      "\n",
      "LOG: Epoch [1137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6710\n",
      "Epoch [1137/2000], Avg Train Loss: 3.6710\n",
      "Epoch [1137/2000], Avg Val Loss: 2.3837\n",
      "Validation loss improved from 2.3839 to 2.3837. Saving model...\n",
      "\n",
      "LOG: Epoch [1138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6334\n",
      "Epoch [1138/2000], Avg Train Loss: 3.6334\n",
      "Epoch [1138/2000], Avg Val Loss: 2.3835\n",
      "Validation loss improved from 2.3837 to 2.3835. Saving model...\n",
      "\n",
      "LOG: Epoch [1139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6658\n",
      "Epoch [1139/2000], Avg Train Loss: 3.6658\n",
      "Epoch [1139/2000], Avg Val Loss: 2.3832\n",
      "Validation loss improved from 2.3835 to 2.3832. Saving model...\n",
      "\n",
      "LOG: Epoch [1140/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7043\n",
      "Epoch [1140/2000], Avg Train Loss: 3.7043\n",
      "Epoch [1140/2000], Avg Val Loss: 2.3829\n",
      "Validation loss improved from 2.3832 to 2.3829. Saving model...\n",
      "\n",
      "LOG: Epoch [1141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6623\n",
      "Epoch [1141/2000], Avg Train Loss: 3.6623\n",
      "Epoch [1141/2000], Avg Val Loss: 2.3827\n",
      "Validation loss improved from 2.3829 to 2.3827. Saving model...\n",
      "\n",
      "LOG: Epoch [1142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6504\n",
      "Epoch [1142/2000], Avg Train Loss: 3.6504\n",
      "Epoch [1142/2000], Avg Val Loss: 2.3825\n",
      "Validation loss improved from 2.3827 to 2.3825. Saving model...\n",
      "\n",
      "LOG: Epoch [1143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6872\n",
      "Epoch [1143/2000], Avg Train Loss: 3.6872\n",
      "Epoch [1143/2000], Avg Val Loss: 2.3821\n",
      "Validation loss improved from 2.3825 to 2.3821. Saving model...\n",
      "\n",
      "LOG: Epoch [1144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6609\n",
      "Epoch [1144/2000], Avg Train Loss: 3.6609\n",
      "Epoch [1144/2000], Avg Val Loss: 2.3817\n",
      "Validation loss improved from 2.3821 to 2.3817. Saving model...\n",
      "\n",
      "LOG: Epoch [1145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6818\n",
      "Epoch [1145/2000], Avg Train Loss: 3.6818\n",
      "Epoch [1145/2000], Avg Val Loss: 2.3813\n",
      "Validation loss improved from 2.3817 to 2.3813. Saving model...\n",
      "\n",
      "LOG: Epoch [1146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6639\n",
      "Epoch [1146/2000], Avg Train Loss: 3.6639\n",
      "Epoch [1146/2000], Avg Val Loss: 2.3809\n",
      "Validation loss improved from 2.3813 to 2.3809. Saving model...\n",
      "\n",
      "LOG: Epoch [1147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6592\n",
      "Epoch [1147/2000], Avg Train Loss: 3.6592\n",
      "Epoch [1147/2000], Avg Val Loss: 2.3804\n",
      "Validation loss improved from 2.3809 to 2.3804. Saving model...\n",
      "\n",
      "LOG: Epoch [1148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6759\n",
      "Epoch [1148/2000], Avg Train Loss: 3.6759\n",
      "Epoch [1148/2000], Avg Val Loss: 2.3798\n",
      "Validation loss improved from 2.3804 to 2.3798. Saving model...\n",
      "\n",
      "LOG: Epoch [1149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6964\n",
      "Epoch [1149/2000], Avg Train Loss: 3.6964\n",
      "Epoch [1149/2000], Avg Val Loss: 2.3793\n",
      "Validation loss improved from 2.3798 to 2.3793. Saving model...\n",
      "\n",
      "LOG: Epoch [1150/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6547\n",
      "Epoch [1150/2000], Avg Train Loss: 3.6547\n",
      "Epoch [1150/2000], Avg Val Loss: 2.3789\n",
      "Validation loss improved from 2.3793 to 2.3789. Saving model...\n",
      "\n",
      "LOG: Epoch [1151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6650\n",
      "Epoch [1151/2000], Avg Train Loss: 3.6650\n",
      "Epoch [1151/2000], Avg Val Loss: 2.3786\n",
      "Validation loss improved from 2.3789 to 2.3786. Saving model...\n",
      "\n",
      "LOG: Epoch [1152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6658\n",
      "Epoch [1152/2000], Avg Train Loss: 3.6658\n",
      "Epoch [1152/2000], Avg Val Loss: 2.3783\n",
      "Validation loss improved from 2.3786 to 2.3783. Saving model...\n",
      "\n",
      "LOG: Epoch [1153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6530\n",
      "Epoch [1153/2000], Avg Train Loss: 3.6530\n",
      "Epoch [1153/2000], Avg Val Loss: 2.3780\n",
      "Validation loss improved from 2.3783 to 2.3780. Saving model...\n",
      "\n",
      "LOG: Epoch [1154/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6439\n",
      "Epoch [1154/2000], Avg Train Loss: 3.6439\n",
      "Epoch [1154/2000], Avg Val Loss: 2.3777\n",
      "Validation loss improved from 2.3780 to 2.3777. Saving model...\n",
      "\n",
      "LOG: Epoch [1155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6507\n",
      "Epoch [1155/2000], Avg Train Loss: 3.6507\n",
      "Epoch [1155/2000], Avg Val Loss: 2.3774\n",
      "Validation loss improved from 2.3777 to 2.3774. Saving model...\n",
      "\n",
      "LOG: Epoch [1156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6963\n",
      "Epoch [1156/2000], Avg Train Loss: 3.6963\n",
      "Epoch [1156/2000], Avg Val Loss: 2.3771\n",
      "Validation loss improved from 2.3774 to 2.3771. Saving model...\n",
      "\n",
      "LOG: Epoch [1157/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6790\n",
      "Epoch [1157/2000], Avg Train Loss: 3.6790\n",
      "Epoch [1157/2000], Avg Val Loss: 2.3769\n",
      "Validation loss improved from 2.3771 to 2.3769. Saving model...\n",
      "\n",
      "LOG: Epoch [1158/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6658\n",
      "Epoch [1158/2000], Avg Train Loss: 3.6658\n",
      "Epoch [1158/2000], Avg Val Loss: 2.3767\n",
      "Validation loss improved from 2.3769 to 2.3767. Saving model...\n",
      "\n",
      "LOG: Epoch [1159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6343\n",
      "Epoch [1159/2000], Avg Train Loss: 3.6343\n",
      "Epoch [1159/2000], Avg Val Loss: 2.3763\n",
      "Validation loss improved from 2.3767 to 2.3763. Saving model...\n",
      "\n",
      "LOG: Epoch [1160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7060\n",
      "Epoch [1160/2000], Avg Train Loss: 3.7060\n",
      "Epoch [1160/2000], Avg Val Loss: 2.3760\n",
      "Validation loss improved from 2.3763 to 2.3760. Saving model...\n",
      "\n",
      "LOG: Epoch [1161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6810\n",
      "Epoch [1161/2000], Avg Train Loss: 3.6810\n",
      "Epoch [1161/2000], Avg Val Loss: 2.3757\n",
      "Validation loss improved from 2.3760 to 2.3757. Saving model...\n",
      "\n",
      "LOG: Epoch [1162/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6661\n",
      "Epoch [1162/2000], Avg Train Loss: 3.6661\n",
      "Epoch [1162/2000], Avg Val Loss: 2.3755\n",
      "Validation loss improved from 2.3757 to 2.3755. Saving model...\n",
      "\n",
      "LOG: Epoch [1163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6398\n",
      "Epoch [1163/2000], Avg Train Loss: 3.6398\n",
      "Epoch [1163/2000], Avg Val Loss: 2.3752\n",
      "Validation loss improved from 2.3755 to 2.3752. Saving model...\n",
      "\n",
      "LOG: Epoch [1164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6529\n",
      "Epoch [1164/2000], Avg Train Loss: 3.6529\n",
      "Epoch [1164/2000], Avg Val Loss: 2.3748\n",
      "Validation loss improved from 2.3752 to 2.3748. Saving model...\n",
      "\n",
      "LOG: Epoch [1165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6597\n",
      "Epoch [1165/2000], Avg Train Loss: 3.6597\n",
      "Epoch [1165/2000], Avg Val Loss: 2.3745\n",
      "Validation loss improved from 2.3748 to 2.3745. Saving model...\n",
      "\n",
      "LOG: Epoch [1166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6698\n",
      "Epoch [1166/2000], Avg Train Loss: 3.6698\n",
      "Epoch [1166/2000], Avg Val Loss: 2.3741\n",
      "Validation loss improved from 2.3745 to 2.3741. Saving model...\n",
      "\n",
      "LOG: Epoch [1167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6586\n",
      "Epoch [1167/2000], Avg Train Loss: 3.6586\n",
      "Epoch [1167/2000], Avg Val Loss: 2.3737\n",
      "Validation loss improved from 2.3741 to 2.3737. Saving model...\n",
      "\n",
      "LOG: Epoch [1168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6885\n",
      "Epoch [1168/2000], Avg Train Loss: 3.6885\n",
      "Epoch [1168/2000], Avg Val Loss: 2.3733\n",
      "Validation loss improved from 2.3737 to 2.3733. Saving model...\n",
      "\n",
      "LOG: Epoch [1169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6521\n",
      "Epoch [1169/2000], Avg Train Loss: 3.6521\n",
      "Epoch [1169/2000], Avg Val Loss: 2.3728\n",
      "Validation loss improved from 2.3733 to 2.3728. Saving model...\n",
      "\n",
      "LOG: Epoch [1170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6185\n",
      "Epoch [1170/2000], Avg Train Loss: 3.6185\n",
      "Epoch [1170/2000], Avg Val Loss: 2.3724\n",
      "Validation loss improved from 2.3728 to 2.3724. Saving model...\n",
      "\n",
      "LOG: Epoch [1171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6459\n",
      "Epoch [1171/2000], Avg Train Loss: 3.6459\n",
      "Epoch [1171/2000], Avg Val Loss: 2.3718\n",
      "Validation loss improved from 2.3724 to 2.3718. Saving model...\n",
      "\n",
      "LOG: Epoch [1172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6292\n",
      "Epoch [1172/2000], Avg Train Loss: 3.6292\n",
      "Epoch [1172/2000], Avg Val Loss: 2.3714\n",
      "Validation loss improved from 2.3718 to 2.3714. Saving model...\n",
      "\n",
      "LOG: Epoch [1173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6266\n",
      "Epoch [1173/2000], Avg Train Loss: 3.6266\n",
      "Epoch [1173/2000], Avg Val Loss: 2.3710\n",
      "Validation loss improved from 2.3714 to 2.3710. Saving model...\n",
      "\n",
      "LOG: Epoch [1174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6602\n",
      "Epoch [1174/2000], Avg Train Loss: 3.6602\n",
      "Epoch [1174/2000], Avg Val Loss: 2.3707\n",
      "Validation loss improved from 2.3710 to 2.3707. Saving model...\n",
      "\n",
      "LOG: Epoch [1175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6095\n",
      "Epoch [1175/2000], Avg Train Loss: 3.6095\n",
      "Epoch [1175/2000], Avg Val Loss: 2.3704\n",
      "Validation loss improved from 2.3707 to 2.3704. Saving model...\n",
      "\n",
      "LOG: Epoch [1176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6544\n",
      "Epoch [1176/2000], Avg Train Loss: 3.6544\n",
      "Epoch [1176/2000], Avg Val Loss: 2.3702\n",
      "Validation loss improved from 2.3704 to 2.3702. Saving model...\n",
      "\n",
      "LOG: Epoch [1177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6976\n",
      "Epoch [1177/2000], Avg Train Loss: 3.6976\n",
      "Epoch [1177/2000], Avg Val Loss: 2.3701\n",
      "Validation loss improved from 2.3702 to 2.3701. Saving model...\n",
      "\n",
      "LOG: Epoch [1178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6411\n",
      "Epoch [1178/2000], Avg Train Loss: 3.6411\n",
      "Epoch [1178/2000], Avg Val Loss: 2.3699\n",
      "Validation loss improved from 2.3701 to 2.3699. Saving model...\n",
      "\n",
      "LOG: Epoch [1179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6398\n",
      "Epoch [1179/2000], Avg Train Loss: 3.6398\n",
      "Epoch [1179/2000], Avg Val Loss: 2.3697\n",
      "Validation loss improved from 2.3699 to 2.3697. Saving model...\n",
      "\n",
      "LOG: Epoch [1180/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6266\n",
      "Epoch [1180/2000], Avg Train Loss: 3.6266\n",
      "Epoch [1180/2000], Avg Val Loss: 2.3696\n",
      "Validation loss improved from 2.3697 to 2.3696. Saving model...\n",
      "\n",
      "LOG: Epoch [1181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6385\n",
      "Epoch [1181/2000], Avg Train Loss: 3.6385\n",
      "Epoch [1181/2000], Avg Val Loss: 2.3695\n",
      "Validation loss improved from 2.3696 to 2.3695. Saving model...\n",
      "\n",
      "LOG: Epoch [1182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6422\n",
      "Epoch [1182/2000], Avg Train Loss: 3.6422\n",
      "Epoch [1182/2000], Avg Val Loss: 2.3695\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6247\n",
      "Epoch [1183/2000], Avg Train Loss: 3.6247\n",
      "Epoch [1183/2000], Avg Val Loss: 2.3695\n",
      "Validation loss improved from 2.3695 to 2.3695. Saving model...\n",
      "\n",
      "LOG: Epoch [1184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6358\n",
      "Epoch [1184/2000], Avg Train Loss: 3.6358\n",
      "Epoch [1184/2000], Avg Val Loss: 2.3695\n",
      "Validation loss improved from 2.3695 to 2.3695. Saving model...\n",
      "\n",
      "LOG: Epoch [1185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6357\n",
      "Epoch [1185/2000], Avg Train Loss: 3.6357\n",
      "Epoch [1185/2000], Avg Val Loss: 2.3695\n",
      "Validation loss improved from 2.3695 to 2.3695. Saving model...\n",
      "\n",
      "LOG: Epoch [1186/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6421\n",
      "Epoch [1186/2000], Avg Train Loss: 3.6421\n",
      "Epoch [1186/2000], Avg Val Loss: 2.3693\n",
      "Validation loss improved from 2.3695 to 2.3693. Saving model...\n",
      "\n",
      "LOG: Epoch [1187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6140\n",
      "Epoch [1187/2000], Avg Train Loss: 3.6140\n",
      "Epoch [1187/2000], Avg Val Loss: 2.3693\n",
      "Validation loss improved from 2.3693 to 2.3693. Saving model...\n",
      "\n",
      "LOG: Epoch [1188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6495\n",
      "Epoch [1188/2000], Avg Train Loss: 3.6495\n",
      "Epoch [1188/2000], Avg Val Loss: 2.3690\n",
      "Validation loss improved from 2.3693 to 2.3690. Saving model...\n",
      "\n",
      "LOG: Epoch [1189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6366\n",
      "Epoch [1189/2000], Avg Train Loss: 3.6366\n",
      "Epoch [1189/2000], Avg Val Loss: 2.3686\n",
      "Validation loss improved from 2.3690 to 2.3686. Saving model...\n",
      "\n",
      "LOG: Epoch [1190/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6476\n",
      "Epoch [1190/2000], Avg Train Loss: 3.6476\n",
      "Epoch [1190/2000], Avg Val Loss: 2.3682\n",
      "Validation loss improved from 2.3686 to 2.3682. Saving model...\n",
      "\n",
      "LOG: Epoch [1191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6182\n",
      "Epoch [1191/2000], Avg Train Loss: 3.6182\n",
      "Epoch [1191/2000], Avg Val Loss: 2.3678\n",
      "Validation loss improved from 2.3682 to 2.3678. Saving model...\n",
      "\n",
      "LOG: Epoch [1192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6576\n",
      "Epoch [1192/2000], Avg Train Loss: 3.6576\n",
      "Epoch [1192/2000], Avg Val Loss: 2.3675\n",
      "Validation loss improved from 2.3678 to 2.3675. Saving model...\n",
      "\n",
      "LOG: Epoch [1193/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5901\n",
      "Epoch [1193/2000], Avg Train Loss: 3.5901\n",
      "Epoch [1193/2000], Avg Val Loss: 2.3672\n",
      "Validation loss improved from 2.3675 to 2.3672. Saving model...\n",
      "\n",
      "LOG: Epoch [1194/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7007\n",
      "Epoch [1194/2000], Avg Train Loss: 3.7007\n",
      "Epoch [1194/2000], Avg Val Loss: 2.3670\n",
      "Validation loss improved from 2.3672 to 2.3670. Saving model...\n",
      "\n",
      "LOG: Epoch [1195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6253\n",
      "Epoch [1195/2000], Avg Train Loss: 3.6253\n",
      "Epoch [1195/2000], Avg Val Loss: 2.3668\n",
      "Validation loss improved from 2.3670 to 2.3668. Saving model...\n",
      "\n",
      "LOG: Epoch [1196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6431\n",
      "Epoch [1196/2000], Avg Train Loss: 3.6431\n",
      "Epoch [1196/2000], Avg Val Loss: 2.3665\n",
      "Validation loss improved from 2.3668 to 2.3665. Saving model...\n",
      "\n",
      "LOG: Epoch [1197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6553\n",
      "Epoch [1197/2000], Avg Train Loss: 3.6553\n",
      "Epoch [1197/2000], Avg Val Loss: 2.3663\n",
      "Validation loss improved from 2.3665 to 2.3663. Saving model...\n",
      "\n",
      "LOG: Epoch [1198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6814\n",
      "Epoch [1198/2000], Avg Train Loss: 3.6814\n",
      "Epoch [1198/2000], Avg Val Loss: 2.3660\n",
      "Validation loss improved from 2.3663 to 2.3660. Saving model...\n",
      "\n",
      "LOG: Epoch [1199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6275\n",
      "Epoch [1199/2000], Avg Train Loss: 3.6275\n",
      "Epoch [1199/2000], Avg Val Loss: 2.3657\n",
      "Validation loss improved from 2.3660 to 2.3657. Saving model...\n",
      "\n",
      "LOG: Epoch [1200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6482\n",
      "Epoch [1200/2000], Avg Train Loss: 3.6482\n",
      "Epoch [1200/2000], Avg Val Loss: 2.3656\n",
      "Validation loss improved from 2.3657 to 2.3656. Saving model...\n",
      "\n",
      "LOG: Epoch [1201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6925\n",
      "Epoch [1201/2000], Avg Train Loss: 3.6925\n",
      "Epoch [1201/2000], Avg Val Loss: 2.3652\n",
      "Validation loss improved from 2.3656 to 2.3652. Saving model...\n",
      "\n",
      "LOG: Epoch [1202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6776\n",
      "Epoch [1202/2000], Avg Train Loss: 3.6776\n",
      "Epoch [1202/2000], Avg Val Loss: 2.3647\n",
      "Validation loss improved from 2.3652 to 2.3647. Saving model...\n",
      "\n",
      "LOG: Epoch [1203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6544\n",
      "Epoch [1203/2000], Avg Train Loss: 3.6544\n",
      "Epoch [1203/2000], Avg Val Loss: 2.3641\n",
      "Validation loss improved from 2.3647 to 2.3641. Saving model...\n",
      "\n",
      "LOG: Epoch [1204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6179\n",
      "Epoch [1204/2000], Avg Train Loss: 3.6179\n",
      "Epoch [1204/2000], Avg Val Loss: 2.3635\n",
      "Validation loss improved from 2.3641 to 2.3635. Saving model...\n",
      "\n",
      "LOG: Epoch [1205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6135\n",
      "Epoch [1205/2000], Avg Train Loss: 3.6135\n",
      "Epoch [1205/2000], Avg Val Loss: 2.3630\n",
      "Validation loss improved from 2.3635 to 2.3630. Saving model...\n",
      "\n",
      "LOG: Epoch [1206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6570\n",
      "Epoch [1206/2000], Avg Train Loss: 3.6570\n",
      "Epoch [1206/2000], Avg Val Loss: 2.3626\n",
      "Validation loss improved from 2.3630 to 2.3626. Saving model...\n",
      "\n",
      "LOG: Epoch [1207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6030\n",
      "Epoch [1207/2000], Avg Train Loss: 3.6030\n",
      "Epoch [1207/2000], Avg Val Loss: 2.3622\n",
      "Validation loss improved from 2.3626 to 2.3622. Saving model...\n",
      "\n",
      "LOG: Epoch [1208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6040\n",
      "Epoch [1208/2000], Avg Train Loss: 3.6040\n",
      "Epoch [1208/2000], Avg Val Loss: 2.3619\n",
      "Validation loss improved from 2.3622 to 2.3619. Saving model...\n",
      "\n",
      "LOG: Epoch [1209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6380\n",
      "Epoch [1209/2000], Avg Train Loss: 3.6380\n",
      "Epoch [1209/2000], Avg Val Loss: 2.3616\n",
      "Validation loss improved from 2.3619 to 2.3616. Saving model...\n",
      "\n",
      "LOG: Epoch [1210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5985\n",
      "Epoch [1210/2000], Avg Train Loss: 3.5985\n",
      "Epoch [1210/2000], Avg Val Loss: 2.3612\n",
      "Validation loss improved from 2.3616 to 2.3612. Saving model...\n",
      "\n",
      "LOG: Epoch [1211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6198\n",
      "Epoch [1211/2000], Avg Train Loss: 3.6198\n",
      "Epoch [1211/2000], Avg Val Loss: 2.3610\n",
      "Validation loss improved from 2.3612 to 2.3610. Saving model...\n",
      "\n",
      "LOG: Epoch [1212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6549\n",
      "Epoch [1212/2000], Avg Train Loss: 3.6549\n",
      "Epoch [1212/2000], Avg Val Loss: 2.3609\n",
      "Validation loss improved from 2.3610 to 2.3609. Saving model...\n",
      "\n",
      "LOG: Epoch [1213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6572\n",
      "Epoch [1213/2000], Avg Train Loss: 3.6572\n",
      "Epoch [1213/2000], Avg Val Loss: 2.3608\n",
      "Validation loss improved from 2.3609 to 2.3608. Saving model...\n",
      "\n",
      "LOG: Epoch [1214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6639\n",
      "Epoch [1214/2000], Avg Train Loss: 3.6639\n",
      "Epoch [1214/2000], Avg Val Loss: 2.3606\n",
      "Validation loss improved from 2.3608 to 2.3606. Saving model...\n",
      "\n",
      "LOG: Epoch [1215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6618\n",
      "Epoch [1215/2000], Avg Train Loss: 3.6618\n",
      "Epoch [1215/2000], Avg Val Loss: 2.3605\n",
      "Validation loss improved from 2.3606 to 2.3605. Saving model...\n",
      "\n",
      "LOG: Epoch [1216/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6354\n",
      "Epoch [1216/2000], Avg Train Loss: 3.6354\n",
      "Epoch [1216/2000], Avg Val Loss: 2.3604\n",
      "Validation loss improved from 2.3605 to 2.3604. Saving model...\n",
      "\n",
      "LOG: Epoch [1217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6366\n",
      "Epoch [1217/2000], Avg Train Loss: 3.6366\n",
      "Epoch [1217/2000], Avg Val Loss: 2.3603\n",
      "Validation loss improved from 2.3604 to 2.3603. Saving model...\n",
      "\n",
      "LOG: Epoch [1218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6457\n",
      "Epoch [1218/2000], Avg Train Loss: 3.6457\n",
      "Epoch [1218/2000], Avg Val Loss: 2.3603\n",
      "Validation loss improved from 2.3603 to 2.3603. Saving model...\n",
      "\n",
      "LOG: Epoch [1219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6909\n",
      "Epoch [1219/2000], Avg Train Loss: 3.6909\n",
      "Epoch [1219/2000], Avg Val Loss: 2.3602\n",
      "Validation loss improved from 2.3603 to 2.3602. Saving model...\n",
      "\n",
      "LOG: Epoch [1220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6690\n",
      "Epoch [1220/2000], Avg Train Loss: 3.6690\n",
      "Epoch [1220/2000], Avg Val Loss: 2.3601\n",
      "Validation loss improved from 2.3602 to 2.3601. Saving model...\n",
      "\n",
      "LOG: Epoch [1221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6354\n",
      "Epoch [1221/2000], Avg Train Loss: 3.6354\n",
      "Epoch [1221/2000], Avg Val Loss: 2.3600\n",
      "Validation loss improved from 2.3601 to 2.3600. Saving model...\n",
      "\n",
      "LOG: Epoch [1222/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6221\n",
      "Epoch [1222/2000], Avg Train Loss: 3.6221\n",
      "Epoch [1222/2000], Avg Val Loss: 2.3599\n",
      "Validation loss improved from 2.3600 to 2.3599. Saving model...\n",
      "\n",
      "LOG: Epoch [1223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5871\n",
      "Epoch [1223/2000], Avg Train Loss: 3.5871\n",
      "Epoch [1223/2000], Avg Val Loss: 2.3598\n",
      "Validation loss improved from 2.3599 to 2.3598. Saving model...\n",
      "\n",
      "LOG: Epoch [1224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6427\n",
      "Epoch [1224/2000], Avg Train Loss: 3.6427\n",
      "Epoch [1224/2000], Avg Val Loss: 2.3598\n",
      "Validation loss improved from 2.3598 to 2.3598. Saving model...\n",
      "\n",
      "LOG: Epoch [1225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6052\n",
      "Epoch [1225/2000], Avg Train Loss: 3.6052\n",
      "Epoch [1225/2000], Avg Val Loss: 2.3598\n",
      "Validation loss improved from 2.3598 to 2.3598. Saving model...\n",
      "\n",
      "LOG: Epoch [1226/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6144\n",
      "Epoch [1226/2000], Avg Train Loss: 3.6144\n",
      "Epoch [1226/2000], Avg Val Loss: 2.3597\n",
      "Validation loss improved from 2.3598 to 2.3597. Saving model...\n",
      "\n",
      "LOG: Epoch [1227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6519\n",
      "Epoch [1227/2000], Avg Train Loss: 3.6519\n",
      "Epoch [1227/2000], Avg Val Loss: 2.3598\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6286\n",
      "Epoch [1228/2000], Avg Train Loss: 3.6286\n",
      "Epoch [1228/2000], Avg Val Loss: 2.3598\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6053\n",
      "Epoch [1229/2000], Avg Train Loss: 3.6053\n",
      "Epoch [1229/2000], Avg Val Loss: 2.3598\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1230/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6220\n",
      "Epoch [1230/2000], Avg Train Loss: 3.6220\n",
      "Epoch [1230/2000], Avg Val Loss: 2.3597\n",
      "Validation loss improved from 2.3597 to 2.3597. Saving model...\n",
      "\n",
      "LOG: Epoch [1231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6374\n",
      "Epoch [1231/2000], Avg Train Loss: 3.6374\n",
      "Epoch [1231/2000], Avg Val Loss: 2.3596\n",
      "Validation loss improved from 2.3597 to 2.3596. Saving model...\n",
      "\n",
      "LOG: Epoch [1232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6262\n",
      "Epoch [1232/2000], Avg Train Loss: 3.6262\n",
      "Epoch [1232/2000], Avg Val Loss: 2.3594\n",
      "Validation loss improved from 2.3596 to 2.3594. Saving model...\n",
      "\n",
      "LOG: Epoch [1233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6180\n",
      "Epoch [1233/2000], Avg Train Loss: 3.6180\n",
      "Epoch [1233/2000], Avg Val Loss: 2.3590\n",
      "Validation loss improved from 2.3594 to 2.3590. Saving model...\n",
      "\n",
      "LOG: Epoch [1234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5821\n",
      "Epoch [1234/2000], Avg Train Loss: 3.5821\n",
      "Epoch [1234/2000], Avg Val Loss: 2.3587\n",
      "Validation loss improved from 2.3590 to 2.3587. Saving model...\n",
      "\n",
      "LOG: Epoch [1235/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5959\n",
      "Epoch [1235/2000], Avg Train Loss: 3.5959\n",
      "Epoch [1235/2000], Avg Val Loss: 2.3583\n",
      "Validation loss improved from 2.3587 to 2.3583. Saving model...\n",
      "\n",
      "LOG: Epoch [1236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6096\n",
      "Epoch [1236/2000], Avg Train Loss: 3.6096\n",
      "Epoch [1236/2000], Avg Val Loss: 2.3577\n",
      "Validation loss improved from 2.3583 to 2.3577. Saving model...\n",
      "\n",
      "LOG: Epoch [1237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6251\n",
      "Epoch [1237/2000], Avg Train Loss: 3.6251\n",
      "Epoch [1237/2000], Avg Val Loss: 2.3572\n",
      "Validation loss improved from 2.3577 to 2.3572. Saving model...\n",
      "\n",
      "LOG: Epoch [1238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6219\n",
      "Epoch [1238/2000], Avg Train Loss: 3.6219\n",
      "Epoch [1238/2000], Avg Val Loss: 2.3566\n",
      "Validation loss improved from 2.3572 to 2.3566. Saving model...\n",
      "\n",
      "LOG: Epoch [1239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6462\n",
      "Epoch [1239/2000], Avg Train Loss: 3.6462\n",
      "Epoch [1239/2000], Avg Val Loss: 2.3561\n",
      "Validation loss improved from 2.3566 to 2.3561. Saving model...\n",
      "\n",
      "LOG: Epoch [1240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5758\n",
      "Epoch [1240/2000], Avg Train Loss: 3.5758\n",
      "Epoch [1240/2000], Avg Val Loss: 2.3554\n",
      "Validation loss improved from 2.3561 to 2.3554. Saving model...\n",
      "\n",
      "LOG: Epoch [1241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6493\n",
      "Epoch [1241/2000], Avg Train Loss: 3.6493\n",
      "Epoch [1241/2000], Avg Val Loss: 2.3548\n",
      "Validation loss improved from 2.3554 to 2.3548. Saving model...\n",
      "\n",
      "LOG: Epoch [1242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6645\n",
      "Epoch [1242/2000], Avg Train Loss: 3.6645\n",
      "Epoch [1242/2000], Avg Val Loss: 2.3543\n",
      "Validation loss improved from 2.3548 to 2.3543. Saving model...\n",
      "\n",
      "LOG: Epoch [1243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5837\n",
      "Epoch [1243/2000], Avg Train Loss: 3.5837\n",
      "Epoch [1243/2000], Avg Val Loss: 2.3538\n",
      "Validation loss improved from 2.3543 to 2.3538. Saving model...\n",
      "\n",
      "LOG: Epoch [1244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6270\n",
      "Epoch [1244/2000], Avg Train Loss: 3.6270\n",
      "Epoch [1244/2000], Avg Val Loss: 2.3533\n",
      "Validation loss improved from 2.3538 to 2.3533. Saving model...\n",
      "\n",
      "LOG: Epoch [1245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5989\n",
      "Epoch [1245/2000], Avg Train Loss: 3.5989\n",
      "Epoch [1245/2000], Avg Val Loss: 2.3530\n",
      "Validation loss improved from 2.3533 to 2.3530. Saving model...\n",
      "\n",
      "LOG: Epoch [1246/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6415\n",
      "Epoch [1246/2000], Avg Train Loss: 3.6415\n",
      "Epoch [1246/2000], Avg Val Loss: 2.3527\n",
      "Validation loss improved from 2.3530 to 2.3527. Saving model...\n",
      "\n",
      "LOG: Epoch [1247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6459\n",
      "Epoch [1247/2000], Avg Train Loss: 3.6459\n",
      "Epoch [1247/2000], Avg Val Loss: 2.3525\n",
      "Validation loss improved from 2.3527 to 2.3525. Saving model...\n",
      "\n",
      "LOG: Epoch [1248/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6292\n",
      "Epoch [1248/2000], Avg Train Loss: 3.6292\n",
      "Epoch [1248/2000], Avg Val Loss: 2.3524\n",
      "Validation loss improved from 2.3525 to 2.3524. Saving model...\n",
      "\n",
      "LOG: Epoch [1249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5833\n",
      "Epoch [1249/2000], Avg Train Loss: 3.5833\n",
      "Epoch [1249/2000], Avg Val Loss: 2.3524\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6155\n",
      "Epoch [1250/2000], Avg Train Loss: 3.6155\n",
      "Epoch [1250/2000], Avg Val Loss: 2.3525\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6120\n",
      "Epoch [1251/2000], Avg Train Loss: 3.6120\n",
      "Epoch [1251/2000], Avg Val Loss: 2.3526\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6062\n",
      "Epoch [1252/2000], Avg Train Loss: 3.6062\n",
      "Epoch [1252/2000], Avg Val Loss: 2.3526\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6180\n",
      "Epoch [1253/2000], Avg Train Loss: 3.6180\n",
      "Epoch [1253/2000], Avg Val Loss: 2.3528\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5994\n",
      "Epoch [1254/2000], Avg Train Loss: 3.5994\n",
      "Epoch [1254/2000], Avg Val Loss: 2.3529\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6180\n",
      "Epoch [1255/2000], Avg Train Loss: 3.6180\n",
      "Epoch [1255/2000], Avg Val Loss: 2.3529\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6162\n",
      "Epoch [1256/2000], Avg Train Loss: 3.6162\n",
      "Epoch [1256/2000], Avg Val Loss: 2.3528\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6200\n",
      "Epoch [1257/2000], Avg Train Loss: 3.6200\n",
      "Epoch [1257/2000], Avg Val Loss: 2.3529\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5768\n",
      "Epoch [1258/2000], Avg Train Loss: 3.5768\n",
      "Epoch [1258/2000], Avg Val Loss: 2.3529\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1259/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6345\n",
      "Epoch [1259/2000], Avg Train Loss: 3.6345\n",
      "Epoch [1259/2000], Avg Val Loss: 2.3530\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6522\n",
      "Epoch [1260/2000], Avg Train Loss: 3.6522\n",
      "Epoch [1260/2000], Avg Val Loss: 2.3532\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6103\n",
      "Epoch [1261/2000], Avg Train Loss: 3.6103\n",
      "Epoch [1261/2000], Avg Val Loss: 2.3535\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6164\n",
      "Epoch [1262/2000], Avg Train Loss: 3.6164\n",
      "Epoch [1262/2000], Avg Val Loss: 2.3538\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6262\n",
      "Epoch [1263/2000], Avg Train Loss: 3.6262\n",
      "Epoch [1263/2000], Avg Val Loss: 2.3542\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6221\n",
      "Epoch [1264/2000], Avg Train Loss: 3.6221\n",
      "Epoch [1264/2000], Avg Val Loss: 2.3547\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1265/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5967\n",
      "Epoch [1265/2000], Avg Train Loss: 3.5967\n",
      "Epoch [1265/2000], Avg Val Loss: 2.3551\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6052\n",
      "Epoch [1266/2000], Avg Train Loss: 3.6052\n",
      "Epoch [1266/2000], Avg Val Loss: 2.3553\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6100\n",
      "Epoch [1267/2000], Avg Train Loss: 3.6100\n",
      "Epoch [1267/2000], Avg Val Loss: 2.3554\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6302\n",
      "Epoch [1268/2000], Avg Train Loss: 3.6302\n",
      "Epoch [1268/2000], Avg Val Loss: 2.3555\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6134\n",
      "Epoch [1269/2000], Avg Train Loss: 3.6134\n",
      "Epoch [1269/2000], Avg Val Loss: 2.3554\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5614\n",
      "Epoch [1270/2000], Avg Train Loss: 3.5614\n",
      "Epoch [1270/2000], Avg Val Loss: 2.3552\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5940\n",
      "Epoch [1271/2000], Avg Train Loss: 3.5940\n",
      "Epoch [1271/2000], Avg Val Loss: 2.3551\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5937\n",
      "Epoch [1272/2000], Avg Train Loss: 3.5937\n",
      "Epoch [1272/2000], Avg Val Loss: 2.3548\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6295\n",
      "Epoch [1273/2000], Avg Train Loss: 3.6295\n",
      "Epoch [1273/2000], Avg Val Loss: 2.3546\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1274/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5638\n",
      "Epoch [1274/2000], Avg Train Loss: 3.5638\n",
      "Epoch [1274/2000], Avg Val Loss: 2.3542\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5729\n",
      "Epoch [1275/2000], Avg Train Loss: 3.5729\n",
      "Epoch [1275/2000], Avg Val Loss: 2.3538\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6170\n",
      "Epoch [1276/2000], Avg Train Loss: 3.6170\n",
      "Epoch [1276/2000], Avg Val Loss: 2.3533\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5532\n",
      "Epoch [1277/2000], Avg Train Loss: 3.5532\n",
      "Epoch [1277/2000], Avg Val Loss: 2.3529\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1278/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5753\n",
      "Epoch [1278/2000], Avg Train Loss: 3.5753\n",
      "Epoch [1278/2000], Avg Val Loss: 2.3524\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6201\n",
      "Epoch [1279/2000], Avg Train Loss: 3.6201\n",
      "Epoch [1279/2000], Avg Val Loss: 2.3520\n",
      "Validation loss improved from 2.3524 to 2.3520. Saving model...\n",
      "\n",
      "LOG: Epoch [1280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6215\n",
      "Epoch [1280/2000], Avg Train Loss: 3.6215\n",
      "Epoch [1280/2000], Avg Val Loss: 2.3516\n",
      "Validation loss improved from 2.3520 to 2.3516. Saving model...\n",
      "\n",
      "LOG: Epoch [1281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5450\n",
      "Epoch [1281/2000], Avg Train Loss: 3.5450\n",
      "Epoch [1281/2000], Avg Val Loss: 2.3511\n",
      "Validation loss improved from 2.3516 to 2.3511. Saving model...\n",
      "\n",
      "LOG: Epoch [1282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5563\n",
      "Epoch [1282/2000], Avg Train Loss: 3.5563\n",
      "Epoch [1282/2000], Avg Val Loss: 2.3506\n",
      "Validation loss improved from 2.3511 to 2.3506. Saving model...\n",
      "\n",
      "LOG: Epoch [1283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6172\n",
      "Epoch [1283/2000], Avg Train Loss: 3.6172\n",
      "Epoch [1283/2000], Avg Val Loss: 2.3501\n",
      "Validation loss improved from 2.3506 to 2.3501. Saving model...\n",
      "\n",
      "LOG: Epoch [1284/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6386\n",
      "Epoch [1284/2000], Avg Train Loss: 3.6386\n",
      "Epoch [1284/2000], Avg Val Loss: 2.3497\n",
      "Validation loss improved from 2.3501 to 2.3497. Saving model...\n",
      "\n",
      "LOG: Epoch [1285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6473\n",
      "Epoch [1285/2000], Avg Train Loss: 3.6473\n",
      "Epoch [1285/2000], Avg Val Loss: 2.3493\n",
      "Validation loss improved from 2.3497 to 2.3493. Saving model...\n",
      "\n",
      "LOG: Epoch [1286/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6089\n",
      "Epoch [1286/2000], Avg Train Loss: 3.6089\n",
      "Epoch [1286/2000], Avg Val Loss: 2.3489\n",
      "Validation loss improved from 2.3493 to 2.3489. Saving model...\n",
      "\n",
      "LOG: Epoch [1287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5699\n",
      "Epoch [1287/2000], Avg Train Loss: 3.5699\n",
      "Epoch [1287/2000], Avg Val Loss: 2.3486\n",
      "Validation loss improved from 2.3489 to 2.3486. Saving model...\n",
      "\n",
      "LOG: Epoch [1288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5567\n",
      "Epoch [1288/2000], Avg Train Loss: 3.5567\n",
      "Epoch [1288/2000], Avg Val Loss: 2.3483\n",
      "Validation loss improved from 2.3486 to 2.3483. Saving model...\n",
      "\n",
      "LOG: Epoch [1289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5628\n",
      "Epoch [1289/2000], Avg Train Loss: 3.5628\n",
      "Epoch [1289/2000], Avg Val Loss: 2.3480\n",
      "Validation loss improved from 2.3483 to 2.3480. Saving model...\n",
      "\n",
      "LOG: Epoch [1290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6217\n",
      "Epoch [1290/2000], Avg Train Loss: 3.6217\n",
      "Epoch [1290/2000], Avg Val Loss: 2.3478\n",
      "Validation loss improved from 2.3480 to 2.3478. Saving model...\n",
      "\n",
      "LOG: Epoch [1291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5748\n",
      "Epoch [1291/2000], Avg Train Loss: 3.5748\n",
      "Epoch [1291/2000], Avg Val Loss: 2.3475\n",
      "Validation loss improved from 2.3478 to 2.3475. Saving model...\n",
      "\n",
      "LOG: Epoch [1292/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5762\n",
      "Epoch [1292/2000], Avg Train Loss: 3.5762\n",
      "Epoch [1292/2000], Avg Val Loss: 2.3474\n",
      "Validation loss improved from 2.3475 to 2.3474. Saving model...\n",
      "\n",
      "LOG: Epoch [1293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5922\n",
      "Epoch [1293/2000], Avg Train Loss: 3.5922\n",
      "Epoch [1293/2000], Avg Val Loss: 2.3471\n",
      "Validation loss improved from 2.3474 to 2.3471. Saving model...\n",
      "\n",
      "LOG: Epoch [1294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6383\n",
      "Epoch [1294/2000], Avg Train Loss: 3.6383\n",
      "Epoch [1294/2000], Avg Val Loss: 2.3467\n",
      "Validation loss improved from 2.3471 to 2.3467. Saving model...\n",
      "\n",
      "LOG: Epoch [1295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5713\n",
      "Epoch [1295/2000], Avg Train Loss: 3.5713\n",
      "Epoch [1295/2000], Avg Val Loss: 2.3463\n",
      "Validation loss improved from 2.3467 to 2.3463. Saving model...\n",
      "\n",
      "LOG: Epoch [1296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5813\n",
      "Epoch [1296/2000], Avg Train Loss: 3.5813\n",
      "Epoch [1296/2000], Avg Val Loss: 2.3460\n",
      "Validation loss improved from 2.3463 to 2.3460. Saving model...\n",
      "\n",
      "LOG: Epoch [1297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5929\n",
      "Epoch [1297/2000], Avg Train Loss: 3.5929\n",
      "Epoch [1297/2000], Avg Val Loss: 2.3458\n",
      "Validation loss improved from 2.3460 to 2.3458. Saving model...\n",
      "\n",
      "LOG: Epoch [1298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6245\n",
      "Epoch [1298/2000], Avg Train Loss: 3.6245\n",
      "Epoch [1298/2000], Avg Val Loss: 2.3456\n",
      "Validation loss improved from 2.3458 to 2.3456. Saving model...\n",
      "\n",
      "LOG: Epoch [1299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5629\n",
      "Epoch [1299/2000], Avg Train Loss: 3.5629\n",
      "Epoch [1299/2000], Avg Val Loss: 2.3454\n",
      "Validation loss improved from 2.3456 to 2.3454. Saving model...\n",
      "\n",
      "LOG: Epoch [1300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5791\n",
      "Epoch [1300/2000], Avg Train Loss: 3.5791\n",
      "Epoch [1300/2000], Avg Val Loss: 2.3453\n",
      "Validation loss improved from 2.3454 to 2.3453. Saving model...\n",
      "\n",
      "LOG: Epoch [1301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6053\n",
      "Epoch [1301/2000], Avg Train Loss: 3.6053\n",
      "Epoch [1301/2000], Avg Val Loss: 2.3452\n",
      "Validation loss improved from 2.3453 to 2.3452. Saving model...\n",
      "\n",
      "LOG: Epoch [1302/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5989\n",
      "Epoch [1302/2000], Avg Train Loss: 3.5989\n",
      "Epoch [1302/2000], Avg Val Loss: 2.3452\n",
      "Validation loss improved from 2.3452 to 2.3452. Saving model...\n",
      "\n",
      "LOG: Epoch [1303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6044\n",
      "Epoch [1303/2000], Avg Train Loss: 3.6044\n",
      "Epoch [1303/2000], Avg Val Loss: 2.3451\n",
      "Validation loss improved from 2.3452 to 2.3451. Saving model...\n",
      "\n",
      "LOG: Epoch [1304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6015\n",
      "Epoch [1304/2000], Avg Train Loss: 3.6015\n",
      "Epoch [1304/2000], Avg Val Loss: 2.3449\n",
      "Validation loss improved from 2.3451 to 2.3449. Saving model...\n",
      "\n",
      "LOG: Epoch [1305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5766\n",
      "Epoch [1305/2000], Avg Train Loss: 3.5766\n",
      "Epoch [1305/2000], Avg Val Loss: 2.3447\n",
      "Validation loss improved from 2.3449 to 2.3447. Saving model...\n",
      "\n",
      "LOG: Epoch [1306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5493\n",
      "Epoch [1306/2000], Avg Train Loss: 3.5493\n",
      "Epoch [1306/2000], Avg Val Loss: 2.3446\n",
      "Validation loss improved from 2.3447 to 2.3446. Saving model...\n",
      "\n",
      "LOG: Epoch [1307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6249\n",
      "Epoch [1307/2000], Avg Train Loss: 3.6249\n",
      "Epoch [1307/2000], Avg Val Loss: 2.3444\n",
      "Validation loss improved from 2.3446 to 2.3444. Saving model...\n",
      "\n",
      "LOG: Epoch [1308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6140\n",
      "Epoch [1308/2000], Avg Train Loss: 3.6140\n",
      "Epoch [1308/2000], Avg Val Loss: 2.3443\n",
      "Validation loss improved from 2.3444 to 2.3443. Saving model...\n",
      "\n",
      "LOG: Epoch [1309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5698\n",
      "Epoch [1309/2000], Avg Train Loss: 3.5698\n",
      "Epoch [1309/2000], Avg Val Loss: 2.3442\n",
      "Validation loss improved from 2.3443 to 2.3442. Saving model...\n",
      "\n",
      "LOG: Epoch [1310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5580\n",
      "Epoch [1310/2000], Avg Train Loss: 3.5580\n",
      "Epoch [1310/2000], Avg Val Loss: 2.3441\n",
      "Validation loss improved from 2.3442 to 2.3441. Saving model...\n",
      "\n",
      "LOG: Epoch [1311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5465\n",
      "Epoch [1311/2000], Avg Train Loss: 3.5465\n",
      "Epoch [1311/2000], Avg Val Loss: 2.3441\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5884\n",
      "Epoch [1312/2000], Avg Train Loss: 3.5884\n",
      "Epoch [1312/2000], Avg Val Loss: 2.3440\n",
      "Validation loss improved from 2.3441 to 2.3440. Saving model...\n",
      "\n",
      "LOG: Epoch [1313/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6172\n",
      "Epoch [1313/2000], Avg Train Loss: 3.6172\n",
      "Epoch [1313/2000], Avg Val Loss: 2.3438\n",
      "Validation loss improved from 2.3440 to 2.3438. Saving model...\n",
      "\n",
      "LOG: Epoch [1314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5554\n",
      "Epoch [1314/2000], Avg Train Loss: 3.5554\n",
      "Epoch [1314/2000], Avg Val Loss: 2.3437\n",
      "Validation loss improved from 2.3438 to 2.3437. Saving model...\n",
      "\n",
      "LOG: Epoch [1315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5655\n",
      "Epoch [1315/2000], Avg Train Loss: 3.5655\n",
      "Epoch [1315/2000], Avg Val Loss: 2.3436\n",
      "Validation loss improved from 2.3437 to 2.3436. Saving model...\n",
      "\n",
      "LOG: Epoch [1316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5982\n",
      "Epoch [1316/2000], Avg Train Loss: 3.5982\n",
      "Epoch [1316/2000], Avg Val Loss: 2.3434\n",
      "Validation loss improved from 2.3436 to 2.3434. Saving model...\n",
      "\n",
      "LOG: Epoch [1317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5973\n",
      "Epoch [1317/2000], Avg Train Loss: 3.5973\n",
      "Epoch [1317/2000], Avg Val Loss: 2.3433\n",
      "Validation loss improved from 2.3434 to 2.3433. Saving model...\n",
      "\n",
      "LOG: Epoch [1318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5889\n",
      "Epoch [1318/2000], Avg Train Loss: 3.5889\n",
      "Epoch [1318/2000], Avg Val Loss: 2.3431\n",
      "Validation loss improved from 2.3433 to 2.3431. Saving model...\n",
      "\n",
      "LOG: Epoch [1319/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5628\n",
      "Epoch [1319/2000], Avg Train Loss: 3.5628\n",
      "Epoch [1319/2000], Avg Val Loss: 2.3429\n",
      "Validation loss improved from 2.3431 to 2.3429. Saving model...\n",
      "\n",
      "LOG: Epoch [1320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5493\n",
      "Epoch [1320/2000], Avg Train Loss: 3.5493\n",
      "Epoch [1320/2000], Avg Val Loss: 2.3427\n",
      "Validation loss improved from 2.3429 to 2.3427. Saving model...\n",
      "\n",
      "LOG: Epoch [1321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5559\n",
      "Epoch [1321/2000], Avg Train Loss: 3.5559\n",
      "Epoch [1321/2000], Avg Val Loss: 2.3425\n",
      "Validation loss improved from 2.3427 to 2.3425. Saving model...\n",
      "\n",
      "LOG: Epoch [1322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6343\n",
      "Epoch [1322/2000], Avg Train Loss: 3.6343\n",
      "Epoch [1322/2000], Avg Val Loss: 2.3424\n",
      "Validation loss improved from 2.3425 to 2.3424. Saving model...\n",
      "\n",
      "LOG: Epoch [1323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6227\n",
      "Epoch [1323/2000], Avg Train Loss: 3.6227\n",
      "Epoch [1323/2000], Avg Val Loss: 2.3422\n",
      "Validation loss improved from 2.3424 to 2.3422. Saving model...\n",
      "\n",
      "LOG: Epoch [1324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6076\n",
      "Epoch [1324/2000], Avg Train Loss: 3.6076\n",
      "Epoch [1324/2000], Avg Val Loss: 2.3420\n",
      "Validation loss improved from 2.3422 to 2.3420. Saving model...\n",
      "\n",
      "LOG: Epoch [1325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5681\n",
      "Epoch [1325/2000], Avg Train Loss: 3.5681\n",
      "Epoch [1325/2000], Avg Val Loss: 2.3417\n",
      "Validation loss improved from 2.3420 to 2.3417. Saving model...\n",
      "\n",
      "LOG: Epoch [1326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5802\n",
      "Epoch [1326/2000], Avg Train Loss: 3.5802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1326/2000], Avg Val Loss: 2.3414\n",
      "Validation loss improved from 2.3417 to 2.3414. Saving model...\n",
      "\n",
      "LOG: Epoch [1327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5826\n",
      "Epoch [1327/2000], Avg Train Loss: 3.5826\n",
      "Epoch [1327/2000], Avg Val Loss: 2.3411\n",
      "Validation loss improved from 2.3414 to 2.3411. Saving model...\n",
      "\n",
      "LOG: Epoch [1328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5504\n",
      "Epoch [1328/2000], Avg Train Loss: 3.5504\n",
      "Epoch [1328/2000], Avg Val Loss: 2.3408\n",
      "Validation loss improved from 2.3411 to 2.3408. Saving model...\n",
      "\n",
      "LOG: Epoch [1329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5662\n",
      "Epoch [1329/2000], Avg Train Loss: 3.5662\n",
      "Epoch [1329/2000], Avg Val Loss: 2.3405\n",
      "Validation loss improved from 2.3408 to 2.3405. Saving model...\n",
      "\n",
      "LOG: Epoch [1330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5874\n",
      "Epoch [1330/2000], Avg Train Loss: 3.5874\n",
      "Epoch [1330/2000], Avg Val Loss: 2.3403\n",
      "Validation loss improved from 2.3405 to 2.3403. Saving model...\n",
      "\n",
      "LOG: Epoch [1331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5650\n",
      "Epoch [1331/2000], Avg Train Loss: 3.5650\n",
      "Epoch [1331/2000], Avg Val Loss: 2.3400\n",
      "Validation loss improved from 2.3403 to 2.3400. Saving model...\n",
      "\n",
      "LOG: Epoch [1332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5756\n",
      "Epoch [1332/2000], Avg Train Loss: 3.5756\n",
      "Epoch [1332/2000], Avg Val Loss: 2.3396\n",
      "Validation loss improved from 2.3400 to 2.3396. Saving model...\n",
      "\n",
      "LOG: Epoch [1333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5813\n",
      "Epoch [1333/2000], Avg Train Loss: 3.5813\n",
      "Epoch [1333/2000], Avg Val Loss: 2.3392\n",
      "Validation loss improved from 2.3396 to 2.3392. Saving model...\n",
      "\n",
      "LOG: Epoch [1334/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5899\n",
      "Epoch [1334/2000], Avg Train Loss: 3.5899\n",
      "Epoch [1334/2000], Avg Val Loss: 2.3390\n",
      "Validation loss improved from 2.3392 to 2.3390. Saving model...\n",
      "\n",
      "LOG: Epoch [1335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5662\n",
      "Epoch [1335/2000], Avg Train Loss: 3.5662\n",
      "Epoch [1335/2000], Avg Val Loss: 2.3387\n",
      "Validation loss improved from 2.3390 to 2.3387. Saving model...\n",
      "\n",
      "LOG: Epoch [1336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5850\n",
      "Epoch [1336/2000], Avg Train Loss: 3.5850\n",
      "Epoch [1336/2000], Avg Val Loss: 2.3386\n",
      "Validation loss improved from 2.3387 to 2.3386. Saving model...\n",
      "\n",
      "LOG: Epoch [1337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5626\n",
      "Epoch [1337/2000], Avg Train Loss: 3.5626\n",
      "Epoch [1337/2000], Avg Val Loss: 2.3385\n",
      "Validation loss improved from 2.3386 to 2.3385. Saving model...\n",
      "\n",
      "LOG: Epoch [1338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5364\n",
      "Epoch [1338/2000], Avg Train Loss: 3.5364\n",
      "Epoch [1338/2000], Avg Val Loss: 2.3383\n",
      "Validation loss improved from 2.3385 to 2.3383. Saving model...\n",
      "\n",
      "LOG: Epoch [1339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5619\n",
      "Epoch [1339/2000], Avg Train Loss: 3.5619\n",
      "Epoch [1339/2000], Avg Val Loss: 2.3381\n",
      "Validation loss improved from 2.3383 to 2.3381. Saving model...\n",
      "\n",
      "LOG: Epoch [1340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5477\n",
      "Epoch [1340/2000], Avg Train Loss: 3.5477\n",
      "Epoch [1340/2000], Avg Val Loss: 2.3378\n",
      "Validation loss improved from 2.3381 to 2.3378. Saving model...\n",
      "\n",
      "LOG: Epoch [1341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5430\n",
      "Epoch [1341/2000], Avg Train Loss: 3.5430\n",
      "Epoch [1341/2000], Avg Val Loss: 2.3375\n",
      "Validation loss improved from 2.3378 to 2.3375. Saving model...\n",
      "\n",
      "LOG: Epoch [1342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5953\n",
      "Epoch [1342/2000], Avg Train Loss: 3.5953\n",
      "Epoch [1342/2000], Avg Val Loss: 2.3374\n",
      "Validation loss improved from 2.3375 to 2.3374. Saving model...\n",
      "\n",
      "LOG: Epoch [1343/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5568\n",
      "Epoch [1343/2000], Avg Train Loss: 3.5568\n",
      "Epoch [1343/2000], Avg Val Loss: 2.3372\n",
      "Validation loss improved from 2.3374 to 2.3372. Saving model...\n",
      "\n",
      "LOG: Epoch [1344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5504\n",
      "Epoch [1344/2000], Avg Train Loss: 3.5504\n",
      "Epoch [1344/2000], Avg Val Loss: 2.3372\n",
      "Validation loss improved from 2.3372 to 2.3372. Saving model...\n",
      "\n",
      "LOG: Epoch [1345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5717\n",
      "Epoch [1345/2000], Avg Train Loss: 3.5717\n",
      "Epoch [1345/2000], Avg Val Loss: 2.3370\n",
      "Validation loss improved from 2.3372 to 2.3370. Saving model...\n",
      "\n",
      "LOG: Epoch [1346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5782\n",
      "Epoch [1346/2000], Avg Train Loss: 3.5782\n",
      "Epoch [1346/2000], Avg Val Loss: 2.3370\n",
      "Validation loss improved from 2.3370 to 2.3370. Saving model...\n",
      "\n",
      "LOG: Epoch [1347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5372\n",
      "Epoch [1347/2000], Avg Train Loss: 3.5372\n",
      "Epoch [1347/2000], Avg Val Loss: 2.3370\n",
      "Validation loss improved from 2.3370 to 2.3370. Saving model...\n",
      "\n",
      "LOG: Epoch [1348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5866\n",
      "Epoch [1348/2000], Avg Train Loss: 3.5866\n",
      "Epoch [1348/2000], Avg Val Loss: 2.3369\n",
      "Validation loss improved from 2.3370 to 2.3369. Saving model...\n",
      "\n",
      "LOG: Epoch [1349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5473\n",
      "Epoch [1349/2000], Avg Train Loss: 3.5473\n",
      "Epoch [1349/2000], Avg Val Loss: 2.3367\n",
      "Validation loss improved from 2.3369 to 2.3367. Saving model...\n",
      "\n",
      "LOG: Epoch [1350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5470\n",
      "Epoch [1350/2000], Avg Train Loss: 3.5470\n",
      "Epoch [1350/2000], Avg Val Loss: 2.3363\n",
      "Validation loss improved from 2.3367 to 2.3363. Saving model...\n",
      "\n",
      "LOG: Epoch [1351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5737\n",
      "Epoch [1351/2000], Avg Train Loss: 3.5737\n",
      "Epoch [1351/2000], Avg Val Loss: 2.3359\n",
      "Validation loss improved from 2.3363 to 2.3359. Saving model...\n",
      "\n",
      "LOG: Epoch [1352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5428\n",
      "Epoch [1352/2000], Avg Train Loss: 3.5428\n",
      "Epoch [1352/2000], Avg Val Loss: 2.3357\n",
      "Validation loss improved from 2.3359 to 2.3357. Saving model...\n",
      "\n",
      "LOG: Epoch [1353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6032\n",
      "Epoch [1353/2000], Avg Train Loss: 3.6032\n",
      "Epoch [1353/2000], Avg Val Loss: 2.3355\n",
      "Validation loss improved from 2.3357 to 2.3355. Saving model...\n",
      "\n",
      "LOG: Epoch [1354/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5386\n",
      "Epoch [1354/2000], Avg Train Loss: 3.5386\n",
      "Epoch [1354/2000], Avg Val Loss: 2.3353\n",
      "Validation loss improved from 2.3355 to 2.3353. Saving model...\n",
      "\n",
      "LOG: Epoch [1355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5605\n",
      "Epoch [1355/2000], Avg Train Loss: 3.5605\n",
      "Epoch [1355/2000], Avg Val Loss: 2.3351\n",
      "Validation loss improved from 2.3353 to 2.3351. Saving model...\n",
      "\n",
      "LOG: Epoch [1356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5189\n",
      "Epoch [1356/2000], Avg Train Loss: 3.5189\n",
      "Epoch [1356/2000], Avg Val Loss: 2.3348\n",
      "Validation loss improved from 2.3351 to 2.3348. Saving model...\n",
      "\n",
      "LOG: Epoch [1357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6066\n",
      "Epoch [1357/2000], Avg Train Loss: 3.6066\n",
      "Epoch [1357/2000], Avg Val Loss: 2.3346\n",
      "Validation loss improved from 2.3348 to 2.3346. Saving model...\n",
      "\n",
      "LOG: Epoch [1358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5924\n",
      "Epoch [1358/2000], Avg Train Loss: 3.5924\n",
      "Epoch [1358/2000], Avg Val Loss: 2.3343\n",
      "Validation loss improved from 2.3346 to 2.3343. Saving model...\n",
      "\n",
      "LOG: Epoch [1359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5803\n",
      "Epoch [1359/2000], Avg Train Loss: 3.5803\n",
      "Epoch [1359/2000], Avg Val Loss: 2.3340\n",
      "Validation loss improved from 2.3343 to 2.3340. Saving model...\n",
      "\n",
      "LOG: Epoch [1360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5390\n",
      "Epoch [1360/2000], Avg Train Loss: 3.5390\n",
      "Epoch [1360/2000], Avg Val Loss: 2.3338\n",
      "Validation loss improved from 2.3340 to 2.3338. Saving model...\n",
      "\n",
      "LOG: Epoch [1361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5657\n",
      "Epoch [1361/2000], Avg Train Loss: 3.5657\n",
      "Epoch [1361/2000], Avg Val Loss: 2.3336\n",
      "Validation loss improved from 2.3338 to 2.3336. Saving model...\n",
      "\n",
      "LOG: Epoch [1362/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5428\n",
      "Epoch [1362/2000], Avg Train Loss: 3.5428\n",
      "Epoch [1362/2000], Avg Val Loss: 2.3336\n",
      "Validation loss improved from 2.3336 to 2.3336. Saving model...\n",
      "\n",
      "LOG: Epoch [1363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5570\n",
      "Epoch [1363/2000], Avg Train Loss: 3.5570\n",
      "Epoch [1363/2000], Avg Val Loss: 2.3336\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1364/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5827\n",
      "Epoch [1364/2000], Avg Train Loss: 3.5827\n",
      "Epoch [1364/2000], Avg Val Loss: 2.3336\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5673\n",
      "Epoch [1365/2000], Avg Train Loss: 3.5673\n",
      "Epoch [1365/2000], Avg Val Loss: 2.3336\n",
      "Validation loss improved from 2.3336 to 2.3336. Saving model...\n",
      "\n",
      "LOG: Epoch [1366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5665\n",
      "Epoch [1366/2000], Avg Train Loss: 3.5665\n",
      "Epoch [1366/2000], Avg Val Loss: 2.3337\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5401\n",
      "Epoch [1367/2000], Avg Train Loss: 3.5401\n",
      "Epoch [1367/2000], Avg Val Loss: 2.3337\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6107\n",
      "Epoch [1368/2000], Avg Train Loss: 3.6107\n",
      "Epoch [1368/2000], Avg Val Loss: 2.3340\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5419\n",
      "Epoch [1369/2000], Avg Train Loss: 3.5419\n",
      "Epoch [1369/2000], Avg Val Loss: 2.3341\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1370/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5571\n",
      "Epoch [1370/2000], Avg Train Loss: 3.5571\n",
      "Epoch [1370/2000], Avg Val Loss: 2.3343\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5181\n",
      "Epoch [1371/2000], Avg Train Loss: 3.5181\n",
      "Epoch [1371/2000], Avg Val Loss: 2.3344\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5818\n",
      "Epoch [1372/2000], Avg Train Loss: 3.5818\n",
      "Epoch [1372/2000], Avg Val Loss: 2.3347\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1373/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5175\n",
      "Epoch [1373/2000], Avg Train Loss: 3.5175\n",
      "Epoch [1373/2000], Avg Val Loss: 2.3350\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5291\n",
      "Epoch [1374/2000], Avg Train Loss: 3.5291\n",
      "Epoch [1374/2000], Avg Val Loss: 2.3353\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5450\n",
      "Epoch [1375/2000], Avg Train Loss: 3.5450\n",
      "Epoch [1375/2000], Avg Val Loss: 2.3353\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5822\n",
      "Epoch [1376/2000], Avg Train Loss: 3.5822\n",
      "Epoch [1376/2000], Avg Val Loss: 2.3354\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5370\n",
      "Epoch [1377/2000], Avg Train Loss: 3.5370\n",
      "Epoch [1377/2000], Avg Val Loss: 2.3354\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5700\n",
      "Epoch [1378/2000], Avg Train Loss: 3.5700\n",
      "Epoch [1378/2000], Avg Val Loss: 2.3355\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5272\n",
      "Epoch [1379/2000], Avg Train Loss: 3.5272\n",
      "Epoch [1379/2000], Avg Val Loss: 2.3355\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5276\n",
      "Epoch [1380/2000], Avg Train Loss: 3.5276\n",
      "Epoch [1380/2000], Avg Val Loss: 2.3356\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5200\n",
      "Epoch [1381/2000], Avg Train Loss: 3.5200\n",
      "Epoch [1381/2000], Avg Val Loss: 2.3355\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5624\n",
      "Epoch [1382/2000], Avg Train Loss: 3.5624\n",
      "Epoch [1382/2000], Avg Val Loss: 2.3355\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5485\n",
      "Epoch [1383/2000], Avg Train Loss: 3.5485\n",
      "Epoch [1383/2000], Avg Val Loss: 2.3357\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5409\n",
      "Epoch [1384/2000], Avg Train Loss: 3.5409\n",
      "Epoch [1384/2000], Avg Val Loss: 2.3359\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5018\n",
      "Epoch [1385/2000], Avg Train Loss: 3.5018\n",
      "Epoch [1385/2000], Avg Val Loss: 2.3361\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5582\n",
      "Epoch [1386/2000], Avg Train Loss: 3.5582\n",
      "Epoch [1386/2000], Avg Val Loss: 2.3362\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5309\n",
      "Epoch [1387/2000], Avg Train Loss: 3.5309\n",
      "Epoch [1387/2000], Avg Val Loss: 2.3363\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5380\n",
      "Epoch [1388/2000], Avg Train Loss: 3.5380\n",
      "Epoch [1388/2000], Avg Val Loss: 2.3363\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5310\n",
      "Epoch [1389/2000], Avg Train Loss: 3.5310\n",
      "Epoch [1389/2000], Avg Val Loss: 2.3363\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5318\n",
      "Epoch [1390/2000], Avg Train Loss: 3.5318\n",
      "Epoch [1390/2000], Avg Val Loss: 2.3362\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5265\n",
      "Epoch [1391/2000], Avg Train Loss: 3.5265\n",
      "Epoch [1391/2000], Avg Val Loss: 2.3361\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5064\n",
      "Epoch [1392/2000], Avg Train Loss: 3.5064\n",
      "Epoch [1392/2000], Avg Val Loss: 2.3359\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5672\n",
      "Epoch [1393/2000], Avg Train Loss: 3.5672\n",
      "Epoch [1393/2000], Avg Val Loss: 2.3358\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6231\n",
      "Epoch [1394/2000], Avg Train Loss: 3.6231\n",
      "Epoch [1394/2000], Avg Val Loss: 2.3358\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5582\n",
      "Epoch [1395/2000], Avg Train Loss: 3.5582\n",
      "Epoch [1395/2000], Avg Val Loss: 2.3357\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5106\n",
      "Epoch [1396/2000], Avg Train Loss: 3.5106\n",
      "Epoch [1396/2000], Avg Val Loss: 2.3357\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1397/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5842\n",
      "Epoch [1397/2000], Avg Train Loss: 3.5842\n",
      "Epoch [1397/2000], Avg Val Loss: 2.3357\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1398/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5440\n",
      "Epoch [1398/2000], Avg Train Loss: 3.5440\n",
      "Epoch [1398/2000], Avg Val Loss: 2.3355\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5049\n",
      "Epoch [1399/2000], Avg Train Loss: 3.5049\n",
      "Epoch [1399/2000], Avg Val Loss: 2.3353\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5321\n",
      "Epoch [1400/2000], Avg Train Loss: 3.5321\n",
      "Epoch [1400/2000], Avg Val Loss: 2.3351\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5386\n",
      "Epoch [1401/2000], Avg Train Loss: 3.5386\n",
      "Epoch [1401/2000], Avg Val Loss: 2.3349\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5040\n",
      "Epoch [1402/2000], Avg Train Loss: 3.5040\n",
      "Epoch [1402/2000], Avg Val Loss: 2.3347\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5372\n",
      "Epoch [1403/2000], Avg Train Loss: 3.5372\n",
      "Epoch [1403/2000], Avg Val Loss: 2.3343\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5512\n",
      "Epoch [1404/2000], Avg Train Loss: 3.5512\n",
      "Epoch [1404/2000], Avg Val Loss: 2.3340\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1405/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5356\n",
      "Epoch [1405/2000], Avg Train Loss: 3.5356\n",
      "Epoch [1405/2000], Avg Val Loss: 2.3338\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5406\n",
      "Epoch [1406/2000], Avg Train Loss: 3.5406\n",
      "Epoch [1406/2000], Avg Val Loss: 2.3333\n",
      "Validation loss improved from 2.3336 to 2.3333. Saving model...\n",
      "\n",
      "LOG: Epoch [1407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5259\n",
      "Epoch [1407/2000], Avg Train Loss: 3.5259\n",
      "Epoch [1407/2000], Avg Val Loss: 2.3330\n",
      "Validation loss improved from 2.3333 to 2.3330. Saving model...\n",
      "\n",
      "LOG: Epoch [1408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5612\n",
      "Epoch [1408/2000], Avg Train Loss: 3.5612\n",
      "Epoch [1408/2000], Avg Val Loss: 2.3326\n",
      "Validation loss improved from 2.3330 to 2.3326. Saving model...\n",
      "\n",
      "LOG: Epoch [1409/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5194\n",
      "Epoch [1409/2000], Avg Train Loss: 3.5194\n",
      "Epoch [1409/2000], Avg Val Loss: 2.3323\n",
      "Validation loss improved from 2.3326 to 2.3323. Saving model...\n",
      "\n",
      "LOG: Epoch [1410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5328\n",
      "Epoch [1410/2000], Avg Train Loss: 3.5328\n",
      "Epoch [1410/2000], Avg Val Loss: 2.3321\n",
      "Validation loss improved from 2.3323 to 2.3321. Saving model...\n",
      "\n",
      "LOG: Epoch [1411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5464\n",
      "Epoch [1411/2000], Avg Train Loss: 3.5464\n",
      "Epoch [1411/2000], Avg Val Loss: 2.3320\n",
      "Validation loss improved from 2.3321 to 2.3320. Saving model...\n",
      "\n",
      "LOG: Epoch [1412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5407\n",
      "Epoch [1412/2000], Avg Train Loss: 3.5407\n",
      "Epoch [1412/2000], Avg Val Loss: 2.3318\n",
      "Validation loss improved from 2.3320 to 2.3318. Saving model...\n",
      "\n",
      "LOG: Epoch [1413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5458\n",
      "Epoch [1413/2000], Avg Train Loss: 3.5458\n",
      "Epoch [1413/2000], Avg Val Loss: 2.3316\n",
      "Validation loss improved from 2.3318 to 2.3316. Saving model...\n",
      "\n",
      "LOG: Epoch [1414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5231\n",
      "Epoch [1414/2000], Avg Train Loss: 3.5231\n",
      "Epoch [1414/2000], Avg Val Loss: 2.3316\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5334\n",
      "Epoch [1415/2000], Avg Train Loss: 3.5334\n",
      "Epoch [1415/2000], Avg Val Loss: 2.3315\n",
      "Validation loss improved from 2.3316 to 2.3315. Saving model...\n",
      "\n",
      "LOG: Epoch [1416/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5400\n",
      "Epoch [1416/2000], Avg Train Loss: 3.5400\n",
      "Epoch [1416/2000], Avg Val Loss: 2.3313\n",
      "Validation loss improved from 2.3315 to 2.3313. Saving model...\n",
      "\n",
      "LOG: Epoch [1417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5317\n",
      "Epoch [1417/2000], Avg Train Loss: 3.5317\n",
      "Epoch [1417/2000], Avg Val Loss: 2.3311\n",
      "Validation loss improved from 2.3313 to 2.3311. Saving model...\n",
      "\n",
      "LOG: Epoch [1418/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5169\n",
      "Epoch [1418/2000], Avg Train Loss: 3.5169\n",
      "Epoch [1418/2000], Avg Val Loss: 2.3311\n",
      "Validation loss improved from 2.3311 to 2.3311. Saving model...\n",
      "\n",
      "LOG: Epoch [1419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5490\n",
      "Epoch [1419/2000], Avg Train Loss: 3.5490\n",
      "Epoch [1419/2000], Avg Val Loss: 2.3312\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5386\n",
      "Epoch [1420/2000], Avg Train Loss: 3.5386\n",
      "Epoch [1420/2000], Avg Val Loss: 2.3311\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4982\n",
      "Epoch [1421/2000], Avg Train Loss: 3.4982\n",
      "Epoch [1421/2000], Avg Val Loss: 2.3311\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5794\n",
      "Epoch [1422/2000], Avg Train Loss: 3.5794\n",
      "Epoch [1422/2000], Avg Val Loss: 2.3312\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5339\n",
      "Epoch [1423/2000], Avg Train Loss: 3.5339\n",
      "Epoch [1423/2000], Avg Val Loss: 2.3310\n",
      "Validation loss improved from 2.3311 to 2.3310. Saving model...\n",
      "\n",
      "LOG: Epoch [1424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5378\n",
      "Epoch [1424/2000], Avg Train Loss: 3.5378\n",
      "Epoch [1424/2000], Avg Val Loss: 2.3309\n",
      "Validation loss improved from 2.3310 to 2.3309. Saving model...\n",
      "\n",
      "LOG: Epoch [1425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5254\n",
      "Epoch [1425/2000], Avg Train Loss: 3.5254\n",
      "Epoch [1425/2000], Avg Val Loss: 2.3307\n",
      "Validation loss improved from 2.3309 to 2.3307. Saving model...\n",
      "\n",
      "LOG: Epoch [1426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5491\n",
      "Epoch [1426/2000], Avg Train Loss: 3.5491\n",
      "Epoch [1426/2000], Avg Val Loss: 2.3304\n",
      "Validation loss improved from 2.3307 to 2.3304. Saving model...\n",
      "\n",
      "LOG: Epoch [1427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5041\n",
      "Epoch [1427/2000], Avg Train Loss: 3.5041\n",
      "Epoch [1427/2000], Avg Val Loss: 2.3302\n",
      "Validation loss improved from 2.3304 to 2.3302. Saving model...\n",
      "\n",
      "LOG: Epoch [1428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5200\n",
      "Epoch [1428/2000], Avg Train Loss: 3.5200\n",
      "Epoch [1428/2000], Avg Val Loss: 2.3297\n",
      "Validation loss improved from 2.3302 to 2.3297. Saving model...\n",
      "\n",
      "LOG: Epoch [1429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5228\n",
      "Epoch [1429/2000], Avg Train Loss: 3.5228\n",
      "Epoch [1429/2000], Avg Val Loss: 2.3293\n",
      "Validation loss improved from 2.3297 to 2.3293. Saving model...\n",
      "\n",
      "LOG: Epoch [1430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5853\n",
      "Epoch [1430/2000], Avg Train Loss: 3.5853\n",
      "Epoch [1430/2000], Avg Val Loss: 2.3291\n",
      "Validation loss improved from 2.3293 to 2.3291. Saving model...\n",
      "\n",
      "LOG: Epoch [1431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5102\n",
      "Epoch [1431/2000], Avg Train Loss: 3.5102\n",
      "Epoch [1431/2000], Avg Val Loss: 2.3288\n",
      "Validation loss improved from 2.3291 to 2.3288. Saving model...\n",
      "\n",
      "LOG: Epoch [1432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4959\n",
      "Epoch [1432/2000], Avg Train Loss: 3.4959\n",
      "Epoch [1432/2000], Avg Val Loss: 2.3284\n",
      "Validation loss improved from 2.3288 to 2.3284. Saving model...\n",
      "\n",
      "LOG: Epoch [1433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5492\n",
      "Epoch [1433/2000], Avg Train Loss: 3.5492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1433/2000], Avg Val Loss: 2.3281\n",
      "Validation loss improved from 2.3284 to 2.3281. Saving model...\n",
      "\n",
      "LOG: Epoch [1434/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5200\n",
      "Epoch [1434/2000], Avg Train Loss: 3.5200\n",
      "Epoch [1434/2000], Avg Val Loss: 2.3279\n",
      "Validation loss improved from 2.3281 to 2.3279. Saving model...\n",
      "\n",
      "LOG: Epoch [1435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5084\n",
      "Epoch [1435/2000], Avg Train Loss: 3.5084\n",
      "Epoch [1435/2000], Avg Val Loss: 2.3277\n",
      "Validation loss improved from 2.3279 to 2.3277. Saving model...\n",
      "\n",
      "LOG: Epoch [1436/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5309\n",
      "Epoch [1436/2000], Avg Train Loss: 3.5309\n",
      "Epoch [1436/2000], Avg Val Loss: 2.3275\n",
      "Validation loss improved from 2.3277 to 2.3275. Saving model...\n",
      "\n",
      "LOG: Epoch [1437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5422\n",
      "Epoch [1437/2000], Avg Train Loss: 3.5422\n",
      "Epoch [1437/2000], Avg Val Loss: 2.3272\n",
      "Validation loss improved from 2.3275 to 2.3272. Saving model...\n",
      "\n",
      "LOG: Epoch [1438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5133\n",
      "Epoch [1438/2000], Avg Train Loss: 3.5133\n",
      "Epoch [1438/2000], Avg Val Loss: 2.3271\n",
      "Validation loss improved from 2.3272 to 2.3271. Saving model...\n",
      "\n",
      "LOG: Epoch [1439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5273\n",
      "Epoch [1439/2000], Avg Train Loss: 3.5273\n",
      "Epoch [1439/2000], Avg Val Loss: 2.3270\n",
      "Validation loss improved from 2.3271 to 2.3270. Saving model...\n",
      "\n",
      "LOG: Epoch [1440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5783\n",
      "Epoch [1440/2000], Avg Train Loss: 3.5783\n",
      "Epoch [1440/2000], Avg Val Loss: 2.3270\n",
      "Validation loss improved from 2.3270 to 2.3270. Saving model...\n",
      "\n",
      "LOG: Epoch [1441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5096\n",
      "Epoch [1441/2000], Avg Train Loss: 3.5096\n",
      "Epoch [1441/2000], Avg Val Loss: 2.3268\n",
      "Validation loss improved from 2.3270 to 2.3268. Saving model...\n",
      "\n",
      "LOG: Epoch [1442/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5425\n",
      "Epoch [1442/2000], Avg Train Loss: 3.5425\n",
      "Epoch [1442/2000], Avg Val Loss: 2.3267\n",
      "Validation loss improved from 2.3268 to 2.3267. Saving model...\n",
      "\n",
      "LOG: Epoch [1443/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5200\n",
      "Epoch [1443/2000], Avg Train Loss: 3.5200\n",
      "Epoch [1443/2000], Avg Val Loss: 2.3266\n",
      "Validation loss improved from 2.3267 to 2.3266. Saving model...\n",
      "\n",
      "LOG: Epoch [1444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5436\n",
      "Epoch [1444/2000], Avg Train Loss: 3.5436\n",
      "Epoch [1444/2000], Avg Val Loss: 2.3264\n",
      "Validation loss improved from 2.3266 to 2.3264. Saving model...\n",
      "\n",
      "LOG: Epoch [1445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5590\n",
      "Epoch [1445/2000], Avg Train Loss: 3.5590\n",
      "Epoch [1445/2000], Avg Val Loss: 2.3262\n",
      "Validation loss improved from 2.3264 to 2.3262. Saving model...\n",
      "\n",
      "LOG: Epoch [1446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5758\n",
      "Epoch [1446/2000], Avg Train Loss: 3.5758\n",
      "Epoch [1446/2000], Avg Val Loss: 2.3259\n",
      "Validation loss improved from 2.3262 to 2.3259. Saving model...\n",
      "\n",
      "LOG: Epoch [1447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5314\n",
      "Epoch [1447/2000], Avg Train Loss: 3.5314\n",
      "Epoch [1447/2000], Avg Val Loss: 2.3256\n",
      "Validation loss improved from 2.3259 to 2.3256. Saving model...\n",
      "\n",
      "LOG: Epoch [1448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5052\n",
      "Epoch [1448/2000], Avg Train Loss: 3.5052\n",
      "Epoch [1448/2000], Avg Val Loss: 2.3256\n",
      "Validation loss improved from 2.3256 to 2.3256. Saving model...\n",
      "\n",
      "LOG: Epoch [1449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4976\n",
      "Epoch [1449/2000], Avg Train Loss: 3.4976\n",
      "Epoch [1449/2000], Avg Val Loss: 2.3255\n",
      "Validation loss improved from 2.3256 to 2.3255. Saving model...\n",
      "\n",
      "LOG: Epoch [1450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4834\n",
      "Epoch [1450/2000], Avg Train Loss: 3.4834\n",
      "Epoch [1450/2000], Avg Val Loss: 2.3255\n",
      "Validation loss improved from 2.3255 to 2.3255. Saving model...\n",
      "\n",
      "LOG: Epoch [1451/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5717\n",
      "Epoch [1451/2000], Avg Train Loss: 3.5717\n",
      "Epoch [1451/2000], Avg Val Loss: 2.3254\n",
      "Validation loss improved from 2.3255 to 2.3254. Saving model...\n",
      "\n",
      "LOG: Epoch [1452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5025\n",
      "Epoch [1452/2000], Avg Train Loss: 3.5025\n",
      "Epoch [1452/2000], Avg Val Loss: 2.3254\n",
      "Validation loss improved from 2.3254 to 2.3254. Saving model...\n",
      "\n",
      "LOG: Epoch [1453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5401\n",
      "Epoch [1453/2000], Avg Train Loss: 3.5401\n",
      "Epoch [1453/2000], Avg Val Loss: 2.3254\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1454/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5421\n",
      "Epoch [1454/2000], Avg Train Loss: 3.5421\n",
      "Epoch [1454/2000], Avg Val Loss: 2.3253\n",
      "Validation loss improved from 2.3254 to 2.3253. Saving model...\n",
      "\n",
      "LOG: Epoch [1455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5378\n",
      "Epoch [1455/2000], Avg Train Loss: 3.5378\n",
      "Epoch [1455/2000], Avg Val Loss: 2.3254\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5558\n",
      "Epoch [1456/2000], Avg Train Loss: 3.5558\n",
      "Epoch [1456/2000], Avg Val Loss: 2.3256\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5518\n",
      "Epoch [1457/2000], Avg Train Loss: 3.5518\n",
      "Epoch [1457/2000], Avg Val Loss: 2.3258\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5115\n",
      "Epoch [1458/2000], Avg Train Loss: 3.5115\n",
      "Epoch [1458/2000], Avg Val Loss: 2.3259\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5244\n",
      "Epoch [1459/2000], Avg Train Loss: 3.5244\n",
      "Epoch [1459/2000], Avg Val Loss: 2.3260\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4691\n",
      "Epoch [1460/2000], Avg Train Loss: 3.4691\n",
      "Epoch [1460/2000], Avg Val Loss: 2.3261\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5263\n",
      "Epoch [1461/2000], Avg Train Loss: 3.5263\n",
      "Epoch [1461/2000], Avg Val Loss: 2.3262\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5334\n",
      "Epoch [1462/2000], Avg Train Loss: 3.5334\n",
      "Epoch [1462/2000], Avg Val Loss: 2.3264\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5296\n",
      "Epoch [1463/2000], Avg Train Loss: 3.5296\n",
      "Epoch [1463/2000], Avg Val Loss: 2.3265\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4666\n",
      "Epoch [1464/2000], Avg Train Loss: 3.4666\n",
      "Epoch [1464/2000], Avg Val Loss: 2.3266\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4897\n",
      "Epoch [1465/2000], Avg Train Loss: 3.4897\n",
      "Epoch [1465/2000], Avg Val Loss: 2.3268\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5194\n",
      "Epoch [1466/2000], Avg Train Loss: 3.5194\n",
      "Epoch [1466/2000], Avg Val Loss: 2.3269\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1467/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4772\n",
      "Epoch [1467/2000], Avg Train Loss: 3.4772\n",
      "Epoch [1467/2000], Avg Val Loss: 2.3270\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5014\n",
      "Epoch [1468/2000], Avg Train Loss: 3.5014\n",
      "Epoch [1468/2000], Avg Val Loss: 2.3270\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5147\n",
      "Epoch [1469/2000], Avg Train Loss: 3.5147\n",
      "Epoch [1469/2000], Avg Val Loss: 2.3270\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4881\n",
      "Epoch [1470/2000], Avg Train Loss: 3.4881\n",
      "Epoch [1470/2000], Avg Val Loss: 2.3269\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5456\n",
      "Epoch [1471/2000], Avg Train Loss: 3.5456\n",
      "Epoch [1471/2000], Avg Val Loss: 2.3268\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4744\n",
      "Epoch [1472/2000], Avg Train Loss: 3.4744\n",
      "Epoch [1472/2000], Avg Val Loss: 2.3268\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4934\n",
      "Epoch [1473/2000], Avg Train Loss: 3.4934\n",
      "Epoch [1473/2000], Avg Val Loss: 2.3268\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5003\n",
      "Epoch [1474/2000], Avg Train Loss: 3.5003\n",
      "Epoch [1474/2000], Avg Val Loss: 2.3267\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1475/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5281\n",
      "Epoch [1475/2000], Avg Train Loss: 3.5281\n",
      "Epoch [1475/2000], Avg Val Loss: 2.3266\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5096\n",
      "Epoch [1476/2000], Avg Train Loss: 3.5096\n",
      "Epoch [1476/2000], Avg Val Loss: 2.3265\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5290\n",
      "Epoch [1477/2000], Avg Train Loss: 3.5290\n",
      "Epoch [1477/2000], Avg Val Loss: 2.3264\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1478/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5304\n",
      "Epoch [1478/2000], Avg Train Loss: 3.5304\n",
      "Epoch [1478/2000], Avg Val Loss: 2.3263\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5075\n",
      "Epoch [1479/2000], Avg Train Loss: 3.5075\n",
      "Epoch [1479/2000], Avg Val Loss: 2.3261\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4625\n",
      "Epoch [1480/2000], Avg Train Loss: 3.4625\n",
      "Epoch [1480/2000], Avg Val Loss: 2.3259\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1481/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4779\n",
      "Epoch [1481/2000], Avg Train Loss: 3.4779\n",
      "Epoch [1481/2000], Avg Val Loss: 2.3257\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5230\n",
      "Epoch [1482/2000], Avg Train Loss: 3.5230\n",
      "Epoch [1482/2000], Avg Val Loss: 2.3256\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5012\n",
      "Epoch [1483/2000], Avg Train Loss: 3.5012\n",
      "Epoch [1483/2000], Avg Val Loss: 2.3254\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4724\n",
      "Epoch [1484/2000], Avg Train Loss: 3.4724\n",
      "Epoch [1484/2000], Avg Val Loss: 2.3253\n",
      "Validation loss improved from 2.3253 to 2.3253. Saving model...\n",
      "\n",
      "LOG: Epoch [1485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5733\n",
      "Epoch [1485/2000], Avg Train Loss: 3.5733\n",
      "Epoch [1485/2000], Avg Val Loss: 2.3251\n",
      "Validation loss improved from 2.3253 to 2.3251. Saving model...\n",
      "\n",
      "LOG: Epoch [1486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5019\n",
      "Epoch [1486/2000], Avg Train Loss: 3.5019\n",
      "Epoch [1486/2000], Avg Val Loss: 2.3249\n",
      "Validation loss improved from 2.3251 to 2.3249. Saving model...\n",
      "\n",
      "LOG: Epoch [1487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5474\n",
      "Epoch [1487/2000], Avg Train Loss: 3.5474\n",
      "Epoch [1487/2000], Avg Val Loss: 2.3248\n",
      "Validation loss improved from 2.3249 to 2.3248. Saving model...\n",
      "\n",
      "LOG: Epoch [1488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4928\n",
      "Epoch [1488/2000], Avg Train Loss: 3.4928\n",
      "Epoch [1488/2000], Avg Val Loss: 2.3246\n",
      "Validation loss improved from 2.3248 to 2.3246. Saving model...\n",
      "\n",
      "LOG: Epoch [1489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4801\n",
      "Epoch [1489/2000], Avg Train Loss: 3.4801\n",
      "Epoch [1489/2000], Avg Val Loss: 2.3245\n",
      "Validation loss improved from 2.3246 to 2.3245. Saving model...\n",
      "\n",
      "LOG: Epoch [1490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5010\n",
      "Epoch [1490/2000], Avg Train Loss: 3.5010\n",
      "Epoch [1490/2000], Avg Val Loss: 2.3244\n",
      "Validation loss improved from 2.3245 to 2.3244. Saving model...\n",
      "\n",
      "LOG: Epoch [1491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4924\n",
      "Epoch [1491/2000], Avg Train Loss: 3.4924\n",
      "Epoch [1491/2000], Avg Val Loss: 2.3243\n",
      "Validation loss improved from 2.3244 to 2.3243. Saving model...\n",
      "\n",
      "LOG: Epoch [1492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5336\n",
      "Epoch [1492/2000], Avg Train Loss: 3.5336\n",
      "Epoch [1492/2000], Avg Val Loss: 2.3244\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5027\n",
      "Epoch [1493/2000], Avg Train Loss: 3.5027\n",
      "Epoch [1493/2000], Avg Val Loss: 2.3244\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5175\n",
      "Epoch [1494/2000], Avg Train Loss: 3.5175\n",
      "Epoch [1494/2000], Avg Val Loss: 2.3244\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5024\n",
      "Epoch [1495/2000], Avg Train Loss: 3.5024\n",
      "Epoch [1495/2000], Avg Val Loss: 2.3244\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1496/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4914\n",
      "Epoch [1496/2000], Avg Train Loss: 3.4914\n",
      "Epoch [1496/2000], Avg Val Loss: 2.3244\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1497/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4537\n",
      "Epoch [1497/2000], Avg Train Loss: 3.4537\n",
      "Epoch [1497/2000], Avg Val Loss: 2.3244\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1498/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4781\n",
      "Epoch [1498/2000], Avg Train Loss: 3.4781\n",
      "Epoch [1498/2000], Avg Val Loss: 2.3242\n",
      "Validation loss improved from 2.3243 to 2.3242. Saving model...\n",
      "\n",
      "LOG: Epoch [1499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5446\n",
      "Epoch [1499/2000], Avg Train Loss: 3.5446\n",
      "Epoch [1499/2000], Avg Val Loss: 2.3242\n",
      "Validation loss improved from 2.3242 to 2.3242. Saving model...\n",
      "\n",
      "LOG: Epoch [1500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4650\n",
      "Epoch [1500/2000], Avg Train Loss: 3.4650\n",
      "Epoch [1500/2000], Avg Val Loss: 2.3242\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4819\n",
      "Epoch [1501/2000], Avg Train Loss: 3.4819\n",
      "Epoch [1501/2000], Avg Val Loss: 2.3241\n",
      "Validation loss improved from 2.3242 to 2.3241. Saving model...\n",
      "\n",
      "LOG: Epoch [1502/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5024\n",
      "Epoch [1502/2000], Avg Train Loss: 3.5024\n",
      "Epoch [1502/2000], Avg Val Loss: 2.3241\n",
      "Validation loss improved from 2.3241 to 2.3241. Saving model...\n",
      "\n",
      "LOG: Epoch [1503/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5135\n",
      "Epoch [1503/2000], Avg Train Loss: 3.5135\n",
      "Epoch [1503/2000], Avg Val Loss: 2.3239\n",
      "Validation loss improved from 2.3241 to 2.3239. Saving model...\n",
      "\n",
      "LOG: Epoch [1504/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4978\n",
      "Epoch [1504/2000], Avg Train Loss: 3.4978\n",
      "Epoch [1504/2000], Avg Val Loss: 2.3237\n",
      "Validation loss improved from 2.3239 to 2.3237. Saving model...\n",
      "\n",
      "LOG: Epoch [1505/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5058\n",
      "Epoch [1505/2000], Avg Train Loss: 3.5058\n",
      "Epoch [1505/2000], Avg Val Loss: 2.3235\n",
      "Validation loss improved from 2.3237 to 2.3235. Saving model...\n",
      "\n",
      "LOG: Epoch [1506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4732\n",
      "Epoch [1506/2000], Avg Train Loss: 3.4732\n",
      "Epoch [1506/2000], Avg Val Loss: 2.3233\n",
      "Validation loss improved from 2.3235 to 2.3233. Saving model...\n",
      "\n",
      "LOG: Epoch [1507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5297\n",
      "Epoch [1507/2000], Avg Train Loss: 3.5297\n",
      "Epoch [1507/2000], Avg Val Loss: 2.3231\n",
      "Validation loss improved from 2.3233 to 2.3231. Saving model...\n",
      "\n",
      "LOG: Epoch [1508/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4729\n",
      "Epoch [1508/2000], Avg Train Loss: 3.4729\n",
      "Epoch [1508/2000], Avg Val Loss: 2.3229\n",
      "Validation loss improved from 2.3231 to 2.3229. Saving model...\n",
      "\n",
      "LOG: Epoch [1509/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5448\n",
      "Epoch [1509/2000], Avg Train Loss: 3.5448\n",
      "Epoch [1509/2000], Avg Val Loss: 2.3228\n",
      "Validation loss improved from 2.3229 to 2.3228. Saving model...\n",
      "\n",
      "LOG: Epoch [1510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4833\n",
      "Epoch [1510/2000], Avg Train Loss: 3.4833\n",
      "Epoch [1510/2000], Avg Val Loss: 2.3226\n",
      "Validation loss improved from 2.3228 to 2.3226. Saving model...\n",
      "\n",
      "LOG: Epoch [1511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5212\n",
      "Epoch [1511/2000], Avg Train Loss: 3.5212\n",
      "Epoch [1511/2000], Avg Val Loss: 2.3225\n",
      "Validation loss improved from 2.3226 to 2.3225. Saving model...\n",
      "\n",
      "LOG: Epoch [1512/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4768\n",
      "Epoch [1512/2000], Avg Train Loss: 3.4768\n",
      "Epoch [1512/2000], Avg Val Loss: 2.3222\n",
      "Validation loss improved from 2.3225 to 2.3222. Saving model...\n",
      "\n",
      "LOG: Epoch [1513/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5141\n",
      "Epoch [1513/2000], Avg Train Loss: 3.5141\n",
      "Epoch [1513/2000], Avg Val Loss: 2.3220\n",
      "Validation loss improved from 2.3222 to 2.3220. Saving model...\n",
      "\n",
      "LOG: Epoch [1514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5216\n",
      "Epoch [1514/2000], Avg Train Loss: 3.5216\n",
      "Epoch [1514/2000], Avg Val Loss: 2.3217\n",
      "Validation loss improved from 2.3220 to 2.3217. Saving model...\n",
      "\n",
      "LOG: Epoch [1515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5038\n",
      "Epoch [1515/2000], Avg Train Loss: 3.5038\n",
      "Epoch [1515/2000], Avg Val Loss: 2.3215\n",
      "Validation loss improved from 2.3217 to 2.3215. Saving model...\n",
      "\n",
      "LOG: Epoch [1516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4574\n",
      "Epoch [1516/2000], Avg Train Loss: 3.4574\n",
      "Epoch [1516/2000], Avg Val Loss: 2.3214\n",
      "Validation loss improved from 2.3215 to 2.3214. Saving model...\n",
      "\n",
      "LOG: Epoch [1517/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5239\n",
      "Epoch [1517/2000], Avg Train Loss: 3.5239\n",
      "Epoch [1517/2000], Avg Val Loss: 2.3213\n",
      "Validation loss improved from 2.3214 to 2.3213. Saving model...\n",
      "\n",
      "LOG: Epoch [1518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5065\n",
      "Epoch [1518/2000], Avg Train Loss: 3.5065\n",
      "Epoch [1518/2000], Avg Val Loss: 2.3213\n",
      "Validation loss improved from 2.3213 to 2.3213. Saving model...\n",
      "\n",
      "LOG: Epoch [1519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5262\n",
      "Epoch [1519/2000], Avg Train Loss: 3.5262\n",
      "Epoch [1519/2000], Avg Val Loss: 2.3214\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5342\n",
      "Epoch [1520/2000], Avg Train Loss: 3.5342\n",
      "Epoch [1520/2000], Avg Val Loss: 2.3214\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5126\n",
      "Epoch [1521/2000], Avg Train Loss: 3.5126\n",
      "Epoch [1521/2000], Avg Val Loss: 2.3216\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5289\n",
      "Epoch [1522/2000], Avg Train Loss: 3.5289\n",
      "Epoch [1522/2000], Avg Val Loss: 2.3217\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5115\n",
      "Epoch [1523/2000], Avg Train Loss: 3.5115\n",
      "Epoch [1523/2000], Avg Val Loss: 2.3217\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5052\n",
      "Epoch [1524/2000], Avg Train Loss: 3.5052\n",
      "Epoch [1524/2000], Avg Val Loss: 2.3217\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5057\n",
      "Epoch [1525/2000], Avg Train Loss: 3.5057\n",
      "Epoch [1525/2000], Avg Val Loss: 2.3217\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4497\n",
      "Epoch [1526/2000], Avg Train Loss: 3.4497\n",
      "Epoch [1526/2000], Avg Val Loss: 2.3218\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1527/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4854\n",
      "Epoch [1527/2000], Avg Train Loss: 3.4854\n",
      "Epoch [1527/2000], Avg Val Loss: 2.3220\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4976\n",
      "Epoch [1528/2000], Avg Train Loss: 3.4976\n",
      "Epoch [1528/2000], Avg Val Loss: 2.3223\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5046\n",
      "Epoch [1529/2000], Avg Train Loss: 3.5046\n",
      "Epoch [1529/2000], Avg Val Loss: 2.3224\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5032\n",
      "Epoch [1530/2000], Avg Train Loss: 3.5032\n",
      "Epoch [1530/2000], Avg Val Loss: 2.3226\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4734\n",
      "Epoch [1531/2000], Avg Train Loss: 3.4734\n",
      "Epoch [1531/2000], Avg Val Loss: 2.3228\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4859\n",
      "Epoch [1532/2000], Avg Train Loss: 3.4859\n",
      "Epoch [1532/2000], Avg Val Loss: 2.3228\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1533/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5083\n",
      "Epoch [1533/2000], Avg Train Loss: 3.5083\n",
      "Epoch [1533/2000], Avg Val Loss: 2.3227\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5002\n",
      "Epoch [1534/2000], Avg Train Loss: 3.5002\n",
      "Epoch [1534/2000], Avg Val Loss: 2.3227\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1535/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4750\n",
      "Epoch [1535/2000], Avg Train Loss: 3.4750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1535/2000], Avg Val Loss: 2.3226\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4578\n",
      "Epoch [1536/2000], Avg Train Loss: 3.4578\n",
      "Epoch [1536/2000], Avg Val Loss: 2.3226\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5283\n",
      "Epoch [1537/2000], Avg Train Loss: 3.5283\n",
      "Epoch [1537/2000], Avg Val Loss: 2.3225\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5073\n",
      "Epoch [1538/2000], Avg Train Loss: 3.5073\n",
      "Epoch [1538/2000], Avg Val Loss: 2.3224\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1539/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4796\n",
      "Epoch [1539/2000], Avg Train Loss: 3.4796\n",
      "Epoch [1539/2000], Avg Val Loss: 2.3224\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5092\n",
      "Epoch [1540/2000], Avg Train Loss: 3.5092\n",
      "Epoch [1540/2000], Avg Val Loss: 2.3223\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4973\n",
      "Epoch [1541/2000], Avg Train Loss: 3.4973\n",
      "Epoch [1541/2000], Avg Val Loss: 2.3223\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1542/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5297\n",
      "Epoch [1542/2000], Avg Train Loss: 3.5297\n",
      "Epoch [1542/2000], Avg Val Loss: 2.3223\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1543/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4900\n",
      "Epoch [1543/2000], Avg Train Loss: 3.4900\n",
      "Epoch [1543/2000], Avg Val Loss: 2.3223\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4842\n",
      "Epoch [1544/2000], Avg Train Loss: 3.4842\n",
      "Epoch [1544/2000], Avg Val Loss: 2.3224\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1545/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4769\n",
      "Epoch [1545/2000], Avg Train Loss: 3.4769\n",
      "Epoch [1545/2000], Avg Val Loss: 2.3224\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5311\n",
      "Epoch [1546/2000], Avg Train Loss: 3.5311\n",
      "Epoch [1546/2000], Avg Val Loss: 2.3222\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1547/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4802\n",
      "Epoch [1547/2000], Avg Train Loss: 3.4802\n",
      "Epoch [1547/2000], Avg Val Loss: 2.3221\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1548/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5030\n",
      "Epoch [1548/2000], Avg Train Loss: 3.5030\n",
      "Epoch [1548/2000], Avg Val Loss: 2.3220\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1549/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4828\n",
      "Epoch [1549/2000], Avg Train Loss: 3.4828\n",
      "Epoch [1549/2000], Avg Val Loss: 2.3219\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4835\n",
      "Epoch [1550/2000], Avg Train Loss: 3.4835\n",
      "Epoch [1550/2000], Avg Val Loss: 2.3218\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1551/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4793\n",
      "Epoch [1551/2000], Avg Train Loss: 3.4793\n",
      "Epoch [1551/2000], Avg Val Loss: 2.3218\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4929\n",
      "Epoch [1552/2000], Avg Train Loss: 3.4929\n",
      "Epoch [1552/2000], Avg Val Loss: 2.3217\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1553/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4903\n",
      "Epoch [1553/2000], Avg Train Loss: 3.4903\n",
      "Epoch [1553/2000], Avg Val Loss: 2.3216\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5131\n",
      "Epoch [1554/2000], Avg Train Loss: 3.5131\n",
      "Epoch [1554/2000], Avg Val Loss: 2.3216\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4870\n",
      "Epoch [1555/2000], Avg Train Loss: 3.4870\n",
      "Epoch [1555/2000], Avg Val Loss: 2.3216\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5012\n",
      "Epoch [1556/2000], Avg Train Loss: 3.5012\n",
      "Epoch [1556/2000], Avg Val Loss: 2.3216\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4955\n",
      "Epoch [1557/2000], Avg Train Loss: 3.4955\n",
      "Epoch [1557/2000], Avg Val Loss: 2.3215\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4879\n",
      "Epoch [1558/2000], Avg Train Loss: 3.4879\n",
      "Epoch [1558/2000], Avg Val Loss: 2.3215\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4713\n",
      "Epoch [1559/2000], Avg Train Loss: 3.4713\n",
      "Epoch [1559/2000], Avg Val Loss: 2.3213\n",
      "Validation loss improved from 2.3213 to 2.3213. Saving model...\n",
      "\n",
      "LOG: Epoch [1560/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5012\n",
      "Epoch [1560/2000], Avg Train Loss: 3.5012\n",
      "Epoch [1560/2000], Avg Val Loss: 2.3211\n",
      "Validation loss improved from 2.3213 to 2.3211. Saving model...\n",
      "\n",
      "LOG: Epoch [1561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4675\n",
      "Epoch [1561/2000], Avg Train Loss: 3.4675\n",
      "Epoch [1561/2000], Avg Val Loss: 2.3210\n",
      "Validation loss improved from 2.3211 to 2.3210. Saving model...\n",
      "\n",
      "LOG: Epoch [1562/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4548\n",
      "Epoch [1562/2000], Avg Train Loss: 3.4548\n",
      "Epoch [1562/2000], Avg Val Loss: 2.3207\n",
      "Validation loss improved from 2.3210 to 2.3207. Saving model...\n",
      "\n",
      "LOG: Epoch [1563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4769\n",
      "Epoch [1563/2000], Avg Train Loss: 3.4769\n",
      "Epoch [1563/2000], Avg Val Loss: 2.3204\n",
      "Validation loss improved from 2.3207 to 2.3204. Saving model...\n",
      "\n",
      "LOG: Epoch [1564/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4881\n",
      "Epoch [1564/2000], Avg Train Loss: 3.4881\n",
      "Epoch [1564/2000], Avg Val Loss: 2.3202\n",
      "Validation loss improved from 2.3204 to 2.3202. Saving model...\n",
      "\n",
      "LOG: Epoch [1565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4813\n",
      "Epoch [1565/2000], Avg Train Loss: 3.4813\n",
      "Epoch [1565/2000], Avg Val Loss: 2.3199\n",
      "Validation loss improved from 2.3202 to 2.3199. Saving model...\n",
      "\n",
      "LOG: Epoch [1566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4671\n",
      "Epoch [1566/2000], Avg Train Loss: 3.4671\n",
      "Epoch [1566/2000], Avg Val Loss: 2.3197\n",
      "Validation loss improved from 2.3199 to 2.3197. Saving model...\n",
      "\n",
      "LOG: Epoch [1567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4529\n",
      "Epoch [1567/2000], Avg Train Loss: 3.4529\n",
      "Epoch [1567/2000], Avg Val Loss: 2.3196\n",
      "Validation loss improved from 2.3197 to 2.3196. Saving model...\n",
      "\n",
      "LOG: Epoch [1568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4553\n",
      "Epoch [1568/2000], Avg Train Loss: 3.4553\n",
      "Epoch [1568/2000], Avg Val Loss: 2.3195\n",
      "Validation loss improved from 2.3196 to 2.3195. Saving model...\n",
      "\n",
      "LOG: Epoch [1569/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4828\n",
      "Epoch [1569/2000], Avg Train Loss: 3.4828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1569/2000], Avg Val Loss: 2.3194\n",
      "Validation loss improved from 2.3195 to 2.3194. Saving model...\n",
      "\n",
      "LOG: Epoch [1570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4976\n",
      "Epoch [1570/2000], Avg Train Loss: 3.4976\n",
      "Epoch [1570/2000], Avg Val Loss: 2.3192\n",
      "Validation loss improved from 2.3194 to 2.3192. Saving model...\n",
      "\n",
      "LOG: Epoch [1571/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4666\n",
      "Epoch [1571/2000], Avg Train Loss: 3.4666\n",
      "Epoch [1571/2000], Avg Val Loss: 2.3190\n",
      "Validation loss improved from 2.3192 to 2.3190. Saving model...\n",
      "\n",
      "LOG: Epoch [1572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4856\n",
      "Epoch [1572/2000], Avg Train Loss: 3.4856\n",
      "Epoch [1572/2000], Avg Val Loss: 2.3188\n",
      "Validation loss improved from 2.3190 to 2.3188. Saving model...\n",
      "\n",
      "LOG: Epoch [1573/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5210\n",
      "Epoch [1573/2000], Avg Train Loss: 3.5210\n",
      "Epoch [1573/2000], Avg Val Loss: 2.3187\n",
      "Validation loss improved from 2.3188 to 2.3187. Saving model...\n",
      "\n",
      "LOG: Epoch [1574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4858\n",
      "Epoch [1574/2000], Avg Train Loss: 3.4858\n",
      "Epoch [1574/2000], Avg Val Loss: 2.3187\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4952\n",
      "Epoch [1575/2000], Avg Train Loss: 3.4952\n",
      "Epoch [1575/2000], Avg Val Loss: 2.3190\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4642\n",
      "Epoch [1576/2000], Avg Train Loss: 3.4642\n",
      "Epoch [1576/2000], Avg Val Loss: 2.3192\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1577/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4706\n",
      "Epoch [1577/2000], Avg Train Loss: 3.4706\n",
      "Epoch [1577/2000], Avg Val Loss: 2.3195\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1578/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4806\n",
      "Epoch [1578/2000], Avg Train Loss: 3.4806\n",
      "Epoch [1578/2000], Avg Val Loss: 2.3197\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1579/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4642\n",
      "Epoch [1579/2000], Avg Train Loss: 3.4642\n",
      "Epoch [1579/2000], Avg Val Loss: 2.3199\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1580/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4823\n",
      "Epoch [1580/2000], Avg Train Loss: 3.4823\n",
      "Epoch [1580/2000], Avg Val Loss: 2.3202\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4888\n",
      "Epoch [1581/2000], Avg Train Loss: 3.4888\n",
      "Epoch [1581/2000], Avg Val Loss: 2.3205\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1582/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4622\n",
      "Epoch [1582/2000], Avg Train Loss: 3.4622\n",
      "Epoch [1582/2000], Avg Val Loss: 2.3207\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4963\n",
      "Epoch [1583/2000], Avg Train Loss: 3.4963\n",
      "Epoch [1583/2000], Avg Val Loss: 2.3206\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1584/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4268\n",
      "Epoch [1584/2000], Avg Train Loss: 3.4268\n",
      "Epoch [1584/2000], Avg Val Loss: 2.3206\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4931\n",
      "Epoch [1585/2000], Avg Train Loss: 3.4931\n",
      "Epoch [1585/2000], Avg Val Loss: 2.3205\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1586/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4461\n",
      "Epoch [1586/2000], Avg Train Loss: 3.4461\n",
      "Epoch [1586/2000], Avg Val Loss: 2.3205\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4645\n",
      "Epoch [1587/2000], Avg Train Loss: 3.4645\n",
      "Epoch [1587/2000], Avg Val Loss: 2.3204\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1588/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4301\n",
      "Epoch [1588/2000], Avg Train Loss: 3.4301\n",
      "Epoch [1588/2000], Avg Val Loss: 2.3203\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4679\n",
      "Epoch [1589/2000], Avg Train Loss: 3.4679\n",
      "Epoch [1589/2000], Avg Val Loss: 2.3202\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4987\n",
      "Epoch [1590/2000], Avg Train Loss: 3.4987\n",
      "Epoch [1590/2000], Avg Val Loss: 2.3201\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4619\n",
      "Epoch [1591/2000], Avg Train Loss: 3.4619\n",
      "Epoch [1591/2000], Avg Val Loss: 2.3200\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4832\n",
      "Epoch [1592/2000], Avg Train Loss: 3.4832\n",
      "Epoch [1592/2000], Avg Val Loss: 2.3200\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1593/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4351\n",
      "Epoch [1593/2000], Avg Train Loss: 3.4351\n",
      "Epoch [1593/2000], Avg Val Loss: 2.3199\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1594/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4776\n",
      "Epoch [1594/2000], Avg Train Loss: 3.4776\n",
      "Epoch [1594/2000], Avg Val Loss: 2.3197\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4917\n",
      "Epoch [1595/2000], Avg Train Loss: 3.4917\n",
      "Epoch [1595/2000], Avg Val Loss: 2.3197\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4967\n",
      "Epoch [1596/2000], Avg Train Loss: 3.4967\n",
      "Epoch [1596/2000], Avg Val Loss: 2.3197\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4447\n",
      "Epoch [1597/2000], Avg Train Loss: 3.4447\n",
      "Epoch [1597/2000], Avg Val Loss: 2.3197\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1598/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4747\n",
      "Epoch [1598/2000], Avg Train Loss: 3.4747\n",
      "Epoch [1598/2000], Avg Val Loss: 2.3198\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1599/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4607\n",
      "Epoch [1599/2000], Avg Train Loss: 3.4607\n",
      "Epoch [1599/2000], Avg Val Loss: 2.3198\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1600/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4418\n",
      "Epoch [1600/2000], Avg Train Loss: 3.4418\n",
      "Epoch [1600/2000], Avg Val Loss: 2.3197\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1601/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4798\n",
      "Epoch [1601/2000], Avg Train Loss: 3.4798\n",
      "Epoch [1601/2000], Avg Val Loss: 2.3195\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4520\n",
      "Epoch [1602/2000], Avg Train Loss: 3.4520\n",
      "Epoch [1602/2000], Avg Val Loss: 2.3196\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1603/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4757\n",
      "Epoch [1603/2000], Avg Train Loss: 3.4757\n",
      "Epoch [1603/2000], Avg Val Loss: 2.3197\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1604/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4471\n",
      "Epoch [1604/2000], Avg Train Loss: 3.4471\n",
      "Epoch [1604/2000], Avg Val Loss: 2.3198\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1605/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4787\n",
      "Epoch [1605/2000], Avg Train Loss: 3.4787\n",
      "Epoch [1605/2000], Avg Val Loss: 2.3200\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1606/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5029\n",
      "Epoch [1606/2000], Avg Train Loss: 3.5029\n",
      "Epoch [1606/2000], Avg Val Loss: 2.3204\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1607/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4491\n",
      "Epoch [1607/2000], Avg Train Loss: 3.4491\n",
      "Epoch [1607/2000], Avg Val Loss: 2.3207\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1608/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4622\n",
      "Epoch [1608/2000], Avg Train Loss: 3.4622\n",
      "Epoch [1608/2000], Avg Val Loss: 2.3209\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1609/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4734\n",
      "Epoch [1609/2000], Avg Train Loss: 3.4734\n",
      "Epoch [1609/2000], Avg Val Loss: 2.3211\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4758\n",
      "Epoch [1610/2000], Avg Train Loss: 3.4758\n",
      "Epoch [1610/2000], Avg Val Loss: 2.3212\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1611/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4365\n",
      "Epoch [1611/2000], Avg Train Loss: 3.4365\n",
      "Epoch [1611/2000], Avg Val Loss: 2.3213\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4722\n",
      "Epoch [1612/2000], Avg Train Loss: 3.4722\n",
      "Epoch [1612/2000], Avg Val Loss: 2.3214\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1613/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4883\n",
      "Epoch [1613/2000], Avg Train Loss: 3.4883\n",
      "Epoch [1613/2000], Avg Val Loss: 2.3214\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4519\n",
      "Epoch [1614/2000], Avg Train Loss: 3.4519\n",
      "Epoch [1614/2000], Avg Val Loss: 2.3213\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1615/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4272\n",
      "Epoch [1615/2000], Avg Train Loss: 3.4272\n",
      "Epoch [1615/2000], Avg Val Loss: 2.3210\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1616/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4583\n",
      "Epoch [1616/2000], Avg Train Loss: 3.4583\n",
      "Epoch [1616/2000], Avg Val Loss: 2.3207\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1617/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4393\n",
      "Epoch [1617/2000], Avg Train Loss: 3.4393\n",
      "Epoch [1617/2000], Avg Val Loss: 2.3203\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1618/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4842\n",
      "Epoch [1618/2000], Avg Train Loss: 3.4842\n",
      "Epoch [1618/2000], Avg Val Loss: 2.3201\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1619/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4317\n",
      "Epoch [1619/2000], Avg Train Loss: 3.4317\n",
      "Epoch [1619/2000], Avg Val Loss: 2.3199\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1620/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4538\n",
      "Epoch [1620/2000], Avg Train Loss: 3.4538\n",
      "Epoch [1620/2000], Avg Val Loss: 2.3197\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1621/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4413\n",
      "Epoch [1621/2000], Avg Train Loss: 3.4413\n",
      "Epoch [1621/2000], Avg Val Loss: 2.3196\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1622/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4754\n",
      "Epoch [1622/2000], Avg Train Loss: 3.4754\n",
      "Epoch [1622/2000], Avg Val Loss: 2.3195\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1623/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4566\n",
      "Epoch [1623/2000], Avg Train Loss: 3.4566\n",
      "Epoch [1623/2000], Avg Val Loss: 2.3196\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1624/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4469\n",
      "Epoch [1624/2000], Avg Train Loss: 3.4469\n",
      "Epoch [1624/2000], Avg Val Loss: 2.3196\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4927\n",
      "Epoch [1625/2000], Avg Train Loss: 3.4927\n",
      "Epoch [1625/2000], Avg Val Loss: 2.3195\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1626/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4466\n",
      "Epoch [1626/2000], Avg Train Loss: 3.4466\n",
      "Epoch [1626/2000], Avg Val Loss: 2.3195\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1627/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4844\n",
      "Epoch [1627/2000], Avg Train Loss: 3.4844\n",
      "Epoch [1627/2000], Avg Val Loss: 2.3195\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1628/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4924\n",
      "Epoch [1628/2000], Avg Train Loss: 3.4924\n",
      "Epoch [1628/2000], Avg Val Loss: 2.3196\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4799\n",
      "Epoch [1629/2000], Avg Train Loss: 3.4799\n",
      "Epoch [1629/2000], Avg Val Loss: 2.3198\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1630/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4852\n",
      "Epoch [1630/2000], Avg Train Loss: 3.4852\n",
      "Epoch [1630/2000], Avg Val Loss: 2.3198\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1631/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4463\n",
      "Epoch [1631/2000], Avg Train Loss: 3.4463\n",
      "Epoch [1631/2000], Avg Val Loss: 2.3197\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1632/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5255\n",
      "Epoch [1632/2000], Avg Train Loss: 3.5255\n",
      "Epoch [1632/2000], Avg Val Loss: 2.3196\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1633/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4512\n",
      "Epoch [1633/2000], Avg Train Loss: 3.4512\n",
      "Epoch [1633/2000], Avg Val Loss: 2.3196\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1634/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4327\n",
      "Epoch [1634/2000], Avg Train Loss: 3.4327\n",
      "Epoch [1634/2000], Avg Val Loss: 2.3196\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4840\n",
      "Epoch [1635/2000], Avg Train Loss: 3.4840\n",
      "Epoch [1635/2000], Avg Val Loss: 2.3195\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1636/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4453\n",
      "Epoch [1636/2000], Avg Train Loss: 3.4453\n",
      "Epoch [1636/2000], Avg Val Loss: 2.3194\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4496\n",
      "Epoch [1637/2000], Avg Train Loss: 3.4496\n",
      "Epoch [1637/2000], Avg Val Loss: 2.3193\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1638/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5116\n",
      "Epoch [1638/2000], Avg Train Loss: 3.5116\n",
      "Epoch [1638/2000], Avg Val Loss: 2.3193\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5055\n",
      "Epoch [1639/2000], Avg Train Loss: 3.5055\n",
      "Epoch [1639/2000], Avg Val Loss: 2.3194\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1640/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4215\n",
      "Epoch [1640/2000], Avg Train Loss: 3.4215\n",
      "Epoch [1640/2000], Avg Val Loss: 2.3194\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1641/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4823\n",
      "Epoch [1641/2000], Avg Train Loss: 3.4823\n",
      "Epoch [1641/2000], Avg Val Loss: 2.3193\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [1642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4605\n",
      "Epoch [1642/2000], Avg Train Loss: 3.4605\n",
      "Epoch [1642/2000], Avg Val Loss: 2.3191\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [1643/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4279\n",
      "Epoch [1643/2000], Avg Train Loss: 3.4279\n",
      "Epoch [1643/2000], Avg Val Loss: 2.3189\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [1644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4744\n",
      "Epoch [1644/2000], Avg Train Loss: 3.4744\n",
      "Epoch [1644/2000], Avg Val Loss: 2.3186\n",
      "Validation loss improved from 2.3187 to 2.3186. Saving model...\n",
      "\n",
      "LOG: Epoch [1645/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4436\n",
      "Epoch [1645/2000], Avg Train Loss: 3.4436\n",
      "Epoch [1645/2000], Avg Val Loss: 2.3184\n",
      "Validation loss improved from 2.3186 to 2.3184. Saving model...\n",
      "\n",
      "LOG: Epoch [1646/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4864\n",
      "Epoch [1646/2000], Avg Train Loss: 3.4864\n",
      "Epoch [1646/2000], Avg Val Loss: 2.3182\n",
      "Validation loss improved from 2.3184 to 2.3182. Saving model...\n",
      "\n",
      "LOG: Epoch [1647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4087\n",
      "Epoch [1647/2000], Avg Train Loss: 3.4087\n",
      "Epoch [1647/2000], Avg Val Loss: 2.3181\n",
      "Validation loss improved from 2.3182 to 2.3181. Saving model...\n",
      "\n",
      "LOG: Epoch [1648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4641\n",
      "Epoch [1648/2000], Avg Train Loss: 3.4641\n",
      "Epoch [1648/2000], Avg Val Loss: 2.3180\n",
      "Validation loss improved from 2.3181 to 2.3180. Saving model...\n",
      "\n",
      "LOG: Epoch [1649/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4550\n",
      "Epoch [1649/2000], Avg Train Loss: 3.4550\n",
      "Epoch [1649/2000], Avg Val Loss: 2.3180\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1650/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4702\n",
      "Epoch [1650/2000], Avg Train Loss: 3.4702\n",
      "Epoch [1650/2000], Avg Val Loss: 2.3179\n",
      "Validation loss improved from 2.3180 to 2.3179. Saving model...\n",
      "\n",
      "LOG: Epoch [1651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4594\n",
      "Epoch [1651/2000], Avg Train Loss: 3.4594\n",
      "Epoch [1651/2000], Avg Val Loss: 2.3179\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1652/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4309\n",
      "Epoch [1652/2000], Avg Train Loss: 3.4309\n",
      "Epoch [1652/2000], Avg Val Loss: 2.3180\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4456\n",
      "Epoch [1653/2000], Avg Train Loss: 3.4456\n",
      "Epoch [1653/2000], Avg Val Loss: 2.3183\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1654/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4440\n",
      "Epoch [1654/2000], Avg Train Loss: 3.4440\n",
      "Epoch [1654/2000], Avg Val Loss: 2.3186\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4236\n",
      "Epoch [1655/2000], Avg Train Loss: 3.4236\n",
      "Epoch [1655/2000], Avg Val Loss: 2.3188\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1656/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4160\n",
      "Epoch [1656/2000], Avg Train Loss: 3.4160\n",
      "Epoch [1656/2000], Avg Val Loss: 2.3190\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4625\n",
      "Epoch [1657/2000], Avg Train Loss: 3.4625\n",
      "Epoch [1657/2000], Avg Val Loss: 2.3188\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1658/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4538\n",
      "Epoch [1658/2000], Avg Train Loss: 3.4538\n",
      "Epoch [1658/2000], Avg Val Loss: 2.3186\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1659/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4355\n",
      "Epoch [1659/2000], Avg Train Loss: 3.4355\n",
      "Epoch [1659/2000], Avg Val Loss: 2.3185\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1660/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4463\n",
      "Epoch [1660/2000], Avg Train Loss: 3.4463\n",
      "Epoch [1660/2000], Avg Val Loss: 2.3181\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1661/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4667\n",
      "Epoch [1661/2000], Avg Train Loss: 3.4667\n",
      "Epoch [1661/2000], Avg Val Loss: 2.3179\n",
      "Validation loss improved from 2.3179 to 2.3179. Saving model...\n",
      "\n",
      "LOG: Epoch [1662/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3890\n",
      "Epoch [1662/2000], Avg Train Loss: 3.3890\n",
      "Epoch [1662/2000], Avg Val Loss: 2.3177\n",
      "Validation loss improved from 2.3179 to 2.3177. Saving model...\n",
      "\n",
      "LOG: Epoch [1663/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4303\n",
      "Epoch [1663/2000], Avg Train Loss: 3.4303\n",
      "Epoch [1663/2000], Avg Val Loss: 2.3176\n",
      "Validation loss improved from 2.3177 to 2.3176. Saving model...\n",
      "\n",
      "LOG: Epoch [1664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4695\n",
      "Epoch [1664/2000], Avg Train Loss: 3.4695\n",
      "Epoch [1664/2000], Avg Val Loss: 2.3176\n",
      "Validation loss improved from 2.3176 to 2.3176. Saving model...\n",
      "\n",
      "LOG: Epoch [1665/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4452\n",
      "Epoch [1665/2000], Avg Train Loss: 3.4452\n",
      "Epoch [1665/2000], Avg Val Loss: 2.3176\n",
      "Validation loss improved from 2.3176 to 2.3176. Saving model...\n",
      "\n",
      "LOG: Epoch [1666/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4242\n",
      "Epoch [1666/2000], Avg Train Loss: 3.4242\n",
      "Epoch [1666/2000], Avg Val Loss: 2.3174\n",
      "Validation loss improved from 2.3176 to 2.3174. Saving model...\n",
      "\n",
      "LOG: Epoch [1667/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4544\n",
      "Epoch [1667/2000], Avg Train Loss: 3.4544\n",
      "Epoch [1667/2000], Avg Val Loss: 2.3173\n",
      "Validation loss improved from 2.3174 to 2.3173. Saving model...\n",
      "\n",
      "LOG: Epoch [1668/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4436\n",
      "Epoch [1668/2000], Avg Train Loss: 3.4436\n",
      "Epoch [1668/2000], Avg Val Loss: 2.3173\n",
      "Validation loss improved from 2.3173 to 2.3173. Saving model...\n",
      "\n",
      "LOG: Epoch [1669/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4795\n",
      "Epoch [1669/2000], Avg Train Loss: 3.4795\n",
      "Epoch [1669/2000], Avg Val Loss: 2.3172\n",
      "Validation loss improved from 2.3173 to 2.3172. Saving model...\n",
      "\n",
      "LOG: Epoch [1670/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4607\n",
      "Epoch [1670/2000], Avg Train Loss: 3.4607\n",
      "Epoch [1670/2000], Avg Val Loss: 2.3173\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1671/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4710\n",
      "Epoch [1671/2000], Avg Train Loss: 3.4710\n",
      "Epoch [1671/2000], Avg Val Loss: 2.3173\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4246\n",
      "Epoch [1672/2000], Avg Train Loss: 3.4246\n",
      "Epoch [1672/2000], Avg Val Loss: 2.3173\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1673/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4132\n",
      "Epoch [1673/2000], Avg Train Loss: 3.4132\n",
      "Epoch [1673/2000], Avg Val Loss: 2.3176\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4354\n",
      "Epoch [1674/2000], Avg Train Loss: 3.4354\n",
      "Epoch [1674/2000], Avg Val Loss: 2.3179\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4540\n",
      "Epoch [1675/2000], Avg Train Loss: 3.4540\n",
      "Epoch [1675/2000], Avg Val Loss: 2.3183\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1676/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4549\n",
      "Epoch [1676/2000], Avg Train Loss: 3.4549\n",
      "Epoch [1676/2000], Avg Val Loss: 2.3186\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4442\n",
      "Epoch [1677/2000], Avg Train Loss: 3.4442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1677/2000], Avg Val Loss: 2.3189\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1678/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4234\n",
      "Epoch [1678/2000], Avg Train Loss: 3.4234\n",
      "Epoch [1678/2000], Avg Val Loss: 2.3192\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1679/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4346\n",
      "Epoch [1679/2000], Avg Train Loss: 3.4346\n",
      "Epoch [1679/2000], Avg Val Loss: 2.3195\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4162\n",
      "Epoch [1680/2000], Avg Train Loss: 3.4162\n",
      "Epoch [1680/2000], Avg Val Loss: 2.3197\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1681/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4848\n",
      "Epoch [1681/2000], Avg Train Loss: 3.4848\n",
      "Epoch [1681/2000], Avg Val Loss: 2.3200\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4209\n",
      "Epoch [1682/2000], Avg Train Loss: 3.4209\n",
      "Epoch [1682/2000], Avg Val Loss: 2.3202\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1683/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4062\n",
      "Epoch [1683/2000], Avg Train Loss: 3.4062\n",
      "Epoch [1683/2000], Avg Val Loss: 2.3205\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4497\n",
      "Epoch [1684/2000], Avg Train Loss: 3.4497\n",
      "Epoch [1684/2000], Avg Val Loss: 2.3206\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1685/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4295\n",
      "Epoch [1685/2000], Avg Train Loss: 3.4295\n",
      "Epoch [1685/2000], Avg Val Loss: 2.3205\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4165\n",
      "Epoch [1686/2000], Avg Train Loss: 3.4165\n",
      "Epoch [1686/2000], Avg Val Loss: 2.3203\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1687/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4741\n",
      "Epoch [1687/2000], Avg Train Loss: 3.4741\n",
      "Epoch [1687/2000], Avg Val Loss: 2.3201\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1688/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4713\n",
      "Epoch [1688/2000], Avg Train Loss: 3.4713\n",
      "Epoch [1688/2000], Avg Val Loss: 2.3200\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1689/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4075\n",
      "Epoch [1689/2000], Avg Train Loss: 3.4075\n",
      "Epoch [1689/2000], Avg Val Loss: 2.3198\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1690/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4523\n",
      "Epoch [1690/2000], Avg Train Loss: 3.4523\n",
      "Epoch [1690/2000], Avg Val Loss: 2.3197\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4479\n",
      "Epoch [1691/2000], Avg Train Loss: 3.4479\n",
      "Epoch [1691/2000], Avg Val Loss: 2.3197\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4643\n",
      "Epoch [1692/2000], Avg Train Loss: 3.4643\n",
      "Epoch [1692/2000], Avg Val Loss: 2.3196\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1693/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4140\n",
      "Epoch [1693/2000], Avg Train Loss: 3.4140\n",
      "Epoch [1693/2000], Avg Val Loss: 2.3194\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1694/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4241\n",
      "Epoch [1694/2000], Avg Train Loss: 3.4241\n",
      "Epoch [1694/2000], Avg Val Loss: 2.3193\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4358\n",
      "Epoch [1695/2000], Avg Train Loss: 3.4358\n",
      "Epoch [1695/2000], Avg Val Loss: 2.3191\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1696/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4485\n",
      "Epoch [1696/2000], Avg Train Loss: 3.4485\n",
      "Epoch [1696/2000], Avg Val Loss: 2.3188\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1697/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4147\n",
      "Epoch [1697/2000], Avg Train Loss: 3.4147\n",
      "Epoch [1697/2000], Avg Val Loss: 2.3186\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1698/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4184\n",
      "Epoch [1698/2000], Avg Train Loss: 3.4184\n",
      "Epoch [1698/2000], Avg Val Loss: 2.3186\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1699/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3919\n",
      "Epoch [1699/2000], Avg Train Loss: 3.3919\n",
      "Epoch [1699/2000], Avg Val Loss: 2.3187\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4759\n",
      "Epoch [1700/2000], Avg Train Loss: 3.4759\n",
      "Epoch [1700/2000], Avg Val Loss: 2.3186\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1701/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4389\n",
      "Epoch [1701/2000], Avg Train Loss: 3.4389\n",
      "Epoch [1701/2000], Avg Val Loss: 2.3186\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1702/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3943\n",
      "Epoch [1702/2000], Avg Train Loss: 3.3943\n",
      "Epoch [1702/2000], Avg Val Loss: 2.3186\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1703/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4322\n",
      "Epoch [1703/2000], Avg Train Loss: 3.4322\n",
      "Epoch [1703/2000], Avg Val Loss: 2.3186\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1704/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4507\n",
      "Epoch [1704/2000], Avg Train Loss: 3.4507\n",
      "Epoch [1704/2000], Avg Val Loss: 2.3187\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1705/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4724\n",
      "Epoch [1705/2000], Avg Train Loss: 3.4724\n",
      "Epoch [1705/2000], Avg Val Loss: 2.3186\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1706/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4324\n",
      "Epoch [1706/2000], Avg Train Loss: 3.4324\n",
      "Epoch [1706/2000], Avg Val Loss: 2.3186\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3889\n",
      "Epoch [1707/2000], Avg Train Loss: 3.3889\n",
      "Epoch [1707/2000], Avg Val Loss: 2.3185\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1708/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4797\n",
      "Epoch [1708/2000], Avg Train Loss: 3.4797\n",
      "Epoch [1708/2000], Avg Val Loss: 2.3182\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1709/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4455\n",
      "Epoch [1709/2000], Avg Train Loss: 3.4455\n",
      "Epoch [1709/2000], Avg Val Loss: 2.3179\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1710/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4379\n",
      "Epoch [1710/2000], Avg Train Loss: 3.4379\n",
      "Epoch [1710/2000], Avg Val Loss: 2.3179\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1711/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4181\n",
      "Epoch [1711/2000], Avg Train Loss: 3.4181\n",
      "Epoch [1711/2000], Avg Val Loss: 2.3178\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1712/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4723\n",
      "Epoch [1712/2000], Avg Train Loss: 3.4723\n",
      "Epoch [1712/2000], Avg Val Loss: 2.3177\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1713/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4499\n",
      "Epoch [1713/2000], Avg Train Loss: 3.4499\n",
      "Epoch [1713/2000], Avg Val Loss: 2.3175\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4363\n",
      "Epoch [1714/2000], Avg Train Loss: 3.4363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1714/2000], Avg Val Loss: 2.3174\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1715/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4501\n",
      "Epoch [1715/2000], Avg Train Loss: 3.4501\n",
      "Epoch [1715/2000], Avg Val Loss: 2.3172\n",
      "Validation loss improved from 2.3172 to 2.3172. Saving model...\n",
      "\n",
      "LOG: Epoch [1716/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4217\n",
      "Epoch [1716/2000], Avg Train Loss: 3.4217\n",
      "Epoch [1716/2000], Avg Val Loss: 2.3169\n",
      "Validation loss improved from 2.3172 to 2.3169. Saving model...\n",
      "\n",
      "LOG: Epoch [1717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4371\n",
      "Epoch [1717/2000], Avg Train Loss: 3.4371\n",
      "Epoch [1717/2000], Avg Val Loss: 2.3166\n",
      "Validation loss improved from 2.3169 to 2.3166. Saving model...\n",
      "\n",
      "LOG: Epoch [1718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4144\n",
      "Epoch [1718/2000], Avg Train Loss: 3.4144\n",
      "Epoch [1718/2000], Avg Val Loss: 2.3164\n",
      "Validation loss improved from 2.3166 to 2.3164. Saving model...\n",
      "\n",
      "LOG: Epoch [1719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4307\n",
      "Epoch [1719/2000], Avg Train Loss: 3.4307\n",
      "Epoch [1719/2000], Avg Val Loss: 2.3162\n",
      "Validation loss improved from 2.3164 to 2.3162. Saving model...\n",
      "\n",
      "LOG: Epoch [1720/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4171\n",
      "Epoch [1720/2000], Avg Train Loss: 3.4171\n",
      "Epoch [1720/2000], Avg Val Loss: 2.3159\n",
      "Validation loss improved from 2.3162 to 2.3159. Saving model...\n",
      "\n",
      "LOG: Epoch [1721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4265\n",
      "Epoch [1721/2000], Avg Train Loss: 3.4265\n",
      "Epoch [1721/2000], Avg Val Loss: 2.3159\n",
      "Validation loss improved from 2.3159 to 2.3159. Saving model...\n",
      "\n",
      "LOG: Epoch [1722/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4478\n",
      "Epoch [1722/2000], Avg Train Loss: 3.4478\n",
      "Epoch [1722/2000], Avg Val Loss: 2.3159\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1723/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4506\n",
      "Epoch [1723/2000], Avg Train Loss: 3.4506\n",
      "Epoch [1723/2000], Avg Val Loss: 2.3161\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1724/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4307\n",
      "Epoch [1724/2000], Avg Train Loss: 3.4307\n",
      "Epoch [1724/2000], Avg Val Loss: 2.3164\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1725/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4313\n",
      "Epoch [1725/2000], Avg Train Loss: 3.4313\n",
      "Epoch [1725/2000], Avg Val Loss: 2.3167\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1726/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4547\n",
      "Epoch [1726/2000], Avg Train Loss: 3.4547\n",
      "Epoch [1726/2000], Avg Val Loss: 2.3170\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1727/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4690\n",
      "Epoch [1727/2000], Avg Train Loss: 3.4690\n",
      "Epoch [1727/2000], Avg Val Loss: 2.3173\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3812\n",
      "Epoch [1728/2000], Avg Train Loss: 3.3812\n",
      "Epoch [1728/2000], Avg Val Loss: 2.3175\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1729/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4102\n",
      "Epoch [1729/2000], Avg Train Loss: 3.4102\n",
      "Epoch [1729/2000], Avg Val Loss: 2.3178\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1730/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4223\n",
      "Epoch [1730/2000], Avg Train Loss: 3.4223\n",
      "Epoch [1730/2000], Avg Val Loss: 2.3180\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1731/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4240\n",
      "Epoch [1731/2000], Avg Train Loss: 3.4240\n",
      "Epoch [1731/2000], Avg Val Loss: 2.3184\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1732/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4020\n",
      "Epoch [1732/2000], Avg Train Loss: 3.4020\n",
      "Epoch [1732/2000], Avg Val Loss: 2.3188\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1733/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3963\n",
      "Epoch [1733/2000], Avg Train Loss: 3.3963\n",
      "Epoch [1733/2000], Avg Val Loss: 2.3192\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4447\n",
      "Epoch [1734/2000], Avg Train Loss: 3.4447\n",
      "Epoch [1734/2000], Avg Val Loss: 2.3195\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1735/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4159\n",
      "Epoch [1735/2000], Avg Train Loss: 3.4159\n",
      "Epoch [1735/2000], Avg Val Loss: 2.3196\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4541\n",
      "Epoch [1736/2000], Avg Train Loss: 3.4541\n",
      "Epoch [1736/2000], Avg Val Loss: 2.3199\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1737/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4360\n",
      "Epoch [1737/2000], Avg Train Loss: 3.4360\n",
      "Epoch [1737/2000], Avg Val Loss: 2.3201\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1738/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4253\n",
      "Epoch [1738/2000], Avg Train Loss: 3.4253\n",
      "Epoch [1738/2000], Avg Val Loss: 2.3201\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1739/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4063\n",
      "Epoch [1739/2000], Avg Train Loss: 3.4063\n",
      "Epoch [1739/2000], Avg Val Loss: 2.3201\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1740/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3994\n",
      "Epoch [1740/2000], Avg Train Loss: 3.3994\n",
      "Epoch [1740/2000], Avg Val Loss: 2.3200\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1741/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4029\n",
      "Epoch [1741/2000], Avg Train Loss: 3.4029\n",
      "Epoch [1741/2000], Avg Val Loss: 2.3198\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1742/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4183\n",
      "Epoch [1742/2000], Avg Train Loss: 3.4183\n",
      "Epoch [1742/2000], Avg Val Loss: 2.3195\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1743/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4072\n",
      "Epoch [1743/2000], Avg Train Loss: 3.4072\n",
      "Epoch [1743/2000], Avg Val Loss: 2.3193\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1744/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4036\n",
      "Epoch [1744/2000], Avg Train Loss: 3.4036\n",
      "Epoch [1744/2000], Avg Val Loss: 2.3189\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1745/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4390\n",
      "Epoch [1745/2000], Avg Train Loss: 3.4390\n",
      "Epoch [1745/2000], Avg Val Loss: 2.3186\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1746/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4552\n",
      "Epoch [1746/2000], Avg Train Loss: 3.4552\n",
      "Epoch [1746/2000], Avg Val Loss: 2.3181\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1747/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4201\n",
      "Epoch [1747/2000], Avg Train Loss: 3.4201\n",
      "Epoch [1747/2000], Avg Val Loss: 2.3176\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1748/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4594\n",
      "Epoch [1748/2000], Avg Train Loss: 3.4594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1748/2000], Avg Val Loss: 2.3171\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1749/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4071\n",
      "Epoch [1749/2000], Avg Train Loss: 3.4071\n",
      "Epoch [1749/2000], Avg Val Loss: 2.3168\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1750/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4201\n",
      "Epoch [1750/2000], Avg Train Loss: 3.4201\n",
      "Epoch [1750/2000], Avg Val Loss: 2.3164\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1751/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4092\n",
      "Epoch [1751/2000], Avg Train Loss: 3.4092\n",
      "Epoch [1751/2000], Avg Val Loss: 2.3161\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1752/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4317\n",
      "Epoch [1752/2000], Avg Train Loss: 3.4317\n",
      "Epoch [1752/2000], Avg Val Loss: 2.3158\n",
      "Validation loss improved from 2.3159 to 2.3158. Saving model...\n",
      "\n",
      "LOG: Epoch [1753/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3925\n",
      "Epoch [1753/2000], Avg Train Loss: 3.3925\n",
      "Epoch [1753/2000], Avg Val Loss: 2.3155\n",
      "Validation loss improved from 2.3158 to 2.3155. Saving model...\n",
      "\n",
      "LOG: Epoch [1754/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4442\n",
      "Epoch [1754/2000], Avg Train Loss: 3.4442\n",
      "Epoch [1754/2000], Avg Val Loss: 2.3151\n",
      "Validation loss improved from 2.3155 to 2.3151. Saving model...\n",
      "\n",
      "LOG: Epoch [1755/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4233\n",
      "Epoch [1755/2000], Avg Train Loss: 3.4233\n",
      "Epoch [1755/2000], Avg Val Loss: 2.3147\n",
      "Validation loss improved from 2.3151 to 2.3147. Saving model...\n",
      "\n",
      "LOG: Epoch [1756/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4146\n",
      "Epoch [1756/2000], Avg Train Loss: 3.4146\n",
      "Epoch [1756/2000], Avg Val Loss: 2.3146\n",
      "Validation loss improved from 2.3147 to 2.3146. Saving model...\n",
      "\n",
      "LOG: Epoch [1757/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4205\n",
      "Epoch [1757/2000], Avg Train Loss: 3.4205\n",
      "Epoch [1757/2000], Avg Val Loss: 2.3145\n",
      "Validation loss improved from 2.3146 to 2.3145. Saving model...\n",
      "\n",
      "LOG: Epoch [1758/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4167\n",
      "Epoch [1758/2000], Avg Train Loss: 3.4167\n",
      "Epoch [1758/2000], Avg Val Loss: 2.3145\n",
      "Validation loss improved from 2.3145 to 2.3145. Saving model...\n",
      "\n",
      "LOG: Epoch [1759/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4083\n",
      "Epoch [1759/2000], Avg Train Loss: 3.4083\n",
      "Epoch [1759/2000], Avg Val Loss: 2.3145\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1760/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4001\n",
      "Epoch [1760/2000], Avg Train Loss: 3.4001\n",
      "Epoch [1760/2000], Avg Val Loss: 2.3146\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1761/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4274\n",
      "Epoch [1761/2000], Avg Train Loss: 3.4274\n",
      "Epoch [1761/2000], Avg Val Loss: 2.3145\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1762/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3858\n",
      "Epoch [1762/2000], Avg Train Loss: 3.3858\n",
      "Epoch [1762/2000], Avg Val Loss: 2.3145\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1763/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4032\n",
      "Epoch [1763/2000], Avg Train Loss: 3.4032\n",
      "Epoch [1763/2000], Avg Val Loss: 2.3145\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1764/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4165\n",
      "Epoch [1764/2000], Avg Train Loss: 3.4165\n",
      "Epoch [1764/2000], Avg Val Loss: 2.3144\n",
      "Validation loss improved from 2.3145 to 2.3144. Saving model...\n",
      "\n",
      "LOG: Epoch [1765/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4343\n",
      "Epoch [1765/2000], Avg Train Loss: 3.4343\n",
      "Epoch [1765/2000], Avg Val Loss: 2.3145\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1766/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4159\n",
      "Epoch [1766/2000], Avg Train Loss: 3.4159\n",
      "Epoch [1766/2000], Avg Val Loss: 2.3147\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1767/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4292\n",
      "Epoch [1767/2000], Avg Train Loss: 3.4292\n",
      "Epoch [1767/2000], Avg Val Loss: 2.3149\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1768/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4386\n",
      "Epoch [1768/2000], Avg Train Loss: 3.4386\n",
      "Epoch [1768/2000], Avg Val Loss: 2.3152\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1769/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4053\n",
      "Epoch [1769/2000], Avg Train Loss: 3.4053\n",
      "Epoch [1769/2000], Avg Val Loss: 2.3154\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1770/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4504\n",
      "Epoch [1770/2000], Avg Train Loss: 3.4504\n",
      "Epoch [1770/2000], Avg Val Loss: 2.3156\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1771/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4624\n",
      "Epoch [1771/2000], Avg Train Loss: 3.4624\n",
      "Epoch [1771/2000], Avg Val Loss: 2.3156\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1772/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4560\n",
      "Epoch [1772/2000], Avg Train Loss: 3.4560\n",
      "Epoch [1772/2000], Avg Val Loss: 2.3156\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1773/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4295\n",
      "Epoch [1773/2000], Avg Train Loss: 3.4295\n",
      "Epoch [1773/2000], Avg Val Loss: 2.3154\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1774/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4189\n",
      "Epoch [1774/2000], Avg Train Loss: 3.4189\n",
      "Epoch [1774/2000], Avg Val Loss: 2.3153\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1775/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4284\n",
      "Epoch [1775/2000], Avg Train Loss: 3.4284\n",
      "Epoch [1775/2000], Avg Val Loss: 2.3153\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1776/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3530\n",
      "Epoch [1776/2000], Avg Train Loss: 3.3530\n",
      "Epoch [1776/2000], Avg Val Loss: 2.3153\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1777/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4431\n",
      "Epoch [1777/2000], Avg Train Loss: 3.4431\n",
      "Epoch [1777/2000], Avg Val Loss: 2.3155\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1778/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4845\n",
      "Epoch [1778/2000], Avg Train Loss: 3.4845\n",
      "Epoch [1778/2000], Avg Val Loss: 2.3156\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1779/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3960\n",
      "Epoch [1779/2000], Avg Train Loss: 3.3960\n",
      "Epoch [1779/2000], Avg Val Loss: 2.3157\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1780/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4233\n",
      "Epoch [1780/2000], Avg Train Loss: 3.4233\n",
      "Epoch [1780/2000], Avg Val Loss: 2.3157\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1781/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4093\n",
      "Epoch [1781/2000], Avg Train Loss: 3.4093\n",
      "Epoch [1781/2000], Avg Val Loss: 2.3158\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1782/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3985\n",
      "Epoch [1782/2000], Avg Train Loss: 3.3985\n",
      "Epoch [1782/2000], Avg Val Loss: 2.3160\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1783/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3868\n",
      "Epoch [1783/2000], Avg Train Loss: 3.3868\n",
      "Epoch [1783/2000], Avg Val Loss: 2.3162\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1784/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4044\n",
      "Epoch [1784/2000], Avg Train Loss: 3.4044\n",
      "Epoch [1784/2000], Avg Val Loss: 2.3162\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1785/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3878\n",
      "Epoch [1785/2000], Avg Train Loss: 3.3878\n",
      "Epoch [1785/2000], Avg Val Loss: 2.3164\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1786/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3929\n",
      "Epoch [1786/2000], Avg Train Loss: 3.3929\n",
      "Epoch [1786/2000], Avg Val Loss: 2.3165\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1787/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3848\n",
      "Epoch [1787/2000], Avg Train Loss: 3.3848\n",
      "Epoch [1787/2000], Avg Val Loss: 2.3167\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1788/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4016\n",
      "Epoch [1788/2000], Avg Train Loss: 3.4016\n",
      "Epoch [1788/2000], Avg Val Loss: 2.3168\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1789/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4030\n",
      "Epoch [1789/2000], Avg Train Loss: 3.4030\n",
      "Epoch [1789/2000], Avg Val Loss: 2.3171\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1790/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3962\n",
      "Epoch [1790/2000], Avg Train Loss: 3.3962\n",
      "Epoch [1790/2000], Avg Val Loss: 2.3173\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1791/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4032\n",
      "Epoch [1791/2000], Avg Train Loss: 3.4032\n",
      "Epoch [1791/2000], Avg Val Loss: 2.3176\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1792/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4181\n",
      "Epoch [1792/2000], Avg Train Loss: 3.4181\n",
      "Epoch [1792/2000], Avg Val Loss: 2.3180\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1793/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4086\n",
      "Epoch [1793/2000], Avg Train Loss: 3.4086\n",
      "Epoch [1793/2000], Avg Val Loss: 2.3184\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1794/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4537\n",
      "Epoch [1794/2000], Avg Train Loss: 3.4537\n",
      "Epoch [1794/2000], Avg Val Loss: 2.3187\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1795/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4379\n",
      "Epoch [1795/2000], Avg Train Loss: 3.4379\n",
      "Epoch [1795/2000], Avg Val Loss: 2.3188\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1796/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3856\n",
      "Epoch [1796/2000], Avg Train Loss: 3.3856\n",
      "Epoch [1796/2000], Avg Val Loss: 2.3188\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1797/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3742\n",
      "Epoch [1797/2000], Avg Train Loss: 3.3742\n",
      "Epoch [1797/2000], Avg Val Loss: 2.3188\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1798/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4265\n",
      "Epoch [1798/2000], Avg Train Loss: 3.4265\n",
      "Epoch [1798/2000], Avg Val Loss: 2.3185\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1799/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3879\n",
      "Epoch [1799/2000], Avg Train Loss: 3.3879\n",
      "Epoch [1799/2000], Avg Val Loss: 2.3182\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1800/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3664\n",
      "Epoch [1800/2000], Avg Train Loss: 3.3664\n",
      "Epoch [1800/2000], Avg Val Loss: 2.3180\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1801/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4134\n",
      "Epoch [1801/2000], Avg Train Loss: 3.4134\n",
      "Epoch [1801/2000], Avg Val Loss: 2.3178\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1802/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4183\n",
      "Epoch [1802/2000], Avg Train Loss: 3.4183\n",
      "Epoch [1802/2000], Avg Val Loss: 2.3177\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1803/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3821\n",
      "Epoch [1803/2000], Avg Train Loss: 3.3821\n",
      "Epoch [1803/2000], Avg Val Loss: 2.3176\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1804/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3645\n",
      "Epoch [1804/2000], Avg Train Loss: 3.3645\n",
      "Epoch [1804/2000], Avg Val Loss: 2.3176\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1805/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4180\n",
      "Epoch [1805/2000], Avg Train Loss: 3.4180\n",
      "Epoch [1805/2000], Avg Val Loss: 2.3177\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1806/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3957\n",
      "Epoch [1806/2000], Avg Train Loss: 3.3957\n",
      "Epoch [1806/2000], Avg Val Loss: 2.3180\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1807/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4440\n",
      "Epoch [1807/2000], Avg Train Loss: 3.4440\n",
      "Epoch [1807/2000], Avg Val Loss: 2.3182\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1808/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4145\n",
      "Epoch [1808/2000], Avg Train Loss: 3.4145\n",
      "Epoch [1808/2000], Avg Val Loss: 2.3185\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1809/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3962\n",
      "Epoch [1809/2000], Avg Train Loss: 3.3962\n",
      "Epoch [1809/2000], Avg Val Loss: 2.3188\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1810/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3854\n",
      "Epoch [1810/2000], Avg Train Loss: 3.3854\n",
      "Epoch [1810/2000], Avg Val Loss: 2.3194\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1811/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3858\n",
      "Epoch [1811/2000], Avg Train Loss: 3.3858\n",
      "Epoch [1811/2000], Avg Val Loss: 2.3198\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1812/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3972\n",
      "Epoch [1812/2000], Avg Train Loss: 3.3972\n",
      "Epoch [1812/2000], Avg Val Loss: 2.3202\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1813/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3756\n",
      "Epoch [1813/2000], Avg Train Loss: 3.3756\n",
      "Epoch [1813/2000], Avg Val Loss: 2.3205\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1814/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4055\n",
      "Epoch [1814/2000], Avg Train Loss: 3.4055\n",
      "Epoch [1814/2000], Avg Val Loss: 2.3208\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1815/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4495\n",
      "Epoch [1815/2000], Avg Train Loss: 3.4495\n",
      "Epoch [1815/2000], Avg Val Loss: 2.3209\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1816/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4450\n",
      "Epoch [1816/2000], Avg Train Loss: 3.4450\n",
      "Epoch [1816/2000], Avg Val Loss: 2.3207\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1817/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3952\n",
      "Epoch [1817/2000], Avg Train Loss: 3.3952\n",
      "Epoch [1817/2000], Avg Val Loss: 2.3206\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1818/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3801\n",
      "Epoch [1818/2000], Avg Train Loss: 3.3801\n",
      "Epoch [1818/2000], Avg Val Loss: 2.3204\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1819/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3895\n",
      "Epoch [1819/2000], Avg Train Loss: 3.3895\n",
      "Epoch [1819/2000], Avg Val Loss: 2.3203\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1820/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3862\n",
      "Epoch [1820/2000], Avg Train Loss: 3.3862\n",
      "Epoch [1820/2000], Avg Val Loss: 2.3204\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1821/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3683\n",
      "Epoch [1821/2000], Avg Train Loss: 3.3683\n",
      "Epoch [1821/2000], Avg Val Loss: 2.3203\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1822/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4304\n",
      "Epoch [1822/2000], Avg Train Loss: 3.4304\n",
      "Epoch [1822/2000], Avg Val Loss: 2.3203\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1823/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3981\n",
      "Epoch [1823/2000], Avg Train Loss: 3.3981\n",
      "Epoch [1823/2000], Avg Val Loss: 2.3203\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1824/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4029\n",
      "Epoch [1824/2000], Avg Train Loss: 3.4029\n",
      "Epoch [1824/2000], Avg Val Loss: 2.3204\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1825/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3714\n",
      "Epoch [1825/2000], Avg Train Loss: 3.3714\n",
      "Epoch [1825/2000], Avg Val Loss: 2.3205\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1826/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4198\n",
      "Epoch [1826/2000], Avg Train Loss: 3.4198\n",
      "Epoch [1826/2000], Avg Val Loss: 2.3205\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1827/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3885\n",
      "Epoch [1827/2000], Avg Train Loss: 3.3885\n",
      "Epoch [1827/2000], Avg Val Loss: 2.3205\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1828/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4258\n",
      "Epoch [1828/2000], Avg Train Loss: 3.4258\n",
      "Epoch [1828/2000], Avg Val Loss: 2.3207\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1829/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4112\n",
      "Epoch [1829/2000], Avg Train Loss: 3.4112\n",
      "Epoch [1829/2000], Avg Val Loss: 2.3209\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1830/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4175\n",
      "Epoch [1830/2000], Avg Train Loss: 3.4175\n",
      "Epoch [1830/2000], Avg Val Loss: 2.3209\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1831/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3708\n",
      "Epoch [1831/2000], Avg Train Loss: 3.3708\n",
      "Epoch [1831/2000], Avg Val Loss: 2.3209\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1832/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3853\n",
      "Epoch [1832/2000], Avg Train Loss: 3.3853\n",
      "Epoch [1832/2000], Avg Val Loss: 2.3209\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [1833/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3828\n",
      "Epoch [1833/2000], Avg Train Loss: 3.3828\n",
      "Epoch [1833/2000], Avg Val Loss: 2.3210\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [1834/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3752\n",
      "Epoch [1834/2000], Avg Train Loss: 3.3752\n",
      "Epoch [1834/2000], Avg Val Loss: 2.3210\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [1835/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4036\n",
      "Epoch [1835/2000], Avg Train Loss: 3.4036\n",
      "Epoch [1835/2000], Avg Val Loss: 2.3210\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [1836/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4358\n",
      "Epoch [1836/2000], Avg Train Loss: 3.4358\n",
      "Epoch [1836/2000], Avg Val Loss: 2.3211\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [1837/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3997\n",
      "Epoch [1837/2000], Avg Train Loss: 3.3997\n",
      "Epoch [1837/2000], Avg Val Loss: 2.3211\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [1838/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4478\n",
      "Epoch [1838/2000], Avg Train Loss: 3.4478\n",
      "Epoch [1838/2000], Avg Val Loss: 2.3210\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [1839/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3806\n",
      "Epoch [1839/2000], Avg Train Loss: 3.3806\n",
      "Epoch [1839/2000], Avg Val Loss: 2.3208\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [1840/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3781\n",
      "Epoch [1840/2000], Avg Train Loss: 3.3781\n",
      "Epoch [1840/2000], Avg Val Loss: 2.3206\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [1841/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3739\n",
      "Epoch [1841/2000], Avg Train Loss: 3.3739\n",
      "Epoch [1841/2000], Avg Val Loss: 2.3203\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [1842/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3615\n",
      "Epoch [1842/2000], Avg Train Loss: 3.3615\n",
      "Epoch [1842/2000], Avg Val Loss: 2.3201\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [1843/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4547\n",
      "Epoch [1843/2000], Avg Train Loss: 3.4547\n",
      "Epoch [1843/2000], Avg Val Loss: 2.3195\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [1844/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3614\n",
      "Epoch [1844/2000], Avg Train Loss: 3.3614\n",
      "Epoch [1844/2000], Avg Val Loss: 2.3189\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [1845/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3862\n",
      "Epoch [1845/2000], Avg Train Loss: 3.3862\n",
      "Epoch [1845/2000], Avg Val Loss: 2.3184\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [1846/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3775\n",
      "Epoch [1846/2000], Avg Train Loss: 3.3775\n",
      "Epoch [1846/2000], Avg Val Loss: 2.3181\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [1847/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3515\n",
      "Epoch [1847/2000], Avg Train Loss: 3.3515\n",
      "Epoch [1847/2000], Avg Val Loss: 2.3177\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [1848/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3588\n",
      "Epoch [1848/2000], Avg Train Loss: 3.3588\n",
      "Epoch [1848/2000], Avg Val Loss: 2.3173\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [1849/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3732\n",
      "Epoch [1849/2000], Avg Train Loss: 3.3732\n",
      "Epoch [1849/2000], Avg Val Loss: 2.3169\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [1850/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3832\n",
      "Epoch [1850/2000], Avg Train Loss: 3.3832\n",
      "Epoch [1850/2000], Avg Val Loss: 2.3164\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [1851/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3643\n",
      "Epoch [1851/2000], Avg Train Loss: 3.3643\n",
      "Epoch [1851/2000], Avg Val Loss: 2.3163\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [1852/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3954\n",
      "Epoch [1852/2000], Avg Train Loss: 3.3954\n",
      "Epoch [1852/2000], Avg Val Loss: 2.3160\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [1853/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3850\n",
      "Epoch [1853/2000], Avg Train Loss: 3.3850\n",
      "Epoch [1853/2000], Avg Val Loss: 2.3157\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [1854/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4036\n",
      "Epoch [1854/2000], Avg Train Loss: 3.4036\n",
      "Epoch [1854/2000], Avg Val Loss: 2.3155\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [1855/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3803\n",
      "Epoch [1855/2000], Avg Train Loss: 3.3803\n",
      "Epoch [1855/2000], Avg Val Loss: 2.3152\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [1856/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3898\n",
      "Epoch [1856/2000], Avg Train Loss: 3.3898\n",
      "Epoch [1856/2000], Avg Val Loss: 2.3149\n",
      "Validation loss did not improve. Patience: 92/100\n",
      "\n",
      "LOG: Epoch [1857/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4131\n",
      "Epoch [1857/2000], Avg Train Loss: 3.4131\n",
      "Epoch [1857/2000], Avg Val Loss: 2.3147\n",
      "Validation loss did not improve. Patience: 93/100\n",
      "\n",
      "LOG: Epoch [1858/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3944\n",
      "Epoch [1858/2000], Avg Train Loss: 3.3944\n",
      "Epoch [1858/2000], Avg Val Loss: 2.3143\n",
      "Validation loss improved from 2.3144 to 2.3143. Saving model...\n",
      "\n",
      "LOG: Epoch [1859/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3700\n",
      "Epoch [1859/2000], Avg Train Loss: 3.3700\n",
      "Epoch [1859/2000], Avg Val Loss: 2.3140\n",
      "Validation loss improved from 2.3143 to 2.3140. Saving model...\n",
      "\n",
      "LOG: Epoch [1860/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4050\n",
      "Epoch [1860/2000], Avg Train Loss: 3.4050\n",
      "Epoch [1860/2000], Avg Val Loss: 2.3138\n",
      "Validation loss improved from 2.3140 to 2.3138. Saving model...\n",
      "\n",
      "LOG: Epoch [1861/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3879\n",
      "Epoch [1861/2000], Avg Train Loss: 3.3879\n",
      "Epoch [1861/2000], Avg Val Loss: 2.3136\n",
      "Validation loss improved from 2.3138 to 2.3136. Saving model...\n",
      "\n",
      "LOG: Epoch [1862/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3726\n",
      "Epoch [1862/2000], Avg Train Loss: 3.3726\n",
      "Epoch [1862/2000], Avg Val Loss: 2.3134\n",
      "Validation loss improved from 2.3136 to 2.3134. Saving model...\n",
      "\n",
      "LOG: Epoch [1863/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3584\n",
      "Epoch [1863/2000], Avg Train Loss: 3.3584\n",
      "Epoch [1863/2000], Avg Val Loss: 2.3133\n",
      "Validation loss improved from 2.3134 to 2.3133. Saving model...\n",
      "\n",
      "LOG: Epoch [1864/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3797\n",
      "Epoch [1864/2000], Avg Train Loss: 3.3797\n",
      "Epoch [1864/2000], Avg Val Loss: 2.3133\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1865/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4060\n",
      "Epoch [1865/2000], Avg Train Loss: 3.4060\n",
      "Epoch [1865/2000], Avg Val Loss: 2.3132\n",
      "Validation loss improved from 2.3133 to 2.3132. Saving model...\n",
      "\n",
      "LOG: Epoch [1866/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4223\n",
      "Epoch [1866/2000], Avg Train Loss: 3.4223\n",
      "Epoch [1866/2000], Avg Val Loss: 2.3132\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1867/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3624\n",
      "Epoch [1867/2000], Avg Train Loss: 3.3624\n",
      "Epoch [1867/2000], Avg Val Loss: 2.3132\n",
      "Validation loss improved from 2.3132 to 2.3132. Saving model...\n",
      "\n",
      "LOG: Epoch [1868/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4073\n",
      "Epoch [1868/2000], Avg Train Loss: 3.4073\n",
      "Epoch [1868/2000], Avg Val Loss: 2.3132\n",
      "Validation loss improved from 2.3132 to 2.3132. Saving model...\n",
      "\n",
      "LOG: Epoch [1869/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3935\n",
      "Epoch [1869/2000], Avg Train Loss: 3.3935\n",
      "Epoch [1869/2000], Avg Val Loss: 2.3132\n",
      "Validation loss improved from 2.3132 to 2.3132. Saving model...\n",
      "\n",
      "LOG: Epoch [1870/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3728\n",
      "Epoch [1870/2000], Avg Train Loss: 3.3728\n",
      "Epoch [1870/2000], Avg Val Loss: 2.3133\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1871/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3728\n",
      "Epoch [1871/2000], Avg Train Loss: 3.3728\n",
      "Epoch [1871/2000], Avg Val Loss: 2.3135\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1872/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3829\n",
      "Epoch [1872/2000], Avg Train Loss: 3.3829\n",
      "Epoch [1872/2000], Avg Val Loss: 2.3136\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1873/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4124\n",
      "Epoch [1873/2000], Avg Train Loss: 3.4124\n",
      "Epoch [1873/2000], Avg Val Loss: 2.3137\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1874/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3875\n",
      "Epoch [1874/2000], Avg Train Loss: 3.3875\n",
      "Epoch [1874/2000], Avg Val Loss: 2.3138\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1875/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4038\n",
      "Epoch [1875/2000], Avg Train Loss: 3.4038\n",
      "Epoch [1875/2000], Avg Val Loss: 2.3139\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1876/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3932\n",
      "Epoch [1876/2000], Avg Train Loss: 3.3932\n",
      "Epoch [1876/2000], Avg Val Loss: 2.3141\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1877/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4130\n",
      "Epoch [1877/2000], Avg Train Loss: 3.4130\n",
      "Epoch [1877/2000], Avg Val Loss: 2.3141\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1878/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4078\n",
      "Epoch [1878/2000], Avg Train Loss: 3.4078\n",
      "Epoch [1878/2000], Avg Val Loss: 2.3143\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1879/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3832\n",
      "Epoch [1879/2000], Avg Train Loss: 3.3832\n",
      "Epoch [1879/2000], Avg Val Loss: 2.3145\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1880/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3936\n",
      "Epoch [1880/2000], Avg Train Loss: 3.3936\n",
      "Epoch [1880/2000], Avg Val Loss: 2.3146\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1881/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3754\n",
      "Epoch [1881/2000], Avg Train Loss: 3.3754\n",
      "Epoch [1881/2000], Avg Val Loss: 2.3146\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1882/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3413\n",
      "Epoch [1882/2000], Avg Train Loss: 3.3413\n",
      "Epoch [1882/2000], Avg Val Loss: 2.3148\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1883/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3494\n",
      "Epoch [1883/2000], Avg Train Loss: 3.3494\n",
      "Epoch [1883/2000], Avg Val Loss: 2.3149\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1884/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3797\n",
      "Epoch [1884/2000], Avg Train Loss: 3.3797\n",
      "Epoch [1884/2000], Avg Val Loss: 2.3149\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1885/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3753\n",
      "Epoch [1885/2000], Avg Train Loss: 3.3753\n",
      "Epoch [1885/2000], Avg Val Loss: 2.3149\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1886/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3699\n",
      "Epoch [1886/2000], Avg Train Loss: 3.3699\n",
      "Epoch [1886/2000], Avg Val Loss: 2.3149\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1887/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3829\n",
      "Epoch [1887/2000], Avg Train Loss: 3.3829\n",
      "Epoch [1887/2000], Avg Val Loss: 2.3149\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1888/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3633\n",
      "Epoch [1888/2000], Avg Train Loss: 3.3633\n",
      "Epoch [1888/2000], Avg Val Loss: 2.3148\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1889/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3645\n",
      "Epoch [1889/2000], Avg Train Loss: 3.3645\n",
      "Epoch [1889/2000], Avg Val Loss: 2.3148\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1890/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3641\n",
      "Epoch [1890/2000], Avg Train Loss: 3.3641\n",
      "Epoch [1890/2000], Avg Val Loss: 2.3147\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1891/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3470\n",
      "Epoch [1891/2000], Avg Train Loss: 3.3470\n",
      "Epoch [1891/2000], Avg Val Loss: 2.3146\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1892/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4096\n",
      "Epoch [1892/2000], Avg Train Loss: 3.4096\n",
      "Epoch [1892/2000], Avg Val Loss: 2.3145\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1893/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3822\n",
      "Epoch [1893/2000], Avg Train Loss: 3.3822\n",
      "Epoch [1893/2000], Avg Val Loss: 2.3145\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1894/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3581\n",
      "Epoch [1894/2000], Avg Train Loss: 3.3581\n",
      "Epoch [1894/2000], Avg Val Loss: 2.3145\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1895/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4073\n",
      "Epoch [1895/2000], Avg Train Loss: 3.4073\n",
      "Epoch [1895/2000], Avg Val Loss: 2.3146\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1896/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3797\n",
      "Epoch [1896/2000], Avg Train Loss: 3.3797\n",
      "Epoch [1896/2000], Avg Val Loss: 2.3145\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1897/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3725\n",
      "Epoch [1897/2000], Avg Train Loss: 3.3725\n",
      "Epoch [1897/2000], Avg Val Loss: 2.3147\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1898/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3821\n",
      "Epoch [1898/2000], Avg Train Loss: 3.3821\n",
      "Epoch [1898/2000], Avg Val Loss: 2.3148\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1899/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3877\n",
      "Epoch [1899/2000], Avg Train Loss: 3.3877\n",
      "Epoch [1899/2000], Avg Val Loss: 2.3150\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1900/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3589\n",
      "Epoch [1900/2000], Avg Train Loss: 3.3589\n",
      "Epoch [1900/2000], Avg Val Loss: 2.3151\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1901/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3538\n",
      "Epoch [1901/2000], Avg Train Loss: 3.3538\n",
      "Epoch [1901/2000], Avg Val Loss: 2.3153\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1902/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4169\n",
      "Epoch [1902/2000], Avg Train Loss: 3.4169\n",
      "Epoch [1902/2000], Avg Val Loss: 2.3157\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1903/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3819\n",
      "Epoch [1903/2000], Avg Train Loss: 3.3819\n",
      "Epoch [1903/2000], Avg Val Loss: 2.3159\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1904/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3637\n",
      "Epoch [1904/2000], Avg Train Loss: 3.3637\n",
      "Epoch [1904/2000], Avg Val Loss: 2.3160\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1905/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3825\n",
      "Epoch [1905/2000], Avg Train Loss: 3.3825\n",
      "Epoch [1905/2000], Avg Val Loss: 2.3159\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1906/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3901\n",
      "Epoch [1906/2000], Avg Train Loss: 3.3901\n",
      "Epoch [1906/2000], Avg Val Loss: 2.3157\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1907/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3497\n",
      "Epoch [1907/2000], Avg Train Loss: 3.3497\n",
      "Epoch [1907/2000], Avg Val Loss: 2.3157\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1908/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3746\n",
      "Epoch [1908/2000], Avg Train Loss: 3.3746\n",
      "Epoch [1908/2000], Avg Val Loss: 2.3156\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1909/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3801\n",
      "Epoch [1909/2000], Avg Train Loss: 3.3801\n",
      "Epoch [1909/2000], Avg Val Loss: 2.3157\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1910/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3504\n",
      "Epoch [1910/2000], Avg Train Loss: 3.3504\n",
      "Epoch [1910/2000], Avg Val Loss: 2.3158\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1911/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4130\n",
      "Epoch [1911/2000], Avg Train Loss: 3.4130\n",
      "Epoch [1911/2000], Avg Val Loss: 2.3158\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1912/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4269\n",
      "Epoch [1912/2000], Avg Train Loss: 3.4269\n",
      "Epoch [1912/2000], Avg Val Loss: 2.3157\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1913/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3769\n",
      "Epoch [1913/2000], Avg Train Loss: 3.3769\n",
      "Epoch [1913/2000], Avg Val Loss: 2.3158\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1914/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3776\n",
      "Epoch [1914/2000], Avg Train Loss: 3.3776\n",
      "Epoch [1914/2000], Avg Val Loss: 2.3159\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1915/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3720\n",
      "Epoch [1915/2000], Avg Train Loss: 3.3720\n",
      "Epoch [1915/2000], Avg Val Loss: 2.3160\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1916/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3955\n",
      "Epoch [1916/2000], Avg Train Loss: 3.3955\n",
      "Epoch [1916/2000], Avg Val Loss: 2.3160\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1917/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3937\n",
      "Epoch [1917/2000], Avg Train Loss: 3.3937\n",
      "Epoch [1917/2000], Avg Val Loss: 2.3160\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1918/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3378\n",
      "Epoch [1918/2000], Avg Train Loss: 3.3378\n",
      "Epoch [1918/2000], Avg Val Loss: 2.3161\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1919/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3671\n",
      "Epoch [1919/2000], Avg Train Loss: 3.3671\n",
      "Epoch [1919/2000], Avg Val Loss: 2.3163\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1920/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3931\n",
      "Epoch [1920/2000], Avg Train Loss: 3.3931\n",
      "Epoch [1920/2000], Avg Val Loss: 2.3164\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1921/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3518\n",
      "Epoch [1921/2000], Avg Train Loss: 3.3518\n",
      "Epoch [1921/2000], Avg Val Loss: 2.3165\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1922/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4007\n",
      "Epoch [1922/2000], Avg Train Loss: 3.4007\n",
      "Epoch [1922/2000], Avg Val Loss: 2.3168\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1923/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3764\n",
      "Epoch [1923/2000], Avg Train Loss: 3.3764\n",
      "Epoch [1923/2000], Avg Val Loss: 2.3169\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1924/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3811\n",
      "Epoch [1924/2000], Avg Train Loss: 3.3811\n",
      "Epoch [1924/2000], Avg Val Loss: 2.3171\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1925/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3877\n",
      "Epoch [1925/2000], Avg Train Loss: 3.3877\n",
      "Epoch [1925/2000], Avg Val Loss: 2.3173\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1926/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3910\n",
      "Epoch [1926/2000], Avg Train Loss: 3.3910\n",
      "Epoch [1926/2000], Avg Val Loss: 2.3176\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1927/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3447\n",
      "Epoch [1927/2000], Avg Train Loss: 3.3447\n",
      "Epoch [1927/2000], Avg Val Loss: 2.3179\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1928/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3781\n",
      "Epoch [1928/2000], Avg Train Loss: 3.3781\n",
      "Epoch [1928/2000], Avg Val Loss: 2.3181\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1929/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3764\n",
      "Epoch [1929/2000], Avg Train Loss: 3.3764\n",
      "Epoch [1929/2000], Avg Val Loss: 2.3183\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1930/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3846\n",
      "Epoch [1930/2000], Avg Train Loss: 3.3846\n",
      "Epoch [1930/2000], Avg Val Loss: 2.3183\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1931/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3408\n",
      "Epoch [1931/2000], Avg Train Loss: 3.3408\n",
      "Epoch [1931/2000], Avg Val Loss: 2.3183\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1932/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3653\n",
      "Epoch [1932/2000], Avg Train Loss: 3.3653\n",
      "Epoch [1932/2000], Avg Val Loss: 2.3182\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1933/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3458\n",
      "Epoch [1933/2000], Avg Train Loss: 3.3458\n",
      "Epoch [1933/2000], Avg Val Loss: 2.3182\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1934/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3993\n",
      "Epoch [1934/2000], Avg Train Loss: 3.3993\n",
      "Epoch [1934/2000], Avg Val Loss: 2.3180\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1935/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3394\n",
      "Epoch [1935/2000], Avg Train Loss: 3.3394\n",
      "Epoch [1935/2000], Avg Val Loss: 2.3178\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1936/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3654\n",
      "Epoch [1936/2000], Avg Train Loss: 3.3654\n",
      "Epoch [1936/2000], Avg Val Loss: 2.3176\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1937/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3707\n",
      "Epoch [1937/2000], Avg Train Loss: 3.3707\n",
      "Epoch [1937/2000], Avg Val Loss: 2.3175\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [1938/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3542\n",
      "Epoch [1938/2000], Avg Train Loss: 3.3542\n",
      "Epoch [1938/2000], Avg Val Loss: 2.3174\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [1939/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3634\n",
      "Epoch [1939/2000], Avg Train Loss: 3.3634\n",
      "Epoch [1939/2000], Avg Val Loss: 2.3173\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [1940/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3812\n",
      "Epoch [1940/2000], Avg Train Loss: 3.3812\n",
      "Epoch [1940/2000], Avg Val Loss: 2.3172\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [1941/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3850\n",
      "Epoch [1941/2000], Avg Train Loss: 3.3850\n",
      "Epoch [1941/2000], Avg Val Loss: 2.3171\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [1942/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3816\n",
      "Epoch [1942/2000], Avg Train Loss: 3.3816\n",
      "Epoch [1942/2000], Avg Val Loss: 2.3168\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [1943/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3582\n",
      "Epoch [1943/2000], Avg Train Loss: 3.3582\n",
      "Epoch [1943/2000], Avg Val Loss: 2.3165\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [1944/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3661\n",
      "Epoch [1944/2000], Avg Train Loss: 3.3661\n",
      "Epoch [1944/2000], Avg Val Loss: 2.3161\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [1945/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3541\n",
      "Epoch [1945/2000], Avg Train Loss: 3.3541\n",
      "Epoch [1945/2000], Avg Val Loss: 2.3157\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [1946/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3461\n",
      "Epoch [1946/2000], Avg Train Loss: 3.3461\n",
      "Epoch [1946/2000], Avg Val Loss: 2.3153\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [1947/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3696\n",
      "Epoch [1947/2000], Avg Train Loss: 3.3696\n",
      "Epoch [1947/2000], Avg Val Loss: 2.3149\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [1948/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3454\n",
      "Epoch [1948/2000], Avg Train Loss: 3.3454\n",
      "Epoch [1948/2000], Avg Val Loss: 2.3145\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [1949/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3677\n",
      "Epoch [1949/2000], Avg Train Loss: 3.3677\n",
      "Epoch [1949/2000], Avg Val Loss: 2.3140\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [1950/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3692\n",
      "Epoch [1950/2000], Avg Train Loss: 3.3692\n",
      "Epoch [1950/2000], Avg Val Loss: 2.3136\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [1951/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3553\n",
      "Epoch [1951/2000], Avg Train Loss: 3.3553\n",
      "Epoch [1951/2000], Avg Val Loss: 2.3130\n",
      "Validation loss improved from 2.3132 to 2.3130. Saving model...\n",
      "\n",
      "LOG: Epoch [1952/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3351\n",
      "Epoch [1952/2000], Avg Train Loss: 3.3351\n",
      "Epoch [1952/2000], Avg Val Loss: 2.3125\n",
      "Validation loss improved from 2.3130 to 2.3125. Saving model...\n",
      "\n",
      "LOG: Epoch [1953/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3696\n",
      "Epoch [1953/2000], Avg Train Loss: 3.3696\n",
      "Epoch [1953/2000], Avg Val Loss: 2.3121\n",
      "Validation loss improved from 2.3125 to 2.3121. Saving model...\n",
      "\n",
      "LOG: Epoch [1954/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3602\n",
      "Epoch [1954/2000], Avg Train Loss: 3.3602\n",
      "Epoch [1954/2000], Avg Val Loss: 2.3117\n",
      "Validation loss improved from 2.3121 to 2.3117. Saving model...\n",
      "\n",
      "LOG: Epoch [1955/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3756\n",
      "Epoch [1955/2000], Avg Train Loss: 3.3756\n",
      "Epoch [1955/2000], Avg Val Loss: 2.3114\n",
      "Validation loss improved from 2.3117 to 2.3114. Saving model...\n",
      "\n",
      "LOG: Epoch [1956/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3891\n",
      "Epoch [1956/2000], Avg Train Loss: 3.3891\n",
      "Epoch [1956/2000], Avg Val Loss: 2.3111\n",
      "Validation loss improved from 2.3114 to 2.3111. Saving model...\n",
      "\n",
      "LOG: Epoch [1957/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3549\n",
      "Epoch [1957/2000], Avg Train Loss: 3.3549\n",
      "Epoch [1957/2000], Avg Val Loss: 2.3110\n",
      "Validation loss improved from 2.3111 to 2.3110. Saving model...\n",
      "\n",
      "LOG: Epoch [1958/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3331\n",
      "Epoch [1958/2000], Avg Train Loss: 3.3331\n",
      "Epoch [1958/2000], Avg Val Loss: 2.3109\n",
      "Validation loss improved from 2.3110 to 2.3109. Saving model...\n",
      "\n",
      "LOG: Epoch [1959/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3499\n",
      "Epoch [1959/2000], Avg Train Loss: 3.3499\n",
      "Epoch [1959/2000], Avg Val Loss: 2.3107\n",
      "Validation loss improved from 2.3109 to 2.3107. Saving model...\n",
      "\n",
      "LOG: Epoch [1960/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3717\n",
      "Epoch [1960/2000], Avg Train Loss: 3.3717\n",
      "Epoch [1960/2000], Avg Val Loss: 2.3105\n",
      "Validation loss improved from 2.3107 to 2.3105. Saving model...\n",
      "\n",
      "LOG: Epoch [1961/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3808\n",
      "Epoch [1961/2000], Avg Train Loss: 3.3808\n",
      "Epoch [1961/2000], Avg Val Loss: 2.3105\n",
      "Validation loss improved from 2.3105 to 2.3105. Saving model...\n",
      "\n",
      "LOG: Epoch [1962/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3769\n",
      "Epoch [1962/2000], Avg Train Loss: 3.3769\n",
      "Epoch [1962/2000], Avg Val Loss: 2.3104\n",
      "Validation loss improved from 2.3105 to 2.3104. Saving model...\n",
      "\n",
      "LOG: Epoch [1963/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4034\n",
      "Epoch [1963/2000], Avg Train Loss: 3.4034\n",
      "Epoch [1963/2000], Avg Val Loss: 2.3105\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1964/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3642\n",
      "Epoch [1964/2000], Avg Train Loss: 3.3642\n",
      "Epoch [1964/2000], Avg Val Loss: 2.3105\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1965/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3406\n",
      "Epoch [1965/2000], Avg Train Loss: 3.3406\n",
      "Epoch [1965/2000], Avg Val Loss: 2.3103\n",
      "Validation loss improved from 2.3104 to 2.3103. Saving model...\n",
      "\n",
      "LOG: Epoch [1966/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3577\n",
      "Epoch [1966/2000], Avg Train Loss: 3.3577\n",
      "Epoch [1966/2000], Avg Val Loss: 2.3101\n",
      "Validation loss improved from 2.3103 to 2.3101. Saving model...\n",
      "\n",
      "LOG: Epoch [1967/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3716\n",
      "Epoch [1967/2000], Avg Train Loss: 3.3716\n",
      "Epoch [1967/2000], Avg Val Loss: 2.3099\n",
      "Validation loss improved from 2.3101 to 2.3099. Saving model...\n",
      "\n",
      "LOG: Epoch [1968/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3847\n",
      "Epoch [1968/2000], Avg Train Loss: 3.3847\n",
      "Epoch [1968/2000], Avg Val Loss: 2.3096\n",
      "Validation loss improved from 2.3099 to 2.3096. Saving model...\n",
      "\n",
      "LOG: Epoch [1969/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3278\n",
      "Epoch [1969/2000], Avg Train Loss: 3.3278\n",
      "Epoch [1969/2000], Avg Val Loss: 2.3093\n",
      "Validation loss improved from 2.3096 to 2.3093. Saving model...\n",
      "\n",
      "LOG: Epoch [1970/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3560\n",
      "Epoch [1970/2000], Avg Train Loss: 3.3560\n",
      "Epoch [1970/2000], Avg Val Loss: 2.3090\n",
      "Validation loss improved from 2.3093 to 2.3090. Saving model...\n",
      "\n",
      "LOG: Epoch [1971/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3426\n",
      "Epoch [1971/2000], Avg Train Loss: 3.3426\n",
      "Epoch [1971/2000], Avg Val Loss: 2.3088\n",
      "Validation loss improved from 2.3090 to 2.3088. Saving model...\n",
      "\n",
      "LOG: Epoch [1972/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3704\n",
      "Epoch [1972/2000], Avg Train Loss: 3.3704\n",
      "Epoch [1972/2000], Avg Val Loss: 2.3084\n",
      "Validation loss improved from 2.3088 to 2.3084. Saving model...\n",
      "\n",
      "LOG: Epoch [1973/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3421\n",
      "Epoch [1973/2000], Avg Train Loss: 3.3421\n",
      "Epoch [1973/2000], Avg Val Loss: 2.3080\n",
      "Validation loss improved from 2.3084 to 2.3080. Saving model...\n",
      "\n",
      "LOG: Epoch [1974/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3415\n",
      "Epoch [1974/2000], Avg Train Loss: 3.3415\n",
      "Epoch [1974/2000], Avg Val Loss: 2.3075\n",
      "Validation loss improved from 2.3080 to 2.3075. Saving model...\n",
      "\n",
      "LOG: Epoch [1975/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3691\n",
      "Epoch [1975/2000], Avg Train Loss: 3.3691\n",
      "Epoch [1975/2000], Avg Val Loss: 2.3071\n",
      "Validation loss improved from 2.3075 to 2.3071. Saving model...\n",
      "\n",
      "LOG: Epoch [1976/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3973\n",
      "Epoch [1976/2000], Avg Train Loss: 3.3973\n",
      "Epoch [1976/2000], Avg Val Loss: 2.3067\n",
      "Validation loss improved from 2.3071 to 2.3067. Saving model...\n",
      "\n",
      "LOG: Epoch [1977/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3462\n",
      "Epoch [1977/2000], Avg Train Loss: 3.3462\n",
      "Epoch [1977/2000], Avg Val Loss: 2.3065\n",
      "Validation loss improved from 2.3067 to 2.3065. Saving model...\n",
      "\n",
      "LOG: Epoch [1978/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3541\n",
      "Epoch [1978/2000], Avg Train Loss: 3.3541\n",
      "Epoch [1978/2000], Avg Val Loss: 2.3063\n",
      "Validation loss improved from 2.3065 to 2.3063. Saving model...\n",
      "\n",
      "LOG: Epoch [1979/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3617\n",
      "Epoch [1979/2000], Avg Train Loss: 3.3617\n",
      "Epoch [1979/2000], Avg Val Loss: 2.3060\n",
      "Validation loss improved from 2.3063 to 2.3060. Saving model...\n",
      "\n",
      "LOG: Epoch [1980/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3747\n",
      "Epoch [1980/2000], Avg Train Loss: 3.3747\n",
      "Epoch [1980/2000], Avg Val Loss: 2.3058\n",
      "Validation loss improved from 2.3060 to 2.3058. Saving model...\n",
      "\n",
      "LOG: Epoch [1981/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3852\n",
      "Epoch [1981/2000], Avg Train Loss: 3.3852\n",
      "Epoch [1981/2000], Avg Val Loss: 2.3058\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1982/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3772\n",
      "Epoch [1982/2000], Avg Train Loss: 3.3772\n",
      "Epoch [1982/2000], Avg Val Loss: 2.3059\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1983/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3672\n",
      "Epoch [1983/2000], Avg Train Loss: 3.3672\n",
      "Epoch [1983/2000], Avg Val Loss: 2.3061\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1984/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3498\n",
      "Epoch [1984/2000], Avg Train Loss: 3.3498\n",
      "Epoch [1984/2000], Avg Val Loss: 2.3063\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1985/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3279\n",
      "Epoch [1985/2000], Avg Train Loss: 3.3279\n",
      "Epoch [1985/2000], Avg Val Loss: 2.3066\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1986/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3541\n",
      "Epoch [1986/2000], Avg Train Loss: 3.3541\n",
      "Epoch [1986/2000], Avg Val Loss: 2.3071\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1987/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3387\n",
      "Epoch [1987/2000], Avg Train Loss: 3.3387\n",
      "Epoch [1987/2000], Avg Val Loss: 2.3075\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1988/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3714\n",
      "Epoch [1988/2000], Avg Train Loss: 3.3714\n",
      "Epoch [1988/2000], Avg Val Loss: 2.3079\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1989/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3884\n",
      "Epoch [1989/2000], Avg Train Loss: 3.3884\n",
      "Epoch [1989/2000], Avg Val Loss: 2.3084\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1990/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3939\n",
      "Epoch [1990/2000], Avg Train Loss: 3.3939\n",
      "Epoch [1990/2000], Avg Val Loss: 2.3088\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1991/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3481\n",
      "Epoch [1991/2000], Avg Train Loss: 3.3481\n",
      "Epoch [1991/2000], Avg Val Loss: 2.3091\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1992/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3197\n",
      "Epoch [1992/2000], Avg Train Loss: 3.3197\n",
      "Epoch [1992/2000], Avg Val Loss: 2.3095\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1993/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3584\n",
      "Epoch [1993/2000], Avg Train Loss: 3.3584\n",
      "Epoch [1993/2000], Avg Val Loss: 2.3099\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1994/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3557\n",
      "Epoch [1994/2000], Avg Train Loss: 3.3557\n",
      "Epoch [1994/2000], Avg Val Loss: 2.3102\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1995/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3528\n",
      "Epoch [1995/2000], Avg Train Loss: 3.3528\n",
      "Epoch [1995/2000], Avg Val Loss: 2.3103\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1996/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4133\n",
      "Epoch [1996/2000], Avg Train Loss: 3.4133\n",
      "Epoch [1996/2000], Avg Val Loss: 2.3104\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1997/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3233\n",
      "Epoch [1997/2000], Avg Train Loss: 3.3233\n",
      "Epoch [1997/2000], Avg Val Loss: 2.3104\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1998/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3366\n",
      "Epoch [1998/2000], Avg Train Loss: 3.3366\n",
      "Epoch [1998/2000], Avg Val Loss: 2.3105\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1999/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3387\n",
      "Epoch [1999/2000], Avg Train Loss: 3.3387\n",
      "Epoch [1999/2000], Avg Val Loss: 2.3107\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [2000/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3673\n",
      "Epoch [2000/2000], Avg Train Loss: 3.3673\n",
      "Epoch [2000/2000], Avg Val Loss: 2.3110\n",
      "Validation loss did not improve. Patience: 20/100\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_model = SupConNet().to(device)\n",
    "tscl_criterion = SupConLoss(temperature=0.07).to(device)\n",
    "tscl_optimizer = optim.Adam(tscl_model.parameters(), lr=1e-4, weight_decay=1e-5)  # Increased learning rate\n",
    "\n",
    "tscl_patience = 100\n",
    "tscl_best_val_loss = float('inf')\n",
    "tscl_epochs_without_improvement = 0\n",
    "\n",
    "tscl_num_epochs = 2000\n",
    "tscl_train_losses = []\n",
    "tscl_val_losses = []\n",
    "\n",
    "# TRAINING\n",
    "for tscl_epoch in range(tscl_num_epochs):\n",
    "    print(f\"\\nLOG: Epoch [{tscl_epoch + 1}/{tscl_num_epochs}] - Training\")\n",
    "    tscl_model.train()\n",
    "    tscl_total_loss = 0\n",
    "\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_train_loader):\n",
    "        vectors = vectors.to(device).float()  # moving input tensors to GPU\n",
    "        labels = labels.to(device)  # moving labels to GPU\n",
    "\n",
    "        # forward pass to get projections\n",
    "        projections = tscl_model(vectors)\n",
    "\n",
    "        # calc contrastive loss\n",
    "        loss = tscl_criterion(projections, labels)\n",
    "\n",
    "        # backprop and optimization\n",
    "        tscl_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        tscl_optimizer.step()\n",
    "\n",
    "        tscl_total_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 1 == 0:\n",
    "            print(f\"    Batch [{batch_idx + 1}/{len(tscl_train_loader)}], \"\n",
    "                  f\"Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc avg training loss for the epoch\n",
    "    tscl_avg_train_loss = tscl_total_loss / len(tscl_train_loader)\n",
    "    tscl_train_losses.append(tscl_avg_train_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {tscl_avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    tscl_model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (vectors, labels) in enumerate(tscl_val_loader):\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            projections = tscl_model(vectors)\n",
    "\n",
    "            loss = tscl_criterion(projections, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Batch [{batch_idx + 1}/{len(tscl_val_loader)}], \"\n",
    "                      f\"Val Loss: {loss.item():.4f}\")\n",
    "\n",
    "    tscl_avg_val_loss = total_val_loss / len(tscl_val_loader)\n",
    "    tscl_val_losses.append(tscl_avg_val_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Val Loss: {tscl_avg_val_loss:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if tscl_avg_val_loss < tscl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_best_val_loss:.4f} to {tscl_avg_val_loss:.4f}. Saving model...\")\n",
    "        tscl_best_val_loss = tscl_avg_val_loss\n",
    "        tscl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        tscl_epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {tscl_epochs_without_improvement}/{tscl_patience}\")\n",
    "\n",
    "    # stopping training if validation loss hasn't improved for patience amount of epochs\n",
    "    if tscl_epochs_without_improvement >= tscl_patience:\n",
    "        print(f\"Early stopping triggered at epoch {tscl_epoch + 1}. No improvement for {tscl_patience} epochs.\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(tscl_train_losses) + 1), tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, len(tscl_val_losses) + 1), tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:14.770895Z",
     "iopub.status.busy": "2025-05-08T19:18:14.770895Z",
     "iopub.status.idle": "2025-05-08T19:18:14.905278Z",
     "shell.execute_reply": "2025-05-08T19:18:14.905278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/12], Loss: 5.5426\n",
      "\n",
      "Test Loss: 5.2879\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "tscl_model.eval()\n",
    "total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = tscl_model(vectors)\n",
    "        loss = criterion(projections, labels)\n",
    "        total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(tscl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "avg_test_loss = total_test_loss / len(tscl_test_loader)\n",
    "print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs = range(1, len(tscl_train_losses) + 1)\n",
    "plt.plot(epochs, tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(epochs, tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving representations learnt by Typical SCL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:14.908283Z",
     "iopub.status.busy": "2025-05-08T19:18:14.907284Z",
     "iopub.status.idle": "2025-05-08T19:18:14.970551Z",
     "shell.execute_reply": "2025-05-08T19:18:14.970551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'tscl_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'tscl_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/12 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'tscl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "tscl_rep_dir = \"tscl_representations\"\n",
    "os.makedirs(tscl_rep_dir, exist_ok=True)\n",
    "\n",
    "tscl_loaders = {\n",
    "    'train': tscl_train_loader,\n",
    "    'val': tscl_val_loader,\n",
    "    'test': tscl_test_loader\n",
    "}\n",
    "\n",
    "tscl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_split_name, tscl_loader in tscl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {tscl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        tscl_split_dir = os.path.join(tscl_rep_dir, tscl_split_name)\n",
    "        os.makedirs(tscl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for tscl_batch_idx, (tscl_vectors, tscl_labels) in enumerate(tscl_loader):\n",
    "            tscl_vectors = tscl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            tscl_projections = tscl_model(tscl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            tscl_projections_np = tscl_projections.cpu().numpy()\n",
    "            tscl_labels_np = tscl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_encoded_batch_{tscl_batch_idx}.npy\"), tscl_projections_np)\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_labels_batch_{tscl_batch_idx}.npy\"), tscl_labels_np)\n",
    "            \n",
    "            if (tscl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {tscl_batch_idx + 1}/{len(tscl_loader)} for {tscl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {tscl_split_name} dataset. Representations saved in '{tscl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying representations learnt by SCL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:14.973645Z",
     "iopub.status.busy": "2025-05-08T19:18:14.972081Z",
     "iopub.status.idle": "2025-05-08T19:18:14.977694Z",
     "shell.execute_reply": "2025-05-08T19:18:14.977694Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_tscl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    tscl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    tscl_all_reps = []\n",
    "    tscl_all_labels = []\n",
    "\n",
    "    for tscl_rep_file in tscl_rep_files:\n",
    "        #deriving label filenames\n",
    "        tscl_label_file = tscl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        tscl_reps = np.load(tscl_rep_file)\n",
    "        tscl_labels = np.load(tscl_label_file)\n",
    "\n",
    "        tscl_all_reps.append(tscl_reps)\n",
    "        tscl_all_labels.append(tscl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    tscl_all_reps = np.concatenate(tscl_all_reps, axis = 0)\n",
    "    tscl_all_labels = np.concatenate(tscl_all_labels, axis = 0)\n",
    "\n",
    "    return tscl_all_reps, tscl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:14.979711Z",
     "iopub.status.busy": "2025-05-08T19:18:14.979711Z",
     "iopub.status.idle": "2025-05-08T19:18:15.115811Z",
     "shell.execute_reply": "2025-05-08T19:18:15.115811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (280, 128)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 128)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "tscl_lrm_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_lrm_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_lrm_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_lrm_train_reps, tscl_lrm_train_labels = load_tscl_reps_and_labels(tscl_lrm_train_dir)\n",
    "tscl_lrm_val_reps, tscl_lrm_val_labels = load_tscl_reps_and_labels(tscl_lrm_val_dir)\n",
    "tscl_lrm_test_reps, tscl_lrm_test_labels = load_tscl_reps_and_labels(tscl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", tscl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:15.118818Z",
     "iopub.status.busy": "2025-05-08T19:18:15.117816Z",
     "iopub.status.idle": "2025-05-08T19:18:15.166016Z",
     "shell.execute_reply": "2025-05-08T19:18:15.166016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 84.29%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       0.83      1.00      0.91         5\n",
      "           2       0.71      1.00      0.83         5\n",
      "           3       1.00      0.80      0.89         5\n",
      "           4       1.00      0.20      0.33         5\n",
      "           5       0.33      0.40      0.36         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       0.50      0.60      0.55         5\n",
      "           9       0.83      1.00      0.91         5\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      0.80      0.89         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.84        70\n",
      "   macro avg       0.87      0.84      0.83        70\n",
      "weighted avg       0.87      0.84      0.83        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 86.06%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       245\n",
      "           1       0.85      0.92      0.89        76\n",
      "           2       0.89      0.96      0.92       226\n",
      "           3       0.83      0.97      0.89       190\n",
      "           4       0.94      0.60      0.73       244\n",
      "           5       0.74      0.60      0.67       244\n",
      "           6       0.96      0.92      0.94       234\n",
      "           7       0.88      0.79      0.83       178\n",
      "           8       0.74      0.84      0.79       289\n",
      "           9       0.71      0.99      0.83       223\n",
      "          10       0.96      0.87      0.91       280\n",
      "          11       0.86      0.98      0.92       156\n",
      "          12       0.89      0.86      0.88       243\n",
      "          13       0.98      0.93      0.96        70\n",
      "\n",
      "    accuracy                           0.86      2898\n",
      "   macro avg       0.87      0.87      0.87      2898\n",
      "weighted avg       0.87      0.86      0.86      2898\n",
      "\n",
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# training LRM on the tscl representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "tscl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "tscl_logistic_clf.fit(tscl_lrm_train_reps, tscl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# eval on val set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "tscl_lrm_val_predictions = tscl_logistic_clf.predict(tscl_lrm_val_reps)\n",
    "tscl_lrm_val_accuracy = accuracy_score(tscl_lrm_val_labels, tscl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {tscl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(tscl_lrm_val_labels, tscl_lrm_val_predictions))\n",
    "\n",
    "# eval on test\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "tscl_lrm_test_predictions = tscl_logistic_clf.predict(tscl_lrm_test_reps)\n",
    "tscl_lrm_test_accuracy = accuracy_score(tscl_lrm_test_labels, tscl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {tscl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(tscl_lrm_test_labels, tscl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_predictions.npy'), tscl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_true_labels.npy'), tscl_lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by Typical SCL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:15.168023Z",
     "iopub.status.busy": "2025-05-08T19:18:15.168023Z",
     "iopub.status.idle": "2025-05-08T19:18:15.173600Z",
     "shell.execute_reply": "2025-05-08T19:18:15.173084Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:15.175613Z",
     "iopub.status.busy": "2025-05-08T19:18:15.175613Z",
     "iopub.status.idle": "2025-05-08T19:18:15.184122Z",
     "shell.execute_reply": "2025-05-08T19:18:15.184122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (280, 128)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 128)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "tscl_mlp_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_mlp_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_mlp_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_mlp_train_reps, tscl_mlp_train_labels = load_tscl_reps_and_labels(tscl_mlp_train_dir)\n",
    "tscl_mlp_val_reps, tscl_mlp_val_labels = load_tscl_reps_and_labels(tscl_mlp_val_dir)\n",
    "tscl_mlp_test_reps, tscl_mlp_test_labels = load_tscl_reps_and_labels(tscl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",tscl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:15.186126Z",
     "iopub.status.busy": "2025-05-08T19:18:15.186126Z",
     "iopub.status.idle": "2025-05-08T19:18:15.190595Z",
     "shell.execute_reply": "2025-05-08T19:18:15.190595Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "tscl_mlp_train_embeddings_torch = torch.tensor(tscl_mlp_train_reps, dtype=torch.float32)\n",
    "tscl_mlp_train_labels_torch = torch.tensor(tscl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_val_embeddings_torch = torch.tensor(tscl_mlp_val_reps, dtype=torch.float32)\n",
    "tscl_mlp_val_labels_torch = torch.tensor(tscl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_test_embeddings_torch = torch.tensor(tscl_mlp_test_reps, dtype=torch.float32)\n",
    "tscl_mlp_test_labels_torch = torch.tensor(tscl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "tscl_mlp_train_dataset = TensorDataset(tscl_mlp_train_embeddings_torch, tscl_mlp_train_labels_torch)\n",
    "tscl_mlp_val_dataset = TensorDataset(tscl_mlp_val_embeddings_torch, tscl_mlp_val_labels_torch)\n",
    "tscl_mlp_test_dataset = TensorDataset(tscl_mlp_test_embeddings_torch, tscl_mlp_test_labels_torch)\n",
    "\n",
    "tscl_mlp_batch_size = 64\n",
    "tscl_mlp_train_loader = DataLoader(tscl_mlp_train_dataset, batch_size=tscl_mlp_batch_size, shuffle=True)\n",
    "tscl_mlp_val_loader = DataLoader(tscl_mlp_val_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n",
    "tscl_mlp_test_loader = DataLoader(tscl_mlp_test_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:15.193600Z",
     "iopub.status.busy": "2025-05-08T19:18:15.192603Z",
     "iopub.status.idle": "2025-05-08T19:18:19.473409Z",
     "shell.execute_reply": "2025-05-08T19:18:19.473409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.7026  |  Val Loss: 2.6603\n",
      "Validation loss improved from inf to 2.6603.\n",
      "[Epoch 2/1000] Train Loss: 2.6624  |  Val Loss: 2.6244\n",
      "Validation loss improved from 2.6603 to 2.6244.\n",
      "[Epoch 3/1000] Train Loss: 2.6221  |  Val Loss: 2.5926\n",
      "Validation loss improved from 2.6244 to 2.5926.\n",
      "[Epoch 4/1000] Train Loss: 2.5895  |  Val Loss: 2.5668\n",
      "Validation loss improved from 2.5926 to 2.5668.\n",
      "[Epoch 5/1000] Train Loss: 2.5613  |  Val Loss: 2.5434\n",
      "Validation loss improved from 2.5668 to 2.5434.\n",
      "[Epoch 6/1000] Train Loss: 2.5363  |  Val Loss: 2.5219\n",
      "Validation loss improved from 2.5434 to 2.5219.\n",
      "[Epoch 7/1000] Train Loss: 2.5125  |  Val Loss: 2.5020\n",
      "Validation loss improved from 2.5219 to 2.5020.\n",
      "[Epoch 8/1000] Train Loss: 2.4904  |  Val Loss: 2.4815\n",
      "Validation loss improved from 2.5020 to 2.4815.\n",
      "[Epoch 9/1000] Train Loss: 2.4677  |  Val Loss: 2.4614\n",
      "Validation loss improved from 2.4815 to 2.4614.\n",
      "[Epoch 10/1000] Train Loss: 2.4447  |  Val Loss: 2.4412\n",
      "Validation loss improved from 2.4614 to 2.4412.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/1000] Train Loss: 2.4220  |  Val Loss: 2.4216\n",
      "Validation loss improved from 2.4412 to 2.4216.\n",
      "[Epoch 12/1000] Train Loss: 2.4012  |  Val Loss: 2.4023\n",
      "Validation loss improved from 2.4216 to 2.4023.\n",
      "[Epoch 13/1000] Train Loss: 2.3794  |  Val Loss: 2.3831\n",
      "Validation loss improved from 2.4023 to 2.3831.\n",
      "[Epoch 14/1000] Train Loss: 2.3591  |  Val Loss: 2.3637\n",
      "Validation loss improved from 2.3831 to 2.3637.\n",
      "[Epoch 15/1000] Train Loss: 2.3388  |  Val Loss: 2.3441\n",
      "Validation loss improved from 2.3637 to 2.3441.\n",
      "[Epoch 16/1000] Train Loss: 2.3178  |  Val Loss: 2.3253\n",
      "Validation loss improved from 2.3441 to 2.3253.\n",
      "[Epoch 17/1000] Train Loss: 2.2978  |  Val Loss: 2.3065\n",
      "Validation loss improved from 2.3253 to 2.3065.\n",
      "[Epoch 18/1000] Train Loss: 2.2777  |  Val Loss: 2.2875\n",
      "Validation loss improved from 2.3065 to 2.2875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/1000] Train Loss: 2.2571  |  Val Loss: 2.2692\n",
      "Validation loss improved from 2.2875 to 2.2692.\n",
      "[Epoch 20/1000] Train Loss: 2.2366  |  Val Loss: 2.2511\n",
      "Validation loss improved from 2.2692 to 2.2511.\n",
      "[Epoch 21/1000] Train Loss: 2.2163  |  Val Loss: 2.2329\n",
      "Validation loss improved from 2.2511 to 2.2329.\n",
      "[Epoch 22/1000] Train Loss: 2.1965  |  Val Loss: 2.2145\n",
      "Validation loss improved from 2.2329 to 2.2145.\n",
      "[Epoch 23/1000] Train Loss: 2.1761  |  Val Loss: 2.1961\n",
      "Validation loss improved from 2.2145 to 2.1961.\n",
      "[Epoch 24/1000] Train Loss: 2.1559  |  Val Loss: 2.1769\n",
      "Validation loss improved from 2.1961 to 2.1769.\n",
      "[Epoch 25/1000] Train Loss: 2.1353  |  Val Loss: 2.1578\n",
      "Validation loss improved from 2.1769 to 2.1578.\n",
      "[Epoch 26/1000] Train Loss: 2.1141  |  Val Loss: 2.1389\n",
      "Validation loss improved from 2.1578 to 2.1389.\n",
      "[Epoch 27/1000] Train Loss: 2.0934  |  Val Loss: 2.1199\n",
      "Validation loss improved from 2.1389 to 2.1199.\n",
      "[Epoch 28/1000] Train Loss: 2.0720  |  Val Loss: 2.1008\n",
      "Validation loss improved from 2.1199 to 2.1008.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29/1000] Train Loss: 2.0517  |  Val Loss: 2.0815\n",
      "Validation loss improved from 2.1008 to 2.0815.\n",
      "[Epoch 30/1000] Train Loss: 2.0299  |  Val Loss: 2.0628\n",
      "Validation loss improved from 2.0815 to 2.0628.\n",
      "[Epoch 31/1000] Train Loss: 2.0093  |  Val Loss: 2.0434\n",
      "Validation loss improved from 2.0628 to 2.0434.\n",
      "[Epoch 32/1000] Train Loss: 1.9880  |  Val Loss: 2.0241\n",
      "Validation loss improved from 2.0434 to 2.0241.\n",
      "[Epoch 33/1000] Train Loss: 1.9671  |  Val Loss: 2.0049\n",
      "Validation loss improved from 2.0241 to 2.0049.\n",
      "[Epoch 34/1000] Train Loss: 1.9457  |  Val Loss: 1.9863\n",
      "Validation loss improved from 2.0049 to 1.9863.\n",
      "[Epoch 35/1000] Train Loss: 1.9242  |  Val Loss: 1.9676\n",
      "Validation loss improved from 1.9863 to 1.9676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36/1000] Train Loss: 1.9033  |  Val Loss: 1.9484\n",
      "Validation loss improved from 1.9676 to 1.9484.\n",
      "[Epoch 37/1000] Train Loss: 1.8819  |  Val Loss: 1.9291\n",
      "Validation loss improved from 1.9484 to 1.9291.\n",
      "[Epoch 38/1000] Train Loss: 1.8612  |  Val Loss: 1.9094\n",
      "Validation loss improved from 1.9291 to 1.9094.\n",
      "[Epoch 39/1000] Train Loss: 1.8400  |  Val Loss: 1.8897\n",
      "Validation loss improved from 1.9094 to 1.8897.\n",
      "[Epoch 40/1000] Train Loss: 1.8188  |  Val Loss: 1.8703\n",
      "Validation loss improved from 1.8897 to 1.8703.\n",
      "[Epoch 41/1000] Train Loss: 1.7976  |  Val Loss: 1.8511\n",
      "Validation loss improved from 1.8703 to 1.8511.\n",
      "[Epoch 42/1000] Train Loss: 1.7761  |  Val Loss: 1.8317\n",
      "Validation loss improved from 1.8511 to 1.8317.\n",
      "[Epoch 43/1000] Train Loss: 1.7547  |  Val Loss: 1.8121\n",
      "Validation loss improved from 1.8317 to 1.8121.\n",
      "[Epoch 44/1000] Train Loss: 1.7340  |  Val Loss: 1.7927\n",
      "Validation loss improved from 1.8121 to 1.7927.\n",
      "[Epoch 45/1000] Train Loss: 1.7126  |  Val Loss: 1.7731\n",
      "Validation loss improved from 1.7927 to 1.7731.\n",
      "[Epoch 46/1000] Train Loss: 1.6912  |  Val Loss: 1.7537\n",
      "Validation loss improved from 1.7731 to 1.7537.\n",
      "[Epoch 47/1000] Train Loss: 1.6695  |  Val Loss: 1.7341\n",
      "Validation loss improved from 1.7537 to 1.7341.\n",
      "[Epoch 48/1000] Train Loss: 1.6481  |  Val Loss: 1.7145\n",
      "Validation loss improved from 1.7341 to 1.7145.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 49/1000] Train Loss: 1.6268  |  Val Loss: 1.6946\n",
      "Validation loss improved from 1.7145 to 1.6946.\n",
      "[Epoch 50/1000] Train Loss: 1.6052  |  Val Loss: 1.6746\n",
      "Validation loss improved from 1.6946 to 1.6746.\n",
      "[Epoch 51/1000] Train Loss: 1.5832  |  Val Loss: 1.6546\n",
      "Validation loss improved from 1.6746 to 1.6546.\n",
      "[Epoch 52/1000] Train Loss: 1.5607  |  Val Loss: 1.6347\n",
      "Validation loss improved from 1.6546 to 1.6347.\n",
      "[Epoch 53/1000] Train Loss: 1.5392  |  Val Loss: 1.6146\n",
      "Validation loss improved from 1.6347 to 1.6146.\n",
      "[Epoch 54/1000] Train Loss: 1.5177  |  Val Loss: 1.5946\n",
      "Validation loss improved from 1.6146 to 1.5946.\n",
      "[Epoch 55/1000] Train Loss: 1.4961  |  Val Loss: 1.5749\n",
      "Validation loss improved from 1.5946 to 1.5749.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 56/1000] Train Loss: 1.4749  |  Val Loss: 1.5553\n",
      "Validation loss improved from 1.5749 to 1.5553.\n",
      "[Epoch 57/1000] Train Loss: 1.4536  |  Val Loss: 1.5358\n",
      "Validation loss improved from 1.5553 to 1.5358.\n",
      "[Epoch 58/1000] Train Loss: 1.4328  |  Val Loss: 1.5164\n",
      "Validation loss improved from 1.5358 to 1.5164.\n",
      "[Epoch 59/1000] Train Loss: 1.4120  |  Val Loss: 1.4971\n",
      "Validation loss improved from 1.5164 to 1.4971.\n",
      "[Epoch 60/1000] Train Loss: 1.3916  |  Val Loss: 1.4777\n",
      "Validation loss improved from 1.4971 to 1.4777.\n",
      "[Epoch 61/1000] Train Loss: 1.3709  |  Val Loss: 1.4588\n",
      "Validation loss improved from 1.4777 to 1.4588.\n",
      "[Epoch 62/1000] Train Loss: 1.3504  |  Val Loss: 1.4396\n",
      "Validation loss improved from 1.4588 to 1.4396.\n",
      "[Epoch 63/1000] Train Loss: 1.3299  |  Val Loss: 1.4204\n",
      "Validation loss improved from 1.4396 to 1.4204.\n",
      "[Epoch 64/1000] Train Loss: 1.3092  |  Val Loss: 1.4020\n",
      "Validation loss improved from 1.4204 to 1.4020.\n",
      "[Epoch 65/1000] Train Loss: 1.2888  |  Val Loss: 1.3836\n",
      "Validation loss improved from 1.4020 to 1.3836.\n",
      "[Epoch 66/1000] Train Loss: 1.2690  |  Val Loss: 1.3652\n",
      "Validation loss improved from 1.3836 to 1.3652.\n",
      "[Epoch 67/1000] Train Loss: 1.2489  |  Val Loss: 1.3472\n",
      "Validation loss improved from 1.3652 to 1.3472.\n",
      "[Epoch 68/1000] Train Loss: 1.2291  |  Val Loss: 1.3294\n",
      "Validation loss improved from 1.3472 to 1.3294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 69/1000] Train Loss: 1.2099  |  Val Loss: 1.3116\n",
      "Validation loss improved from 1.3294 to 1.3116.\n",
      "[Epoch 70/1000] Train Loss: 1.1900  |  Val Loss: 1.2942\n",
      "Validation loss improved from 1.3116 to 1.2942.\n",
      "[Epoch 71/1000] Train Loss: 1.1705  |  Val Loss: 1.2771\n",
      "Validation loss improved from 1.2942 to 1.2771.\n",
      "[Epoch 72/1000] Train Loss: 1.1512  |  Val Loss: 1.2604\n",
      "Validation loss improved from 1.2771 to 1.2604.\n",
      "[Epoch 73/1000] Train Loss: 1.1329  |  Val Loss: 1.2436\n",
      "Validation loss improved from 1.2604 to 1.2436.\n",
      "[Epoch 74/1000] Train Loss: 1.1136  |  Val Loss: 1.2272\n",
      "Validation loss improved from 1.2436 to 1.2272.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 75/1000] Train Loss: 1.0949  |  Val Loss: 1.2109\n",
      "Validation loss improved from 1.2272 to 1.2109.\n",
      "[Epoch 76/1000] Train Loss: 1.0763  |  Val Loss: 1.1949\n",
      "Validation loss improved from 1.2109 to 1.1949.\n",
      "[Epoch 77/1000] Train Loss: 1.0579  |  Val Loss: 1.1792\n",
      "Validation loss improved from 1.1949 to 1.1792.\n",
      "[Epoch 78/1000] Train Loss: 1.0399  |  Val Loss: 1.1633\n",
      "Validation loss improved from 1.1792 to 1.1633.\n",
      "[Epoch 79/1000] Train Loss: 1.0220  |  Val Loss: 1.1475\n",
      "Validation loss improved from 1.1633 to 1.1475.\n",
      "[Epoch 80/1000] Train Loss: 1.0044  |  Val Loss: 1.1319\n",
      "Validation loss improved from 1.1475 to 1.1319.\n",
      "[Epoch 81/1000] Train Loss: 0.9871  |  Val Loss: 1.1169\n",
      "Validation loss improved from 1.1319 to 1.1169.\n",
      "[Epoch 82/1000] Train Loss: 0.9700  |  Val Loss: 1.1023\n",
      "Validation loss improved from 1.1169 to 1.1023.\n",
      "[Epoch 83/1000] Train Loss: 0.9528  |  Val Loss: 1.0879\n",
      "Validation loss improved from 1.1023 to 1.0879.\n",
      "[Epoch 84/1000] Train Loss: 0.9362  |  Val Loss: 1.0738\n",
      "Validation loss improved from 1.0879 to 1.0738.\n",
      "[Epoch 85/1000] Train Loss: 0.9198  |  Val Loss: 1.0598\n",
      "Validation loss improved from 1.0738 to 1.0598.\n",
      "[Epoch 86/1000] Train Loss: 0.9035  |  Val Loss: 1.0457\n",
      "Validation loss improved from 1.0598 to 1.0457.\n",
      "[Epoch 87/1000] Train Loss: 0.8875  |  Val Loss: 1.0317\n",
      "Validation loss improved from 1.0457 to 1.0317.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 88/1000] Train Loss: 0.8714  |  Val Loss: 1.0182\n",
      "Validation loss improved from 1.0317 to 1.0182.\n",
      "[Epoch 89/1000] Train Loss: 0.8557  |  Val Loss: 1.0055\n",
      "Validation loss improved from 1.0182 to 1.0055.\n",
      "[Epoch 90/1000] Train Loss: 0.8404  |  Val Loss: 0.9927\n",
      "Validation loss improved from 1.0055 to 0.9927.\n",
      "[Epoch 91/1000] Train Loss: 0.8254  |  Val Loss: 0.9800\n",
      "Validation loss improved from 0.9927 to 0.9800.\n",
      "[Epoch 92/1000] Train Loss: 0.8102  |  Val Loss: 0.9677\n",
      "Validation loss improved from 0.9800 to 0.9677.\n",
      "[Epoch 93/1000] Train Loss: 0.7952  |  Val Loss: 0.9556\n",
      "Validation loss improved from 0.9677 to 0.9556.\n",
      "[Epoch 94/1000] Train Loss: 0.7808  |  Val Loss: 0.9433\n",
      "Validation loss improved from 0.9556 to 0.9433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 95/1000] Train Loss: 0.7664  |  Val Loss: 0.9313\n",
      "Validation loss improved from 0.9433 to 0.9313.\n",
      "[Epoch 96/1000] Train Loss: 0.7525  |  Val Loss: 0.9195\n",
      "Validation loss improved from 0.9313 to 0.9195.\n",
      "[Epoch 97/1000] Train Loss: 0.7389  |  Val Loss: 0.9071\n",
      "Validation loss improved from 0.9195 to 0.9071.\n",
      "[Epoch 98/1000] Train Loss: 0.7249  |  Val Loss: 0.8943\n",
      "Validation loss improved from 0.9071 to 0.8943.\n",
      "[Epoch 99/1000] Train Loss: 0.7114  |  Val Loss: 0.8823\n",
      "Validation loss improved from 0.8943 to 0.8823.\n",
      "[Epoch 100/1000] Train Loss: 0.6981  |  Val Loss: 0.8717\n",
      "Validation loss improved from 0.8823 to 0.8717.\n",
      "[Epoch 101/1000] Train Loss: 0.6852  |  Val Loss: 0.8611\n",
      "Validation loss improved from 0.8717 to 0.8611.\n",
      "[Epoch 102/1000] Train Loss: 0.6724  |  Val Loss: 0.8512\n",
      "Validation loss improved from 0.8611 to 0.8512.\n",
      "[Epoch 103/1000] Train Loss: 0.6597  |  Val Loss: 0.8406\n",
      "Validation loss improved from 0.8512 to 0.8406.\n",
      "[Epoch 104/1000] Train Loss: 0.6469  |  Val Loss: 0.8305\n",
      "Validation loss improved from 0.8406 to 0.8305.\n",
      "[Epoch 105/1000] Train Loss: 0.6343  |  Val Loss: 0.8202\n",
      "Validation loss improved from 0.8305 to 0.8202.\n",
      "[Epoch 106/1000] Train Loss: 0.6221  |  Val Loss: 0.8094\n",
      "Validation loss improved from 0.8202 to 0.8094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 107/1000] Train Loss: 0.6103  |  Val Loss: 0.7991\n",
      "Validation loss improved from 0.8094 to 0.7991.\n",
      "[Epoch 108/1000] Train Loss: 0.5983  |  Val Loss: 0.7888\n",
      "Validation loss improved from 0.7991 to 0.7888.\n",
      "[Epoch 109/1000] Train Loss: 0.5866  |  Val Loss: 0.7799\n",
      "Validation loss improved from 0.7888 to 0.7799.\n",
      "[Epoch 110/1000] Train Loss: 0.5748  |  Val Loss: 0.7704\n",
      "Validation loss improved from 0.7799 to 0.7704.\n",
      "[Epoch 111/1000] Train Loss: 0.5634  |  Val Loss: 0.7611\n",
      "Validation loss improved from 0.7704 to 0.7611.\n",
      "[Epoch 112/1000] Train Loss: 0.5522  |  Val Loss: 0.7517\n",
      "Validation loss improved from 0.7611 to 0.7517.\n",
      "[Epoch 113/1000] Train Loss: 0.5413  |  Val Loss: 0.7424\n",
      "Validation loss improved from 0.7517 to 0.7424.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 114/1000] Train Loss: 0.5305  |  Val Loss: 0.7326\n",
      "Validation loss improved from 0.7424 to 0.7326.\n",
      "[Epoch 115/1000] Train Loss: 0.5194  |  Val Loss: 0.7240\n",
      "Validation loss improved from 0.7326 to 0.7240.\n",
      "[Epoch 116/1000] Train Loss: 0.5090  |  Val Loss: 0.7149\n",
      "Validation loss improved from 0.7240 to 0.7149.\n",
      "[Epoch 117/1000] Train Loss: 0.4988  |  Val Loss: 0.7061\n",
      "Validation loss improved from 0.7149 to 0.7061.\n",
      "[Epoch 118/1000] Train Loss: 0.4883  |  Val Loss: 0.6982\n",
      "Validation loss improved from 0.7061 to 0.6982.\n",
      "[Epoch 119/1000] Train Loss: 0.4781  |  Val Loss: 0.6911\n",
      "Validation loss improved from 0.6982 to 0.6911.\n",
      "[Epoch 120/1000] Train Loss: 0.4684  |  Val Loss: 0.6848\n",
      "Validation loss improved from 0.6911 to 0.6848.\n",
      "[Epoch 121/1000] Train Loss: 0.4588  |  Val Loss: 0.6775\n",
      "Validation loss improved from 0.6848 to 0.6775.\n",
      "[Epoch 122/1000] Train Loss: 0.4493  |  Val Loss: 0.6702\n",
      "Validation loss improved from 0.6775 to 0.6702.\n",
      "[Epoch 123/1000] Train Loss: 0.4401  |  Val Loss: 0.6625\n",
      "Validation loss improved from 0.6702 to 0.6625.\n",
      "[Epoch 124/1000] Train Loss: 0.4308  |  Val Loss: 0.6549\n",
      "Validation loss improved from 0.6625 to 0.6549.\n",
      "[Epoch 125/1000] Train Loss: 0.4220  |  Val Loss: 0.6475\n",
      "Validation loss improved from 0.6549 to 0.6475.\n",
      "[Epoch 126/1000] Train Loss: 0.4132  |  Val Loss: 0.6404\n",
      "Validation loss improved from 0.6475 to 0.6404.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 127/1000] Train Loss: 0.4041  |  Val Loss: 0.6328\n",
      "Validation loss improved from 0.6404 to 0.6328.\n",
      "[Epoch 128/1000] Train Loss: 0.3953  |  Val Loss: 0.6251\n",
      "Validation loss improved from 0.6328 to 0.6251.\n",
      "[Epoch 129/1000] Train Loss: 0.3866  |  Val Loss: 0.6177\n",
      "Validation loss improved from 0.6251 to 0.6177.\n",
      "[Epoch 130/1000] Train Loss: 0.3783  |  Val Loss: 0.6107\n",
      "Validation loss improved from 0.6177 to 0.6107.\n",
      "[Epoch 131/1000] Train Loss: 0.3700  |  Val Loss: 0.6032\n",
      "Validation loss improved from 0.6107 to 0.6032.\n",
      "[Epoch 132/1000] Train Loss: 0.3625  |  Val Loss: 0.5959\n",
      "Validation loss improved from 0.6032 to 0.5959.\n",
      "[Epoch 133/1000] Train Loss: 0.3548  |  Val Loss: 0.5896\n",
      "Validation loss improved from 0.5959 to 0.5896.\n",
      "[Epoch 134/1000] Train Loss: 0.3472  |  Val Loss: 0.5830\n",
      "Validation loss improved from 0.5896 to 0.5830.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 135/1000] Train Loss: 0.3401  |  Val Loss: 0.5781\n",
      "Validation loss improved from 0.5830 to 0.5781.\n",
      "[Epoch 136/1000] Train Loss: 0.3328  |  Val Loss: 0.5729\n",
      "Validation loss improved from 0.5781 to 0.5729.\n",
      "[Epoch 137/1000] Train Loss: 0.3260  |  Val Loss: 0.5681\n",
      "Validation loss improved from 0.5729 to 0.5681.\n",
      "[Epoch 138/1000] Train Loss: 0.3189  |  Val Loss: 0.5627\n",
      "Validation loss improved from 0.5681 to 0.5627.\n",
      "[Epoch 139/1000] Train Loss: 0.3123  |  Val Loss: 0.5576\n",
      "Validation loss improved from 0.5627 to 0.5576.\n",
      "[Epoch 140/1000] Train Loss: 0.3058  |  Val Loss: 0.5523\n",
      "Validation loss improved from 0.5576 to 0.5523.\n",
      "[Epoch 141/1000] Train Loss: 0.2995  |  Val Loss: 0.5482\n",
      "Validation loss improved from 0.5523 to 0.5482.\n",
      "[Epoch 142/1000] Train Loss: 0.2932  |  Val Loss: 0.5443\n",
      "Validation loss improved from 0.5482 to 0.5443.\n",
      "[Epoch 143/1000] Train Loss: 0.2871  |  Val Loss: 0.5403\n",
      "Validation loss improved from 0.5443 to 0.5403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 144/1000] Train Loss: 0.2811  |  Val Loss: 0.5358\n",
      "Validation loss improved from 0.5403 to 0.5358.\n",
      "[Epoch 145/1000] Train Loss: 0.2753  |  Val Loss: 0.5303\n",
      "Validation loss improved from 0.5358 to 0.5303.\n",
      "[Epoch 146/1000] Train Loss: 0.2695  |  Val Loss: 0.5247\n",
      "Validation loss improved from 0.5303 to 0.5247.\n",
      "[Epoch 147/1000] Train Loss: 0.2637  |  Val Loss: 0.5205\n",
      "Validation loss improved from 0.5247 to 0.5205.\n",
      "[Epoch 148/1000] Train Loss: 0.2581  |  Val Loss: 0.5161\n",
      "Validation loss improved from 0.5205 to 0.5161.\n",
      "[Epoch 149/1000] Train Loss: 0.2527  |  Val Loss: 0.5120\n",
      "Validation loss improved from 0.5161 to 0.5120.\n",
      "[Epoch 150/1000] Train Loss: 0.2474  |  Val Loss: 0.5076\n",
      "Validation loss improved from 0.5120 to 0.5076.\n",
      "[Epoch 151/1000] Train Loss: 0.2421  |  Val Loss: 0.5033\n",
      "Validation loss improved from 0.5076 to 0.5033.\n",
      "[Epoch 152/1000] Train Loss: 0.2370  |  Val Loss: 0.4985\n",
      "Validation loss improved from 0.5033 to 0.4985.\n",
      "[Epoch 153/1000] Train Loss: 0.2318  |  Val Loss: 0.4942\n",
      "Validation loss improved from 0.4985 to 0.4942.\n",
      "[Epoch 154/1000] Train Loss: 0.2269  |  Val Loss: 0.4904\n",
      "Validation loss improved from 0.4942 to 0.4904.\n",
      "[Epoch 155/1000] Train Loss: 0.2219  |  Val Loss: 0.4865\n",
      "Validation loss improved from 0.4904 to 0.4865.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 156/1000] Train Loss: 0.2173  |  Val Loss: 0.4823\n",
      "Validation loss improved from 0.4865 to 0.4823.\n",
      "[Epoch 157/1000] Train Loss: 0.2126  |  Val Loss: 0.4792\n",
      "Validation loss improved from 0.4823 to 0.4792.\n",
      "[Epoch 158/1000] Train Loss: 0.2081  |  Val Loss: 0.4761\n",
      "Validation loss improved from 0.4792 to 0.4761.\n",
      "[Epoch 159/1000] Train Loss: 0.2037  |  Val Loss: 0.4738\n",
      "Validation loss improved from 0.4761 to 0.4738.\n",
      "[Epoch 160/1000] Train Loss: 0.1995  |  Val Loss: 0.4705\n",
      "Validation loss improved from 0.4738 to 0.4705.\n",
      "[Epoch 161/1000] Train Loss: 0.1953  |  Val Loss: 0.4677\n",
      "Validation loss improved from 0.4705 to 0.4677.\n",
      "[Epoch 162/1000] Train Loss: 0.1912  |  Val Loss: 0.4649\n",
      "Validation loss improved from 0.4677 to 0.4649.\n",
      "[Epoch 163/1000] Train Loss: 0.1874  |  Val Loss: 0.4620\n",
      "Validation loss improved from 0.4649 to 0.4620.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 164/1000] Train Loss: 0.1836  |  Val Loss: 0.4581\n",
      "Validation loss improved from 0.4620 to 0.4581.\n",
      "[Epoch 165/1000] Train Loss: 0.1798  |  Val Loss: 0.4551\n",
      "Validation loss improved from 0.4581 to 0.4551.\n",
      "[Epoch 166/1000] Train Loss: 0.1763  |  Val Loss: 0.4522\n",
      "Validation loss improved from 0.4551 to 0.4522.\n",
      "[Epoch 167/1000] Train Loss: 0.1727  |  Val Loss: 0.4504\n",
      "Validation loss improved from 0.4522 to 0.4504.\n",
      "[Epoch 168/1000] Train Loss: 0.1691  |  Val Loss: 0.4479\n",
      "Validation loss improved from 0.4504 to 0.4479.\n",
      "[Epoch 169/1000] Train Loss: 0.1658  |  Val Loss: 0.4461\n",
      "Validation loss improved from 0.4479 to 0.4461.\n",
      "[Epoch 170/1000] Train Loss: 0.1625  |  Val Loss: 0.4437\n",
      "Validation loss improved from 0.4461 to 0.4437.\n",
      "[Epoch 171/1000] Train Loss: 0.1592  |  Val Loss: 0.4418\n",
      "Validation loss improved from 0.4437 to 0.4418.\n",
      "[Epoch 172/1000] Train Loss: 0.1562  |  Val Loss: 0.4398\n",
      "Validation loss improved from 0.4418 to 0.4398.\n",
      "[Epoch 173/1000] Train Loss: 0.1532  |  Val Loss: 0.4368\n",
      "Validation loss improved from 0.4398 to 0.4368.\n",
      "[Epoch 174/1000] Train Loss: 0.1503  |  Val Loss: 0.4338\n",
      "Validation loss improved from 0.4368 to 0.4338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 175/1000] Train Loss: 0.1474  |  Val Loss: 0.4313\n",
      "Validation loss improved from 0.4338 to 0.4313.\n",
      "[Epoch 176/1000] Train Loss: 0.1446  |  Val Loss: 0.4290\n",
      "Validation loss improved from 0.4313 to 0.4290.\n",
      "[Epoch 177/1000] Train Loss: 0.1419  |  Val Loss: 0.4267\n",
      "Validation loss improved from 0.4290 to 0.4267.\n",
      "[Epoch 178/1000] Train Loss: 0.1393  |  Val Loss: 0.4250\n",
      "Validation loss improved from 0.4267 to 0.4250.\n",
      "[Epoch 179/1000] Train Loss: 0.1367  |  Val Loss: 0.4234\n",
      "Validation loss improved from 0.4250 to 0.4234.\n",
      "[Epoch 180/1000] Train Loss: 0.1341  |  Val Loss: 0.4221\n",
      "Validation loss improved from 0.4234 to 0.4221.\n",
      "[Epoch 181/1000] Train Loss: 0.1317  |  Val Loss: 0.4211\n",
      "Validation loss improved from 0.4221 to 0.4211.\n",
      "[Epoch 182/1000] Train Loss: 0.1292  |  Val Loss: 0.4204\n",
      "Validation loss improved from 0.4211 to 0.4204.\n",
      "[Epoch 183/1000] Train Loss: 0.1270  |  Val Loss: 0.4201\n",
      "Validation loss improved from 0.4204 to 0.4201.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 184/1000] Train Loss: 0.1245  |  Val Loss: 0.4187\n",
      "Validation loss improved from 0.4201 to 0.4187.\n",
      "[Epoch 185/1000] Train Loss: 0.1223  |  Val Loss: 0.4175\n",
      "Validation loss improved from 0.4187 to 0.4175.\n",
      "[Epoch 186/1000] Train Loss: 0.1202  |  Val Loss: 0.4153\n",
      "Validation loss improved from 0.4175 to 0.4153.\n",
      "[Epoch 187/1000] Train Loss: 0.1181  |  Val Loss: 0.4126\n",
      "Validation loss improved from 0.4153 to 0.4126.\n",
      "[Epoch 188/1000] Train Loss: 0.1161  |  Val Loss: 0.4110\n",
      "Validation loss improved from 0.4126 to 0.4110.\n",
      "[Epoch 189/1000] Train Loss: 0.1139  |  Val Loss: 0.4095\n",
      "Validation loss improved from 0.4110 to 0.4095.\n",
      "[Epoch 190/1000] Train Loss: 0.1120  |  Val Loss: 0.4087\n",
      "Validation loss improved from 0.4095 to 0.4087.\n",
      "[Epoch 191/1000] Train Loss: 0.1100  |  Val Loss: 0.4070\n",
      "Validation loss improved from 0.4087 to 0.4070.\n",
      "[Epoch 192/1000] Train Loss: 0.1082  |  Val Loss: 0.4060\n",
      "Validation loss improved from 0.4070 to 0.4060.\n",
      "[Epoch 193/1000] Train Loss: 0.1064  |  Val Loss: 0.4049\n",
      "Validation loss improved from 0.4060 to 0.4049.\n",
      "[Epoch 194/1000] Train Loss: 0.1046  |  Val Loss: 0.4046\n",
      "Validation loss improved from 0.4049 to 0.4046.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 195/1000] Train Loss: 0.1029  |  Val Loss: 0.4042\n",
      "Validation loss improved from 0.4046 to 0.4042.\n",
      "[Epoch 196/1000] Train Loss: 0.1013  |  Val Loss: 0.4032\n",
      "Validation loss improved from 0.4042 to 0.4032.\n",
      "[Epoch 197/1000] Train Loss: 0.0996  |  Val Loss: 0.4027\n",
      "Validation loss improved from 0.4032 to 0.4027.\n",
      "[Epoch 198/1000] Train Loss: 0.0980  |  Val Loss: 0.4013\n",
      "Validation loss improved from 0.4027 to 0.4013.\n",
      "[Epoch 199/1000] Train Loss: 0.0965  |  Val Loss: 0.3998\n",
      "Validation loss improved from 0.4013 to 0.3998.\n",
      "[Epoch 200/1000] Train Loss: 0.0950  |  Val Loss: 0.3992\n",
      "Validation loss improved from 0.3998 to 0.3992.\n",
      "[Epoch 201/1000] Train Loss: 0.0934  |  Val Loss: 0.3980\n",
      "Validation loss improved from 0.3992 to 0.3980.\n",
      "[Epoch 202/1000] Train Loss: 0.0919  |  Val Loss: 0.3972\n",
      "Validation loss improved from 0.3980 to 0.3972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 203/1000] Train Loss: 0.0904  |  Val Loss: 0.3949\n",
      "Validation loss improved from 0.3972 to 0.3949.\n",
      "[Epoch 204/1000] Train Loss: 0.0890  |  Val Loss: 0.3939\n",
      "Validation loss improved from 0.3949 to 0.3939.\n",
      "[Epoch 205/1000] Train Loss: 0.0876  |  Val Loss: 0.3926\n",
      "Validation loss improved from 0.3939 to 0.3926.\n",
      "[Epoch 206/1000] Train Loss: 0.0864  |  Val Loss: 0.3917\n",
      "Validation loss improved from 0.3926 to 0.3917.\n",
      "[Epoch 207/1000] Train Loss: 0.0850  |  Val Loss: 0.3901\n",
      "Validation loss improved from 0.3917 to 0.3901.\n",
      "[Epoch 208/1000] Train Loss: 0.0837  |  Val Loss: 0.3890\n",
      "Validation loss improved from 0.3901 to 0.3890.\n",
      "[Epoch 209/1000] Train Loss: 0.0825  |  Val Loss: 0.3884\n",
      "Validation loss improved from 0.3890 to 0.3884.\n",
      "[Epoch 210/1000] Train Loss: 0.0812  |  Val Loss: 0.3881\n",
      "Validation loss improved from 0.3884 to 0.3881.\n",
      "[Epoch 211/1000] Train Loss: 0.0800  |  Val Loss: 0.3872\n",
      "Validation loss improved from 0.3881 to 0.3872.\n",
      "[Epoch 212/1000] Train Loss: 0.0788  |  Val Loss: 0.3868\n",
      "Validation loss improved from 0.3872 to 0.3868.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 213/1000] Train Loss: 0.0777  |  Val Loss: 0.3862\n",
      "Validation loss improved from 0.3868 to 0.3862.\n",
      "[Epoch 214/1000] Train Loss: 0.0766  |  Val Loss: 0.3862\n",
      "Validation loss improved from 0.3862 to 0.3862.\n",
      "[Epoch 215/1000] Train Loss: 0.0754  |  Val Loss: 0.3853\n",
      "Validation loss improved from 0.3862 to 0.3853.\n",
      "[Epoch 216/1000] Train Loss: 0.0743  |  Val Loss: 0.3847\n",
      "Validation loss improved from 0.3853 to 0.3847.\n",
      "[Epoch 217/1000] Train Loss: 0.0733  |  Val Loss: 0.3835\n",
      "Validation loss improved from 0.3847 to 0.3835.\n",
      "[Epoch 218/1000] Train Loss: 0.0722  |  Val Loss: 0.3816\n",
      "Validation loss improved from 0.3835 to 0.3816.\n",
      "[Epoch 219/1000] Train Loss: 0.0712  |  Val Loss: 0.3803\n",
      "Validation loss improved from 0.3816 to 0.3803.\n",
      "[Epoch 220/1000] Train Loss: 0.0702  |  Val Loss: 0.3802\n",
      "Validation loss improved from 0.3803 to 0.3802.\n",
      "[Epoch 221/1000] Train Loss: 0.0692  |  Val Loss: 0.3803\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 222/1000] Train Loss: 0.0683  |  Val Loss: 0.3805\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 223/1000] Train Loss: 0.0674  |  Val Loss: 0.3806\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 224/1000] Train Loss: 0.0664  |  Val Loss: 0.3807\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 225/1000] Train Loss: 0.0655  |  Val Loss: 0.3801\n",
      "Validation loss improved from 0.3802 to 0.3801.\n",
      "[Epoch 226/1000] Train Loss: 0.0647  |  Val Loss: 0.3805\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 227/1000] Train Loss: 0.0638  |  Val Loss: 0.3802\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 228/1000] Train Loss: 0.0629  |  Val Loss: 0.3804\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 229/1000] Train Loss: 0.0621  |  Val Loss: 0.3787\n",
      "Validation loss improved from 0.3801 to 0.3787.\n",
      "[Epoch 230/1000] Train Loss: 0.0612  |  Val Loss: 0.3786\n",
      "Validation loss improved from 0.3787 to 0.3786.\n",
      "[Epoch 231/1000] Train Loss: 0.0604  |  Val Loss: 0.3769\n",
      "Validation loss improved from 0.3786 to 0.3769.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 232/1000] Train Loss: 0.0597  |  Val Loss: 0.3755\n",
      "Validation loss improved from 0.3769 to 0.3755.\n",
      "[Epoch 233/1000] Train Loss: 0.0589  |  Val Loss: 0.3753\n",
      "Validation loss improved from 0.3755 to 0.3753.\n",
      "[Epoch 234/1000] Train Loss: 0.0582  |  Val Loss: 0.3742\n",
      "Validation loss improved from 0.3753 to 0.3742.\n",
      "[Epoch 235/1000] Train Loss: 0.0575  |  Val Loss: 0.3732\n",
      "Validation loss improved from 0.3742 to 0.3732.\n",
      "[Epoch 236/1000] Train Loss: 0.0567  |  Val Loss: 0.3728\n",
      "Validation loss improved from 0.3732 to 0.3728.\n",
      "[Epoch 237/1000] Train Loss: 0.0560  |  Val Loss: 0.3727\n",
      "Validation loss improved from 0.3728 to 0.3727.\n",
      "[Epoch 238/1000] Train Loss: 0.0553  |  Val Loss: 0.3729\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 239/1000] Train Loss: 0.0546  |  Val Loss: 0.3715\n",
      "Validation loss improved from 0.3727 to 0.3715.\n",
      "[Epoch 240/1000] Train Loss: 0.0539  |  Val Loss: 0.3712\n",
      "Validation loss improved from 0.3715 to 0.3712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 241/1000] Train Loss: 0.0533  |  Val Loss: 0.3714\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 242/1000] Train Loss: 0.0526  |  Val Loss: 0.3712\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 243/1000] Train Loss: 0.0520  |  Val Loss: 0.3717\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 244/1000] Train Loss: 0.0513  |  Val Loss: 0.3714\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 245/1000] Train Loss: 0.0507  |  Val Loss: 0.3710\n",
      "Validation loss improved from 0.3712 to 0.3710.\n",
      "[Epoch 246/1000] Train Loss: 0.0501  |  Val Loss: 0.3709\n",
      "Validation loss improved from 0.3710 to 0.3709.\n",
      "[Epoch 247/1000] Train Loss: 0.0495  |  Val Loss: 0.3713\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 248/1000] Train Loss: 0.0489  |  Val Loss: 0.3718\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 249/1000] Train Loss: 0.0484  |  Val Loss: 0.3722\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 250/1000] Train Loss: 0.0478  |  Val Loss: 0.3732\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 251/1000] Train Loss: 0.0472  |  Val Loss: 0.3725\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 252/1000] Train Loss: 0.0467  |  Val Loss: 0.3707\n",
      "Validation loss improved from 0.3709 to 0.3707.\n",
      "[Epoch 253/1000] Train Loss: 0.0461  |  Val Loss: 0.3692\n",
      "Validation loss improved from 0.3707 to 0.3692.\n",
      "[Epoch 254/1000] Train Loss: 0.0456  |  Val Loss: 0.3694\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 255/1000] Train Loss: 0.0452  |  Val Loss: 0.3698\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 256/1000] Train Loss: 0.0446  |  Val Loss: 0.3703\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 257/1000] Train Loss: 0.0442  |  Val Loss: 0.3699\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 258/1000] Train Loss: 0.0436  |  Val Loss: 0.3690\n",
      "Validation loss improved from 0.3692 to 0.3690.\n",
      "[Epoch 259/1000] Train Loss: 0.0431  |  Val Loss: 0.3687\n",
      "Validation loss improved from 0.3690 to 0.3687.\n",
      "[Epoch 260/1000] Train Loss: 0.0427  |  Val Loss: 0.3685\n",
      "Validation loss improved from 0.3687 to 0.3685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 261/1000] Train Loss: 0.0423  |  Val Loss: 0.3682\n",
      "Validation loss improved from 0.3685 to 0.3682.\n",
      "[Epoch 262/1000] Train Loss: 0.0418  |  Val Loss: 0.3680\n",
      "Validation loss improved from 0.3682 to 0.3680.\n",
      "[Epoch 263/1000] Train Loss: 0.0414  |  Val Loss: 0.3687\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 264/1000] Train Loss: 0.0409  |  Val Loss: 0.3679\n",
      "Validation loss improved from 0.3680 to 0.3679.\n",
      "[Epoch 265/1000] Train Loss: 0.0404  |  Val Loss: 0.3679\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 266/1000] Train Loss: 0.0400  |  Val Loss: 0.3672\n",
      "Validation loss improved from 0.3679 to 0.3672.\n",
      "[Epoch 267/1000] Train Loss: 0.0396  |  Val Loss: 0.3673\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 268/1000] Train Loss: 0.0392  |  Val Loss: 0.3672\n",
      "Validation loss improved from 0.3672 to 0.3672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 269/1000] Train Loss: 0.0388  |  Val Loss: 0.3669\n",
      "Validation loss improved from 0.3672 to 0.3669.\n",
      "[Epoch 270/1000] Train Loss: 0.0384  |  Val Loss: 0.3674\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 271/1000] Train Loss: 0.0380  |  Val Loss: 0.3682\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 272/1000] Train Loss: 0.0376  |  Val Loss: 0.3697\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 273/1000] Train Loss: 0.0373  |  Val Loss: 0.3705\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 274/1000] Train Loss: 0.0369  |  Val Loss: 0.3719\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 275/1000] Train Loss: 0.0365  |  Val Loss: 0.3716\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 276/1000] Train Loss: 0.0361  |  Val Loss: 0.3714\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 277/1000] Train Loss: 0.0357  |  Val Loss: 0.3706\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 278/1000] Train Loss: 0.0354  |  Val Loss: 0.3707\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 279/1000] Train Loss: 0.0350  |  Val Loss: 0.3711\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 280/1000] Train Loss: 0.0347  |  Val Loss: 0.3711\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 281/1000] Train Loss: 0.0343  |  Val Loss: 0.3709\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 282/1000] Train Loss: 0.0340  |  Val Loss: 0.3719\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 283/1000] Train Loss: 0.0337  |  Val Loss: 0.3719\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 284/1000] Train Loss: 0.0333  |  Val Loss: 0.3720\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 285/1000] Train Loss: 0.0330  |  Val Loss: 0.3721\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 286/1000] Train Loss: 0.0327  |  Val Loss: 0.3723\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 287/1000] Train Loss: 0.0324  |  Val Loss: 0.3723\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 288/1000] Train Loss: 0.0320  |  Val Loss: 0.3719\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 289/1000] Train Loss: 0.0318  |  Val Loss: 0.3708\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 290/1000] Train Loss: 0.0315  |  Val Loss: 0.3708\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 291/1000] Train Loss: 0.0312  |  Val Loss: 0.3701\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 292/1000] Train Loss: 0.0309  |  Val Loss: 0.3700\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 293/1000] Train Loss: 0.0306  |  Val Loss: 0.3701\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 294/1000] Train Loss: 0.0303  |  Val Loss: 0.3690\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 295/1000] Train Loss: 0.0300  |  Val Loss: 0.3691\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 296/1000] Train Loss: 0.0298  |  Val Loss: 0.3686\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 297/1000] Train Loss: 0.0295  |  Val Loss: 0.3691\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 298/1000] Train Loss: 0.0292  |  Val Loss: 0.3696\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 299/1000] Train Loss: 0.0289  |  Val Loss: 0.3700\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 300/1000] Train Loss: 0.0287  |  Val Loss: 0.3691\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 301/1000] Train Loss: 0.0284  |  Val Loss: 0.3685\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 302/1000] Train Loss: 0.0282  |  Val Loss: 0.3685\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 303/1000] Train Loss: 0.0279  |  Val Loss: 0.3687\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 304/1000] Train Loss: 0.0276  |  Val Loss: 0.3695\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 305/1000] Train Loss: 0.0274  |  Val Loss: 0.3707\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 306/1000] Train Loss: 0.0272  |  Val Loss: 0.3719\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 307/1000] Train Loss: 0.0270  |  Val Loss: 0.3722\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 308/1000] Train Loss: 0.0267  |  Val Loss: 0.3726\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 309/1000] Train Loss: 0.0265  |  Val Loss: 0.3731\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 310/1000] Train Loss: 0.0263  |  Val Loss: 0.3734\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 311/1000] Train Loss: 0.0260  |  Val Loss: 0.3737\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 312/1000] Train Loss: 0.0258  |  Val Loss: 0.3733\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 313/1000] Train Loss: 0.0256  |  Val Loss: 0.3721\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 314/1000] Train Loss: 0.0254  |  Val Loss: 0.3724\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 315/1000] Train Loss: 0.0252  |  Val Loss: 0.3734\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 316/1000] Train Loss: 0.0251  |  Val Loss: 0.3732\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 317/1000] Train Loss: 0.0247  |  Val Loss: 0.3734\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 318/1000] Train Loss: 0.0246  |  Val Loss: 0.3730\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 319/1000] Train Loss: 0.0243  |  Val Loss: 0.3733\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 320/1000] Train Loss: 0.0241  |  Val Loss: 0.3740\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 321/1000] Train Loss: 0.0239  |  Val Loss: 0.3744\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 322/1000] Train Loss: 0.0237  |  Val Loss: 0.3742\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 323/1000] Train Loss: 0.0235  |  Val Loss: 0.3743\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 324/1000] Train Loss: 0.0234  |  Val Loss: 0.3747\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 325/1000] Train Loss: 0.0232  |  Val Loss: 0.3753\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 326/1000] Train Loss: 0.0230  |  Val Loss: 0.3758\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 327/1000] Train Loss: 0.0228  |  Val Loss: 0.3761\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 328/1000] Train Loss: 0.0226  |  Val Loss: 0.3763\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 329/1000] Train Loss: 0.0224  |  Val Loss: 0.3755\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 330/1000] Train Loss: 0.0222  |  Val Loss: 0.3757\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 331/1000] Train Loss: 0.0221  |  Val Loss: 0.3753\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 332/1000] Train Loss: 0.0219  |  Val Loss: 0.3758\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 333/1000] Train Loss: 0.0217  |  Val Loss: 0.3761\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 334/1000] Train Loss: 0.0215  |  Val Loss: 0.3767\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 335/1000] Train Loss: 0.0214  |  Val Loss: 0.3769\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 336/1000] Train Loss: 0.0213  |  Val Loss: 0.3770\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 337/1000] Train Loss: 0.0211  |  Val Loss: 0.3773\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 338/1000] Train Loss: 0.0209  |  Val Loss: 0.3774\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 339/1000] Train Loss: 0.0208  |  Val Loss: 0.3777\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 340/1000] Train Loss: 0.0206  |  Val Loss: 0.3778\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 341/1000] Train Loss: 0.0204  |  Val Loss: 0.3782\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 342/1000] Train Loss: 0.0203  |  Val Loss: 0.3786\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 343/1000] Train Loss: 0.0201  |  Val Loss: 0.3776\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 344/1000] Train Loss: 0.0200  |  Val Loss: 0.3769\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 345/1000] Train Loss: 0.0198  |  Val Loss: 0.3766\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 346/1000] Train Loss: 0.0197  |  Val Loss: 0.3769\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 347/1000] Train Loss: 0.0195  |  Val Loss: 0.3775\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 348/1000] Train Loss: 0.0194  |  Val Loss: 0.3782\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 349/1000] Train Loss: 0.0193  |  Val Loss: 0.3789\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 350/1000] Train Loss: 0.0191  |  Val Loss: 0.3786\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 351/1000] Train Loss: 0.0190  |  Val Loss: 0.3780\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 352/1000] Train Loss: 0.0189  |  Val Loss: 0.3776\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 353/1000] Train Loss: 0.0187  |  Val Loss: 0.3777\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 354/1000] Train Loss: 0.0186  |  Val Loss: 0.3782\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 355/1000] Train Loss: 0.0184  |  Val Loss: 0.3783\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 356/1000] Train Loss: 0.0182  |  Val Loss: 0.3779\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 357/1000] Train Loss: 0.0181  |  Val Loss: 0.3779\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 358/1000] Train Loss: 0.0180  |  Val Loss: 0.3785\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 359/1000] Train Loss: 0.0179  |  Val Loss: 0.3782\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 360/1000] Train Loss: 0.0178  |  Val Loss: 0.3782\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 361/1000] Train Loss: 0.0176  |  Val Loss: 0.3787\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 362/1000] Train Loss: 0.0175  |  Val Loss: 0.3794\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 363/1000] Train Loss: 0.0174  |  Val Loss: 0.3789\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 364/1000] Train Loss: 0.0172  |  Val Loss: 0.3782\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 365/1000] Train Loss: 0.0171  |  Val Loss: 0.3772\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 366/1000] Train Loss: 0.0170  |  Val Loss: 0.3770\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 367/1000] Train Loss: 0.0169  |  Val Loss: 0.3770\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 368/1000] Train Loss: 0.0168  |  Val Loss: 0.3781\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 369/1000] Train Loss: 0.0166  |  Val Loss: 0.3788\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 369 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_input_dim = tscl_mlp_train_reps.shape[1]\n",
    "tscl_mlp_num_classes = len(torch.unique(tscl_mlp_train_labels_torch))\n",
    "tscl_mlp_model = MLPClassifier(tscl_mlp_input_dim, tscl_mlp_num_classes).to(device)\n",
    "\n",
    "tscl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "tscl_mlp_optimizer = optim.Adam(tscl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "tscl_mlp_num_epochs = 1000\n",
    "tscl_mlp_patience = 100\n",
    "\n",
    "tscl_mlp_train_losses = []\n",
    "tscl_mlp_val_losses = []\n",
    "\n",
    "tscl_mlp_best_val_loss = float('inf')\n",
    "tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for tscl_mlp_epoch in range(tscl_mlp_num_epochs):\n",
    "    # Training\n",
    "    tscl_mlp_model.train()\n",
    "    tscl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for tscl_mlp_embeddings_batch, tscl_mlp_labels_batch in tscl_mlp_train_loader:\n",
    "        tscl_mlp_embeddings_batch = tscl_mlp_embeddings_batch.to(device)\n",
    "        tscl_mlp_labels_batch = tscl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        tscl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        tscl_mlp_outputs = tscl_mlp_model(tscl_mlp_embeddings_batch)\n",
    "        tscl_mlp_loss = tscl_mlp_criterion(tscl_mlp_outputs, tscl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        tscl_mlp_loss.backward()\n",
    "        tscl_mlp_optimizer.step()\n",
    "        \n",
    "        tscl_mlp_train_running_loss += tscl_mlp_loss.item() * tscl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    tscl_mlp_epoch_train_loss = tscl_mlp_train_running_loss / len(tscl_mlp_train_loader.dataset)\n",
    "    tscl_mlp_train_losses.append(tscl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    tscl_mlp_model.eval()\n",
    "    tscl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for tscl_mlp_val_embeddings_batch, tscl_mlp_val_labels_batch in tscl_mlp_val_loader:\n",
    "            tscl_mlp_val_embeddings_batch = tscl_mlp_val_embeddings_batch.to(device)\n",
    "            tscl_mlp_val_labels_batch = tscl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            tscl_mlp_val_outputs = tscl_mlp_model(tscl_mlp_val_embeddings_batch)\n",
    "            tscl_mlp_val_loss = tscl_mlp_criterion(tscl_mlp_val_outputs, tscl_mlp_val_labels_batch)\n",
    "\n",
    "            tscl_mlp_val_running_loss += tscl_mlp_val_loss.item() * tscl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    tscl_mlp_epoch_val_loss = tscl_mlp_val_running_loss / len(tscl_mlp_val_loader.dataset)\n",
    "    tscl_mlp_val_losses.append(tscl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {tscl_mlp_epoch+1}/{tscl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {tscl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {tscl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if tscl_mlp_epoch_val_loss < tscl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_mlp_best_val_loss:.4f} to {tscl_mlp_epoch_val_loss:.4f}.\")\n",
    "        tscl_mlp_best_val_loss = tscl_mlp_epoch_val_loss\n",
    "        tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        tscl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {tscl_mlp_epochs_without_improvement}/{tscl_mlp_patience}\")\n",
    "        \n",
    "        if tscl_mlp_epochs_without_improvement >= tscl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {tscl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {tscl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(tscl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(tscl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:19.476923Z",
     "iopub.status.busy": "2025-05-08T19:18:19.475416Z",
     "iopub.status.idle": "2025-05-08T19:18:19.614005Z",
     "shell.execute_reply": "2025-05-08T19:18:19.614005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TSCL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.4733 | Test Accuracy: 86.68%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_model.eval()\n",
    "\n",
    "tscl_mlp_test_running_loss = 0.0\n",
    "tscl_mlp_test_correct = 0\n",
    "tscl_mlp_all_predictions = []\n",
    "tscl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_mlp_test_embeddings_batch, tscl_mlp_test_labels_batch in tscl_mlp_test_loader:\n",
    "        tscl_mlp_test_embeddings_batch = tscl_mlp_test_embeddings_batch.to(device)\n",
    "        tscl_mlp_test_labels_batch = tscl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        tscl_mlp_test_outputs = tscl_mlp_model(tscl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        tscl_mlp_test_loss_batch = tscl_mlp_criterion(tscl_mlp_test_outputs, tscl_mlp_test_labels_batch)\n",
    "        tscl_mlp_test_running_loss += tscl_mlp_test_loss_batch.item() * tscl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, tscl_mlp_test_predicted = torch.max(tscl_mlp_test_outputs, dim=1)\n",
    "        tscl_mlp_test_correct += (tscl_mlp_test_predicted == tscl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        tscl_mlp_all_predictions.extend(tscl_mlp_test_predicted.cpu().numpy())\n",
    "        tscl_mlp_all_true_labels.extend(tscl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_predictions.npy'), np.array(tscl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_true_labels.npy'), np.array(tscl_mlp_all_true_labels))\n",
    "print(f\"Saved TSCL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "tscl_mlp_epoch_test_loss = tscl_mlp_test_running_loss / len(tscl_mlp_test_loader.dataset)\n",
    "tscl_mlp_test_accuracy = tscl_mlp_test_correct / len(tscl_mlp_test_loader.dataset)\n",
    "\n",
    "tscl_mlp_test_accuracy_pct = tscl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {tscl_mlp_epoch_test_loss:.4f} | Test Accuracy: {tscl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "tscl_mlp_num_epochs_run = len(tscl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         [tscl_mlp_epoch_test_loss]*tscl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Supervised Contrastive Learning with Silhouette Distance Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:19.616895Z",
     "iopub.status.busy": "2025-05-08T19:18:19.615887Z",
     "iopub.status.idle": "2025-05-08T19:18:19.625411Z",
     "shell.execute_reply": "2025-05-08T19:18:19.625411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 280 samples with 64 features each\n",
      "LOG: Labels shape: (280,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2898 samples with 64 features each\n",
      "LOG: Labels shape: (2898,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (280, 64), \n",
      "Train labels shape: (280,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (70, 64), \n",
      "Val labels shape: (70,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (2898, 64), \n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "sclsdl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "sclsdl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "sclsdl_train_embeddings, sclsdl_train_labels = load_encoded_data(sclsdl_encoded_train_dir)\n",
    "sclsdl_val_embeddings, sclsdl_val_labels = load_encoded_data(sclsdl_encoded_val_dir)\n",
    "sclsdl_test_embeddings, sclsdl_test_labels = load_encoded_data(sclsdl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {sclsdl_train_embeddings.shape}, \\nTrain labels shape: {sclsdl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {sclsdl_val_embeddings.shape}, \\nVal labels shape: {sclsdl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {sclsdl_test_embeddings.shape}, \\nTest labels shape: {sclsdl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:19.627726Z",
     "iopub.status.busy": "2025-05-08T19:18:19.627726Z",
     "iopub.status.idle": "2025-05-08T19:18:19.638659Z",
     "shell.execute_reply": "2025-05-08T19:18:19.638659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20}\n",
      "Training batch size: 280\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "sclsdl_train_embeddings = sclsdl_train_embeddings.reshape(sclsdl_train_embeddings.shape[0], -1)\n",
    "sclsdl_val_embeddings = sclsdl_val_embeddings.reshape(sclsdl_val_embeddings.shape[0], -1)\n",
    "sclsdl_test_embeddings = sclsdl_test_embeddings.reshape(sclsdl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "sclsdl_train_mean = np.mean(sclsdl_train_embeddings, axis=0)\n",
    "sclsdl_train_std = np.std(sclsdl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "#sclsdl_train_embeddings = (sclsdl_train_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_val_embeddings = (sclsdl_val_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_test_embeddings = (sclsdl_test_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "\n",
    "sclsdl_train_dataset = TensorDataset(torch.tensor(sclsdl_train_embeddings, dtype=torch.float32), torch.tensor(sclsdl_train_labels, dtype=torch.long))\n",
    "sclsdl_val_dataset = TensorDataset(torch.tensor(sclsdl_val_embeddings, dtype=torch.float32), torch.tensor(sclsdl_val_labels, dtype=torch.long))\n",
    "sclsdl_test_dataset = TensorDataset(torch.tensor(sclsdl_test_embeddings, dtype=torch.float32), torch.tensor(sclsdl_test_labels, dtype=torch.long))\n",
    "\n",
    "\n",
    "sclsdl_m = 20\n",
    "sclsdl_num_classes = len(np.unique(sclsdl_train_labels))\n",
    "\n",
    "# calc theoretical required batch size\n",
    "sclsdl_required_batch_size = sclsdl_m * sclsdl_num_classes\n",
    "\n",
    "if sclsdl_required_batch_size > len(sclsdl_train_dataset):\n",
    "    sclsdl_max_possible_m = len(sclsdl_train_dataset) // sclsdl_num_classes\n",
    "    sclsdl_m = max(1, sclsdl_max_possible_m)\n",
    "    sclsdl_batch_size_train = sclsdl_m * sclsdl_num_classes\n",
    "else:\n",
    "    sclsdl_batch_size_train = sclsdl_required_batch_size\n",
    "\n",
    "sclsdl_sampler = MPerClassSampler(labels = sclsdl_train_labels, m = sclsdl_m, batch_size = sclsdl_batch_size_train, length_before_new_iter=len(sclsdl_train_dataset))\n",
    "sclsdl_train_loader = DataLoader(sclsdl_train_dataset, batch_size=sclsdl_batch_size_train, sampler=sclsdl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "sclsdl_dataloader_bs = 64\n",
    "sclsdl_val_loader = DataLoader(sclsdl_val_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "sclsdl_test_loader = DataLoader(sclsdl_test_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for sclsdl_X_batch, sclsdl_y_batch in sclsdl_train_loader:\n",
    "    sclsdl_unique, sclsdl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(sclsdl_unique, sclsdl_counts)))\n",
    "    print(f\"Training batch size: {sclsdl_batch_size_train}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:19.641665Z",
     "iopub.status.busy": "2025-05-08T19:18:19.640665Z",
     "iopub.status.idle": "2025-05-08T19:18:19.644546Z",
     "shell.execute_reply": "2025-05-08T19:18:19.644546Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.projection_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:19.646550Z",
     "iopub.status.busy": "2025-05-08T19:18:19.646550Z",
     "iopub.status.idle": "2025-05-08T19:18:19.653054Z",
     "shell.execute_reply": "2025-05-08T19:18:19.653054Z"
    }
   },
   "outputs": [],
   "source": [
    "class SilhouetteDistanceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SilhouetteDistanceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        return self.score(features, labels, True,True)\n",
    "\n",
    "    def score(self,X, labels,feature_norm=True, loss=False):\n",
    "        unique_labels = torch.unique(labels)\n",
    "        if feature_norm:\n",
    "            X= F.normalize(X, p=2, dim=1)\n",
    "\n",
    "\n",
    "        A, B = self._compute_distances(X, labels, unique_labels)\n",
    "\n",
    "        # A= scale*A\n",
    "        # B = (1-scale)*B\n",
    "        sil_samples = (B - A) / torch.clamp(torch.maximum(A, B), min=0.0001)\n",
    "\n",
    "        # nan values are for clusters of size 1, and should be 0\n",
    "        mean_sil_score = torch.mean(torch.nan_to_num(sil_samples))\n",
    "        if loss:\n",
    "            return (1 - mean_sil_score) / 2\n",
    "        else:\n",
    "            return mean_sil_score.item()\n",
    "\n",
    "\n",
    "    def _compute_distances(self,X, labels, unique_labels):\n",
    "        intra_dist = torch.zeros_like(labels, dtype=torch.float32)\n",
    "        inter_dist = torch.full_like(labels, torch.inf, dtype=torch.float32)\n",
    "\n",
    "        for i, label_a in enumerate(unique_labels):\n",
    "            cluster_indices_a = (labels == label_a)\n",
    "            subX_a = X[cluster_indices_a]\n",
    "\n",
    "\n",
    "            intra_distances_a = torch.cdist(subX_a, subX_a)\n",
    "            div = (subX_a.size(0) - 1) if subX_a.shape[0]>1 else 1\n",
    "            intra_dist[cluster_indices_a] = intra_distances_a.sum(dim=1) / div\n",
    "\n",
    "            for label_b in unique_labels[i + 1:]:\n",
    "                cluster_indices_b = (labels == label_b)\n",
    "                subX_b = X[cluster_indices_b]\n",
    "                inter_distances_ab = torch.cdist(subX_a, subX_b)\n",
    "                inter_distances_ba = torch.cdist(subX_b, subX_a)\n",
    "\n",
    "                inter_dist[cluster_indices_a] = torch.minimum(inter_distances_ab.mean(dim=1), inter_dist[cluster_indices_a])\n",
    "                inter_dist[cluster_indices_b] = torch.minimum(inter_distances_ba.mean(dim=1), inter_dist[cluster_indices_b])\n",
    "\n",
    "        return intra_dist, inter_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:18:19.656058Z",
     "iopub.status.busy": "2025-05-08T19:18:19.655058Z",
     "iopub.status.idle": "2025-05-08T19:26:43.263704Z",
     "shell.execute_reply": "2025-05-08T19:26:43.263704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Epoch [1/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4876\n",
      "LOG: Epoch [1/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4792\n",
      "    Batch [2/2], Val Loss: 0.2834\n",
      "Epoch [1/2000], Avg Train Loss: 0.4876, Avg Val Loss: 0.3813\n",
      "\n",
      "Validation loss improved from inf to 0.3813. Saving model...\n",
      "LOG: Epoch [2/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4841\n",
      "LOG: Epoch [2/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4792\n",
      "    Batch [2/2], Val Loss: 0.2828\n",
      "Epoch [2/2000], Avg Train Loss: 0.4841, Avg Val Loss: 0.3810\n",
      "\n",
      "Validation loss improved from 0.3813 to 0.3810. Saving model...\n",
      "LOG: Epoch [3/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4820\n",
      "LOG: Epoch [3/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4795\n",
      "    Batch [2/2], Val Loss: 0.2811\n",
      "Epoch [3/2000], Avg Train Loss: 0.4820, Avg Val Loss: 0.3803\n",
      "\n",
      "Validation loss improved from 0.3810 to 0.3803. Saving model...\n",
      "LOG: Epoch [4/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4835\n",
      "LOG: Epoch [4/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4797\n",
      "    Batch [2/2], Val Loss: 0.2791\n",
      "Epoch [4/2000], Avg Train Loss: 0.4835, Avg Val Loss: 0.3794\n",
      "\n",
      "Validation loss improved from 0.3803 to 0.3794. Saving model...\n",
      "LOG: Epoch [5/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4814\n",
      "LOG: Epoch [5/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4797\n",
      "    Batch [2/2], Val Loss: 0.2795\n",
      "Epoch [5/2000], Avg Train Loss: 0.4814, Avg Val Loss: 0.3796\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [6/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4779\n",
      "LOG: Epoch [6/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4795\n",
      "    Batch [2/2], Val Loss: 0.2807\n",
      "Epoch [6/2000], Avg Train Loss: 0.4779, Avg Val Loss: 0.3801\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [7/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4787\n",
      "LOG: Epoch [7/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4796\n",
      "    Batch [2/2], Val Loss: 0.2816\n",
      "Epoch [7/2000], Avg Train Loss: 0.4787, Avg Val Loss: 0.3806\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [8/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4778\n",
      "LOG: Epoch [8/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4795\n",
      "    Batch [2/2], Val Loss: 0.2811\n",
      "Epoch [8/2000], Avg Train Loss: 0.4778, Avg Val Loss: 0.3803\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [9/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4771\n",
      "LOG: Epoch [9/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4793\n",
      "    Batch [2/2], Val Loss: 0.2788\n",
      "Epoch [9/2000], Avg Train Loss: 0.4771, Avg Val Loss: 0.3791\n",
      "\n",
      "Validation loss improved from 0.3794 to 0.3791. Saving model...\n",
      "LOG: Epoch [10/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4743\n",
      "LOG: Epoch [10/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4795\n",
      "    Batch [2/2], Val Loss: 0.2759\n",
      "Epoch [10/2000], Avg Train Loss: 0.4743, Avg Val Loss: 0.3777\n",
      "\n",
      "Validation loss improved from 0.3791 to 0.3777. Saving model...\n",
      "LOG: Epoch [11/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4731\n",
      "LOG: Epoch [11/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4795\n",
      "    Batch [2/2], Val Loss: 0.2725\n",
      "Epoch [11/2000], Avg Train Loss: 0.4731, Avg Val Loss: 0.3760\n",
      "\n",
      "Validation loss improved from 0.3777 to 0.3760. Saving model...\n",
      "LOG: Epoch [12/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4731\n",
      "LOG: Epoch [12/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4796\n",
      "    Batch [2/2], Val Loss: 0.2666\n",
      "Epoch [12/2000], Avg Train Loss: 0.4731, Avg Val Loss: 0.3731\n",
      "\n",
      "Validation loss improved from 0.3760 to 0.3731. Saving model...\n",
      "LOG: Epoch [13/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4737\n",
      "LOG: Epoch [13/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4790\n",
      "    Batch [2/2], Val Loss: 0.2602\n",
      "Epoch [13/2000], Avg Train Loss: 0.4737, Avg Val Loss: 0.3696\n",
      "\n",
      "Validation loss improved from 0.3731 to 0.3696. Saving model...\n",
      "LOG: Epoch [14/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4678\n",
      "LOG: Epoch [14/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4783\n",
      "    Batch [2/2], Val Loss: 0.2553\n",
      "Epoch [14/2000], Avg Train Loss: 0.4678, Avg Val Loss: 0.3668\n",
      "\n",
      "Validation loss improved from 0.3696 to 0.3668. Saving model...\n",
      "LOG: Epoch [15/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4702\n",
      "LOG: Epoch [15/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4771\n",
      "    Batch [2/2], Val Loss: 0.2512\n",
      "Epoch [15/2000], Avg Train Loss: 0.4702, Avg Val Loss: 0.3642\n",
      "\n",
      "Validation loss improved from 0.3668 to 0.3642. Saving model...\n",
      "LOG: Epoch [16/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4694\n",
      "LOG: Epoch [16/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4760\n",
      "    Batch [2/2], Val Loss: 0.2470\n",
      "Epoch [16/2000], Avg Train Loss: 0.4694, Avg Val Loss: 0.3615\n",
      "\n",
      "Validation loss improved from 0.3642 to 0.3615. Saving model...\n",
      "LOG: Epoch [17/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4723\n",
      "LOG: Epoch [17/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4749\n",
      "    Batch [2/2], Val Loss: 0.2421\n",
      "Epoch [17/2000], Avg Train Loss: 0.4723, Avg Val Loss: 0.3585\n",
      "\n",
      "Validation loss improved from 0.3615 to 0.3585. Saving model...\n",
      "LOG: Epoch [18/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4674\n",
      "LOG: Epoch [18/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4743\n",
      "    Batch [2/2], Val Loss: 0.2365\n",
      "Epoch [18/2000], Avg Train Loss: 0.4674, Avg Val Loss: 0.3554\n",
      "\n",
      "Validation loss improved from 0.3585 to 0.3554. Saving model...\n",
      "LOG: Epoch [19/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4667\n",
      "LOG: Epoch [19/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4733\n",
      "    Batch [2/2], Val Loss: 0.2324\n",
      "Epoch [19/2000], Avg Train Loss: 0.4667, Avg Val Loss: 0.3528\n",
      "\n",
      "Validation loss improved from 0.3554 to 0.3528. Saving model...\n",
      "LOG: Epoch [20/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4631\n",
      "LOG: Epoch [20/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4724\n",
      "    Batch [2/2], Val Loss: 0.2306\n",
      "Epoch [20/2000], Avg Train Loss: 0.4631, Avg Val Loss: 0.3515\n",
      "\n",
      "Validation loss improved from 0.3528 to 0.3515. Saving model...\n",
      "LOG: Epoch [21/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4639\n",
      "LOG: Epoch [21/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4710\n",
      "    Batch [2/2], Val Loss: 0.2244\n",
      "Epoch [21/2000], Avg Train Loss: 0.4639, Avg Val Loss: 0.3477\n",
      "\n",
      "Validation loss improved from 0.3515 to 0.3477. Saving model...\n",
      "LOG: Epoch [22/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4637\n",
      "LOG: Epoch [22/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4689\n",
      "    Batch [2/2], Val Loss: 0.2162\n",
      "Epoch [22/2000], Avg Train Loss: 0.4637, Avg Val Loss: 0.3425\n",
      "\n",
      "Validation loss improved from 0.3477 to 0.3425. Saving model...\n",
      "LOG: Epoch [23/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4643\n",
      "LOG: Epoch [23/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4672\n",
      "    Batch [2/2], Val Loss: 0.2082\n",
      "Epoch [23/2000], Avg Train Loss: 0.4643, Avg Val Loss: 0.3377\n",
      "\n",
      "Validation loss improved from 0.3425 to 0.3377. Saving model...\n",
      "LOG: Epoch [24/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4586\n",
      "LOG: Epoch [24/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4667\n",
      "    Batch [2/2], Val Loss: 0.2018\n",
      "Epoch [24/2000], Avg Train Loss: 0.4586, Avg Val Loss: 0.3343\n",
      "\n",
      "Validation loss improved from 0.3377 to 0.3343. Saving model...\n",
      "LOG: Epoch [25/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4588\n",
      "LOG: Epoch [25/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4668\n",
      "    Batch [2/2], Val Loss: 0.1970\n",
      "Epoch [25/2000], Avg Train Loss: 0.4588, Avg Val Loss: 0.3319\n",
      "\n",
      "Validation loss improved from 0.3343 to 0.3319. Saving model...\n",
      "LOG: Epoch [26/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4603\n",
      "LOG: Epoch [26/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4666\n",
      "    Batch [2/2], Val Loss: 0.1936\n",
      "Epoch [26/2000], Avg Train Loss: 0.4603, Avg Val Loss: 0.3301\n",
      "\n",
      "Validation loss improved from 0.3319 to 0.3301. Saving model...\n",
      "LOG: Epoch [27/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4599\n",
      "LOG: Epoch [27/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4666\n",
      "    Batch [2/2], Val Loss: 0.1906\n",
      "Epoch [27/2000], Avg Train Loss: 0.4599, Avg Val Loss: 0.3286\n",
      "\n",
      "Validation loss improved from 0.3301 to 0.3286. Saving model...\n",
      "LOG: Epoch [28/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4569\n",
      "LOG: Epoch [28/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4669\n",
      "    Batch [2/2], Val Loss: 0.1880\n",
      "Epoch [28/2000], Avg Train Loss: 0.4569, Avg Val Loss: 0.3274\n",
      "\n",
      "Validation loss improved from 0.3286 to 0.3274. Saving model...\n",
      "LOG: Epoch [29/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4574\n",
      "LOG: Epoch [29/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4666\n",
      "    Batch [2/2], Val Loss: 0.1851\n",
      "Epoch [29/2000], Avg Train Loss: 0.4574, Avg Val Loss: 0.3259\n",
      "\n",
      "Validation loss improved from 0.3274 to 0.3259. Saving model...\n",
      "LOG: Epoch [30/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4551\n",
      "LOG: Epoch [30/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4663\n",
      "    Batch [2/2], Val Loss: 0.1829\n",
      "Epoch [30/2000], Avg Train Loss: 0.4551, Avg Val Loss: 0.3246\n",
      "\n",
      "Validation loss improved from 0.3259 to 0.3246. Saving model...\n",
      "LOG: Epoch [31/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4578\n",
      "LOG: Epoch [31/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4660\n",
      "    Batch [2/2], Val Loss: 0.1817\n",
      "Epoch [31/2000], Avg Train Loss: 0.4578, Avg Val Loss: 0.3238\n",
      "\n",
      "Validation loss improved from 0.3246 to 0.3238. Saving model...\n",
      "LOG: Epoch [32/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4537\n",
      "LOG: Epoch [32/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4656\n",
      "    Batch [2/2], Val Loss: 0.1812\n",
      "Epoch [32/2000], Avg Train Loss: 0.4537, Avg Val Loss: 0.3234\n",
      "\n",
      "Validation loss improved from 0.3238 to 0.3234. Saving model...\n",
      "LOG: Epoch [33/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4561\n",
      "LOG: Epoch [33/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4649\n",
      "    Batch [2/2], Val Loss: 0.1826\n",
      "Epoch [33/2000], Avg Train Loss: 0.4561, Avg Val Loss: 0.3237\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [34/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4543\n",
      "LOG: Epoch [34/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4640\n",
      "    Batch [2/2], Val Loss: 0.1842\n",
      "Epoch [34/2000], Avg Train Loss: 0.4543, Avg Val Loss: 0.3241\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [35/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4522\n",
      "LOG: Epoch [35/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4630\n",
      "    Batch [2/2], Val Loss: 0.1859\n",
      "Epoch [35/2000], Avg Train Loss: 0.4522, Avg Val Loss: 0.3245\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [36/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4508\n",
      "LOG: Epoch [36/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4616\n",
      "    Batch [2/2], Val Loss: 0.1875\n",
      "Epoch [36/2000], Avg Train Loss: 0.4508, Avg Val Loss: 0.3245\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [37/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4492\n",
      "LOG: Epoch [37/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4602\n",
      "    Batch [2/2], Val Loss: 0.1887\n",
      "Epoch [37/2000], Avg Train Loss: 0.4492, Avg Val Loss: 0.3245\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [38/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4502\n",
      "LOG: Epoch [38/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4589\n",
      "    Batch [2/2], Val Loss: 0.1902\n",
      "Epoch [38/2000], Avg Train Loss: 0.4502, Avg Val Loss: 0.3246\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [39/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4501\n",
      "LOG: Epoch [39/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4575\n",
      "    Batch [2/2], Val Loss: 0.1916\n",
      "Epoch [39/2000], Avg Train Loss: 0.4501, Avg Val Loss: 0.3245\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [40/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4508\n",
      "LOG: Epoch [40/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4559\n",
      "    Batch [2/2], Val Loss: 0.1927\n",
      "Epoch [40/2000], Avg Train Loss: 0.4508, Avg Val Loss: 0.3243\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [41/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4497\n",
      "LOG: Epoch [41/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4545\n",
      "    Batch [2/2], Val Loss: 0.1938\n",
      "Epoch [41/2000], Avg Train Loss: 0.4497, Avg Val Loss: 0.3241\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [42/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4459\n",
      "LOG: Epoch [42/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4531\n",
      "    Batch [2/2], Val Loss: 0.1948\n",
      "Epoch [42/2000], Avg Train Loss: 0.4459, Avg Val Loss: 0.3239\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [43/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4464\n",
      "LOG: Epoch [43/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4516\n",
      "    Batch [2/2], Val Loss: 0.1961\n",
      "Epoch [43/2000], Avg Train Loss: 0.4464, Avg Val Loss: 0.3239\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [44/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4484\n",
      "LOG: Epoch [44/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4503\n",
      "    Batch [2/2], Val Loss: 0.1972\n",
      "Epoch [44/2000], Avg Train Loss: 0.4484, Avg Val Loss: 0.3237\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [45/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4460\n",
      "LOG: Epoch [45/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4488\n",
      "    Batch [2/2], Val Loss: 0.1982\n",
      "Epoch [45/2000], Avg Train Loss: 0.4460, Avg Val Loss: 0.3235\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [46/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4440\n",
      "LOG: Epoch [46/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4474\n",
      "    Batch [2/2], Val Loss: 0.1993\n",
      "Epoch [46/2000], Avg Train Loss: 0.4440, Avg Val Loss: 0.3233\n",
      "\n",
      "Validation loss improved from 0.3234 to 0.3233. Saving model...\n",
      "LOG: Epoch [47/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4465\n",
      "LOG: Epoch [47/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4463\n",
      "    Batch [2/2], Val Loss: 0.2004\n",
      "Epoch [47/2000], Avg Train Loss: 0.4465, Avg Val Loss: 0.3233\n",
      "\n",
      "Validation loss improved from 0.3233 to 0.3233. Saving model...\n",
      "LOG: Epoch [48/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4450\n",
      "LOG: Epoch [48/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4450\n",
      "    Batch [2/2], Val Loss: 0.2016\n",
      "Epoch [48/2000], Avg Train Loss: 0.4450, Avg Val Loss: 0.3233\n",
      "\n",
      "Validation loss improved from 0.3233 to 0.3233. Saving model...\n",
      "LOG: Epoch [49/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4402\n",
      "LOG: Epoch [49/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4437\n",
      "    Batch [2/2], Val Loss: 0.2029\n",
      "Epoch [49/2000], Avg Train Loss: 0.4402, Avg Val Loss: 0.3233\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [50/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4399\n",
      "LOG: Epoch [50/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4424\n",
      "    Batch [2/2], Val Loss: 0.2041\n",
      "Epoch [50/2000], Avg Train Loss: 0.4399, Avg Val Loss: 0.3233\n",
      "\n",
      "Validation loss improved from 0.3233 to 0.3233. Saving model...\n",
      "LOG: Epoch [51/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4435\n",
      "LOG: Epoch [51/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4412\n",
      "    Batch [2/2], Val Loss: 0.2049\n",
      "Epoch [51/2000], Avg Train Loss: 0.4435, Avg Val Loss: 0.3230\n",
      "\n",
      "Validation loss improved from 0.3233 to 0.3230. Saving model...\n",
      "LOG: Epoch [52/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4381\n",
      "LOG: Epoch [52/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4401\n",
      "    Batch [2/2], Val Loss: 0.2056\n",
      "Epoch [52/2000], Avg Train Loss: 0.4381, Avg Val Loss: 0.3228\n",
      "\n",
      "Validation loss improved from 0.3230 to 0.3228. Saving model...\n",
      "LOG: Epoch [53/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4378\n",
      "LOG: Epoch [53/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4389\n",
      "    Batch [2/2], Val Loss: 0.2061\n",
      "Epoch [53/2000], Avg Train Loss: 0.4378, Avg Val Loss: 0.3225\n",
      "\n",
      "Validation loss improved from 0.3228 to 0.3225. Saving model...\n",
      "LOG: Epoch [54/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4423\n",
      "LOG: Epoch [54/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4380\n",
      "    Batch [2/2], Val Loss: 0.2066\n",
      "Epoch [54/2000], Avg Train Loss: 0.4423, Avg Val Loss: 0.3223\n",
      "\n",
      "Validation loss improved from 0.3225 to 0.3223. Saving model...\n",
      "LOG: Epoch [55/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4404\n",
      "LOG: Epoch [55/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4373\n",
      "    Batch [2/2], Val Loss: 0.2070\n",
      "Epoch [55/2000], Avg Train Loss: 0.4404, Avg Val Loss: 0.3221\n",
      "\n",
      "Validation loss improved from 0.3223 to 0.3221. Saving model...\n",
      "LOG: Epoch [56/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4360\n",
      "LOG: Epoch [56/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4363\n",
      "    Batch [2/2], Val Loss: 0.2077\n",
      "Epoch [56/2000], Avg Train Loss: 0.4360, Avg Val Loss: 0.3220\n",
      "\n",
      "Validation loss improved from 0.3221 to 0.3220. Saving model...\n",
      "LOG: Epoch [57/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4359\n",
      "LOG: Epoch [57/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4354\n",
      "    Batch [2/2], Val Loss: 0.2085\n",
      "Epoch [57/2000], Avg Train Loss: 0.4359, Avg Val Loss: 0.3220\n",
      "\n",
      "Validation loss improved from 0.3220 to 0.3220. Saving model...\n",
      "LOG: Epoch [58/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4354\n",
      "LOG: Epoch [58/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4345\n",
      "    Batch [2/2], Val Loss: 0.2093\n",
      "Epoch [58/2000], Avg Train Loss: 0.4354, Avg Val Loss: 0.3219\n",
      "\n",
      "Validation loss improved from 0.3220 to 0.3219. Saving model...\n",
      "LOG: Epoch [59/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4370\n",
      "LOG: Epoch [59/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4337\n",
      "    Batch [2/2], Val Loss: 0.2096\n",
      "Epoch [59/2000], Avg Train Loss: 0.4370, Avg Val Loss: 0.3216\n",
      "\n",
      "Validation loss improved from 0.3219 to 0.3216. Saving model...\n",
      "LOG: Epoch [60/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4391\n",
      "LOG: Epoch [60/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4329\n",
      "    Batch [2/2], Val Loss: 0.2096\n",
      "Epoch [60/2000], Avg Train Loss: 0.4391, Avg Val Loss: 0.3213\n",
      "\n",
      "Validation loss improved from 0.3216 to 0.3213. Saving model...\n",
      "LOG: Epoch [61/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4360\n",
      "LOG: Epoch [61/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4318\n",
      "    Batch [2/2], Val Loss: 0.2096\n",
      "Epoch [61/2000], Avg Train Loss: 0.4360, Avg Val Loss: 0.3207\n",
      "\n",
      "Validation loss improved from 0.3213 to 0.3207. Saving model...\n",
      "LOG: Epoch [62/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4380\n",
      "LOG: Epoch [62/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4308\n",
      "    Batch [2/2], Val Loss: 0.2091\n",
      "Epoch [62/2000], Avg Train Loss: 0.4380, Avg Val Loss: 0.3200\n",
      "\n",
      "Validation loss improved from 0.3207 to 0.3200. Saving model...\n",
      "LOG: Epoch [63/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4340\n",
      "LOG: Epoch [63/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4298\n",
      "    Batch [2/2], Val Loss: 0.2088\n",
      "Epoch [63/2000], Avg Train Loss: 0.4340, Avg Val Loss: 0.3193\n",
      "\n",
      "Validation loss improved from 0.3200 to 0.3193. Saving model...\n",
      "LOG: Epoch [64/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4346\n",
      "LOG: Epoch [64/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4285\n",
      "    Batch [2/2], Val Loss: 0.2084\n",
      "Epoch [64/2000], Avg Train Loss: 0.4346, Avg Val Loss: 0.3185\n",
      "\n",
      "Validation loss improved from 0.3193 to 0.3185. Saving model...\n",
      "LOG: Epoch [65/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4313\n",
      "LOG: Epoch [65/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4273\n",
      "    Batch [2/2], Val Loss: 0.2086\n",
      "Epoch [65/2000], Avg Train Loss: 0.4313, Avg Val Loss: 0.3180\n",
      "\n",
      "Validation loss improved from 0.3185 to 0.3180. Saving model...\n",
      "LOG: Epoch [66/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4277\n",
      "LOG: Epoch [66/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4262\n",
      "    Batch [2/2], Val Loss: 0.2087\n",
      "Epoch [66/2000], Avg Train Loss: 0.4277, Avg Val Loss: 0.3175\n",
      "\n",
      "Validation loss improved from 0.3180 to 0.3175. Saving model...\n",
      "LOG: Epoch [67/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4322\n",
      "LOG: Epoch [67/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4251\n",
      "    Batch [2/2], Val Loss: 0.2089\n",
      "Epoch [67/2000], Avg Train Loss: 0.4322, Avg Val Loss: 0.3170\n",
      "\n",
      "Validation loss improved from 0.3175 to 0.3170. Saving model...\n",
      "LOG: Epoch [68/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4337\n",
      "LOG: Epoch [68/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4240\n",
      "    Batch [2/2], Val Loss: 0.2089\n",
      "Epoch [68/2000], Avg Train Loss: 0.4337, Avg Val Loss: 0.3165\n",
      "\n",
      "Validation loss improved from 0.3170 to 0.3165. Saving model...\n",
      "LOG: Epoch [69/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4278\n",
      "LOG: Epoch [69/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4228\n",
      "    Batch [2/2], Val Loss: 0.2090\n",
      "Epoch [69/2000], Avg Train Loss: 0.4278, Avg Val Loss: 0.3159\n",
      "\n",
      "Validation loss improved from 0.3165 to 0.3159. Saving model...\n",
      "LOG: Epoch [70/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4277\n",
      "LOG: Epoch [70/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4218\n",
      "    Batch [2/2], Val Loss: 0.2085\n",
      "Epoch [70/2000], Avg Train Loss: 0.4277, Avg Val Loss: 0.3151\n",
      "\n",
      "Validation loss improved from 0.3159 to 0.3151. Saving model...\n",
      "LOG: Epoch [71/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4265\n",
      "LOG: Epoch [71/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4208\n",
      "    Batch [2/2], Val Loss: 0.2079\n",
      "Epoch [71/2000], Avg Train Loss: 0.4265, Avg Val Loss: 0.3144\n",
      "\n",
      "Validation loss improved from 0.3151 to 0.3144. Saving model...\n",
      "LOG: Epoch [72/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4292\n",
      "LOG: Epoch [72/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4200\n",
      "    Batch [2/2], Val Loss: 0.2073\n",
      "Epoch [72/2000], Avg Train Loss: 0.4292, Avg Val Loss: 0.3136\n",
      "\n",
      "Validation loss improved from 0.3144 to 0.3136. Saving model...\n",
      "LOG: Epoch [73/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4275\n",
      "LOG: Epoch [73/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4191\n",
      "    Batch [2/2], Val Loss: 0.2071\n",
      "Epoch [73/2000], Avg Train Loss: 0.4275, Avg Val Loss: 0.3131\n",
      "\n",
      "Validation loss improved from 0.3136 to 0.3131. Saving model...\n",
      "LOG: Epoch [74/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4244\n",
      "LOG: Epoch [74/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4186\n",
      "    Batch [2/2], Val Loss: 0.2071\n",
      "Epoch [74/2000], Avg Train Loss: 0.4244, Avg Val Loss: 0.3128\n",
      "\n",
      "Validation loss improved from 0.3131 to 0.3128. Saving model...\n",
      "LOG: Epoch [75/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4241\n",
      "LOG: Epoch [75/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4181\n",
      "    Batch [2/2], Val Loss: 0.2074\n",
      "Epoch [75/2000], Avg Train Loss: 0.4241, Avg Val Loss: 0.3127\n",
      "\n",
      "Validation loss improved from 0.3128 to 0.3127. Saving model...\n",
      "LOG: Epoch [76/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4230\n",
      "LOG: Epoch [76/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4177\n",
      "    Batch [2/2], Val Loss: 0.2079\n",
      "Epoch [76/2000], Avg Train Loss: 0.4230, Avg Val Loss: 0.3128\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [77/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4248\n",
      "LOG: Epoch [77/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4171\n",
      "    Batch [2/2], Val Loss: 0.2081\n",
      "Epoch [77/2000], Avg Train Loss: 0.4248, Avg Val Loss: 0.3126\n",
      "\n",
      "Validation loss improved from 0.3127 to 0.3126. Saving model...\n",
      "LOG: Epoch [78/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4255\n",
      "LOG: Epoch [78/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4168\n",
      "    Batch [2/2], Val Loss: 0.2078\n",
      "Epoch [78/2000], Avg Train Loss: 0.4255, Avg Val Loss: 0.3123\n",
      "\n",
      "Validation loss improved from 0.3126 to 0.3123. Saving model...\n",
      "LOG: Epoch [79/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4222\n",
      "LOG: Epoch [79/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4163\n",
      "    Batch [2/2], Val Loss: 0.2078\n",
      "Epoch [79/2000], Avg Train Loss: 0.4222, Avg Val Loss: 0.3121\n",
      "\n",
      "Validation loss improved from 0.3123 to 0.3121. Saving model...\n",
      "LOG: Epoch [80/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4223\n",
      "LOG: Epoch [80/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4160\n",
      "    Batch [2/2], Val Loss: 0.2076\n",
      "Epoch [80/2000], Avg Train Loss: 0.4223, Avg Val Loss: 0.3118\n",
      "\n",
      "Validation loss improved from 0.3121 to 0.3118. Saving model...\n",
      "LOG: Epoch [81/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4247\n",
      "LOG: Epoch [81/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4157\n",
      "    Batch [2/2], Val Loss: 0.2071\n",
      "Epoch [81/2000], Avg Train Loss: 0.4247, Avg Val Loss: 0.3114\n",
      "\n",
      "Validation loss improved from 0.3118 to 0.3114. Saving model...\n",
      "LOG: Epoch [82/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4207\n",
      "LOG: Epoch [82/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4153\n",
      "    Batch [2/2], Val Loss: 0.2064\n",
      "Epoch [82/2000], Avg Train Loss: 0.4207, Avg Val Loss: 0.3109\n",
      "\n",
      "Validation loss improved from 0.3114 to 0.3109. Saving model...\n",
      "LOG: Epoch [83/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4212\n",
      "LOG: Epoch [83/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4149\n",
      "    Batch [2/2], Val Loss: 0.2058\n",
      "Epoch [83/2000], Avg Train Loss: 0.4212, Avg Val Loss: 0.3103\n",
      "\n",
      "Validation loss improved from 0.3109 to 0.3103. Saving model...\n",
      "LOG: Epoch [84/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4197\n",
      "LOG: Epoch [84/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4145\n",
      "    Batch [2/2], Val Loss: 0.2050\n",
      "Epoch [84/2000], Avg Train Loss: 0.4197, Avg Val Loss: 0.3098\n",
      "\n",
      "Validation loss improved from 0.3103 to 0.3098. Saving model...\n",
      "LOG: Epoch [85/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4230\n",
      "LOG: Epoch [85/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4140\n",
      "    Batch [2/2], Val Loss: 0.2036\n",
      "Epoch [85/2000], Avg Train Loss: 0.4230, Avg Val Loss: 0.3088\n",
      "\n",
      "Validation loss improved from 0.3098 to 0.3088. Saving model...\n",
      "LOG: Epoch [86/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4185\n",
      "LOG: Epoch [86/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4141\n",
      "    Batch [2/2], Val Loss: 0.2023\n",
      "Epoch [86/2000], Avg Train Loss: 0.4185, Avg Val Loss: 0.3082\n",
      "\n",
      "Validation loss improved from 0.3088 to 0.3082. Saving model...\n",
      "LOG: Epoch [87/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4189\n",
      "LOG: Epoch [87/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4139\n",
      "    Batch [2/2], Val Loss: 0.2016\n",
      "Epoch [87/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.3077\n",
      "\n",
      "Validation loss improved from 0.3082 to 0.3077. Saving model...\n",
      "LOG: Epoch [88/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4178\n",
      "LOG: Epoch [88/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4137\n",
      "    Batch [2/2], Val Loss: 0.2009\n",
      "Epoch [88/2000], Avg Train Loss: 0.4178, Avg Val Loss: 0.3073\n",
      "\n",
      "Validation loss improved from 0.3077 to 0.3073. Saving model...\n",
      "LOG: Epoch [89/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4195\n",
      "LOG: Epoch [89/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4137\n",
      "    Batch [2/2], Val Loss: 0.2000\n",
      "Epoch [89/2000], Avg Train Loss: 0.4195, Avg Val Loss: 0.3068\n",
      "\n",
      "Validation loss improved from 0.3073 to 0.3068. Saving model...\n",
      "LOG: Epoch [90/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4199\n",
      "LOG: Epoch [90/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4134\n",
      "    Batch [2/2], Val Loss: 0.1985\n",
      "Epoch [90/2000], Avg Train Loss: 0.4199, Avg Val Loss: 0.3060\n",
      "\n",
      "Validation loss improved from 0.3068 to 0.3060. Saving model...\n",
      "LOG: Epoch [91/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4170\n",
      "LOG: Epoch [91/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4129\n",
      "    Batch [2/2], Val Loss: 0.1976\n",
      "Epoch [91/2000], Avg Train Loss: 0.4170, Avg Val Loss: 0.3052\n",
      "\n",
      "Validation loss improved from 0.3060 to 0.3052. Saving model...\n",
      "LOG: Epoch [92/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4182\n",
      "LOG: Epoch [92/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4121\n",
      "    Batch [2/2], Val Loss: 0.1973\n",
      "Epoch [92/2000], Avg Train Loss: 0.4182, Avg Val Loss: 0.3047\n",
      "\n",
      "Validation loss improved from 0.3052 to 0.3047. Saving model...\n",
      "LOG: Epoch [93/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4155\n",
      "LOG: Epoch [93/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4115\n",
      "    Batch [2/2], Val Loss: 0.1972\n",
      "Epoch [93/2000], Avg Train Loss: 0.4155, Avg Val Loss: 0.3043\n",
      "\n",
      "Validation loss improved from 0.3047 to 0.3043. Saving model...\n",
      "LOG: Epoch [94/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4145\n",
      "LOG: Epoch [94/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4107\n",
      "    Batch [2/2], Val Loss: 0.1970\n",
      "Epoch [94/2000], Avg Train Loss: 0.4145, Avg Val Loss: 0.3039\n",
      "\n",
      "Validation loss improved from 0.3043 to 0.3039. Saving model...\n",
      "LOG: Epoch [95/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4147\n",
      "LOG: Epoch [95/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4100\n",
      "    Batch [2/2], Val Loss: 0.1967\n",
      "Epoch [95/2000], Avg Train Loss: 0.4147, Avg Val Loss: 0.3033\n",
      "\n",
      "Validation loss improved from 0.3039 to 0.3033. Saving model...\n",
      "LOG: Epoch [96/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4171\n",
      "LOG: Epoch [96/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4096\n",
      "    Batch [2/2], Val Loss: 0.1960\n",
      "Epoch [96/2000], Avg Train Loss: 0.4171, Avg Val Loss: 0.3028\n",
      "\n",
      "Validation loss improved from 0.3033 to 0.3028. Saving model...\n",
      "LOG: Epoch [97/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4130\n",
      "LOG: Epoch [97/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4096\n",
      "    Batch [2/2], Val Loss: 0.1949\n",
      "Epoch [97/2000], Avg Train Loss: 0.4130, Avg Val Loss: 0.3022\n",
      "\n",
      "Validation loss improved from 0.3028 to 0.3022. Saving model...\n",
      "LOG: Epoch [98/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4121\n",
      "LOG: Epoch [98/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4094\n",
      "    Batch [2/2], Val Loss: 0.1938\n",
      "Epoch [98/2000], Avg Train Loss: 0.4121, Avg Val Loss: 0.3016\n",
      "\n",
      "Validation loss improved from 0.3022 to 0.3016. Saving model...\n",
      "LOG: Epoch [99/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4126\n",
      "LOG: Epoch [99/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4089\n",
      "    Batch [2/2], Val Loss: 0.1924\n",
      "Epoch [99/2000], Avg Train Loss: 0.4126, Avg Val Loss: 0.3007\n",
      "\n",
      "Validation loss improved from 0.3016 to 0.3007. Saving model...\n",
      "LOG: Epoch [100/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4132\n",
      "LOG: Epoch [100/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4086\n",
      "    Batch [2/2], Val Loss: 0.1914\n",
      "Epoch [100/2000], Avg Train Loss: 0.4132, Avg Val Loss: 0.3000\n",
      "\n",
      "Validation loss improved from 0.3007 to 0.3000. Saving model...\n",
      "LOG: Epoch [101/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4102\n",
      "LOG: Epoch [101/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4084\n",
      "    Batch [2/2], Val Loss: 0.1903\n",
      "Epoch [101/2000], Avg Train Loss: 0.4102, Avg Val Loss: 0.2993\n",
      "\n",
      "Validation loss improved from 0.3000 to 0.2993. Saving model...\n",
      "LOG: Epoch [102/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4151\n",
      "LOG: Epoch [102/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4079\n",
      "    Batch [2/2], Val Loss: 0.1891\n",
      "Epoch [102/2000], Avg Train Loss: 0.4151, Avg Val Loss: 0.2985\n",
      "\n",
      "Validation loss improved from 0.2993 to 0.2985. Saving model...\n",
      "LOG: Epoch [103/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4093\n",
      "LOG: Epoch [103/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4078\n",
      "    Batch [2/2], Val Loss: 0.1880\n",
      "Epoch [103/2000], Avg Train Loss: 0.4093, Avg Val Loss: 0.2979\n",
      "\n",
      "Validation loss improved from 0.2985 to 0.2979. Saving model...\n",
      "LOG: Epoch [104/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4117\n",
      "LOG: Epoch [104/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4075\n",
      "    Batch [2/2], Val Loss: 0.1872\n",
      "Epoch [104/2000], Avg Train Loss: 0.4117, Avg Val Loss: 0.2974\n",
      "\n",
      "Validation loss improved from 0.2979 to 0.2974. Saving model...\n",
      "LOG: Epoch [105/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4106\n",
      "LOG: Epoch [105/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4075\n",
      "    Batch [2/2], Val Loss: 0.1857\n",
      "Epoch [105/2000], Avg Train Loss: 0.4106, Avg Val Loss: 0.2966\n",
      "\n",
      "Validation loss improved from 0.2974 to 0.2966. Saving model...\n",
      "LOG: Epoch [106/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4064\n",
      "LOG: Epoch [106/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4075\n",
      "    Batch [2/2], Val Loss: 0.1847\n",
      "Epoch [106/2000], Avg Train Loss: 0.4064, Avg Val Loss: 0.2961\n",
      "\n",
      "Validation loss improved from 0.2966 to 0.2961. Saving model...\n",
      "LOG: Epoch [107/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [107/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4081\n",
      "    Batch [2/2], Val Loss: 0.1836\n",
      "Epoch [107/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2958\n",
      "\n",
      "Validation loss improved from 0.2961 to 0.2958. Saving model...\n",
      "LOG: Epoch [108/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4105\n",
      "LOG: Epoch [108/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4084\n",
      "    Batch [2/2], Val Loss: 0.1826\n",
      "Epoch [108/2000], Avg Train Loss: 0.4105, Avg Val Loss: 0.2955\n",
      "\n",
      "Validation loss improved from 0.2958 to 0.2955. Saving model...\n",
      "LOG: Epoch [109/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [109/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4083\n",
      "    Batch [2/2], Val Loss: 0.1819\n",
      "Epoch [109/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2951\n",
      "\n",
      "Validation loss improved from 0.2955 to 0.2951. Saving model...\n",
      "LOG: Epoch [110/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4103\n",
      "LOG: Epoch [110/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4088\n",
      "    Batch [2/2], Val Loss: 0.1813\n",
      "Epoch [110/2000], Avg Train Loss: 0.4103, Avg Val Loss: 0.2950\n",
      "\n",
      "Validation loss improved from 0.2951 to 0.2950. Saving model...\n",
      "LOG: Epoch [111/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [111/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4086\n",
      "    Batch [2/2], Val Loss: 0.1808\n",
      "Epoch [111/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2947\n",
      "\n",
      "Validation loss improved from 0.2950 to 0.2947. Saving model...\n",
      "LOG: Epoch [112/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [112/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4081\n",
      "    Batch [2/2], Val Loss: 0.1801\n",
      "Epoch [112/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2941\n",
      "\n",
      "Validation loss improved from 0.2947 to 0.2941. Saving model...\n",
      "LOG: Epoch [113/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4060\n",
      "LOG: Epoch [113/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4069\n",
      "    Batch [2/2], Val Loss: 0.1796\n",
      "Epoch [113/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.2933\n",
      "\n",
      "Validation loss improved from 0.2941 to 0.2933. Saving model...\n",
      "LOG: Epoch [114/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [114/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1790\n",
      "Epoch [114/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2924\n",
      "\n",
      "Validation loss improved from 0.2933 to 0.2924. Saving model...\n",
      "LOG: Epoch [115/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [115/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4047\n",
      "    Batch [2/2], Val Loss: 0.1786\n",
      "Epoch [115/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2917\n",
      "\n",
      "Validation loss improved from 0.2924 to 0.2917. Saving model...\n",
      "LOG: Epoch [116/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [116/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4033\n",
      "    Batch [2/2], Val Loss: 0.1783\n",
      "Epoch [116/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2908\n",
      "\n",
      "Validation loss improved from 0.2917 to 0.2908. Saving model...\n",
      "LOG: Epoch [117/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [117/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4022\n",
      "    Batch [2/2], Val Loss: 0.1778\n",
      "Epoch [117/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2900\n",
      "\n",
      "Validation loss improved from 0.2908 to 0.2900. Saving model...\n",
      "LOG: Epoch [118/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [118/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4013\n",
      "    Batch [2/2], Val Loss: 0.1771\n",
      "Epoch [118/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2892\n",
      "\n",
      "Validation loss improved from 0.2900 to 0.2892. Saving model...\n",
      "LOG: Epoch [119/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [119/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4008\n",
      "    Batch [2/2], Val Loss: 0.1765\n",
      "Epoch [119/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2886\n",
      "\n",
      "Validation loss improved from 0.2892 to 0.2886. Saving model...\n",
      "LOG: Epoch [120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [120/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4005\n",
      "    Batch [2/2], Val Loss: 0.1758\n",
      "Epoch [120/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2881\n",
      "\n",
      "Validation loss improved from 0.2886 to 0.2881. Saving model...\n",
      "LOG: Epoch [121/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3981\n",
      "LOG: Epoch [121/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4004\n",
      "    Batch [2/2], Val Loss: 0.1753\n",
      "Epoch [121/2000], Avg Train Loss: 0.3981, Avg Val Loss: 0.2878\n",
      "\n",
      "Validation loss improved from 0.2881 to 0.2878. Saving model...\n",
      "LOG: Epoch [122/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4003\n",
      "LOG: Epoch [122/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4010\n",
      "    Batch [2/2], Val Loss: 0.1743\n",
      "Epoch [122/2000], Avg Train Loss: 0.4003, Avg Val Loss: 0.2876\n",
      "\n",
      "Validation loss improved from 0.2878 to 0.2876. Saving model...\n",
      "LOG: Epoch [123/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4004\n",
      "LOG: Epoch [123/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4020\n",
      "    Batch [2/2], Val Loss: 0.1736\n",
      "Epoch [123/2000], Avg Train Loss: 0.4004, Avg Val Loss: 0.2878\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [124/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3953\n",
      "LOG: Epoch [124/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4031\n",
      "    Batch [2/2], Val Loss: 0.1736\n",
      "Epoch [124/2000], Avg Train Loss: 0.3953, Avg Val Loss: 0.2884\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [125/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [125/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4044\n",
      "    Batch [2/2], Val Loss: 0.1733\n",
      "Epoch [125/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2888\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4005\n",
      "LOG: Epoch [126/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1728\n",
      "Epoch [126/2000], Avg Train Loss: 0.4005, Avg Val Loss: 0.2888\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [127/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [127/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1721\n",
      "Epoch [127/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2884\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [128/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [128/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4043\n",
      "    Batch [2/2], Val Loss: 0.1718\n",
      "Epoch [128/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2881\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [129/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [129/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4032\n",
      "    Batch [2/2], Val Loss: 0.1710\n",
      "Epoch [129/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2871\n",
      "\n",
      "Validation loss improved from 0.2876 to 0.2871. Saving model...\n",
      "LOG: Epoch [130/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3980\n",
      "LOG: Epoch [130/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4019\n",
      "    Batch [2/2], Val Loss: 0.1703\n",
      "Epoch [130/2000], Avg Train Loss: 0.3980, Avg Val Loss: 0.2861\n",
      "\n",
      "Validation loss improved from 0.2871 to 0.2861. Saving model...\n",
      "LOG: Epoch [131/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [131/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4007\n",
      "    Batch [2/2], Val Loss: 0.1695\n",
      "Epoch [131/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2851\n",
      "\n",
      "Validation loss improved from 0.2861 to 0.2851. Saving model...\n",
      "LOG: Epoch [132/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [132/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3992\n",
      "    Batch [2/2], Val Loss: 0.1691\n",
      "Epoch [132/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2842\n",
      "\n",
      "Validation loss improved from 0.2851 to 0.2842. Saving model...\n",
      "LOG: Epoch [133/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3949\n",
      "LOG: Epoch [133/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3979\n",
      "    Batch [2/2], Val Loss: 0.1690\n",
      "Epoch [133/2000], Avg Train Loss: 0.3949, Avg Val Loss: 0.2835\n",
      "\n",
      "Validation loss improved from 0.2842 to 0.2835. Saving model...\n",
      "LOG: Epoch [134/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [134/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3963\n",
      "    Batch [2/2], Val Loss: 0.1685\n",
      "Epoch [134/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2824\n",
      "\n",
      "Validation loss improved from 0.2835 to 0.2824. Saving model...\n",
      "LOG: Epoch [135/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3980\n",
      "LOG: Epoch [135/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3949\n",
      "    Batch [2/2], Val Loss: 0.1680\n",
      "Epoch [135/2000], Avg Train Loss: 0.3980, Avg Val Loss: 0.2814\n",
      "\n",
      "Validation loss improved from 0.2824 to 0.2814. Saving model...\n",
      "LOG: Epoch [136/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3894\n",
      "LOG: Epoch [136/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3939\n",
      "    Batch [2/2], Val Loss: 0.1675\n",
      "Epoch [136/2000], Avg Train Loss: 0.3894, Avg Val Loss: 0.2807\n",
      "\n",
      "Validation loss improved from 0.2814 to 0.2807. Saving model...\n",
      "LOG: Epoch [137/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [137/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3929\n",
      "    Batch [2/2], Val Loss: 0.1670\n",
      "Epoch [137/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2799\n",
      "\n",
      "Validation loss improved from 0.2807 to 0.2799. Saving model...\n",
      "LOG: Epoch [138/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3966\n",
      "LOG: Epoch [138/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3924\n",
      "    Batch [2/2], Val Loss: 0.1665\n",
      "Epoch [138/2000], Avg Train Loss: 0.3966, Avg Val Loss: 0.2794\n",
      "\n",
      "Validation loss improved from 0.2799 to 0.2794. Saving model...\n",
      "LOG: Epoch [139/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [139/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3922\n",
      "    Batch [2/2], Val Loss: 0.1658\n",
      "Epoch [139/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2790\n",
      "\n",
      "Validation loss improved from 0.2794 to 0.2790. Saving model...\n",
      "LOG: Epoch [140/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [140/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3923\n",
      "    Batch [2/2], Val Loss: 0.1651\n",
      "Epoch [140/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2787\n",
      "\n",
      "Validation loss improved from 0.2790 to 0.2787. Saving model...\n",
      "LOG: Epoch [141/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [141/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3921\n",
      "    Batch [2/2], Val Loss: 0.1644\n",
      "Epoch [141/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2783\n",
      "\n",
      "Validation loss improved from 0.2787 to 0.2783. Saving model...\n",
      "LOG: Epoch [142/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3887\n",
      "LOG: Epoch [142/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3920\n",
      "    Batch [2/2], Val Loss: 0.1643\n",
      "Epoch [142/2000], Avg Train Loss: 0.3887, Avg Val Loss: 0.2781\n",
      "\n",
      "Validation loss improved from 0.2783 to 0.2781. Saving model...\n",
      "LOG: Epoch [143/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3841\n",
      "LOG: Epoch [143/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3921\n",
      "    Batch [2/2], Val Loss: 0.1646\n",
      "Epoch [143/2000], Avg Train Loss: 0.3841, Avg Val Loss: 0.2783\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [144/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [144/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3920\n",
      "    Batch [2/2], Val Loss: 0.1649\n",
      "Epoch [144/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2784\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [145/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [145/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3913\n",
      "    Batch [2/2], Val Loss: 0.1651\n",
      "Epoch [145/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2782\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [146/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3875\n",
      "LOG: Epoch [146/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3910\n",
      "    Batch [2/2], Val Loss: 0.1647\n",
      "Epoch [146/2000], Avg Train Loss: 0.3875, Avg Val Loss: 0.2779\n",
      "\n",
      "Validation loss improved from 0.2781 to 0.2779. Saving model...\n",
      "LOG: Epoch [147/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3824\n",
      "LOG: Epoch [147/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3912\n",
      "    Batch [2/2], Val Loss: 0.1637\n",
      "Epoch [147/2000], Avg Train Loss: 0.3824, Avg Val Loss: 0.2774\n",
      "\n",
      "Validation loss improved from 0.2779 to 0.2774. Saving model...\n",
      "LOG: Epoch [148/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3806\n",
      "LOG: Epoch [148/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3916\n",
      "    Batch [2/2], Val Loss: 0.1630\n",
      "Epoch [148/2000], Avg Train Loss: 0.3806, Avg Val Loss: 0.2773\n",
      "\n",
      "Validation loss improved from 0.2774 to 0.2773. Saving model...\n",
      "LOG: Epoch [149/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3853\n",
      "LOG: Epoch [149/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3915\n",
      "    Batch [2/2], Val Loss: 0.1623\n",
      "Epoch [149/2000], Avg Train Loss: 0.3853, Avg Val Loss: 0.2769\n",
      "\n",
      "Validation loss improved from 0.2773 to 0.2769. Saving model...\n",
      "LOG: Epoch [150/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3844\n",
      "LOG: Epoch [150/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3908\n",
      "    Batch [2/2], Val Loss: 0.1617\n",
      "Epoch [150/2000], Avg Train Loss: 0.3844, Avg Val Loss: 0.2762\n",
      "\n",
      "Validation loss improved from 0.2769 to 0.2762. Saving model...\n",
      "LOG: Epoch [151/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [151/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3902\n",
      "    Batch [2/2], Val Loss: 0.1612\n",
      "Epoch [151/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2757\n",
      "\n",
      "Validation loss improved from 0.2762 to 0.2757. Saving model...\n",
      "LOG: Epoch [152/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3798\n",
      "LOG: Epoch [152/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3904\n",
      "    Batch [2/2], Val Loss: 0.1604\n",
      "Epoch [152/2000], Avg Train Loss: 0.3798, Avg Val Loss: 0.2754\n",
      "\n",
      "Validation loss improved from 0.2757 to 0.2754. Saving model...\n",
      "LOG: Epoch [153/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3813\n",
      "LOG: Epoch [153/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3906\n",
      "    Batch [2/2], Val Loss: 0.1598\n",
      "Epoch [153/2000], Avg Train Loss: 0.3813, Avg Val Loss: 0.2752\n",
      "\n",
      "Validation loss improved from 0.2754 to 0.2752. Saving model...\n",
      "LOG: Epoch [154/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3794\n",
      "LOG: Epoch [154/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3911\n",
      "    Batch [2/2], Val Loss: 0.1598\n",
      "Epoch [154/2000], Avg Train Loss: 0.3794, Avg Val Loss: 0.2755\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [155/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3769\n",
      "LOG: Epoch [155/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3913\n",
      "    Batch [2/2], Val Loss: 0.1604\n",
      "Epoch [155/2000], Avg Train Loss: 0.3769, Avg Val Loss: 0.2759\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [156/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3801\n",
      "LOG: Epoch [156/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3910\n",
      "    Batch [2/2], Val Loss: 0.1608\n",
      "Epoch [156/2000], Avg Train Loss: 0.3801, Avg Val Loss: 0.2759\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [157/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3820\n",
      "LOG: Epoch [157/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3908\n",
      "    Batch [2/2], Val Loss: 0.1611\n",
      "Epoch [157/2000], Avg Train Loss: 0.3820, Avg Val Loss: 0.2759\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [158/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3854\n",
      "LOG: Epoch [158/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3905\n",
      "    Batch [2/2], Val Loss: 0.1612\n",
      "Epoch [158/2000], Avg Train Loss: 0.3854, Avg Val Loss: 0.2758\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [159/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3870\n",
      "LOG: Epoch [159/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3898\n",
      "    Batch [2/2], Val Loss: 0.1608\n",
      "Epoch [159/2000], Avg Train Loss: 0.3870, Avg Val Loss: 0.2753\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [160/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3738\n",
      "LOG: Epoch [160/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3889\n",
      "    Batch [2/2], Val Loss: 0.1600\n",
      "Epoch [160/2000], Avg Train Loss: 0.3738, Avg Val Loss: 0.2745\n",
      "\n",
      "Validation loss improved from 0.2752 to 0.2745. Saving model...\n",
      "LOG: Epoch [161/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3804\n",
      "LOG: Epoch [161/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3881\n",
      "    Batch [2/2], Val Loss: 0.1596\n",
      "Epoch [161/2000], Avg Train Loss: 0.3804, Avg Val Loss: 0.2738\n",
      "\n",
      "Validation loss improved from 0.2745 to 0.2738. Saving model...\n",
      "LOG: Epoch [162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3786\n",
      "LOG: Epoch [162/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3879\n",
      "    Batch [2/2], Val Loss: 0.1590\n",
      "Epoch [162/2000], Avg Train Loss: 0.3786, Avg Val Loss: 0.2734\n",
      "\n",
      "Validation loss improved from 0.2738 to 0.2734. Saving model...\n",
      "LOG: Epoch [163/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3749\n",
      "LOG: Epoch [163/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3874\n",
      "    Batch [2/2], Val Loss: 0.1583\n",
      "Epoch [163/2000], Avg Train Loss: 0.3749, Avg Val Loss: 0.2728\n",
      "\n",
      "Validation loss improved from 0.2734 to 0.2728. Saving model...\n",
      "LOG: Epoch [164/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3778\n",
      "LOG: Epoch [164/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3869\n",
      "    Batch [2/2], Val Loss: 0.1575\n",
      "Epoch [164/2000], Avg Train Loss: 0.3778, Avg Val Loss: 0.2722\n",
      "\n",
      "Validation loss improved from 0.2728 to 0.2722. Saving model...\n",
      "LOG: Epoch [165/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3756\n",
      "LOG: Epoch [165/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3872\n",
      "    Batch [2/2], Val Loss: 0.1569\n",
      "Epoch [165/2000], Avg Train Loss: 0.3756, Avg Val Loss: 0.2720\n",
      "\n",
      "Validation loss improved from 0.2722 to 0.2720. Saving model...\n",
      "LOG: Epoch [166/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3746\n",
      "LOG: Epoch [166/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3876\n",
      "    Batch [2/2], Val Loss: 0.1560\n",
      "Epoch [166/2000], Avg Train Loss: 0.3746, Avg Val Loss: 0.2718\n",
      "\n",
      "Validation loss improved from 0.2720 to 0.2718. Saving model...\n",
      "LOG: Epoch [167/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3807\n",
      "LOG: Epoch [167/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3880\n",
      "    Batch [2/2], Val Loss: 0.1551\n",
      "Epoch [167/2000], Avg Train Loss: 0.3807, Avg Val Loss: 0.2715\n",
      "\n",
      "Validation loss improved from 0.2718 to 0.2715. Saving model...\n",
      "LOG: Epoch [168/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3783\n",
      "LOG: Epoch [168/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3890\n",
      "    Batch [2/2], Val Loss: 0.1546\n",
      "Epoch [168/2000], Avg Train Loss: 0.3783, Avg Val Loss: 0.2718\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [169/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3747\n",
      "LOG: Epoch [169/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3897\n",
      "    Batch [2/2], Val Loss: 0.1545\n",
      "Epoch [169/2000], Avg Train Loss: 0.3747, Avg Val Loss: 0.2721\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [170/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3746\n",
      "LOG: Epoch [170/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3900\n",
      "    Batch [2/2], Val Loss: 0.1543\n",
      "Epoch [170/2000], Avg Train Loss: 0.3746, Avg Val Loss: 0.2721\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [171/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3748\n",
      "LOG: Epoch [171/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3906\n",
      "    Batch [2/2], Val Loss: 0.1538\n",
      "Epoch [171/2000], Avg Train Loss: 0.3748, Avg Val Loss: 0.2722\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [172/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3700\n",
      "LOG: Epoch [172/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3907\n",
      "    Batch [2/2], Val Loss: 0.1533\n",
      "Epoch [172/2000], Avg Train Loss: 0.3700, Avg Val Loss: 0.2720\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [173/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3714\n",
      "LOG: Epoch [173/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3910\n",
      "    Batch [2/2], Val Loss: 0.1530\n",
      "Epoch [173/2000], Avg Train Loss: 0.3714, Avg Val Loss: 0.2720\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [174/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3727\n",
      "LOG: Epoch [174/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3906\n",
      "    Batch [2/2], Val Loss: 0.1525\n",
      "Epoch [174/2000], Avg Train Loss: 0.3727, Avg Val Loss: 0.2715\n",
      "\n",
      "Validation loss improved from 0.2715 to 0.2715. Saving model...\n",
      "LOG: Epoch [175/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3703\n",
      "LOG: Epoch [175/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3903\n",
      "    Batch [2/2], Val Loss: 0.1526\n",
      "Epoch [175/2000], Avg Train Loss: 0.3703, Avg Val Loss: 0.2714\n",
      "\n",
      "Validation loss improved from 0.2715 to 0.2714. Saving model...\n",
      "LOG: Epoch [176/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3688\n",
      "LOG: Epoch [176/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3900\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [176/2000], Avg Train Loss: 0.3688, Avg Val Loss: 0.2712\n",
      "\n",
      "Validation loss improved from 0.2714 to 0.2712. Saving model...\n",
      "LOG: Epoch [177/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3705\n",
      "LOG: Epoch [177/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3898\n",
      "    Batch [2/2], Val Loss: 0.1524\n",
      "Epoch [177/2000], Avg Train Loss: 0.3705, Avg Val Loss: 0.2711\n",
      "\n",
      "Validation loss improved from 0.2712 to 0.2711. Saving model...\n",
      "LOG: Epoch [178/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3715\n",
      "LOG: Epoch [178/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3898\n",
      "    Batch [2/2], Val Loss: 0.1522\n",
      "Epoch [178/2000], Avg Train Loss: 0.3715, Avg Val Loss: 0.2710\n",
      "\n",
      "Validation loss improved from 0.2711 to 0.2710. Saving model...\n",
      "LOG: Epoch [179/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3719\n",
      "LOG: Epoch [179/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3893\n",
      "    Batch [2/2], Val Loss: 0.1517\n",
      "Epoch [179/2000], Avg Train Loss: 0.3719, Avg Val Loss: 0.2705\n",
      "\n",
      "Validation loss improved from 0.2710 to 0.2705. Saving model...\n",
      "LOG: Epoch [180/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3693\n",
      "LOG: Epoch [180/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3885\n",
      "    Batch [2/2], Val Loss: 0.1510\n",
      "Epoch [180/2000], Avg Train Loss: 0.3693, Avg Val Loss: 0.2698\n",
      "\n",
      "Validation loss improved from 0.2705 to 0.2698. Saving model...\n",
      "LOG: Epoch [181/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3689\n",
      "LOG: Epoch [181/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3879\n",
      "    Batch [2/2], Val Loss: 0.1503\n",
      "Epoch [181/2000], Avg Train Loss: 0.3689, Avg Val Loss: 0.2691\n",
      "\n",
      "Validation loss improved from 0.2698 to 0.2691. Saving model...\n",
      "LOG: Epoch [182/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3675\n",
      "LOG: Epoch [182/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3873\n",
      "    Batch [2/2], Val Loss: 0.1499\n",
      "Epoch [182/2000], Avg Train Loss: 0.3675, Avg Val Loss: 0.2686\n",
      "\n",
      "Validation loss improved from 0.2691 to 0.2686. Saving model...\n",
      "LOG: Epoch [183/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3737\n",
      "LOG: Epoch [183/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3869\n",
      "    Batch [2/2], Val Loss: 0.1498\n",
      "Epoch [183/2000], Avg Train Loss: 0.3737, Avg Val Loss: 0.2684\n",
      "\n",
      "Validation loss improved from 0.2686 to 0.2684. Saving model...\n",
      "LOG: Epoch [184/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3678\n",
      "LOG: Epoch [184/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3867\n",
      "    Batch [2/2], Val Loss: 0.1494\n",
      "Epoch [184/2000], Avg Train Loss: 0.3678, Avg Val Loss: 0.2681\n",
      "\n",
      "Validation loss improved from 0.2684 to 0.2681. Saving model...\n",
      "LOG: Epoch [185/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3701\n",
      "LOG: Epoch [185/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3859\n",
      "    Batch [2/2], Val Loss: 0.1492\n",
      "Epoch [185/2000], Avg Train Loss: 0.3701, Avg Val Loss: 0.2675\n",
      "\n",
      "Validation loss improved from 0.2681 to 0.2675. Saving model...\n",
      "LOG: Epoch [186/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3621\n",
      "LOG: Epoch [186/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3847\n",
      "    Batch [2/2], Val Loss: 0.1484\n",
      "Epoch [186/2000], Avg Train Loss: 0.3621, Avg Val Loss: 0.2665\n",
      "\n",
      "Validation loss improved from 0.2675 to 0.2665. Saving model...\n",
      "LOG: Epoch [187/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3606\n",
      "LOG: Epoch [187/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3830\n",
      "    Batch [2/2], Val Loss: 0.1475\n",
      "Epoch [187/2000], Avg Train Loss: 0.3606, Avg Val Loss: 0.2652\n",
      "\n",
      "Validation loss improved from 0.2665 to 0.2652. Saving model...\n",
      "LOG: Epoch [188/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3678\n",
      "LOG: Epoch [188/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3814\n",
      "    Batch [2/2], Val Loss: 0.1472\n",
      "Epoch [188/2000], Avg Train Loss: 0.3678, Avg Val Loss: 0.2643\n",
      "\n",
      "Validation loss improved from 0.2652 to 0.2643. Saving model...\n",
      "LOG: Epoch [189/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3646\n",
      "LOG: Epoch [189/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3800\n",
      "    Batch [2/2], Val Loss: 0.1464\n",
      "Epoch [189/2000], Avg Train Loss: 0.3646, Avg Val Loss: 0.2632\n",
      "\n",
      "Validation loss improved from 0.2643 to 0.2632. Saving model...\n",
      "LOG: Epoch [190/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3644\n",
      "LOG: Epoch [190/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3786\n",
      "    Batch [2/2], Val Loss: 0.1455\n",
      "Epoch [190/2000], Avg Train Loss: 0.3644, Avg Val Loss: 0.2620\n",
      "\n",
      "Validation loss improved from 0.2632 to 0.2620. Saving model...\n",
      "LOG: Epoch [191/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3626\n",
      "LOG: Epoch [191/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3775\n",
      "    Batch [2/2], Val Loss: 0.1446\n",
      "Epoch [191/2000], Avg Train Loss: 0.3626, Avg Val Loss: 0.2611\n",
      "\n",
      "Validation loss improved from 0.2620 to 0.2611. Saving model...\n",
      "LOG: Epoch [192/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3681\n",
      "LOG: Epoch [192/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3771\n",
      "    Batch [2/2], Val Loss: 0.1439\n",
      "Epoch [192/2000], Avg Train Loss: 0.3681, Avg Val Loss: 0.2605\n",
      "\n",
      "Validation loss improved from 0.2611 to 0.2605. Saving model...\n",
      "LOG: Epoch [193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3627\n",
      "LOG: Epoch [193/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3762\n",
      "    Batch [2/2], Val Loss: 0.1428\n",
      "Epoch [193/2000], Avg Train Loss: 0.3627, Avg Val Loss: 0.2595\n",
      "\n",
      "Validation loss improved from 0.2605 to 0.2595. Saving model...\n",
      "LOG: Epoch [194/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3639\n",
      "LOG: Epoch [194/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3760\n",
      "    Batch [2/2], Val Loss: 0.1417\n",
      "Epoch [194/2000], Avg Train Loss: 0.3639, Avg Val Loss: 0.2589\n",
      "\n",
      "Validation loss improved from 0.2595 to 0.2589. Saving model...\n",
      "LOG: Epoch [195/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3627\n",
      "LOG: Epoch [195/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.1407\n",
      "Epoch [195/2000], Avg Train Loss: 0.3627, Avg Val Loss: 0.2584\n",
      "\n",
      "Validation loss improved from 0.2589 to 0.2584. Saving model...\n",
      "LOG: Epoch [196/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3624\n",
      "LOG: Epoch [196/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3763\n",
      "    Batch [2/2], Val Loss: 0.1401\n",
      "Epoch [196/2000], Avg Train Loss: 0.3624, Avg Val Loss: 0.2582\n",
      "\n",
      "Validation loss improved from 0.2584 to 0.2582. Saving model...\n",
      "LOG: Epoch [197/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3604\n",
      "LOG: Epoch [197/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.1395\n",
      "Epoch [197/2000], Avg Train Loss: 0.3604, Avg Val Loss: 0.2579\n",
      "\n",
      "Validation loss improved from 0.2582 to 0.2579. Saving model...\n",
      "LOG: Epoch [198/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3610\n",
      "LOG: Epoch [198/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.1392\n",
      "Epoch [198/2000], Avg Train Loss: 0.3610, Avg Val Loss: 0.2576\n",
      "\n",
      "Validation loss improved from 0.2579 to 0.2576. Saving model...\n",
      "LOG: Epoch [199/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3612\n",
      "LOG: Epoch [199/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3760\n",
      "    Batch [2/2], Val Loss: 0.1388\n",
      "Epoch [199/2000], Avg Train Loss: 0.3612, Avg Val Loss: 0.2574\n",
      "\n",
      "Validation loss improved from 0.2576 to 0.2574. Saving model...\n",
      "LOG: Epoch [200/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3573\n",
      "LOG: Epoch [200/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3757\n",
      "    Batch [2/2], Val Loss: 0.1385\n",
      "Epoch [200/2000], Avg Train Loss: 0.3573, Avg Val Loss: 0.2571\n",
      "\n",
      "Validation loss improved from 0.2574 to 0.2571. Saving model...\n",
      "LOG: Epoch [201/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3591\n",
      "LOG: Epoch [201/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3756\n",
      "    Batch [2/2], Val Loss: 0.1384\n",
      "Epoch [201/2000], Avg Train Loss: 0.3591, Avg Val Loss: 0.2570\n",
      "\n",
      "Validation loss improved from 0.2571 to 0.2570. Saving model...\n",
      "LOG: Epoch [202/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3565\n",
      "LOG: Epoch [202/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3760\n",
      "    Batch [2/2], Val Loss: 0.1388\n",
      "Epoch [202/2000], Avg Train Loss: 0.3565, Avg Val Loss: 0.2574\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [203/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3564\n",
      "LOG: Epoch [203/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.1393\n",
      "Epoch [203/2000], Avg Train Loss: 0.3564, Avg Val Loss: 0.2579\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [204/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3581\n",
      "LOG: Epoch [204/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3769\n",
      "    Batch [2/2], Val Loss: 0.1399\n",
      "Epoch [204/2000], Avg Train Loss: 0.3581, Avg Val Loss: 0.2584\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [205/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3539\n",
      "LOG: Epoch [205/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3773\n",
      "    Batch [2/2], Val Loss: 0.1402\n",
      "Epoch [205/2000], Avg Train Loss: 0.3539, Avg Val Loss: 0.2587\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [206/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3532\n",
      "LOG: Epoch [206/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3770\n",
      "    Batch [2/2], Val Loss: 0.1400\n",
      "Epoch [206/2000], Avg Train Loss: 0.3532, Avg Val Loss: 0.2585\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [207/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3529\n",
      "LOG: Epoch [207/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3767\n",
      "    Batch [2/2], Val Loss: 0.1394\n",
      "Epoch [207/2000], Avg Train Loss: 0.3529, Avg Val Loss: 0.2580\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [208/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3559\n",
      "LOG: Epoch [208/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3765\n",
      "    Batch [2/2], Val Loss: 0.1384\n",
      "Epoch [208/2000], Avg Train Loss: 0.3559, Avg Val Loss: 0.2575\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [209/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3581\n",
      "LOG: Epoch [209/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3763\n",
      "    Batch [2/2], Val Loss: 0.1374\n",
      "Epoch [209/2000], Avg Train Loss: 0.3581, Avg Val Loss: 0.2568\n",
      "\n",
      "Validation loss improved from 0.2570 to 0.2568. Saving model...\n",
      "LOG: Epoch [210/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3538\n",
      "LOG: Epoch [210/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.1371\n",
      "Epoch [210/2000], Avg Train Loss: 0.3538, Avg Val Loss: 0.2566\n",
      "\n",
      "Validation loss improved from 0.2568 to 0.2566. Saving model...\n",
      "LOG: Epoch [211/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3541\n",
      "LOG: Epoch [211/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3750\n",
      "    Batch [2/2], Val Loss: 0.1367\n",
      "Epoch [211/2000], Avg Train Loss: 0.3541, Avg Val Loss: 0.2558\n",
      "\n",
      "Validation loss improved from 0.2566 to 0.2558. Saving model...\n",
      "LOG: Epoch [212/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3523\n",
      "LOG: Epoch [212/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3744\n",
      "    Batch [2/2], Val Loss: 0.1364\n",
      "Epoch [212/2000], Avg Train Loss: 0.3523, Avg Val Loss: 0.2554\n",
      "\n",
      "Validation loss improved from 0.2558 to 0.2554. Saving model...\n",
      "LOG: Epoch [213/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3552\n",
      "LOG: Epoch [213/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3742\n",
      "    Batch [2/2], Val Loss: 0.1361\n",
      "Epoch [213/2000], Avg Train Loss: 0.3552, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2554 to 0.2551. Saving model...\n",
      "LOG: Epoch [214/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3547\n",
      "LOG: Epoch [214/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3744\n",
      "    Batch [2/2], Val Loss: 0.1360\n",
      "Epoch [214/2000], Avg Train Loss: 0.3547, Avg Val Loss: 0.2552\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [215/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3517\n",
      "LOG: Epoch [215/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3743\n",
      "    Batch [2/2], Val Loss: 0.1360\n",
      "Epoch [215/2000], Avg Train Loss: 0.3517, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [216/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3523\n",
      "LOG: Epoch [216/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3741\n",
      "    Batch [2/2], Val Loss: 0.1355\n",
      "Epoch [216/2000], Avg Train Loss: 0.3523, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2548. Saving model...\n",
      "LOG: Epoch [217/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3507\n",
      "LOG: Epoch [217/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3742\n",
      "    Batch [2/2], Val Loss: 0.1347\n",
      "Epoch [217/2000], Avg Train Loss: 0.3507, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2544. Saving model...\n",
      "LOG: Epoch [218/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3493\n",
      "LOG: Epoch [218/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3741\n",
      "    Batch [2/2], Val Loss: 0.1339\n",
      "Epoch [218/2000], Avg Train Loss: 0.3493, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2540. Saving model...\n",
      "LOG: Epoch [219/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3513\n",
      "LOG: Epoch [219/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3744\n",
      "    Batch [2/2], Val Loss: 0.1335\n",
      "Epoch [219/2000], Avg Train Loss: 0.3513, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [220/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3513\n",
      "LOG: Epoch [220/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3749\n",
      "    Batch [2/2], Val Loss: 0.1334\n",
      "Epoch [220/2000], Avg Train Loss: 0.3513, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [221/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3536\n",
      "LOG: Epoch [221/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3751\n",
      "    Batch [2/2], Val Loss: 0.1336\n",
      "Epoch [221/2000], Avg Train Loss: 0.3536, Avg Val Loss: 0.2544\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [222/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3494\n",
      "LOG: Epoch [222/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3750\n",
      "    Batch [2/2], Val Loss: 0.1330\n",
      "Epoch [222/2000], Avg Train Loss: 0.3494, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [223/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3496\n",
      "LOG: Epoch [223/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3752\n",
      "    Batch [2/2], Val Loss: 0.1330\n",
      "Epoch [223/2000], Avg Train Loss: 0.3496, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [224/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3498\n",
      "LOG: Epoch [224/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3748\n",
      "    Batch [2/2], Val Loss: 0.1327\n",
      "Epoch [224/2000], Avg Train Loss: 0.3498, Avg Val Loss: 0.2537\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2537. Saving model...\n",
      "LOG: Epoch [225/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [225/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3749\n",
      "    Batch [2/2], Val Loss: 0.1318\n",
      "Epoch [225/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2534\n",
      "\n",
      "Validation loss improved from 0.2537 to 0.2534. Saving model...\n",
      "LOG: Epoch [226/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [226/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3751\n",
      "    Batch [2/2], Val Loss: 0.1309\n",
      "Epoch [226/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2530\n",
      "\n",
      "Validation loss improved from 0.2534 to 0.2530. Saving model...\n",
      "LOG: Epoch [227/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [227/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3753\n",
      "    Batch [2/2], Val Loss: 0.1294\n",
      "Epoch [227/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2524\n",
      "\n",
      "Validation loss improved from 0.2530 to 0.2524. Saving model...\n",
      "LOG: Epoch [228/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3561\n",
      "LOG: Epoch [228/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3753\n",
      "    Batch [2/2], Val Loss: 0.1286\n",
      "Epoch [228/2000], Avg Train Loss: 0.3561, Avg Val Loss: 0.2520\n",
      "\n",
      "Validation loss improved from 0.2524 to 0.2520. Saving model...\n",
      "LOG: Epoch [229/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [229/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3749\n",
      "    Batch [2/2], Val Loss: 0.1284\n",
      "Epoch [229/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2516\n",
      "\n",
      "Validation loss improved from 0.2520 to 0.2516. Saving model...\n",
      "LOG: Epoch [230/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3482\n",
      "LOG: Epoch [230/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3741\n",
      "    Batch [2/2], Val Loss: 0.1278\n",
      "Epoch [230/2000], Avg Train Loss: 0.3482, Avg Val Loss: 0.2510\n",
      "\n",
      "Validation loss improved from 0.2516 to 0.2510. Saving model...\n",
      "LOG: Epoch [231/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [231/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3730\n",
      "    Batch [2/2], Val Loss: 0.1269\n",
      "Epoch [231/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2500\n",
      "\n",
      "Validation loss improved from 0.2510 to 0.2500. Saving model...\n",
      "LOG: Epoch [232/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [232/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3711\n",
      "    Batch [2/2], Val Loss: 0.1258\n",
      "Epoch [232/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2485\n",
      "\n",
      "Validation loss improved from 0.2500 to 0.2485. Saving model...\n",
      "LOG: Epoch [233/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [233/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3697\n",
      "    Batch [2/2], Val Loss: 0.1250\n",
      "Epoch [233/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2473\n",
      "\n",
      "Validation loss improved from 0.2485 to 0.2473. Saving model...\n",
      "LOG: Epoch [234/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [234/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3687\n",
      "    Batch [2/2], Val Loss: 0.1245\n",
      "Epoch [234/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2466\n",
      "\n",
      "Validation loss improved from 0.2473 to 0.2466. Saving model...\n",
      "LOG: Epoch [235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3386\n",
      "LOG: Epoch [235/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3679\n",
      "    Batch [2/2], Val Loss: 0.1244\n",
      "Epoch [235/2000], Avg Train Loss: 0.3386, Avg Val Loss: 0.2461\n",
      "\n",
      "Validation loss improved from 0.2466 to 0.2461. Saving model...\n",
      "LOG: Epoch [236/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [236/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3672\n",
      "    Batch [2/2], Val Loss: 0.1242\n",
      "Epoch [236/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2457\n",
      "\n",
      "Validation loss improved from 0.2461 to 0.2457. Saving model...\n",
      "LOG: Epoch [237/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [237/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3669\n",
      "    Batch [2/2], Val Loss: 0.1238\n",
      "Epoch [237/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2454\n",
      "\n",
      "Validation loss improved from 0.2457 to 0.2454. Saving model...\n",
      "LOG: Epoch [238/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [238/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3666\n",
      "    Batch [2/2], Val Loss: 0.1238\n",
      "Epoch [238/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2452\n",
      "\n",
      "Validation loss improved from 0.2454 to 0.2452. Saving model...\n",
      "LOG: Epoch [239/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [239/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3664\n",
      "    Batch [2/2], Val Loss: 0.1239\n",
      "Epoch [239/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2451\n",
      "\n",
      "Validation loss improved from 0.2452 to 0.2451. Saving model...\n",
      "LOG: Epoch [240/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [240/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3661\n",
      "    Batch [2/2], Val Loss: 0.1241\n",
      "Epoch [240/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2451\n",
      "\n",
      "Validation loss improved from 0.2451 to 0.2451. Saving model...\n",
      "LOG: Epoch [241/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [241/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3661\n",
      "    Batch [2/2], Val Loss: 0.1242\n",
      "Epoch [241/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2451\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [242/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3377\n",
      "LOG: Epoch [242/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3663\n",
      "    Batch [2/2], Val Loss: 0.1237\n",
      "Epoch [242/2000], Avg Train Loss: 0.3377, Avg Val Loss: 0.2450\n",
      "\n",
      "Validation loss improved from 0.2451 to 0.2450. Saving model...\n",
      "LOG: Epoch [243/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3377\n",
      "LOG: Epoch [243/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3656\n",
      "    Batch [2/2], Val Loss: 0.1233\n",
      "Epoch [243/2000], Avg Train Loss: 0.3377, Avg Val Loss: 0.2444\n",
      "\n",
      "Validation loss improved from 0.2450 to 0.2444. Saving model...\n",
      "LOG: Epoch [244/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3383\n",
      "LOG: Epoch [244/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3648\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [244/2000], Avg Train Loss: 0.3383, Avg Val Loss: 0.2439\n",
      "\n",
      "Validation loss improved from 0.2444 to 0.2439. Saving model...\n",
      "LOG: Epoch [245/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3368\n",
      "LOG: Epoch [245/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3638\n",
      "    Batch [2/2], Val Loss: 0.1225\n",
      "Epoch [245/2000], Avg Train Loss: 0.3368, Avg Val Loss: 0.2432\n",
      "\n",
      "Validation loss improved from 0.2439 to 0.2432. Saving model...\n",
      "LOG: Epoch [246/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [246/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3637\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [246/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.2432\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [247/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3385\n",
      "LOG: Epoch [247/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3643\n",
      "    Batch [2/2], Val Loss: 0.1233\n",
      "Epoch [247/2000], Avg Train Loss: 0.3385, Avg Val Loss: 0.2438\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [248/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3362\n",
      "LOG: Epoch [248/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3645\n",
      "    Batch [2/2], Val Loss: 0.1238\n",
      "Epoch [248/2000], Avg Train Loss: 0.3362, Avg Val Loss: 0.2441\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [249/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3385\n",
      "LOG: Epoch [249/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3647\n",
      "    Batch [2/2], Val Loss: 0.1248\n",
      "Epoch [249/2000], Avg Train Loss: 0.3385, Avg Val Loss: 0.2448\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [250/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3385\n",
      "LOG: Epoch [250/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3649\n",
      "    Batch [2/2], Val Loss: 0.1255\n",
      "Epoch [250/2000], Avg Train Loss: 0.3385, Avg Val Loss: 0.2452\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [251/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3363\n",
      "LOG: Epoch [251/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3643\n",
      "    Batch [2/2], Val Loss: 0.1259\n",
      "Epoch [251/2000], Avg Train Loss: 0.3363, Avg Val Loss: 0.2451\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [252/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3390\n",
      "LOG: Epoch [252/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3639\n",
      "    Batch [2/2], Val Loss: 0.1260\n",
      "Epoch [252/2000], Avg Train Loss: 0.3390, Avg Val Loss: 0.2450\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [253/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3348\n",
      "LOG: Epoch [253/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3636\n",
      "    Batch [2/2], Val Loss: 0.1260\n",
      "Epoch [253/2000], Avg Train Loss: 0.3348, Avg Val Loss: 0.2448\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [254/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3334\n",
      "LOG: Epoch [254/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3634\n",
      "    Batch [2/2], Val Loss: 0.1260\n",
      "Epoch [254/2000], Avg Train Loss: 0.3334, Avg Val Loss: 0.2447\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [255/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3303\n",
      "LOG: Epoch [255/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3635\n",
      "    Batch [2/2], Val Loss: 0.1255\n",
      "Epoch [255/2000], Avg Train Loss: 0.3303, Avg Val Loss: 0.2445\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [256/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3333\n",
      "LOG: Epoch [256/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3639\n",
      "    Batch [2/2], Val Loss: 0.1251\n",
      "Epoch [256/2000], Avg Train Loss: 0.3333, Avg Val Loss: 0.2445\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [257/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3351\n",
      "LOG: Epoch [257/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3648\n",
      "    Batch [2/2], Val Loss: 0.1248\n",
      "Epoch [257/2000], Avg Train Loss: 0.3351, Avg Val Loss: 0.2448\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [258/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3357\n",
      "LOG: Epoch [258/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3652\n",
      "    Batch [2/2], Val Loss: 0.1238\n",
      "Epoch [258/2000], Avg Train Loss: 0.3357, Avg Val Loss: 0.2445\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [259/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3375\n",
      "LOG: Epoch [259/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3657\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [259/2000], Avg Train Loss: 0.3375, Avg Val Loss: 0.2443\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [260/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3333\n",
      "LOG: Epoch [260/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3664\n",
      "    Batch [2/2], Val Loss: 0.1217\n",
      "Epoch [260/2000], Avg Train Loss: 0.3333, Avg Val Loss: 0.2441\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [261/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3331\n",
      "LOG: Epoch [261/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3675\n",
      "    Batch [2/2], Val Loss: 0.1209\n",
      "Epoch [261/2000], Avg Train Loss: 0.3331, Avg Val Loss: 0.2442\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [262/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3288\n",
      "LOG: Epoch [262/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3681\n",
      "    Batch [2/2], Val Loss: 0.1199\n",
      "Epoch [262/2000], Avg Train Loss: 0.3288, Avg Val Loss: 0.2440\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [263/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3296\n",
      "LOG: Epoch [263/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3682\n",
      "    Batch [2/2], Val Loss: 0.1193\n",
      "Epoch [263/2000], Avg Train Loss: 0.3296, Avg Val Loss: 0.2438\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [264/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3337\n",
      "LOG: Epoch [264/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3688\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [264/2000], Avg Train Loss: 0.3337, Avg Val Loss: 0.2438\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [265/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3320\n",
      "LOG: Epoch [265/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3686\n",
      "    Batch [2/2], Val Loss: 0.1185\n",
      "Epoch [265/2000], Avg Train Loss: 0.3320, Avg Val Loss: 0.2436\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [266/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3275\n",
      "LOG: Epoch [266/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3685\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [266/2000], Avg Train Loss: 0.3275, Avg Val Loss: 0.2436\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3339\n",
      "LOG: Epoch [267/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3687\n",
      "    Batch [2/2], Val Loss: 0.1185\n",
      "Epoch [267/2000], Avg Train Loss: 0.3339, Avg Val Loss: 0.2436\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [268/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3272\n",
      "LOG: Epoch [268/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3690\n",
      "    Batch [2/2], Val Loss: 0.1184\n",
      "Epoch [268/2000], Avg Train Loss: 0.3272, Avg Val Loss: 0.2437\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [269/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3314\n",
      "LOG: Epoch [269/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3688\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [269/2000], Avg Train Loss: 0.3314, Avg Val Loss: 0.2435\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [270/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3313\n",
      "LOG: Epoch [270/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3678\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [270/2000], Avg Train Loss: 0.3313, Avg Val Loss: 0.2427\n",
      "\n",
      "Validation loss improved from 0.2432 to 0.2427. Saving model...\n",
      "LOG: Epoch [271/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3302\n",
      "LOG: Epoch [271/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3671\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [271/2000], Avg Train Loss: 0.3302, Avg Val Loss: 0.2424\n",
      "\n",
      "Validation loss improved from 0.2427 to 0.2424. Saving model...\n",
      "LOG: Epoch [272/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3296\n",
      "LOG: Epoch [272/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3660\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [272/2000], Avg Train Loss: 0.3296, Avg Val Loss: 0.2421\n",
      "\n",
      "Validation loss improved from 0.2424 to 0.2421. Saving model...\n",
      "LOG: Epoch [273/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3253\n",
      "LOG: Epoch [273/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3652\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [273/2000], Avg Train Loss: 0.3253, Avg Val Loss: 0.2419\n",
      "\n",
      "Validation loss improved from 0.2421 to 0.2419. Saving model...\n",
      "LOG: Epoch [274/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3267\n",
      "LOG: Epoch [274/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3640\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [274/2000], Avg Train Loss: 0.3267, Avg Val Loss: 0.2414\n",
      "\n",
      "Validation loss improved from 0.2419 to 0.2414. Saving model...\n",
      "LOG: Epoch [275/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3322\n",
      "LOG: Epoch [275/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3622\n",
      "    Batch [2/2], Val Loss: 0.1185\n",
      "Epoch [275/2000], Avg Train Loss: 0.3322, Avg Val Loss: 0.2404\n",
      "\n",
      "Validation loss improved from 0.2414 to 0.2404. Saving model...\n",
      "LOG: Epoch [276/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3239\n",
      "LOG: Epoch [276/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [276/2000], Avg Train Loss: 0.3239, Avg Val Loss: 0.2391\n",
      "\n",
      "Validation loss improved from 0.2404 to 0.2391. Saving model...\n",
      "LOG: Epoch [277/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3220\n",
      "LOG: Epoch [277/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3580\n",
      "    Batch [2/2], Val Loss: 0.1170\n",
      "Epoch [277/2000], Avg Train Loss: 0.3220, Avg Val Loss: 0.2375\n",
      "\n",
      "Validation loss improved from 0.2391 to 0.2375. Saving model...\n",
      "LOG: Epoch [278/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3266\n",
      "LOG: Epoch [278/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3558\n",
      "    Batch [2/2], Val Loss: 0.1164\n",
      "Epoch [278/2000], Avg Train Loss: 0.3266, Avg Val Loss: 0.2361\n",
      "\n",
      "Validation loss improved from 0.2375 to 0.2361. Saving model...\n",
      "LOG: Epoch [279/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3255\n",
      "LOG: Epoch [279/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3541\n",
      "    Batch [2/2], Val Loss: 0.1149\n",
      "Epoch [279/2000], Avg Train Loss: 0.3255, Avg Val Loss: 0.2345\n",
      "\n",
      "Validation loss improved from 0.2361 to 0.2345. Saving model...\n",
      "LOG: Epoch [280/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3254\n",
      "LOG: Epoch [280/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3527\n",
      "    Batch [2/2], Val Loss: 0.1139\n",
      "Epoch [280/2000], Avg Train Loss: 0.3254, Avg Val Loss: 0.2333\n",
      "\n",
      "Validation loss improved from 0.2345 to 0.2333. Saving model...\n",
      "LOG: Epoch [281/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3238\n",
      "LOG: Epoch [281/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3519\n",
      "    Batch [2/2], Val Loss: 0.1131\n",
      "Epoch [281/2000], Avg Train Loss: 0.3238, Avg Val Loss: 0.2325\n",
      "\n",
      "Validation loss improved from 0.2333 to 0.2325. Saving model...\n",
      "LOG: Epoch [282/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3259\n",
      "LOG: Epoch [282/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3514\n",
      "    Batch [2/2], Val Loss: 0.1125\n",
      "Epoch [282/2000], Avg Train Loss: 0.3259, Avg Val Loss: 0.2320\n",
      "\n",
      "Validation loss improved from 0.2325 to 0.2320. Saving model...\n",
      "LOG: Epoch [283/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3213\n",
      "LOG: Epoch [283/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3519\n",
      "    Batch [2/2], Val Loss: 0.1123\n",
      "Epoch [283/2000], Avg Train Loss: 0.3213, Avg Val Loss: 0.2321\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [284/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3228\n",
      "LOG: Epoch [284/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3522\n",
      "    Batch [2/2], Val Loss: 0.1120\n",
      "Epoch [284/2000], Avg Train Loss: 0.3228, Avg Val Loss: 0.2321\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [285/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3251\n",
      "LOG: Epoch [285/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3531\n",
      "    Batch [2/2], Val Loss: 0.1123\n",
      "Epoch [285/2000], Avg Train Loss: 0.3251, Avg Val Loss: 0.2327\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [286/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3213\n",
      "LOG: Epoch [286/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3549\n",
      "    Batch [2/2], Val Loss: 0.1128\n",
      "Epoch [286/2000], Avg Train Loss: 0.3213, Avg Val Loss: 0.2338\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [287/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3213\n",
      "LOG: Epoch [287/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3567\n",
      "    Batch [2/2], Val Loss: 0.1129\n",
      "Epoch [287/2000], Avg Train Loss: 0.3213, Avg Val Loss: 0.2348\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [288/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3207\n",
      "LOG: Epoch [288/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3582\n",
      "    Batch [2/2], Val Loss: 0.1133\n",
      "Epoch [288/2000], Avg Train Loss: 0.3207, Avg Val Loss: 0.2358\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [289/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3163\n",
      "LOG: Epoch [289/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3592\n",
      "    Batch [2/2], Val Loss: 0.1134\n",
      "Epoch [289/2000], Avg Train Loss: 0.3163, Avg Val Loss: 0.2363\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [290/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3165\n",
      "LOG: Epoch [290/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.1138\n",
      "Epoch [290/2000], Avg Train Loss: 0.3165, Avg Val Loss: 0.2370\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [291/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3173\n",
      "LOG: Epoch [291/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.1139\n",
      "Epoch [291/2000], Avg Train Loss: 0.3173, Avg Val Loss: 0.2375\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [292/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3189\n",
      "LOG: Epoch [292/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3620\n",
      "    Batch [2/2], Val Loss: 0.1140\n",
      "Epoch [292/2000], Avg Train Loss: 0.3189, Avg Val Loss: 0.2380\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [293/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3200\n",
      "LOG: Epoch [293/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3638\n",
      "    Batch [2/2], Val Loss: 0.1139\n",
      "Epoch [293/2000], Avg Train Loss: 0.3200, Avg Val Loss: 0.2389\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [294/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3222\n",
      "LOG: Epoch [294/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3642\n",
      "    Batch [2/2], Val Loss: 0.1139\n",
      "Epoch [294/2000], Avg Train Loss: 0.3222, Avg Val Loss: 0.2391\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [295/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3212\n",
      "LOG: Epoch [295/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3639\n",
      "    Batch [2/2], Val Loss: 0.1138\n",
      "Epoch [295/2000], Avg Train Loss: 0.3212, Avg Val Loss: 0.2389\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [296/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3217\n",
      "LOG: Epoch [296/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3628\n",
      "    Batch [2/2], Val Loss: 0.1135\n",
      "Epoch [296/2000], Avg Train Loss: 0.3217, Avg Val Loss: 0.2381\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [297/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3184\n",
      "LOG: Epoch [297/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.1135\n",
      "Epoch [297/2000], Avg Train Loss: 0.3184, Avg Val Loss: 0.2371\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [298/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3202\n",
      "LOG: Epoch [298/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3581\n",
      "    Batch [2/2], Val Loss: 0.1132\n",
      "Epoch [298/2000], Avg Train Loss: 0.3202, Avg Val Loss: 0.2356\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [299/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3179\n",
      "LOG: Epoch [299/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3556\n",
      "    Batch [2/2], Val Loss: 0.1128\n",
      "Epoch [299/2000], Avg Train Loss: 0.3179, Avg Val Loss: 0.2342\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [300/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3140\n",
      "LOG: Epoch [300/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3538\n",
      "    Batch [2/2], Val Loss: 0.1132\n",
      "Epoch [300/2000], Avg Train Loss: 0.3140, Avg Val Loss: 0.2335\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [301/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3152\n",
      "LOG: Epoch [301/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3524\n",
      "    Batch [2/2], Val Loss: 0.1134\n",
      "Epoch [301/2000], Avg Train Loss: 0.3152, Avg Val Loss: 0.2329\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [302/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3166\n",
      "LOG: Epoch [302/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3509\n",
      "    Batch [2/2], Val Loss: 0.1134\n",
      "Epoch [302/2000], Avg Train Loss: 0.3166, Avg Val Loss: 0.2321\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [303/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3169\n",
      "LOG: Epoch [303/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3501\n",
      "    Batch [2/2], Val Loss: 0.1135\n",
      "Epoch [303/2000], Avg Train Loss: 0.3169, Avg Val Loss: 0.2318\n",
      "\n",
      "Validation loss improved from 0.2320 to 0.2318. Saving model...\n",
      "LOG: Epoch [304/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3191\n",
      "LOG: Epoch [304/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3495\n",
      "    Batch [2/2], Val Loss: 0.1133\n",
      "Epoch [304/2000], Avg Train Loss: 0.3191, Avg Val Loss: 0.2314\n",
      "\n",
      "Validation loss improved from 0.2318 to 0.2314. Saving model...\n",
      "LOG: Epoch [305/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3169\n",
      "LOG: Epoch [305/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3499\n",
      "    Batch [2/2], Val Loss: 0.1133\n",
      "Epoch [305/2000], Avg Train Loss: 0.3169, Avg Val Loss: 0.2316\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [306/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3123\n",
      "LOG: Epoch [306/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3504\n",
      "    Batch [2/2], Val Loss: 0.1137\n",
      "Epoch [306/2000], Avg Train Loss: 0.3123, Avg Val Loss: 0.2321\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [307/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3128\n",
      "LOG: Epoch [307/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3505\n",
      "    Batch [2/2], Val Loss: 0.1140\n",
      "Epoch [307/2000], Avg Train Loss: 0.3128, Avg Val Loss: 0.2323\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [308/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3126\n",
      "LOG: Epoch [308/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3505\n",
      "    Batch [2/2], Val Loss: 0.1141\n",
      "Epoch [308/2000], Avg Train Loss: 0.3126, Avg Val Loss: 0.2323\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [309/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3149\n",
      "LOG: Epoch [309/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3501\n",
      "    Batch [2/2], Val Loss: 0.1141\n",
      "Epoch [309/2000], Avg Train Loss: 0.3149, Avg Val Loss: 0.2321\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [310/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3119\n",
      "LOG: Epoch [310/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3496\n",
      "    Batch [2/2], Val Loss: 0.1138\n",
      "Epoch [310/2000], Avg Train Loss: 0.3119, Avg Val Loss: 0.2317\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [311/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3169\n",
      "LOG: Epoch [311/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3487\n",
      "    Batch [2/2], Val Loss: 0.1134\n",
      "Epoch [311/2000], Avg Train Loss: 0.3169, Avg Val Loss: 0.2310\n",
      "\n",
      "Validation loss improved from 0.2314 to 0.2310. Saving model...\n",
      "LOG: Epoch [312/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3113\n",
      "LOG: Epoch [312/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3479\n",
      "    Batch [2/2], Val Loss: 0.1132\n",
      "Epoch [312/2000], Avg Train Loss: 0.3113, Avg Val Loss: 0.2306\n",
      "\n",
      "Validation loss improved from 0.2310 to 0.2306. Saving model...\n",
      "LOG: Epoch [313/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3115\n",
      "LOG: Epoch [313/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3466\n",
      "    Batch [2/2], Val Loss: 0.1133\n",
      "Epoch [313/2000], Avg Train Loss: 0.3115, Avg Val Loss: 0.2299\n",
      "\n",
      "Validation loss improved from 0.2306 to 0.2299. Saving model...\n",
      "LOG: Epoch [314/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3106\n",
      "LOG: Epoch [314/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3442\n",
      "    Batch [2/2], Val Loss: 0.1134\n",
      "Epoch [314/2000], Avg Train Loss: 0.3106, Avg Val Loss: 0.2288\n",
      "\n",
      "Validation loss improved from 0.2299 to 0.2288. Saving model...\n",
      "LOG: Epoch [315/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3101\n",
      "LOG: Epoch [315/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3412\n",
      "    Batch [2/2], Val Loss: 0.1131\n",
      "Epoch [315/2000], Avg Train Loss: 0.3101, Avg Val Loss: 0.2271\n",
      "\n",
      "Validation loss improved from 0.2288 to 0.2271. Saving model...\n",
      "LOG: Epoch [316/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3087\n",
      "LOG: Epoch [316/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3397\n",
      "    Batch [2/2], Val Loss: 0.1128\n",
      "Epoch [316/2000], Avg Train Loss: 0.3087, Avg Val Loss: 0.2263\n",
      "\n",
      "Validation loss improved from 0.2271 to 0.2263. Saving model...\n",
      "LOG: Epoch [317/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3093\n",
      "LOG: Epoch [317/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3388\n",
      "    Batch [2/2], Val Loss: 0.1125\n",
      "Epoch [317/2000], Avg Train Loss: 0.3093, Avg Val Loss: 0.2256\n",
      "\n",
      "Validation loss improved from 0.2263 to 0.2256. Saving model...\n",
      "LOG: Epoch [318/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3074\n",
      "LOG: Epoch [318/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3392\n",
      "    Batch [2/2], Val Loss: 0.1126\n",
      "Epoch [318/2000], Avg Train Loss: 0.3074, Avg Val Loss: 0.2259\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [319/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3072\n",
      "LOG: Epoch [319/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3396\n",
      "    Batch [2/2], Val Loss: 0.1125\n",
      "Epoch [319/2000], Avg Train Loss: 0.3072, Avg Val Loss: 0.2260\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [320/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3081\n",
      "LOG: Epoch [320/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3395\n",
      "    Batch [2/2], Val Loss: 0.1123\n",
      "Epoch [320/2000], Avg Train Loss: 0.3081, Avg Val Loss: 0.2259\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [321/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3032\n",
      "LOG: Epoch [321/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3398\n",
      "    Batch [2/2], Val Loss: 0.1119\n",
      "Epoch [321/2000], Avg Train Loss: 0.3032, Avg Val Loss: 0.2259\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [322/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3128\n",
      "LOG: Epoch [322/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3405\n",
      "    Batch [2/2], Val Loss: 0.1113\n",
      "Epoch [322/2000], Avg Train Loss: 0.3128, Avg Val Loss: 0.2259\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [323/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3061\n",
      "LOG: Epoch [323/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3403\n",
      "    Batch [2/2], Val Loss: 0.1104\n",
      "Epoch [323/2000], Avg Train Loss: 0.3061, Avg Val Loss: 0.2254\n",
      "\n",
      "Validation loss improved from 0.2256 to 0.2254. Saving model...\n",
      "LOG: Epoch [324/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3088\n",
      "LOG: Epoch [324/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3400\n",
      "    Batch [2/2], Val Loss: 0.1093\n",
      "Epoch [324/2000], Avg Train Loss: 0.3088, Avg Val Loss: 0.2246\n",
      "\n",
      "Validation loss improved from 0.2254 to 0.2246. Saving model...\n",
      "LOG: Epoch [325/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3062\n",
      "LOG: Epoch [325/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3394\n",
      "    Batch [2/2], Val Loss: 0.1080\n",
      "Epoch [325/2000], Avg Train Loss: 0.3062, Avg Val Loss: 0.2237\n",
      "\n",
      "Validation loss improved from 0.2246 to 0.2237. Saving model...\n",
      "LOG: Epoch [326/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3046\n",
      "LOG: Epoch [326/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3392\n",
      "    Batch [2/2], Val Loss: 0.1071\n",
      "Epoch [326/2000], Avg Train Loss: 0.3046, Avg Val Loss: 0.2231\n",
      "\n",
      "Validation loss improved from 0.2237 to 0.2231. Saving model...\n",
      "LOG: Epoch [327/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3043\n",
      "LOG: Epoch [327/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3397\n",
      "    Batch [2/2], Val Loss: 0.1066\n",
      "Epoch [327/2000], Avg Train Loss: 0.3043, Avg Val Loss: 0.2232\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [328/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3066\n",
      "LOG: Epoch [328/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3400\n",
      "    Batch [2/2], Val Loss: 0.1063\n",
      "Epoch [328/2000], Avg Train Loss: 0.3066, Avg Val Loss: 0.2231\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [329/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3017\n",
      "LOG: Epoch [329/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3401\n",
      "    Batch [2/2], Val Loss: 0.1058\n",
      "Epoch [329/2000], Avg Train Loss: 0.3017, Avg Val Loss: 0.2230\n",
      "\n",
      "Validation loss improved from 0.2231 to 0.2230. Saving model...\n",
      "LOG: Epoch [330/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3060\n",
      "LOG: Epoch [330/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3407\n",
      "    Batch [2/2], Val Loss: 0.1051\n",
      "Epoch [330/2000], Avg Train Loss: 0.3060, Avg Val Loss: 0.2229\n",
      "\n",
      "Validation loss improved from 0.2230 to 0.2229. Saving model...\n",
      "LOG: Epoch [331/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3021\n",
      "LOG: Epoch [331/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3414\n",
      "    Batch [2/2], Val Loss: 0.1049\n",
      "Epoch [331/2000], Avg Train Loss: 0.3021, Avg Val Loss: 0.2232\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [332/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3109\n",
      "LOG: Epoch [332/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3419\n",
      "    Batch [2/2], Val Loss: 0.1048\n",
      "Epoch [332/2000], Avg Train Loss: 0.3109, Avg Val Loss: 0.2234\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [333/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3021\n",
      "LOG: Epoch [333/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3415\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [333/2000], Avg Train Loss: 0.3021, Avg Val Loss: 0.2229\n",
      "\n",
      "Validation loss improved from 0.2229 to 0.2229. Saving model...\n",
      "LOG: Epoch [334/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3020\n",
      "LOG: Epoch [334/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3414\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [334/2000], Avg Train Loss: 0.3020, Avg Val Loss: 0.2228\n",
      "\n",
      "Validation loss improved from 0.2229 to 0.2228. Saving model...\n",
      "LOG: Epoch [335/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3038\n",
      "LOG: Epoch [335/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3424\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [335/2000], Avg Train Loss: 0.3038, Avg Val Loss: 0.2234\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [336/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3036\n",
      "LOG: Epoch [336/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3428\n",
      "    Batch [2/2], Val Loss: 0.1048\n",
      "Epoch [336/2000], Avg Train Loss: 0.3036, Avg Val Loss: 0.2238\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [337/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2983\n",
      "LOG: Epoch [337/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3430\n",
      "    Batch [2/2], Val Loss: 0.1050\n",
      "Epoch [337/2000], Avg Train Loss: 0.2983, Avg Val Loss: 0.2240\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [338/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3028\n",
      "LOG: Epoch [338/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3438\n",
      "    Batch [2/2], Val Loss: 0.1055\n",
      "Epoch [338/2000], Avg Train Loss: 0.3028, Avg Val Loss: 0.2246\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [339/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2996\n",
      "LOG: Epoch [339/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3449\n",
      "    Batch [2/2], Val Loss: 0.1057\n",
      "Epoch [339/2000], Avg Train Loss: 0.2996, Avg Val Loss: 0.2253\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [340/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2943\n",
      "LOG: Epoch [340/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3449\n",
      "    Batch [2/2], Val Loss: 0.1061\n",
      "Epoch [340/2000], Avg Train Loss: 0.2943, Avg Val Loss: 0.2255\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [341/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3017\n",
      "LOG: Epoch [341/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3441\n",
      "    Batch [2/2], Val Loss: 0.1064\n",
      "Epoch [341/2000], Avg Train Loss: 0.3017, Avg Val Loss: 0.2253\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [342/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3027\n",
      "LOG: Epoch [342/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3440\n",
      "    Batch [2/2], Val Loss: 0.1070\n",
      "Epoch [342/2000], Avg Train Loss: 0.3027, Avg Val Loss: 0.2255\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [343/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3048\n",
      "LOG: Epoch [343/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3432\n",
      "    Batch [2/2], Val Loss: 0.1072\n",
      "Epoch [343/2000], Avg Train Loss: 0.3048, Avg Val Loss: 0.2252\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [344/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2997\n",
      "LOG: Epoch [344/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3426\n",
      "    Batch [2/2], Val Loss: 0.1074\n",
      "Epoch [344/2000], Avg Train Loss: 0.2997, Avg Val Loss: 0.2250\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [345/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3026\n",
      "LOG: Epoch [345/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3421\n",
      "    Batch [2/2], Val Loss: 0.1072\n",
      "Epoch [345/2000], Avg Train Loss: 0.3026, Avg Val Loss: 0.2247\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [346/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3028\n",
      "LOG: Epoch [346/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3414\n",
      "    Batch [2/2], Val Loss: 0.1068\n",
      "Epoch [346/2000], Avg Train Loss: 0.3028, Avg Val Loss: 0.2241\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [347/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2987\n",
      "LOG: Epoch [347/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3409\n",
      "    Batch [2/2], Val Loss: 0.1064\n",
      "Epoch [347/2000], Avg Train Loss: 0.2987, Avg Val Loss: 0.2237\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [348/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3040\n",
      "LOG: Epoch [348/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3397\n",
      "    Batch [2/2], Val Loss: 0.1057\n",
      "Epoch [348/2000], Avg Train Loss: 0.3040, Avg Val Loss: 0.2227\n",
      "\n",
      "Validation loss improved from 0.2228 to 0.2227. Saving model...\n",
      "LOG: Epoch [349/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2983\n",
      "LOG: Epoch [349/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3384\n",
      "    Batch [2/2], Val Loss: 0.1050\n",
      "Epoch [349/2000], Avg Train Loss: 0.2983, Avg Val Loss: 0.2217\n",
      "\n",
      "Validation loss improved from 0.2227 to 0.2217. Saving model...\n",
      "LOG: Epoch [350/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3003\n",
      "LOG: Epoch [350/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3365\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [350/2000], Avg Train Loss: 0.3003, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2217 to 0.2203. Saving model...\n",
      "LOG: Epoch [351/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3022\n",
      "LOG: Epoch [351/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3340\n",
      "    Batch [2/2], Val Loss: 0.1028\n",
      "Epoch [351/2000], Avg Train Loss: 0.3022, Avg Val Loss: 0.2184\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2184. Saving model...\n",
      "LOG: Epoch [352/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2978\n",
      "LOG: Epoch [352/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3324\n",
      "    Batch [2/2], Val Loss: 0.1017\n",
      "Epoch [352/2000], Avg Train Loss: 0.2978, Avg Val Loss: 0.2171\n",
      "\n",
      "Validation loss improved from 0.2184 to 0.2171. Saving model...\n",
      "LOG: Epoch [353/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2966\n",
      "LOG: Epoch [353/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3306\n",
      "    Batch [2/2], Val Loss: 0.1010\n",
      "Epoch [353/2000], Avg Train Loss: 0.2966, Avg Val Loss: 0.2158\n",
      "\n",
      "Validation loss improved from 0.2171 to 0.2158. Saving model...\n",
      "LOG: Epoch [354/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2964\n",
      "LOG: Epoch [354/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3288\n",
      "    Batch [2/2], Val Loss: 0.0998\n",
      "Epoch [354/2000], Avg Train Loss: 0.2964, Avg Val Loss: 0.2143\n",
      "\n",
      "Validation loss improved from 0.2158 to 0.2143. Saving model...\n",
      "LOG: Epoch [355/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3015\n",
      "LOG: Epoch [355/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3283\n",
      "    Batch [2/2], Val Loss: 0.0992\n",
      "Epoch [355/2000], Avg Train Loss: 0.3015, Avg Val Loss: 0.2137\n",
      "\n",
      "Validation loss improved from 0.2143 to 0.2137. Saving model...\n",
      "LOG: Epoch [356/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2959\n",
      "LOG: Epoch [356/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3280\n",
      "    Batch [2/2], Val Loss: 0.0988\n",
      "Epoch [356/2000], Avg Train Loss: 0.2959, Avg Val Loss: 0.2134\n",
      "\n",
      "Validation loss improved from 0.2137 to 0.2134. Saving model...\n",
      "LOG: Epoch [357/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2945\n",
      "LOG: Epoch [357/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3279\n",
      "    Batch [2/2], Val Loss: 0.0980\n",
      "Epoch [357/2000], Avg Train Loss: 0.2945, Avg Val Loss: 0.2130\n",
      "\n",
      "Validation loss improved from 0.2134 to 0.2130. Saving model...\n",
      "LOG: Epoch [358/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2951\n",
      "LOG: Epoch [358/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3286\n",
      "    Batch [2/2], Val Loss: 0.0974\n",
      "Epoch [358/2000], Avg Train Loss: 0.2951, Avg Val Loss: 0.2130\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [359/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2927\n",
      "LOG: Epoch [359/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3280\n",
      "    Batch [2/2], Val Loss: 0.0964\n",
      "Epoch [359/2000], Avg Train Loss: 0.2927, Avg Val Loss: 0.2122\n",
      "\n",
      "Validation loss improved from 0.2130 to 0.2122. Saving model...\n",
      "LOG: Epoch [360/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2966\n",
      "LOG: Epoch [360/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3284\n",
      "    Batch [2/2], Val Loss: 0.0963\n",
      "Epoch [360/2000], Avg Train Loss: 0.2966, Avg Val Loss: 0.2124\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [361/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2942\n",
      "LOG: Epoch [361/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3276\n",
      "    Batch [2/2], Val Loss: 0.0961\n",
      "Epoch [361/2000], Avg Train Loss: 0.2942, Avg Val Loss: 0.2119\n",
      "\n",
      "Validation loss improved from 0.2122 to 0.2119. Saving model...\n",
      "LOG: Epoch [362/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2958\n",
      "LOG: Epoch [362/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3279\n",
      "    Batch [2/2], Val Loss: 0.0963\n",
      "Epoch [362/2000], Avg Train Loss: 0.2958, Avg Val Loss: 0.2121\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [363/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2889\n",
      "LOG: Epoch [363/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3280\n",
      "    Batch [2/2], Val Loss: 0.0965\n",
      "Epoch [363/2000], Avg Train Loss: 0.2889, Avg Val Loss: 0.2123\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [364/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2934\n",
      "LOG: Epoch [364/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3276\n",
      "    Batch [2/2], Val Loss: 0.0968\n",
      "Epoch [364/2000], Avg Train Loss: 0.2934, Avg Val Loss: 0.2122\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [365/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2914\n",
      "LOG: Epoch [365/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3282\n",
      "    Batch [2/2], Val Loss: 0.0972\n",
      "Epoch [365/2000], Avg Train Loss: 0.2914, Avg Val Loss: 0.2127\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [366/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2922\n",
      "LOG: Epoch [366/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3294\n",
      "    Batch [2/2], Val Loss: 0.0984\n",
      "Epoch [366/2000], Avg Train Loss: 0.2922, Avg Val Loss: 0.2139\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [367/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2916\n",
      "LOG: Epoch [367/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3304\n",
      "    Batch [2/2], Val Loss: 0.0993\n",
      "Epoch [367/2000], Avg Train Loss: 0.2916, Avg Val Loss: 0.2149\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [368/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2936\n",
      "LOG: Epoch [368/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3309\n",
      "    Batch [2/2], Val Loss: 0.1001\n",
      "Epoch [368/2000], Avg Train Loss: 0.2936, Avg Val Loss: 0.2155\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [369/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2911\n",
      "LOG: Epoch [369/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3309\n",
      "    Batch [2/2], Val Loss: 0.1004\n",
      "Epoch [369/2000], Avg Train Loss: 0.2911, Avg Val Loss: 0.2157\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [370/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2876\n",
      "LOG: Epoch [370/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3304\n",
      "    Batch [2/2], Val Loss: 0.1008\n",
      "Epoch [370/2000], Avg Train Loss: 0.2876, Avg Val Loss: 0.2156\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [371/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2915\n",
      "LOG: Epoch [371/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3302\n",
      "    Batch [2/2], Val Loss: 0.1011\n",
      "Epoch [371/2000], Avg Train Loss: 0.2915, Avg Val Loss: 0.2156\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [372/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2892\n",
      "LOG: Epoch [372/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3298\n",
      "    Batch [2/2], Val Loss: 0.1011\n",
      "Epoch [372/2000], Avg Train Loss: 0.2892, Avg Val Loss: 0.2155\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [373/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2925\n",
      "LOG: Epoch [373/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3297\n",
      "    Batch [2/2], Val Loss: 0.1011\n",
      "Epoch [373/2000], Avg Train Loss: 0.2925, Avg Val Loss: 0.2154\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [374/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2845\n",
      "LOG: Epoch [374/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3295\n",
      "    Batch [2/2], Val Loss: 0.1011\n",
      "Epoch [374/2000], Avg Train Loss: 0.2845, Avg Val Loss: 0.2153\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [375/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2911\n",
      "LOG: Epoch [375/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3296\n",
      "    Batch [2/2], Val Loss: 0.1008\n",
      "Epoch [375/2000], Avg Train Loss: 0.2911, Avg Val Loss: 0.2152\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [376/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2891\n",
      "LOG: Epoch [376/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3296\n",
      "    Batch [2/2], Val Loss: 0.1007\n",
      "Epoch [376/2000], Avg Train Loss: 0.2891, Avg Val Loss: 0.2152\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [377/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2897\n",
      "LOG: Epoch [377/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3299\n",
      "    Batch [2/2], Val Loss: 0.1005\n",
      "Epoch [377/2000], Avg Train Loss: 0.2897, Avg Val Loss: 0.2152\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [378/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2867\n",
      "LOG: Epoch [378/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3313\n",
      "    Batch [2/2], Val Loss: 0.1000\n",
      "Epoch [378/2000], Avg Train Loss: 0.2867, Avg Val Loss: 0.2156\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [379/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2915\n",
      "LOG: Epoch [379/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3326\n",
      "    Batch [2/2], Val Loss: 0.0998\n",
      "Epoch [379/2000], Avg Train Loss: 0.2915, Avg Val Loss: 0.2162\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [380/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2897\n",
      "LOG: Epoch [380/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3348\n",
      "    Batch [2/2], Val Loss: 0.0995\n",
      "Epoch [380/2000], Avg Train Loss: 0.2897, Avg Val Loss: 0.2172\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [381/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2885\n",
      "LOG: Epoch [381/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3377\n",
      "    Batch [2/2], Val Loss: 0.0996\n",
      "Epoch [381/2000], Avg Train Loss: 0.2885, Avg Val Loss: 0.2187\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [382/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2833\n",
      "LOG: Epoch [382/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3406\n",
      "    Batch [2/2], Val Loss: 0.1006\n",
      "Epoch [382/2000], Avg Train Loss: 0.2833, Avg Val Loss: 0.2206\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [383/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2863\n",
      "LOG: Epoch [383/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3423\n",
      "    Batch [2/2], Val Loss: 0.1022\n",
      "Epoch [383/2000], Avg Train Loss: 0.2863, Avg Val Loss: 0.2222\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [384/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [384/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3430\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [384/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2233\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [385/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2882\n",
      "LOG: Epoch [385/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3443\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [385/2000], Avg Train Loss: 0.2882, Avg Val Loss: 0.2244\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [386/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2866\n",
      "LOG: Epoch [386/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3443\n",
      "    Batch [2/2], Val Loss: 0.1046\n",
      "Epoch [386/2000], Avg Train Loss: 0.2866, Avg Val Loss: 0.2245\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [387/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2842\n",
      "LOG: Epoch [387/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3440\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [387/2000], Avg Train Loss: 0.2842, Avg Val Loss: 0.2240\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [388/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2839\n",
      "LOG: Epoch [388/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3402\n",
      "    Batch [2/2], Val Loss: 0.1027\n",
      "Epoch [388/2000], Avg Train Loss: 0.2839, Avg Val Loss: 0.2215\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [389/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2845\n",
      "LOG: Epoch [389/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3369\n",
      "    Batch [2/2], Val Loss: 0.1014\n",
      "Epoch [389/2000], Avg Train Loss: 0.2845, Avg Val Loss: 0.2192\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [390/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [390/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3338\n",
      "    Batch [2/2], Val Loss: 0.1004\n",
      "Epoch [390/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2171\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [391/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2851\n",
      "LOG: Epoch [391/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3310\n",
      "    Batch [2/2], Val Loss: 0.0995\n",
      "Epoch [391/2000], Avg Train Loss: 0.2851, Avg Val Loss: 0.2153\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [392/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2880\n",
      "LOG: Epoch [392/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3286\n",
      "    Batch [2/2], Val Loss: 0.0988\n",
      "Epoch [392/2000], Avg Train Loss: 0.2880, Avg Val Loss: 0.2137\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [393/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2884\n",
      "LOG: Epoch [393/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3266\n",
      "    Batch [2/2], Val Loss: 0.0982\n",
      "Epoch [393/2000], Avg Train Loss: 0.2884, Avg Val Loss: 0.2124\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [394/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2906\n",
      "LOG: Epoch [394/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3247\n",
      "    Batch [2/2], Val Loss: 0.0977\n",
      "Epoch [394/2000], Avg Train Loss: 0.2906, Avg Val Loss: 0.2112\n",
      "\n",
      "Validation loss improved from 0.2119 to 0.2112. Saving model...\n",
      "LOG: Epoch [395/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2861\n",
      "LOG: Epoch [395/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3231\n",
      "    Batch [2/2], Val Loss: 0.0972\n",
      "Epoch [395/2000], Avg Train Loss: 0.2861, Avg Val Loss: 0.2102\n",
      "\n",
      "Validation loss improved from 0.2112 to 0.2102. Saving model...\n",
      "LOG: Epoch [396/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2857\n",
      "LOG: Epoch [396/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3218\n",
      "    Batch [2/2], Val Loss: 0.0968\n",
      "Epoch [396/2000], Avg Train Loss: 0.2857, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2102 to 0.2093. Saving model...\n",
      "LOG: Epoch [397/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [397/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3208\n",
      "    Batch [2/2], Val Loss: 0.0965\n",
      "Epoch [397/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2086. Saving model...\n",
      "LOG: Epoch [398/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [398/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3200\n",
      "    Batch [2/2], Val Loss: 0.0962\n",
      "Epoch [398/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2081\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2081. Saving model...\n",
      "LOG: Epoch [399/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [399/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3195\n",
      "    Batch [2/2], Val Loss: 0.0958\n",
      "Epoch [399/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2077\n",
      "\n",
      "Validation loss improved from 0.2081 to 0.2077. Saving model...\n",
      "LOG: Epoch [400/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2860\n",
      "LOG: Epoch [400/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3191\n",
      "    Batch [2/2], Val Loss: 0.0957\n",
      "Epoch [400/2000], Avg Train Loss: 0.2860, Avg Val Loss: 0.2074\n",
      "\n",
      "Validation loss improved from 0.2077 to 0.2074. Saving model...\n",
      "LOG: Epoch [401/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2847\n",
      "LOG: Epoch [401/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3188\n",
      "    Batch [2/2], Val Loss: 0.0957\n",
      "Epoch [401/2000], Avg Train Loss: 0.2847, Avg Val Loss: 0.2072\n",
      "\n",
      "Validation loss improved from 0.2074 to 0.2072. Saving model...\n",
      "LOG: Epoch [402/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2848\n",
      "LOG: Epoch [402/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3185\n",
      "    Batch [2/2], Val Loss: 0.0956\n",
      "Epoch [402/2000], Avg Train Loss: 0.2848, Avg Val Loss: 0.2070\n",
      "\n",
      "Validation loss improved from 0.2072 to 0.2070. Saving model...\n",
      "LOG: Epoch [403/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [403/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3183\n",
      "    Batch [2/2], Val Loss: 0.0955\n",
      "Epoch [403/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2069\n",
      "\n",
      "Validation loss improved from 0.2070 to 0.2069. Saving model...\n",
      "LOG: Epoch [404/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [404/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3180\n",
      "    Batch [2/2], Val Loss: 0.0955\n",
      "Epoch [404/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2068\n",
      "\n",
      "Validation loss improved from 0.2069 to 0.2068. Saving model...\n",
      "LOG: Epoch [405/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [405/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3178\n",
      "    Batch [2/2], Val Loss: 0.0954\n",
      "Epoch [405/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2066\n",
      "\n",
      "Validation loss improved from 0.2068 to 0.2066. Saving model...\n",
      "LOG: Epoch [406/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2821\n",
      "LOG: Epoch [406/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3175\n",
      "    Batch [2/2], Val Loss: 0.0954\n",
      "Epoch [406/2000], Avg Train Loss: 0.2821, Avg Val Loss: 0.2065\n",
      "\n",
      "Validation loss improved from 0.2066 to 0.2065. Saving model...\n",
      "LOG: Epoch [407/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2825\n",
      "LOG: Epoch [407/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3174\n",
      "    Batch [2/2], Val Loss: 0.0953\n",
      "Epoch [407/2000], Avg Train Loss: 0.2825, Avg Val Loss: 0.2064\n",
      "\n",
      "Validation loss improved from 0.2065 to 0.2064. Saving model...\n",
      "LOG: Epoch [408/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [408/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3173\n",
      "    Batch [2/2], Val Loss: 0.0953\n",
      "Epoch [408/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2063\n",
      "\n",
      "Validation loss improved from 0.2064 to 0.2063. Saving model...\n",
      "LOG: Epoch [409/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2861\n",
      "LOG: Epoch [409/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3171\n",
      "    Batch [2/2], Val Loss: 0.0952\n",
      "Epoch [409/2000], Avg Train Loss: 0.2861, Avg Val Loss: 0.2062\n",
      "\n",
      "Validation loss improved from 0.2063 to 0.2062. Saving model...\n",
      "LOG: Epoch [410/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2827\n",
      "LOG: Epoch [410/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3170\n",
      "    Batch [2/2], Val Loss: 0.0953\n",
      "Epoch [410/2000], Avg Train Loss: 0.2827, Avg Val Loss: 0.2061\n",
      "\n",
      "Validation loss improved from 0.2062 to 0.2061. Saving model...\n",
      "LOG: Epoch [411/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [411/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3168\n",
      "    Batch [2/2], Val Loss: 0.0953\n",
      "Epoch [411/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2060\n",
      "\n",
      "Validation loss improved from 0.2061 to 0.2060. Saving model...\n",
      "LOG: Epoch [412/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2841\n",
      "LOG: Epoch [412/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3166\n",
      "    Batch [2/2], Val Loss: 0.0953\n",
      "Epoch [412/2000], Avg Train Loss: 0.2841, Avg Val Loss: 0.2060\n",
      "\n",
      "Validation loss improved from 0.2060 to 0.2060. Saving model...\n",
      "LOG: Epoch [413/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2868\n",
      "LOG: Epoch [413/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3165\n",
      "    Batch [2/2], Val Loss: 0.0953\n",
      "Epoch [413/2000], Avg Train Loss: 0.2868, Avg Val Loss: 0.2059\n",
      "\n",
      "Validation loss improved from 0.2060 to 0.2059. Saving model...\n",
      "LOG: Epoch [414/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2863\n",
      "LOG: Epoch [414/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3165\n",
      "    Batch [2/2], Val Loss: 0.0953\n",
      "Epoch [414/2000], Avg Train Loss: 0.2863, Avg Val Loss: 0.2059\n",
      "\n",
      "Validation loss improved from 0.2059 to 0.2059. Saving model...\n",
      "LOG: Epoch [415/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2832\n",
      "LOG: Epoch [415/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3163\n",
      "    Batch [2/2], Val Loss: 0.0952\n",
      "Epoch [415/2000], Avg Train Loss: 0.2832, Avg Val Loss: 0.2058\n",
      "\n",
      "Validation loss improved from 0.2059 to 0.2058. Saving model...\n",
      "LOG: Epoch [416/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2870\n",
      "LOG: Epoch [416/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3162\n",
      "    Batch [2/2], Val Loss: 0.0952\n",
      "Epoch [416/2000], Avg Train Loss: 0.2870, Avg Val Loss: 0.2057\n",
      "\n",
      "Validation loss improved from 0.2058 to 0.2057. Saving model...\n",
      "LOG: Epoch [417/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2844\n",
      "LOG: Epoch [417/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3162\n",
      "    Batch [2/2], Val Loss: 0.0952\n",
      "Epoch [417/2000], Avg Train Loss: 0.2844, Avg Val Loss: 0.2057\n",
      "\n",
      "Validation loss improved from 0.2057 to 0.2057. Saving model...\n",
      "LOG: Epoch [418/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2850\n",
      "LOG: Epoch [418/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3161\n",
      "    Batch [2/2], Val Loss: 0.0952\n",
      "Epoch [418/2000], Avg Train Loss: 0.2850, Avg Val Loss: 0.2056\n",
      "\n",
      "Validation loss improved from 0.2057 to 0.2056. Saving model...\n",
      "LOG: Epoch [419/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2841\n",
      "LOG: Epoch [419/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3160\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [419/2000], Avg Train Loss: 0.2841, Avg Val Loss: 0.2056\n",
      "\n",
      "Validation loss improved from 0.2056 to 0.2056. Saving model...\n",
      "LOG: Epoch [420/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2812\n",
      "LOG: Epoch [420/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3159\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [420/2000], Avg Train Loss: 0.2812, Avg Val Loss: 0.2055\n",
      "\n",
      "Validation loss improved from 0.2056 to 0.2055. Saving model...\n",
      "LOG: Epoch [421/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [421/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3158\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [421/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2054\n",
      "\n",
      "Validation loss improved from 0.2055 to 0.2054. Saving model...\n",
      "LOG: Epoch [422/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [422/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3158\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [422/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2054\n",
      "\n",
      "Validation loss improved from 0.2054 to 0.2054. Saving model...\n",
      "LOG: Epoch [423/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2846\n",
      "LOG: Epoch [423/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3158\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [423/2000], Avg Train Loss: 0.2846, Avg Val Loss: 0.2054\n",
      "\n",
      "Validation loss improved from 0.2054 to 0.2054. Saving model...\n",
      "LOG: Epoch [424/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2828\n",
      "LOG: Epoch [424/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3158\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [424/2000], Avg Train Loss: 0.2828, Avg Val Loss: 0.2054\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [425/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [425/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3159\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [425/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2054\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [426/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [426/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3159\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [426/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2055\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [427/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [427/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3158\n",
      "    Batch [2/2], Val Loss: 0.0952\n",
      "Epoch [427/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2055\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [428/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [428/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3158\n",
      "    Batch [2/2], Val Loss: 0.0952\n",
      "Epoch [428/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2055\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [429/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2876\n",
      "LOG: Epoch [429/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3157\n",
      "    Batch [2/2], Val Loss: 0.0953\n",
      "Epoch [429/2000], Avg Train Loss: 0.2876, Avg Val Loss: 0.2055\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [430/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2842\n",
      "LOG: Epoch [430/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3156\n",
      "    Batch [2/2], Val Loss: 0.0953\n",
      "Epoch [430/2000], Avg Train Loss: 0.2842, Avg Val Loss: 0.2055\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [431/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2840\n",
      "LOG: Epoch [431/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3155\n",
      "    Batch [2/2], Val Loss: 0.0954\n",
      "Epoch [431/2000], Avg Train Loss: 0.2840, Avg Val Loss: 0.2055\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [432/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2890\n",
      "LOG: Epoch [432/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3154\n",
      "    Batch [2/2], Val Loss: 0.0955\n",
      "Epoch [432/2000], Avg Train Loss: 0.2890, Avg Val Loss: 0.2054\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [433/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [433/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3153\n",
      "    Batch [2/2], Val Loss: 0.0955\n",
      "Epoch [433/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2054\n",
      "\n",
      "Validation loss improved from 0.2054 to 0.2054. Saving model...\n",
      "LOG: Epoch [434/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [434/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3152\n",
      "    Batch [2/2], Val Loss: 0.0956\n",
      "Epoch [434/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2054\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [435/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2848\n",
      "LOG: Epoch [435/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3152\n",
      "    Batch [2/2], Val Loss: 0.0956\n",
      "Epoch [435/2000], Avg Train Loss: 0.2848, Avg Val Loss: 0.2054\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2827\n",
      "LOG: Epoch [436/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3151\n",
      "    Batch [2/2], Val Loss: 0.0956\n",
      "Epoch [436/2000], Avg Train Loss: 0.2827, Avg Val Loss: 0.2054\n",
      "\n",
      "Validation loss improved from 0.2054 to 0.2054. Saving model...\n",
      "LOG: Epoch [437/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [437/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3151\n",
      "    Batch [2/2], Val Loss: 0.0956\n",
      "Epoch [437/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2054\n",
      "\n",
      "Validation loss improved from 0.2054 to 0.2054. Saving model...\n",
      "LOG: Epoch [438/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [438/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3150\n",
      "    Batch [2/2], Val Loss: 0.0956\n",
      "Epoch [438/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2053\n",
      "\n",
      "Validation loss improved from 0.2054 to 0.2053. Saving model...\n",
      "LOG: Epoch [439/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [439/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3150\n",
      "    Batch [2/2], Val Loss: 0.0956\n",
      "Epoch [439/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2053\n",
      "\n",
      "Validation loss improved from 0.2053 to 0.2053. Saving model...\n",
      "LOG: Epoch [440/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2848\n",
      "LOG: Epoch [440/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3150\n",
      "    Batch [2/2], Val Loss: 0.0955\n",
      "Epoch [440/2000], Avg Train Loss: 0.2848, Avg Val Loss: 0.2053\n",
      "\n",
      "Validation loss improved from 0.2053 to 0.2053. Saving model...\n",
      "LOG: Epoch [441/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2815\n",
      "LOG: Epoch [441/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3149\n",
      "    Batch [2/2], Val Loss: 0.0955\n",
      "Epoch [441/2000], Avg Train Loss: 0.2815, Avg Val Loss: 0.2052\n",
      "\n",
      "Validation loss improved from 0.2053 to 0.2052. Saving model...\n",
      "LOG: Epoch [442/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2878\n",
      "LOG: Epoch [442/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3149\n",
      "    Batch [2/2], Val Loss: 0.0954\n",
      "Epoch [442/2000], Avg Train Loss: 0.2878, Avg Val Loss: 0.2052\n",
      "\n",
      "Validation loss improved from 0.2052 to 0.2052. Saving model...\n",
      "LOG: Epoch [443/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2843\n",
      "LOG: Epoch [443/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3149\n",
      "    Batch [2/2], Val Loss: 0.0953\n",
      "Epoch [443/2000], Avg Train Loss: 0.2843, Avg Val Loss: 0.2051\n",
      "\n",
      "Validation loss improved from 0.2052 to 0.2051. Saving model...\n",
      "LOG: Epoch [444/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [444/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3149\n",
      "    Batch [2/2], Val Loss: 0.0952\n",
      "Epoch [444/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2051\n",
      "\n",
      "Validation loss improved from 0.2051 to 0.2051. Saving model...\n",
      "LOG: Epoch [445/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [445/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3149\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [445/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2050\n",
      "\n",
      "Validation loss improved from 0.2051 to 0.2050. Saving model...\n",
      "LOG: Epoch [446/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [446/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3149\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [446/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2050\n",
      "\n",
      "Validation loss improved from 0.2050 to 0.2050. Saving model...\n",
      "LOG: Epoch [447/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [447/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3149\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [447/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2050\n",
      "\n",
      "Validation loss improved from 0.2050 to 0.2050. Saving model...\n",
      "LOG: Epoch [448/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [448/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3150\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [448/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2050\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [449/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [449/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3151\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [449/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2050\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [450/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2851\n",
      "LOG: Epoch [450/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3151\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [450/2000], Avg Train Loss: 0.2851, Avg Val Loss: 0.2050\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [451/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3151\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [451/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2050\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [452/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2861\n",
      "LOG: Epoch [452/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3151\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [452/2000], Avg Train Loss: 0.2861, Avg Val Loss: 0.2050\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [453/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2848\n",
      "LOG: Epoch [453/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3151\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [453/2000], Avg Train Loss: 0.2848, Avg Val Loss: 0.2051\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [454/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2834\n",
      "LOG: Epoch [454/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3152\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [454/2000], Avg Train Loss: 0.2834, Avg Val Loss: 0.2051\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [455/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2871\n",
      "LOG: Epoch [455/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3152\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [455/2000], Avg Train Loss: 0.2871, Avg Val Loss: 0.2051\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [456/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2861\n",
      "LOG: Epoch [456/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3152\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [456/2000], Avg Train Loss: 0.2861, Avg Val Loss: 0.2052\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [457/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [457/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3153\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [457/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2052\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [458/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2767\n",
      "LOG: Epoch [458/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3153\n",
      "    Batch [2/2], Val Loss: 0.0952\n",
      "Epoch [458/2000], Avg Train Loss: 0.2767, Avg Val Loss: 0.2052\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [459/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [459/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3153\n",
      "    Batch [2/2], Val Loss: 0.0952\n",
      "Epoch [459/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2052\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [460/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [460/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3153\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [460/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2052\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [461/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [461/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3153\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [461/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2052\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [462/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2799\n",
      "LOG: Epoch [462/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3153\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [462/2000], Avg Train Loss: 0.2799, Avg Val Loss: 0.2052\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [463/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [463/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3152\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [463/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2052\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [464/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2862\n",
      "LOG: Epoch [464/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3153\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [464/2000], Avg Train Loss: 0.2862, Avg Val Loss: 0.2051\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [465/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2850\n",
      "LOG: Epoch [465/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3153\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [465/2000], Avg Train Loss: 0.2850, Avg Val Loss: 0.2051\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [466/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2829\n",
      "LOG: Epoch [466/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3153\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [466/2000], Avg Train Loss: 0.2829, Avg Val Loss: 0.2051\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [467/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2762\n",
      "LOG: Epoch [467/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3153\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [467/2000], Avg Train Loss: 0.2762, Avg Val Loss: 0.2050\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [468/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [468/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3153\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [468/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2050\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [469/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2863\n",
      "LOG: Epoch [469/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3152\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [469/2000], Avg Train Loss: 0.2863, Avg Val Loss: 0.2050\n",
      "\n",
      "Validation loss improved from 0.2050 to 0.2050. Saving model...\n",
      "LOG: Epoch [470/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2834\n",
      "LOG: Epoch [470/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3152\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [470/2000], Avg Train Loss: 0.2834, Avg Val Loss: 0.2049\n",
      "\n",
      "Validation loss improved from 0.2050 to 0.2049. Saving model...\n",
      "LOG: Epoch [471/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [471/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3152\n",
      "    Batch [2/2], Val Loss: 0.0945\n",
      "Epoch [471/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2049\n",
      "\n",
      "Validation loss improved from 0.2049 to 0.2049. Saving model...\n",
      "LOG: Epoch [472/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2867\n",
      "LOG: Epoch [472/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3152\n",
      "    Batch [2/2], Val Loss: 0.0945\n",
      "Epoch [472/2000], Avg Train Loss: 0.2867, Avg Val Loss: 0.2048\n",
      "\n",
      "Validation loss improved from 0.2049 to 0.2048. Saving model...\n",
      "LOG: Epoch [473/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [473/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3152\n",
      "    Batch [2/2], Val Loss: 0.0945\n",
      "Epoch [473/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2048\n",
      "\n",
      "Validation loss improved from 0.2048 to 0.2048. Saving model...\n",
      "LOG: Epoch [474/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2750\n",
      "LOG: Epoch [474/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3152\n",
      "    Batch [2/2], Val Loss: 0.0945\n",
      "Epoch [474/2000], Avg Train Loss: 0.2750, Avg Val Loss: 0.2048\n",
      "\n",
      "Validation loss improved from 0.2048 to 0.2048. Saving model...\n",
      "LOG: Epoch [475/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2836\n",
      "LOG: Epoch [475/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3152\n",
      "    Batch [2/2], Val Loss: 0.0945\n",
      "Epoch [475/2000], Avg Train Loss: 0.2836, Avg Val Loss: 0.2049\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [476/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [476/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3153\n",
      "    Batch [2/2], Val Loss: 0.0945\n",
      "Epoch [476/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2049\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [477/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [477/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3153\n",
      "    Batch [2/2], Val Loss: 0.0945\n",
      "Epoch [477/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2049\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [478/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [478/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3154\n",
      "    Batch [2/2], Val Loss: 0.0945\n",
      "Epoch [478/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2049\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [479/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2858\n",
      "LOG: Epoch [479/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3154\n",
      "    Batch [2/2], Val Loss: 0.0945\n",
      "Epoch [479/2000], Avg Train Loss: 0.2858, Avg Val Loss: 0.2049\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [480/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [480/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3153\n",
      "    Batch [2/2], Val Loss: 0.0945\n",
      "Epoch [480/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2049\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [481/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2821\n",
      "LOG: Epoch [481/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3152\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [481/2000], Avg Train Loss: 0.2821, Avg Val Loss: 0.2049\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [482/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [482/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3151\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [482/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2049\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [483/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [483/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3151\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [483/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2049\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [484/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [484/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3150\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [484/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2048\n",
      "\n",
      "Validation loss improved from 0.2048 to 0.2048. Saving model...\n",
      "LOG: Epoch [485/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2832\n",
      "LOG: Epoch [485/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3149\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [485/2000], Avg Train Loss: 0.2832, Avg Val Loss: 0.2048\n",
      "\n",
      "Validation loss improved from 0.2048 to 0.2048. Saving model...\n",
      "LOG: Epoch [486/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [486/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3148\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [486/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2048\n",
      "\n",
      "Validation loss improved from 0.2048 to 0.2048. Saving model...\n",
      "LOG: Epoch [487/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [487/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3147\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [487/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2047\n",
      "\n",
      "Validation loss improved from 0.2048 to 0.2047. Saving model...\n",
      "LOG: Epoch [488/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2868\n",
      "LOG: Epoch [488/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [488/2000], Avg Train Loss: 0.2868, Avg Val Loss: 0.2047\n",
      "\n",
      "Validation loss improved from 0.2047 to 0.2047. Saving model...\n",
      "LOG: Epoch [489/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2862\n",
      "LOG: Epoch [489/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [489/2000], Avg Train Loss: 0.2862, Avg Val Loss: 0.2047\n",
      "\n",
      "Validation loss improved from 0.2047 to 0.2047. Saving model...\n",
      "LOG: Epoch [490/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2858\n",
      "LOG: Epoch [490/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [490/2000], Avg Train Loss: 0.2858, Avg Val Loss: 0.2047\n",
      "\n",
      "Validation loss improved from 0.2047 to 0.2047. Saving model...\n",
      "LOG: Epoch [491/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2842\n",
      "LOG: Epoch [491/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [491/2000], Avg Train Loss: 0.2842, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [492/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2821\n",
      "LOG: Epoch [492/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [492/2000], Avg Train Loss: 0.2821, Avg Val Loss: 0.2047\n",
      "\n",
      "Validation loss improved from 0.2047 to 0.2047. Saving model...\n",
      "LOG: Epoch [493/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [493/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [493/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2047\n",
      "\n",
      "Validation loss improved from 0.2047 to 0.2047. Saving model...\n",
      "LOG: Epoch [494/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2771\n",
      "LOG: Epoch [494/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [494/2000], Avg Train Loss: 0.2771, Avg Val Loss: 0.2047\n",
      "\n",
      "Validation loss improved from 0.2047 to 0.2047. Saving model...\n",
      "LOG: Epoch [495/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2736\n",
      "LOG: Epoch [495/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [495/2000], Avg Train Loss: 0.2736, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [496/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2852\n",
      "LOG: Epoch [496/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [496/2000], Avg Train Loss: 0.2852, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [497/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2768\n",
      "LOG: Epoch [497/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [497/2000], Avg Train Loss: 0.2768, Avg Val Loss: 0.2047\n",
      "\n",
      "Validation loss improved from 0.2047 to 0.2047. Saving model...\n",
      "LOG: Epoch [498/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [498/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [498/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2046\n",
      "\n",
      "Validation loss improved from 0.2047 to 0.2046. Saving model...\n",
      "LOG: Epoch [499/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [499/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [499/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2046\n",
      "\n",
      "Validation loss improved from 0.2046 to 0.2046. Saving model...\n",
      "LOG: Epoch [500/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2865\n",
      "LOG: Epoch [500/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [500/2000], Avg Train Loss: 0.2865, Avg Val Loss: 0.2046\n",
      "\n",
      "Validation loss improved from 0.2046 to 0.2046. Saving model...\n",
      "LOG: Epoch [501/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [501/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [501/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2046\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [502/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [502/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [502/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [503/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2775\n",
      "LOG: Epoch [503/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [503/2000], Avg Train Loss: 0.2775, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [504/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [504/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [504/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [505/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [505/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [505/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [506/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2799\n",
      "LOG: Epoch [506/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [506/2000], Avg Train Loss: 0.2799, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [507/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2812\n",
      "LOG: Epoch [507/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [507/2000], Avg Train Loss: 0.2812, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [508/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2766\n",
      "LOG: Epoch [508/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [508/2000], Avg Train Loss: 0.2766, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [509/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [509/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [509/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [510/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [510/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [510/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [511/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2813\n",
      "LOG: Epoch [511/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [511/2000], Avg Train Loss: 0.2813, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [512/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2731\n",
      "LOG: Epoch [512/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [512/2000], Avg Train Loss: 0.2731, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [513/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2839\n",
      "LOG: Epoch [513/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [513/2000], Avg Train Loss: 0.2839, Avg Val Loss: 0.2046\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [514/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [514/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [514/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2046\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [515/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2831\n",
      "LOG: Epoch [515/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [515/2000], Avg Train Loss: 0.2831, Avg Val Loss: 0.2046\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [516/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [516/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [516/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [517/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [517/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [517/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [518/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [518/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [518/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [519/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [519/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [519/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2048\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [520/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [520/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [520/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2048\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [521/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [521/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [521/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2048\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [522/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [522/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3147\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [522/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2048\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [523/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [523/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3147\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [523/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2048\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [524/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [524/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3147\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [524/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2049\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [525/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2799\n",
      "LOG: Epoch [525/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [525/2000], Avg Train Loss: 0.2799, Avg Val Loss: 0.2049\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [526/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2742\n",
      "LOG: Epoch [526/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3146\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [526/2000], Avg Train Loss: 0.2742, Avg Val Loss: 0.2048\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [527/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2771\n",
      "LOG: Epoch [527/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [527/2000], Avg Train Loss: 0.2771, Avg Val Loss: 0.2048\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [528/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [528/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [528/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2048\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [529/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [529/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [529/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [530/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2799\n",
      "LOG: Epoch [530/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3145\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [530/2000], Avg Train Loss: 0.2799, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [531/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [531/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3144\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [531/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [532/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2817\n",
      "LOG: Epoch [532/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3144\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [532/2000], Avg Train Loss: 0.2817, Avg Val Loss: 0.2047\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [533/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2738\n",
      "LOG: Epoch [533/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3144\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [533/2000], Avg Train Loss: 0.2738, Avg Val Loss: 0.2046\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [534/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [534/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [534/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2046\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [535/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2759\n",
      "LOG: Epoch [535/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [535/2000], Avg Train Loss: 0.2759, Avg Val Loss: 0.2046\n",
      "\n",
      "Validation loss improved from 0.2046 to 0.2046. Saving model...\n",
      "LOG: Epoch [536/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [536/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [536/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2046\n",
      "\n",
      "Validation loss improved from 0.2046 to 0.2046. Saving model...\n",
      "LOG: Epoch [537/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2831\n",
      "LOG: Epoch [537/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0949\n",
      "Epoch [537/2000], Avg Train Loss: 0.2831, Avg Val Loss: 0.2046\n",
      "\n",
      "Validation loss improved from 0.2046 to 0.2046. Saving model...\n",
      "LOG: Epoch [538/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2768\n",
      "LOG: Epoch [538/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [538/2000], Avg Train Loss: 0.2768, Avg Val Loss: 0.2046\n",
      "\n",
      "Validation loss improved from 0.2046 to 0.2046. Saving model...\n",
      "LOG: Epoch [539/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [539/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [539/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2046\n",
      "\n",
      "Validation loss improved from 0.2046 to 0.2046. Saving model...\n",
      "LOG: Epoch [540/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [540/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [540/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2046\n",
      "\n",
      "Validation loss improved from 0.2046 to 0.2046. Saving model...\n",
      "LOG: Epoch [541/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [541/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [541/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2046 to 0.2045. Saving model...\n",
      "LOG: Epoch [542/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [542/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [542/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [543/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2741\n",
      "LOG: Epoch [543/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0948\n",
      "Epoch [543/2000], Avg Train Loss: 0.2741, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [544/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2851\n",
      "LOG: Epoch [544/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [544/2000], Avg Train Loss: 0.2851, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [545/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2853\n",
      "LOG: Epoch [545/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [545/2000], Avg Train Loss: 0.2853, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [546/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [546/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [546/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [547/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2763\n",
      "LOG: Epoch [547/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [547/2000], Avg Train Loss: 0.2763, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [548/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2859\n",
      "LOG: Epoch [548/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [548/2000], Avg Train Loss: 0.2859, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [549/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [549/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [549/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [550/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2766\n",
      "LOG: Epoch [550/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [550/2000], Avg Train Loss: 0.2766, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [551/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [551/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [551/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [552/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [552/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [552/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [553/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [553/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [553/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [554/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [554/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [554/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [555/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [555/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [555/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [556/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [556/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [556/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [557/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [557/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3143\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [557/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [558/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2737\n",
      "LOG: Epoch [558/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [558/2000], Avg Train Loss: 0.2737, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [559/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [559/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [559/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [560/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [560/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [560/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2045\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2045. Saving model...\n",
      "LOG: Epoch [561/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2762\n",
      "LOG: Epoch [561/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [561/2000], Avg Train Loss: 0.2762, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2045 to 0.2044. Saving model...\n",
      "LOG: Epoch [562/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [562/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [562/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [563/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [563/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [563/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [564/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2777\n",
      "LOG: Epoch [564/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [564/2000], Avg Train Loss: 0.2777, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [565/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2764\n",
      "LOG: Epoch [565/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [565/2000], Avg Train Loss: 0.2764, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [566/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2765\n",
      "LOG: Epoch [566/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [566/2000], Avg Train Loss: 0.2765, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [567/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2708\n",
      "LOG: Epoch [567/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [567/2000], Avg Train Loss: 0.2708, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [568/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [568/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [568/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [569/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [569/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [569/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2044\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [570/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2763\n",
      "LOG: Epoch [570/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [570/2000], Avg Train Loss: 0.2763, Avg Val Loss: 0.2044\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [571/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [571/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [571/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2044\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [572/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [572/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [572/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [573/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2754\n",
      "LOG: Epoch [573/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [573/2000], Avg Train Loss: 0.2754, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [574/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [574/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [574/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [575/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2762\n",
      "LOG: Epoch [575/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [575/2000], Avg Train Loss: 0.2762, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [576/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [576/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [576/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [577/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2831\n",
      "LOG: Epoch [577/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [577/2000], Avg Train Loss: 0.2831, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [578/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [578/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2044\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [579/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2846\n",
      "LOG: Epoch [579/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [579/2000], Avg Train Loss: 0.2846, Avg Val Loss: 0.2044\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [580/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [580/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3142\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [580/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2044\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [581/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2764\n",
      "LOG: Epoch [581/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3141\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [581/2000], Avg Train Loss: 0.2764, Avg Val Loss: 0.2044\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [582/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2764\n",
      "LOG: Epoch [582/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3141\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [582/2000], Avg Train Loss: 0.2764, Avg Val Loss: 0.2044\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [583/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [583/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3141\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [583/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [584/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [584/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3141\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [584/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [585/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2826\n",
      "LOG: Epoch [585/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3141\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [585/2000], Avg Train Loss: 0.2826, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [586/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2751\n",
      "LOG: Epoch [586/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3141\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [586/2000], Avg Train Loss: 0.2751, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [587/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [587/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3141\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [587/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [588/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [588/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3141\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [588/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [589/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [589/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3141\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [589/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [590/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2770\n",
      "LOG: Epoch [590/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3141\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [590/2000], Avg Train Loss: 0.2770, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [591/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2799\n",
      "LOG: Epoch [591/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3141\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [591/2000], Avg Train Loss: 0.2799, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [592/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [592/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3141\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [592/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [593/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [593/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3141\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [593/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [594/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [594/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3141\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [594/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [595/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2821\n",
      "LOG: Epoch [595/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [595/2000], Avg Train Loss: 0.2821, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [596/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2760\n",
      "LOG: Epoch [596/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [596/2000], Avg Train Loss: 0.2760, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [597/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2829\n",
      "LOG: Epoch [597/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [597/2000], Avg Train Loss: 0.2829, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [598/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2838\n",
      "LOG: Epoch [598/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [598/2000], Avg Train Loss: 0.2838, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [599/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [599/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [599/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2044\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2044. Saving model...\n",
      "LOG: Epoch [600/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2824\n",
      "LOG: Epoch [600/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [600/2000], Avg Train Loss: 0.2824, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2044 to 0.2043. Saving model...\n",
      "LOG: Epoch [601/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [601/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [601/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [602/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [602/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [602/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [603/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2812\n",
      "LOG: Epoch [603/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [603/2000], Avg Train Loss: 0.2812, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [604/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2827\n",
      "LOG: Epoch [604/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [604/2000], Avg Train Loss: 0.2827, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [605/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [605/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [605/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [606/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [606/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [606/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [607/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [607/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [607/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [608/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [608/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [608/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [609/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [609/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [609/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [610/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [610/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [610/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [611/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2752\n",
      "LOG: Epoch [611/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [611/2000], Avg Train Loss: 0.2752, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [612/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [612/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [612/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [613/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2808\n",
      "LOG: Epoch [613/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [613/2000], Avg Train Loss: 0.2808, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [614/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [614/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [615/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [615/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [615/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2755\n",
      "LOG: Epoch [616/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [616/2000], Avg Train Loss: 0.2755, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [617/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2841\n",
      "LOG: Epoch [617/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [617/2000], Avg Train Loss: 0.2841, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [618/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2847\n",
      "LOG: Epoch [618/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [618/2000], Avg Train Loss: 0.2847, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [619/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2767\n",
      "LOG: Epoch [619/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [619/2000], Avg Train Loss: 0.2767, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [620/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2747\n",
      "LOG: Epoch [620/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [620/2000], Avg Train Loss: 0.2747, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [621/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2836\n",
      "LOG: Epoch [621/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [621/2000], Avg Train Loss: 0.2836, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [622/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [622/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [622/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [623/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [623/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [623/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [624/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2808\n",
      "LOG: Epoch [624/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [624/2000], Avg Train Loss: 0.2808, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [625/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [625/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [625/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [626/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2763\n",
      "LOG: Epoch [626/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [626/2000], Avg Train Loss: 0.2763, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [627/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [627/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [627/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [628/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [628/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [628/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [629/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [629/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [629/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [630/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [630/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [630/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [631/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2815\n",
      "LOG: Epoch [631/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [631/2000], Avg Train Loss: 0.2815, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [632/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [632/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [632/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [633/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [633/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [633/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [634/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2767\n",
      "LOG: Epoch [634/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [634/2000], Avg Train Loss: 0.2767, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [635/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2833\n",
      "LOG: Epoch [635/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [635/2000], Avg Train Loss: 0.2833, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [636/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [636/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [636/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [637/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2813\n",
      "LOG: Epoch [637/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [637/2000], Avg Train Loss: 0.2813, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [638/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [638/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [638/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [639/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2777\n",
      "LOG: Epoch [639/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [639/2000], Avg Train Loss: 0.2777, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [640/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [640/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [640/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [641/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2760\n",
      "LOG: Epoch [641/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [641/2000], Avg Train Loss: 0.2760, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [642/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [642/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [642/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [643/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [643/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [643/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [644/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2759\n",
      "LOG: Epoch [644/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [644/2000], Avg Train Loss: 0.2759, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [645/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [645/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [645/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [646/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2799\n",
      "LOG: Epoch [646/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [646/2000], Avg Train Loss: 0.2799, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [647/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2833\n",
      "LOG: Epoch [647/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [647/2000], Avg Train Loss: 0.2833, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [648/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [648/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [648/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [649/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [649/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [649/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [650/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [650/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [650/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [651/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [651/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [651/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [652/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [652/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [652/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [653/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2755\n",
      "LOG: Epoch [653/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [653/2000], Avg Train Loss: 0.2755, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [654/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [654/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [654/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [655/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [655/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [655/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [656/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [656/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [656/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [657/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2758\n",
      "LOG: Epoch [657/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [657/2000], Avg Train Loss: 0.2758, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [658/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [658/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [658/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [659/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [659/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [659/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [660/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [660/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [660/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [661/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [661/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [661/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [662/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [662/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [662/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [663/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2836\n",
      "LOG: Epoch [663/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [663/2000], Avg Train Loss: 0.2836, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [664/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [664/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [664/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [665/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2842\n",
      "LOG: Epoch [665/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [665/2000], Avg Train Loss: 0.2842, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [666/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [666/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [666/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [667/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2752\n",
      "LOG: Epoch [667/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [667/2000], Avg Train Loss: 0.2752, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [668/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [668/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [668/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [669/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [669/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [669/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [670/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2758\n",
      "LOG: Epoch [670/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [670/2000], Avg Train Loss: 0.2758, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [671/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [671/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [671/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [672/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2777\n",
      "LOG: Epoch [672/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [672/2000], Avg Train Loss: 0.2777, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [673/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2837\n",
      "LOG: Epoch [673/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [673/2000], Avg Train Loss: 0.2837, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [674/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [674/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [674/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [675/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2812\n",
      "LOG: Epoch [675/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [675/2000], Avg Train Loss: 0.2812, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [676/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2828\n",
      "LOG: Epoch [676/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [676/2000], Avg Train Loss: 0.2828, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [677/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [677/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [677/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [678/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [678/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [678/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [679/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [679/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [679/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [680/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [680/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [680/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [681/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2759\n",
      "LOG: Epoch [681/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [681/2000], Avg Train Loss: 0.2759, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [682/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [682/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [682/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [683/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [683/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [683/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [684/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2749\n",
      "LOG: Epoch [684/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [684/2000], Avg Train Loss: 0.2749, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [685/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [685/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [685/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [686/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [686/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [686/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [687/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2841\n",
      "LOG: Epoch [687/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [687/2000], Avg Train Loss: 0.2841, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [688/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [688/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [688/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [689/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2849\n",
      "LOG: Epoch [689/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [689/2000], Avg Train Loss: 0.2849, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [690/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2750\n",
      "LOG: Epoch [690/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [690/2000], Avg Train Loss: 0.2750, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [691/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [691/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [691/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [692/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2759\n",
      "LOG: Epoch [692/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [692/2000], Avg Train Loss: 0.2759, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [693/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [693/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [693/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [694/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2850\n",
      "LOG: Epoch [694/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [694/2000], Avg Train Loss: 0.2850, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [695/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [695/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [695/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [696/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [696/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [696/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [697/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2857\n",
      "LOG: Epoch [697/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [697/2000], Avg Train Loss: 0.2857, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [698/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [698/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [698/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [699/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2775\n",
      "LOG: Epoch [699/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [699/2000], Avg Train Loss: 0.2775, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [700/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [700/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [700/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [701/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2784\n",
      "LOG: Epoch [701/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [701/2000], Avg Train Loss: 0.2784, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [702/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [702/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [702/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [703/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [703/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [703/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [704/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2747\n",
      "LOG: Epoch [704/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [704/2000], Avg Train Loss: 0.2747, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [705/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2754\n",
      "LOG: Epoch [705/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [705/2000], Avg Train Loss: 0.2754, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [706/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2775\n",
      "LOG: Epoch [706/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [706/2000], Avg Train Loss: 0.2775, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "LOG: Epoch [707/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [707/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [707/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "LOG: Epoch [708/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2771\n",
      "LOG: Epoch [708/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [708/2000], Avg Train Loss: 0.2771, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "LOG: Epoch [709/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [709/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [709/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "LOG: Epoch [710/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2830\n",
      "LOG: Epoch [710/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [710/2000], Avg Train Loss: 0.2830, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "LOG: Epoch [711/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2767\n",
      "LOG: Epoch [711/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [711/2000], Avg Train Loss: 0.2767, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "LOG: Epoch [712/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2829\n",
      "LOG: Epoch [712/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [712/2000], Avg Train Loss: 0.2829, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "LOG: Epoch [713/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [713/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [713/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "LOG: Epoch [714/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [714/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [714/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "LOG: Epoch [715/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [715/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [715/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "LOG: Epoch [716/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [716/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [716/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "LOG: Epoch [717/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2762\n",
      "LOG: Epoch [717/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [717/2000], Avg Train Loss: 0.2762, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "LOG: Epoch [718/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [718/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [718/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "LOG: Epoch [719/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2746\n",
      "LOG: Epoch [719/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [719/2000], Avg Train Loss: 0.2746, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "LOG: Epoch [720/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [720/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [720/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "LOG: Epoch [721/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [721/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [721/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "LOG: Epoch [722/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [722/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [722/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "LOG: Epoch [723/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [723/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [723/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "LOG: Epoch [724/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [724/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [724/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "LOG: Epoch [725/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2830\n",
      "LOG: Epoch [725/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [725/2000], Avg Train Loss: 0.2830, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "LOG: Epoch [726/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [726/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [726/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "LOG: Epoch [727/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [727/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [727/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "LOG: Epoch [728/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [728/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [728/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [729/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2756\n",
      "LOG: Epoch [729/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [729/2000], Avg Train Loss: 0.2756, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [730/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [730/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [730/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [731/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [731/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [731/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [732/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [732/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [732/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [733/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [733/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [733/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [734/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2826\n",
      "LOG: Epoch [734/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [734/2000], Avg Train Loss: 0.2826, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [735/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2829\n",
      "LOG: Epoch [735/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [735/2000], Avg Train Loss: 0.2829, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [736/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [736/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [736/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [737/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [737/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [737/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [738/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2777\n",
      "LOG: Epoch [738/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [738/2000], Avg Train Loss: 0.2777, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [739/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [739/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [739/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [740/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2825\n",
      "LOG: Epoch [740/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [740/2000], Avg Train Loss: 0.2825, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [741/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [741/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [741/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [742/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [742/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [742/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [743/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [743/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [743/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [744/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2844\n",
      "LOG: Epoch [744/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [744/2000], Avg Train Loss: 0.2844, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [745/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2758\n",
      "LOG: Epoch [745/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [745/2000], Avg Train Loss: 0.2758, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [746/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2832\n",
      "LOG: Epoch [746/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [746/2000], Avg Train Loss: 0.2832, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [747/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2838\n",
      "LOG: Epoch [747/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [747/2000], Avg Train Loss: 0.2838, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [748/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2860\n",
      "LOG: Epoch [748/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [748/2000], Avg Train Loss: 0.2860, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [749/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2841\n",
      "LOG: Epoch [749/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [749/2000], Avg Train Loss: 0.2841, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [750/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [750/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [750/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [751/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [751/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [751/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [752/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [752/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [752/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [753/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [753/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [753/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [754/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2851\n",
      "LOG: Epoch [754/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [754/2000], Avg Train Loss: 0.2851, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [755/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [755/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [755/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [756/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2765\n",
      "LOG: Epoch [756/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [756/2000], Avg Train Loss: 0.2765, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [757/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2737\n",
      "LOG: Epoch [757/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [757/2000], Avg Train Loss: 0.2737, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [758/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2799\n",
      "LOG: Epoch [758/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [758/2000], Avg Train Loss: 0.2799, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [759/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2763\n",
      "LOG: Epoch [759/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [759/2000], Avg Train Loss: 0.2763, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [760/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2826\n",
      "LOG: Epoch [760/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [760/2000], Avg Train Loss: 0.2826, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [761/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2759\n",
      "LOG: Epoch [761/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [761/2000], Avg Train Loss: 0.2759, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [762/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [762/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [762/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [763/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [763/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [763/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [764/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2777\n",
      "LOG: Epoch [764/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [764/2000], Avg Train Loss: 0.2777, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [765/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2808\n",
      "LOG: Epoch [765/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [765/2000], Avg Train Loss: 0.2808, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [766/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [766/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [766/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [767/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2765\n",
      "LOG: Epoch [767/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [767/2000], Avg Train Loss: 0.2765, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [768/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [768/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [768/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [769/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [769/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [769/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [770/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2824\n",
      "LOG: Epoch [770/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [770/2000], Avg Train Loss: 0.2824, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [771/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2847\n",
      "LOG: Epoch [771/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [771/2000], Avg Train Loss: 0.2847, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [772/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2813\n",
      "LOG: Epoch [772/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [772/2000], Avg Train Loss: 0.2813, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [773/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [773/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [773/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [774/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2746\n",
      "LOG: Epoch [774/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [774/2000], Avg Train Loss: 0.2746, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [775/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [775/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [775/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [776/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [776/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [776/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [777/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [777/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [777/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [778/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [778/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [778/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [779/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2815\n",
      "LOG: Epoch [779/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [779/2000], Avg Train Loss: 0.2815, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [780/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [780/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [780/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [781/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2751\n",
      "LOG: Epoch [781/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [781/2000], Avg Train Loss: 0.2751, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [782/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2799\n",
      "LOG: Epoch [782/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [782/2000], Avg Train Loss: 0.2799, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [783/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2767\n",
      "LOG: Epoch [783/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [783/2000], Avg Train Loss: 0.2767, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [784/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2834\n",
      "LOG: Epoch [784/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [784/2000], Avg Train Loss: 0.2834, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [785/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2828\n",
      "LOG: Epoch [785/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [785/2000], Avg Train Loss: 0.2828, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [786/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [786/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [786/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [787/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2768\n",
      "LOG: Epoch [787/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [787/2000], Avg Train Loss: 0.2768, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [788/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2821\n",
      "LOG: Epoch [788/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [788/2000], Avg Train Loss: 0.2821, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [789/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2757\n",
      "LOG: Epoch [789/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [789/2000], Avg Train Loss: 0.2757, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [790/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [790/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [790/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [791/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [791/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [791/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [792/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2739\n",
      "LOG: Epoch [792/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [792/2000], Avg Train Loss: 0.2739, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [793/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2826\n",
      "LOG: Epoch [793/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [793/2000], Avg Train Loss: 0.2826, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [794/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [794/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [794/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [795/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2837\n",
      "LOG: Epoch [795/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [795/2000], Avg Train Loss: 0.2837, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [796/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2735\n",
      "LOG: Epoch [796/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [796/2000], Avg Train Loss: 0.2735, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [797/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [797/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [797/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [798/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [798/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [798/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [799/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [799/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [799/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [800/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2831\n",
      "LOG: Epoch [800/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [800/2000], Avg Train Loss: 0.2831, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [801/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [801/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [801/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [802/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [802/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [802/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [803/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [803/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [803/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [804/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [804/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [804/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [805/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [805/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [805/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [806/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [806/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [806/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [807/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2766\n",
      "LOG: Epoch [807/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [807/2000], Avg Train Loss: 0.2766, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [808/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [808/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [808/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [809/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2745\n",
      "LOG: Epoch [809/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [809/2000], Avg Train Loss: 0.2745, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [810/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [810/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [810/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [811/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2758\n",
      "LOG: Epoch [811/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [811/2000], Avg Train Loss: 0.2758, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [812/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [812/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [812/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [813/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [813/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [813/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [814/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [814/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [814/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [815/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [815/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [815/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [816/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2812\n",
      "LOG: Epoch [816/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [816/2000], Avg Train Loss: 0.2812, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [817/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2758\n",
      "LOG: Epoch [817/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [817/2000], Avg Train Loss: 0.2758, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [818/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2813\n",
      "LOG: Epoch [818/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [818/2000], Avg Train Loss: 0.2813, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [819/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [819/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [819/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [820/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2784\n",
      "LOG: Epoch [820/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [820/2000], Avg Train Loss: 0.2784, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [821/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2767\n",
      "LOG: Epoch [821/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [821/2000], Avg Train Loss: 0.2767, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [822/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [822/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [822/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [823/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2773\n",
      "LOG: Epoch [823/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [823/2000], Avg Train Loss: 0.2773, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [824/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2824\n",
      "LOG: Epoch [824/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [824/2000], Avg Train Loss: 0.2824, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [825/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [825/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [825/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [826/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [826/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [826/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [827/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2741\n",
      "LOG: Epoch [827/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [827/2000], Avg Train Loss: 0.2741, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [828/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [828/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [828/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [829/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2836\n",
      "LOG: Epoch [829/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [829/2000], Avg Train Loss: 0.2836, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [830/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [830/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [830/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [831/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2777\n",
      "LOG: Epoch [831/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [831/2000], Avg Train Loss: 0.2777, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [832/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [832/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [832/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [833/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2808\n",
      "LOG: Epoch [833/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [833/2000], Avg Train Loss: 0.2808, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [834/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [834/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [834/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [835/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [835/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [835/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [836/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [836/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [836/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [837/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [837/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [837/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [838/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [838/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [838/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [839/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2852\n",
      "LOG: Epoch [839/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [839/2000], Avg Train Loss: 0.2852, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [840/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2784\n",
      "LOG: Epoch [840/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [840/2000], Avg Train Loss: 0.2784, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [841/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [841/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [841/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [842/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2740\n",
      "LOG: Epoch [842/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [842/2000], Avg Train Loss: 0.2740, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [843/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2746\n",
      "LOG: Epoch [843/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [843/2000], Avg Train Loss: 0.2746, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [844/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [844/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [844/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [845/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [845/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [845/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [846/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [846/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [846/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [847/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2836\n",
      "LOG: Epoch [847/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [847/2000], Avg Train Loss: 0.2836, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [848/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2775\n",
      "LOG: Epoch [848/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [848/2000], Avg Train Loss: 0.2775, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [849/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [849/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [849/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [850/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [850/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [850/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [851/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2777\n",
      "LOG: Epoch [851/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [851/2000], Avg Train Loss: 0.2777, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [852/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2754\n",
      "LOG: Epoch [852/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [852/2000], Avg Train Loss: 0.2754, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [853/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [853/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [853/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [854/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2757\n",
      "LOG: Epoch [854/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [854/2000], Avg Train Loss: 0.2757, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [855/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2741\n",
      "LOG: Epoch [855/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [855/2000], Avg Train Loss: 0.2741, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [856/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [856/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [856/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [857/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [857/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [857/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [858/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2760\n",
      "LOG: Epoch [858/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [858/2000], Avg Train Loss: 0.2760, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [859/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2854\n",
      "LOG: Epoch [859/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [859/2000], Avg Train Loss: 0.2854, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [860/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2834\n",
      "LOG: Epoch [860/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [860/2000], Avg Train Loss: 0.2834, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [861/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [861/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [861/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [862/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2764\n",
      "LOG: Epoch [862/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [862/2000], Avg Train Loss: 0.2764, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [863/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [863/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [863/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [864/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [864/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [864/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [865/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2770\n",
      "LOG: Epoch [865/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [865/2000], Avg Train Loss: 0.2770, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [866/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [866/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [866/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [867/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2754\n",
      "LOG: Epoch [867/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [867/2000], Avg Train Loss: 0.2754, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [868/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [868/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [868/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [869/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [869/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [869/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [870/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [870/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [870/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [871/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [871/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [871/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [872/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2775\n",
      "LOG: Epoch [872/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [872/2000], Avg Train Loss: 0.2775, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [873/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [873/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [873/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [874/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [874/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [874/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [875/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [875/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [875/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [876/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [876/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [876/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [877/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2812\n",
      "LOG: Epoch [877/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [877/2000], Avg Train Loss: 0.2812, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [878/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [878/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [878/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [879/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [879/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [879/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [880/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [880/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [880/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [881/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2759\n",
      "LOG: Epoch [881/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [881/2000], Avg Train Loss: 0.2759, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [882/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2827\n",
      "LOG: Epoch [882/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [882/2000], Avg Train Loss: 0.2827, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [883/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [883/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [883/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [884/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [884/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [884/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [885/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [885/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [885/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [886/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2784\n",
      "LOG: Epoch [886/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [886/2000], Avg Train Loss: 0.2784, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [887/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [887/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [887/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [888/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2815\n",
      "LOG: Epoch [888/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [888/2000], Avg Train Loss: 0.2815, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [889/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [889/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [889/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [890/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [890/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [890/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [891/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2844\n",
      "LOG: Epoch [891/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [891/2000], Avg Train Loss: 0.2844, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [892/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [892/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [892/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [893/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [893/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [893/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [894/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [894/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [894/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [895/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2843\n",
      "LOG: Epoch [895/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [895/2000], Avg Train Loss: 0.2843, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [896/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2815\n",
      "LOG: Epoch [896/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [896/2000], Avg Train Loss: 0.2815, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [897/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [897/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [897/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [898/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [898/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [898/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [899/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2725\n",
      "LOG: Epoch [899/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [899/2000], Avg Train Loss: 0.2725, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [900/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [900/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [900/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [901/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2825\n",
      "LOG: Epoch [901/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [901/2000], Avg Train Loss: 0.2825, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [902/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [902/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [902/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [903/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [903/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [903/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [904/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [904/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [904/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [905/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2852\n",
      "LOG: Epoch [905/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [905/2000], Avg Train Loss: 0.2852, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [906/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2813\n",
      "LOG: Epoch [906/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [906/2000], Avg Train Loss: 0.2813, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [907/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2775\n",
      "LOG: Epoch [907/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [907/2000], Avg Train Loss: 0.2775, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [908/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2715\n",
      "LOG: Epoch [908/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [908/2000], Avg Train Loss: 0.2715, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [909/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [909/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [909/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [910/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [910/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [910/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "LOG: Epoch [911/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2824\n",
      "LOG: Epoch [911/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [911/2000], Avg Train Loss: 0.2824, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "LOG: Epoch [912/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2762\n",
      "LOG: Epoch [912/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [912/2000], Avg Train Loss: 0.2762, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "LOG: Epoch [913/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2756\n",
      "LOG: Epoch [913/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [913/2000], Avg Train Loss: 0.2756, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [914/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2831\n",
      "LOG: Epoch [914/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [914/2000], Avg Train Loss: 0.2831, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [915/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2844\n",
      "LOG: Epoch [915/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [915/2000], Avg Train Loss: 0.2844, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [916/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [916/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [916/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [917/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [917/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [917/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [918/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [918/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [918/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [919/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [919/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [919/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [920/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2808\n",
      "LOG: Epoch [920/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [920/2000], Avg Train Loss: 0.2808, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [921/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [921/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [921/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [922/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2824\n",
      "LOG: Epoch [922/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [922/2000], Avg Train Loss: 0.2824, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [923/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [923/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [923/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [924/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2834\n",
      "LOG: Epoch [924/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [924/2000], Avg Train Loss: 0.2834, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [925/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2829\n",
      "LOG: Epoch [925/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [925/2000], Avg Train Loss: 0.2829, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [926/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [926/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [926/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [927/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [927/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [927/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [928/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2821\n",
      "LOG: Epoch [928/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [928/2000], Avg Train Loss: 0.2821, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [929/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [929/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [929/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [930/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2834\n",
      "LOG: Epoch [930/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [930/2000], Avg Train Loss: 0.2834, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [931/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2784\n",
      "LOG: Epoch [931/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [931/2000], Avg Train Loss: 0.2784, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [932/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [932/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [932/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [933/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2881\n",
      "LOG: Epoch [933/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [933/2000], Avg Train Loss: 0.2881, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [934/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [934/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [934/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [935/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [935/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [935/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [936/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [936/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [936/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [937/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [937/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [937/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [938/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [938/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [938/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [939/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [939/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [939/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [940/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [940/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [940/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [941/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [941/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [941/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [942/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [942/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [942/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [943/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2763\n",
      "LOG: Epoch [943/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [943/2000], Avg Train Loss: 0.2763, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [944/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2747\n",
      "LOG: Epoch [944/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [944/2000], Avg Train Loss: 0.2747, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [945/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2865\n",
      "LOG: Epoch [945/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [945/2000], Avg Train Loss: 0.2865, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [946/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [946/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [946/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [947/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [947/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [947/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [948/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [948/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [948/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [949/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2813\n",
      "LOG: Epoch [949/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [949/2000], Avg Train Loss: 0.2813, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [950/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [950/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [950/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [951/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2833\n",
      "LOG: Epoch [951/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [951/2000], Avg Train Loss: 0.2833, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [952/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2824\n",
      "LOG: Epoch [952/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [952/2000], Avg Train Loss: 0.2824, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [953/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2775\n",
      "LOG: Epoch [953/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [953/2000], Avg Train Loss: 0.2775, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [954/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [954/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [954/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [955/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [955/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [955/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [956/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2850\n",
      "LOG: Epoch [956/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [956/2000], Avg Train Loss: 0.2850, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [957/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [957/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [957/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [958/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [958/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [958/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [959/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2755\n",
      "LOG: Epoch [959/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [959/2000], Avg Train Loss: 0.2755, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [960/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [960/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [960/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [961/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [961/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [961/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [962/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2824\n",
      "LOG: Epoch [962/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [962/2000], Avg Train Loss: 0.2824, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [963/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [963/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [963/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [964/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [964/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [964/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [965/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2754\n",
      "LOG: Epoch [965/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [965/2000], Avg Train Loss: 0.2754, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [966/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2830\n",
      "LOG: Epoch [966/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [966/2000], Avg Train Loss: 0.2830, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [967/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2762\n",
      "LOG: Epoch [967/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [967/2000], Avg Train Loss: 0.2762, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [968/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2784\n",
      "LOG: Epoch [968/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [968/2000], Avg Train Loss: 0.2784, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [969/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2736\n",
      "LOG: Epoch [969/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [969/2000], Avg Train Loss: 0.2736, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [970/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2725\n",
      "LOG: Epoch [970/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [970/2000], Avg Train Loss: 0.2725, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [971/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [971/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [971/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [972/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [972/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [972/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [973/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2808\n",
      "LOG: Epoch [973/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [973/2000], Avg Train Loss: 0.2808, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [974/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2808\n",
      "LOG: Epoch [974/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [974/2000], Avg Train Loss: 0.2808, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [975/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2880\n",
      "LOG: Epoch [975/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [975/2000], Avg Train Loss: 0.2880, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [976/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [976/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [976/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [977/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [977/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [977/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [978/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [978/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [978/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [979/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [979/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [979/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [980/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [980/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [980/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [981/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [981/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [981/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [982/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [982/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [982/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [983/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2815\n",
      "LOG: Epoch [983/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [983/2000], Avg Train Loss: 0.2815, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [984/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [984/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [984/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [985/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [985/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [985/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [986/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2855\n",
      "LOG: Epoch [986/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [986/2000], Avg Train Loss: 0.2855, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [987/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2752\n",
      "LOG: Epoch [987/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [987/2000], Avg Train Loss: 0.2752, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [988/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2808\n",
      "LOG: Epoch [988/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [988/2000], Avg Train Loss: 0.2808, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [989/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [989/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [989/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [990/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2739\n",
      "LOG: Epoch [990/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [990/2000], Avg Train Loss: 0.2739, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [991/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2753\n",
      "LOG: Epoch [991/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [991/2000], Avg Train Loss: 0.2753, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [992/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2826\n",
      "LOG: Epoch [992/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [992/2000], Avg Train Loss: 0.2826, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [993/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2722\n",
      "LOG: Epoch [993/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [993/2000], Avg Train Loss: 0.2722, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [994/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2775\n",
      "LOG: Epoch [994/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [994/2000], Avg Train Loss: 0.2775, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [995/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2768\n",
      "LOG: Epoch [995/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [995/2000], Avg Train Loss: 0.2768, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [996/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2834\n",
      "LOG: Epoch [996/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [996/2000], Avg Train Loss: 0.2834, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [997/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [997/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [997/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [998/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [998/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [998/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [999/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2866\n",
      "LOG: Epoch [999/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [999/2000], Avg Train Loss: 0.2866, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1000/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2770\n",
      "LOG: Epoch [1000/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1000/2000], Avg Train Loss: 0.2770, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1001/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1001/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1001/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1002/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [1002/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1002/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1003/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2838\n",
      "LOG: Epoch [1003/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1003/2000], Avg Train Loss: 0.2838, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1004/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [1004/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1004/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1005/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2812\n",
      "LOG: Epoch [1005/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1005/2000], Avg Train Loss: 0.2812, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1006/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [1006/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1006/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1007/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [1007/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1007/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1008/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [1008/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1008/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1009/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2759\n",
      "LOG: Epoch [1009/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1009/2000], Avg Train Loss: 0.2759, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1010/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [1010/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1010/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1011/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [1011/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1011/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1012/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2773\n",
      "LOG: Epoch [1012/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1012/2000], Avg Train Loss: 0.2773, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1013/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2826\n",
      "LOG: Epoch [1013/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1013/2000], Avg Train Loss: 0.2826, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1014/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1014/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1014/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1015/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2827\n",
      "LOG: Epoch [1015/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1015/2000], Avg Train Loss: 0.2827, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1016/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [1016/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1016/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1017/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [1017/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1017/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1018/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [1018/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1018/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1019/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1019/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1019/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1020/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2821\n",
      "LOG: Epoch [1020/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1020/2000], Avg Train Loss: 0.2821, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1021/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2759\n",
      "LOG: Epoch [1021/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1021/2000], Avg Train Loss: 0.2759, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1022/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1022/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1022/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1023/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [1023/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1023/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1024/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2856\n",
      "LOG: Epoch [1024/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1024/2000], Avg Train Loss: 0.2856, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1025/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2839\n",
      "LOG: Epoch [1025/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1025/2000], Avg Train Loss: 0.2839, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1026/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [1026/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1026/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [1027/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2770\n",
      "LOG: Epoch [1027/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1027/2000], Avg Train Loss: 0.2770, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [1028/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [1028/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1028/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [1029/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2784\n",
      "LOG: Epoch [1029/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1029/2000], Avg Train Loss: 0.2784, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [1030/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [1030/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1030/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [1031/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2841\n",
      "LOG: Epoch [1031/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1031/2000], Avg Train Loss: 0.2841, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [1032/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2815\n",
      "LOG: Epoch [1032/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1032/2000], Avg Train Loss: 0.2815, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1033/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2813\n",
      "LOG: Epoch [1033/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1033/2000], Avg Train Loss: 0.2813, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1034/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1034/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1034/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1035/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2861\n",
      "LOG: Epoch [1035/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1035/2000], Avg Train Loss: 0.2861, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1036/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [1036/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1036/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1037/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [1037/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1037/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1038/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2756\n",
      "LOG: Epoch [1038/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1038/2000], Avg Train Loss: 0.2756, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1039/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [1039/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1039/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1040/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [1040/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1040/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1041/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [1041/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1041/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1042/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [1042/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1042/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1043/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2827\n",
      "LOG: Epoch [1043/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1043/2000], Avg Train Loss: 0.2827, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1044/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [1044/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1044/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1045/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2837\n",
      "LOG: Epoch [1045/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1045/2000], Avg Train Loss: 0.2837, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1046/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [1046/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1046/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1047/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [1047/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1047/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1048/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [1048/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1048/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1049/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1049/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1049/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1050/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1050/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1050/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1051/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [1051/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1051/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1052/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [1052/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1052/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1053/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2773\n",
      "LOG: Epoch [1053/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1053/2000], Avg Train Loss: 0.2773, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1054/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2799\n",
      "LOG: Epoch [1054/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1054/2000], Avg Train Loss: 0.2799, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1055/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [1055/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1055/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1056/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2847\n",
      "LOG: Epoch [1056/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1056/2000], Avg Train Loss: 0.2847, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1057/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [1057/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1057/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1058/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2729\n",
      "LOG: Epoch [1058/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1058/2000], Avg Train Loss: 0.2729, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1059/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [1059/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1059/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1060/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2771\n",
      "LOG: Epoch [1060/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1060/2000], Avg Train Loss: 0.2771, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1061/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2775\n",
      "LOG: Epoch [1061/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1061/2000], Avg Train Loss: 0.2775, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1062/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2883\n",
      "LOG: Epoch [1062/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1062/2000], Avg Train Loss: 0.2883, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1063/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [1063/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1063/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1064/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [1064/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1064/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1065/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1065/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1065/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1066/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2849\n",
      "LOG: Epoch [1066/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1066/2000], Avg Train Loss: 0.2849, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1067/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2834\n",
      "LOG: Epoch [1067/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1067/2000], Avg Train Loss: 0.2834, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1068/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [1068/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1068/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1069/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2730\n",
      "LOG: Epoch [1069/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1069/2000], Avg Train Loss: 0.2730, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1070/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2768\n",
      "LOG: Epoch [1070/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1070/2000], Avg Train Loss: 0.2768, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1071/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [1071/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1071/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1072/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2756\n",
      "LOG: Epoch [1072/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1072/2000], Avg Train Loss: 0.2756, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1073/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [1073/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1073/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1074/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2739\n",
      "LOG: Epoch [1074/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1074/2000], Avg Train Loss: 0.2739, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1075/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [1075/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1075/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1076/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2847\n",
      "LOG: Epoch [1076/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1076/2000], Avg Train Loss: 0.2847, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1077/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [1077/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1077/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1078/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2813\n",
      "LOG: Epoch [1078/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1078/2000], Avg Train Loss: 0.2813, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1079/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [1079/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1079/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1080/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2815\n",
      "LOG: Epoch [1080/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1080/2000], Avg Train Loss: 0.2815, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1081/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2751\n",
      "LOG: Epoch [1081/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1081/2000], Avg Train Loss: 0.2751, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1082/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2825\n",
      "LOG: Epoch [1082/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1082/2000], Avg Train Loss: 0.2825, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1083/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [1083/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1083/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1084/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2757\n",
      "LOG: Epoch [1084/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1084/2000], Avg Train Loss: 0.2757, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1085/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2833\n",
      "LOG: Epoch [1085/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1085/2000], Avg Train Loss: 0.2833, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1086/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [1086/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1086/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1087/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1087/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1087/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1088/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2853\n",
      "LOG: Epoch [1088/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1088/2000], Avg Train Loss: 0.2853, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1089/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [1089/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1089/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1090/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2763\n",
      "LOG: Epoch [1090/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1090/2000], Avg Train Loss: 0.2763, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1091/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [1091/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1091/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1092/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1092/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1092/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1093/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [1093/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1093/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1094/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2830\n",
      "LOG: Epoch [1094/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1094/2000], Avg Train Loss: 0.2830, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1095/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2753\n",
      "LOG: Epoch [1095/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1095/2000], Avg Train Loss: 0.2753, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1096/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1096/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1096/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1097/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2767\n",
      "LOG: Epoch [1097/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1097/2000], Avg Train Loss: 0.2767, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1098/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [1098/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1098/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1099/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2766\n",
      "LOG: Epoch [1099/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1099/2000], Avg Train Loss: 0.2766, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1100/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [1100/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1100/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1101/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [1101/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1101/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1102/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1102/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1102/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1103/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2808\n",
      "LOG: Epoch [1103/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1103/2000], Avg Train Loss: 0.2808, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1104/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [1104/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1104/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1105/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [1105/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1105/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1106/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1106/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1106/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1107/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2817\n",
      "LOG: Epoch [1107/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1107/2000], Avg Train Loss: 0.2817, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1108/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2858\n",
      "LOG: Epoch [1108/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1108/2000], Avg Train Loss: 0.2858, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1109/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2833\n",
      "LOG: Epoch [1109/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1109/2000], Avg Train Loss: 0.2833, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1110/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [1110/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1110/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1111/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [1111/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1111/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1112/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [1112/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1112/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1113/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [1113/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1113/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1114/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2784\n",
      "LOG: Epoch [1114/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1114/2000], Avg Train Loss: 0.2784, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1115/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2784\n",
      "LOG: Epoch [1115/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1115/2000], Avg Train Loss: 0.2784, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1116/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [1116/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1116/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1117/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1117/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1117/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1118/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2881\n",
      "LOG: Epoch [1118/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1118/2000], Avg Train Loss: 0.2881, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1119/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [1119/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1119/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [1120/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1120/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1121/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2741\n",
      "LOG: Epoch [1121/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1121/2000], Avg Train Loss: 0.2741, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1122/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [1122/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1122/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [1123/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1123/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1123/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [1124/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [1124/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1124/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [1125/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [1125/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1125/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [1126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [1126/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1126/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [1127/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [1127/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1127/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [1128/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2869\n",
      "LOG: Epoch [1128/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1128/2000], Avg Train Loss: 0.2869, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [1129/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2849\n",
      "LOG: Epoch [1129/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1129/2000], Avg Train Loss: 0.2849, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [1130/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [1130/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1130/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "LOG: Epoch [1131/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2833\n",
      "LOG: Epoch [1131/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1131/2000], Avg Train Loss: 0.2833, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "LOG: Epoch [1132/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2759\n",
      "LOG: Epoch [1132/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1132/2000], Avg Train Loss: 0.2759, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "LOG: Epoch [1133/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [1133/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1133/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "LOG: Epoch [1134/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2848\n",
      "LOG: Epoch [1134/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1134/2000], Avg Train Loss: 0.2848, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "LOG: Epoch [1135/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1135/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1135/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "LOG: Epoch [1136/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [1136/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1136/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "LOG: Epoch [1137/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [1137/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1137/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "LOG: Epoch [1138/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2834\n",
      "LOG: Epoch [1138/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1138/2000], Avg Train Loss: 0.2834, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "LOG: Epoch [1139/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [1139/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1139/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "LOG: Epoch [1140/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [1140/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1140/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "LOG: Epoch [1141/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [1141/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1141/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "LOG: Epoch [1142/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [1142/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1142/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "LOG: Epoch [1143/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2853\n",
      "LOG: Epoch [1143/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1143/2000], Avg Train Loss: 0.2853, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "LOG: Epoch [1144/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [1144/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1144/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "LOG: Epoch [1145/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2875\n",
      "LOG: Epoch [1145/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1145/2000], Avg Train Loss: 0.2875, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "LOG: Epoch [1146/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2808\n",
      "LOG: Epoch [1146/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1146/2000], Avg Train Loss: 0.2808, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1147/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2878\n",
      "LOG: Epoch [1147/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1147/2000], Avg Train Loss: 0.2878, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1148/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [1148/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1148/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1149/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2764\n",
      "LOG: Epoch [1149/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1149/2000], Avg Train Loss: 0.2764, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1150/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2824\n",
      "LOG: Epoch [1150/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1150/2000], Avg Train Loss: 0.2824, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1151/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2836\n",
      "LOG: Epoch [1151/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1151/2000], Avg Train Loss: 0.2836, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1152/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2837\n",
      "LOG: Epoch [1152/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1152/2000], Avg Train Loss: 0.2837, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1153/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [1153/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1153/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1154/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [1154/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1154/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1155/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [1155/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1155/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1156/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [1156/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1156/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1157/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2808\n",
      "LOG: Epoch [1157/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1157/2000], Avg Train Loss: 0.2808, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1158/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2739\n",
      "LOG: Epoch [1158/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1158/2000], Avg Train Loss: 0.2739, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1159/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [1159/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1159/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1160/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [1160/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1160/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1161/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [1161/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1161/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [1162/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1162/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1163/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [1163/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1163/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1164/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [1164/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1164/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1165/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2843\n",
      "LOG: Epoch [1165/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1165/2000], Avg Train Loss: 0.2843, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1166/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [1166/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1166/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1167/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [1167/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1167/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1168/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2867\n",
      "LOG: Epoch [1168/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1168/2000], Avg Train Loss: 0.2867, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1169/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1169/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1169/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1170/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [1170/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1170/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1171/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [1171/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1171/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1172/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [1172/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1172/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1173/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2747\n",
      "LOG: Epoch [1173/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1173/2000], Avg Train Loss: 0.2747, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1174/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [1174/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1174/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1175/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [1175/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1175/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1176/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2773\n",
      "LOG: Epoch [1176/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1176/2000], Avg Train Loss: 0.2773, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1177/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2821\n",
      "LOG: Epoch [1177/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1177/2000], Avg Train Loss: 0.2821, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1178/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2771\n",
      "LOG: Epoch [1178/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1178/2000], Avg Train Loss: 0.2771, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1179/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2775\n",
      "LOG: Epoch [1179/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1179/2000], Avg Train Loss: 0.2775, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1180/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [1180/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1180/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1181/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [1181/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1181/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1182/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [1182/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1182/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1183/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [1183/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1183/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1184/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1184/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1184/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1185/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2741\n",
      "LOG: Epoch [1185/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1185/2000], Avg Train Loss: 0.2741, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1186/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2839\n",
      "LOG: Epoch [1186/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1186/2000], Avg Train Loss: 0.2839, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1187/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [1187/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1187/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1188/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2748\n",
      "LOG: Epoch [1188/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1188/2000], Avg Train Loss: 0.2748, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1189/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1189/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1189/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1190/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [1190/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1190/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1191/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [1191/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1191/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1192/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [1192/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1192/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [1193/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1193/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1194/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2833\n",
      "LOG: Epoch [1194/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1194/2000], Avg Train Loss: 0.2833, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1195/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2767\n",
      "LOG: Epoch [1195/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1195/2000], Avg Train Loss: 0.2767, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1196/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2767\n",
      "LOG: Epoch [1196/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1196/2000], Avg Train Loss: 0.2767, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1197/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2834\n",
      "LOG: Epoch [1197/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1197/2000], Avg Train Loss: 0.2834, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1198/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [1198/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1198/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1199/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [1199/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1199/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1200/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [1200/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1200/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1201/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2746\n",
      "LOG: Epoch [1201/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1201/2000], Avg Train Loss: 0.2746, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1202/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2755\n",
      "LOG: Epoch [1202/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1202/2000], Avg Train Loss: 0.2755, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1203/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2766\n",
      "LOG: Epoch [1203/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1203/2000], Avg Train Loss: 0.2766, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1204/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2844\n",
      "LOG: Epoch [1204/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1204/2000], Avg Train Loss: 0.2844, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1205/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [1205/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1205/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1206/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [1206/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1206/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1207/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [1207/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1207/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1208/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [1208/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1208/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1209/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1209/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1209/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1210/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2799\n",
      "LOG: Epoch [1210/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1210/2000], Avg Train Loss: 0.2799, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1211/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [1211/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1211/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1212/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2757\n",
      "LOG: Epoch [1212/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1212/2000], Avg Train Loss: 0.2757, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1213/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2844\n",
      "LOG: Epoch [1213/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1213/2000], Avg Train Loss: 0.2844, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1214/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [1214/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1214/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1215/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1215/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1215/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1216/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [1216/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1216/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1217/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2764\n",
      "LOG: Epoch [1217/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1217/2000], Avg Train Loss: 0.2764, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1218/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2828\n",
      "LOG: Epoch [1218/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1218/2000], Avg Train Loss: 0.2828, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1219/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2838\n",
      "LOG: Epoch [1219/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1219/2000], Avg Train Loss: 0.2838, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1220/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [1220/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1220/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1221/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [1221/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1221/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1222/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [1222/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1222/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1223/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2762\n",
      "LOG: Epoch [1223/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1223/2000], Avg Train Loss: 0.2762, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1224/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [1224/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1224/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1225/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2808\n",
      "LOG: Epoch [1225/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1225/2000], Avg Train Loss: 0.2808, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1226/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [1226/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1226/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1227/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [1227/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1227/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1228/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [1228/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1228/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1229/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2853\n",
      "LOG: Epoch [1229/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1229/2000], Avg Train Loss: 0.2853, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1230/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [1230/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1230/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1231/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [1231/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1231/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1232/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [1232/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1232/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1233/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2771\n",
      "LOG: Epoch [1233/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1233/2000], Avg Train Loss: 0.2771, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1234/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [1234/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1234/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2813\n",
      "LOG: Epoch [1235/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1235/2000], Avg Train Loss: 0.2813, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1236/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2832\n",
      "LOG: Epoch [1236/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1236/2000], Avg Train Loss: 0.2832, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1237/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2827\n",
      "LOG: Epoch [1237/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1237/2000], Avg Train Loss: 0.2827, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1238/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [1238/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1238/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1239/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2755\n",
      "LOG: Epoch [1239/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1239/2000], Avg Train Loss: 0.2755, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1240/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [1240/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1240/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1241/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2735\n",
      "LOG: Epoch [1241/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1241/2000], Avg Train Loss: 0.2735, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1242/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2812\n",
      "LOG: Epoch [1242/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1242/2000], Avg Train Loss: 0.2812, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1243/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [1243/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1243/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1244/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [1244/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1244/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1245/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2837\n",
      "LOG: Epoch [1245/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1245/2000], Avg Train Loss: 0.2837, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1246/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [1246/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1246/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1247/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2832\n",
      "LOG: Epoch [1247/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1247/2000], Avg Train Loss: 0.2832, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1248/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [1248/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1248/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1249/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2817\n",
      "LOG: Epoch [1249/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1249/2000], Avg Train Loss: 0.2817, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1250/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [1250/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1250/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1251/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [1251/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1251/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1252/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2770\n",
      "LOG: Epoch [1252/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1252/2000], Avg Train Loss: 0.2770, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1253/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [1253/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1253/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1254/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2836\n",
      "LOG: Epoch [1254/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1254/2000], Avg Train Loss: 0.2836, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1255/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2836\n",
      "LOG: Epoch [1255/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1255/2000], Avg Train Loss: 0.2836, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1256/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2861\n",
      "LOG: Epoch [1256/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1256/2000], Avg Train Loss: 0.2861, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1257/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [1257/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1257/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1258/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [1258/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1258/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1259/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [1259/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1259/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1260/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2759\n",
      "LOG: Epoch [1260/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1260/2000], Avg Train Loss: 0.2759, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1261/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [1261/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1261/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1262/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1262/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1262/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1263/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2743\n",
      "LOG: Epoch [1263/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1263/2000], Avg Train Loss: 0.2743, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1264/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1264/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1264/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1265/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [1265/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1265/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1266/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [1266/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1266/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2843\n",
      "LOG: Epoch [1267/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1267/2000], Avg Train Loss: 0.2843, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1268/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2830\n",
      "LOG: Epoch [1268/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1268/2000], Avg Train Loss: 0.2830, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1269/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [1269/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1269/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1270/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2754\n",
      "LOG: Epoch [1270/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1270/2000], Avg Train Loss: 0.2754, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1271/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [1271/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1271/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1272/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [1272/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1272/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1273/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [1273/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1273/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1274/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [1274/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1274/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1275/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [1275/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1275/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1276/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [1276/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1276/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1277/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [1277/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1277/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1278/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2839\n",
      "LOG: Epoch [1278/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1278/2000], Avg Train Loss: 0.2839, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1279/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2754\n",
      "LOG: Epoch [1279/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1279/2000], Avg Train Loss: 0.2754, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1280/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2840\n",
      "LOG: Epoch [1280/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1280/2000], Avg Train Loss: 0.2840, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1281/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1281/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1281/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1282/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2784\n",
      "LOG: Epoch [1282/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1282/2000], Avg Train Loss: 0.2784, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1283/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2856\n",
      "LOG: Epoch [1283/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1283/2000], Avg Train Loss: 0.2856, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1284/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [1284/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1284/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1285/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2846\n",
      "LOG: Epoch [1285/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1285/2000], Avg Train Loss: 0.2846, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1286/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [1286/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1286/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1287/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1287/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1287/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1288/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2852\n",
      "LOG: Epoch [1288/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1288/2000], Avg Train Loss: 0.2852, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1289/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2838\n",
      "LOG: Epoch [1289/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1289/2000], Avg Train Loss: 0.2838, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1290/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2862\n",
      "LOG: Epoch [1290/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1290/2000], Avg Train Loss: 0.2862, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1291/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [1291/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1291/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1292/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2853\n",
      "LOG: Epoch [1292/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1292/2000], Avg Train Loss: 0.2853, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1293/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1293/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1293/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1294/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [1294/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1294/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1295/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2838\n",
      "LOG: Epoch [1295/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1295/2000], Avg Train Loss: 0.2838, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1296/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1296/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1296/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1297/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [1297/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1297/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1298/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [1298/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1298/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1299/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1299/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1299/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1300/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1300/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1300/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1301/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1301/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1301/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1302/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1302/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1302/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1303/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2799\n",
      "LOG: Epoch [1303/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1303/2000], Avg Train Loss: 0.2799, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1304/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2856\n",
      "LOG: Epoch [1304/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1304/2000], Avg Train Loss: 0.2856, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1305/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [1305/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1305/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1306/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [1306/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1306/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1307/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1307/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1307/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1308/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1308/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1308/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1309/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [1309/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1309/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1310/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [1310/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1310/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1311/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2729\n",
      "LOG: Epoch [1311/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1311/2000], Avg Train Loss: 0.2729, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1312/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [1312/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1312/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1313/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2886\n",
      "LOG: Epoch [1313/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1313/2000], Avg Train Loss: 0.2886, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1314/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2849\n",
      "LOG: Epoch [1314/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1314/2000], Avg Train Loss: 0.2849, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1315/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2777\n",
      "LOG: Epoch [1315/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1315/2000], Avg Train Loss: 0.2777, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1316/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [1316/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1316/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1317/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [1317/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1317/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1318/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [1318/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1318/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1319/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [1319/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1319/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1320/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2821\n",
      "LOG: Epoch [1320/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1320/2000], Avg Train Loss: 0.2821, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1321/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2852\n",
      "LOG: Epoch [1321/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1321/2000], Avg Train Loss: 0.2852, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1322/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1322/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1322/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1323/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2750\n",
      "LOG: Epoch [1323/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1323/2000], Avg Train Loss: 0.2750, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1324/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2768\n",
      "LOG: Epoch [1324/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1324/2000], Avg Train Loss: 0.2768, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [1325/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [1325/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1325/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [1326/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [1326/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1326/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [1327/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [1327/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1327/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [1328/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2766\n",
      "LOG: Epoch [1328/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1328/2000], Avg Train Loss: 0.2766, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [1329/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2748\n",
      "LOG: Epoch [1329/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1329/2000], Avg Train Loss: 0.2748, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [1330/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2754\n",
      "LOG: Epoch [1330/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1330/2000], Avg Train Loss: 0.2754, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [1331/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [1331/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1331/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [1332/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2754\n",
      "LOG: Epoch [1332/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1332/2000], Avg Train Loss: 0.2754, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "LOG: Epoch [1333/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1333/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1333/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "LOG: Epoch [1334/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [1334/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1334/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "LOG: Epoch [1335/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [1335/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1335/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "LOG: Epoch [1336/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1336/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1336/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "LOG: Epoch [1337/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [1337/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1337/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "LOG: Epoch [1338/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2851\n",
      "LOG: Epoch [1338/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1338/2000], Avg Train Loss: 0.2851, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "LOG: Epoch [1339/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [1339/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1339/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "LOG: Epoch [1340/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [1340/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1340/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "LOG: Epoch [1341/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [1341/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1341/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "LOG: Epoch [1342/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2857\n",
      "LOG: Epoch [1342/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1342/2000], Avg Train Loss: 0.2857, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "LOG: Epoch [1343/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [1343/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1343/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "LOG: Epoch [1344/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [1344/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1344/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "LOG: Epoch [1345/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1345/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1345/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "LOG: Epoch [1346/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2736\n",
      "LOG: Epoch [1346/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1346/2000], Avg Train Loss: 0.2736, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "LOG: Epoch [1347/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [1347/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1347/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "LOG: Epoch [1348/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [1348/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1348/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "LOG: Epoch [1349/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [1349/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1349/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "LOG: Epoch [1350/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2743\n",
      "LOG: Epoch [1350/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1350/2000], Avg Train Loss: 0.2743, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "LOG: Epoch [1351/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [1351/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1351/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "LOG: Epoch [1352/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [1352/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1352/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "LOG: Epoch [1353/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [1353/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1353/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "LOG: Epoch [1354/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1354/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1354/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "LOG: Epoch [1355/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2827\n",
      "LOG: Epoch [1355/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1355/2000], Avg Train Loss: 0.2827, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "LOG: Epoch [1356/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2842\n",
      "LOG: Epoch [1356/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1356/2000], Avg Train Loss: 0.2842, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "LOG: Epoch [1357/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2771\n",
      "LOG: Epoch [1357/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1357/2000], Avg Train Loss: 0.2771, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "LOG: Epoch [1358/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2773\n",
      "LOG: Epoch [1358/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1358/2000], Avg Train Loss: 0.2773, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "LOG: Epoch [1359/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [1359/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1359/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "LOG: Epoch [1360/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [1360/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1360/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "LOG: Epoch [1361/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [1361/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1361/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "LOG: Epoch [1362/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [1362/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1362/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "LOG: Epoch [1363/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2771\n",
      "LOG: Epoch [1363/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1363/2000], Avg Train Loss: 0.2771, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "LOG: Epoch [1364/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [1364/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1364/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "LOG: Epoch [1365/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2799\n",
      "LOG: Epoch [1365/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1365/2000], Avg Train Loss: 0.2799, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "LOG: Epoch [1366/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [1366/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1366/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "LOG: Epoch [1367/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2865\n",
      "LOG: Epoch [1367/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1367/2000], Avg Train Loss: 0.2865, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "LOG: Epoch [1368/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2766\n",
      "LOG: Epoch [1368/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1368/2000], Avg Train Loss: 0.2766, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "LOG: Epoch [1369/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [1369/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1369/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "LOG: Epoch [1370/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2799\n",
      "LOG: Epoch [1370/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1370/2000], Avg Train Loss: 0.2799, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "LOG: Epoch [1371/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2770\n",
      "LOG: Epoch [1371/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1371/2000], Avg Train Loss: 0.2770, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "LOG: Epoch [1372/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2799\n",
      "LOG: Epoch [1372/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1372/2000], Avg Train Loss: 0.2799, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "LOG: Epoch [1373/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [1373/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1373/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "LOG: Epoch [1374/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2734\n",
      "LOG: Epoch [1374/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1374/2000], Avg Train Loss: 0.2734, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "LOG: Epoch [1375/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [1375/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1375/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "LOG: Epoch [1376/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [1376/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1376/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "LOG: Epoch [1377/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1377/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1377/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "LOG: Epoch [1378/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [1378/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1378/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "LOG: Epoch [1379/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2739\n",
      "LOG: Epoch [1379/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1379/2000], Avg Train Loss: 0.2739, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1380/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2887\n",
      "LOG: Epoch [1380/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1380/2000], Avg Train Loss: 0.2887, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1381/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2838\n",
      "LOG: Epoch [1381/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1381/2000], Avg Train Loss: 0.2838, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1382/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [1382/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1382/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1383/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1383/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1383/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1384/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2759\n",
      "LOG: Epoch [1384/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1384/2000], Avg Train Loss: 0.2759, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1385/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2784\n",
      "LOG: Epoch [1385/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1385/2000], Avg Train Loss: 0.2784, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1386/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2838\n",
      "LOG: Epoch [1386/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1386/2000], Avg Train Loss: 0.2838, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1387/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2844\n",
      "LOG: Epoch [1387/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1387/2000], Avg Train Loss: 0.2844, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1388/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2720\n",
      "LOG: Epoch [1388/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1388/2000], Avg Train Loss: 0.2720, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1389/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2840\n",
      "LOG: Epoch [1389/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1389/2000], Avg Train Loss: 0.2840, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1390/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [1390/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1390/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1391/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1391/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1391/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1392/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2821\n",
      "LOG: Epoch [1392/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1392/2000], Avg Train Loss: 0.2821, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1393/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [1393/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1393/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1394/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [1394/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1394/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1395/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [1395/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1395/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1396/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [1396/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1396/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1397/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2829\n",
      "LOG: Epoch [1397/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1397/2000], Avg Train Loss: 0.2829, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1398/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2760\n",
      "LOG: Epoch [1398/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1398/2000], Avg Train Loss: 0.2760, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1399/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2834\n",
      "LOG: Epoch [1399/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1399/2000], Avg Train Loss: 0.2834, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1400/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [1400/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1400/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1401/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [1401/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1401/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1402/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [1402/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1402/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1403/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2711\n",
      "LOG: Epoch [1403/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1403/2000], Avg Train Loss: 0.2711, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1404/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2832\n",
      "LOG: Epoch [1404/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1404/2000], Avg Train Loss: 0.2832, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1405/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [1405/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1405/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1406/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [1406/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1406/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1407/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [1407/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1407/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1408/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [1408/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1408/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1409/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2743\n",
      "LOG: Epoch [1409/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1409/2000], Avg Train Loss: 0.2743, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1410/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1410/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1410/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1411/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [1411/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1411/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1412/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [1412/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1412/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1413/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1413/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1413/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1414/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [1414/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1414/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1415/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2879\n",
      "LOG: Epoch [1415/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1415/2000], Avg Train Loss: 0.2879, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1416/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2745\n",
      "LOG: Epoch [1416/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1416/2000], Avg Train Loss: 0.2745, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1417/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2817\n",
      "LOG: Epoch [1417/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1417/2000], Avg Train Loss: 0.2817, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1418/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2768\n",
      "LOG: Epoch [1418/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1418/2000], Avg Train Loss: 0.2768, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1419/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1419/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1419/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1420/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2728\n",
      "LOG: Epoch [1420/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1420/2000], Avg Train Loss: 0.2728, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1421/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1421/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1421/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1422/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [1422/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1422/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1423/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2773\n",
      "LOG: Epoch [1423/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1423/2000], Avg Train Loss: 0.2773, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1424/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1424/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1424/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1425/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [1425/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1425/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1426/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2812\n",
      "LOG: Epoch [1426/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1426/2000], Avg Train Loss: 0.2812, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1427/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1427/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1427/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1428/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2740\n",
      "LOG: Epoch [1428/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1428/2000], Avg Train Loss: 0.2740, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1429/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1429/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1429/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1430/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2763\n",
      "LOG: Epoch [1430/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1430/2000], Avg Train Loss: 0.2763, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1431/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [1431/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1431/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1432/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [1432/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1432/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1433/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2839\n",
      "LOG: Epoch [1433/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1433/2000], Avg Train Loss: 0.2839, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1434/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2868\n",
      "LOG: Epoch [1434/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1434/2000], Avg Train Loss: 0.2868, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1435/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2813\n",
      "LOG: Epoch [1435/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1435/2000], Avg Train Loss: 0.2813, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [1436/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1436/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1437/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2762\n",
      "LOG: Epoch [1437/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1437/2000], Avg Train Loss: 0.2762, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1438/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2755\n",
      "LOG: Epoch [1438/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1438/2000], Avg Train Loss: 0.2755, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1439/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [1439/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1439/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1440/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2767\n",
      "LOG: Epoch [1440/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1440/2000], Avg Train Loss: 0.2767, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1441/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2752\n",
      "LOG: Epoch [1441/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1441/2000], Avg Train Loss: 0.2752, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1442/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [1442/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1442/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1443/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2739\n",
      "LOG: Epoch [1443/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1443/2000], Avg Train Loss: 0.2739, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1444/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [1444/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1444/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1445/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [1445/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1445/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1446/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2867\n",
      "LOG: Epoch [1446/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1446/2000], Avg Train Loss: 0.2867, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1447/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [1447/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1447/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1448/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [1448/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1448/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1449/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [1449/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1449/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1450/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2759\n",
      "LOG: Epoch [1450/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1450/2000], Avg Train Loss: 0.2759, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2756\n",
      "LOG: Epoch [1451/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1451/2000], Avg Train Loss: 0.2756, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1452/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2832\n",
      "LOG: Epoch [1452/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1452/2000], Avg Train Loss: 0.2832, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1453/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [1453/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1453/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1454/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2773\n",
      "LOG: Epoch [1454/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1454/2000], Avg Train Loss: 0.2773, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1455/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [1455/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1455/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1456/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [1456/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1456/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1457/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2833\n",
      "LOG: Epoch [1457/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1457/2000], Avg Train Loss: 0.2833, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1458/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2842\n",
      "LOG: Epoch [1458/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1458/2000], Avg Train Loss: 0.2842, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1459/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [1459/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1459/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1460/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [1460/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1460/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1461/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [1461/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1461/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1462/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [1462/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1462/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1463/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [1463/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1463/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1464/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [1464/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1464/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1465/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [1465/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1465/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1466/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [1466/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1466/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1467/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2756\n",
      "LOG: Epoch [1467/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1467/2000], Avg Train Loss: 0.2756, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1468/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [1468/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1468/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1469/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2808\n",
      "LOG: Epoch [1469/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1469/2000], Avg Train Loss: 0.2808, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1470/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2834\n",
      "LOG: Epoch [1470/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1470/2000], Avg Train Loss: 0.2834, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1471/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [1471/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1471/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1472/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2751\n",
      "LOG: Epoch [1472/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1472/2000], Avg Train Loss: 0.2751, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1473/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [1473/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1473/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1474/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2750\n",
      "LOG: Epoch [1474/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1474/2000], Avg Train Loss: 0.2750, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1475/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2765\n",
      "LOG: Epoch [1475/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1475/2000], Avg Train Loss: 0.2765, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1476/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [1476/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1476/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1477/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [1477/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1477/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1478/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1478/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1478/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1479/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2837\n",
      "LOG: Epoch [1479/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1479/2000], Avg Train Loss: 0.2837, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1480/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [1480/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1480/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1481/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2813\n",
      "LOG: Epoch [1481/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1481/2000], Avg Train Loss: 0.2813, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1482/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2799\n",
      "LOG: Epoch [1482/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1482/2000], Avg Train Loss: 0.2799, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1483/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2757\n",
      "LOG: Epoch [1483/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1483/2000], Avg Train Loss: 0.2757, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1484/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [1484/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1484/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1485/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [1485/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1485/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1486/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [1486/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1486/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1487/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2831\n",
      "LOG: Epoch [1487/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1487/2000], Avg Train Loss: 0.2831, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1488/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2821\n",
      "LOG: Epoch [1488/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1488/2000], Avg Train Loss: 0.2821, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1489/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1489/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1489/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1490/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [1490/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1490/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1491/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2764\n",
      "LOG: Epoch [1491/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1491/2000], Avg Train Loss: 0.2764, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1492/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2831\n",
      "LOG: Epoch [1492/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1492/2000], Avg Train Loss: 0.2831, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1493/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [1493/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1493/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1494/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2742\n",
      "LOG: Epoch [1494/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1494/2000], Avg Train Loss: 0.2742, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1495/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [1495/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1495/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1496/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [1496/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1496/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1497/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [1497/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1497/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1498/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [1498/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1498/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1499/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2755\n",
      "LOG: Epoch [1499/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1499/2000], Avg Train Loss: 0.2755, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1500/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2846\n",
      "LOG: Epoch [1500/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1500/2000], Avg Train Loss: 0.2846, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1501/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [1501/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1501/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1502/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2831\n",
      "LOG: Epoch [1502/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1502/2000], Avg Train Loss: 0.2831, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1503/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2833\n",
      "LOG: Epoch [1503/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1503/2000], Avg Train Loss: 0.2833, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1504/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [1504/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1504/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1505/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1505/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1505/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1506/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [1506/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1506/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1507/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [1507/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1507/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1508/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [1508/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1508/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1509/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2858\n",
      "LOG: Epoch [1509/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1509/2000], Avg Train Loss: 0.2858, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1510/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2815\n",
      "LOG: Epoch [1510/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1510/2000], Avg Train Loss: 0.2815, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1511/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2812\n",
      "LOG: Epoch [1511/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1511/2000], Avg Train Loss: 0.2812, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1512/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [1512/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1512/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1513/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [1513/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1513/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1514/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [1514/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1514/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1515/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2839\n",
      "LOG: Epoch [1515/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1515/2000], Avg Train Loss: 0.2839, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1516/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [1516/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1516/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1517/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2771\n",
      "LOG: Epoch [1517/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1517/2000], Avg Train Loss: 0.2771, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1518/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1518/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1518/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1519/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2824\n",
      "LOG: Epoch [1519/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1519/2000], Avg Train Loss: 0.2824, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1520/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [1520/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1520/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1521/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [1521/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1521/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1522/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1522/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1522/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1523/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [1523/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1523/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1524/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2784\n",
      "LOG: Epoch [1524/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1524/2000], Avg Train Loss: 0.2784, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1525/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2836\n",
      "LOG: Epoch [1525/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1525/2000], Avg Train Loss: 0.2836, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1526/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [1526/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1526/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1527/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [1527/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1527/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1528/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2770\n",
      "LOG: Epoch [1528/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1528/2000], Avg Train Loss: 0.2770, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1529/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2812\n",
      "LOG: Epoch [1529/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1529/2000], Avg Train Loss: 0.2812, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1530/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [1530/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1530/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1531/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2812\n",
      "LOG: Epoch [1531/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1531/2000], Avg Train Loss: 0.2812, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1532/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2758\n",
      "LOG: Epoch [1532/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1532/2000], Avg Train Loss: 0.2758, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1533/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2837\n",
      "LOG: Epoch [1533/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1533/2000], Avg Train Loss: 0.2837, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1534/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2743\n",
      "LOG: Epoch [1534/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1534/2000], Avg Train Loss: 0.2743, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1535/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2817\n",
      "LOG: Epoch [1535/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1535/2000], Avg Train Loss: 0.2817, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1536/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [1536/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1536/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1537/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2764\n",
      "LOG: Epoch [1537/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1537/2000], Avg Train Loss: 0.2764, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1538/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [1538/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1538/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1539/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2756\n",
      "LOG: Epoch [1539/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1539/2000], Avg Train Loss: 0.2756, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1540/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2813\n",
      "LOG: Epoch [1540/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1540/2000], Avg Train Loss: 0.2813, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1541/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2768\n",
      "LOG: Epoch [1541/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1541/2000], Avg Train Loss: 0.2768, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1542/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [1542/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1542/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1543/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [1543/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1543/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1544/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [1544/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1544/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1545/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1545/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1545/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1546/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [1546/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1546/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1547/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2762\n",
      "LOG: Epoch [1547/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1547/2000], Avg Train Loss: 0.2762, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1548/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [1548/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1548/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1549/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2829\n",
      "LOG: Epoch [1549/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1549/2000], Avg Train Loss: 0.2829, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1550/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [1550/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1550/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1551/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [1551/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1551/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1552/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [1552/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1552/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1553/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [1553/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1553/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1554/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [1554/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1554/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1555/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2770\n",
      "LOG: Epoch [1555/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1555/2000], Avg Train Loss: 0.2770, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1556/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [1556/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1556/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1557/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2777\n",
      "LOG: Epoch [1557/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1557/2000], Avg Train Loss: 0.2777, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1558/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2784\n",
      "LOG: Epoch [1558/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1558/2000], Avg Train Loss: 0.2784, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1559/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2771\n",
      "LOG: Epoch [1559/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1559/2000], Avg Train Loss: 0.2771, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1560/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [1560/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1560/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1561/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1561/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1561/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1562/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [1562/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1562/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1563/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1563/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1563/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1564/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2837\n",
      "LOG: Epoch [1564/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1564/2000], Avg Train Loss: 0.2837, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1565/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [1565/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1565/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1566/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [1566/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1566/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1567/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [1567/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1567/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1568/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2777\n",
      "LOG: Epoch [1568/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1568/2000], Avg Train Loss: 0.2777, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1569/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1569/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1569/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1570/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [1570/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1570/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1571/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [1571/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1571/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1572/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2758\n",
      "LOG: Epoch [1572/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1572/2000], Avg Train Loss: 0.2758, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1573/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2845\n",
      "LOG: Epoch [1573/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1573/2000], Avg Train Loss: 0.2845, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1574/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2770\n",
      "LOG: Epoch [1574/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1574/2000], Avg Train Loss: 0.2770, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1575/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [1575/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1575/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1576/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2837\n",
      "LOG: Epoch [1576/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1576/2000], Avg Train Loss: 0.2837, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1577/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [1577/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1577/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2744\n",
      "LOG: Epoch [1578/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1578/2000], Avg Train Loss: 0.2744, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1579/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [1579/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1579/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1580/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [1580/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1580/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1581/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2863\n",
      "LOG: Epoch [1581/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1581/2000], Avg Train Loss: 0.2863, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1582/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [1582/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1582/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1583/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2808\n",
      "LOG: Epoch [1583/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1583/2000], Avg Train Loss: 0.2808, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1584/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2848\n",
      "LOG: Epoch [1584/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1584/2000], Avg Train Loss: 0.2848, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1585/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2840\n",
      "LOG: Epoch [1585/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1585/2000], Avg Train Loss: 0.2840, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1586/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1586/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1586/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1587/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [1587/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1587/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1588/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [1588/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1588/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1589/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [1589/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1589/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1590/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [1590/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1590/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1591/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [1591/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1591/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1592/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2770\n",
      "LOG: Epoch [1592/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1592/2000], Avg Train Loss: 0.2770, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1593/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2852\n",
      "LOG: Epoch [1593/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1593/2000], Avg Train Loss: 0.2852, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1594/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2830\n",
      "LOG: Epoch [1594/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1594/2000], Avg Train Loss: 0.2830, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1595/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [1595/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1595/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1596/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [1596/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1596/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1597/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [1597/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1597/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1598/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [1598/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1598/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1599/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [1599/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1599/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1600/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1600/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1600/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1601/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [1601/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1601/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1602/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [1602/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1602/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1603/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1603/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1603/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1604/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [1604/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1604/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1605/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1605/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1605/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1606/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2764\n",
      "LOG: Epoch [1606/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1606/2000], Avg Train Loss: 0.2764, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1607/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [1607/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1607/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1608/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2821\n",
      "LOG: Epoch [1608/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1608/2000], Avg Train Loss: 0.2821, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1609/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [1609/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1609/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1610/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1610/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1610/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1611/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2827\n",
      "LOG: Epoch [1611/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1611/2000], Avg Train Loss: 0.2827, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1612/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2842\n",
      "LOG: Epoch [1612/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1612/2000], Avg Train Loss: 0.2842, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1613/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [1613/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1613/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [1614/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1614/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1615/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [1615/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1615/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2777\n",
      "LOG: Epoch [1616/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1616/2000], Avg Train Loss: 0.2777, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1617/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [1617/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1617/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1618/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [1618/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1618/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1619/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1619/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1619/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1620/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2769\n",
      "LOG: Epoch [1620/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1620/2000], Avg Train Loss: 0.2769, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1621/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2852\n",
      "LOG: Epoch [1621/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1621/2000], Avg Train Loss: 0.2852, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1622/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2765\n",
      "LOG: Epoch [1622/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1622/2000], Avg Train Loss: 0.2765, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1623/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2727\n",
      "LOG: Epoch [1623/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1623/2000], Avg Train Loss: 0.2727, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1624/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [1624/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1624/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1625/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [1625/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1625/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1626/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1626/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1626/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1627/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [1627/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1627/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1628/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [1628/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1628/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1629/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [1629/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1629/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1630/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2831\n",
      "LOG: Epoch [1630/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1630/2000], Avg Train Loss: 0.2831, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1631/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [1631/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1631/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1632/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2758\n",
      "LOG: Epoch [1632/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1632/2000], Avg Train Loss: 0.2758, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1633/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [1633/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1633/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1634/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [1634/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1634/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1635/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [1635/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1635/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1636/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [1636/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1636/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1637/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2826\n",
      "LOG: Epoch [1637/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1637/2000], Avg Train Loss: 0.2826, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1638/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2775\n",
      "LOG: Epoch [1638/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1638/2000], Avg Train Loss: 0.2775, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1639/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2777\n",
      "LOG: Epoch [1639/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1639/2000], Avg Train Loss: 0.2777, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1640/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2837\n",
      "LOG: Epoch [1640/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1640/2000], Avg Train Loss: 0.2837, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1641/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [1641/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1641/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1642/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [1642/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1642/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1643/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2817\n",
      "LOG: Epoch [1643/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1643/2000], Avg Train Loss: 0.2817, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1644/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [1644/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1644/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1645/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [1645/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1645/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1646/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2784\n",
      "LOG: Epoch [1646/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1646/2000], Avg Train Loss: 0.2784, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1647/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2805\n",
      "LOG: Epoch [1647/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1647/2000], Avg Train Loss: 0.2805, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1648/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2828\n",
      "LOG: Epoch [1648/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1648/2000], Avg Train Loss: 0.2828, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1649/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2830\n",
      "LOG: Epoch [1649/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1649/2000], Avg Train Loss: 0.2830, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1650/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [1650/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1650/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1651/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2821\n",
      "LOG: Epoch [1651/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1651/2000], Avg Train Loss: 0.2821, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1652/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [1652/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1652/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1653/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [1653/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1653/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1654/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [1654/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1654/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1655/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2784\n",
      "LOG: Epoch [1655/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1655/2000], Avg Train Loss: 0.2784, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1656/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2850\n",
      "LOG: Epoch [1656/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1656/2000], Avg Train Loss: 0.2850, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1657/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [1657/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1657/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1658/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1658/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1658/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1659/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1659/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1659/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1660/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2771\n",
      "LOG: Epoch [1660/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1660/2000], Avg Train Loss: 0.2771, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1661/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2848\n",
      "LOG: Epoch [1661/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1661/2000], Avg Train Loss: 0.2848, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1662/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [1662/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1662/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1663/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [1663/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1663/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1664/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2829\n",
      "LOG: Epoch [1664/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1664/2000], Avg Train Loss: 0.2829, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1665/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [1665/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1665/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1666/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [1666/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1666/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1667/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [1667/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1667/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1668/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2745\n",
      "LOG: Epoch [1668/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1668/2000], Avg Train Loss: 0.2745, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1669/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2713\n",
      "LOG: Epoch [1669/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1669/2000], Avg Train Loss: 0.2713, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1670/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [1670/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1670/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1671/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [1671/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1671/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1672/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [1672/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1672/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1673/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [1673/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1673/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1674/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2832\n",
      "LOG: Epoch [1674/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1674/2000], Avg Train Loss: 0.2832, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1675/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [1675/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1675/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1676/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2824\n",
      "LOG: Epoch [1676/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1676/2000], Avg Train Loss: 0.2824, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1677/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2831\n",
      "LOG: Epoch [1677/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1677/2000], Avg Train Loss: 0.2831, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1678/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [1678/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1678/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1679/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [1679/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1679/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1680/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [1680/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1680/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1681/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [1681/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1681/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1682/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2832\n",
      "LOG: Epoch [1682/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1682/2000], Avg Train Loss: 0.2832, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1683/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2762\n",
      "LOG: Epoch [1683/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1683/2000], Avg Train Loss: 0.2762, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1684/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [1684/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1684/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1685/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2749\n",
      "LOG: Epoch [1685/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1685/2000], Avg Train Loss: 0.2749, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1686/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2825\n",
      "LOG: Epoch [1686/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1686/2000], Avg Train Loss: 0.2825, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1687/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2851\n",
      "LOG: Epoch [1687/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1687/2000], Avg Train Loss: 0.2851, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1688/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2770\n",
      "LOG: Epoch [1688/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1688/2000], Avg Train Loss: 0.2770, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1689/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [1689/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1689/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1690/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1690/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1690/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1691/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [1691/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1691/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1692/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1692/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1692/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1693/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2842\n",
      "LOG: Epoch [1693/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1693/2000], Avg Train Loss: 0.2842, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1694/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2817\n",
      "LOG: Epoch [1694/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1694/2000], Avg Train Loss: 0.2817, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1695/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1695/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1695/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1696/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [1696/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1696/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1697/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2775\n",
      "LOG: Epoch [1697/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1697/2000], Avg Train Loss: 0.2775, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1698/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [1698/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1698/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1699/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1699/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1699/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1700/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [1700/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1700/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1701/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [1701/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1701/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1702/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [1702/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1702/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1703/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [1703/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1703/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1704/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2775\n",
      "LOG: Epoch [1704/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1704/2000], Avg Train Loss: 0.2775, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1705/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [1705/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1705/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1706/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1706/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1706/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1707/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [1707/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1707/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1708/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2773\n",
      "LOG: Epoch [1708/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1708/2000], Avg Train Loss: 0.2773, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1709/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2768\n",
      "LOG: Epoch [1709/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1709/2000], Avg Train Loss: 0.2768, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1710/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [1710/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1710/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1711/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1711/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1711/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1712/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [1712/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1712/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1713/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2824\n",
      "LOG: Epoch [1713/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1713/2000], Avg Train Loss: 0.2824, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1714/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1714/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1714/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1715/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [1715/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1715/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1716/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1716/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1716/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1717/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [1717/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1717/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1718/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2765\n",
      "LOG: Epoch [1718/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1718/2000], Avg Train Loss: 0.2765, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1719/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1719/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1719/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1720/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2760\n",
      "LOG: Epoch [1720/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1720/2000], Avg Train Loss: 0.2760, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1721/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [1721/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1721/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1722/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [1722/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1722/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1723/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [1723/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1723/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1724/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [1724/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1724/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1725/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2813\n",
      "LOG: Epoch [1725/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1725/2000], Avg Train Loss: 0.2813, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1726/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [1726/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1726/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1727/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [1727/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1727/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1728/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [1728/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1728/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1729/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [1729/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1729/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1730/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2848\n",
      "LOG: Epoch [1730/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1730/2000], Avg Train Loss: 0.2848, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1731/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [1731/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1731/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1732/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [1732/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1732/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1733/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2764\n",
      "LOG: Epoch [1733/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1733/2000], Avg Train Loss: 0.2764, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1734/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [1734/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1734/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1735/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [1735/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1735/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1736/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2813\n",
      "LOG: Epoch [1736/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1736/2000], Avg Train Loss: 0.2813, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1737/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2758\n",
      "LOG: Epoch [1737/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1737/2000], Avg Train Loss: 0.2758, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1738/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2765\n",
      "LOG: Epoch [1738/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1738/2000], Avg Train Loss: 0.2765, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1739/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [1739/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1739/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1740/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2764\n",
      "LOG: Epoch [1740/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1740/2000], Avg Train Loss: 0.2764, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1741/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2845\n",
      "LOG: Epoch [1741/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1741/2000], Avg Train Loss: 0.2845, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1742/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2768\n",
      "LOG: Epoch [1742/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1742/2000], Avg Train Loss: 0.2768, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1743/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [1743/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1743/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1744/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [1744/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1744/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1745/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2770\n",
      "LOG: Epoch [1745/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1745/2000], Avg Train Loss: 0.2770, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1746/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [1746/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1746/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1747/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2815\n",
      "LOG: Epoch [1747/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1747/2000], Avg Train Loss: 0.2815, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1748/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [1748/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1748/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1749/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [1749/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1749/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1750/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [1750/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1750/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1751/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [1751/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1751/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1752/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2827\n",
      "LOG: Epoch [1752/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1752/2000], Avg Train Loss: 0.2827, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1753/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2757\n",
      "LOG: Epoch [1753/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1753/2000], Avg Train Loss: 0.2757, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1754/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2858\n",
      "LOG: Epoch [1754/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1754/2000], Avg Train Loss: 0.2858, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1755/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1755/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1755/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1756/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [1756/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1756/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1757/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2812\n",
      "LOG: Epoch [1757/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1757/2000], Avg Train Loss: 0.2812, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1758/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [1758/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1758/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1759/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2749\n",
      "LOG: Epoch [1759/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1759/2000], Avg Train Loss: 0.2749, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1760/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [1760/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1760/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1761/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2826\n",
      "LOG: Epoch [1761/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1761/2000], Avg Train Loss: 0.2826, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1762/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1762/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1762/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1763/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2758\n",
      "LOG: Epoch [1763/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1763/2000], Avg Train Loss: 0.2758, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1764/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1764/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1764/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1765/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2817\n",
      "LOG: Epoch [1765/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1765/2000], Avg Train Loss: 0.2817, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1766/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [1766/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1766/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1767/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [1767/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1767/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1768/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2768\n",
      "LOG: Epoch [1768/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1768/2000], Avg Train Loss: 0.2768, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1769/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2843\n",
      "LOG: Epoch [1769/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1769/2000], Avg Train Loss: 0.2843, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1770/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [1770/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1770/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1771/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [1771/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1771/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1772/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [1772/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1772/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1773/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2823\n",
      "LOG: Epoch [1773/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1773/2000], Avg Train Loss: 0.2823, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1774/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2764\n",
      "LOG: Epoch [1774/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1774/2000], Avg Train Loss: 0.2764, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1775/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2733\n",
      "LOG: Epoch [1775/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1775/2000], Avg Train Loss: 0.2733, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1776/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [1776/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1776/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1777/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [1777/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1777/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1778/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2752\n",
      "LOG: Epoch [1778/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1778/2000], Avg Train Loss: 0.2752, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1779/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2753\n",
      "LOG: Epoch [1779/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1779/2000], Avg Train Loss: 0.2753, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1780/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [1780/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1780/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1781/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [1781/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1781/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1782/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [1782/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1782/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1783/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2828\n",
      "LOG: Epoch [1783/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1783/2000], Avg Train Loss: 0.2828, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1784/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [1784/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1784/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1785/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [1785/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1785/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1786/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [1786/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1786/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1787/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [1787/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1787/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1788/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2775\n",
      "LOG: Epoch [1788/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1788/2000], Avg Train Loss: 0.2775, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1789/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1789/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1789/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1790/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [1790/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1790/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1791/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2750\n",
      "LOG: Epoch [1791/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1791/2000], Avg Train Loss: 0.2750, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1792/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [1792/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1792/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1793/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [1793/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1793/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1794/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [1794/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1794/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1795/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [1795/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1795/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1796/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2831\n",
      "LOG: Epoch [1796/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1796/2000], Avg Train Loss: 0.2831, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1797/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2841\n",
      "LOG: Epoch [1797/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1797/2000], Avg Train Loss: 0.2841, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1798/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2771\n",
      "LOG: Epoch [1798/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1798/2000], Avg Train Loss: 0.2771, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1799/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [1799/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1799/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1800/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [1800/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1800/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1801/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1801/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1801/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1802/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [1802/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1802/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1803/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [1803/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1803/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1804/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1804/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1804/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1805/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2830\n",
      "LOG: Epoch [1805/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1805/2000], Avg Train Loss: 0.2830, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1806/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2764\n",
      "LOG: Epoch [1806/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1806/2000], Avg Train Loss: 0.2764, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1807/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [1807/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1807/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1808/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [1808/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1808/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1809/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2777\n",
      "LOG: Epoch [1809/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1809/2000], Avg Train Loss: 0.2777, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1810/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1810/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1810/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1811/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [1811/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1811/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1812/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [1812/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1812/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1813/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [1813/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1813/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1814/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2772\n",
      "LOG: Epoch [1814/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1814/2000], Avg Train Loss: 0.2772, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1815/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [1815/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1815/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1816/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [1816/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1816/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1817/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2773\n",
      "LOG: Epoch [1817/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1817/2000], Avg Train Loss: 0.2773, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1818/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2774\n",
      "LOG: Epoch [1818/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1818/2000], Avg Train Loss: 0.2774, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1819/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [1819/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1819/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1820/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [1820/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1820/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1821/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [1821/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1821/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1822/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [1822/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1822/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1823/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2816\n",
      "LOG: Epoch [1823/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1823/2000], Avg Train Loss: 0.2816, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1824/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [1824/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1824/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1825/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2854\n",
      "LOG: Epoch [1825/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1825/2000], Avg Train Loss: 0.2854, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1826/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2763\n",
      "LOG: Epoch [1826/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1826/2000], Avg Train Loss: 0.2763, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1827/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1827/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1827/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1828/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2762\n",
      "LOG: Epoch [1828/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1828/2000], Avg Train Loss: 0.2762, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1829/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [1829/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1829/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1830/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [1830/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1830/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1831/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2760\n",
      "LOG: Epoch [1831/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1831/2000], Avg Train Loss: 0.2760, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1832/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [1832/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1832/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1833/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [1833/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1833/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1834/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [1834/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1834/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1835/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [1835/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1835/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1836/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [1836/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1836/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1837/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2755\n",
      "LOG: Epoch [1837/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1837/2000], Avg Train Loss: 0.2755, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1838/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [1838/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1838/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1839/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2808\n",
      "LOG: Epoch [1839/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1839/2000], Avg Train Loss: 0.2808, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1840/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2766\n",
      "LOG: Epoch [1840/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1840/2000], Avg Train Loss: 0.2766, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1841/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [1841/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1841/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1842/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [1842/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1842/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1843/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1843/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1843/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1844/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [1844/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1844/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1845/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2778\n",
      "LOG: Epoch [1845/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1845/2000], Avg Train Loss: 0.2778, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1846/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1846/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1846/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1847/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2803\n",
      "LOG: Epoch [1847/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1847/2000], Avg Train Loss: 0.2803, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1848/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2742\n",
      "LOG: Epoch [1848/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1848/2000], Avg Train Loss: 0.2742, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1849/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2826\n",
      "LOG: Epoch [1849/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1849/2000], Avg Train Loss: 0.2826, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1850/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2757\n",
      "LOG: Epoch [1850/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1850/2000], Avg Train Loss: 0.2757, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1851/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2786\n",
      "LOG: Epoch [1851/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1851/2000], Avg Train Loss: 0.2786, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1852/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2720\n",
      "LOG: Epoch [1852/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1852/2000], Avg Train Loss: 0.2720, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1853/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2781\n",
      "LOG: Epoch [1853/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1853/2000], Avg Train Loss: 0.2781, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1854/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2737\n",
      "LOG: Epoch [1854/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1854/2000], Avg Train Loss: 0.2737, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1855/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [1855/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1855/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1856/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [1856/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1856/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1857/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2841\n",
      "LOG: Epoch [1857/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1857/2000], Avg Train Loss: 0.2841, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1858/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1858/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1858/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1859/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [1859/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1859/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1860/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2815\n",
      "LOG: Epoch [1860/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1860/2000], Avg Train Loss: 0.2815, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1861/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [1861/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1861/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1862/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [1862/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1862/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1863/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [1863/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1863/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1864/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2773\n",
      "LOG: Epoch [1864/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1864/2000], Avg Train Loss: 0.2773, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1865/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [1865/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1865/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1866/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [1866/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1866/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1867/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2747\n",
      "LOG: Epoch [1867/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1867/2000], Avg Train Loss: 0.2747, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1868/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2791\n",
      "LOG: Epoch [1868/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1868/2000], Avg Train Loss: 0.2791, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1869/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2767\n",
      "LOG: Epoch [1869/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1869/2000], Avg Train Loss: 0.2767, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1870/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2799\n",
      "LOG: Epoch [1870/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1870/2000], Avg Train Loss: 0.2799, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1871/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [1871/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1871/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1872/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [1872/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1872/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1873/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2821\n",
      "LOG: Epoch [1873/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1873/2000], Avg Train Loss: 0.2821, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1874/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2770\n",
      "LOG: Epoch [1874/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1874/2000], Avg Train Loss: 0.2770, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1875/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2841\n",
      "LOG: Epoch [1875/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1875/2000], Avg Train Loss: 0.2841, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1876/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2824\n",
      "LOG: Epoch [1876/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1876/2000], Avg Train Loss: 0.2824, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1877/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2852\n",
      "LOG: Epoch [1877/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1877/2000], Avg Train Loss: 0.2852, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1878/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2827\n",
      "LOG: Epoch [1878/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1878/2000], Avg Train Loss: 0.2827, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1879/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2770\n",
      "LOG: Epoch [1879/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1879/2000], Avg Train Loss: 0.2770, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1880/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2818\n",
      "LOG: Epoch [1880/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1880/2000], Avg Train Loss: 0.2818, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1881/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2835\n",
      "LOG: Epoch [1881/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1881/2000], Avg Train Loss: 0.2835, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1882/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2763\n",
      "LOG: Epoch [1882/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1882/2000], Avg Train Loss: 0.2763, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1883/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2764\n",
      "LOG: Epoch [1883/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1883/2000], Avg Train Loss: 0.2764, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1884/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2750\n",
      "LOG: Epoch [1884/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1884/2000], Avg Train Loss: 0.2750, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1885/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [1885/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1885/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1886/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2785\n",
      "LOG: Epoch [1886/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1886/2000], Avg Train Loss: 0.2785, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1887/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2798\n",
      "LOG: Epoch [1887/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1887/2000], Avg Train Loss: 0.2798, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1888/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [1888/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1888/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1889/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2773\n",
      "LOG: Epoch [1889/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1889/2000], Avg Train Loss: 0.2773, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1890/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2836\n",
      "LOG: Epoch [1890/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1890/2000], Avg Train Loss: 0.2836, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1891/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [1891/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1891/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1892/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2765\n",
      "LOG: Epoch [1892/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1892/2000], Avg Train Loss: 0.2765, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1893/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2829\n",
      "LOG: Epoch [1893/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1893/2000], Avg Train Loss: 0.2829, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1894/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [1894/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1894/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1895/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [1895/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1895/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1896/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2770\n",
      "LOG: Epoch [1896/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1896/2000], Avg Train Loss: 0.2770, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1897/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [1897/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1897/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1898/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [1898/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1898/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1899/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2779\n",
      "LOG: Epoch [1899/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1899/2000], Avg Train Loss: 0.2779, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1900/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2817\n",
      "LOG: Epoch [1900/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1900/2000], Avg Train Loss: 0.2817, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1901/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1901/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1901/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1902/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2761\n",
      "LOG: Epoch [1902/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1902/2000], Avg Train Loss: 0.2761, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1903/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2777\n",
      "LOG: Epoch [1903/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1903/2000], Avg Train Loss: 0.2777, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1904/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2758\n",
      "LOG: Epoch [1904/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1904/2000], Avg Train Loss: 0.2758, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1905/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2811\n",
      "LOG: Epoch [1905/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1905/2000], Avg Train Loss: 0.2811, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1906/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2771\n",
      "LOG: Epoch [1906/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1906/2000], Avg Train Loss: 0.2771, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1907/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [1907/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1907/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1908/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1908/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1908/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1909/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [1909/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1909/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1910/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2760\n",
      "LOG: Epoch [1910/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1910/2000], Avg Train Loss: 0.2760, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1911/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [1911/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1911/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1912/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1912/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1912/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1913/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2824\n",
      "LOG: Epoch [1913/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1913/2000], Avg Train Loss: 0.2824, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1914/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1914/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1914/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1915/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2846\n",
      "LOG: Epoch [1915/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1915/2000], Avg Train Loss: 0.2846, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [1916/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2735\n",
      "LOG: Epoch [1916/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1916/2000], Avg Train Loss: 0.2735, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [1917/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [1917/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1917/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [1918/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2760\n",
      "LOG: Epoch [1918/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1918/2000], Avg Train Loss: 0.2760, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [1919/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [1919/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1919/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [1920/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2842\n",
      "LOG: Epoch [1920/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1920/2000], Avg Train Loss: 0.2842, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [1921/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2874\n",
      "LOG: Epoch [1921/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1921/2000], Avg Train Loss: 0.2874, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [1922/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1922/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1922/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [1923/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2789\n",
      "LOG: Epoch [1923/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1923/2000], Avg Train Loss: 0.2789, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "LOG: Epoch [1924/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2814\n",
      "LOG: Epoch [1924/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1924/2000], Avg Train Loss: 0.2814, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "LOG: Epoch [1925/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2833\n",
      "LOG: Epoch [1925/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1925/2000], Avg Train Loss: 0.2833, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "LOG: Epoch [1926/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [1926/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1926/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "LOG: Epoch [1927/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2853\n",
      "LOG: Epoch [1927/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1927/2000], Avg Train Loss: 0.2853, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "LOG: Epoch [1928/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [1928/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1928/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "LOG: Epoch [1929/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2743\n",
      "LOG: Epoch [1929/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1929/2000], Avg Train Loss: 0.2743, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "LOG: Epoch [1930/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [1930/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1930/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "LOG: Epoch [1931/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1931/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1931/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "LOG: Epoch [1932/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2822\n",
      "LOG: Epoch [1932/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1932/2000], Avg Train Loss: 0.2822, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "LOG: Epoch [1933/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2773\n",
      "LOG: Epoch [1933/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1933/2000], Avg Train Loss: 0.2773, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "LOG: Epoch [1934/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2787\n",
      "LOG: Epoch [1934/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1934/2000], Avg Train Loss: 0.2787, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "LOG: Epoch [1935/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2810\n",
      "LOG: Epoch [1935/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1935/2000], Avg Train Loss: 0.2810, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "LOG: Epoch [1936/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2850\n",
      "LOG: Epoch [1936/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1936/2000], Avg Train Loss: 0.2850, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "LOG: Epoch [1937/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [1937/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1937/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "LOG: Epoch [1938/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2760\n",
      "LOG: Epoch [1938/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1938/2000], Avg Train Loss: 0.2760, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "LOG: Epoch [1939/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2825\n",
      "LOG: Epoch [1939/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1939/2000], Avg Train Loss: 0.2825, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "LOG: Epoch [1940/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1940/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1940/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "LOG: Epoch [1941/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2793\n",
      "LOG: Epoch [1941/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1941/2000], Avg Train Loss: 0.2793, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "LOG: Epoch [1942/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2829\n",
      "LOG: Epoch [1942/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1942/2000], Avg Train Loss: 0.2829, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "LOG: Epoch [1943/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [1943/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1943/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "LOG: Epoch [1944/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2801\n",
      "LOG: Epoch [1944/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1944/2000], Avg Train Loss: 0.2801, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "LOG: Epoch [1945/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2850\n",
      "LOG: Epoch [1945/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1945/2000], Avg Train Loss: 0.2850, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "LOG: Epoch [1946/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1946/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1946/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "LOG: Epoch [1947/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2825\n",
      "LOG: Epoch [1947/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1947/2000], Avg Train Loss: 0.2825, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "LOG: Epoch [1948/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [1948/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1948/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "LOG: Epoch [1949/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2808\n",
      "LOG: Epoch [1949/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1949/2000], Avg Train Loss: 0.2808, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "LOG: Epoch [1950/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2743\n",
      "LOG: Epoch [1950/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1950/2000], Avg Train Loss: 0.2743, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "LOG: Epoch [1951/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2813\n",
      "LOG: Epoch [1951/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1951/2000], Avg Train Loss: 0.2813, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "LOG: Epoch [1952/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2783\n",
      "LOG: Epoch [1952/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1952/2000], Avg Train Loss: 0.2783, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "LOG: Epoch [1953/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2866\n",
      "LOG: Epoch [1953/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1953/2000], Avg Train Loss: 0.2866, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "LOG: Epoch [1954/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2782\n",
      "LOG: Epoch [1954/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1954/2000], Avg Train Loss: 0.2782, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "LOG: Epoch [1955/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [1955/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1955/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "LOG: Epoch [1956/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [1956/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1956/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "LOG: Epoch [1957/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1957/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1957/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "LOG: Epoch [1958/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2796\n",
      "LOG: Epoch [1958/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1958/2000], Avg Train Loss: 0.2796, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "LOG: Epoch [1959/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2795\n",
      "LOG: Epoch [1959/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1959/2000], Avg Train Loss: 0.2795, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "LOG: Epoch [1960/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1960/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1960/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "LOG: Epoch [1961/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2763\n",
      "LOG: Epoch [1961/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1961/2000], Avg Train Loss: 0.2763, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "LOG: Epoch [1962/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [1962/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1962/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "LOG: Epoch [1963/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2745\n",
      "LOG: Epoch [1963/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1963/2000], Avg Train Loss: 0.2745, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "LOG: Epoch [1964/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2771\n",
      "LOG: Epoch [1964/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1964/2000], Avg Train Loss: 0.2771, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1965/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2820\n",
      "LOG: Epoch [1965/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1965/2000], Avg Train Loss: 0.2820, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1966/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2821\n",
      "LOG: Epoch [1966/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1966/2000], Avg Train Loss: 0.2821, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1967/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2804\n",
      "LOG: Epoch [1967/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1967/2000], Avg Train Loss: 0.2804, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1968/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2788\n",
      "LOG: Epoch [1968/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1968/2000], Avg Train Loss: 0.2788, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1969/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2809\n",
      "LOG: Epoch [1969/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1969/2000], Avg Train Loss: 0.2809, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1970/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [1970/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1970/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1971/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [1971/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1971/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1972/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [1972/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1972/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1973/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2723\n",
      "LOG: Epoch [1973/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1973/2000], Avg Train Loss: 0.2723, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1974/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2776\n",
      "LOG: Epoch [1974/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1974/2000], Avg Train Loss: 0.2776, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1975/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [1975/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1975/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1976/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2740\n",
      "LOG: Epoch [1976/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1976/2000], Avg Train Loss: 0.2740, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1977/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2741\n",
      "LOG: Epoch [1977/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1977/2000], Avg Train Loss: 0.2741, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1978/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2851\n",
      "LOG: Epoch [1978/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1978/2000], Avg Train Loss: 0.2851, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1979/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [1979/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3140\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1979/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1980/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2771\n",
      "LOG: Epoch [1980/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1980/2000], Avg Train Loss: 0.2771, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1981/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2784\n",
      "LOG: Epoch [1981/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1981/2000], Avg Train Loss: 0.2784, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1982/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2768\n",
      "LOG: Epoch [1982/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1982/2000], Avg Train Loss: 0.2768, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1983/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2800\n",
      "LOG: Epoch [1983/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1983/2000], Avg Train Loss: 0.2800, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1984/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2750\n",
      "LOG: Epoch [1984/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1984/2000], Avg Train Loss: 0.2750, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1985/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2797\n",
      "LOG: Epoch [1985/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1985/2000], Avg Train Loss: 0.2797, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1986/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [1986/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1986/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1987/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2790\n",
      "LOG: Epoch [1987/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1987/2000], Avg Train Loss: 0.2790, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1988/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2830\n",
      "LOG: Epoch [1988/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1988/2000], Avg Train Loss: 0.2830, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1989/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2780\n",
      "LOG: Epoch [1989/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1989/2000], Avg Train Loss: 0.2780, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1990/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2751\n",
      "LOG: Epoch [1990/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1990/2000], Avg Train Loss: 0.2751, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1991/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2802\n",
      "LOG: Epoch [1991/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1991/2000], Avg Train Loss: 0.2802, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1992/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2819\n",
      "LOG: Epoch [1992/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1992/2000], Avg Train Loss: 0.2819, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1993/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2807\n",
      "LOG: Epoch [1993/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1993/2000], Avg Train Loss: 0.2807, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1994/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2830\n",
      "LOG: Epoch [1994/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1994/2000], Avg Train Loss: 0.2830, Avg Val Loss: 0.2043\n",
      "\n",
      "Validation loss improved from 0.2043 to 0.2043. Saving model...\n",
      "LOG: Epoch [1995/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2792\n",
      "LOG: Epoch [1995/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1995/2000], Avg Train Loss: 0.2792, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1996/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2844\n",
      "LOG: Epoch [1996/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1996/2000], Avg Train Loss: 0.2844, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1997/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2747\n",
      "LOG: Epoch [1997/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1997/2000], Avg Train Loss: 0.2747, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1998/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2806\n",
      "LOG: Epoch [1998/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1998/2000], Avg Train Loss: 0.2806, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1999/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2748\n",
      "LOG: Epoch [1999/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [1999/2000], Avg Train Loss: 0.2748, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [2000/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.2794\n",
      "LOG: Epoch [2000/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3139\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [2000/2000], Avg Train Loss: 0.2794, Avg Val Loss: 0.2043\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_model = SupConNet().to(device)\n",
    "sclsdl_criterion = SilhouetteDistanceLoss()\n",
    "sclsdl_optimizer = optim.AdamW(sclsdl_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "sclsdl_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    sclsdl_optimizer, \n",
    "    mode='min',\n",
    "    patience=25,\n",
    "    factor=0.1\n",
    ")\n",
    "\n",
    "sclsdl_num_epochs = 2000\n",
    "\n",
    "sclsdl_patience = 100\n",
    "sclsdl_best_val_loss = float('inf')\n",
    "sclsdl_epochs_without_improvement = 0\n",
    "\n",
    "sclsdl_train_loss_history = []\n",
    "sclsdl_val_loss_history = []\n",
    "\n",
    "for sclsdl_epoch in range(sclsdl_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_model.train()\n",
    "    sclsdl_running_train_loss = 0.0\n",
    "    \n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Training\")\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_train_loader):\n",
    "\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_train_projections = sclsdl_model(vectors)\n",
    "\n",
    "        sclsdl_loss = sclsdl_criterion(sclsdl_train_projections, labels)\n",
    "\n",
    "        # Backprop and optimize\n",
    "        sclsdl_optimizer.zero_grad()\n",
    "        sclsdl_loss.backward()\n",
    "        sclsdl_optimizer.step()\n",
    "\n",
    "        sclsdl_running_train_loss += sclsdl_loss.item()\n",
    "        print(f\"    Batch [{batch_idx+1}/{len(sclsdl_train_loader)}], Train Loss: {sclsdl_loss.item():.4f}\")\n",
    "\n",
    "    sclsdl_train_epoch_loss = sclsdl_running_train_loss / len(sclsdl_train_loader)\n",
    "    sclsdl_train_loss_history.append(sclsdl_train_epoch_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_model.eval()\n",
    "    sclsdl_running_val_loss = 0.0\n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Validation\")\n",
    "    with torch.no_grad():\n",
    "        for val_batch_idx, (vectors, labels) in enumerate(sclsdl_val_loader):\n",
    "\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            sclsdl_val_projections = sclsdl_model(vectors)\n",
    "            sclsdl_val_batch_loss = sclsdl_criterion(sclsdl_val_projections, labels).item()\n",
    "            sclsdl_running_val_loss += sclsdl_val_batch_loss\n",
    "            print(f\"    Batch [{val_batch_idx+1}/{len(sclsdl_val_loader)}], Val Loss: {sclsdl_val_batch_loss:.4f}\")\n",
    "\n",
    "    sclsdl_val_epoch_loss = sclsdl_running_val_loss / len(sclsdl_val_loader)\n",
    "    sclsdl_val_loss_history.append(sclsdl_val_epoch_loss)\n",
    "    \n",
    "    sclsdl_scheduler.step(sclsdl_val_epoch_loss)\n",
    "\n",
    "    print(f\"Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {sclsdl_train_epoch_loss:.4f}, \"\n",
    "          f\"Avg Val Loss: {sclsdl_val_epoch_loss:.4f}\\n\")\n",
    "    \n",
    "    #early stopping logic\n",
    "    if sclsdl_val_epoch_loss < sclsdl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_best_val_loss:.4f} to {sclsdl_val_epoch_loss:.4f}. Saving model...\")\n",
    "        sclsdl_best_val_loss = sclsdl_val_epoch_loss\n",
    "        sclsdl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        sclsdl_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! Patience: {sclsdl_epochs_without_improvement}/{sclsdl_patience}\")\n",
    "\n",
    "    #stop training if val loss not improving\n",
    "    if sclsdl_epochs_without_improvement >= sclsdl_patience:\n",
    "        print(f\"!! Early stopping triggered at epoch {sclsdl_epoch + 1}!!\\nNo improvement for {sclsdl_patience} epochs\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Silhouette Distance Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:26:43.267815Z",
     "iopub.status.busy": "2025-05-08T19:26:43.267815Z",
     "iopub.status.idle": "2025-05-08T19:26:43.629372Z",
     "shell.execute_reply": "2025-05-08T19:26:43.629372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/46], Loss: 0.1446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [20/46], Loss: 0.1554\n",
      "Test Batch [30/46], Loss: 0.2154\n",
      "Test Batch [40/46], Loss: 0.1782\n",
      "\n",
      "Test Loss: 0.2253\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "sclsdl_model.eval()\n",
    "sclsdl_total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = sclsdl_model(vectors)\n",
    "        loss = sclsdl_criterion(projections, labels)\n",
    "        sclsdl_total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(sclsdl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "sclsdl_avg_test_loss = sclsdl_total_test_loss / len(sclsdl_test_loader)\n",
    "print(f\"\\nTest Loss: {sclsdl_avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=sclsdl_avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the representations learnt by SCL w/ SDL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:26:43.632380Z",
     "iopub.status.busy": "2025-05-08T19:26:43.632380Z",
     "iopub.status.idle": "2025-05-08T19:26:44.011827Z",
     "shell.execute_reply": "2025-05-08T19:26:44.011827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL_SDL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'sclsdl_representations\\train'.\n",
      "\n",
      "Extracting SCL_SDL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'sclsdl_representations\\val'.\n",
      "\n",
      "Extracting SCL_SDL representations for the test dataset...\n",
      "  Processed batch 10/46 for test dataset.\n",
      "  Processed batch 20/46 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 30/46 for test dataset.\n",
      "  Processed batch 40/46 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'sclsdl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "sclsdl_rep_dir = \"sclsdl_representations\"\n",
    "os.makedirs(sclsdl_rep_dir, exist_ok=True)\n",
    "\n",
    "sclsdl_loaders = {\n",
    "    'train': sclsdl_train_loader,\n",
    "    'val': sclsdl_val_loader,\n",
    "    'test': sclsdl_test_loader\n",
    "}\n",
    "\n",
    "sclsdl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_split_name, sclsdl_loader in sclsdl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL_SDL representations for the {sclsdl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        sclsdl_split_dir = os.path.join(sclsdl_rep_dir, sclsdl_split_name)\n",
    "        os.makedirs(sclsdl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for sclsdl_batch_idx, (sclsdl_vectors, sclsdl_labels) in enumerate(sclsdl_loader):\n",
    "            sclsdl_vectors = sclsdl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            sclsdl_projections = sclsdl_model(sclsdl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            sclsdl_projections_np = sclsdl_projections.cpu().numpy()\n",
    "            sclsdl_labels_np = sclsdl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_encoded_batch_{sclsdl_batch_idx}.npy\"), sclsdl_projections_np)\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_labels_batch_{sclsdl_batch_idx}.npy\"), sclsdl_labels_np)\n",
    "            \n",
    "            if (sclsdl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {sclsdl_batch_idx + 1}/{len(sclsdl_loader)} for {sclsdl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {sclsdl_split_name} dataset. Representations saved in '{sclsdl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by SCL w/ SDL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:26:44.014084Z",
     "iopub.status.busy": "2025-05-08T19:26:44.014084Z",
     "iopub.status.idle": "2025-05-08T19:26:44.017748Z",
     "shell.execute_reply": "2025-05-08T19:26:44.017748Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_sclsdl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    sclsdl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    sclsdl_all_reps = []\n",
    "    sclsdl_all_labels = []\n",
    "\n",
    "    for sclsdl_rep_file in sclsdl_rep_files:\n",
    "        #deriving label filenames\n",
    "        sclsdl_label_file = sclsdl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        sclsdl_reps = np.load(sclsdl_rep_file)\n",
    "        sclsdl_labels = np.load(sclsdl_label_file)\n",
    "\n",
    "        sclsdl_all_reps.append(sclsdl_reps)\n",
    "        sclsdl_all_labels.append(sclsdl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    sclsdl_all_reps = np.concatenate(sclsdl_all_reps, axis = 0)\n",
    "    sclsdl_all_labels = np.concatenate(sclsdl_all_labels, axis = 0)\n",
    "\n",
    "    return sclsdl_all_reps, sclsdl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:26:44.020758Z",
     "iopub.status.busy": "2025-05-08T19:26:44.019757Z",
     "iopub.status.idle": "2025-05-08T19:26:44.581017Z",
     "shell.execute_reply": "2025-05-08T19:26:44.581017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (280, 128)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 128)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_lrm_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_lrm_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_lrm_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_lrm_train_reps, sclsdl_lrm_train_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_train_dir)\n",
    "sclsdl_lrm_val_reps, sclsdl_lrm_val_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_val_dir)\n",
    "sclsdl_lrm_test_reps, sclsdl_lrm_test_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:26:44.584024Z",
     "iopub.status.busy": "2025-05-08T19:26:44.583024Z",
     "iopub.status.idle": "2025-05-08T19:26:44.628361Z",
     "shell.execute_reply": "2025-05-08T19:26:44.628361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 90.00%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       0.83      1.00      0.91         5\n",
      "           3       1.00      0.80      0.89         5\n",
      "           4       1.00      0.80      0.89         5\n",
      "           5       0.67      0.40      0.50         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       0.50      0.80      0.62         5\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       0.83      1.00      0.91         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.90        70\n",
      "   macro avg       0.92      0.90      0.90        70\n",
      "weighted avg       0.92      0.90      0.90        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 88.47%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       245\n",
      "           1       0.95      0.93      0.94        76\n",
      "           2       0.89      0.97      0.93       226\n",
      "           3       0.91      0.98      0.95       190\n",
      "           4       0.94      0.66      0.78       244\n",
      "           5       0.66      0.70      0.68       244\n",
      "           6       0.97      0.95      0.96       234\n",
      "           7       0.94      0.82      0.88       178\n",
      "           8       0.77      0.79      0.78       289\n",
      "           9       0.77      0.97      0.86       223\n",
      "          10       0.97      0.93      0.95       280\n",
      "          11       0.95      0.99      0.97       156\n",
      "          12       0.92      0.91      0.92       243\n",
      "          13       0.98      0.90      0.94        70\n",
      "\n",
      "    accuracy                           0.88      2898\n",
      "   macro avg       0.90      0.89      0.89      2898\n",
      "weighted avg       0.89      0.88      0.88      2898\n",
      "\n",
      "Saved SCL_SDL+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression Model on the SCLSDL representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "sclsdl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "sclsdl_logistic_clf.fit(sclsdl_lrm_train_reps, sclsdl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "sclsdl_lrm_val_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_val_reps)\n",
    "sclsdl_lrm_val_accuracy = accuracy_score(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {sclsdl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions))\n",
    "\n",
    "# Evaluate on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "sclsdl_lrm_test_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_test_reps)\n",
    "sclsdl_lrm_test_accuracy = accuracy_score(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {sclsdl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_predictions.npy'), sclsdl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_true_labels.npy'), sclsdl_lrm_test_labels)\n",
    "print(f\"Saved SCL_SDL+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the representations learnt by SCL w/ SDL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:26:44.630367Z",
     "iopub.status.busy": "2025-05-08T19:26:44.630367Z",
     "iopub.status.idle": "2025-05-08T19:26:44.648408Z",
     "shell.execute_reply": "2025-05-08T19:26:44.648408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (280, 128)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 128)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_mlp_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_mlp_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_mlp_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_mlp_train_reps, sclsdl_mlp_train_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_train_dir)\n",
    "sclsdl_mlp_val_reps, sclsdl_mlp_val_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_val_dir)\n",
    "sclsdl_mlp_test_reps, sclsdl_mlp_test_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:26:44.650936Z",
     "iopub.status.busy": "2025-05-08T19:26:44.650936Z",
     "iopub.status.idle": "2025-05-08T19:26:44.656443Z",
     "shell.execute_reply": "2025-05-08T19:26:44.655940Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "sclsdl_mlp_train_embeddings_torch = torch.tensor(sclsdl_mlp_train_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_train_labels_torch = torch.tensor(sclsdl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_val_embeddings_torch = torch.tensor(sclsdl_mlp_val_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_val_labels_torch = torch.tensor(sclsdl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_test_embeddings_torch = torch.tensor(sclsdl_mlp_test_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_test_labels_torch = torch.tensor(sclsdl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "sclsdl_mlp_train_dataset = TensorDataset(sclsdl_mlp_train_embeddings_torch, sclsdl_mlp_train_labels_torch)\n",
    "sclsdl_mlp_val_dataset = TensorDataset(sclsdl_mlp_val_embeddings_torch, sclsdl_mlp_val_labels_torch)\n",
    "sclsdl_mlp_test_dataset = TensorDataset(sclsdl_mlp_test_embeddings_torch, sclsdl_mlp_test_labels_torch)\n",
    "\n",
    "sclsdl_mlp_batch_size = 64\n",
    "sclsdl_mlp_train_loader = DataLoader(sclsdl_mlp_train_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=True)\n",
    "sclsdl_mlp_val_loader = DataLoader(sclsdl_mlp_val_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n",
    "sclsdl_mlp_test_loader = DataLoader(sclsdl_mlp_test_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:26:44.658453Z",
     "iopub.status.busy": "2025-05-08T19:26:44.658453Z",
     "iopub.status.idle": "2025-05-08T19:26:48.879210Z",
     "shell.execute_reply": "2025-05-08T19:26:48.879210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.6376  |  Val Loss: 2.6008\n",
      "Validation loss improved from inf to 2.6008.\n",
      "[Epoch 2/1000] Train Loss: 2.5936  |  Val Loss: 2.5615\n",
      "Validation loss improved from 2.6008 to 2.5615.\n",
      "[Epoch 3/1000] Train Loss: 2.5525  |  Val Loss: 2.5273\n",
      "Validation loss improved from 2.5615 to 2.5273.\n",
      "[Epoch 4/1000] Train Loss: 2.5150  |  Val Loss: 2.4950\n",
      "Validation loss improved from 2.5273 to 2.4950.\n",
      "[Epoch 5/1000] Train Loss: 2.4815  |  Val Loss: 2.4629\n",
      "Validation loss improved from 2.4950 to 2.4629.\n",
      "[Epoch 6/1000] Train Loss: 2.4465  |  Val Loss: 2.4328\n",
      "Validation loss improved from 2.4629 to 2.4328.\n",
      "[Epoch 7/1000] Train Loss: 2.4153  |  Val Loss: 2.4028\n",
      "Validation loss improved from 2.4328 to 2.4028.\n",
      "[Epoch 8/1000] Train Loss: 2.3833  |  Val Loss: 2.3738\n",
      "Validation loss improved from 2.4028 to 2.3738.\n",
      "[Epoch 9/1000] Train Loss: 2.3501  |  Val Loss: 2.3447\n",
      "Validation loss improved from 2.3738 to 2.3447.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/1000] Train Loss: 2.3194  |  Val Loss: 2.3145\n",
      "Validation loss improved from 2.3447 to 2.3145.\n",
      "[Epoch 11/1000] Train Loss: 2.2868  |  Val Loss: 2.2854\n",
      "Validation loss improved from 2.3145 to 2.2854.\n",
      "[Epoch 12/1000] Train Loss: 2.2554  |  Val Loss: 2.2573\n",
      "Validation loss improved from 2.2854 to 2.2573.\n",
      "[Epoch 13/1000] Train Loss: 2.2259  |  Val Loss: 2.2301\n",
      "Validation loss improved from 2.2573 to 2.2301.\n",
      "[Epoch 14/1000] Train Loss: 2.1973  |  Val Loss: 2.2039\n",
      "Validation loss improved from 2.2301 to 2.2039.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/1000] Train Loss: 2.1698  |  Val Loss: 2.1792\n",
      "Validation loss improved from 2.2039 to 2.1792.\n",
      "[Epoch 16/1000] Train Loss: 2.1445  |  Val Loss: 2.1551\n",
      "Validation loss improved from 2.1792 to 2.1551.\n",
      "[Epoch 17/1000] Train Loss: 2.1189  |  Val Loss: 2.1324\n",
      "Validation loss improved from 2.1551 to 2.1324.\n",
      "[Epoch 18/1000] Train Loss: 2.0955  |  Val Loss: 2.1104\n",
      "Validation loss improved from 2.1324 to 2.1104.\n",
      "[Epoch 19/1000] Train Loss: 2.0723  |  Val Loss: 2.0895\n",
      "Validation loss improved from 2.1104 to 2.0895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/1000] Train Loss: 2.0502  |  Val Loss: 2.0689\n",
      "Validation loss improved from 2.0895 to 2.0689.\n",
      "[Epoch 21/1000] Train Loss: 2.0283  |  Val Loss: 2.0487\n",
      "Validation loss improved from 2.0689 to 2.0487.\n",
      "[Epoch 22/1000] Train Loss: 2.0062  |  Val Loss: 2.0293\n",
      "Validation loss improved from 2.0487 to 2.0293.\n",
      "[Epoch 23/1000] Train Loss: 1.9849  |  Val Loss: 2.0095\n",
      "Validation loss improved from 2.0293 to 2.0095.\n",
      "[Epoch 24/1000] Train Loss: 1.9626  |  Val Loss: 1.9893\n",
      "Validation loss improved from 2.0095 to 1.9893.\n",
      "[Epoch 25/1000] Train Loss: 1.9399  |  Val Loss: 1.9680\n",
      "Validation loss improved from 1.9893 to 1.9680.\n",
      "[Epoch 26/1000] Train Loss: 1.9170  |  Val Loss: 1.9467\n",
      "Validation loss improved from 1.9680 to 1.9467.\n",
      "[Epoch 27/1000] Train Loss: 1.8944  |  Val Loss: 1.9258\n",
      "Validation loss improved from 1.9467 to 1.9258.\n",
      "[Epoch 28/1000] Train Loss: 1.8714  |  Val Loss: 1.9055\n",
      "Validation loss improved from 1.9258 to 1.9055.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29/1000] Train Loss: 1.8495  |  Val Loss: 1.8850\n",
      "Validation loss improved from 1.9055 to 1.8850.\n",
      "[Epoch 30/1000] Train Loss: 1.8269  |  Val Loss: 1.8646\n",
      "Validation loss improved from 1.8850 to 1.8646.\n",
      "[Epoch 31/1000] Train Loss: 1.8053  |  Val Loss: 1.8439\n",
      "Validation loss improved from 1.8646 to 1.8439.\n",
      "[Epoch 32/1000] Train Loss: 1.7824  |  Val Loss: 1.8238\n",
      "Validation loss improved from 1.8439 to 1.8238.\n",
      "[Epoch 33/1000] Train Loss: 1.7604  |  Val Loss: 1.8042\n",
      "Validation loss improved from 1.8238 to 1.8042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/1000] Train Loss: 1.7387  |  Val Loss: 1.7842\n",
      "Validation loss improved from 1.8042 to 1.7842.\n",
      "[Epoch 35/1000] Train Loss: 1.7161  |  Val Loss: 1.7642\n",
      "Validation loss improved from 1.7842 to 1.7642.\n",
      "[Epoch 36/1000] Train Loss: 1.6941  |  Val Loss: 1.7442\n",
      "Validation loss improved from 1.7642 to 1.7442.\n",
      "[Epoch 37/1000] Train Loss: 1.6716  |  Val Loss: 1.7243\n",
      "Validation loss improved from 1.7442 to 1.7243.\n",
      "[Epoch 38/1000] Train Loss: 1.6497  |  Val Loss: 1.7042\n",
      "Validation loss improved from 1.7243 to 1.7042.\n",
      "[Epoch 39/1000] Train Loss: 1.6281  |  Val Loss: 1.6838\n",
      "Validation loss improved from 1.7042 to 1.6838.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40/1000] Train Loss: 1.6049  |  Val Loss: 1.6639\n",
      "Validation loss improved from 1.6838 to 1.6639.\n",
      "[Epoch 41/1000] Train Loss: 1.5830  |  Val Loss: 1.6439\n",
      "Validation loss improved from 1.6639 to 1.6439.\n",
      "[Epoch 42/1000] Train Loss: 1.5603  |  Val Loss: 1.6242\n",
      "Validation loss improved from 1.6439 to 1.6242.\n",
      "[Epoch 43/1000] Train Loss: 1.5383  |  Val Loss: 1.6042\n",
      "Validation loss improved from 1.6242 to 1.6042.\n",
      "[Epoch 44/1000] Train Loss: 1.5157  |  Val Loss: 1.5845\n",
      "Validation loss improved from 1.6042 to 1.5845.\n",
      "[Epoch 45/1000] Train Loss: 1.4930  |  Val Loss: 1.5650\n",
      "Validation loss improved from 1.5845 to 1.5650.\n",
      "[Epoch 46/1000] Train Loss: 1.4710  |  Val Loss: 1.5452\n",
      "Validation loss improved from 1.5650 to 1.5452.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 47/1000] Train Loss: 1.4481  |  Val Loss: 1.5259\n",
      "Validation loss improved from 1.5452 to 1.5259.\n",
      "[Epoch 48/1000] Train Loss: 1.4260  |  Val Loss: 1.5062\n",
      "Validation loss improved from 1.5259 to 1.5062.\n",
      "[Epoch 49/1000] Train Loss: 1.4034  |  Val Loss: 1.4868\n",
      "Validation loss improved from 1.5062 to 1.4868.\n",
      "[Epoch 50/1000] Train Loss: 1.3815  |  Val Loss: 1.4672\n",
      "Validation loss improved from 1.4868 to 1.4672.\n",
      "[Epoch 51/1000] Train Loss: 1.3592  |  Val Loss: 1.4480\n",
      "Validation loss improved from 1.4672 to 1.4480.\n",
      "[Epoch 52/1000] Train Loss: 1.3370  |  Val Loss: 1.4290\n",
      "Validation loss improved from 1.4480 to 1.4290.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 53/1000] Train Loss: 1.3151  |  Val Loss: 1.4101\n",
      "Validation loss improved from 1.4290 to 1.4101.\n",
      "[Epoch 54/1000] Train Loss: 1.2930  |  Val Loss: 1.3912\n",
      "Validation loss improved from 1.4101 to 1.3912.\n",
      "[Epoch 55/1000] Train Loss: 1.2718  |  Val Loss: 1.3721\n",
      "Validation loss improved from 1.3912 to 1.3721.\n",
      "[Epoch 56/1000] Train Loss: 1.2501  |  Val Loss: 1.3530\n",
      "Validation loss improved from 1.3721 to 1.3530.\n",
      "[Epoch 57/1000] Train Loss: 1.2285  |  Val Loss: 1.3337\n",
      "Validation loss improved from 1.3530 to 1.3337.\n",
      "[Epoch 58/1000] Train Loss: 1.2068  |  Val Loss: 1.3146\n",
      "Validation loss improved from 1.3337 to 1.3146.\n",
      "[Epoch 59/1000] Train Loss: 1.1855  |  Val Loss: 1.2951\n",
      "Validation loss improved from 1.3146 to 1.2951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 60/1000] Train Loss: 1.1635  |  Val Loss: 1.2757\n",
      "Validation loss improved from 1.2951 to 1.2757.\n",
      "[Epoch 61/1000] Train Loss: 1.1422  |  Val Loss: 1.2565\n",
      "Validation loss improved from 1.2757 to 1.2565.\n",
      "[Epoch 62/1000] Train Loss: 1.1214  |  Val Loss: 1.2375\n",
      "Validation loss improved from 1.2565 to 1.2375.\n",
      "[Epoch 63/1000] Train Loss: 1.1007  |  Val Loss: 1.2187\n",
      "Validation loss improved from 1.2375 to 1.2187.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 64/1000] Train Loss: 1.0804  |  Val Loss: 1.2001\n",
      "Validation loss improved from 1.2187 to 1.2001.\n",
      "[Epoch 65/1000] Train Loss: 1.0603  |  Val Loss: 1.1814\n",
      "Validation loss improved from 1.2001 to 1.1814.\n",
      "[Epoch 66/1000] Train Loss: 1.0400  |  Val Loss: 1.1630\n",
      "Validation loss improved from 1.1814 to 1.1630.\n",
      "[Epoch 67/1000] Train Loss: 1.0207  |  Val Loss: 1.1448\n",
      "Validation loss improved from 1.1630 to 1.1448.\n",
      "[Epoch 68/1000] Train Loss: 1.0005  |  Val Loss: 1.1270\n",
      "Validation loss improved from 1.1448 to 1.1270.\n",
      "[Epoch 69/1000] Train Loss: 0.9805  |  Val Loss: 1.1096\n",
      "Validation loss improved from 1.1270 to 1.1096.\n",
      "[Epoch 70/1000] Train Loss: 0.9612  |  Val Loss: 1.0924\n",
      "Validation loss improved from 1.1096 to 1.0924.\n",
      "[Epoch 71/1000] Train Loss: 0.9415  |  Val Loss: 1.0752\n",
      "Validation loss improved from 1.0924 to 1.0752.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 72/1000] Train Loss: 0.9220  |  Val Loss: 1.0580\n",
      "Validation loss improved from 1.0752 to 1.0580.\n",
      "[Epoch 73/1000] Train Loss: 0.9028  |  Val Loss: 1.0405\n",
      "Validation loss improved from 1.0580 to 1.0405.\n",
      "[Epoch 74/1000] Train Loss: 0.8835  |  Val Loss: 1.0229\n",
      "Validation loss improved from 1.0405 to 1.0229.\n",
      "[Epoch 75/1000] Train Loss: 0.8647  |  Val Loss: 1.0053\n",
      "Validation loss improved from 1.0229 to 1.0053.\n",
      "[Epoch 76/1000] Train Loss: 0.8457  |  Val Loss: 0.9885\n",
      "Validation loss improved from 1.0053 to 0.9885.\n",
      "[Epoch 77/1000] Train Loss: 0.8274  |  Val Loss: 0.9722\n",
      "Validation loss improved from 0.9885 to 0.9722.\n",
      "[Epoch 78/1000] Train Loss: 0.8090  |  Val Loss: 0.9559\n",
      "Validation loss improved from 0.9722 to 0.9559.\n",
      "[Epoch 79/1000] Train Loss: 0.7914  |  Val Loss: 0.9393\n",
      "Validation loss improved from 0.9559 to 0.9393.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 80/1000] Train Loss: 0.7737  |  Val Loss: 0.9226\n",
      "Validation loss improved from 0.9393 to 0.9226.\n",
      "[Epoch 81/1000] Train Loss: 0.7561  |  Val Loss: 0.9065\n",
      "Validation loss improved from 0.9226 to 0.9065.\n",
      "[Epoch 82/1000] Train Loss: 0.7391  |  Val Loss: 0.8909\n",
      "Validation loss improved from 0.9065 to 0.8909.\n",
      "[Epoch 83/1000] Train Loss: 0.7228  |  Val Loss: 0.8754\n",
      "Validation loss improved from 0.8909 to 0.8754.\n",
      "[Epoch 84/1000] Train Loss: 0.7063  |  Val Loss: 0.8602\n",
      "Validation loss improved from 0.8754 to 0.8602.\n",
      "[Epoch 85/1000] Train Loss: 0.6903  |  Val Loss: 0.8455\n",
      "Validation loss improved from 0.8602 to 0.8455.\n",
      "[Epoch 86/1000] Train Loss: 0.6744  |  Val Loss: 0.8310\n",
      "Validation loss improved from 0.8455 to 0.8310.\n",
      "[Epoch 87/1000] Train Loss: 0.6587  |  Val Loss: 0.8170\n",
      "Validation loss improved from 0.8310 to 0.8170.\n",
      "[Epoch 88/1000] Train Loss: 0.6433  |  Val Loss: 0.8031\n",
      "Validation loss improved from 0.8170 to 0.8031.\n",
      "[Epoch 89/1000] Train Loss: 0.6282  |  Val Loss: 0.7891\n",
      "Validation loss improved from 0.8031 to 0.7891.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 90/1000] Train Loss: 0.6130  |  Val Loss: 0.7755\n",
      "Validation loss improved from 0.7891 to 0.7755.\n",
      "[Epoch 91/1000] Train Loss: 0.5980  |  Val Loss: 0.7620\n",
      "Validation loss improved from 0.7755 to 0.7620.\n",
      "[Epoch 92/1000] Train Loss: 0.5836  |  Val Loss: 0.7487\n",
      "Validation loss improved from 0.7620 to 0.7487.\n",
      "[Epoch 93/1000] Train Loss: 0.5696  |  Val Loss: 0.7357\n",
      "Validation loss improved from 0.7487 to 0.7357.\n",
      "[Epoch 94/1000] Train Loss: 0.5551  |  Val Loss: 0.7228\n",
      "Validation loss improved from 0.7357 to 0.7228.\n",
      "[Epoch 95/1000] Train Loss: 0.5409  |  Val Loss: 0.7101\n",
      "Validation loss improved from 0.7228 to 0.7101.\n",
      "[Epoch 96/1000] Train Loss: 0.5273  |  Val Loss: 0.6975\n",
      "Validation loss improved from 0.7101 to 0.6975.\n",
      "[Epoch 97/1000] Train Loss: 0.5136  |  Val Loss: 0.6847\n",
      "Validation loss improved from 0.6975 to 0.6847.\n",
      "[Epoch 98/1000] Train Loss: 0.5001  |  Val Loss: 0.6726\n",
      "Validation loss improved from 0.6847 to 0.6726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 99/1000] Train Loss: 0.4868  |  Val Loss: 0.6609\n",
      "Validation loss improved from 0.6726 to 0.6609.\n",
      "[Epoch 100/1000] Train Loss: 0.4742  |  Val Loss: 0.6494\n",
      "Validation loss improved from 0.6609 to 0.6494.\n",
      "[Epoch 101/1000] Train Loss: 0.4612  |  Val Loss: 0.6376\n",
      "Validation loss improved from 0.6494 to 0.6376.\n",
      "[Epoch 102/1000] Train Loss: 0.4488  |  Val Loss: 0.6258\n",
      "Validation loss improved from 0.6376 to 0.6258.\n",
      "[Epoch 103/1000] Train Loss: 0.4368  |  Val Loss: 0.6146\n",
      "Validation loss improved from 0.6258 to 0.6146.\n",
      "[Epoch 104/1000] Train Loss: 0.4249  |  Val Loss: 0.6031\n",
      "Validation loss improved from 0.6146 to 0.6031.\n",
      "[Epoch 105/1000] Train Loss: 0.4125  |  Val Loss: 0.5922\n",
      "Validation loss improved from 0.6031 to 0.5922.\n",
      "[Epoch 106/1000] Train Loss: 0.4013  |  Val Loss: 0.5811\n",
      "Validation loss improved from 0.5922 to 0.5811.\n",
      "[Epoch 107/1000] Train Loss: 0.3901  |  Val Loss: 0.5703\n",
      "Validation loss improved from 0.5811 to 0.5703.\n",
      "[Epoch 108/1000] Train Loss: 0.3790  |  Val Loss: 0.5598\n",
      "Validation loss improved from 0.5703 to 0.5598.\n",
      "[Epoch 109/1000] Train Loss: 0.3683  |  Val Loss: 0.5496\n",
      "Validation loss improved from 0.5598 to 0.5496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 110/1000] Train Loss: 0.3577  |  Val Loss: 0.5400\n",
      "Validation loss improved from 0.5496 to 0.5400.\n",
      "[Epoch 111/1000] Train Loss: 0.3478  |  Val Loss: 0.5308\n",
      "Validation loss improved from 0.5400 to 0.5308.\n",
      "[Epoch 112/1000] Train Loss: 0.3379  |  Val Loss: 0.5220\n",
      "Validation loss improved from 0.5308 to 0.5220.\n",
      "[Epoch 113/1000] Train Loss: 0.3286  |  Val Loss: 0.5129\n",
      "Validation loss improved from 0.5220 to 0.5129.\n",
      "[Epoch 114/1000] Train Loss: 0.3194  |  Val Loss: 0.5041\n",
      "Validation loss improved from 0.5129 to 0.5041.\n",
      "[Epoch 115/1000] Train Loss: 0.3106  |  Val Loss: 0.4953\n",
      "Validation loss improved from 0.5041 to 0.4953.\n",
      "[Epoch 116/1000] Train Loss: 0.3020  |  Val Loss: 0.4872\n",
      "Validation loss improved from 0.4953 to 0.4872.\n",
      "[Epoch 117/1000] Train Loss: 0.2937  |  Val Loss: 0.4798\n",
      "Validation loss improved from 0.4872 to 0.4798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 118/1000] Train Loss: 0.2856  |  Val Loss: 0.4728\n",
      "Validation loss improved from 0.4798 to 0.4728.\n",
      "[Epoch 119/1000] Train Loss: 0.2783  |  Val Loss: 0.4656\n",
      "Validation loss improved from 0.4728 to 0.4656.\n",
      "[Epoch 120/1000] Train Loss: 0.2706  |  Val Loss: 0.4585\n",
      "Validation loss improved from 0.4656 to 0.4585.\n",
      "[Epoch 121/1000] Train Loss: 0.2636  |  Val Loss: 0.4515\n",
      "Validation loss improved from 0.4585 to 0.4515.\n",
      "[Epoch 122/1000] Train Loss: 0.2564  |  Val Loss: 0.4451\n",
      "Validation loss improved from 0.4515 to 0.4451.\n",
      "[Epoch 123/1000] Train Loss: 0.2500  |  Val Loss: 0.4387\n",
      "Validation loss improved from 0.4451 to 0.4387.\n",
      "[Epoch 124/1000] Train Loss: 0.2435  |  Val Loss: 0.4331\n",
      "Validation loss improved from 0.4387 to 0.4331.\n",
      "[Epoch 125/1000] Train Loss: 0.2372  |  Val Loss: 0.4280\n",
      "Validation loss improved from 0.4331 to 0.4280.\n",
      "[Epoch 126/1000] Train Loss: 0.2317  |  Val Loss: 0.4231\n",
      "Validation loss improved from 0.4280 to 0.4231.\n",
      "[Epoch 127/1000] Train Loss: 0.2260  |  Val Loss: 0.4176\n",
      "Validation loss improved from 0.4231 to 0.4176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 128/1000] Train Loss: 0.2207  |  Val Loss: 0.4123\n",
      "Validation loss improved from 0.4176 to 0.4123.\n",
      "[Epoch 129/1000] Train Loss: 0.2152  |  Val Loss: 0.4079\n",
      "Validation loss improved from 0.4123 to 0.4079.\n",
      "[Epoch 130/1000] Train Loss: 0.2102  |  Val Loss: 0.4027\n",
      "Validation loss improved from 0.4079 to 0.4027.\n",
      "[Epoch 131/1000] Train Loss: 0.2054  |  Val Loss: 0.3978\n",
      "Validation loss improved from 0.4027 to 0.3978.\n",
      "[Epoch 132/1000] Train Loss: 0.2009  |  Val Loss: 0.3929\n",
      "Validation loss improved from 0.3978 to 0.3929.\n",
      "[Epoch 133/1000] Train Loss: 0.1961  |  Val Loss: 0.3891\n",
      "Validation loss improved from 0.3929 to 0.3891.\n",
      "[Epoch 134/1000] Train Loss: 0.1918  |  Val Loss: 0.3857\n",
      "Validation loss improved from 0.3891 to 0.3857.\n",
      "[Epoch 135/1000] Train Loss: 0.1879  |  Val Loss: 0.3828\n",
      "Validation loss improved from 0.3857 to 0.3828.\n",
      "[Epoch 136/1000] Train Loss: 0.1837  |  Val Loss: 0.3795\n",
      "Validation loss improved from 0.3828 to 0.3795.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 137/1000] Train Loss: 0.1797  |  Val Loss: 0.3754\n",
      "Validation loss improved from 0.3795 to 0.3754.\n",
      "[Epoch 138/1000] Train Loss: 0.1761  |  Val Loss: 0.3718\n",
      "Validation loss improved from 0.3754 to 0.3718.\n",
      "[Epoch 139/1000] Train Loss: 0.1722  |  Val Loss: 0.3682\n",
      "Validation loss improved from 0.3718 to 0.3682.\n",
      "[Epoch 140/1000] Train Loss: 0.1689  |  Val Loss: 0.3647\n",
      "Validation loss improved from 0.3682 to 0.3647.\n",
      "[Epoch 141/1000] Train Loss: 0.1655  |  Val Loss: 0.3617\n",
      "Validation loss improved from 0.3647 to 0.3617.\n",
      "[Epoch 142/1000] Train Loss: 0.1622  |  Val Loss: 0.3588\n",
      "Validation loss improved from 0.3617 to 0.3588.\n",
      "[Epoch 143/1000] Train Loss: 0.1590  |  Val Loss: 0.3565\n",
      "Validation loss improved from 0.3588 to 0.3565.\n",
      "[Epoch 144/1000] Train Loss: 0.1560  |  Val Loss: 0.3549\n",
      "Validation loss improved from 0.3565 to 0.3549.\n",
      "[Epoch 145/1000] Train Loss: 0.1531  |  Val Loss: 0.3530\n",
      "Validation loss improved from 0.3549 to 0.3530.\n",
      "[Epoch 146/1000] Train Loss: 0.1502  |  Val Loss: 0.3511\n",
      "Validation loss improved from 0.3530 to 0.3511.\n",
      "[Epoch 147/1000] Train Loss: 0.1475  |  Val Loss: 0.3500\n",
      "Validation loss improved from 0.3511 to 0.3500.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 148/1000] Train Loss: 0.1451  |  Val Loss: 0.3490\n",
      "Validation loss improved from 0.3500 to 0.3490.\n",
      "[Epoch 149/1000] Train Loss: 0.1423  |  Val Loss: 0.3465\n",
      "Validation loss improved from 0.3490 to 0.3465.\n",
      "[Epoch 150/1000] Train Loss: 0.1399  |  Val Loss: 0.3449\n",
      "Validation loss improved from 0.3465 to 0.3449.\n",
      "[Epoch 151/1000] Train Loss: 0.1376  |  Val Loss: 0.3427\n",
      "Validation loss improved from 0.3449 to 0.3427.\n",
      "[Epoch 152/1000] Train Loss: 0.1352  |  Val Loss: 0.3405\n",
      "Validation loss improved from 0.3427 to 0.3405.\n",
      "[Epoch 153/1000] Train Loss: 0.1329  |  Val Loss: 0.3381\n",
      "Validation loss improved from 0.3405 to 0.3381.\n",
      "[Epoch 154/1000] Train Loss: 0.1307  |  Val Loss: 0.3359\n",
      "Validation loss improved from 0.3381 to 0.3359.\n",
      "[Epoch 155/1000] Train Loss: 0.1285  |  Val Loss: 0.3333\n",
      "Validation loss improved from 0.3359 to 0.3333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 156/1000] Train Loss: 0.1265  |  Val Loss: 0.3308\n",
      "Validation loss improved from 0.3333 to 0.3308.\n",
      "[Epoch 157/1000] Train Loss: 0.1245  |  Val Loss: 0.3284\n",
      "Validation loss improved from 0.3308 to 0.3284.\n",
      "[Epoch 158/1000] Train Loss: 0.1225  |  Val Loss: 0.3265\n",
      "Validation loss improved from 0.3284 to 0.3265.\n",
      "[Epoch 159/1000] Train Loss: 0.1206  |  Val Loss: 0.3254\n",
      "Validation loss improved from 0.3265 to 0.3254.\n",
      "[Epoch 160/1000] Train Loss: 0.1187  |  Val Loss: 0.3243\n",
      "Validation loss improved from 0.3254 to 0.3243.\n",
      "[Epoch 161/1000] Train Loss: 0.1170  |  Val Loss: 0.3234\n",
      "Validation loss improved from 0.3243 to 0.3234.\n",
      "[Epoch 162/1000] Train Loss: 0.1152  |  Val Loss: 0.3227\n",
      "Validation loss improved from 0.3234 to 0.3227.\n",
      "[Epoch 163/1000] Train Loss: 0.1136  |  Val Loss: 0.3219\n",
      "Validation loss improved from 0.3227 to 0.3219.\n",
      "[Epoch 164/1000] Train Loss: 0.1119  |  Val Loss: 0.3213\n",
      "Validation loss improved from 0.3219 to 0.3213.\n",
      "[Epoch 165/1000] Train Loss: 0.1102  |  Val Loss: 0.3205\n",
      "Validation loss improved from 0.3213 to 0.3205.\n",
      "[Epoch 166/1000] Train Loss: 0.1086  |  Val Loss: 0.3190\n",
      "Validation loss improved from 0.3205 to 0.3190.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 167/1000] Train Loss: 0.1071  |  Val Loss: 0.3175\n",
      "Validation loss improved from 0.3190 to 0.3175.\n",
      "[Epoch 168/1000] Train Loss: 0.1058  |  Val Loss: 0.3156\n",
      "Validation loss improved from 0.3175 to 0.3156.\n",
      "[Epoch 169/1000] Train Loss: 0.1042  |  Val Loss: 0.3144\n",
      "Validation loss improved from 0.3156 to 0.3144.\n",
      "[Epoch 170/1000] Train Loss: 0.1028  |  Val Loss: 0.3130\n",
      "Validation loss improved from 0.3144 to 0.3130.\n",
      "[Epoch 171/1000] Train Loss: 0.1014  |  Val Loss: 0.3115\n",
      "Validation loss improved from 0.3130 to 0.3115.\n",
      "[Epoch 172/1000] Train Loss: 0.1001  |  Val Loss: 0.3109\n",
      "Validation loss improved from 0.3115 to 0.3109.\n",
      "[Epoch 173/1000] Train Loss: 0.0987  |  Val Loss: 0.3091\n",
      "Validation loss improved from 0.3109 to 0.3091.\n",
      "[Epoch 174/1000] Train Loss: 0.0975  |  Val Loss: 0.3078\n",
      "Validation loss improved from 0.3091 to 0.3078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 175/1000] Train Loss: 0.0961  |  Val Loss: 0.3081\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 176/1000] Train Loss: 0.0948  |  Val Loss: 0.3089\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 177/1000] Train Loss: 0.0936  |  Val Loss: 0.3099\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 178/1000] Train Loss: 0.0927  |  Val Loss: 0.3106\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 179/1000] Train Loss: 0.0916  |  Val Loss: 0.3110\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 180/1000] Train Loss: 0.0905  |  Val Loss: 0.3107\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 181/1000] Train Loss: 0.0894  |  Val Loss: 0.3091\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 182/1000] Train Loss: 0.0883  |  Val Loss: 0.3076\n",
      "Validation loss improved from 0.3078 to 0.3076.\n",
      "[Epoch 183/1000] Train Loss: 0.0871  |  Val Loss: 0.3064\n",
      "Validation loss improved from 0.3076 to 0.3064.\n",
      "[Epoch 184/1000] Train Loss: 0.0860  |  Val Loss: 0.3044\n",
      "Validation loss improved from 0.3064 to 0.3044.\n",
      "[Epoch 185/1000] Train Loss: 0.0848  |  Val Loss: 0.3025\n",
      "Validation loss improved from 0.3044 to 0.3025.\n",
      "[Epoch 186/1000] Train Loss: 0.0837  |  Val Loss: 0.3010\n",
      "Validation loss improved from 0.3025 to 0.3010.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 187/1000] Train Loss: 0.0828  |  Val Loss: 0.2996\n",
      "Validation loss improved from 0.3010 to 0.2996.\n",
      "[Epoch 188/1000] Train Loss: 0.0818  |  Val Loss: 0.2991\n",
      "Validation loss improved from 0.2996 to 0.2991.\n",
      "[Epoch 189/1000] Train Loss: 0.0808  |  Val Loss: 0.2975\n",
      "Validation loss improved from 0.2991 to 0.2975.\n",
      "[Epoch 190/1000] Train Loss: 0.0799  |  Val Loss: 0.2958\n",
      "Validation loss improved from 0.2975 to 0.2958.\n",
      "[Epoch 191/1000] Train Loss: 0.0790  |  Val Loss: 0.2951\n",
      "Validation loss improved from 0.2958 to 0.2951.\n",
      "[Epoch 192/1000] Train Loss: 0.0781  |  Val Loss: 0.2941\n",
      "Validation loss improved from 0.2951 to 0.2941.\n",
      "[Epoch 193/1000] Train Loss: 0.0772  |  Val Loss: 0.2946\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 194/1000] Train Loss: 0.0762  |  Val Loss: 0.2944\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 195/1000] Train Loss: 0.0754  |  Val Loss: 0.2941\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 196/1000] Train Loss: 0.0745  |  Val Loss: 0.2934\n",
      "Validation loss improved from 0.2941 to 0.2934.\n",
      "[Epoch 197/1000] Train Loss: 0.0737  |  Val Loss: 0.2933\n",
      "Validation loss improved from 0.2934 to 0.2933.\n",
      "[Epoch 198/1000] Train Loss: 0.0729  |  Val Loss: 0.2932\n",
      "Validation loss improved from 0.2933 to 0.2932.\n",
      "[Epoch 199/1000] Train Loss: 0.0721  |  Val Loss: 0.2944\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 200/1000] Train Loss: 0.0714  |  Val Loss: 0.2949\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 201/1000] Train Loss: 0.0706  |  Val Loss: 0.2934\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 202/1000] Train Loss: 0.0696  |  Val Loss: 0.2939\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 203/1000] Train Loss: 0.0690  |  Val Loss: 0.2937\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 204/1000] Train Loss: 0.0681  |  Val Loss: 0.2941\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 205/1000] Train Loss: 0.0675  |  Val Loss: 0.2948\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 206/1000] Train Loss: 0.0668  |  Val Loss: 0.2941\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 207/1000] Train Loss: 0.0660  |  Val Loss: 0.2920\n",
      "Validation loss improved from 0.2932 to 0.2920.\n",
      "[Epoch 208/1000] Train Loss: 0.0652  |  Val Loss: 0.2913\n",
      "Validation loss improved from 0.2920 to 0.2913.\n",
      "[Epoch 209/1000] Train Loss: 0.0647  |  Val Loss: 0.2911\n",
      "Validation loss improved from 0.2913 to 0.2911.\n",
      "[Epoch 210/1000] Train Loss: 0.0641  |  Val Loss: 0.2910\n",
      "Validation loss improved from 0.2911 to 0.2910.\n",
      "[Epoch 211/1000] Train Loss: 0.0634  |  Val Loss: 0.2906\n",
      "Validation loss improved from 0.2910 to 0.2906.\n",
      "[Epoch 212/1000] Train Loss: 0.0627  |  Val Loss: 0.2902\n",
      "Validation loss improved from 0.2906 to 0.2902.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 213/1000] Train Loss: 0.0621  |  Val Loss: 0.2897\n",
      "Validation loss improved from 0.2902 to 0.2897.\n",
      "[Epoch 214/1000] Train Loss: 0.0614  |  Val Loss: 0.2898\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 215/1000] Train Loss: 0.0608  |  Val Loss: 0.2905\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 216/1000] Train Loss: 0.0602  |  Val Loss: 0.2905\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 217/1000] Train Loss: 0.0596  |  Val Loss: 0.2909\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 218/1000] Train Loss: 0.0590  |  Val Loss: 0.2910\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 219/1000] Train Loss: 0.0586  |  Val Loss: 0.2908\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 220/1000] Train Loss: 0.0580  |  Val Loss: 0.2915\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 221/1000] Train Loss: 0.0574  |  Val Loss: 0.2911\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 222/1000] Train Loss: 0.0569  |  Val Loss: 0.2891\n",
      "Validation loss improved from 0.2897 to 0.2891.\n",
      "[Epoch 223/1000] Train Loss: 0.0563  |  Val Loss: 0.2888\n",
      "Validation loss improved from 0.2891 to 0.2888.\n",
      "[Epoch 224/1000] Train Loss: 0.0558  |  Val Loss: 0.2888\n",
      "Validation loss improved from 0.2888 to 0.2888.\n",
      "[Epoch 225/1000] Train Loss: 0.0552  |  Val Loss: 0.2891\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 226/1000] Train Loss: 0.0547  |  Val Loss: 0.2893\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 227/1000] Train Loss: 0.0543  |  Val Loss: 0.2895\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 228/1000] Train Loss: 0.0538  |  Val Loss: 0.2893\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 229/1000] Train Loss: 0.0533  |  Val Loss: 0.2883\n",
      "Validation loss improved from 0.2888 to 0.2883.\n",
      "[Epoch 230/1000] Train Loss: 0.0528  |  Val Loss: 0.2873\n",
      "Validation loss improved from 0.2883 to 0.2873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 231/1000] Train Loss: 0.0523  |  Val Loss: 0.2872\n",
      "Validation loss improved from 0.2873 to 0.2872.\n",
      "[Epoch 232/1000] Train Loss: 0.0519  |  Val Loss: 0.2872\n",
      "Validation loss improved from 0.2872 to 0.2872.\n",
      "[Epoch 233/1000] Train Loss: 0.0514  |  Val Loss: 0.2873\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 234/1000] Train Loss: 0.0509  |  Val Loss: 0.2868\n",
      "Validation loss improved from 0.2872 to 0.2868.\n",
      "[Epoch 235/1000] Train Loss: 0.0505  |  Val Loss: 0.2867\n",
      "Validation loss improved from 0.2868 to 0.2867.\n",
      "[Epoch 236/1000] Train Loss: 0.0501  |  Val Loss: 0.2868\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 237/1000] Train Loss: 0.0496  |  Val Loss: 0.2878\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 238/1000] Train Loss: 0.0493  |  Val Loss: 0.2886\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 239/1000] Train Loss: 0.0489  |  Val Loss: 0.2884\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 240/1000] Train Loss: 0.0484  |  Val Loss: 0.2874\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 241/1000] Train Loss: 0.0480  |  Val Loss: 0.2871\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 242/1000] Train Loss: 0.0476  |  Val Loss: 0.2869\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 243/1000] Train Loss: 0.0472  |  Val Loss: 0.2877\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 244/1000] Train Loss: 0.0468  |  Val Loss: 0.2895\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 245/1000] Train Loss: 0.0464  |  Val Loss: 0.2901\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 246/1000] Train Loss: 0.0461  |  Val Loss: 0.2898\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 247/1000] Train Loss: 0.0456  |  Val Loss: 0.2892\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 248/1000] Train Loss: 0.0453  |  Val Loss: 0.2880\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 249/1000] Train Loss: 0.0449  |  Val Loss: 0.2880\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 250/1000] Train Loss: 0.0446  |  Val Loss: 0.2878\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 251/1000] Train Loss: 0.0442  |  Val Loss: 0.2878\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 252/1000] Train Loss: 0.0438  |  Val Loss: 0.2879\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 253/1000] Train Loss: 0.0436  |  Val Loss: 0.2884\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 254/1000] Train Loss: 0.0431  |  Val Loss: 0.2883\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 255/1000] Train Loss: 0.0428  |  Val Loss: 0.2891\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 256/1000] Train Loss: 0.0424  |  Val Loss: 0.2890\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 257/1000] Train Loss: 0.0421  |  Val Loss: 0.2882\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 258/1000] Train Loss: 0.0418  |  Val Loss: 0.2870\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 259/1000] Train Loss: 0.0415  |  Val Loss: 0.2863\n",
      "Validation loss improved from 0.2867 to 0.2863.\n",
      "[Epoch 260/1000] Train Loss: 0.0411  |  Val Loss: 0.2865\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 261/1000] Train Loss: 0.0408  |  Val Loss: 0.2868\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 262/1000] Train Loss: 0.0405  |  Val Loss: 0.2871\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 263/1000] Train Loss: 0.0402  |  Val Loss: 0.2878\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 264/1000] Train Loss: 0.0399  |  Val Loss: 0.2884\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 265/1000] Train Loss: 0.0396  |  Val Loss: 0.2888\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 266/1000] Train Loss: 0.0393  |  Val Loss: 0.2893\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 267/1000] Train Loss: 0.0390  |  Val Loss: 0.2890\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 268/1000] Train Loss: 0.0386  |  Val Loss: 0.2905\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 269/1000] Train Loss: 0.0384  |  Val Loss: 0.2910\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 270/1000] Train Loss: 0.0381  |  Val Loss: 0.2918\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 271/1000] Train Loss: 0.0378  |  Val Loss: 0.2915\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 272/1000] Train Loss: 0.0375  |  Val Loss: 0.2917\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 273/1000] Train Loss: 0.0372  |  Val Loss: 0.2913\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 274/1000] Train Loss: 0.0370  |  Val Loss: 0.2917\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 275/1000] Train Loss: 0.0366  |  Val Loss: 0.2902\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 276/1000] Train Loss: 0.0363  |  Val Loss: 0.2883\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 277/1000] Train Loss: 0.0362  |  Val Loss: 0.2871\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 278/1000] Train Loss: 0.0359  |  Val Loss: 0.2879\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 279/1000] Train Loss: 0.0356  |  Val Loss: 0.2882\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 280/1000] Train Loss: 0.0353  |  Val Loss: 0.2899\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 281/1000] Train Loss: 0.0350  |  Val Loss: 0.2913\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 282/1000] Train Loss: 0.0347  |  Val Loss: 0.2922\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 283/1000] Train Loss: 0.0345  |  Val Loss: 0.2930\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 284/1000] Train Loss: 0.0343  |  Val Loss: 0.2937\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 285/1000] Train Loss: 0.0340  |  Val Loss: 0.2959\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 286/1000] Train Loss: 0.0338  |  Val Loss: 0.2971\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 287/1000] Train Loss: 0.0336  |  Val Loss: 0.2975\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 288/1000] Train Loss: 0.0333  |  Val Loss: 0.2967\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 289/1000] Train Loss: 0.0330  |  Val Loss: 0.2959\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 290/1000] Train Loss: 0.0329  |  Val Loss: 0.2947\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 291/1000] Train Loss: 0.0325  |  Val Loss: 0.2958\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 292/1000] Train Loss: 0.0322  |  Val Loss: 0.2968\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 293/1000] Train Loss: 0.0320  |  Val Loss: 0.2969\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 294/1000] Train Loss: 0.0318  |  Val Loss: 0.2971\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 295/1000] Train Loss: 0.0316  |  Val Loss: 0.2961\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 296/1000] Train Loss: 0.0313  |  Val Loss: 0.2954\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 297/1000] Train Loss: 0.0310  |  Val Loss: 0.2950\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 298/1000] Train Loss: 0.0309  |  Val Loss: 0.2941\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 299/1000] Train Loss: 0.0306  |  Val Loss: 0.2959\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 300/1000] Train Loss: 0.0304  |  Val Loss: 0.2973\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 301/1000] Train Loss: 0.0302  |  Val Loss: 0.2982\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 302/1000] Train Loss: 0.0300  |  Val Loss: 0.2986\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 303/1000] Train Loss: 0.0297  |  Val Loss: 0.2987\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 304/1000] Train Loss: 0.0295  |  Val Loss: 0.2984\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 305/1000] Train Loss: 0.0294  |  Val Loss: 0.2971\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 306/1000] Train Loss: 0.0291  |  Val Loss: 0.2987\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 307/1000] Train Loss: 0.0288  |  Val Loss: 0.2990\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 308/1000] Train Loss: 0.0286  |  Val Loss: 0.2986\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 309/1000] Train Loss: 0.0284  |  Val Loss: 0.2985\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 310/1000] Train Loss: 0.0282  |  Val Loss: 0.2970\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 311/1000] Train Loss: 0.0280  |  Val Loss: 0.2965\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 312/1000] Train Loss: 0.0278  |  Val Loss: 0.2957\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 313/1000] Train Loss: 0.0277  |  Val Loss: 0.2958\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 314/1000] Train Loss: 0.0275  |  Val Loss: 0.2954\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 315/1000] Train Loss: 0.0273  |  Val Loss: 0.2961\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 316/1000] Train Loss: 0.0271  |  Val Loss: 0.2963\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 317/1000] Train Loss: 0.0269  |  Val Loss: 0.2965\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 318/1000] Train Loss: 0.0268  |  Val Loss: 0.2967\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 319/1000] Train Loss: 0.0265  |  Val Loss: 0.2982\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 320/1000] Train Loss: 0.0263  |  Val Loss: 0.2987\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 321/1000] Train Loss: 0.0262  |  Val Loss: 0.2996\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 322/1000] Train Loss: 0.0259  |  Val Loss: 0.3003\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 323/1000] Train Loss: 0.0258  |  Val Loss: 0.3003\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 324/1000] Train Loss: 0.0256  |  Val Loss: 0.3025\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 325/1000] Train Loss: 0.0255  |  Val Loss: 0.3040\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 326/1000] Train Loss: 0.0253  |  Val Loss: 0.3039\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 327/1000] Train Loss: 0.0251  |  Val Loss: 0.3031\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 328/1000] Train Loss: 0.0249  |  Val Loss: 0.3021\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 329/1000] Train Loss: 0.0247  |  Val Loss: 0.3015\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 330/1000] Train Loss: 0.0245  |  Val Loss: 0.3022\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 331/1000] Train Loss: 0.0244  |  Val Loss: 0.3023\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 332/1000] Train Loss: 0.0242  |  Val Loss: 0.3031\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 333/1000] Train Loss: 0.0240  |  Val Loss: 0.3029\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 334/1000] Train Loss: 0.0238  |  Val Loss: 0.3034\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 335/1000] Train Loss: 0.0237  |  Val Loss: 0.3032\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 336/1000] Train Loss: 0.0235  |  Val Loss: 0.3028\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 337/1000] Train Loss: 0.0234  |  Val Loss: 0.3022\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 338/1000] Train Loss: 0.0232  |  Val Loss: 0.3018\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 339/1000] Train Loss: 0.0230  |  Val Loss: 0.3017\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 340/1000] Train Loss: 0.0229  |  Val Loss: 0.3017\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 341/1000] Train Loss: 0.0227  |  Val Loss: 0.3024\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 342/1000] Train Loss: 0.0226  |  Val Loss: 0.3028\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 343/1000] Train Loss: 0.0224  |  Val Loss: 0.3028\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 344/1000] Train Loss: 0.0223  |  Val Loss: 0.3029\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 345/1000] Train Loss: 0.0221  |  Val Loss: 0.3032\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 346/1000] Train Loss: 0.0220  |  Val Loss: 0.3039\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 347/1000] Train Loss: 0.0219  |  Val Loss: 0.3042\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 348/1000] Train Loss: 0.0217  |  Val Loss: 0.3064\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 349/1000] Train Loss: 0.0216  |  Val Loss: 0.3076\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 350/1000] Train Loss: 0.0214  |  Val Loss: 0.3078\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 351/1000] Train Loss: 0.0213  |  Val Loss: 0.3084\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 352/1000] Train Loss: 0.0211  |  Val Loss: 0.3084\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 353/1000] Train Loss: 0.0210  |  Val Loss: 0.3080\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 354/1000] Train Loss: 0.0208  |  Val Loss: 0.3075\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 355/1000] Train Loss: 0.0207  |  Val Loss: 0.3062\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 356/1000] Train Loss: 0.0206  |  Val Loss: 0.3058\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 357/1000] Train Loss: 0.0204  |  Val Loss: 0.3058\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 358/1000] Train Loss: 0.0202  |  Val Loss: 0.3063\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 359/1000] Train Loss: 0.0201  |  Val Loss: 0.3064\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 359 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_input_dim = sclsdl_mlp_train_reps.shape[1]\n",
    "sclsdl_mlp_num_classes = len(torch.unique(sclsdl_mlp_train_labels_torch))\n",
    "sclsdl_mlp_model = MLPClassifier(sclsdl_mlp_input_dim, sclsdl_mlp_num_classes).to(device)\n",
    "\n",
    "sclsdl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "sclsdl_mlp_optimizer = optim.Adam(sclsdl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "sclsdl_mlp_num_epochs = 1000\n",
    "sclsdl_mlp_patience = 100\n",
    "\n",
    "sclsdl_mlp_train_losses = []\n",
    "sclsdl_mlp_val_losses = []\n",
    "\n",
    "sclsdl_mlp_best_val_loss = float('inf')\n",
    "sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for sclsdl_mlp_epoch in range(sclsdl_mlp_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_mlp_model.train()\n",
    "    sclsdl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for sclsdl_mlp_embeddings_batch, sclsdl_mlp_labels_batch in sclsdl_mlp_train_loader:\n",
    "        sclsdl_mlp_embeddings_batch = sclsdl_mlp_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_labels_batch = sclsdl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        sclsdl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        sclsdl_mlp_outputs = sclsdl_mlp_model(sclsdl_mlp_embeddings_batch)\n",
    "        sclsdl_mlp_loss = sclsdl_mlp_criterion(sclsdl_mlp_outputs, sclsdl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        sclsdl_mlp_loss.backward()\n",
    "        sclsdl_mlp_optimizer.step()\n",
    "        \n",
    "        sclsdl_mlp_train_running_loss += sclsdl_mlp_loss.item() * sclsdl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    sclsdl_mlp_epoch_train_loss = sclsdl_mlp_train_running_loss / len(sclsdl_mlp_train_loader.dataset)\n",
    "    sclsdl_mlp_train_losses.append(sclsdl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_mlp_model.eval()\n",
    "    sclsdl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sclsdl_mlp_val_embeddings_batch, sclsdl_mlp_val_labels_batch in sclsdl_mlp_val_loader:\n",
    "            sclsdl_mlp_val_embeddings_batch = sclsdl_mlp_val_embeddings_batch.to(device)\n",
    "            sclsdl_mlp_val_labels_batch = sclsdl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            sclsdl_mlp_val_outputs = sclsdl_mlp_model(sclsdl_mlp_val_embeddings_batch)\n",
    "            sclsdl_mlp_val_loss = sclsdl_mlp_criterion(sclsdl_mlp_val_outputs, sclsdl_mlp_val_labels_batch)\n",
    "\n",
    "            sclsdl_mlp_val_running_loss += sclsdl_mlp_val_loss.item() * sclsdl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    sclsdl_mlp_epoch_val_loss = sclsdl_mlp_val_running_loss / len(sclsdl_mlp_val_loader.dataset)\n",
    "    sclsdl_mlp_val_losses.append(sclsdl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {sclsdl_mlp_epoch+1}/{sclsdl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {sclsdl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {sclsdl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if sclsdl_mlp_epoch_val_loss < sclsdl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_mlp_best_val_loss:.4f} to {sclsdl_mlp_epoch_val_loss:.4f}.\")\n",
    "        sclsdl_mlp_best_val_loss = sclsdl_mlp_epoch_val_loss\n",
    "        sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "\n",
    "    else:\n",
    "        sclsdl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {sclsdl_mlp_epochs_without_improvement}/{sclsdl_mlp_patience}\")\n",
    "        \n",
    "        if sclsdl_mlp_epochs_without_improvement >= sclsdl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {sclsdl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {sclsdl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(sclsdl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(sclsdl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:26:48.881219Z",
     "iopub.status.busy": "2025-05-08T19:26:48.881219Z",
     "iopub.status.idle": "2025-05-08T19:26:49.031201Z",
     "shell.execute_reply": "2025-05-08T19:26:49.031201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SCL_SDL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.3588 | Test Accuracy: 88.58%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_model.eval()\n",
    "\n",
    "sclsdl_mlp_test_running_loss = 0.0\n",
    "sclsdl_mlp_test_correct = 0\n",
    "sclsdl_mlp_all_predictions = []\n",
    "sclsdl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_mlp_test_embeddings_batch, sclsdl_mlp_test_labels_batch in sclsdl_mlp_test_loader:\n",
    "        sclsdl_mlp_test_embeddings_batch = sclsdl_mlp_test_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_test_labels_batch = sclsdl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_mlp_test_outputs = sclsdl_mlp_model(sclsdl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        sclsdl_mlp_test_loss_batch = sclsdl_mlp_criterion(sclsdl_mlp_test_outputs, sclsdl_mlp_test_labels_batch)\n",
    "        sclsdl_mlp_test_running_loss += sclsdl_mlp_test_loss_batch.item() * sclsdl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, sclsdl_mlp_test_predicted = torch.max(sclsdl_mlp_test_outputs, dim=1)\n",
    "        sclsdl_mlp_test_correct += (sclsdl_mlp_test_predicted == sclsdl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        sclsdl_mlp_all_predictions.extend(sclsdl_mlp_test_predicted.cpu().numpy())\n",
    "        sclsdl_mlp_all_true_labels.extend(sclsdl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_predictions.npy'), np.array(sclsdl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_true_labels.npy'), np.array(sclsdl_mlp_all_true_labels))\n",
    "print(f\"Saved SCL_SDL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "sclsdl_mlp_epoch_test_loss = sclsdl_mlp_test_running_loss / len(sclsdl_mlp_test_loader.dataset)\n",
    "sclsdl_mlp_test_accuracy = sclsdl_mlp_test_correct / len(sclsdl_mlp_test_loader.dataset)\n",
    "\n",
    "sclsdl_mlp_test_accuracy_pct = sclsdl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {sclsdl_mlp_epoch_test_loss:.4f} | Test Accuracy: {sclsdl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "sclsdl_mlp_num_epochs_run = len(sclsdl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         [sclsdl_mlp_epoch_test_loss]*sclsdl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Results and Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:26:49.033510Z",
     "iopub.status.busy": "2025-05-08T19:26:49.033510Z",
     "iopub.status.idle": "2025-05-08T19:26:49.038380Z",
     "shell.execute_reply": "2025-05-08T19:26:49.038380Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_conf_matrix(model_name, class_names = None, cm_save_dir='confusion_matrices'):\n",
    "    os.makedirs(cm_save_dir, exist_ok = True)\n",
    "\n",
    "    #loading predictions and true labels\n",
    "    predictions_path = os.path.join(predictions_dir, f'{model_name}_predictions.npy')\n",
    "    true_labels_path = os.path.join(predictions_dir, f'{model_name}_true_labels.npy')\n",
    "\n",
    "    if not os.path.exists(predictions_path) or not os.path.exists(true_labels_path):\n",
    "        print(f\"Error: Files not found for model {model_name}\")\n",
    "        return\n",
    "    \n",
    "    cm_predictions = np.load(predictions_path)\n",
    "    cm_true_labels = np.load(true_labels_path)\n",
    "\n",
    "    conf_matrix = confusion_matrix(cm_true_labels, cm_predictions)\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    conf_matrix_normalised = conf_matrix.astype('float') / conf_matrix.sum(axis = 1)[:, np.newaxis]\n",
    "    sns.heatmap(conf_matrix_normalised, annot=conf_matrix, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "    plt.title(f\"{model_name.upper()} Confusion Matrix\", fontsize=16)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    cm_save_path = os.path.join(cm_save_dir, f'{model_name}_confusion_matrix.png')\n",
    "    plt.savefig(cm_save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved confusion matrix to: {cm_save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "    print(f\"Classification Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:26:49.041386Z",
     "iopub.status.busy": "2025-05-08T19:26:49.041386Z",
     "iopub.status.idle": "2025-05-08T19:26:53.926797Z",
     "shell.execute_reply": "2025-05-08T19:26:53.926797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving confusion matrices to: confusion_matrices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\e2e_cnn_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAMWCAYAAABIgshOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACzX0lEQVR4nOzdd3gUVcOG8XsTSOgQgjSlSZNeQpFeBBQEQZSiUkSkI1WEiNIsoUhTmoCIFJFiV0RAAQVE6SqgolQhlJAQegLJfn/wsa9L6sJmZw48v/fa63qZnZ29M4t6cnJm4nA6nU5ERERERMR2/KwOEBERERGRxGmwLiIiIiJiUxqsi4iIiIjYlAbrIiIiIiI2pcG6iIiIiIhNabAuIiIiImJTGqyLiIiIiNiUBusiIiIiIjalwbqIiIiIiE1psC4iYoH169fToEEDsmXLhsPhwOFwcOjQIZ+9/6hRo3A4HIwaNcpn73k3q1+/Pg6Hg/Xr11udIiKG0WBdJBGFCxd2DaCSe8yfP9/1GqfTycaNGxkyZAgPPvggOXLkICAggPz58/PEE0+wbt26JN/vxn/IU3p4a2D122+/0b9/f8qXL09QUBABAQHkyZOHxo0bM3nyZM6cOeO2//r1610N+fLl4/Lly4ke999//3Xtl9zXOGXKlCTbnn/++dv6WuPj4/noo49o06YNhQoVIlOmTGTOnJnixYvToUMHvvrqK5xO5y0d21v27NnDww8/zPr168mVKxe1atWiVq1aZMiQwdIuu7nxDYXD4SBPnjxcu3YtyX3PnDlDQEBAov9s3o758+czatQon34jJSLyX+msDhCxs+LFi5M7d+4kn8+TJ4/r/3///fc0atQIAD8/P4oVK0bmzJnZv38/n3zyCZ988gmvvPIKr732WpLHK1CgAAULFkzy+eSeS424uDgGDhzI9OnTiY+PJ126dBQrVoysWbNy8uRJ1q5dy9q1axk9ejQrVqxwfT3/deLECWbOnMmgQYNuuWPs2LF0796dTJky3c6Xk8A///xD69at+fXXXwEICgqiZMmSOJ1ODh8+zOLFi1m8eDEhISFs3LjRssHxe++9R2xsLC+88AJvv/22JQ25cuWiZMmS5MqVy5L399SpU6dYvXo1zZo1S/T5jz76iKtXr3r9fefPn8+GDRuoX78+hQsXvuXjFCxYkJIlS3r977yI3AWcIpJAoUKFnIDz/fffT/Vr1qxZ4yxWrJhzxowZzsjISNf2mJgYZ2hoqBNwAs4vv/wywWvr1avnBJwjR470Qn3S2rZt6wScWbNmdU6dOtUZHR3t9vzBgwedw4YNc2bKlMk5efJk1/Z169Y5Aae/v78TcObOndt58eLFBMc/evSo6+u82Y2v8cYxJkyYkGhj165db+lcHDp0yHnPPfc4AWeVKlWc69atc8bFxbmev3btmnPdunXOxo0bOwFnVFSUR8f3pqZNmzoB58qVKy1rMMHIkSOdgLNkyZJOwNm+ffsk961evbrT4XA4ixcv7vE/u8m58fd23bp1XjmeiIintAxGxEuqVavGvn376NWrF0FBQa7tAQEBvPnmmzRt2hSAOXPmWNI3d+5cli1bRsaMGVm3bh39+vUjW7ZsbvsULlyYsLAwtm7dSrFixRIco3DhwtSoUYNTp04xffr0W+p46qmnABg/fjwXL168pWMk5plnnuH06dPUq1ePH374gfr16+Pn979/xfn7+1O/fn1Wr17N9OnT8ff399p7e+rGMqKMGTNa1mCSWrVqUbhwYT7//HPOnz+f4Pm///6bn3/+mXr16t32T59EROxGg3URL8mWLRvp0iW9sqxx48YA/PXXX75KcomLi+ONN94AYMSIEYSEhCS7f+nSpWnevHmiz40ePRq4Pti+cOGCxy0PP/wwNWvW5PTp00ybNs3j1yfm+++/Z9OmTaRPn54FCxakOAju3bs3WbNmddt29epV3nnnHapVq0a2bNnInDkzFSpU4I033uDSpUsJjnHo0CEcDodracSiRYuoUqUKmTJlImfOnLRp04YDBw64vebZZ591u8iwQYMGrjXWzz77LHB92cV//3yzG9cP1K9fP8FzGzdu5PHHHydv3rykT5+enDlzUqpUKZ5//nm2bNnitm9KF5hu3ryZ1q1bkydPHgICArjvvvvo1KkT+/btS3T//15A+ccff9CmTRty5cpFxowZCQkJYdmyZYm+LjUcDgfPPPMMly9f5uOPP07w/MKFCwHo0KFDkse4fPkyS5YsoX379pQsWZIsWbKQJUsWKlasyOuvv57gG8cb53nDhg2A+2f13zXxN/89mDNnDlWrViVr1qxu124kdoHpjz/+iL+/P5kzZ+bPP/9M0Lx3714yZsyIv78/P/74Y6rOlYjceTRYF/GRK1euANbMpv78888cOnSIdOnS0b1799s6VuPGjalduzYRERG88847t3SMGwP+CRMm3NKA/2YfffQRAM2bN7+lmdXLly/zyCOP0K9fP7Zu3cp9991HsWLF+P3333nllVeoVatWgotu/ys0NJSOHTsSERFBiRIluHTpEitWrHCdpxtKlChBrVq1XD/RKFu2rOvi0hIlSnjc/V+ff/459erV47PPPuPatWuUL1+ePHnycPToUd577z3XOUqNmTNnUrt2bT799FMAKlSowMWLF1m4cCGVK1fm66+/TvK127dvp2rVqnz77bcULlyYrFmzsmPHDtq1a8eiRYtu+evr2LEjQKLHWLx4MRkyZODJJ59Mtuvpp5/m448/5tKlS5QqVYr8+fOzZ88eXn31VerWret24XT27NmT/Kxq1arldr3KDb169aJ79+6cPHmSBx54gBw5ciT7NdWpU4fBgwdz6dIlOnTo4HYB7dWrV+nYsSNXrlxhyJAh1KlTJ9ljicgdzOp1OCJ2dCtr1pMTHx/vrFSpkhNw9u3bN8Hzab1mfcKECU7AWbFixVt6/Y0160WLFnU6nU7nd9995wScOXPmdJ47d861X2rWrC9cuNDpdDqddevWdQLON954w22/W1mzXqZMGSfgnDJlyi18dU7n4MGDnYAzf/78zu3bt7u279+/3/nAAw84AWfbtm3dXnPw4EEn4EyXLp0zW7ZsbuvPw8PDneXLl3cCzqFDhyZ4v+TWQb///vtOwNm5c+dEW298FvXq1XPbXrZsWSfgnDFjhvPatWuu7fHx8c5169Y5v/jiC7f9b6wHv/k879y505kuXTon4Bw/frxr3f+VK1ecvXv3dgLO7NmzO48fP57o15Q+fXpn3759nZcvX3a9/9ChQ13n979tKbnR2LVrV6fT6XRWrVrV6efn5/z3339d+2zatMnt83nooYcS/Wf30KFDzmXLljnPnz/vtj08PNz55JNPOgHnqFGjEjSktGb9xt8Df39/Z+bMmZ2ff/6567lLly6leJyYmBjX35VXXnnFtf3GdS4VKlRwxsTEJH2SROSOp5l1kWR06dIl2Vspnj17NlXHmTNnDjt37iQgIIABAwYkud/o0aOTfb9du3bd0tdx7NgxAIoUKXJLr79Zw4YNqVevHpGRkUydOvWWjnFjdn3ixImcO3futnpu5+s7d+4cM2fOBGD69OlUrlzZ9VyxYsVYsGABAMuXL+eff/5J8Ppr164xcuRI1zUJAHnz5uX1118H4JtvvvG46Vbs37+foKAgevXq5bYe/8aSmRYtWqTqOG+99RbXrl2jZcuWDBkyxLXuPzAwkGnTplGmTBmio6Nd5+xmpUuXZurUqa477TgcDl577TXy5s3L8ePHXXfquRUdOnQgPj6exYsXu7alZgkMQKFChWjTpg1ZsmRx2543b14WLFhAQECA23E9FRcXx5gxY3jsscdc21LzU7SAgAAWLVpEYGAgYWFh/PTTT2zevJnx48eTIUMGFi9eTEBAwC13iYj5NFgXSUbx4sXdfvR98yO5Neo37Nixg/79+wPw+uuvU7Ro0ST3LVCgQLLvd/NAI7VuXJSXOXPmW3p9Ym4MtidNmkR0dLTHr69fvz7169cnMjIy2fuup8btfH0bN27k0qVLFCxYkJYtWyZ4vmrVqtSoUQOn08maNWsSPUbXrl0TfR2QYN16WilQoABnz55NsjG1Vq9eDcALL7yQ4DmHw0G/fv3c9rvZc88953ZhL0D69OmpUKECcHvn46mnniJdunSupTCxsbEsW7aMXLly8cgjj6T4+vj4eD7//HP69OlD06ZNqVOnDrVr16Zx48Y4HA7279+f6PUJqdWpU6dbel25cuV4/fXXiYuLo2PHjnTs2JG4uDjefPNNypQpc8s9InJn0H3WRZLx8ssvJ3mhX2ocPHiQ5s2bc+XKFZ5++mlefPHFZPd/7rnn0uQ3St64mNKbd1+pV68eDRs25Pvvv2fKlCmMHDnS42OMGTOGunXrMnnyZPr165fiGt+kZM2albNnz97S13fjgt8HHngg0V/mBFCmTBl++umnRC8OzpUrF9mzZ0+w/cb9+b2xJj81Bg4cSJ8+fWjSpAkhISE0atSI2rVrU69evQQX0ybl7NmznD59Grg+Q56YG4PHpC6UTuqbUW+cj3vuuYcmTZqwcuVKdu/ezcGDB4mMjKRPnz6kT58+2deePXuWZs2a8dNPPyW7X1RU1C3dCz1Xrly3dc/6QYMG8fXXX7suQG3YsGGyP4UTkbuHZtZF0siJEydo3Lgx4eHhPProo667fFjh3nvvBa5/8+BNY8aMAWDy5MmpXhL0X3Xq1KFRo0acPXuWyZMn33LH7Xx9NwaPqfnlV4ndNjCp2fybZ5fTWu/evVmwYAEVKlRg+/btjBs3jhYtWpA7d266d++eqp9+/HcgndT5SO5cQMrnw3mbvz32vxea3phhv7EtOYMGDeKnn36iZMmSfPzxxxw7doyYmBicTidOp9P1d+hWf7HS7f7Uys/Pj3r16rn+fOPOQSIiGqyLpIHIyEgaN27MP//8Q7169Vi+fHmKM39pqWbNmgD8/vvvREZGeu24tWrVonHjxkRHRzNx4sRbOsaN5TRTpkwhKirqlo5x4+u7cZs9T9xYWnTq1Kkk9zl58iRAqmeob8eNAVpSg9rkfnrQsWNHdu3aRXh4OB999BFdu3YlXbp0zJkzJ8U13YDbMqukzocvz0ViWrZsSbZs2Vi4cCFfffUVxYsXp3r16sm+5tq1a65bR37++ee0bt2a/Pnzu9aCX7t2jRMnTqR5e3J27dpFWFiY65ual156ye1OQiJy99JgXcTLLly4QLNmzfj999+pWrUqX375peW//KZ69eoULlyYa9euMXv2bK8e+8bs+tSpU2/pG4GaNWvy8MMPc+7cuVse8Ldr1w6Ar776iiNHjnj02hu3TNy3b1+SA+Q9e/a47ZuWbszQ3liOcrO///47xWPkzZuXdu3aMXfuXH7++Wf8/Pz46quvCA8PT/Z1OXLk4J577gGu3+M7Mb48F4nJmDEjrVu35uTJk8TExKTqm5DTp09z8eJFcubMScmSJRM8//vvvxMXF5foa30xu33lyhU6dOhAbGwsY8aM4cknn+TEiRP07Nkzzd9bROxPg3URL4qJiaFly5b8/PPPlClThlWrVlk2A/lf/v7+hIaGAvDaa6+xY8eOZPfft28fX331VaqO/eCDD9K0aVPOnz/PW2+9dUt9Nwb8b7/9drL3M0/KQw89RI0aNbh69SqdO3d23dM+KbNmzXIt46hduzaZMmXi6NGjfP755wn23bZtGz/99BMOh8P1i63S0v333w9cn2n973234foFku+//75HxytdurRrTf3x48dT3P/hhx8GSPQe+k6n07X9xn5W6N69Ow899BAPPfRQqpbA3Phm+dy5c273Ur9h/PjxKb42sdd5y8svv8yePXt48MEHGTZsGLNmzSJv3rx8/PHHrrsRicjdS4N1ES+Ji4ujffv2fP/99xQtWpQ1a9aQM2dOq7NcunfvzhNPPMGlS5do0KAB77zzToJ1x0ePHuWVV16hSpUqqZrBveHGUpYPP/zwltqqVatGs2bNOH/+PF9++eUtHWPx4sUEBwezfv166tSpw/r164mPj3c9Hx8fz8aNG3nkkUfo1auXayY1W7Zs9OrVC4C+ffuyc+dO12v++ecfOnfuDEDbtm2TvZOPt1SoUIH8+fMTHh7OyJEjXbP9V65cYcCAAYnOeJ87d4727dsn+Jrj4uJ4++23iYqKInPmzInOKt9s8ODBpEuXjs8//5yJEye6jhcbG0v//v35/fffyZ49u+ucWaFGjRqsXbuWtWvXpup2nTly5KBMmTJcu3aNgQMHEhsbC1w/P+PGjWPp0qVJ3h7xxjdPt7LEKjXWrVvHlClTyJQpEwsWLMDf35/g4GDmzZsHXL8rj6c/LRKRO4vuBiOSjDfffJO5c+cm+Xzbtm1dt7JbtmwZn332GXD9YrE2bdok+pp8+fKxfPnyRJ+bN28ea9euTfL96taty5tvvpnK+oQ++ugj+vfvz8yZM+nXrx+DBw+mWLFiZM2alVOnTnHo0CEAcubMSfny5VN93KpVq9K8efNUz8YnZsyYMaxcuTLJ5QgpKVKkCD/99BOtW7dm27ZtNGjQgJw5c1KoUCGcTieHDx92rYmvXr2629KkGz9tWLduHZUrV6Z06dKkT5/etTyiQoUKTJ8+/Za/Nk/4+/szbtw4OnbsyJtvvsmcOXMoVKgQf/31F/Hx8YSFhSW4q1B8fDxLly5l6dKlZM6cmWLFipE+fXoOHTpEREQEDoeDKVOmpOrWnxUrVuTtt9+mT58+vPjii0yYMIGCBQuyf/9+zp49S2BgIIsXLyZv3rxpdQrSRFhYGC1btuTdd99l+fLl3H///a7z8+qrr7JgwQIOHz6c4HXt2rVj+vTpjBs3jk8//ZS8efPicDgYNmxYqm4XmZzo6GieffZZnE4nEydOpHjx4q7nmjZtSs+ePZk1axadO3fm+++/1wWnIncpDdZFkrF//37279+f5PNVqlRx/f+YmJhUva5QoUJJHu/o0aMcPXo0yedv59ZwAOnSpWP69On06NGDOXPmsG7dOv79918uXbpEUFAQDz30EI899hidOnXy+DaKo0ePvq3BekhICI899hhffPHFLR+jePHi7Nq1i6VLl/Lxxx+zdetW9u3bh8PhIH/+/DRr1owOHTrw8MMPuw18MmbMyLfffsvMmTNZuHAh+/btIz4+ntKlS9OuXTsGDhx4S7fzu1UdOnQgMDCQcePGsWfPHg4cOMBDDz3E66+/nuiFn1mzZmXhwoWsXr2arVu3cujQIWJjYylQoACPPPIIL774ous+56nRq1cvypcvz1tvvcWmTZvYtWsX99xzD82bNyc0NDTJ2zraWYsWLfjmm28YM2YMO3fu5M8//6RMmTJMmTKFZ555JsnlJnXq1OHDDz9kypQp7Nmzx3XLytu5pesNffv25ciRIzzyyCOJrk+fOHEi3333HevXr2fSpEkMHjz4tt9TRMzjcN7ufbRERERERCRNaM26iIiIiIhNabAuIiIiImJTWrMuYpgTJ07w5JNPpnr/4cOH07Rp0zQsEhERkbSiwbqIYa5cucKmTZtSvf+N3zgpIiIit+6HH35gwoQJbN++nfDwcD799FNatWqV7Gs2bNjAoEGD2LNnD/nz5+ell17y+BeeaRmMiGEKFy6M0+lM9cMbd60QERG52128eJEKFSowbdq0VO1/8OBBmjVrRp06ddi5cycvv/wy/fr14+OPP/bofXU3GBERERERDzgcjhRn1ocOHcoXX3zBvn37XNt69uzJ7t27+emnn1L9XppZFxEREZG7UkxMDOfOnXN7/Pf3ptyOn376iSZNmrhte/jhh9m2bRtXr15N9XHu2DXrGSv1tTohVaK2pu5HKSIiIiK3IoPNRnt2GqMNbZmL0aNHu20bOXIko0aNuu1jnzhxgjx58rhty5MnD9euXSMiIoJ8+fKl6jg2+/hERERERHwjNDSUQYMGuW0LDAz02vH/+9uyAW6sPr95e3I0WBcRERGRu1JgYKBXB+f/lTdvXk6cOOG27dSpU6RLl47g4OBUH0eDdRERERHxHcfdcclkjRo1+PLLL922rV69mipVqpA+ffpUH+fuOFsiIiIiIrfhwoUL7Nq1i127dgHXb824a9cujhw5AlxfUtOpUyfX/j179uTw4cMMGjSIffv2MW/ePN577z1efPFFj95XM+siIiIiIinYtm0bDRo0cP35xlr3zp07M3/+fMLDw10Dd4AiRYqwcuVKBg4cyPTp08mfPz9vv/02TzzxhEfve8feZ91OVxonR3eDERERkbRku7vBhPS3OsHl8vapViekSMtgRERERERsSoN1ERERERGbstkPRkRERETkjnaX3A3GW3S2RERERERsSjPrIiIiIuI7Hvz2TtHMuoiIiIiIbWmwLiIiIiJiU1oGIyIiIiK+owtMPaKzJSIiIiJiUxqsi4iIiIjYlJbBiIiIiIjv6G4wHtHMuoiIiIiITd3Vg/UXn2vCxkVDOLXxLQ5/F8aySd0oXih3kvu/M7w9l3dOo+/T9d22fzunP5d3TnN7LBjbJY3rE1q6ZDFNmzSkaqVytG/Tmh3bt/m8ISUmNIIZnSY0ghmdJjSCGZ0mNIIZnSY0ghmdJjSCOZ23zeFnn4cBzKhMI3UqF2PW0h+o1+ktmveahr+/P1/N7EumDAEJ9m1RvzxVyxXm+KmziR7rvY83UbhRqOvR9/UlaVzvbtU3Kxk/Noxu3XuxdMVnVK4cQu8e3Qg/ftynHckxoRHM6DShEczoNKERzOg0oRHM6DShEczoNKERzOkU37urB+st+85g0Zc/s+/ACX776xg9Ri2iYL6cVCpdwG2//PdkZ/KwNnR5eT5Xr8UleqzLV2I5eea863HuwhVffAkuCz94n8efeILWT7bh/qJFeSl0OHnz5WXZUt9+05AcExrBjE4TGsGMThMawYxOExrBjE4TGsGMThMawZxO8b27erB+s2xZMgAQFX3Jtc3hcPDe652Y/MF37DtwIsnXtmtWhaPfj2X7iuGEDXycLJkC07z3hquxsezbu4caNWu7ba9Rsxa7d+30WUdyTGgEMzpNaAQzOk1oBDM6TWgEMzpNaAQzOk1oBHM6vcbhsM/DALobzH+MG/wEm3b8zd5/wl3bBndpzLW4eKYvWZ/k6z5auZVDx89wMuIcZYrlZ8wLLShX4l6a95rmg2qIOhtFXFwcwcHBbtuDg3MREXHaJw0pMaERzOg0oRHM6DShEczoNKERzOg0oRHM6DShEczpFGvYfrB+9OhRRo4cybx585LcJyYmhpiYGLdtzvg4HH7+qX6fycPaUq54fh7qMtm1rVKpAvR5qj41nx6X7Gvf/3Sz6//v/Secv4+cYvOHQ6n4wH3s+uPfVDfcLsdN3yE6nc4E26xmQiOY0WlCI5jRaUIjmNFpQiOY0WlCI5jRaUIjmNMpvmX7ZTCRkZF88MEHye4TFhZG9uzZ3R7XTm5P9XtMGtqG5vXK8XC3tzn2nwtIa1UqSu6cWfhr5RjOb53K+a1TKZQ/mLGDWvPH16OTPN7OfUeJvXqNYgWTvrOMNwXlCMLf35+IiAi37ZGRZwgOzuWThpSY0AhmdJrQCGZ0mtAIZnSa0AhmdJrQCGZ0mtAI5nR6jdV3gNHdYDzzxRdfJPtYt25discIDQ0lOjra7ZEuT0iq3n/y0Da0bFiBR3q8zeHjZ9ye+/DrrVRtG0b19mNdj+OnzjJ5wVpa9J6e5DFLF81HQPp0hEdEp6rhdqUPCKBU6TJs2bzJbfuWzZupULGSTxpSYkIjmNFpQiOY0WlCI5jRaUIjmNFpQiOY0WlCI5jTKdawfBlMq1atcDgcOJ3OJPdJ6UdAgYGBBAa6X9CZmiUwU0Lb0q5pFdoMnM2Fi1fIE5wVgOgLV7gSc5XI6ItERl90e83Va3GcjDjH/sOnAChyXy7aN6vCtxv3EhF1gVJF8zJ2YGt27jvKT7sOpNjgLR07d2H4sJcoXbYsFSpU4uPlSwkPD6dNu/Y+a0iJCY1gRqcJjWBGpwmNYEanCY1gRqcJjWBGpwmNYE6n+J7lg/V8+fIxffp0WrVqlejzu3btIiQkdbPknurRti4Aa+YOcNvebcRCFn35c6qOcfXqNRpUK0mfpxqQJVMA/544y6qNv/PGu98QH5/0NyDe9kjTZkSfjWL2zBmcPn2KYsVLMH3WbPLnv9dnDSkxoRHM6DShEczoNKERzOg0oRHM6DShEczoNKERzOn0Cq3D94jDmdyUtg889thjVKxYkTFjxiT6/O7du6lUqRLx8fEeHTdjpb7eyEtzUVt9c8cYERERuTtlsHxq1l3GWsOtTnC5vOkNqxNSZPnHN2TIEC5evJjk88WKFUvVunURERERMYAhF3baheWD9Tp16iT7fObMmalXr56PakRERERE7EPf2oiIiIiI2JTlM+siIiIichfRBaYe0cy6iIiIiIhNabAuIiIiImJTWgYjIiIiIr6ju8F4RGdLRERERMSmNFgXEREREbEpLYMREREREd/RMhiP6GyJiIiIiNiUZtZFRERExHf8dJ91T2hmXURERETEpjRYFxERERGxKS2DERERERHf0QWmHtHZEhERERGxKQ3WRURERERsSstgRERERMR3HLobjCc0sy4iIiIiYlMarIuIiIiI2NQduwwmaus0qxNSJahqX6sTUmTKuRQRERED6G4wHtHZEhERERGxqTt2Zl1EREREbEgXmHpEM+siIiIiIjalwbqIiIiIiE1pGYyIiIiI+I4uMPWIzpaIiIiIiE1psC4iIiIiYlNaBiMiIiIivqO7wXhEM+siIiIiIjalmXURERER8R1dYOoRnS0REREREZvSYF1ERERExKa0DEZEREREfEcXmHpEM+siIiIiIjalwbqIiIiIiE1pGYyIiIiI+I7uBuMRnS0REREREZvSYF1ERERExKY0WE+FpUsW07RJQ6pWKkf7Nq3ZsX2bpT1/fD2ayzunJXhMHtbWtU/JInlYPqUHJ36YwKmNb7Hhg8EUyBtkYfV1djuXSTGh04RGMKPThEYwo9OERjCj04RGMKPThEYwp/O2ORz2eRhAg/UUrPpmJePHhtGtey+WrviMypVD6N2jG+HHj1vWVLvDBAo3CnU9mvV8B4BP1uwEoMh9ufhu3iD+OniCh7tNpVq7MMLmrOJKzFXLmsGe5zIxJnSa0AhmdJrQCGZ0mtAIZnSa0AhmdJrQCOZ0iu85nE6n0+qItHDlmneO80z7NpQqXZpXRox2bWvVoikNGjai/8DBt338oKp9b/sYE158gqZ1ylK25fXGBWO7cPVqHF1fXXDbxwaI2jrNK8dJ63PpLSZ0mtAIZnSa0AhmdJrQCGZ0mtAIZnSa0Ahp25nBZrcTydjcO+MKb7j81e2Pw9KaZtaTcTU2ln1791CjZm237TVq1mL3rp0WVblLn86f9s2q8sHnPwHgcDh4pHYZ9h85xRfT+3D4uzB+WPAiLeqXt7TThHMJZnSa0AhmdJrQCGZ0mtAIZnSa0AhmdJrQCOZ0ijU0WE9G1Nko4uLiCA4OdtseHJyLiIjTFlW5e6xBeXJkzciiL38GIHfOLGTNnIEXuzRmzea9tOg1jS/W7eajic9TO6SYZZ0mnEswo9OERjCj04RGMKPThEYwo9OERjCj04RGMKdTrGGLH4xcvnyZ7du3kzNnTkqXLu323JUrV1i2bBmdOnVK8vUxMTHExMS4bXP6BxIYGOiVPsdNFyA4nc4E26zSuVVNvt20l/DT0QD4+V3//uur9b/xzuJ1APz61zGqV7ifbk/WZuP2vy1rBXufy/8yodOERjCj04RGMKPThEYwo9OERjCj04RGMKfztuk+6x6x/Gz99ddflCpVirp161KuXDnq169PeHi46/no6Gi6dOmS7DHCwsLInj2722PCuLDbbgvKEYS/vz8RERFu2yMjzxAcnOu2j3+7CuYLomH1ksz/bLNrW0TUBa5ejWPfgXC3ff88cMLSu8HY/VzeYEKnCY1gRqcJjWBGpwmNYEanCY1gRqcJjWBOp1jD8sH60KFDKVeuHKdOneLPP/8kW7Zs1KpViyNHjqT6GKGhoURHR7s9hgwNve229AEBlCpdhi2bN7lt37J5MxUqVrrt49+ujo/V4FTkeb75cY9r29VrcWzfe5gShfK47Vu8UG6OhEf5OtHF7ufyBhM6TWgEMzpNaAQzOk1oBDM6TWgEMzpNaARzOsUali+D2bx5M2vXriVXrlzkypWLL774gj59+lCnTh3WrVtH5syZUzxGYGDCJS/euhtMx85dGD7sJUqXLUuFCpX4ePlSwsPDadOuvXfe4BY5HA46tXyQxV/9TFxcvNtzkz9Yy8Jxz7Fxx99s2PYXTWqWplndsjzcbapFtdfZ9VzezIROExrBjE4TGsGMThMawYxOExrBjE4TGsGcTq+4E5f2pCHLB+uXL18mXTr3jOnTp+Pn50e9evX48MMPLSq77pGmzYg+G8XsmTM4ffoUxYqXYPqs2eTPf6+lXQ2rl6Rgvpx88NmWBM99se5XXnjjI4Y814SJLz3JX4dP8dSQuWzedcCC0v+x67m8mQmdJjSCGZ0mNIIZnSY0ghmdJjSCGZ0mNII5neJ7lt9nvVq1arzwwgt07NgxwXN9+/Zl8eLFnDt3jri4OI+O662Z9bTmjfuspzVv3WddREREfM9291l/bKbVCS6Xv+hldUKKLF+z/vjjj7NkyZJEn5s2bRpPPfUUd+jvbRIRERG5+zj87PMwgOUz62lFM+veo5l1ERERc9luZr3lu1YnuFz+vIfVCSmy2ccnIiIiInc0XWDqETPm/0VERERE7kIarIuIiIiI2JSWwYiIiIiI7xhyYadd6GyJiIiIiNiUBusiIiIiIjalZTAiIiIi4ju6G4xHNLMuIiIiImJTmlkXEREREZ9xaGbdI5pZFxERERGxKQ3WRURERERsSstgRERERMRntAzGM5pZFxERERGxKQ3WRURERERsSstgRERERMR3tArGI5pZFxERERGxKQ3WRURERERsSstgRERERMRndDcYz2iwbrGordOsTkhRUNW+ViekignnUkRERMQTGqyLiIiIiM9oZt0zWrMuIiIiImJTGqyLiIiIiNiUlsGIiIiIiM9oGYxnNLMuIiIiImJTGqyLiIiIiNiUlsGIiIiIiM9oGYxnNLMuIiIiImJTGqyLiIiIiNiUlsGIiIiIiO9oFYxHNLMuIiIiImJTmlkXEREREZ/RBaae0cy6iIiIiIhNabAuIiIiImJTWgYjIiIiIj6jZTCe0cy6iIiIiIhNabAuIiIiImJTWgYjIiIiIj6jZTCe0cx6KixdspimTRpStVI52rdpzY7t26xOSpSVnS8+14SNi4ZwauNbHP4ujGWTulG8UG7X8+nS+fF6v5ZsXfYyEZsncmD1G8x9rSP57sme4FjVyxfhm3dfIGLzRMJ/GM+3c/qTITC9z74WMOMzN6ERzOg0oRHM6DShEczoNKERzOg0oRHM6RTf0mA9Bau+Wcn4sWF0696LpSs+o3LlEHr36Eb48eNWp7mxurNO5WLMWvoD9Tq9RfNe0/D39+ermX3JlCEAgEwZAqhYqgBj53xDjafG0X7wHIoXzM3yKT3cjlO9fBE+n9ab77b8QZ0OE6jdYQKzlm4gPt7pk68DrD+XqWFCI5jRaUIjmNFpQiOY0WlCI5jRaUIjmNMpvudwOp2+GwX50JVr3jnOM+3bUKp0aV4ZMdq1rVWLpjRo2Ij+Awd75028IC07g6r29fg1uYKycPT7sTTqOplNO/5JdJ+Q0gXZuPglSjR9laMnogDY8MFgvvv5D8bM+Nrj94zaOs3j1yTGhM/chEYwo9OERjCj04RGMKPThEYwo9OERkjbzgw2W/Qc3GmJ1QkuZxY8ZXVCijSznoyrsbHs27uHGjVru22vUbMWu3fttKgqITt2ZsuSAYCo6EtJ75M1I/Hx8Zw9fxmAe4KyUK18EU5HXmDd/EEcWvsmq+f2p2bF+33SDPY8lzczoRHM6DShEczoNKERzOg0oRHM6DShEczpFGtosJ6MqLNRxMXFERwc7LY9ODgXERGnLapKyI6d4wY/waYdf7P3n/BEnw8MSMdr/Vqy9JttnL94BYAi9+UCYHiPZsz7ZDMt+8xg176jrHz3BYoWvMcn3XY8lzczoRHM6DShEczoNKERzOg0oRHM6DShEczp9BqHjR4GsMUPRvbt28eWLVuoUaMGDzzwAH/88QdTp04lJiaGDh060LBhw2RfHxMTQ0xMjNs2p38ggYGBXum7+aplp9NpyyuZ7dI5eVhbyhXPz0NdJif6fLp0fiwc2wU/h4P+Yctc2/38rre+9/FGFn6xBYDdf/5L/Wol6dyyBiPe+SLt4/+fXc5lckxoBDM6TWgEMzpNaAQzOk1oBDM6TWgEczrFtyyfWV+1ahUVK1bkxRdfpFKlSqxatYq6devy999/c+TIER5++GG+//77ZI8RFhZG9uzZ3R4TxoXddltQjiD8/f2JiIhw2x4ZeYbg4Fy3fXxvsVPnpKFtaF6vHA93e5tjp84meD5dOj8Wj+tKoXuDad5rmmtWHSD89DkA9h044faaPw+eoEDeoDTtvsFO5zIpJjSCGZ0mNIIZnSY0ghmdJjSCGZ0mNII5nWINywfrY8aMYciQIZw5c4b333+fp59+mm7durFmzRrWrl3LSy+9xNixY5M9RmhoKNHR0W6PIUNDb7stfUAApUqXYcvmTW7bt2zeTIWKlW77+N5il87JQ9vQsmEFHunxNoePn0nw/I2BetGC9/Boz2lERl90e/7w8TMcP3WWEoVzu20vVig3R8Ij07T9Brucy+SY0AhmdJrQCGZ0mtAIZnSa0AhmdJrQCOZ0eovD4bDNwwSWL4PZs2cPCxYsAKBt27Z07NiRJ554wvX8U089xXvvvZfsMQIDEy558dbdYDp27sLwYS9RumxZKlSoxMfLlxIeHk6bdu298wZeYnXnlNC2tGtahTYDZ3Ph4hXyBGcFIPrCFa7EXMXf348PJzxPpQcK0Lr/LPz9HK59IqMvcfVaHACTP1jLKz0f5be/jrH7z3/p0KI6JQvn4ekhyf8d8Carz2VqmNAIZnSa0AhmdJrQCGZ0mtAIZnSa0AjmdIrvWT5Y/y8/Pz8yZMhAjhw5XNuyZs1KdHS0ZU2PNG1G9NkoZs+cwenTpyhWvATTZ80mf/57LWtKjNWdPdrWBWDN3AFu27uNWMiiL3/m3tw5aFG/PAC/LHX/qUeT56fy4/b9AEz7cD0ZAtMzfvATBGXPxG9/HaN5r2kc/Nf9R4NpyepzmRomNIIZnSY0ghmdJjSCGZ0mNIIZnSY0gjmd4nuW32e9QoUKjBs3jkceeQSA33//nQceeIB06a5/H7Fx40Y6derEgQMHPDqut2bW5dbus24Fb91nXURE5E5it/us39NlqdUJLqffb2d1Qoos//h69epFXFyc689ly5Z1e/6bb75J8W4wIiIiIiJ3IssH6z179kz2+TfeeMNHJSIiIiKS1ky5sNMuLL8bjIiIiIiIJE6DdRERERERm7J8GYyIiIiI3EW0CsYjmlkXEREREbEpDdZFRERERFJpxowZFClShAwZMhASEsKPP/6Y7P6LFy+mQoUKZMqUiXz58tGlSxfOnEn4m96TosG6iIiIiPiMw+GwzcNTS5cuZcCAAQwfPpydO3dSp04dmjZtypEjRxLd/8bvC+ratSt79uxh+fLlbN26leeffz7V76nBuoiIiIhIKkyaNImuXbvy/PPPU6pUKaZMmUKBAgWYOXNmovtv2bKFwoUL069fP4oUKULt2rXp0aMH27ZtS/V7arAuIiIiInelmJgYzp075/aIiYlJdN/Y2Fi2b99OkyZN3LY3adKEzZs3J/qamjVr8u+//7Jy5UqcTicnT55kxYoVPProo6lu1GBdRERERHzG6qUv/32EhYWRPXt2t0dYWFii3REREcTFxZEnTx637Xny5OHEiROJvqZmzZosXryYdu3aERAQQN68ecmRIwfvvPNOqs+XBusiIiIiclcKDQ0lOjra7REaGprsa25e6+50OpNc/75371769evHiBEj2L59O6tWreLgwYP07Nkz1Y26z7qIiIiI+MytXNiZVgIDAwkMDEzVvrly5cLf3z/BLPqpU6cSzLbfEBYWRq1atRgyZAgA5cuXJ3PmzNSpU4fXX3+dfPnypfi+mlkXEREREUlBQEAAISEhrFmzxm37mjVrqFmzZqKvuXTpEn5+7sNtf39/4PqMfGposC4iIiIikgqDBg1i7ty5zJs3j3379jFw4ECOHDniWtYSGhpKp06dXPu3aNGCTz75hJkzZ3LgwAE2bdpEv379qFatGvnz50/Ve2oZjIiIiIj4jJ2WwXiqXbt2nDlzhjFjxhAeHk7ZsmVZuXIlhQoVAiA8PNztnuvPPvss58+fZ9q0aQwePJgcOXLQsGFDxo0bl+r3dDhTOwdvmCvXrC64cwRV7Wt1QqpEbZ1mdYKIiIjtZLDZ1Gz+Hp9YneBy/N3WViekSMtgRERERERsymbfa4mIiIjIHc3cVTCW0My6iIiIiIhNaWZdUmTKWvCgGoOsTkhR1E+TrE4QMVZcvP0vsfL305ShiHiXBusiIiIi4jMm3w3GCloGIyIiIiJiU5pZFxERERGf0cy6ZzSzLiIiIiJiUxqsi4iIiIjYlJbBiIiIiIjPaBmMZzSzLiIiIiJiUxqsi4iIiIjYlJbBiIiIiIjvaBWMRzSzLiIiIiJiUxqsi4iIiIjYlJbBiIiIiIjP6G4wntHMuoiIiIiITWlmXURERER8RjPrntHMuoiIiIiITWmwLiIiIiJiU1oGIyIiIiI+o2UwntHMuoiIiIiITWmwngpLlyymaZOGVK1UjvZtWrNj+zarkxJlQqfVjbUq3c+KSV05sHIkl7dOokW9sm7PZ84YwOQhrfn7qxFE/jiOncuG0u2Jmq7nC+YL4vLWSYk+Wj9Uwadfi9XnMrVM6DShEczotHvj8qVLaNv6Meo8GEKdB0Po/Ew7Nv34g9VZibL7ubzBhE4TGsGcTvEtDdZTsOqblYwfG0a37r1YuuIzKlcOoXePboQfP251mhsTOu3QmDljAL/9dZyBEz5J9Pnxg1rRuMYDdBmxmIptx/LOkg1MevFxmtctA8C/J89S+JGRbo8x767iwqUYvt28z2dfhx3OZWqY0GlCI5jRaUJj7jx56DdgMIs+WsGij1ZQtfqDDOzXh3/+3m91mhsTziWY0WlCI5jT6Q0Oh8M2DxNosJ6ChR+8z+NPPEHrJ9twf9GivBQ6nLz58rJs6RKr09yY0GmHxtWb/2D0rG/4fN1viT5fvVwhFn29lR93/MOR8CjmfbqFX/cfp3LpAgDExzs5eea82+Ox+mVZsWYXFy/H+uzrsMO5TA0TOk1oBDM6TWisV78htevWo1DhIhQqXIS+/QaSKVMmfvt1t9Vpbkw4l2BGpwmNYE6n+J4tB+tOp9PqBACuxsayb+8eatSs7ba9Rs1a7N6106KqhEzoNKERYPOugzSvW4b892QHoG5IMYoXvIe1P/2Z6P6VHriPiiXv44MvfvZZoynn0oROExrBjE4TGm8WFxfHt998zeXLlyhfoaLVOS6mnEsTOk1oBHM6vcZho4cBbHk3mMDAQHbv3k2pUqUs7Yg6G0VcXBzBwcFu24ODcxERcdqiqoRM6DShEWDwW58yY3hb/lk5kqvX4oiPd9Lr9aVs3n0w0f07t6zOvgMn2PLrIZ81mnIuTeg0oRHM6DSh8Yb9f/3Jsx2eIjY2hoyZMjFxyjTuL1rM6iwXU86lCZ0mNII5nWINSwfrgwYNSnR7XFwcY8eOdf2lnTRpUrLHiYmJISYmxm2b0z+QwMBAr3TevKbJ6XTacp2TCZ12b+zTvg7VyhXiiUFzORIeRe1KRZk69AlOnDnHul/c17RmCExPu4crM/a91Za02v1c3mBCpwmNYEanCY2FixRhyYpPuXD+HN+tWc2IV4Yx9/2FthqwgxnnEszoNKERzOkU37J0sD5lyhQqVKhAjhw53LY7nU727dtH5syZU/WXNCwsjNGjR7ttG/7qSF4ZMeq2+oJyBOHv709ERITb9sjIMwQH57qtY3uTCZ0mNGYITM/o3s1oN+R9Vm26frHo73+HU75EfgZ0aJBgsP54w/JkypCexV/79mp9E84lmNFpQiOY0WlC4w3p0wdQsGAhAEqXKcee33/nw0ULeGXkGIvLrjPlXJrQaUIjmNPpLfoGxDOWrll/4403iI6O5tVXX2XdunWuh7+/P/Pnz2fdunV8//33KR4nNDSU6Ohot8eQoaG33Zc+IIBSpcuwZfMmt+1bNm+mQsVKt318bzGh04jGdH4EpE9H/E3XTMTFO/FL5F8sz7asztc/7CHi7EVfJQJmnEswo9OERjCj04TGpDhxcjXWdxeIp8SUc2lCpwmNYE6nWMPSmfXQ0FAaNWpEhw4daNGiBWFhYaRPn97j4wQGJlzycuWadxo7du7C8GEvUbpsWSpUqMTHy5cSHh5Om3btvfMGXmJCpx0aM2cMoGiB/81SFM6fk/Il8hMVfYmjJ8/yw/a/ebNfCy5fucqRE1HUqVyUZ5pVYeiUz92Oc/99uahd6X5aDZjrs/b/ssO5TA0TOk1oBDM6TWh8Z+okatWuS968ebl48SLfrlrJ9q2/MG3mHKvT3JhwLsGMThMawZxO8T3LLzCtWrUq27dvp0+fPlSpUoVFixbZ6scjjzRtRvTZKGbPnMHp06coVrwE02fNJn/+e61Oc2NCpx0aK5cqwOp3+7j+PH5QKwAWfvUL3Ud/RKfhCxnT51Hmv9aBoGyZOHIiklEzVzLn481ux+n8WDWOn45m7ZbE7xKT1uxwLlPDhE4TGsGMThMaI8+c4dWXXyLi9GmyZM1K8eIlmTZzDg/WrGV1mhsTziWY0WlCI5jT6Q12GueZwOG0y30SgY8++ogBAwZw+vRpfvvtN0qXLn3Lx/LWzLqYI6hG4hcs20nUT8lfLC0iSYuLt81/rpLk76dBiNhPBsunZt0VHfyN1Qku/0xsanVCimz18bVv357atWuzfft2ChUqZHWOiIiIiIilbDVYB7jvvvu47777rM4QERERkTSgVTCeseVvMBURERERERvOrIuIiIjInUsXmHpGM+siIiIiIjalwbqIiIiIiE1pGYyIiIiI+IxWwXhGM+siIiIiIjalwbqIiIiIiE1pGYyIiIiI+IzuBuMZzayLiIiIiNiUBusiIiIiIjalZTAiIiIi4jNaBeMZzayLiIiIiNiUZtZFRERExGf8/DS17gnNrIuIiIiI2JQG6yIiIiIiNqVlMCIiIiLiM7rA1DOaWRcRERERsSkN1kVEREREbErLYCx2OTbO6oQUZQzwtzohVSI2TbQ6IUX3Pf+R1Qmpsm1iK6sTUpQ3ewarE8TH/HUHCZE7gkPrYDyimXUREREREZvSYF1ERERExKa0DEZEREREfEarYDyjmXUREREREZvSzLqIiIiI+IwuMPWMZtZFRERERGxKg3UREREREZvSMhgRERER8Rktg/GMZtZFRERERGxKg3UREREREZvSMhgRERER8RmtgvGMZtZFRERERGxKM+siIiIi4jO6wNQzmlkXEREREbEpDdZFRERERGxKy2BERERExGe0CsYzmlkXEREREbEpDdZFRERERGxKg/VUWLpkMU2bNKRqpXK0b9OaHdu3Wdqzc/s2BvfvTfPG9XiwUmk2rFvr9vy679bQv3c3Hm5QkwcrleavP/dZVJqQ3c5lSubNfZfK5R5gwrg3ffae/R8txZoRjTk08wn2vd2KBf1qUyxv1gT7vdSqLL9PbsnR2U/y+bCGlMyfze35gHR+hHWozJ/vPM7hd59kUf865AvKmCbNHy14jxeee5pWjWrQtll9Rg0dwNHDh9z2iYo8w1uvv8pTjzXisQbVeXlgL44dPZwmPZ4y5e+lCZ0mNIIZnSY0ghmdJjSCOZ23y+Fw2OZhAg3WU7Dqm5WMHxtGt+69WLriMypXDqF3j26EHz9uWdPly5coXqIkg4e9kujzVy5fpnyFSvR+YZCPy5Jnx3OZnD2//8YnK5ZRvERJn75vzQdy8973f/Pwa2t4csJ60vk5WP5ifTIF+Lv2eaHZA/R6uCRDF22n8eg1nIq+zMdDGpAlw/8uQ3nj6Uo8Wvk+us3cTPM31pI5MB0fDqyLXxr8y+nXndto8UQ7psxeSNjUd4mLu8bLA3py5fIlAJxOJ6OHDiD82L+MGjuF6fOXkidvPob16+Haxyqm/L00odOERjCj04RGMKPThEYwp1N8T4P1FCz84H0ef+IJWj/ZhvuLFuWl0OHkzZeXZUuXWNZUs3ZdevbpT4OHGif6fNPmj9G1R2+qPljDx2XJs+O5TMqlSxcZPuxFXh35GtmyZUv5BV7UbuIGPtp4kD+Pn2PP0bO88N4vFMiVmQqFc7r26dmkJJO+3MPX2//lj2PR9JnzMxkD/XniwUIAZM2Ynmfq3s+Ij3byw96T/HbkLL1m/0Tp+7JTr0werze/OXkmTR5tSeH7i1G0eEkGDx/DqZPh7P/j+k91jh09zL49v/LCkOGULF2WAoUK0/fF4Vy+fIl1a1Z5vccTpvy9NKHThEYwo9OERjCj04RGMKdTfE+D9WRcjY1l39491KhZ2217jZq12L1rp0VVZjLtXI59Ywy169Sneo2aVqeQLWN6AKIuxgJQ6J7M5MmRkfW/n3DtE3stns1/nKJqsVwAVCwcREA6f9b9Z58TZ6+w799oqv3/Pmnp4sULAGT9/290rl69CkBAQKBrH39/f9KnT8+eX637/E35e2lCpwmNYEanCY1gRqcJjWBOp7c4HPZ5mECD9WREnY0iLi6O4OBgt+3BwbmIiDhtUZWZTDqX337zNX/s3csLA+yxjOi1pyrx05+n+eNYNAC5s2cA4PS5K277nT4X43oud/aMxFyNI/rS1ST3SStOp5PZb79FmQqVKFy0OAAFChUmT978zJv1NufPnePq1assXfAekWciiLTw8zfl76UJnSY0ghmdJjSCGZ0mNII5nWIN291nPSoqig8++ID9+/eTL18+OnfuTIECBZJ9TUxMDDExMW7bnP6BBAYGJvEKz9x8AYLT6TTmogS7sfu5PHEinAlj32TG7Pe89vfndozrGELpAjl49I21CZ5zOt3/7HCAM8FeN+1DyvvcrukTwzj4934mzprv2pYuXXpefXMik8JG8eQjdfDz96dSlepUrVE76QP5kN3/Xt5gQqcJjWBGpwmNYEanCY1gTuftuhO/prRk+cx6/vz5OXPmDAAHDx6kdOnSjBs3jv379/Puu+9Srlw5/vjjj2SPERYWRvbs2d0eE8aF3XZbUI4g/P39iYiIcNseGXmG4OC0X0pwJzHlXO7bs4fIyDM80+4JqlYsQ9WKZdi+bSsfLV5I1YpliIuL81lLWIfKPFLxXlqN/Z7wqMuu7aeir8+o3zxDnitrIKf//7lT0ZcJTO9P9kzp3ffJ9r990sL0SWH8tHE946fN4Z7c7mvjiz9QmpkfLOOT1RtZ8sVa3pw8k3PRZ8mb794060mJKX8vTeg0oRHM6DShEczoNKERzOkUa1g+WD9x4oRrAPTyyy/zwAMP8M8//7B69Wr+/vtv6tSpw6uvvprsMUJDQ4mOjnZ7DBkaettt6QMCKFW6DFs2b3LbvmXzZipUrHTbx7+bmHIuqz34IMs++YIlyz91PUqXKUvTR1uwZPmn+Pv7p3wQLxjboTLNQ+7j8fHfcyTiottzh09f5OTZy9Qvk9e1Lb2/HzUfyM3Wv6//i37XoShir8W57ZMnewZK3ZedX/52/4+BNzidTqZNfJNN679j/DtzyJv/viT3zZwlKzmCcnLs6GH2/7GXGnXqe70ntUz5e2lCpwmNYEanCY1gRqcJjWBOp1jDVstgfv75Z+bOnUumTJkACAwM5JVXXuHJJ59M9nWBgQmXvFy55p2mjp27MHzYS5QuW5YKFSrx8fKlhIeH06Zde++8wS24dOki/x494vrz8WPH+OvPfWTLlp28+fITHX2WkyfCiTh1CoDDhw4B19e+Bee6x4pkwJ7n8maZM2ehWPESbtsyZsxI9hw5EmxPK+M7hvBEjUJ0nPojF65cc82gn7t0lStXr39jO2v1nwxoUZp/Tp7nwMkLDGxemssxcXy85fp9y89fvsriHw4wpn0lIi/EcvZiDKPbV2Lvv9Fs2HPS683T3nqTdWu+YdS4KWTMlJnIM9e/IcicJQuBgdf7f/h+NdlzBJE7Tz4O/rOfWVPGU6NuA0KqW3sRrwl/L8GMThMawYxOExrBjE4TGsGcTm/QKhjP2GKwfmPtUkxMDHnyuP/oPE+ePJw+bd3FFY80bUb02Shmz5zB6dOnKFa8BNNnzSZ/fut+dL9v7x76dHvW9eepE8cB0KxFK0aMeZMfN6zj9ZHDXc+/OmwwAF179KZbz74+bf0vO55LO3ruoesXZX4R+pDb9r5zf+ajjQcBeGflH2QMSMeETlXInjmAHf+c4cm31nPhP9+lvrJkJ9finbzXpyYZ0vvz476T9J3yM/E3L3b3gq8+XQbAkD5d3bYPHj6GJo+2BCAy4jTvvv0WZyPPkDP4Hho1bc7TXXp4vcVTpvy9NKHThEYwo9OERjCj04RGMKdTfM/hdKbBf7k94OfnR9myZUmXLh379+9nwYIFPP74467nf/jhB55++mn+/fdfj47rrZn1tHY51ndroG9VxgDfLP24XXHxlv5VTpVC3ZdanZAq2ya2sjohRXnT+K42IiJ3igy2mJr9n2pvrrc6weWXl+tbnZAiyz++kSNHuv35xhKYG7788kvq1KnjyyQRERERSSO6G4xnbDdYv9mECRN8VCIiIiIiYi+W3w1GREREREQSZ/nMuoiIiIjcPbQKxjOaWRcRERERsSnNrIuIiIiIz+gCU89oZl1ERERExKY0WBcRERERsSktgxERERERn9EqGM9oZl1ERERExKY0WBcRERERsSktgxERERERn9HdYDyjmXUREREREZvSzLqIiIiI+Iwm1j2jmXUREREREZvSYF1ERERExKa0DEZEREREfEYXmHpGM+siIiIiIjalwbqIiIiIiE1pGYyIiIiI+IyWwXhGg3WLZQzwtzrhjuHvZ/9/+I/Mbmd1QqoEN3/L6oQURa0cYnXCHeP85WtWJ6RK1oz6T5aI3H20DEZERERExKY0TSEiIiIiPqNVMJ7RzLqIiIiIiE1pZl1EREREfEYXmHpGM+siIiIiIjalwbqIiIiIiE1pGYyIiIiI+IxWwXhGM+siIiIiIjalwbqIiIiIiE1pGYyIiIiI+IzuBuMZzayLiIiIiNiUBusiIiIiIjalZTAiIiIi4jNaBeMZzayLiIiIiNiUZtZFRERExGf8NLXuEc2si4iIiIjYlAbrIiIiIiI2pWUwIiIiIuIzWgXjGc2sp8LSJYtp2qQhVSuVo32b1uzYvs3qpESZ0GlCI9i/c9nSJbRt/Ri1Hwyh9oMhdHqmHRt//MFn7/9i++psfKcDpz7rz+FlvVk2qhXF7wtyPZ/O34/Xu9Zl67vPEvFFfw4s6cXcIc3IlzNzksf87I0nuLx6CC1qFvPFl+DG7p/3DXbq3LVjGy8N7E3LR+pTu0oZflj/ndvztauUSfTx4YJ5FhW7s9O5TIoJjWBGpwmNYE6n+JYG6ylY9c1Kxo8No1v3Xixd8RmVK4fQu0c3wo8ftzrNjQmdJjSCGZ158uThhQGDWfzRChZ/tIJq1R9kYL8+/PP3fp+8f51yBZj1xU7q9V9E82HL8ffz46uwNmTKkB6ATIHpqFg8D2MX/0SN3gtoP/ozit8XxPIxrRM93gutQ3A6fZKegAmfN9iv8/LlyxQrXpJBLw1P9PnPV613e4SOeB2Hw0G9ho19XJqQ3c5lYkxoBDM6TWgEczrF9xxOp1X/iUxbV6555zjPtG9DqdKleWXEaNe2Vi2a0qBhI/oPHOydN/ECEzpNaIS07YyPT7t/3OrVqs6AwUN4vPWTt32s4OZvebR/ruwZObq8L40GL2HTb/8muk9IibxsnNaREs/M4ujp867t5e6/h09ea03tvos4tLQ3bUd9ypeb/07xPaNWDvGoMSn6ewnnL9/evzBrVynDm2+9Td36DyW5T+jgF7h06SJTZ976zHrWjN5ZuWnCZ25CI5jRaUIjpG1nBpsten54xs9WJ7h827u61Qkp0sx6Mq7GxrJv7x5q1Kzttr1GzVrs3rXToqqETOg0oRHM6fyvuLg4Vn3zNZcvX6J8hYqWNGTLHAhA1Pkrye4TH+/k7MUY17aMgen4ILQ5A6d9x8moi2neeTNTPm9TOpMSeSaCzRt/4NGWif9kxZdMOJcmNIIZnSY0gjmdYg2bfa9lL1Fno4iLiyM4ONhte3BwLiIiTltUlZAJnSY0gjmdAPv/+pPOHZ4iNjaGjJkyMXHKNIoW9f16b4BxPRqw6bd/2XsoItHnA9P781rXuixdt4/zl2Jd28f3bMiWvcf56qeUZ9LTgimftymdSfnmq8/JlDkT9RpYvwTGhHNpQiOY0WlCI5jTKdawfGZ9586dHDx40PXnRYsWUatWLQoUKEDt2rX56KOPUjxGTEwM586dc3vExMSk+LrUctx02bLT6UywzQ5M6DShEczoLFykCB+t+JQPFn9Em7btGfHKMP75x/eD3sl9G1GuyD10Dvsy0efT+fuxcHgL/BwO+r+zxrX90QeLUr9iQYbM/N5XqUky4fMGczpv9vUXn9LkkeYEBgZaneJiwrk0oRHM6DShEczpvF1+Dvs8TGD5YL1r164cOnQIgLlz59K9e3eqVKnC8OHDqVq1Kt26dWPevOTXOIaFhZE9e3a3x4RxYbfdFpQjCH9/fyIi3GcLIyPPEByc67aP7y0mdJrQCOZ0AqRPH0DBgoUoU6Yc/QYMpkSJB1iyaIFPGyb1fojmNYry8EtLORZxIcHz6fz9WPzKYxTKk53mw5a5zarXr1iQ+/Pl4MSn/Tj/zWDOf3N9TeaSV1vy7YR2Puk35fM2pTMxu3du58jhgzRv9YTVKYAZ59KERjCj04RGMKdTrGH5YP3PP/+kaNGiAMyYMYMpU6YwdepUevbsyeTJk3n33XeZOHFisscIDQ0lOjra7TFkaOhtt6UPCKBU6TJs2bzJbfuWzZupULHSbR/fW0zoNKERzOlMnJPY2NiUd/OSyX0eomXt4jwyZCmHT0QneP7GQL3ovTl4dNgyIm9az/7W0l+o2nM+1Xt94HoAvPTuOrpPXOWTr8GUz9uUzsR89fnHlCxVhuIlHrA6BTDjXJrQCGZ0mtAI5nR6i8PhsM3jVsyYMYMiRYqQIUMGQkJC+PHHH5PdPyYmhuHDh1OoUCECAwMpWrRoihPR/2X5mvWMGTNy+vRpChYsyLFjx6he3f2q3OrVq7stk0lMYGBggh+veutuMB07d2H4sJcoXbYsFSpU4uPlSwkPD6dNu/beeQMvMaHThEYwo/OdqZOoVbsuefPm5eLFi3y7aiXbtv7C9JlzfPL+U15oRLsGpWgz8lMuXL5KnqDr90+PvhjDldhr+Ps5+PDVx6hUPA+tX/0Efz8/1z6R5y9z9Vo8J6MuJnpR6dFT5xId/KcVEz5vsF/npUsXOXb0iOvP4cf+Zf+f+8iaPTt58+YH4OKFC6xbu5q+A7xz5x5vsdu5TIwJjWBGpwmNYE7n3W7p0qUMGDCAGTNmUKtWLd59912aNm3K3r17KViwYKKvadu2LSdPnuS9996jWLFinDp1imvXUj9QtXyw3rRpU2bOnMncuXOpV68eK1asoEKFCq7nly1bRrFi1lw0B/BI02ZEn41i9swZnD59imLFSzB91mzy57/XsqbEmNBpQiOY0XnmzBleefklIk6fJkvWrBQvXpLpM+fwYM1aPnn/Hi2uz/SsmfiU2/ZuE1ayaM0e7r0nKy1qFgfgl1nPuu3T5MWP+PHXoz7pTA0TPm+wX+cfe/fQr2cX15/fmTwegKbNWzJ81JsArF29EqfTSaNHmlnSmBS7ncvEmNAIZnSa0AjmdN7tJk2aRNeuXXn++ecBmDJlCt9++y0zZ84kLCzhEuxVq1axYcMGDhw4QM6cOQEoXLiwR+9p+X3Wjx8/Tq1atShYsCBVqlRh5syZhISEUKpUKf7880+2bNnCp59+SrNmnv3L3lsz6yLelJb3WfcmT++zbgVv3Wddbv8+677irfusi9xt7Haf9Uff/cXqBJdPnq2Q4KYkia3YAIiNjSVTpkwsX76cxx9/3LW9f//+7Nq1iw0bNiR4Te/evfnrr7+oUqUKCxcuJHPmzDz22GO89tprZMyYMVWNlq9Zz58/Pzt37qRGjRqsWrUKp9PJL7/8wurVq7nvvvvYtGmTxwN1EREREZGUJHaTksRmyAEiIiKIi4sjT548btvz5MnDiRMnEn3NgQMH2LhxI7///juffvopU6ZMYcWKFfTp0yfVjbb4XitHjhyMHTuWsWPHWp0iIiIiIneJ0NBQBg0a5LYtpdvMenKLzfj4eBwOB4sXLyZ79uzA9aU0Tz75JNOnT0/V7LotBusiIiIicndwYJ8bnCe15CUxuXLlwt/fP8Es+qlTpxLMtt+QL18+7r33XtdAHaBUqVI4nU7+/fdfihcvnuL7Wr4MRkRERETE7gICAggJCWHNmjVu29esWUPNmjUTfU2tWrU4fvw4Fy7873eR/PXXX/j5+XHfffel6n01WBcRERERn7H6t5bezm8wHTRoEHPnzmXevHns27ePgQMHcuTIEXr27AlcX1bTqVMn1/5PP/00wcHBdOnShb179/LDDz8wZMgQnnvuuVRfYKplMCIiIiIiqdCuXTvOnDnDmDFjCA8Pp2zZsqxcuZJChQoBEB4ezpEj//sdFFmyZGHNmjW88MILVKlSheDgYNq2bcvrr7+e6ve0/NaNaUW3bhQ70q0bvUe3bvQe3bpR5M5mt1s3PjZ7q9UJLl90r2p1Qops9vGJiIiIyJ0sqTunSOK0Zl1ERERExKY0WBcRERERsSktgxERERERn9EqGM9oZl1ERERExKY0WBcRERERsSktgxERERERn/HTOhiPaGZdRERERMSmNLMuIiIiIj6jiXXPaGZdRERERMSmNFgXEREREbEpLYMREREREZ9xaB2MRzSzLiIiIiJiU5pZF/EhPz8zZhOiVg6xOiFFQVX7Wp2QKlFbp1mdkKKsGfWfAhERu9K/oUVERETEZ7QKxjNaBiMiIiIiYlMarIuIiIiI2JSWwYiIiIiIz/hpHYxHNLMuIiIiImJTmlkXEREREZ/RvLpnNLMuIiIiImJTGqyLiIiIiNhUqpbBHDlyxKODFixY8JZiREREROTO5tAFph5J1WC9cOHCHp3YuLi4Ww4SEREREZHrUjVYnzdvnr4LEhERERHxsVQN1p999tk0zhARERGRu4Gf5n89clsXmF6+fJljx45x7do1b/WIiIiIiMj/u6XB+rp166hRowZZs2alUKFC/PrrrwD06dOHTz75xKuBIiIiIiJ3K48H699//z1NmjThypUrvPjii8THx7uey5UrF/Pnz/dmn4iIiIjcQRwOh20eJvB4sD5ixAiaNWvGzp07ef31192eq1ChArt27fJWm4iIiIjIXS1VF5j+186dO1m+fDmQ8D6Z99xzD6dOnfJOmYiIiIjccQyZ0LYNj2fW06VLx9WrVxN97tSpU2TNmvW2o0RERERE5BYG61WrVmXhwoWJPrdixQpq1Khx21F2s3TJYpo2aUjVSuVo36Y1O7ZvszopUSZ0mtAIZnSa0AjWdr74XBM2LhrCqY1vcfi7MJZN6kbxQrnd9hneoxm7PnmFiM0TOb5hPF/P6kvVsoWSPOZn03pxeec0WtQvn9b5CZjwmZvQCGZ0mtAIZnSa0AjmdIpveTxYHzZsGJ9++imPP/44X3zxBQ6Hg59//pm+ffuyYsUKXnrppbTotMyqb1YyfmwY3br3YumKz6hcOYTePboRfvy41WluTOg0oRHM6DShEazvrFO5GLOW/kC9Tm/RvNc0/P39+WpmXzJlCHDt8/fhUwwct5wqbd7koS6TOHw8ki9n9CVXUJYEx3vhmQY4nT5JT8Dqc5kaJjSCGZ0mNIIZnSY0gjmd3mD1RaWmXWDqcDo9/0/PokWLGDBgAJGRka5tOXLk4J133uGZZ57xauCtuuKlW78/074NpUqX5pURo13bWrVoSoOGjeg/cLB33sQLTOg0oRHM6DShEdK2M6hqX49fkysoC0e/H0ujrpPZtOOfRPfJmjkDpza+RdMeb7P+l79c28uVuJdPpvakdofxHFobRtuBs/ly/a8pvmfU1mkedybGhM/chEYwo9OERjCj04RGSNvODB5foZi2On2Y8r87fWXB077/Kamnbuk+6x06dODo0aOsXr2aRYsWsWrVKo4ePWqbgbq3XI2NZd/ePdSoWdtte42atdi9a6dFVQmZ0GlCI5jRaUIj2LMzW5YMAERFX0r0+fTp/OnauhZnz1/it7+OubZnzJCeD8KeZeC4ZZw8c94nrf9lx3N5MxMawYxOExrBjE4TGsGcTrHGLX+vlTFjRho1anTbAS+88AJt27alTp06t30sb4s6G0VcXBzBwcFu24ODcxERcdqiqoRM6DShEczoNKER7Nk5bvATbNrxN3v/CXfb3rROWRaM7UKmDOk5EXGO5j2ncebsRdfz4wc/wZbdB/lq/W++TgbseS5vZkIjmNFpQiOY0WlCI5jT6S1+Zqw+sY1bmlk/d+4cYWFhNGnShJCQEJo0aUJYWBhnz571+FjTp0+nfv36lChRgnHjxnHixAmPjxETE8O5c+fcHjExMR4fJyk3r2lyOp22XOdkQqcJjWBGpwmNYJ/OycPaUq54fjqHzk/w3Iatf1G9fRgNnp3E6s17WTT+Oe75/zXrj9YrR/1qJRgyYYWPixOyy7lMjgmNYEanCY1gRqcJjWBOp/iWx4P1gwcPUr58eYYPH87+/fsJCAhg//79DB8+nAoVKnDgwAGPI1avXk2zZs146623KFiwIC1btuSrr75y++2oyQkLCyN79uxujwnjwjzuuFlQjiD8/f2JiIhw2x4ZeYbg4Fy3fXxvMaHThEYwo9OERrBX56ShbWherxwPd3ubY6fOJnj+0pVYDhyN4JffDtFr9Idci4un8+M1AahftQT335eLEz9M4PzWqZzfOhWAJW89z7dz+vuk307nMikmNIIZnSY0ghmdJjSCOZ3eYvVFpaZdYOrxYL1///5cuXKFTZs2cfDgQX766ScOHjzIxo0biYmJYcCAAR5HlCtXjilTpnD8+HEWLVpETEwMrVq1okCBAgwfPpy///472deHhoYSHR3t9hgyNNTjjpulDwigVOkybNm8yW37ls2bqVCx0m0f31tM6DShEczoNKER7NM5eWgbWjaswCM93ubw8TOpeo0DB4Hpr68SfOv91VRtG0b19mNdD4CXJn5M95GL0qz7v+xyLpNjQiOY0WlCI5jRaUIjmNMp1vB4zfr333/P1KlTE9xPvWbNmrz++uu3NFi/IX369LRt25a2bdty5MgR5s2bx/z58xk7dixxcXFJvi4wMJDAwEC3bd66G0zHzl0YPuwlSpctS4UKlfh4+VLCw8Np0669d97AS0zoNKERzOg0oRGs75wS2pZ2TavQZuBsLly8Qp7g67+0LfrCFa7EXCVThgCGPv8wX2/4jRMR0eTMnpnubetyb54cfLJmBwAnz5xP9KLSo+FRqR78e4PV5zI1TGgEMzpNaAQzOk1oBHM6xfc8HqwHBgZSoECBRJ8rWLBggkHzrSpYsCCjRo1i5MiRrF271ivHvBWPNG1G9NkoZs+cwenTpyhWvATTZ80mf/57LWtKjAmdJjSCGZ0mNIL1nT3a1gVgzdwBbtu7jVjIoi9/Ji4+npKF89ChRXWCc2QmMvoS2/YcptFzk9l3wPPrZ9KS1ecyNUxoBDM6TWgEMzpNaARzOr3BjMUn9uHxfdafe+45/P39mTNnToLnunXrRmxsLB988EGqj1ekSBG2bduW4Aro2+WtmXURsadbuc+6Fbx1n3URkVtlt/usP/eRNXfWSsy89uWsTkhRqj6+HTt2uP7/008/TdeuXWnTpg1PP/00efPm5cSJEyxevJht27bx3nvveRRw8OBBz4pFRERERO4SqRqsV6lSxe2KWafTydGjR/nkk0/ctgE0adIk2fXlIiIiInL38jPkLix2karB+vvvv5/WHSIiIiIicpNUDdY7d+6c1h0iIiIiInITm11yICIiIiJ3Mq2C8cwtDdYjIyP58MMP2bdvH5cvX3Z7zuFweHyRqYiIiIiIJOTxYP3IkSNUrVqVS5cucenSJXLlykVkZCRxcXEEBQWRPXv2tOgUERERkTuAQ1PrHvHz9AXDhg2jTJkynDx5EqfTyTfffMPFixd55513yJAhA19//XVadIqIiIiI3HU8Hqz/9NNP9OrViwwZMgDXb9kYEBBAnz596Nq1K0OGDPF6pIiIiIjI3cjjwfrJkyfJly8ffn5++Pv7c+7cOddz9erVY+PGjV4NFBEREZE7h8Nhn4cJPB6s58mTh8jISAAKFy7Mtm3bXM8dOnSIdOl0gxkREREREW/weGT94IMPsnPnTh577DFat27NmDFjiImJISAggAkTJtCwYcO06BQRERERuet4PFh/8cUXOXToEAAjRoxg3759jBw5EqfTSd26dZkyZYqXE0VERETkTuFnyvoTm/B4sB4SEkJISAgAmTNn5osvvuDcuXM4HA6yZs3q9UARERERkbuVx2vWE5MtWzayZs3KDz/8oGUwIiIiIiJe4tWrQU+fPs2GDRu8eUgRERERuYNoFYxnvDKzLiIiIiIi3qf7LIqIiIiIzzg0te4RzayLiIiIiNiUBusiIiIiIjaVqmUw5cuXT9XBzp07d1sxIiKpFbV1mtUJqRJUrZ/VCSmK+uVtqxNSxem0uiBl+um+SMo0U+yZVA3Wc+bMmar1RcHBwRQpUuS2o0REREREJJWD9fXr16dxhoiIiIiI3Ex3gxERERERn9HdYDyjZUMiIiIiIjalmXURERER8Rk/Tax7RDPrIiIiIiI2pcG6iIiIiIhNaRmMiIiIiPiMlsF45pYH63/88QcbNmwgIiKCrl27kjdvXo4fP05QUBAZM2b0ZqOIiIiIyF3J48F6XFwc3bt3Z/78+TidThwOB02bNiVv3rz06NGDSpUqMWbMmLRoFRERERG5q3i8Zv2NN97gww8/ZMKECfz+++84//P7n5s2bcqqVau8GigiIiIidw6Hw2Gbhwk8nlmfP38+r776KoMGDSIuLs7tuSJFinDw4EGvxYmIiIiI3M08nlk/duwYNWrUSPS5DBkycP78+duOEhERERGRWxis586dmwMHDiT63J9//sl9991321EiIiIicmfyc9jnYQKPB+vNmjXjjTfe4NixY65tDoeD6Oho3n77bVq0aOHVQBERERGRu5XHg/UxY8Zw7do1SpcuzRNPPIHD4eDll1+mbNmyXLlyhVdffTUtOkVERETkDuBw2OdhAo8H63ny5GHr1q089dRTbN++HX9/f3bv3k3Tpk3ZvHkzOXPmTItOEREREZG7zi39UqQ8efIwa9Ysb7eIiIiIiMh/eDyzfjdaumQxTZs0pGqlcrRv05od27dZnZQoEzpNaAQzOk1oBDM6rW6sVbkoK6Z058C3r3F5x9u0qF/O7fnLO95O9DGwU0MACubLmeQ+rRtV9OnXYvW5TMn2bVvp16cnjRvUpmLZknz/3Vqrk5Jk93N5gwmdJjSCOZ23y8/hsM3DBB4P1p977rlkH127dk2LTsus+mYl48eG0a17L5au+IzKlUPo3aMb4cePW53mxoROExrBjE4TGsGMTjs0Zs4QwG9/HWPguOWJPl+48XC3R/dRi4mPj+fT73YD8O/JqAT7jJm5kguXYvh2016ffR12OJcpuXz5EiVKlmTYyyOsTkmWCecSzOg0oRHM6RTfczj/+ytIU6Fw4cIJfuPTmTNnuHDhAjly5CBHjhxJ3trRl65c885xnmnfhlKlS/PKiNGuba1aNKVBw0b0HzjYO2/iBSZ0mtAIZnSa0AhmdKZ1Y1C1fh7tf3nH27QdNIcv1/+W5D7LJj5PlsyBNOs5Pcl9fvrwJXb9cZReY5ak+J5Rv7ztUWNS0vpcevZfq5RVLFuSSVOn0/ChRl47prcm6kz4ZwfM6DShEdK2M8MtLXpOO8NW/mV1gsvYZiWsTkiRxzPrhw4d4uDBg26Pc+fOsXbtWnLnzs3nn3+eFp2WuBoby769e6hRs7bb9ho1a7F7106LqhIyodOERjCj04RGMKPThMab5c6ZlUdql+GDz7YkuU+lUgWo+MB9ye7jbSaeS7sy5Vya0GlCI5jT6S1+NnqYwGudDRs2pG/fvvTv39/j177zzjt07tyZZcuWAbBw4UJKly7NAw88wMsvv8y1a16aJvdQ1Nko4uLiCA4OdtseHJyLiIjTljQlxoROExrBjE4TGsGMThMab9ahRTXOX7rCZ9/vTnKfzi0fZN+BE2z59aDPukw8l3Zlyrk0odOERjCnU6zh1R+MlC5dmmHDhnn0mtdee40JEybQpEkT+vfvz8GDB5kwYQIDBw7Ez8+PyZMnkz59ekaPHp3kMWJiYoiJiXHb5vQPJDAw8Ja+jpvdvOzH6XQm2GYHJnSa0AhmdJrQCGZ0mtB4Q6fHHmTpN9uIiU18EiNDYHraNQ1h7JxvfVx2nUnn0u5MOZcmdJrQCOZ0im959ScAGzZsIFeuXB69Zv78+cyfP58VK1awatUqhg8fztSpUxk+fDihoaG8++67fPjhh8keIywsjOzZs7s9JowLu50vBYCgHEH4+/sTERHhtj0y8gzBwZ59nWnJhE4TGsGMThMawYxOExr/q1al+ylZJA/vf/pTkvs83qgimTIEsPirrT4sM+9c2pkp59KEThMawZxOb7H6FyHd8b8UacyYMQkew4cPp0WLFrzxxhs89dRTHh0vPDycKlWqAFChQgX8/PyoWLGi6/nKlStzPIUroUNDQ4mOjnZ7DBka6umXlkD6gABKlS7Dls2b3LZv2byZChUr3fbxvcWEThMawYxOExrBjE4TGv+rc8sabN97hN/2J/3vxGdbPsjXG34n4uwFH5aZdy7tzJRzaUKnCY1gTqdYw+NlMKNGjUqwLTAwkMKFCzNmzBiGDBni0fHy5s3L3r17KViwIPv37ycuLo69e/dSpkwZAPbs2UPu3LmTPUZgYMIlL966G0zHzl0YPuwlSpctS4UKlfh4+VLCw8Np0669d97AS0zoNKERzOg0oRHM6LRDY+aMARQtcI/rz4XvDaZ8iXuJOneJoyeiAMiaOQOtG1dk2KTPkjzO/QVyUbtyUVr1ezetkxNlh3OZkkuXLnLkyBHXn48d+5c//thH9uzZyZcvv4Vl7kw4l2BGpwmNYE6nN5hyf3O78HiwHh8f79WAp59+mk6dOtGyZUu+++47hg4dyosvvsiZM2dwOBy88cYbPPnkk159T0880rQZ0WejmD1zBqdPn6JY8RJMnzWb/PnvtawpMSZ0mtAIZnSa0AhmdNqhsXLpgqye879bPI4f3BqAhV/8TPdRiwFo83BlHDhY9u32JI/TueWDHD8Vzdqf/kjb4CTY4VymZM/vv9PtuU6uP08cf33JZIuWj/PaG2OtykrAhHMJZnSa0AjmdIrveXSf9cuXL9O1a1d69+5N7dq1U35BKsTFxTF27Fi2bNlC7dq1GTp0KB999BEvvfQSly5dokWLFkybNo3MmTN7dFxvzayLiNwOT++zbgVv3Wc9rXn7PutpQROGYkd2u8/6q6v2W53g8tojxa1OSJHHvxQpc+bMfPPNN9StWzetmrxCg3URsQMN1r1Hg3WRW2O3wfqIb+0zWB/zsP0H6x5fYFqxYkV+//33tGgREREREZH/8HiwPnbsWMaPH8+GDRvSokdERERERP5fqn4w8sMPP1C5cmWyZMlC7969uXDhAg0bNiQoKIh8+fK53bDf4XCwe3fSv1lPRERERO5eflou5pFUDdYbNGjATz/9RLVq1QgODvb4Fx+JiIiIiIjnUjVY/+81qOvXr0+rFhERERER+Q+bXR8sIiIiIncy/VIkz6T6AlOHTqyIiIiIiE+lema9QYMG+PmlPLZ3OBxER0ffVpSIiIiI3Jk0/+uZVA/W69evzz333JOWLSIiIiIi8h+pHqyPGDGCatWqpWWLiIiIiIj8hy4wFRERERGf0X3WPePxbzAVERERERHf0GBdRERERMSmUrUMJj4+Pq07REREROQu4EDrYDyhmXUREREREZvSBaYiIiIi4jO6wNQzmlkXEREREbEpDdZFRERERGxKy2BERERExGe0DMYzGqyLiKShqF/etjohRUHV+1udkCpntkyxOiFFusuFiHiblsGIiIiIiNiUZtZFRERExGccDv0EyhOaWRcRERERsSkN1kVEREREbErLYERERETEZ3Q3GM9oZl1ERERExKY0sy4iIiIiPqPrSz2jmXUREREREZvSYF1ERERExKa0DEZEREREfMZP62A8opl1ERERERGb0mBdRERERMSmtAxGRERERHxG91n3jGbWRURERERsSoN1EREREZFUmjFjBkWKFCFDhgyEhITw448/pup1mzZtIl26dFSsWNGj99NgXURERER8xuGwz8NTS5cuZcCAAQwfPpydO3dSp04dmjZtypEjR5J9XXR0NJ06deKhhx7y+D01WBcRERERSYVJkybRtWtXnn/+eUqVKsWUKVMoUKAAM2fOTPZ1PXr04Omnn6ZGjRoev6cG6yIiIiLiM344bPPwRGxsLNu3b6dJkyZu25s0acLmzZuTfN3777/PP//8w8iRI2/xfEmKli5ZTNMmDalaqRzt27Rmx/ZtViclyoROExrBjE4TGsGMThMawbrOF7s0YuOCwZz6YRyH17zOsoldKV4ot9s+mTMGMPmlJ/h75WgiN01g54pQuj1ZK8GxqpcrzDez+hCxcTzh68P49t2+ZAhM75OvA2DZR0to+/hj1K4eQu3qIXR6ph0bf/zBZ+/vCf299B4TGsGczjtJTEwM586dc3vExMQkum9ERARxcXHkyZPHbXuePHk4ceJEoq/Zv38/w4YNY/HixaRLd2s3YdRgPQWrvlnJ+LFhdOvei6UrPqNy5RB69+hG+PHjVqe5MaHThEYwo9OERjCj04RGsLazTuVizFr+I/WenUzz3jPw9/fnq+m9yJQhwLXP+MGP07hmKbq8upCKT4bxzuL1TBryBM3rlXXtU71cYT6f1pPvtvxJnU6TqN1xErOW/Uh8fHyafw035MmbhxcGDmbx0hUsXrqCatUeZOALffjn7/0+a0gN/b30HhMawZzOO01YWBjZs2d3e4SFhSX7GsdNi92dTmeCbQBxcXE8/fTTjB49mhIlStxyo8PpdDpv+dU2duWad47zTPs2lCpdmldGjHZta9WiKQ0aNqL/wMHeeRMvMKHThEYwo9OERjCj04RGSNvOoOr9Pdo/V47MHP3uTRo9/zabdv4DwLalw1ixZgdj56527bdp0Yt8u2kvY2auBGDD/IF89/Ofrj976syWKbf0upTUq1mdAYOH8PgTT972sbz1a9T199J7TGiEtO3MYLPfqjNj8yGrE1y6huRLMJMeGBhIYGBggn1jY2PJlCkTy5cv5/HHH3dt79+/P7t27WLDhg1u+589e5agoCD8/f1d2+Lj43E6nfj7+7N69WoaNmyYYqPlM+vh4eGMGDGChg0bUqpUKcqWLUuLFi147733iIuLs7Ttamws+/buoUbN2m7ba9Ssxe5dOy2qSsiEThMawYxOExrBjE4TGsF+ndmyZAQg6twl17bNuw7QvG458t+THYC6VYpRvOA9rP3pDwDuCcpCtXKFOR15nnXzBnBo9eusnv0CNSve7/P+G+Li4li18msuX75EeQ9vpZaW7PZ5J8WEThMawZzOO1FgYCDZsmVzeyQ2UAcICAggJCSENWvWuG1fs2YNNWvWTLB/tmzZ+O2339i1a5fr0bNnT0qWLMmuXbuoXr16qhot/V5r27ZtNGrUiCJFipAxY0b++usvnnnmGWJjY3nxxRd57733+Pbbb8maNaslfVFno4iLiyM4ONhte3BwLiIiTlvSlBgTOk1oBDM6TWgEMzpNaAT7dY4b1IpNO/9h7z/hrm2DJ3zMjFfb88+qMVy9Fkd8vJNery1h864DABS593r78O5NCZ3yOb/+9S/PPFqNlTP7ENJ2LP8c9d3Xsf+vP+n8zFPExsaQMVMmJk6dRtGixXz2/imx2+edFBM6TWgEczoFBg0aRMeOHalSpQo1atRg9uzZHDlyhJ49ewIQGhrKsWPHWLBgAX5+fpQtW9bt9blz5yZDhgwJtifH0sH6gAEDGDhwoOvq2EWLFjFt2jS2bNlCVFQUDRs25JVXXmHq1KnJHicmJibBjzCc/on/CONWpHZtktVM6DShEczoNKERzOg0oRHs0Tl56JOUK56fh7q6/3u5z1N1qVa2EE8MmM2R8ChqVy7K1GFtOBFxjnW//IXf//9+8fc+2czCL38GYPefn1K/Wgk6t6zOiGlf+exrKFykCB99/Cnnz53juzWrGTF8GHPnL7TVgB3s8XmnhgmdJjSCOZ23y8/gL6ldu3acOXOGMWPGEB4eTtmyZVm5ciWFChUCrq8YSeme656ydBnMjh076Nixo+vPTz/9NDt27ODkyZMEBQUxfvx4VqxYkeJxErs4YMK45C8OSI2gHNfXGUVERLhtj4w8Q3Bwrts+vreY0GlCI5jRaUIjmNFpQiPYp3PSkCdoXrcsD/eYxrFT0a7tGQLTM7pPc4ZO/oyVP+7h97+PM2vZj6xYs5MBHa+vxwyPOAfAvgPud0z48+AJCuQN8tnXAJA+fQAFCxaiTNly9Bs4mBIlH2DJogU+bUiOXT7vlJjQaUIjmNMp1/Xu3ZtDhw4RExPD9u3bqVu3ruu5+fPns379+iRfO2rUKHbt2uXR+1k6WM+dOzfh4f/7MerJkye5du0a2bJlA6B48eJERkameJzQ0FCio6PdHkOGht52X/qAAEqVLsOWzZvctm/ZvJkKFSvd9vG9xYROExrBjE4TGsGMThMawR6dk196gpYNy/NIz+kcPu7+7+X06fwISJ+O+Hj3+xXExcW7ZtQPH4/k+KmzlCjsfsvHYgVzcyQ8Km3jU+J0Ehsba23Df9jh804NEzpNaARzOsUali6DadWqFT179mTChAkEBgby2muvUa9ePTJmvH7x0p9//sm9996b4nESu2rXW3eD6di5C8OHvUTpsmWpUKESHy9fSnh4OG3atffOG3iJCZ0mNIIZnSY0ghmdJjSCtZ1ThrWh3SOVaTNoLhcuXSFP8PXriKIvXOFKzFXOX4zhh237ebN/Sy7HXOVIeCR1QorxzKNVGTr5M9dxJi/4nld6NuW3v46x+89jdGhRjZKFc/P00Hlp/jXc8M6USdSqU5e8efNy8eJFvv1mJdu2/sL0WXN81pAa+nvpPSY0gjmd3uCtuybdLSwdrL/++uuEh4fTokUL4uLiqFGjBosWLXI973A4UrzXZVp7pGkzos9GMXvmDE6fPkWx4iWYPms2+fOn/E2EL5nQaUIjmNFpQiOY0WlCI1jb2aPN9TtUrJnTz217t1GLWfTlLwB0evkDxvRtwfzXOxKULRNHTkQxasbXzFnxv5nCaUs2kCEwPeMHPU5Q9kz89tdxmveZycF/z6T513DDmTNneCX0JSJOnyZL1qwUL1GS6bPm8GDNhL/AyUr6e+k9JjSCOZ3ie7a4z/qVK1e4du0aWbJk8d4xvTSzLiJyp/P0PutWSav7rHuTZgzFjux2n/U5Px+2OsGlW/VCViekyBYfX4YMGaxOEBERERGxHct/KZKIiIiIiCTOFjPrIiIiInJ30HIxz2hmXURERETEpjRYFxERERGxKS2DERERERGf0SoYz2hmXURERETEpjSzLiIiIiI+o5liz+h8iYiIiIjYlAbrIiIiIiI2pWUwIiIiIuIzDl1h6hHNrIuIiIiI2JQG6yIiIiIiNqVlMCIiIiLiM1oE4xnNrIuIiIiI2JQG6yIiIiIiNqVlMCIiIiLiM366G4xHNLMuIiIiImJTmlkXEREREZ/RvLpnNLMuIiIiImJTmlkXEbnLRf081eqEVAmq1s/qhBRF/vy21Qkp0nJhEbNosC4iIiIiPqNvGD2jZTAiIiIiIjalwbqIiIiIiE1pGYyIiIiI+IxD62A8opl1ERERERGb0mBdRERERMSmtAxGRERERHxGM8We0fkSEREREbEpzayLiIiIiM/oAlPPaGZdRERERMSmNFgXEREREbEpLYMREREREZ/RIhjPaGZdRERERMSmNFgXEREREbEpLYMREREREZ/R3WA8o5l1ERERERGb0mBdRERERMSmtAxGRERERHxGM8We0flKhaVLFtO0SUOqVipH+zat2bF9m9VJiTKh04RGMKPThEYwo9OERjCj08rGF7s0ZuPCwZz6cTyH177BsonPU7xQbtfz6dL58Xq/x9i6dBgRmyZw4NvXmDumA/lyZXPtE5QtE5NeeoLdnwznzKa3+OvrUUwc8gTZsmTw2dcBsH3bVvr16UnjBrWpWLYk33+31qfv7wn9vfQeUzrFt2wxWL948SJz5syhS5cuNG3alGbNmtGlSxfmzp3LxYsXLW1b9c1Kxo8No1v3Xixd8RmVK4fQu0c3wo8ft7TrZiZ0mtAIZnSa0AhmdJrQCGZ0Wt1YJ6QYs5b9SL3Ok2jeazr+6fz4akZvMmUIACBThgAqPnAfY+d+S42nJ9D+xfcoXig3y6d0dx0j3z3ZyXdPdkKnfE6VdmPpNmoxjWuWYtaIp33yNdxw+fIlSpQsybCXR/j0fT1l9WeeGiY0gjmd3uBwOGzzMIHD6XQ6rQzYu3cvjRs35tKlS9SrV488efLgdDo5deoUGzZsIHPmzKxevZrSpUt7dNwr17zT90z7NpQqXZpXRox2bWvVoikNGjai/8DB3nkTLzCh04RGMKPThEYwo9OERjCjM60bg6r182j/XDmycPT7N2n0/FQ27fgn0X1CShdk46IXKdFsJEdPRCW6T+tGFZn3eieCa71IXFx8su8Z+fPbHjWmRsWyJZk0dToNH2rkleN5c3yiv5fek5adGWy26PnTX09YneDyePm8ViekyPKZ9T59+lC3bl1OnjzJZ599xrvvvsvs2bP57LPPOHnyJHXr1qVPnz6WtF2NjWXf3j3UqFnbbXuNmrXYvWunJU2JMaHThEYwo9OERjCj04RGMKPTjo3Zsl5fuhIVfSnpfbJkID4+nrPnLyezT0bOXbyS4kD9bmPHz/xmJjSCOZ1iDcu/1/r555/Ztm0bAQEBCZ4LCAjg5Zdfplq1ahaUQdTZKOLi4ggODnbbHhyci4iI05Y0JcaEThMawYxOExrBjE4TGsGMTjs2jhv0OJt2/sPef8ITfT4wIB2v9XuMpau2c/7ilUT3yZk9E6HdHua9jzelZaqR7PiZ38yERjCn01vMWHxiH5YP1oOCgti/f3+Sy1z+/vtvgoKCkj1GTEwMMTExbtuc/oEEBgZ6pfHmNU1Op9OW65xM6DShEczoNKERzOg0oRHM6LRL4+RhbShXPD8PPTc10efTpfNjYdiz+Dkc9A9bnug+WTNn4NO3e7LvwAnemP1NWuYazS6feXJMaARzOsW3LF8G061bNzp37sxbb73F7t27OXHiBCdPnmT37t289dZbPPfcc/To0SPZY4SFhZE9e3a3x4RxYbfdFpQjCH9/fyIiIty2R0aeITg4120f31tM6DShEczoNKERzOg0oRHM6LRT46SXnqB53bI83P0djp06m+D5dOn8WDy2C4XuDaZ57+mJzqpnyRTIF9N6ceFSDO0Gz+XaNS2BuZmdPvOkmNAI5nSKNSwfrI8aNYrQ0FAmTZpEpUqVuPfee8mfPz+VKlVi0qRJDBs2jBEjkr8aPjQ0lOjoaLfHkKGht92WPiCAUqXLsGWz+48/t2zeTIWKlW77+N5iQqcJjWBGpwmNYEanCY1gRqddGicPfZKWDSvwSI9pHD4emeD5GwP1ogXv4dGe04lMZD171swZ+GpGb2KvXuPJgbOJifXSHQvuMHb5zJNjQiOY0+ktDod9HiawfBkMwNChQxk6dCgHDx7kxInrVwjnzZuXIkWKpOr1gYEJl7x4624wHTt3YfiwlyhdtiwVKlTi4+VLCQ8Pp0279t55Ay8xodOERjCj04RGMKPThEYwo9PqxinD2tCuaQhtBs7lwqUr5AnOCkD0hStcibmKv78fH47vSqUH7qN1/3fx93e49omMvsTVa3FkyRTIVzN6kzFDerq8spBsmTOQLfP1C1VPR10gPt43N1C7dOkiR44ccf352LF/+eOPfWTPnp18+fL7pCE1rP7MU8OERjCnU3zPFoP1G4oUKZJggH706FFGjhzJvHnzLGl6pGkzos9GMXvmDE6fPkWx4iWYPms2+fPfa0lPUkzoNKERzOg0oRHM6DShEczotLqxR9s6AKyZ636Lx24jF7Hoy1+4N3cOWtQvB8AvS4e57dOk29v8uP1vKpUqQLVyhQHY+4X7T3VLPjqKI+EJZ+vTwp7ff6fbc51cf544/vrSzhYtH+e1N8b6pCE1rP7MU8OERjCn0xv8dImpRyy/z3pKdu/eTeXKlYmLi/Podd6aWRcREXvw9D7rVkiL+6x7myk/+hfvsdt91r/87aTVCS4tyuWxOiFFln98X3zxRbLPHzhwwEclIiIiIiL2YvlgvVWrVjgcDpKb4Ndti0RERETuDBrWecbyu8Hky5ePjz/+mPj4+EQfO3bssDpRRERERMQSlg/WQ0JCkh2QpzTrLiIiIiJyp7J8GcyQIUO4ePFiks8XK1aMdevW+bBIRERERNKKQ3eD8Yjlg/U6deok+3zmzJmpV6+ej2pEREREROzD8mUwIiIiIiKSOMtn1kVERETk7qG7wXhGM+siIiIiIjalmXURERER8Rk/XWDqEc2si4iIiIjYlAbrIiIiIiI2pWUwIiIiIuIzusDUM5pZFxERERGxKQ3WRURERERsSstgRERERMRntAzGM5pZFxERERGxKQ3WRURERERsSstgRERERMRnHPqlSB7RzLqIiIiIiE1pZl1ERIxwfONkqxNSlLPBq1YnpChq/WtWJ8hdzk8T6x7RzLqIiIiIiE1psC4iIiIiYlNaBiMiIiIiPqMLTD2jmXUREREREZvSYF1ERERExKa0DEZEREREfMahVTAe0cy6iIiIiIhNaWZdRERERHxGF5h6RjPrIiIiIiI2pcG6iIiIiIhNaRmMiIiIiPiMn1bBeEQz6yIiIiIiNqXBuoiIiIiITWkZjIiIiIj4jO4G4xnNrIuIiIiI2JQG6yIiIiIiNqVlMCIiIiLiMw6tgvGIZtZFRERERGxKg/VUWLpkMU2bNKRqpXK0b9OaHdu3WZ2UKBM6TWgEMzpNaAQzOk1oBDM67da4c/s2BvfvTfPG9XiwUmk2rFvr9vycWdNo9/ij1K8RQuO6D9K3x3P8/tvuNOt5sUNdNs7pwanVr3D4y6Ese/NpihfIlWC/koXuYfnYZzixajinVr/Chne7UyBPdgAK5s3B5Y2vJfpo3aBMmrUnxW6feWJMaARzOm+Xw0YPE9h+sH7y5EnGjBlj2fuv+mYl48eG0a17L5au+IzKlUPo3aMb4cePW9aUGBM6TWgEMzpNaAQzOk1oBDM67dh4+fIlipcoyeBhryT6fMFChRk8dDiLl3/Gu+8vJF/+e+nfuxtRkZFp0lOnUmFmffIL9XrMpvnAD/D39+OryZ3JlCG9a58i+YP4bsbz/HX4NA+/MI9qz04nbP56rsRcA+DfU9EUfmyc22PM3O+4cCmGb7fsT5PupNjxM7+ZCY1gTqf4nsPpdDqtjkjO7t27qVy5MnFxcR697so177z/M+3bUKp0aV4ZMdq1rVWLpjRo2Ij+Awd75028wIROExrBjE4TGsGMThMawYzOtG68HOvZfwdu9mCl0oyb9Db1GjRKcp+LFy7wUJ1qvDPrPapWr+Hxe+RvMsqj/XPlyMTRr0Jp1Gcum3YfBmDBqLZcvRZH19c/TvVxfprXm11/HafX2M9S3Ddq/WseNSZHfy+9Jy07M9jsCsVN+6OsTnCpVTzI6oQUWT6z/uuvvyb7+PPPPy1ruxoby769e6hRs7bb9ho1a7F7106LqhIyodOERjCj04RGMKPThEYwo9OExpRcvRrLZ58sI0uWrBQv8YBP3jNb5gwARJ27DIDD4eCRmiXYf/QMX0zsxOEvh/LD7O60qFMqyWNUKpmfiiXy8cFX233SfIMJn7kJjWBOp7f4ORy2eZjA8u+1KlasiMPhILEJ/hvbHRadzKizUcTFxREcHOy2PTg4FxERpy1pSowJnSY0ghmdJjSCGZ0mNIIZnSY0JmXjD+t5ddhgrly5Qq5c9/D2rLnkCPLNbNu4F5qyafch9h48BUDuoMxkzRTIix3qMHrOWl6ZuZomDxbnozfa83C/99m461CCY3RuXpl9B0+x5fejPmm+wYTP3IRGMKdTrGH5YD04OJhx48bx0EMPJfr8nj17aNGiRbLHiImJISYmxm2b0z+QwMBArzTe/M2Cld9AJMeEThMawYxOExrBjE4TGsGMThMabxZStRoLPvqE6LNn+fyT5Qx/aRDvLfyInDmDU37xbZg8qDnliubhod5zXdtuzPR9tfEP3ln2EwC//n2C6mUL0q1V1QSD9QwB6WjXqDxjP1ifpq3JMeEzN6ERzOkU37J8GUxISAjHjx+nUKFCiT7uvffeRGfd/yssLIzs2bO7PSaMC7vttqAcQfj7+xMREeG2PTLyDMHBCa/et4oJnSY0ghmdJjSCGZ0mNIIZnSY0JiVjxkwUKFiIsuUrMHzU6/j7+/Plp6lfL34rJg14lOa1HuDhfvM4dvqca3tE9CWuXotj36FTbvv/efg0BXJnT3CcxxuUIVOG9CxetStNexNjwmduQiOY0+ktVt8BRneD8VCPHj0oXLhwks8XLFiQ999/P9ljhIaGEh0d7fYYMjT0ttvSBwRQqnQZtmze5LZ9y+bNVKhY6baP7y0mdJrQCGZ0mtAIZnSa0AhmdJrQmHpOYq/GptnRJw98lJb1SvNI/3kcDj/r9tzVa3Fs33eMEjfdzrF4gWCOnIxOcKxnm4fw9cY/iTh7Kc16k2LCZ25CI5jTKdawfBnM448/nuzzQUFBdO7cOdl9AgMTLnnx1t1gOnbuwvBhL1G6bFkqVKjEx8uXEh4eTpt27b3zBl5iQqcJjWBGpwmNYEanCY1gRqcdGy9dusi/R4+4/nz82DH++nMf2bJlJ3uOHMyf+y516jUkOFcuoqOj+XjZEk6dPMlDjR9Ok54pg5vTrlF52oR+yIVLseTJmQWA6AtXuBJ7/T9ck5dsZOHotmzcfYgNOw7SpHpxmtUsycP95rkd6/57c1K7QiFaDVmYJq2pYcfP/GYmNII5neJ7lg/WU3L06FFGjhzJvHnzUt45DTzStBnRZ6OYPXMGp0+foljxEkyfNZv8+e+1pCcpJnSa0AhmdJrQCGZ0mtAIZnTasXHf3j306fas689TJ44DoFmLVgwdPpJDhw6y8sv+nD0bRfbsOShVpiyz5i3k/qLF06Snx+PVAVgzravb9m5vfMKib67f9eOLH/bxwltfMqRDXSYOeJS/jkTw1CsfsfnXI26v6fxoZY6fPs/aX/5Jk9bUsONnfjMTGsGcTq8wZf2JTeg+6yIiYoTbvc+6L3h6n3UrePM+62IGu91nfcs/Z61OcHmwaA6rE1Jk+cf3xRdfJPv8gQMHfFQiIiIiImnNoal1j1g+WG/VqlWS91m/QbctEhEREZG7keV3g8mXLx8ff/wx8fHxiT527NhhdaKIiIiIiCUsH6yHhIQkOyBPadZdRERERMzhcNjnYQLLl8EMGTKEixcvJvl8sWLFWLdunQ+LRERERETswfLBep06dZJ9PnPmzNSrV89HNSIiIiIi9mH5YF1ERERE7h6GrD6xDcvXrIuIiIiISOI0WBcRERERsSktgxERERER39E6GI9oZl1ERERExKY0sy4iIiIiPuPQ1LpHNLMuIiIiImJTGqyLiIiIiNiUlsGIiIiIiM84tArGI5pZFxERERGxKQ3WRURERERsSstgRERERMRntArGM5pZFxERERGxKc2si4iIiIjvaGrdIw6n0+m0OiItXLlmdYGIiIj9BFXta3VCqkRtnWZ1wh0jg82mZnccPmd1gkvlQtmsTkiRlsGIiIiIiNiUzb7XEhEREZE7mUPrYDyimXUREREREZvSYF1ERERExKY0WBcRERERn3E47PO4FTNmzKBIkSJkyJCBkJAQfvzxxyT3/eSTT2jcuDH33HMP2bJlo0aNGnz77bcevZ8G6yIiIiIiqbB06VIGDBjA8OHD2blzJ3Xq1KFp06YcOXIk0f1/+OEHGjduzMqVK9m+fTsNGjSgRYsW7Ny5M9XvqVs3ioiI3EV068a7j91u3bjryHmrE1wqFszq0f7Vq1encuXKzJw507WtVKlStGrVirCwsFQdo0yZMrRr144RI0akan/NrIuIiIiIzzhs9PBEbGws27dvp0mTJm7bmzRpwubNm1N1jPj4eM6fP0/OnDlT/b42+15LRERERMQ3YmJiiImJcdsWGBhIYGBggn0jIiKIi4sjT548btvz5MnDiRMnUvV+EydO5OLFi7Rt2zbVjZpZFxERERHfsXo6/T+PsLAwsmfP7vZIaTmL46YrU51OZ4JtiVmyZAmjRo1i6dKl5M6dO8X9b9DMuoiIiIjclUJDQxk0aJDbtsRm1QFy5cqFv79/gln0U6dOJZhtv9nSpUvp2rUry5cvp1GjRh41amZdRERERO5KgYGBZMuWze2R1GA9ICCAkJAQ1qxZ47Z9zZo11KxZM8n3WLJkCc8++ywffvghjz76qMeNmlkXEREREZ9xeHxpp30MGjSIjh07UqVKFWrUqMHs2bM5cuQIPXv2BK7P1B87dowFCxYA1wfqnTp1YurUqTz44IOuWfmMGTOSPXv2VL2nBusiIiIiIqnQrl07zpw5w5gxYwgPD6ds2bKsXLmSQoUKARAeHu52z/V3332Xa9eu0adPH/r06ePa3rlzZ+bPn5+q99R91kVERO4ius/63cdu91n/9egFqxNcyhfIYnVCimz28YmIiIjInSwVN06R/9AFpiIiIiIiNqXBuoiIiIiITWmwngpLlyymaZOGVK1UjvZtWrNj+zarkxJlQqcJjWBGpwmNYEanCY1gRqcJjWBGp5WNtSoXZcWUHhxY/QaXd06jRf3ybs/PHt2ByzunuT02fDA4wXGqly/CN+++QMTmiYT/MJ5v5/QnQ2B6X30ZLiZ83mBO5+2ywe9Ccj1MYJvB+r///suFCwkvOLh69So//PCDBUXXrfpmJePHhtGtey+WrviMypVD6N2jG+HHj1vWlBgTOk1oBDM6TWgEMzpNaAQzOk1oBDM6rW7MnDGQ3/46xsCxy5Lc59tNeyjcKNT1aPXCTLfnq5cvwufTevPdlj+o02ECtTtMYNbSDcTH+/a+Flafy9QypVN8z/LBenh4ONWqVaNQoULkyJGDzp07uw3aIyMjadCggWV9Cz94n8efeILWT7bh/qJFeSl0OHnz5WXZ0iWWNSXGhE4TGsGMThMawYxOExrBjE4TGsGMTqsbV2/ay+gZX/H597uT3Cc29honz5x3PaLOXXJ7fvzg1sz4aD1vvb+GfQdO8M+R03y6dhexV317uzarz2VqmdLpFVZPpxs2tW75YH3YsGH4+/vz888/s2rVKvbu3Uv9+vWJiopy7WPV3SWvxsayb+8eatSs7ba9Rs1a7N6105KmxJjQaUIjmNFpQiOY0WlCI5jRaUIjmNFpQiNAnSrFOfxdGL9+NoLprz7FPUH/uwXePUFZqFa+CKcjL7Bu/iAOrX2T1XP7U7Pi/T5tNOVcmtIp1rB8sL527VqmTp1KlSpVaNSoERs3buS+++6jYcOGREZGAuCw6B4/UWejiIuLIzg42G17cHAuIiJOW9KUGBM6TWgEMzpNaAQzOk1oBDM6TWgEMzpNaFy9aS9dXv6Apt3fZtikTwgpU4hvZvcjIP31O0IXuS8XAMN7NGPeJ5tp2WcGu/YdZeW7L1C04D0+6zThXII5nWINywfr0dHRBAUFuf4cGBjIihUrKFy4MA0aNODUqVMpHiMmJoZz5865PWJiYrzWePM3C06n07JvIJJjQqcJjWBGpwmNYEanCY1gRqcJjWBGp50bV6zewaqNe9j7Tzgrf/idVn1nULxQbprWKQOAn9/1zvc+3sjCL7aw+89/eWniJ/x16BSdW9bwea+dz+V/mdJ5uxw2+p8JLB+s33///fz6669u29KlS8fy5cu5//77ad68eYrHCAsLI3v27G6PCePCbrstKEcQ/v7+REREuG2PjDxDcHCu2z6+t5jQaUIjmNFpQiOY0WlCI5jRaUIjmNFpQuPNTkSc40h4JMX+f9Y8/PQ5APYdOOG2358HT1Agb1CC16cVU86lKZ1iDcsH602bNmX27NkJtt8YsFesWDHFNeuhoaFER0e7PYYMDb3ttvQBAZQqXYYtmze5bd+yeTMVKla67eN7iwmdJjSCGZ0mNIIZnSY0ghmdJjSCGZ0mNN4sZ/bM3JcniPCI64P0w8fPcPzUWUoUzu22X7FCuTkSHumzLlPOpSmdYo10Vge88cYbXLp0KdHn0qVLxyeffMK///6b7DECAwMJDAx023bFSxebd+zcheHDXqJ02bJUqFCJj5cvJTw8nDbt2nvnDbzEhE4TGsGMThMawYxOExrBjE4TGsGMTqsbM2cMoGiB/60tL3xvMOVL3EvUuUtERl/klZ6P8tl3uwg/HU2h/MGMeaEFZ85e4Iv/3D1m8gdreaXno/z21zF2//kvHVpUp2ThPDw95D2ffA03WH0uU8uUTm+4A1f2pCnLB+vp0qUjW7ZsST5//PhxRo8ezbx583xY9T+PNG1G9NkoZs+cwenTpyhWvATTZ80mf/57LelJigmdJjSCGZ0mNIIZnSY0ghmdJjSCGZ1WN1YuXYjVc/u7/jz+xScAWPjFFvq9uZQyxfLzdPNq5MiakRMR/9fencdFXS3+H3+PLMMioODCoAmuiEskaCouuF1MDZfcyFLS9NZVc8HIBe9Fc9cyNbevuWWulUteyxCNuBkkKOo15aamgQuKiCKCsgzn90c/psYZtsT5fI6+n/cxj8flzGc+84LpAYfDmY/3EJt4HsOnbsT93D/eL7Zy+/ew09pg8ZSBqO7igDPnr+Hlf6zE5asZJs/3JCn9tSwvWTrJ8jRCqesiltPp06fh5+cHvV5focdV1so6ERHR06R6m/FKJ5TLncSVSic8NewUX5o1du56jtIJBs08HJVOKJPiL9/+/ftLvf/SpUsWKiEiIiKiJ427YCpG8cl6//79odFoSn0T6dN42SIiIiIiorIofjUYnU6H3bt3o6ioyOwtKSlJ6UQiIiIiqiwaFd0koPhk3d/fv9QJeVmr7kRERERETyvFt8GEh4cjJ6fkNxo0atQIMTExFiwiIiIiIlIHxSfrnTp1KvV+R0dHBAYGWqiGiIiIiJ4kjSz7T1RC8W0wRERERERkHifrREREREQqpfg2GCIiIiJ6dvCK3BXDlXUiIiIiIpXiyjoRERERWQwX1iuGK+tERERERCrFyToRERERkUpxGwwRERERWQ73wVQIV9aJiIiIiFSKk3UiIiIiIpXiNhgiIiIishgN98FUCFfWiYiIiIhUipN1IiIiIiKV4jYYIiIiIrIYDXfBVIhGCCGUjngSHhYqXUBERKQ+svzUd207QemEMt1JWKF0QrnYqWxp9mL6A6UTDBrVslc6oUwqe/mIiIiI6GnGhfWK4Z51IiIiIiKV4mSdiIiIiEiluA2GiIiIiCyH+2AqhCvrREREREQqxck6EREREZFKcRsMEREREVmMhvtgKoQr60REREREKsXJOhERERGRSnEbDBERERFZjIa7YCqEK+tERERERCrFlXUiIiIishgurFcMV9aJiIiIiFSKk3UiIiIiIpXiNhgiIiIishzug6kQrqwTEREREakUJ+tERERERCrFbTBEREREZDEa7oOpEK6sl8OuHdvQK6gb2rRqiZDBryDpxHGlk8ySoVOGRkCOThkaATk6ZWgE5OiUoRGQo1PtjSeOJ2LCuLfxt64d8UILb3x35LBFn//dkX/D0c+mIP2HxUg5PA+ffzgajT1rlXj8xxFD8SBpBcYP62IYq+7sgKXvDcTpPRG4/eMHOP/1LHwYPhDOVe0s8BmYUvtrTspQxWT99u3biImJQWZmJgAgIyMDixYtwvvvv4/k5GRF2749+A0WL1yAMX//B3Z9uQ9+fv4Y+9YYpF2/rmjXo2TolKERkKNThkZAjk4ZGgE5OmVoBOTolKHxwYNcNPH2xrQZ/1Lk+Tv5N8Laz39AYOhSvPyPVbCyroIDq8fCwc7W5NjgLi3RpoUnrqffNRrX1XSBrqYLpi/7Cq2HLsSYWdvwtwAfrP3XMAt9Fn+Q4TWvLBqNem4y0AghhJIBCQkJCAoKwr1791CtWjVER0dj8ODBsLa2hhAC165dw9GjR+Hn51eh8z4srJy+10IGw6dZM8z812zDWP/gXujarQcmTp5SOU9SCWTolKERkKNThkZAjk4ZGgE5OmVoBOTofJKNT+Kn/gstvLF0+Sp0696j0s7p2nZChY6vUa0qrnw3Hz1GL8ePSb8axj1quuA/W6YgeNxq7F3xFlZuj8XK7d+XeJ5XeryAjXNHwK3Du9Dri0p9zjsJKyrUWJon+ZrbqWzTc2pmntIJBvVctUonlEnxlfWIiAgMHjwYWVlZmDFjBvr374/u3bvj/PnzuHDhAoYNG4Y5c+Yo0laQn4/kc2fRPqCj0Xj7gA44feqkIk3myNApQyMgR6cMjYAcnTI0AnJ0ytAIyNEpQ6MaOTv9vnXlTlauYUyj0WDD3OH4aMsRJF+6Ub7zVLXHvZyHZU7UKxNfcyqN4pP1EydOICwsDE5OTpg4cSKuX7+OMWPGGO4fN24cEhMTFWm7c/cO9Ho93NzcjMbd3GogI+OWIk3myNApQyMgR6cMjYAcnTI0AnJ0ytAIyNEpQ6MaLQobgB9P/opzv6YZxqa80QOFhUVYtSO2XOdwdXHA9DE9sWH3j08q06xn7TXXqOgmA8X/MJKfnw97e3sAgI2NDRwcHFCjRg3D/W5ubrh9+3ap58jLy0NenvGfVISVFlpt5fxpQ/PIpiYhhMmYGsjQKUMjIEenDI2AHJ0yNAJydMrQCMjRKUOjWnw0bTBaNvZA91HLDWOtfJ7DuFcDETBscbnO4eRoh70r3kbypRuYt+7gk0otFV9zMkfxlfXnnnsOly5dMny8c+dO6HQ6w8dpaWlGk3dzFixYABcXF6PbkkULHruterXqsLKyQkZGhtF4ZuZtuLmV3mRJMnTK0AjI0SlDIyBHpwyNgBydMjQCcnTK0KgmS98biJc7t0DPv3+Ma396A2mHVg1Ry7Uqzn8zG9kJHyE74SN4erhh4eT++N+BSKNzVHXQYv/Kf+B+bh6GTlmPwkLLbYEB+JpT6RSfrIeEhCA9Pd3wcZ8+fQwr7QCwf/9+vPjii6WeY/r06cjKyjK6hU+d/thtNra28GnWHD/FGf857Ke4OPi+0Oqxz19ZZOiUoRGQo1OGRkCOThkaATk6ZWgE5OiUoVEtPpo6CP26+eKlt1Yi5Xqm0X3bv05Am6GL0PbVxYbb9fS7+GjLEQSPW2M4zsnRDgdWj0V+QSEGTV6HvPxKukJFBTxrr7nSV4CR7Wowim+DiYyMLPX+iIgIWFlZlXqMVmu65aWyrgYzPHQkIqa9h2YtWsDXtxV2f7ELaWlpGDw0pHKeoJLI0ClDIyBHpwyNgBydMjQCcnTK0AjI0SlDY25uDlJTUw0fX7t2Ff/7XzJcXFyg03k88edfNm0whvbyx+DJ63E/9yFquzkBALLuP8TDvAJkZuUi809vNgWAgkI9bt7OxoWU3xcJqzpocWD1WNjb2WDkzM/g7GgHZ8ff36h66859FBVZ7oJ5MrzmpAzFJ+tluX37NiIjI7Fx40ZFnv+lXr2RdfcO1q1ZjVu30tGocROsWrsOHh51FOkpiQydMjQCcnTK0AjI0SlDIyBHpwyNgBydMjSe/flnjBk1wvDxh4t/334a3G8A5sxb+MSf/60hnQAA0euNL/E4JnIrtv47oVznaOXzHF5s6QUAOLff+Hrx3n1mITUt08yjngwZXnNShuLXWS/L6dOn4efnB71eX6HHVdbKOhER0dNE3T/1/1DR66wroTKvs/4kqe0661fv5CudYFC3uuk/oqU2ir98+/fvL/X+P7/5lIiIiIjoWaL4ZL1///7QaDQobYGfly0iIiIiejpwWlcxil8NRqfTYffu3SgqKjJ7S0pKUjqRiIiIiEgRik/W/f39S52Ql7XqTkRERET0tFJ8G0x4eDhycnJKvL9Ro0aIiYmxYBERERERPSncBVMxik/WO3XqVOr9jo6OCAwMtFANEREREZF6KL4NhoiIiIiIzFN8ZZ2IiIiInh28GkzFcGWdiIiIiEilOFknIiIiIlIpboMhIiIiIovR8HowFcKVdSIiIiIileLKOhERERFZDhfWK4Qr60REREREKsXJOhERERGRSnEbDBERERFZDHfBVAxX1omIiIiIVIqTdSIiIiIileI2GCIiIiKyGA33wVQIV9aJiIiIiFRKI4QQSkc8CQ8LlS4gIiKip1n1NuOVTiiXBydXKp1gJD27QOkEg1pONkonlInbYIiIiIjIYjS8HkyFcBsMEREREZFKcWWdiIiIiCyHC+sVwpV1IiIiIiKV4mSdiIiIiEiluA2GiIiIiCyGu2AqhivrREREREQqxck6EREREZFKcRsMEREREVmMhvtgKoQr60REREREKsWVdSIiIiKyGP4LphXDlXUiIiIiIpXiZJ2IiIiISKW4DYaIiIiILIZvMK0YrqwTEREREakUJ+tERERERCrFyToRERERkUpxsk5EREREpFKcrJfDrh3b0CuoG9q0aomQwa8g6cRxpZPMkqFThkZAjk4ZGgE5OmVoBOTolKERkKNThkZAjk41Nf7v69l4cHKlye2jaUMMx0S81RuXDs1DZvxSRH0yET4N3BXrJeWpdrLeoEEDXLhwQekMfHvwGyxeuABj/v4P7PpyH/z8/DH2rTFIu35d6TQjMnTK0AjI0SlDIyBHpwyNgBydMjQCcnTK0AjI0am2xo6vL4FXj+mGW++3PwYA7Ik+CQCY8kYPTHi9KyYv/BwdX1+Cm7fv4eu176Cqg1aR3idBo1HPTQYaIYRQMmDFihVmx8PCwvDee+/B3f333yYnTJhQofM+LHzsNADAayGD4dOsGWb+a7ZhrH9wL3Tt1gMTJ0+pnCepBDJ0ytAIyNEpQyMgR6cMjYAcnTI0AnJ0ytAIyNH5JBurtxn/uHlY8u5A9OrUAi36/d536dA8rNoegw83HwYA2NpYI+XIfMxc/hU27P7xLz3Hg5MrH7uzMt19oFc6waCavZXSCWVS/DrrkyZNQp06dWBtbZxSVFSELVu2wMbGBhqNpsKT9cpQkJ+P5HNnMWr0343G2wd0wOlTJy3eUxIZOmVoBOTolKERkKNThkZAjk4ZGgE5OmVoBOToVHujjbUVQnq3wYqt3wEAvOq4QVfTBYfj/2c4Jr+gED+cuIh2vg3+8mRdbTSQZElbJRSfrI8ZMwYJCQnYvn07fHx8DOM2NjY4dOgQmjVrpljbnbt3oNfr4ebmZjTu5lYDGRm3FKoyJUOnDI2AHJ0yNAJydMrQCMjRKUMjIEenDI2AHJ1qb+zb9XlUc7LH1n8fAwC413AGAKRnZhsdl347G/V0rhbvI3VQfM/6//3f/yEyMhI9e/bEypV/7c80eXl5uHfvntEtLy+v0ho1j2xqEkKYjKmBDJ0yNAJydMrQCMjRKUMjIEenDI2AHJ0yNAJydKq1MbR/AKJ+PIe0W1lG44/uUNZoTMfo2aH4ZB0A+vfvj/j4eOzduxe9evXCjRs3KvT4BQsWwMXFxei2ZNGCx+6qXq06rKyskJGRYTSemXkbbm41Hvv8lUWGThkaATk6ZWgE5OiUoRGQo1OGRkCOThkaATk61dxYT1cd3dp6Y/O+OMPYjYx7AIDabs5Gx9Z0dTJZbZeZ0m8qle0NpqqYrANAnTp1cPjwYXTu3BmtWrWq0G+Q06dPR1ZWltEtfOr0x26ysbWFT7Pm+CnOeI/YT3Fx8H2h1WOfv7LI0ClDIyBHpwyNgBydMjQCcnTK0AjI0SlDIyBHp5obh/dtj/TMbBz84axh7Ldrt5F2Kwvd2zU1jNlYW6GTfyP8dPqSEpmkAorvWf8zjUaD6dOnIygoCEePHoVOpyvX47RaLbRa40saVdbVYIaHjkTEtPfQrEUL+Pq2wu4vdiEtLQ2Dh4ZUzhNUEhk6ZWgE5OiUoRGQo1OGRkCOThkaATk6ZWgE5OhUY6NGo8GIfu2w7cAx6PVFRvet2h6D8DeDcDE1HRdTb+G9N3viwcMC7DqovuvXk2WoarJezN/fH/7+/gCAK1euIDIyEhs3blSk5aVevZF19w7WrVmNW7fS0ahxE6xauw4eHnUU6SmJDJ0yNAJydMrQCMjRKUMjIEenDI2AHJ0yNAJydKqxsVtbb9TTueLTfT+Z3Pfh5sOw09pi2fShqO7sgMSff8PL/1iJ+7mV9148pUmy+0Q1FL/OellOnz4NPz8/6PUVuyZnZa2sExEREZlTGddZtwS1XWc9+2FR2QdZiJOdanaEl0jxlfX9+/eXev+lS9yjRURERETPJsUn6/3794dGoyn1DaVquLwSEREREVUCTusqRPG1f51Oh927d6OoqMjsLSkpSelEIiIiIiJFKD5Z9/f3L3VCXtaqOxERERHJQ6Oi/8lA8W0w4eHhyMnJKfH+Ro0aISYmxoJFRERERETqoPqrwfxVvBoMERERPUm8Gsxfcz9PPVPPqlr1r64rvrJORERERM8OXjekYhTfs05EREREROZxsk5EREREpFLcBkNEREREFsNdMBXDlXUiIiIiIpXiZJ2IiIiISKW4DYaIiIiILIf7YCqEK+tERERERCrFlXUiIiIishgNl9YrhCvrRERERETltHr1atSvXx92dnbw9/fHDz/8UOrxsbGx8Pf3h52dHRo0aIC1a9dW6Pk4WSciIiIiKoddu3Zh0qRJiIiIwMmTJ9GpUyf06tULqampZo+/fPkyevfujU6dOuHkyZOYMWMGJkyYgN27d5f7OTVCCFFZn4CaPCxUuoCIiIieZtXbjFc6oVwenFypdIIRNc3R7Cq4Ibxt27bw8/PDmjVrDGM+Pj7o378/FixYYHL81KlTsX//fiQnJxvG3n77bZw+fRrx8fHlek6urBMRERERlSE/Px8nTpxAUFCQ0XhQUBDi4uLMPiY+Pt7k+J49e+L48eMoKCgo1/PyDaZERERE9EzKy8tDXl6e0ZhWq4VWqzU5NiMjA3q9HrVr1zYar127Nm7cuGH2/Ddu3DB7fGFhITIyMqDT6cqOFFQuDx8+FJGRkeLhw4dKp5RIhkYh5OiUoVEIOTplaBRCjk4ZGoWQo1OGRiHk6JShUQg5OmVofNpERkYKAEa3yMhIs8deu3ZNABBxcXFG43PnzhXe3t5mH9O4cWMxf/58o7GjR48KACItLa1cjU/tnvXKdu/ePbi4uCArKwvOzs5K55glQyMgR6cMjYAcnTI0AnJ0ytAIyNEpQyMgR6cMjYAcnTI0Pm0qsrKen58PBwcHfPHFFxgwYIBhfOLEiTh16hRiY2NNHtO5c2e0atUKy5cvN4zt3bsXQ4YMQW5uLmxsbMps5J51IiIiInomabVaODs7G93MTdQBwNbWFv7+/oiOjjYaj46ORkBAgNnHtG/f3uT4Q4cOoXXr1uWaqAOcrBMRERERlUtYWBjWr1+PjRs3Ijk5GZMnT0ZqairefvttAMD06dMxYsQIw/Fvv/02UlJSEBYWhuTkZGzcuBEbNmzAu+++W+7n5BtMiYiIiIjKYejQobh9+zbef/99pKWloUWLFvjmm2/g6ekJAEhLSzO65nr9+vXxzTffYPLkyVi1ahU8PDywYsUKDBw4sNzPycl6OWm1WkRGRpb4pxE1kKERkKNThkZAjk4ZGgE5OmVoBOTolKERkKNThkZAjk4ZGgkYO3Ysxo4da/a+zZs3m4wFBgYiKSnpLz8f32BKRERERKRS3LNORERERKRSnKwTEREREakUJ+tERERERCrFyXoZ/vOf/yA4OBgeHh7QaDTYt2+f0kkmFixYgDZt2sDJyQm1atVC//798csvvyidZWLNmjV4/vnnDdcxbd++PQ4ePKh0VqkWLFgAjUaDSZMmKZ1iZNasWdBoNEY3d3d3pbNMXLt2Da+//jrc3Nzg4OCAF154ASdOnFA6y4iXl5fJ11Kj0WDcuHFKpxkUFhZi5syZqF+/Puzt7dGgQQO8//77KCoqUjrNSHZ2NiZNmgRPT0/Y29sjICAAiYmJijaV9T1cCIFZs2bBw8MD9vb26NKlC86ePauqxj179qBnz56oUaMGNBoNTp06ZdG+8nQWFBRg6tSpaNmyJRwdHeHh4YERI0bg+vXrqmkEfv/e2bRpUzg6OqJ69ero0aMHjh07ZtHG8nT+2VtvvQWNRoNly5ZZrI/UhZP1MuTk5MDX1xcrV65UOqVEsbGxGDduHH766SdER0ejsLAQQUFByMnJUTrNSN26dbFw4UIcP34cx48fR7du3dCvXz+L/2Asr8TERKxbtw7PP/+80ilmNW/eHGlpaYbbmTNnlE4ycufOHXTo0AE2NjY4ePAgzp07hw8//BDVqlVTOs1IYmKi0dex+B+vGDx4sMJlf1i0aBHWrl2LlStXIjk5GYsXL8aSJUvw8ccfK51mZPTo0YiOjsZnn32GM2fOICgoCD169MC1a9cUayrre/jixYuxdOlSrFy5EomJiXB3d8ff/vY3ZGdnq6YxJycHHTp0wMKFCy3WVFJHSZ25ublISkrCP//5TyQlJWHPnj04f/48+vbtq5pGAGjSpAlWrlyJM2fO4OjRo/Dy8kJQUBBu3bqlqs5i+/btw7Fjx+Dh4WGhMlIlQeUGQOzdu1fpjDKlp6cLACI2NlbplDJVr15drF+/XukME9nZ2aJx48YiOjpaBAYGiokTJyqdZCQyMlL4+voqnVGqqVOnio4dOyqdUWETJ04UDRs2FEVFRUqnGPTp00eMGjXKaOyVV14Rr7/+ukJFpnJzc4WVlZU4cOCA0bivr6+IiIhQqMrYo9/Di4qKhLu7u1i4cKFh7OHDh8LFxUWsXbtWgcLSf85cvnxZABAnT560aJM55fl5mJCQIACIlJQUy0Q9ojyNWVlZAoA4fPiwZaLMKKnz6tWrok6dOuLnn38Wnp6e4qOPPrJ4G6kDV9afQllZWQAAV1dXhUtKptfrsXPnTuTk5KB9+/ZK55gYN24c+vTpgx49eiidUqILFy7Aw8MD9evXR0hICC5duqR0kpH9+/ejdevWGDx4MGrVqoVWrVrhk08+UTqrVPn5+di6dStGjRoFjUajdI5Bx44dceTIEZw/fx4AcPr0aRw9ehS9e/dWuOwPhYWF0Ov1sLOzMxq3t7fH0aNHFaoq3eXLl3Hjxg0EBQUZxrRaLQIDAxEXF6dg2dMhKysLGo1GdX9NK5afn49169bBxcUFvr6+SucYKSoqwvDhwxEeHo7mzZsrnUMK4z+K9JQRQiAsLAwdO3ZEixYtlM4xcebMGbRv3x4PHz5E1apVsXfvXjRr1kzpLCM7d+5EUlKS4nttS9O2bVts2bIFTZo0wc2bNzF37lwEBATg7NmzcHNzUzoPAHDp0iWsWbMGYWFhmDFjBhISEjBhwgRotVqjf4pZTfbt24e7d+/ijTfeUDrFyNSpU5GVlYWmTZvCysoKer0e8+bNw6uvvqp0moGTkxPat2+POXPmwMfHB7Vr18aOHTtw7NgxNG7cWOk8s27cuAEAqF27ttF47dq1kZKSokTSU+Phw4eYNm0ahg0bBmdnZ6VzjBw4cAAhISHIzc2FTqdDdHQ0atSooXSWkUWLFsHa2hoTJkxQOoVUgJP1p8z48ePx3//+V7UrWd7e3jh16hTu3r2L3bt3IzQ0FLGxsaqZsF+5cgUTJ07EoUOHTFYI1aRXr16G/9+yZUu0b98eDRs2xKeffoqwsDAFy/5QVFSE1q1bY/78+QCAVq1a4ezZs1izZo1qJ+sbNmxAr169VLc/dNeuXdi6dSu2b9+O5s2b49SpU5g0aRI8PDwQGhqqdJ7BZ599hlGjRqFOnTqwsrKCn58fhg0b9lj/cp8lPPpXFCGEqv6yIpuCggKEhISgqKgIq1evVjrHRNeuXXHq1ClkZGTgk08+wZAhQ3Ds2DHUqlVL6TQAwIkTJ7B8+XIkJSXxv0MCwDeYPlXeeecd7N+/HzExMahbt67SOWbZ2tqiUaNGaN26NRYsWABfX18sX75c6SyDEydOID09Hf7+/rC2toa1tTViY2OxYsUKWFtbQ6/XK51olqOjI1q2bIkLFy4onWKg0+lMfgnz8fFBamqqQkWlS0lJweHDhzF69GilU0yEh4dj2rRpCAkJQcuWLTF8+HBMnjwZCxYsUDrNSMOGDREbG4v79+/jypUrSEhIQEFBAerXr690mlnFV1AqXmEvlp6ebrLaTuVTUFCAIUOG4PLly4iOjlbdqjrw+/fLRo0aoV27dtiwYQOsra2xYcMGpbMMfvjhB6Snp6NevXqGn0MpKSmYMmUKvLy8lM4jBXCy/hQQQmD8+PHYs2cPvvvuO9X+YDRHCIG8vDylMwy6d++OM2fO4NSpU4Zb69at8dprr+HUqVOwsrJSOtGsvLw8JCcnQ6fTKZ1i0KFDB5NLiJ4/fx6enp4KFZVu06ZNqFWrFvr06aN0ionc3FxUqWL87drKykp1l24s5ujoCJ1Ohzt37iAqKgr9+vVTOsms+vXrw93d3XAFIOD3fcyxsbEICAhQsExOxRP1Cxcu4PDhw6rZklcWtf0cGj58OP773/8a/Rzy8PBAeHg4oqKilM4jBXAbTBnu37+PixcvGj6+fPkyTp06BVdXV9SrV0/Bsj+MGzcO27dvx1dffQUnJyfDKpGLiwvs7e0VrvvDjBkz0KtXLzz33HPIzs7Gzp078f333+Pbb79VOs3AycnJZK+/o6Mj3NzcVPUegHfffRfBwcGoV68e0tPTMXfuXNy7d09VWyImT56MgIAAzJ8/H0OGDEFCQgLWrVuHdevWKZ1moqioCJs2bUJoaCisrdX3bTE4OBjz5s1DvXr10Lx5c5w8eRJLly7FqFGjlE4zEhUVBSEEvL29cfHiRYSHh8Pb2xsjR45UrKms7+GTJk3C/Pnz0bhxYzRu3Bjz58+Hg4MDhg0bpprGzMxMpKamGq5ZXvxLsLu7u0X/fYXSOj08PDBo0CAkJSXhwIED0Ov1hp9Frq6usLW1VbzRzc0N8+bNQ9++faHT6XD79m2sXr0aV69etfilWst6zR/9RcfGxgbu7u7w9va2aCephJKXopFBTEyMAGByCw0NVTrNwFwfALFp0yal04yMGjVKeHp6CltbW1GzZk3RvXt3cejQIaWzyqTGSzcOHTpU6HQ6YWNjIzw8PMQrr7wizp49q3SWiX//+9+iRYsWQqvViqZNm4p169YpnWRWVFSUACB++eUXpVPMunfvnpg4caKoV6+esLOzEw0aNBAREREiLy9P6TQju3btEg0aNBC2trbC3d1djBs3Tty9e1fRprK+hxcVFYnIyEjh7u4utFqt6Ny5szhz5oyqGjdt2mT2/sjISNV0Fl9W0twtJiZGFY0PHjwQAwYMEB4eHsLW1lbodDrRt29fkZCQYLG+8nSaw0s3Pts0QghR+b8CEBERERHR4+KedSIiIiIileJknYiIiIhIpThZJyIiIiJSKU7WiYiIiIhUipN1IiIiIiKV4mSdiIiIiEilOFknIiIiIlIpTtaJiIiIiFSKk3UieqI2b94MjUZjuFlbW6Nu3boYOXIkrl27ZpEGLy8vvPHGG4aPv//+e2g0Gnz//fcVOk9cXBxmzZqFu3fvVmofALzxxhvw8vIq87guXbqgRYsWlfKcxa/N8ePHK+V8fz7nb7/9VmnnJCJ6lnGyTkQWsWnTJsTHxyM6OhpjxozBjh070KlTJ+Tk5Fi8xc/PD/Hx8fDz86vQ4+Li4jB79uwnMlknIiIyx1rpACJ6NrRo0QKtW7cGAHTt2hV6vR5z5szBvn378Nprr5l9TG5uLhwcHCq9xdnZGe3atav08xIREVU2rqwTkSKKJ8spKSkAft8GUrVqVZw5cwZBQUFwcnJC9+7dAQD5+fmYO3cumjZtCq1Wi5o1a2LkyJG4deuW0TkLCgrw3nvvwd3dHQ4ODujYsSMSEhJMnrukbTDHjh1DcHAw3NzcYGdnh4YNG2LSpEkAgFmzZiE8PBwAUL9+fcO2nj+fY9euXWjfvj0cHR1RtWpV9OzZEydPnjR5/s2bN8Pb2xtarRY+Pj7YsmXLX/oaluT48eMICQmBl5cX7O3t4eXlhVdffdXwtX7UnTt3MHLkSLi6usLR0RHBwcG4dOmSyXGHDx9G9+7d4ezsDAcHB3To0AFHjhyp1HYiIjLGyToRKeLixYsAgJo1axrG8vPz0bdvX3Tr1g1fffUVZs+ejaKiIvTr1w8LFy7EsGHD8PXXX2PhwoWIjo5Gly5d8ODBA8Pjx4wZgw8++AAjRozAV199hYEDB+KVV17BnTt3yuyJiopCp06dkJqaiqVLl+LgwYOYOXMmbt68CQAYPXo03nnnHQDAnj17EB8fb7SVZv78+Xj11VfRrFkzfP755/jss8+QnZ2NTp064dy5c4bn2bx5M0aOHAkfHx/s3r0bM2fOxJw5c/Ddd989/hf1//vtt9/g7e2NZcuWISoqCosWLUJaWhratGmDjIwMk+PffPNNVKlSBdu3b8eyZcuQkJCALl26GG332bp1K4KCguDs7IxPP/0Un3/+OVxdXdGzZ09O2ImIniRBRPQEbdq0SQAQP/30kygoKBDZ2dniwIEDombNmsLJyUncuHFDCCFEaGioACA2btxo9PgdO3YIAGL37t1G44mJiQKAWL16tRBCiOTkZAFATJ482ei4bdu2CQAiNDTUMBYTEyMAiJiYGMNYw4YNRcOGDcWDBw9K/FyWLFkiAIjLly8bjaempgpra2vxzjvvGI1nZ2cLd3d3MWTIECGEEHq9Xnh4eAg/Pz9RVFRkOO63334TNjY2wtPTs8TnLhYYGCiaN29e5nF/VlhYKO7fvy8cHR3F8uXLDePFr82AAQOMjv/xxx8FADF37lwhhBA5OTnC1dVVBAcHGx2n1+uFr6+vePHFF03O+ejXiIiI/hqurBORRbRr1w42NjZwcnLCyy+/DHd3dxw8eBC1a9c2Om7gwIFGHx84cADVqlVDcHAwCgsLDbcXXngB7u7uhm0oMTExAGCy/33IkCGwti797Tnnz5/Hr7/+ijfffBN2dnYV/tyioqJQWFiIESNGGDXa2dkhMDDQ0PjLL7/g+vXrGDZsGDQajeHxnp6eCAgIqPDzluT+/fuYOnUqGjVqBGtra1hbW6Nq1arIyclBcnKyyfGPfs0CAgLg6elp+JrGxcUhMzMToaGhRp9fUVERXnrpJSQmJiryRmEiomcB32BKRBaxZcsW+Pj4wNraGrVr14ZOpzM5xsHBAc7OzkZjN2/exN27d2Fra2v2vMXbOm7fvg0AcHd3N7rf2toabm5upbYV732vW7du+T6ZRxRvlWnTpo3Z+6tUqVJqY/FYZV3ucNiwYThy5Aj++c9/ok2bNnB2doZGo0Hv3r2Ntg39+bnNjRX3Fn9+gwYNKvE5MzMz4ejoWCn9RET0B07WicgifHx8DFeDKcmfV5uL1ahRA25ubvj222/NPsbJyQkADBPyGzduoE6dOob7CwsLDZPOkhTvm7969Wqpx5WkRo0aAIAvv/wSnp6eJR7358ZHmRv7K7KysnDgwAFERkZi2rRphvG8vDxkZmaafUxJPY0aNQLwx+f38ccfl3gVnUf/QkJERJWDk3UiUrWXX34ZO3fuhF6vR9u2bUs8rkuXLgCAbdu2wd/f3zD++eefo7CwsNTnaNKkCRo2bIiNGzciLCwMWq3W7HHF44+uTvfs2RPW1tb49ddfTbbx/Jm3tzd0Oh127NiBsLAwwy8nKSkpiIuLg4eHR6md5aHRaCCEMPkc1q9fD71eb/Yx27ZtM+qOi4tDSkoKRo8eDQDo0KEDqlWrhnPnzmH8+PGP3UhEROXHyToRqVpISAi2bduG3r17Y+LEiXjxxRdhY2ODq1evIiYmBv369cOAAQPg4+OD119/HcuWLYONjQ169OiBn3/+GR988IHJ1hpzVq1aheDgYLRr1w6TJ09GvXr1kJqaiqioKGzbtg0A0LJlSwDA8uXLERoaChsbG3h7e8PLywvvv/8+IiIicOnSJbz00kuoXr06bt68iYSEBDg6OmL27NmoUqUK5syZg9GjR2PAgAEYM2YM7t69i1mzZpndilKSe/fu4csvvzQZr1mzJgIDA9G5c2csWbIENWrUgJeXF2JjY7FhwwZUq1bN7PmOHz+O0aNHY/Dgwbhy5QoiIiJQp04djB07FgBQtWpVfPzxxwgNDUVmZiYGDRqEWrVq4datWzh9+jRu3bqFNWvWlLufiIgqQOl3uBLR06346iCJiYmlHhcaGiocHR3N3ldQUCA++OAD4evrK+zs7ETVqlVF06ZNxVtvvSUuXLhgOC4vL09MmTJF1KpVS9jZ2Yl27dqJ+Ph44enpWebVYIQQIj4+XvTq1Uu4uLgIrVYrGjZsaHJ1menTpwsPDw9RpUoVk3Ps27dPdO3aVTg7OwutVis8PT3FoEGDxOHDh43OsX79etG4cWNha2srmjRpIjZu3ChCQ0PLfTUYAGZvgYGBQgghrl69KgYOHCiqV68unJycxEsvvSR+/vlnk69D8Wtz6NAhMXz4cFGtWjVhb28vevfubfR1LRYbGyv69OkjXF1dhY2NjahTp47o06eP+OKLL0zOyavBEBFVDo0QQij0ewIREREREZWCl24kIiIiIlIpTtaJiIiIiFSKk3UiIiIiIpXiZJ2IiIiISKU4WSciIiIiUilO1omIiIiIVIqTdSIiIiIileJknYiIiIhIpThZJyIiIiJSKU7WiYiIiIhUipN1IiIiIiKV4mSdiIiIiEil/h/KEvbUVkcEogAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 97.03%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 77.29%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 52.24%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 86.06%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 86.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAMWCAYAAABIgshOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADLzklEQVR4nOzdd1QU198G8GdZqqiIoGCjKKIiSrNEsGuMmtg1lliixm5i770FS2yxxd67xsSfUaPGLvaW2DWKWFCkiAoIssz7hy8bV5aysuzM1edzzpyj0/bhzrJ89+6duypJkiQQEREREZHimMkdgIiIiIiI9GOxTkRERESkUCzWiYiIiIgUisU6EREREZFCsVgnIiIiIlIoFutERERERArFYp2IiIiISKFYrBMRERERKRSLdSIiIiIihWKxTkT0kYiKikK3bt1QpEgRqNVqqFQqjB8/3mSPHxoaCpVKBTc3N5M95qds1apVUKlU+Pbbb+WOQkQ5iMU6fTTCwsIwcOBAeHt7w9bWFjY2NnBxcUFgYCCGDBmCP//8M8Pj//nnH/Tr1w/ly5eHvb09LC0t4eTkhM8//xyzZ89GVFSUzv6HDx+GSqWCSqUyKOe1a9fQo0cPeHp6wsbGBra2tnB3d0fNmjUxZswYhISEpDnGzc1N+1gqlQpmZmbImzcvihUrhs8//xyjR4/GtWvXMnzcmjVr5ljxNn78eKhUKtSsWTNL+7/bdu//TP7+/hg7diyeP3+e7vHvHjdv3rwMH2vAgAHafbNTRBr6/JBDkyZNsGzZMsTFxaFChQoICgqCi4uL3LEUJfUNReryv//9L8P9mzVrpt03q8/vzFy6dAnjx4/Hb7/9ZpTzEdFHTiL6CPz1119Snjx5JACSWq2W3NzcpEqVKkkeHh6SSqWSAEgODg56j01OTpa+//57yczMTAIgmZubS6VLl5YqVqwoubi4SAAkAJKdnZ20f/9+7XGHDh3SbsuqdevWSZaWlhIAycLCQipRooRUsWJFydXVVXuugICANMelbi9ZsqQUFBQkBQUFSQEBATrHAZBatGghRUZG6n3sGjVqSACkcePGZTlvVo0bN04CINWoUSNL+7/bdqk/T2BgoOTi4qK9Xm5ubtKjR4/0Hv/uz1yxYsV0Hyc5OVlydnbW7uvq6mrwz/ahzw9Tu3z5sgRAKlKkiPT8+XNZMjx8+FAqVaqUVLt2bVkePyvu3bun8/xp1apVuvtGR0drf18NeX5nZuXKlRIAqVOnTtk6z6+//iqVKlVKGj58uFFyEZEysWedhPfixQu0bt0aL1++xJdffol///0X9+7dw+nTp3H79m1ER0dj1apVqFy5st7j27Vrh3nz5sHW1hZz585FVFQUrl+/jjNnzuD+/fu4d+8ehg8fjjdv3uDKlSsfnDM0NBRdu3ZFUlISunTpgocPH+LOnTs4c+YMQkNDER4ejvnz58PLyyvdc4wcORLHjx/H8ePHce7cOYSGhuLZs2eYM2cOHB0dsX37dlStWhWxsbEfnNPUUn+eEydO4P79+zh16hQKFSqE0NBQDBkyJMNjS5UqhbNnz+LmzZt6t+/fvx9PnjxBqVKlPjifqZ4f2XXjxg0AQFBQEOzs7GTJUKRIEdy4cQN//fWXLI9vCLVajRIlSuB///tfur8vmzdvRlJSUraePzmpWbNmuHHjBoKDg+WOQkQ5iMU6CW/37t2IjIxE3rx5sWXLFri6uupsz5cvHzp16oQ//vgjzbHLli3Dli1bYGNjg0OHDuGHH35A3rx5dfZxc3NDcHAwzp49Cw8Pjw/OuWnTJiQmJqJUqVJYunQpChYsqLPd2dkZffr0wZo1aww6r6OjI/r164dz586hUKFCuHHjBvr37//BOeVWqVIlTJo0CQCwc+dOaDSadPdt3749AGDdunV6t6eu79ChwwdlMeXzI7sSEhIAADY2NrJlEE379u3x+vVrbNu2Te/2devWQaVS4ZtvvjFxMiKi/7BYJ+HdvXsXAODp6YlcuXJl+TiNRoMpU6YAAMaOHYuAgIAM9/fy8sJXX32V7ZzlypWDmZnxf/VcXV2xcOFCAG+LjAcPHhj9MUylYsWKAIBXr14hMjIy3f1atGgBGxsbrFu3DpIk6WyLi4vDb7/9BhcXF1SvXt3gDMZ6foSEhKB58+ZwcnKCpaUlihYtio4dO+L69et6z5N6b8Hhw4dx48YNtGrVCo6OjrCxsUFAQAC2bNmis3/q+P/UmwxXr16tMyY7VWb3V6TeFxEaGqqzPioqCoMHD0bp0qVhbW0NW1tbuLm5oX79+trnW6rMbjCNiorC0KFDUapUKdjY2MDe3h41a9bE+vXr01w/QPcGysTERIwfPx4eHh6wtrZGsWLFMHDgQMTFxaX7M2Um9c3e2rVr02y7d+8eTpw4gaCgILi7u6d7jlOnTmHo0KGoUKECChYsCCsrKxQrVgwdOnTA1atX0+zv5uaGzp07A0h7rd4dE//u8+DSpUto2bIlnJycYGZmhlWrVqVpn1SJiYkoV64cVCqV9k3vuyRJQq1ataBSqdC9e/esNBMRyYzFOgkvtafz9u3bGd6U+L7Tp08jNDQU5ubmJvmjlZrz0qVLePPmTY48RuPGjVG4cGEkJydj3759OfIYphAfH6/9d0ZvwPLkyYMmTZogNDQUJ06c0Nn266+/Ii4uDt98843BNwEDxnl+LFq0CFWrVsWOHTsAAD4+PoiLi8PatWvh7++v99OeVOfPn0fFihXx559/ws3NDXny5MGFCxfQunVrnU8S7OzsEBQUhJIlSwIAChYsiKCgIO2SHbGxsahcuTJmzpyJe/fuoUSJEihdujQSEhKwb98+jBw5MsvnunPnDvz8/DBjxgyEhobCy8sL+fPnx5EjR9C+fXt8++23egt2AHjz5g3q1auHiRMnwtraGm5ubnj8+DFmz56NZs2affDP5+Hhgc8++wxHjx5FWFiYzrasfirTvn177c/k5OSEMmXK4OXLl1i3bh0qVqyIw4cP6+xfsWLFdK9VuXLl0pz/6NGj+Oyzz/Dnn3+iWLFiGb5xAAArKyusXbsWlpaWmDhxIs6ePauzfebMmTh8+DBKlCiBWbNmZXguIlIIeYfME2XfzZs3tTf/BQQESNu2bcvSDXYzZsyQAEi+vr4f9LiG3mC6f/9+7f516tSRdu/eLcXFxWXp2NQbSVeuXJnpvi1atJAASD169NBZr9QbTPUZO3asBEAqXry43u2pxz548ED6448/JABS9+7ddfb5/PPPJQDS1atXpWPHjhl8g2l2nx8XL16UzM3NJQDS9OnTJY1GI0mSJL1+/Vrq3bu39qbUx48f6xyXep0sLCykvn37SgkJCZIkSVJKSoo0bNgwCYBUuHBhKTk5Wee4zG5azOy5mvocu3fvnnbdTz/9JAGQ6tWrJ0VFRensf//+fWn27Nk661Jv3ny/nVNSUqQKFSponyNPnjzRbtuzZ49ka2srAZAWLlyo92eysLCQvLy8pJs3b2q3nTx5UsqbN68EQNqzZ0+6P9f7UjOq1WpJkiRpwYIFEgDpxx9/1NnP09NTsrKykqKjo6W1a9em+/xevXq19O+//+qse/PmjbRs2TLJ3NxcKl68uPbav/9zZXSDaerzQK1WS927d9d5rYiPj8/0PMHBwRIAydPTU3vsP//8I1lZWUlqtVoKCQlJ97GJSFnYs07C8/T01H7ce/78ebRs2RL29vYoXbo0OnfujM2bNyMxMTHNcY8ePQKATHuqjKVu3braHtq//voLDRs2hJ2dHXx8fNCzZ0/s2rUrw/HZWVWsWDEAQERERLbPZUqSJOHhw4eYNWsWpk2bBgAYMWJEpsfVq1cPBQsWxJYtW7TXOTw8HAcPHoS/v3+GN+xmJLvPj59++gnJyclo0qQJhgwZoh36ZGVlhfnz56Ns2bKIjY3FokWL9B7v5eWFuXPnwtraGgC0wxqcnZ3x+PFj/P333x+UyxC3b98GAPTp0wf58+fX2ebi4pLleyP++usvnDt3DlZWVti0aROcnJy02+rXr49x48YBAKZNm6a3dz05ORmrV6+Gp6endt1nn32G7777DgCwZ88eg36ud7Vu3RoWFhY6Q2FOnz6NW7du4csvv4S9vX2Gx3fs2BHFixfXWWdubo6uXbuiTZs2uHv3Lk6dOvXB+by9vbFo0SKdT5iycl/C0KFDUbVqVdy6dQuDBw9GUlIS2rdvj8TERIwYMQJVqlT54ExEZFos1umjMHLkSBw8eBANGzaEpaUlJEnCzZs3sWrVKrRp0waenp5pPo5++fIlAMDW1tZkORcvXozt27ejRo0aUKvVSE5Oxt9//43FixejUaNG8PHxwT///JOtx0j9eVJ/PqV7d571YsWKYdCgQcibNy/mzZunLcYyYm5ujjZt2uD58+faYSUbNmyARqP54BtLgew/P1KHIX3//fdptqlUKvzwww86+72vS5cuae5tsLCwgI+PD4D/7oHISalv/Hbs2IHk5OQPPk/qz9iqVSs4Ozun2d6zZ09YWVnh/v37emf28fX1RYUKFdKsT723ITtt4eDggAYNGuD69eu4cOECAMNvTL5x4wbGjRuH5s2bo2bNmqhatSqqVq2KI0eOAAAuX778wfnat2//Qfe4mJmZYc2aNciTJw8WLVqEL7/8EpcvX0ZAQADGjh37wXmIyPRYrNNHo1atWvjjjz/w/PlzHD16FDNmzNDeSBUWFoaGDRtqp7cD3o53BpCtG9Q+RPPmzXH48GFER0dj//79mDRpEipVqgQAuHr1KurWrYtnz5598PlfvXoFAGlmLVGq1PG6FStW1PZi2tnZoVq1alk+x/s3Cq5duxZqtRpt27b94FzZeX48f/5cew3T69kvW7YsAODWrVt6t5coUULv+tRZhFKvc07q3Lkz7OzssGrVKhQtWhTffvstli9fbnBxnPozptcWefLk0b4x0NceOd0W7z5/kpOTsXnzZuTPnx8NGzbM9Njg4GCULVsWEydOxI4dO3DkyBGcOHECJ06c0N7kHR0d/cHZypQp88HHuru7Y86cOQCAAwcOaG/GtrCw+OBzEpHpsVinj46NjQ2qVauGwYMH4+DBgzh69ChsbW2RkJCAmTNnavcrUqQIgLezPsghb968qFu3LkaPHo3Tp09j69atMDMzQ0REBJYsWfLB5029Ue79qSGVKnWe9TNnzuDJkycYN24c7ty5g/r162c4E8y7KlasiNKlS2P37t04evQoLl++jM8//1xnuIWhsvP8eLd4TO86pGZL7xOQ9Hr0U3tZ9Q0XMbbChQvj5MmTaNGiBWJjY7F69Wp89913KFGiBKpUqYKTJ09m6Typ7ZHRczKj9sjptmjUqBHs7OywceNG7Nq1C8+ePcPXX38NS0vLDI87evQoRo4cCZVKheDgYFy9ehWvXr1CSkoKJEnCqFGjACBbN5Rn95O/6tWrw9zcHABQpUoVlC5dOlvnIyLTY7FOH72qVauid+/eAIAzZ85o1wcGBgIArly5kq2eL2Np2bIlWrRoAUA3pyFSUlK0BVRqb71ILC0tMX78eDRp0gRPnjzB8OHDs3xs+/btkZSUpB26kJ0hMED2nh+5c+fW/ju9eweePn0K4L8efFNJr7BN7xOEMmXKYNu2bXj+/DkOHTqE8ePHo3Tp0jh16hTq1auXZqpHfVLbI6P7KORqDwCwtrZGq1at8PTpU/Tr1w9A1p4/69evBwAMGTIEw4cPh5eXF2xtbbWzD8k9fapGo0HHjh2RnJwMMzMzHDx4UJuZiMTBYp0+Cak3gCUlJWnXVa5cGW5ubkhOTs5WT7Yx6ctpiN9++w1PnjyBhYUF6tWrZ8xoJhUcHKydT/rOnTtZOqZ9+/baIU+5c+dG06ZNs5UhO8+PfPnyoUCBAgCAa9eu6d0ndQ7ud2+azEmpPbT6hljFxsZm+imGlZUVatasiXHjxuHKlSsICgrCq1evsHHjxkwfO/VnTK8tXr58qS1sTdUe70sdChMWFobixYtr36xlJPWNSnr7pjdW/UOmEv0QP/74I06ePImyZcti8+bNAIC+ffvK/iaCiAzDYp2EFxkZmenH4CEhIQCgnd8YePt146mzjUyaNEl7c1l6rl+/jl27dn1wzqzMzqIvZ1bdv38fffv2BfB2horUYRwiKlOmDBo3bgyNRqOdGSYzrq6u6NGjB+rUqYPBgwcb9AVZ+mT3+fHFF18AAObNm5dmX0mStOtT98tpqW8E3593G3j7Ta2GUKvV2ps7Hz9+nOn+qT/j1q1b8eTJkzTbFy9ejMTERLi6uqJUqVIGZTGW6tWro3nz5qhTpw6GDBmSpWNSZ2VJ/VTgXfv27Uu3WE89LvVbZ3PC+fPnMWnSJFhYWGDdunVo2bIlunXrhufPn2c4pz0RKQ+LdRLeunXr4Ovri6VLlyIqKkpn2/PnzzF27Fjt7A6p3xyYqnv37mjRogXi4+NRq1YtzJs3L82Y2QcPHmD06NGoUKFClnt59fnxxx9RrVo1bNy4Mc1jhIeHo2fPnjh27BhUKhU6deqU5fNGRkbi559/RoUKFRAeHg4vL6+P4stOhg0bBgBYs2YNHj58mKVjFi1ahAMHDminAsyu7Dw/Bg0aBHNzc/z++++YOXMmUlJSALz91KRfv364cuUK7Ozs0KtXL6NkzUyDBg0AAKNHj9YpLvfu3YuJEydqxzW/a9SoUVi+fHmaLxu7cuWK9ptU/f39M33s2rVro2LFikhMTETbtm113rju27cPEyZMAAAMHz7cZL3O71OpVNi+fTsOHDiAnj17ZumYqlWrAgCmTp2qc2/D2bNn0aVLF+20m+97943Tu18AZiwJCQno0KED3rx5gwkTJsDX1xcAMGvWLJQoUQIHDx7E3Llzjf64RJRD5JrgnchY5syZo/3CFwCSu7u7VKlSJalkyZKSpaWldv3gwYP1Hv/mzRupd+/ekkql0n4BS5kyZaRKlSpJbm5u2uPz588v/fXXX9rj3v1iHwcHh3SXmjVrSpIkSf3799fub2ZmJpUsWVKqVKmS5O7urv3yHLVaLc2dOzdNxtQvrClZsqQUFBQkBQUFSRUqVNDJB0Bq1apVmi+vSZX6JSs2NjYZ5t29e7fB1yD1S5HMzc0zPPeoUaPStF1GqlWrJgGQ+vXrp7M+9dgHDx5kKd+HfClSqg99fkiSJC1cuFB7nJOTk1SxYkUpX758EgDJyspK2rVrV5rHS71Ohw4d0punU6dOer8gK7Mv2omIiJCcnZ21j+3r66vNP3z4cL1fitSkSRPt89XDw0OqVKmS5OHhof2Za9WqJb1580a7f3pfiiRJknT79m2paNGi2sf39/fXOVeHDh2klJQUg36m1OdRVr+M692MqV+KlBXpfSlSbGysVLx4cQmAZGlpKZUrV04qVaqUBEDy8vKSBg4cqPeLyDQajVSyZEnta0eVKlWkGjVq6DzPM3seSFL67fP9999LAKTAwMA0X5514sQJSa1WS9bW1tK1a9ey3AZEJB/2rJPwevfujYMHD2LIkCEIDAyERqPBpUuX8OjRI7i6uqJjx444duwYZsyYofd4c3NzLFiwAJcuXULfvn3h6emJx48f4+LFi4iPj0edOnUwd+5c/Pvvv6hdu7bec0RFRaW7xMTEAHjbs/7HH3+gb9++CAgIQFxcHC5evIhnz57B09MTPXv2xIULF7Tzb+tz+/Zt7bRwN27cQHJyMurWrYtRo0bh2rVr2LJlS5ovr3lfQkJChnn1fYFUViUnJ2d4bkOn2EvtXV+6dGm2prPMjuw8P3r16oVjx46hadOmSElJwaVLl5ArVy60b98eFy5cwJdffmmyn6NAgQI4ceIEWrVqhVy5cuHmzZuwt7fHypUrERwcrPeY0aNHY/jw4ahYsSJevXqFS5cuISEhATVq1MCaNWuwb98+vT3y+nh4eODixYsYPHgwXFxccPXqVURERKB69epYu3YtVq9eLVuv+ofKmzcvjh8/jo4dOyJv3ry4efMmkpKSMHDgQJw8eTLdm2XNzMzwxx9/oGXLllCr1Thz5gyOHDmCS5cuZTvTgQMHMH/+fNja2mLNmjVQq9U62wMDAzFs2DC8fv0a7du3z9ZMNURkGipJ4sA1IiIiIiIlYs86EREREZFCsVgnIiIiIlKorA02JKJPRqtWrRAeHp6lfRs2bIiRI0fmcCIiIqJPF4t1ItJx9uxZ3L9/P0v7enh45HAaIiKiTxtvMCUiIiIiUiiOWSciIiIiUigW60RERERECvXRjlm3qTBA7ghZEnNqttwRiISUrBFjBJ+5Wqwv+iGij4+1wqo9G7++ckfQSrg4X+4ImWLPOhERERGRQrFYJyIiIiJSKIV9MEJEREREHzUV+4oNwdYiIiIiIlIoFutERERERArFYTBEREREZDoqzpJlCPasExEREREpFIt1IiIiIiKF4jAYIiIiIjIdzgZjELYWEREREZFCsWediIiIiEyHN5gahD3rREREREQKxWKdiIiIiEihOAyGiIiIiEyHN5gahK1FRERERKRQLNaJiIiIiBSKw2CIiIiIyHQ4G4xB2LNORERERKRQn3SxPvjbOji+egAijgTj/r6J2PJTF5R0LZDu/vNGtkLCudno27a6znpLCzVmDWmOBwcmIfLYVGyd1RVFCtrldPw0Nm9cjwb1aqOiXzm0adUcF86fM3mGzIiQERAjpwgZAWXnXLxwHgLKl9ZZ6tWqKnesdCm5LVOJkBEQI6cIGQExcoqQERAnZ7apzJSzCECMlDmkmn8J/LL1OGp0nouv+vwCtdoMu+b3RC5ryzT7NqrhjYplXfE44nmabTMGNUPjmuXQceRa1PluHnLbWGH77G4wMzPdxzx79+zG9KnB6Na9FzZv+w3+/gHo3aMbwh8/NlmGzIiQERAjpwgZATFylihREn8ePKZdNm/fKXckvURoSxEyAmLkFCEjIEZOETIC4uQk0/uki/UmPyzBul1ncf3uE/xz+zF6TNgIl0L54VemqM5+hQvYYfbQFug8Zh3eJKfobMtra41vm1TG8Dm/49CZW7h88xG6jFkHb49CqF3J02Q/y9rVK9GsRQs0b9kKxUuUwNARo+BcyBlbNm80WYbMiJARECOnCBkBMXKqzdVwdCygXezz55c7kl4itKUIGQExcoqQERAjpwgZAXFykul90sX6+/LmtgEAxLyI165TqVRYPvEbzF57CNfvPklzjF+ZorC0MMeBUze168IjX+Dqv+H4rLx7zocG8CYpCdevXUWVQN2P76sEBuHypYsmyZAZETICYuQUISMgTs6w+/fxRZ1qaFS/DkYMHYiHDx/IHSkNEdpShIyAGDlFyAiIkVOEjIA4OY1GpVLOIgDOBvOOaQOb4MTFu7j2739F+aBOtZGsScGCTUf1HuPskBeJScl4/jJBZ31E9Cs4OebJ0bypYp7HQKPRwMHBQWe9g4MjIiOfmSRDZkTICIiRU4SMgBg5vcv5YOKUqXBxdUN0dBSWL1mELh3aYsuO/yFfPnu542mJ0JYiZATEyClCRkCMnCJkBMTJSfJQfLH+4MEDjBs3DitWrEh3n8TERCQmJuqsk1KSoTLL+o83e2gLlPMojDrf/axd51e6KPq0qY7A9jMNzq1SAZJk8GHZonrvHaIkSWnWyU2EjIAYOUXICCg7Z1A13ZvFy5f3RZMv62HXzt/QvmNnmVKlT8ltmUqEjIAYOUXICIiRU4SMgDg5ybQUPwwmOjoaq1evznCf4OBg2NnZ6SzJT85m+TFmDWmOr6qXxRc9F+BRRKx2fZBfcRTMnxu3do3Fy1M/4eWpn+BaOD+m9m+CGzvHAACeRL2AlaU58uWx0TlnAfvciIh6acBP+uHs89lDrVYjMjJSZ310dBQcHBxNkiEzImQExMgpQkZAnJzvssmVCx4lPRF2/77cUXSI0JYiZATEyClCRkCMnCJkBMTJaTRyzwDD2WAMs3PnzgyXQ4cOZXqOESNGIDY2Vmcxd66YpcefPbQ5mtQqh/q9FuL+42idbRt2n0PFtjNQ+ZuftMvjiOeYvfYQGn3/CwDg4vWHSHqTjDqVS2mPc3bIi7IlCuHU3/cMaIkPZ2FpiTJeZXEq5ITO+lMhIfDx9TNJhsyIkBEQI6cIGQFxcr4rKSkJ9+7+C8cC6U/hKgcR2lKEjIAYOUXICIiRU4SMgDg5SR6yD4Np2rQpVCoVpAzGjGT2EZCVlRWsrKx0j8nCEJg5w1qgdf0AtBq0HK/iE+Hk8HaMeeyr13id+AbRsfGIjo3XOeZNcgqeRr3A7ftvx5C9iHuNVb+fxtT+jREVG4eYF/EI7tcYV+6E4+CZW5lmMJYOnTpj1PCh8PL2ho+PH7Zv3Yzw8HC0at3GZBkyI0JGQIycImQElJ9z9k/TUL1mLTg7F9aOWY+Le4VGjZvKHS0NpbclIEZGQIycImQExMgpQkZAnJxkerIX64UKFcKCBQvQtGlTvdsvXbqEgICAHHnsHq3e3nW9f0lfnfXdxm/Aul1ZH0YzdNZv0GhSsC64E2ysLXDozG10n7AMKSmmG7Rev0FDxD6PwZJFC/HsWQQ8SnpiwS9LULhwEZNlyIwIGQExcoqQEVB+zoiIpxg5bBCexzyHfX57lCvng1XrNqOQQvK9S+ltCYiRERAjpwgZATFyipARECenUXAcvkFUUkZd2ibQuHFj+Pr6YuLEiXq3X758GX5+fkhJSdG7PT02FQYYI16Oizk1W+4IREJK1sj60pVl5mr+USIieVnL3jWryyZolNwRtBJOTJE7QqZkv3xDhgxBXFxcuts9PDyyNG6diIiIiAQgyI2dSiF7sV6tWrUMt9va2qJGjRomSkNEREREpBx8a0NEREREpFCy96wTERER0SeEN5gahD3rREREREQKxWKdiIiIiEihOAyGiIiIiEyHs8EYhK1FRERERKRQLNaJiIiIiBSKw2CIiIiIyHQ4DMYgbC0iIiIiIoVizzoRERERmY4Z51k3BHvWiYiIiIgUisU6EREREZFCcRgMEREREZkObzA1CFuLiIiIiEihWKwTERERESkUh8EQERERkemoOBuMIdizTkRERESkUCzWiYiIiIgU6qMdBhNzarbcEbLE/vNJckfIVMz+MXJH+GikpEhyR8iSJE2K3BEyZW2hljvCR0OU56UZv0iF6OPA2WAMwtYiIiIiIlKoj7ZnnYiIiIgUiDeYGoQ960RERERECsVinYiIiIhIoTgMhoiIiIhMhzeYGoStRURERESkUCzWiYiIiIgUisNgiIiIiMh0OBuMQdizTkRERESkUOxZJyIiIiLT4Q2mBmFrEREREREpFIt1IiIiIiKF4jAYIiIiIjId3mBqEPasExEREREpFIt1IiIiIiKF4jAYIiIiIjIdzgZjELYWEREREZFCsVgnIiIiIlIoFutZsHnjejSoVxsV/cqhTavmuHD+nKx5bmz8HgmHxqRZZverDwBoUq00dk5vhwe/DULCoTEoX8JJ1rzvUlpbpkfpOc+fO4t+fXvi89rV4FeuNA79dUDuSGls37IJ37RqilpBFVErqCK6dmyLkONH5Y6ll9Kvdyql5xTheZlK6W0JiJERECOnCBkBcXJmm0qlnEUALNYzsXfPbkyfGoxu3Xth87bf4O8fgN49uiH88WPZMlXtuRxuzWdpl4aD1gEAfj18HQCQy9oCJ688wJglf8mWUR8ltqU+IuRMSEiAp2dpDB85Ru4o6Sro5ITePwzA6g1bsXrDVlSoWBlD+vfF3Tu35Y6mQ4TrDYiRU4TnJSBGW4qQERAjpwgZAXFykumxWM/E2tUr0axFCzRv2QrFS5TA0BGj4FzIGVs2b5QtU2RsPJ7GxGmXhlVK4t9H0Th2+T4AYOP+fxC85hgOnr8nW0Z9lNiW+oiQs2q16ujzQ3/UqVtP7ijpqlajFoKq1YCLqxtcXN3Q6/v+yJUrF67887fc0XSIcL0BMXKK8LwExGhLETICYuQUISMgTk6jUJkpZxGAGCll8iYpCdevXUWVwKo666sEBuHypYsypdJlYW6GNp+Xw+o9l+SOkiER2hIQJ6doNBoN9u3djYSEBHiX95E7jpYo11uUnCIQoS1FyAiIkVOEjIA4OUkenLoxAzHPY6DRaODg4KCz3sHBEZGRz2RKpatx1dLIl9sa6/ZeljtKhkRoS0CcnKK4c/sWvuvYFklJSbCxyYVps35G8RIecsfSEuV6i5JTBCK0pQgZATFyipARECcnyUMRPesJCQk4fvw4rl27lmbb69evsWbNmgyPT0xMxIsXL3SWxMREo+VTvXcDgiRJadbJpVNDX/x5+g7Co17JHSVLlNyW7xIlp9K5urlh7eZfsXzNRjT/ujUmjh2Ju//ekTtWGqJcb1FyikCEthQhIyBGThEyAuLkzDa5h75wGIxhbt26hTJlyqB69eooV64catasifDwcO322NhYdO7cOcNzBAcHw87OTmeZMS0429ns89lDrVYjMjJSZ310dBQcHByzff7scnGyQ21/d6zarfyPyJTelqlEySkKCwtLFHNxRZmy3ujzw0CU9CyFzRvWyh1LS5TrLUpOEYjQliJkBMTIKUJGQJycJA/Zi/Vhw4ahXLlyiIiIwM2bN5E3b14EBQUhLCwsy+cYMWIEYmNjdZYhw0ZkO5uFpSXKeJXFqZATOutPhYTAx9cv2+fPrg71fRDxPA57Tiprdg19lN6WqUTJKSpJkvAm6Y3cMbREud6i5BSBCG0pQkZAjJwiZATEyUnykH3MekhICA4cOABHR0c4Ojpi586d6NOnD6pVq4ZDhw7B1tY203NYWVnByspKZ93rZOPk69CpM0YNHwovb2/4+Phh+9bNCA8PR6vWbYzzAB9IpQI61vfB+j//hiZF0tlmn8caxQraoZBjHgCAp8vbMXBPo1/haUycybOmUmpbvk+EnPHxcXjwzhvaR48e4uaN68hrZ4dChQrLmOw/C3+ejSpVq8HJqRDi4+Owf+9uXDh3FnMWLJE7mg4RrjcgRk4RnpeAGG0pQkZAjJwiZATEyWkUH+PQnhwke7GekJAAc3PdGAsWLICZmRlq1KiBDRs2yJTsrfoNGiL2eQyWLFqIZ88i4FHSEwt+WYLChYvImqt2QHG4OOfTOwvMl4GeWDq8ifb/a8e2AABMXnUEU1bL96U0Sm3L94mQ89rVK+jWpZP2/zNnTAUANGrcFBOnTJUrlo7o6ChMGDUckZHPkDt3Hnh4emLOgiWoXCVQ7mg6RLjegBg5RXheAmK0pQgZATFyipARECcnmZ5KkiQp891yTqVKlfD999+jQ4cOabb17dsX69evx4sXL6DRaAw6r7F61nOa/eeT5I6QqZj9yv6CE5GkpMj665ZlSZoUuSNkytpCLXeEj4Yoz0szM/bGEX0Ia9m7ZnXZNF4kdwSthJ295I6QKdnHrDdr1gwbN+qf8H/+/Plo27YtZH4/QURERETGIvcMMILNBiN7z3pOYc+68bBn3XhE6cFkz/qnRZTnJXvWiT6M4nrWmyyWO4JWwu895I6QKYVdPiIiIiL6qPEGU4OI0f9PRERERPQJYrFORERERKRQHAZDRERERKYjyI2dSsHWIiIiIiJSKBbrREREREQKxWEwRERERGQ6nA3GIOxZJyIiIiJSKPasExEREZHJqNizbhD2rBMRERERKRSLdSIiIiIiheIwGCIiIiIyGQ6DMQx71omIiIiIFIrFOhERERGRQnEYDBERERGZDkfBGIQ960RERERECsVinYiIiIhIoTgMhoiIiIhMhrPBGIbFusxi9o+RO0Km7IOGyB0hS2JOzJA7QqbMzMR4gbI2U8sdgUxIlD+cbzQpckfIlIWaH1gTkXGxWCciIiIikxGlg0Ap2AVARERERKRQLNaJiIiIiBSKw2CIiIiIyGQ4DMYw7FknIiIiIlIoFutERERERArFYTBEREREZDIcBmMY9qwTERERESkUi3UiIiIiIoXiMBgiIiIiMh2OgjEIe9aJiIiIiBSKPetEREREZDK8wdQw7FknIiIiIlIoFutERERERArFYTBEREREZDIcBmMY9qwTERERESkUi3UiIiIiIoXiMBgiIiIiMhkOgzEMe9azYPPG9WhQrzYq+pVDm1bNceH8Obkj6SVnzsGdauH4yh8QcXAS7u8Zhy3TO6GkSwGdfZrU9MbOud/hwZ/jkXB6BsqXLJzmPO5FHLB5WieE7R2HpwcnYd2U9iiYP7epfgwtEa65CBkBMXKKkBFQfs7z587ihz498XmtqvD1LoWDfx2QO5JeEU+fYsyIoahT7TMEVfJDu1bNcP3aVbljpaH0651KhJwiZATEyUmmxWI9E3v37Mb0qcHo1r0XNm/7Df7+AejdoxvCHz+WO5oOuXNW8yuBX7aFoEbX+fjqhyVQq82w6+duyGVtod0nl40lTv4dijELdus9Ry5rC+z6uRskSUKDPotRu9sCWFqosf2nziZ9Fy53W2aFCBkBMXKKkBEQI2dCQjw8S5XC8JFj5Y6SrhcvYtG1UzuYm5tj7sIl2LpjF/oPGoo8efLIHU2HCNcbECOnCBkBcXKS6akkSZLkDpETXicb5zzftGmFMl5eGD12gnZd00YNUKt2XfQbMMg4D2IEOZnTPmiIwcc45rPFgz/Ho26PhThx6Z7ONpdC9rj520hUbj8bf9/+70WoTmVP/D67Kwp9PhYv4xIBAPny2CD8wEQ07LsEh87ezvAxY07MMDinPiJccxEyAmLkFCEjkLM5c+KvgK93KcyauwC169Q12jmTU1KyfY55c2bi8sWLWLZ6nRESpWWhNk4fGJ+XxiNCRiBnc1orbNCzQ8eNckfQilrTVu4ImWLPegbeJCXh+rWrqBJYVWd9lcAgXL50UaZUaSkxZ97c1gCAmBfxWT7GykINSZKQmPTfO63XSW+g0aQg0MfN2BH1UmJbvk+EjIAYOUXICIiTUwRHDx9CmbJlMWxQf3xeIwjtvm6OHdu2yB1LhyjXW4ScImQExMlJ8mCxnoGY5zHQaDRwcHDQWe/g4IjIyGcypUpLiTmn9WuEE5fu4trdp1k+5syVMMS9TsKUvl/CxsoCuawtEPz9V1CrzeDsmDcH0/5HiW35PhEyAmLkFCEjIE5OETx6+ADbt2yCi4sr5v2yFC1atcZP037Erp2/yR1NS5TrLUJOETIC4uQ0GpWCFgEo4oOR69ev49SpU6hSpQpKly6NGzduYO7cuUhMTET79u1Ru3btDI9PTExEYmKizjpJbQUrKyuj5Ht/vLQkSYq8k1kpOWcPaYZyHoVQp8dCg46LfB6Hb0auw89Dm6P310FISZGwZf8lXLjxEBpN9j/+NoRS2jIjImQExMgpQkZAnJxKlpIiwatsWfTpNwAAULqMF+7+ewfbt2zCV42byhvuPaJcbxFyipARECcnmZbsPet79+6Fr68vBg8eDD8/P+zduxfVq1fHnTt3EBYWhi+++AIHDx7M8BzBwcGws7PTWWZMC852Nvt89lCr1YiMjNRZHx0dBQcHx2yf31iUlHPWoCb4qpoXvuj9Cx5FxBp8/F+nb6Fsi6lwqT8BRb8Yj67jN6FwATvcD4/OgbRpKakt0yNCRkCMnCJkBMTJKQLHAo5wL15CZ527e3E8eRIuU6K0RLneIuQUISMgTk6Sh+zF+sSJEzFkyBBERUVh5cqVaNeuHbp164b9+/fjwIEDGDp0KKZOnZrhOUaMGIHY2FidZciwEdnOZmFpiTJeZXEq5ITO+lMhIfDx9cv2+Y1FKTlnD26KJjXLoX6fxbgfHpOtc0XFxiP21WvUCCiBgva22HX0mpFSZkwpbZkRETICYuQUISMgTk4R+Pj6435oqM66+/dDUahQ2qlk5SLK9RYhpwgZAXFyGotKpVLMIgLZh8FcvXoVa9asAQB8/fXX6NChA1q0aKHd3rZtWyxfvjzDc1hZpR3yYqzZYDp06oxRw4fCy9sbPj5+2L51M8LDw9GqdRvjPICRyJ1zzpBmaP2FH1oNWYVXcYlwyv92GrTYuAS8Tnx7Mezz2qCYkz0KFXg7/tzT9e087E+jXuJp9Mu3P8dXFXAzNALPYuJQuZwrfhrYGPM2HsPtMNON2ZO7LbNChIyAGDlFyAiIkTM+Pg5hYWHa/z969BA3blyHnZ2dYorhdh06oUvHdlixdDE+/6I+rv7zD3Zs24pR4yZkfrAJiXC9ATFyipARECcnmZ7sxfq7zMzMYG1tjXz58mnX5cmTB7Gxhg+nMJb6DRoi9nkMlixaiGfPIuBR0hMLflmCwoWLyJZJH7lz9mgZCADY/0svnfXdJm7Guj/efqnDl9XKYunY1tpta6e0BwBMXroPU5btBwB4uhTAxN4NkT+vDe6Hx2D6yoP4eeNRU/wIWnK3ZVaIkBEQI6cIGQExcl69cgXdunTU/n/m9LfDERs1aYZJUzL+hNRUynqXw0+zf8b8ubOxbPFCFC5SFIOGDkeDLxvJHU2HCNcbECOnCBkBcXKS6ck+z7qPjw+mTZuG+vXrAwCuXLmC0qVLw9z87fuI48ePo2PHjrh7965B5zVWzzp92DzrcjDWPOtEnxpRvm3DGPOs5zRjzbNOZExKm2e9QOfNckfQeraydeY7yUz2y9erVy9oNBrt/729vXW279mzJ9PZYIiIiIiIPkayF+s9e/bMcPuUKVNMlISIiIiIcpooN3YqBT+vIyIiIiLKooULF8Ld3R3W1tYICAjAsWPHMtx//fr18PHxQa5cuVCoUCF07twZUVFRWX48FutERERERFmwefNm9O/fH6NGjcLFixdRrVo1NGjQQGcmrHel3nvZtWtXXL16FVu3bsXZs2fx3XffZfkxWawTERERkemoFLQYaNasWejatSu+++47lClTBnPmzEGxYsWwaNEivfufOnUKbm5u+OGHH+Du7o6qVauiR48eOHfuXJYfk8U6EREREVEmkpKScP78edSrV09nfb169RASEqL3mMDAQDx8+BC7d++GJEl4+vQptm3bhi+//DLLj8tinYiIiIg+SYmJiXjx4oXOkpiYqHffyMhIaDQaODk56ax3cnLCkydP9B4TGBiI9evXo3Xr1rC0tISzszPy5cuHefPmZTkji3UiIiIiMhmVSqWYJTg4GHZ2djpLcHBwpvnfJUlSujPcXLt2DT/88APGjh2L8+fPY+/evbh3716msyG+S/apG4mIiIiI5DBixAgMHDhQZ52VlZXefR0dHaFWq9P0okdERKTpbU8VHByMoKAgDBny9gsmy5cvD1tbW1SrVg2TJ09GoUKFMs3InnUiIiIi+iRZWVkhb968Okt6xbqlpSUCAgKwf/9+nfX79+9HYGCg3mPi4+NhZqZbbqvVagBve+Szgj3rRERERGQyIn8p0sCBA9GhQwdUqFABVapUwZIlSxAWFqYd1jJixAg8evQIa9asAQA0atQI3bp1w6JFi/DFF18gPDwc/fv3R6VKlVC4cOEsPSaLdSIiIiKiLGjdujWioqIwceJEhIeHw9vbG7t374arqysAIDw8XGfO9W+//RYvX77E/PnzMWjQIOTLlw+1a9fGtGnTsvyYKimrffCCeZ0sd4KPh33QELkjZEnMiRlyRyASkih/BZJTUuSOkCkLNUeXkvJYK6xrtlD37XJH0Apf0kLuCJniqwoRERERkUKxWCciIiIiUiiFfTBCRERERB8zkW8wlQN71omIiIiIFIrFOhERERGRQnEYDBERERGZDkfBGIQ960RERERECsWedcpU1PHpckfIEvvK/eSOkKmY03PljpAlIsy7zfuTjEeUtuQc5kT0KWKxTkREREQmw9lgDMNuCiIiIiIihWLPOhERERGZDHvWDcOedSIiIiIihWKxTkRERESkUBwGQ0REREQmw2EwhmHPOhERERGRQrFYJyIiIiJSKA6DISIiIiLT4SgYg7BnnYiIiIhIoVisExEREREpFIfBEBEREZHJcDYYw7BnnYiIiIhIodizTkREREQmw551w7BnnYiIiIhIoVisExEREREpFIfBEBEREZHJcBiMYdizTkRERESkUCzWs2DzxvVoUK82KvqVQ5tWzXHh/Dm5I+ml9JzLly7GN61bIqiSP2pXD8SAH/og9N5dk2YI8iuBbbO74e7eiUg4PxeNapbT2W5rY4nZQ1vgzu4JiD4xAxe3jUC3lkHa7S6F8iPh/Fy9S/O6vib9WZR+vc+fO4sf+vTE57Wqwte7FA7+dUDuSOlSelumEiGnCBkBMXKKkBEQI6cIGQFxcpJpsVjPxN49uzF9ajC6de+Fzdt+g79/AHr36Ibwx4/ljqZDhJwXzp1F67btsGbDZixasgKa5GT06v4dEuLjTZbB1sYS/9x6hAHTtundPn1QM3weWAadx6yFb8tgzFt/GLOGtMBXNbwBAA+fxsCt3midZeIvu/EqPhF/nrhmsp9DhOudkBAPz1KlMHzkWLmjZEiEtgTEyClCRkCMnCJkBMTIKUJGQJycxqBSqRSziIDFeibWrl6JZi1aoHnLViheogSGjhgF50LO2LJ5o9zRdIiQc8HiZWjctDlKeJREqdKlMX5yMJ6EP8a1a1dNlmFfyHVMWLQbvx/6W+/2yuXcsW7XGRw7fwdh4dFYseMk/r79GP5eLgCAlBQJT6Ne6iyNa5bHtn0XEZeQZLKfQ4TrXbVaDfT9YQDqfF5P7igZEqEtATFyipARECOnCBkBMXKKkBEQJyeZniKLdUmS5I4AAHiTlITr166iSmBVnfVVAoNw+dJFmVKlJUrO97169RIAYGdnJ3OS/4RcuouvqpdD4QJvM1Wv4IGSLgVw4OQNvfv7lS4K39JFsfr3kybLKOr1ViJR2lKEnCJkBMTIKUJGQIycImQExMlpNCoFLQJQ5GwwVlZWuHz5MsqUKSNrjpjnMdBoNHBwcNBZ7+DgiMjIZzKlSkuUnO+SJAkzp0+Fn38APEp6yh1Ha9CM7Vg4pg3+3TsRb5I1SEmR0GvSRoRc0j+2vlPTKrh+9wlO/R1qsowiXm+lEqUtRcgpQkZAjJwiZATEyClCRkCcnCQPWYv1gQMH6l2v0WgwdepU7ZN21qxZGZ4nMTERiYmJOusktRWsrKyMkvP9MU2SJClynJMoOQFg6pRJuH3rJlau2SB3FB192lZHJW9XtOi/BGHhMajqXwJzh7fCk8gXOHTmls6+1lYWaF3fH1OX7ZMlq0jXW+lEaUsRcoqQERAjpwgZATFyipARECcnmZasxfqcOXPg4+ODfPny6ayXJAnXr1+Hra1tlp6kwcHBmDBhgs66UWPGYfTY8dnKZ5/PHmq1GpGRkTrro6Oj4ODgmK1zG5MoOVNN/XESjhw6iOWr18HJ2VnuOFrWVhaY0OcrtB68HHuPv71Z9Mqdxyhfqgj6d6idplhvVscHuawtsX7XGZPmFO16K5kobSlCThEyAmLkFCEjIEZOETIC4uQ0Fr4BMYysY9anTJmC2NhYjBkzBocOHdIuarUaq1atwqFDh3Dw4MFMzzNixAjExsbqLEOGjch2PgtLS5TxKotTISd01p8KCYGPr1+2z28souSUJAlTp0zEwQP7sXjFKhQpWlTuSDoszM1gaWGOlBTdeyY0mhSYmaV9Yfm2yWf448gVRD6PM1VEAOJcbxGI0pYi5BQhIyBGThEyAmLkFCEjIE5OkoesPesjRoxA3bp10b59ezRq1AjBwcGwsLAw+DxWVmmHvLxONk7GDp06Y9TwofDy9oaPjx+2b92M8PBwtGrdxjgPYCQi5AyePBF7du/C7J8XwNbWVjsOL3fuPLC2tjZJBlsbS5QoVkD7f7fCDijvWQQxL+Lx4EkMjp67jR/7NUFC4huEhUejWoAHvvmyIobN/k3nPMWLOqKqfwk0/WGxSXK/T4TrHR8fh7CwMO3/Hz16iBs3rsPOzg6FChWWMZkuEdoSECOnCBkBMXKKkBEQI6cIGQFxcpLpyX6DacWKFXH+/Hn06dMHFSpUwLp16xT18Uj9Bg0R+zwGSxYtxLNnEfAo6YkFvyxB4cJF5I6mQ4ScW/9/+qlunTvqrJ8w+Uc0btrcJBn8vVywb8n32v9PH9QMALD2f6fRffwGdBy5GhP7NsKqyR1gnzcXwp7EYPzCP7B0m25vR6cmn+FxRCwOnLppktzvE+F6X71yBd26/HetZ04PBgA0atIMk6ZMlStWGiK0JSBGThEyAmLkFCEjIEZOETIC4uQ0BiXVeSJQSUqZJxHApk2b0L9/fzx79gz//PMPvLy8PvhcxupZJyBFOU+RDDl81l/uCJmKOT1X7ghZIsIl52s9EVHWWMveNaurxKA9ckfQ+ndmA7kjZEpRl69NmzaoWrUqzp8/D1dXV7njEBERERHJSlHFOgAULVoURRV24yERERERGQc/GTWMIr/BlIiIiIiIFNizTkREREQfL95gahj2rBMRERERKRSLdSIiIiIiheIwGCIiIiIyGY6CMQx71omIiIiIFIrFOhERERGRQnEYDBERERGZDGeDMQx71omIiIiIFIrFOhERERGRQnEYDBERERGZDEfBGIY960RERERECsWedSIiIiIyGTMzdq0bgj3rREREREQKxWKdiIiIiEihOAyGiIiIiEyGN5gahj3rREREREQKxWKdiIiIiEihOAxGZimSJHeETJkJ8nlVRMhsuSNkqsaMI3JHyJL5rX3ljpAp72J2ckf4aGhSlP86BABqAWaQEOHlUoS/OwCQrFF+Tktz9nl+CJUIvygKwmcZEREREZFCsVgnIiIiIlIoDoMhIiIiIpPhKBjDsGediIiIiEih2LNORERERCbDG0wNw551IiIiIiKFYrFORERERKRQHAZDRERERCbDYTCGYc86EREREZFCsVgnIiIiIlIoDoMhIiIiIpPhKBjDsGediIiIiEih2LNORERERCbDG0wNw551IiIiIiKFYrFORERERKRQHAZDRERERCbDUTCGYc86EREREZFCsVgnIiIiIlIoDoPJgs0b12PVyuWIfPYMJTxKYujwkfAPqCB3LK3lSxfj4IH9CL13F1bW1vDx9UO/AYPg5l5c7mhpKL0tASDi6VPMmzMTIceP4nViIlxd3TBmwmSU8Sprksf3LWaH9pWLobRzbhTIY4Uh267g6O0onX3cHHKhTy13+BfLB5UKuBcZj5G/XcPTF4nIa22ObtXcUNndHk55rfA8/g2O3I7E4qOhiEvU5Fju7euWYMf6ZTrr7OzzY8GGvdr/Pwq7h00r5uPGPxcgSRKKuBTH9yN/hGNB5xzLlZnz585i9crluH7tCp49e4ZZcxegdp26suXRR4SMixfOw5JfFuisc3BwxL5Dx2VKpJ8IbZlK6a+XIvztSU5OxtJf5mPvH7sQFRUJB8cC+KpxU3Tt3gtmZsrrr1T6NTcWzgZjGBbrmdi7ZzemTw3GqDHj4Ovnj21bNqF3j27YsfMPFCpcWO54AIAL586iddt2KOtdDsnJGiz4eTZ6df8Ov/6+Cza5cskdT0uEtnzxIhZdO7VDhYqVMXfhEuTP74CHD8KQJ08ek2WwsVDjdsQr7Pr7Caa1SPsGoUg+ayzp4Iudl59g6bH7eJWYDHeHXEhKTgEAOOa2RIHclvj54F3ci4yDs501htcviQK5rTBix7UczV7UtTiG/zhf+38zM7X2308fP8Skwd1Q44vGaNG+O3LZ5sajB/dgYWmZo5kyk5AQD89SpdCkaXMMGvC9rFnSI0JGAChRoiQWLl2h/b/6neuvFKK0pQivlyL87Vmzchm2b92M8ZOCUbxESVy/dgUTx45E7jx50PabjnLH0yHCNSd5sFjPxNrVK9GsRQs0b9kKADB0xCiEhBzHls0b0W/AIJnTvbVgsW5v5vjJwahTPRDXrl1FQIWKMqVKS4S2XL1iGZycCmHcpB+16woXKWLSDCfvRuPk3eh0t/eq4Y6Qf6Mx/9Bd7brHz19r/303Mh7D3ynKHz1/jUVH7mFCozJQqwCNlDO5AcBMrUa+/I56t21dvQg+FYPQtusP2nUFC5m2bfWpWq0GqlarIXeMDImQEQDU5mo4OhaQO0aGRGlLEV4vRfjb88/lS6hRszaqVq8J4O3r+Z97/sD1q1fkDaaHCNec5KG8z4AU5E1SEq5fu4oqgVV11lcJDMLlSxdlSpW5V69eAgDs7OxkTvIfUdry6OFDKFO2LIYN6o/PawSh3dfNsWPbFrljaakABJbIj7DoeMxtXQ57fqiC5Z38UL2kQ4bH5bYyR1xSco4W6gDw9NED9P2mIQZ82wTzg0chIvwRACAlJQWXzp6AcxEXTBv1PXq3+QLj+nfGuZDDORuITCrs/n18UacaGtWvgxFDB+LhwwdyRxKSKK+X71Pi3x4fvwCcPXMK90PvAQBu3byByxcvIEhhb9hEveYfSqVSziICFusZiHkeA41GAwcH3ULIwcERkZHPZEqVMUmSMHP6VPj5B8CjpKfccbREactHDx9g+5ZNcHFxxbxflqJFq9b4adqP2LXzN7mjAQDsbS1ga2WOjp+54OTdaPyw6W8cuRmJaS3Kwq+Y/j+QeW3M0SXIFTsuhudoNo9S3ugxeDyGTf4ZXfuNwvOYKEwY1BUvXzzHi+fReJ0Qj11bVqN8hSoYNmUeAgJrYu7kYbj+94UczUWm4V3OBxOnTMX8RcswevwkREU+Q5cObfH8eYzc0YQjyuvlu5T6t6dTl+9Qr/6XaNX0S3wWUA7tWzdHm/Yd8UWDL+WOpkPEa06mo7hhMDExMVi9ejVu376NQoUKoVOnTihWrFiGxyQmJiIxMVFnnaS2gpWVlVEyvX8jhCRJir05YuqUSbh96yZWrtkgdxS9lN6WKSkSvMqWRZ9+AwAApct44e6/d7B9yyZ81bipvOEAmP1/Wx29HYlNZ9/2Wt+OiEO5onnR3L8wLj6I1dnf1lKN2a3K4V5kPJYdv5+j2XwqBmr/XQyAR5lyGNSlGY4d+ANVatQDAPhXqY4GzdoBAFxLeOL2tb/x1+5fUaa8f45mo5wXVK26zv/Ll/dFky/rYdfO39C+Y2eZUolN6a+X71Lq3579e3djzx//w+TgGSjuURK3blzHrBnBKFCgoCJe098n0jXPjo/xZ8pJsvesFy5cGFFRb2e6uHfvHry8vDBt2jTcvn0bixcvRrly5XDjxo0MzxEcHAw7OzudZca04Gxns89nD7VajcjISJ310dFRcHDQPy5XTlN/nIQjhw5i6Yo1cHKWb3YNfURpS8cCjnAvXkJnnbt7cTx5krO90ln1PP4NkjUpuBcZr7M+NDIeTnl135zmslRjTutyiE/SYNj2K9Ck5PAYmPdYW9ugmJsHnj56gDx580GtVqOIi7vOPkWKuSHq2ROT5iLTsMmVCx4lPRF2P2ffJH6MRHm9TKXkvz1zZ//0tne9wZfwKOmJho2aoG37Tli1fInc0XSIds3JtGQv1p88eQKN5u10ciNHjkTp0qXx77//Yt++fbhz5w6qVauGMWPGZHiOESNGIDY2VmcZMmxEtrNZWFqijFdZnAo5obP+VEgIfHz9sn1+Y5EkCVOnTMTBA/uxeMUqFClaVO5IaYjSlj6+/rgfGqqz7v79UBQqpIw78ZNTJFwLfwlXB92ZFlzy58KT2P9uMrW1VOPnNuXxRiNh8LYrSMrpwep6vElKwqOwUOTL7whzCwsU9/RC+MMwnX3CH4XJOm0j5ZykpCTcu/svHAso+4ZTJRLl9VKEvz2JrxPSTNFoplZDSkmRKZF+olxzkoeihsGcPn0ay5YtQ67/n/LJysoKo0ePRsuWLTM8zsoq7ZCX18nGydShU2eMGj4UXt7e8PHxw/atmxEeHo5WrdsY5wGMIHjyROzZvQuzf14AW1tb7fi23LnzwNraWuZ0/xGhLdt16IQuHdthxdLF+PyL+rj6zz/YsW0rRo2bYLIMNhZmKGpvo/1/4XzWKFnQFi9eJ+Ppi0SsO/0AU5p64WLYc5wPe47PiudH1ZIO6L3+EoC3Peo/tykPKwszjNt5HbZWathavZ1C73n8G+RUB/uGpXPhV7kaHAo64cXzGPy+cQUS4uNQre7bsaENW7TH/KmjUNrbD2V8AvD3uZO4ePo4Rk1blDOBsig+Pg5hYf+9iXj06CFu3LgOOzs7xbxJEyHj7J+moXrNWnB2Lozo6CgsX7IIcXGv0EhhQw1EaEtAjNdLEf72VK1RCyuXLoazcyEUL1ESN29cw4a1q9C4SXO5o6UhwjU3Fo6CMYxKkiTTd7m9w8zMDE+fPkWBAgVQpEgR7Nu3D2XL/je3dGhoKEqXLo3Xr19ncJa0jFWsA///JQUrluPZswh4lPTEkGEjjDYtVYoRmt/Pu7Te9RMm/4jGTbP/gmRmxN+qnGzLNxrj9JQcO3II8+fOxoOw+yhcpCi+6dAJzVp+bZRz1511LNN9/F3ssOgb3zTrd/39BJP+uAkAaFTeGZ2qFEOBPFYIi07A0mOh2i9OSu94AGi68BTCYxP1bnvX/Nb6j8/wmOBRuHHlIl6+eI68dvbwKO2Nlh16oIjrf1+QcuTPndi5ZTWiIyNQqKgLWrTvjoAqHzYrg3c6N9Qa6uyZ0+jWJe18y42aNMOkKVON8hjZldMZjTFEasTQgbhw/iyexzyHfX57lCvng159+6F4CY9snzuV2iz7r0U53ZbGLEJy6vXSGH93gJz/25NshE8E4+Li8MuCuTh88ABioqPhWKAgvmjQEN/16A0Li+x/x4OluXEHKOTUNbdWVNcsUOnHw3JH0DozsqbcETKliGLd29sb5ubmuH37NtasWYNmzZpptx89ehTt2rXDw4cPDTqvMYv1nGSsF82cZMxiPScZq1jPSVkp1pXgQ4p1UzNWsU7GKdZNwRjFek4T4eVShL87gHGK9Zxm7GI9p7BYT58Ixbrsl2/cuHE6/8/13ree/e9//0O1atVMGYmIiIiIcghngzGM4or1982YMcNESYiIiIiIlEWMz2+IiIiIiD5BsvesExEREdGng6NgDMOedSIiIiIihWLPOhERERGZDG8wNQx71omIiIiIFIrFOhERERGRQnEYDBERERGZDEfBGIY960RERERECsVinYiIiIhIoTgMhoiIiIhMhrPBGIY960RERERECsWedSIiIiIyGXasG4Y960RERERECsVinYiIiIhIoTgMhoiIiIhMhjeYGoY960RERERECsVinYiIiIhIoTgMhoiIiIhMhsNgDMNinT4aagF++Q8Nri53hCypMvmg3BEydXpMHbkjfDT+eRArd4Qs8XPLJ3eEj4KZAK+VAKBSSXJHIFIEDoMhIiIiIlIo9qwTERERkckI8uGOYrBnnYiIiIhIodizTkREREQmwxtMDcOedSIiIiIihWKxTkRERESkUBwGQ0REREQmw1EwhmHPOhERERGRQrFYJyIiIiJSKA6DISIiIiKT4WwwhmHPOhERERGRQrFYJyIiIiJSKA6DISIiIiKT4SgYw7BnnYiIiIhIodizTkREREQmY8audYOwZ52IiIiISKFYrBMRERERKRSHwRARERGRyXAUjGFYrGfB5o3rsWrlckQ+e4YSHiUxdPhI+AdUkDuW1vKli3HwwH6E3rsLK2tr+Pj6od+AQXBzLy53tDSU3pZbNm/Ets0b8fjxIwBA8RIe6N6zD6pWqy5zsv8o5Xr7u+bDt0EuKFMoLwrmtUL/jZdx6EakdvvlCXX0Hjdr322sPhEGALBQqzDoi5Ko7+0Eaws1Tt+NxpQ/biLiRaJJfoZUSn9eplJazpjICGxZuQB/nw/Bm6REOBV2Qdd+o+BWsgwA4NyJQzi8dwdC79zAqxexmPDzWriW8JQt77uU1pb6iJARUH7OiKdPMW/OTIQcP4rXiYlwdXXDmAmTUcarrNzR0lB6W5I8OAwmE3v37Mb0qcHo1r0XNm/7Df7+AejdoxvCHz+WO5rWhXNn0bptO6zZsBmLlqyAJjkZvbp/h4T4eLmj6RChLZ2cnPB9/0FYv2kb1m/ahkqVP8OAH/rg3zu35Y6mpZTrbWOhxs0nrzB1902922vPOKazjN1xDSkpEg5ci9DuM7SBJ2qXLoBh267g2+XnkMtSjXntfGBmwl4XEZ6XgPJyxr18gclDukNtrsagCXMwZdEmtP2uH3LlzqPdJzExASXLlEerb/vIkjE9SmtLfUTICCg/54sXsejaqR3Mzc0xd+ESbN2xC/0HDUWePHkyP9jElN6WJB+VJEmS3CFywutk45znmzatUMbLC6PHTtCua9qoAWrVrot+AwZl+/wpOdD80dHRqFM9EMtWrUVAhYrZPp+x7trO8bZMyZmnco2gyug/aAiaNW+Z/ZPlQBFq7OsNAFUmHzRo/8sT6qTpWX/f7DblYWulRvfVFwEAua3UODy0Okb9ehV/Xn1bwBfIY4k/B1ZF33WXEPJvdIaPeXqM/p57Q+X089JYcjLnxdDnBh+zZeUC3Ll+GSOnL8l032dPH2NIl2bZ7ln3c8v3wce+S4RrLkJGIGdzvtGkZDce5s2ZicsXL2LZ6nXZPpc+Fmrj9XnmZFtaK2wcxRcLT8sdQevP3pXljpAp9qxn4E1SEq5fu4oqgVV11lcJDMLlSxdlSpW5V69eAgDs7OxkTvIfEdtSo9Fg754/kJAQj/I+vnLHSZcSr/f78ttaopqnA3Zc+K+HyKtwXliYm+kU5c9eJuFOxCv4uJjmZxHleanEnJdOH4WbRxnM/3EEvm9XH2O/74DDe3+TJYshlNiW7xMhIyBGzqOHD6FM2bIYNqg/Pq8RhHZfN8eObVvkjpWGCG1J8mGxnoGY5zHQaDRwcHDQWe/g4IjIyGcypcqYJEmYOX0q/PwD4FFSGWNDAbHa8vatmwis5I/KAeUxZdJ4zJwzHyVKeMgdSy+lXu/3NfZ1RnyiBn9d/+9aO+S2RFJyCl6+9zFY9KskOOa2MkkuUZ6XSswZ8eQxDu7+Fc5FimHwpLmo1bAZ1i+ehRN/7ZYlT1YpsS3fJ0JGQIycjx4+wPYtm+Di4op5vyxFi1at8dO0H7Fr529yR9MhQlvSfxYuXAh3d3dYW1sjICAAx44dy3D/xMREjBo1Cq6urrCyskKJEiWwYsWKLD+e7B+MXLx4Efny5YO7uzsAYN26dVi0aBHCwsLg6uqKvn37ok2bNhmeIzExEYmJujekSWorWFkZ5w++6r1hIJIkpVmnFFOnTMLtWzexcs0GuaPoJUJburm7Y9O2HXj58gX+2r8PY0cPx7KVaxVZsCv9eqdq6lcYu/95gqTkLHysrXr7vDAlEZ6XgLJySlIK3D3KoGWn3gAA1xKl8Oj+PRzcvR1BdRrKkskQSmrL9IiQEVB2zpQUCV5ly6JPvwEAgNJlvHD33zvYvmUTvmrcVN5weii5LY3JlPclGdvmzZvRv39/LFy4EEFBQVi8eDEaNGiAa9euwcXFRe8xX3/9NZ4+fYrly5fDw8MDERERSE7O+nht2XvWu3btitDQUADAsmXL0L17d1SoUAGjRo1CxYoV0a1bt0zffQQHB8POzk5nmTEtONvZ7PPZQ61WIzJSdxxudHQUHBwcs31+Y5v64yQcOXQQS1esgZOzs9xxdIjUlhYWlnBxcUXZsuXwQ/9B8PQsjY3r1sgdKw0lX+93+bnkg3sBW/x6XvcmqahXSbA0N0Oe9wZT5re1RFRckkmyifK8VGLOfPaOKOzirrOucDE3RD17KkuerFJiW75PhIyAGDkdCzjCvXgJnXXu7sXx5Em4TIn0E6Et6a1Zs2aha9eu+O6771CmTBnMmTMHxYoVw6JFi/Tuv3fvXhw5cgS7d+9G3bp14ebmhkqVKiEwMDDLjyl7sX7z5k2UKPH2F2nhwoWYM2cO5s6di549e2L27NlYvHgxZs6cmeE5RowYgdjYWJ1lyLAR2c5mYWmJMl5lcSrkhM76UyEh8PH1y/b5jUWSJEydMhEHD+zH4hWrUKRoUbkjpSFKW+onISnJNMVjVohwvd/VzL8Qrj56gVtPX+msv/b4Bd4kp6BKifzadY65LeFRMDcuh8WaJJsoz0sl5izpVR5PHt3XWffkURgcCyj3jSOgzLZ8nwgZATFy+vj64/7/dwimun8/FIUKFZYnUDpEaEtjUqlUilkSExPx4sULneX90RqpkpKScP78edSrV09nfb169RASEqL3mJ07d6JChQqYPn06ihQpAk9PTwwePBgJCQlZbi/Zh8HY2Njg2bNncHFxwaNHj1C5su5duZUrV8a9e/cyPIeVVdohL8aaDaZDp84YNXwovLy94ePjh+1bNyM8PBytWmc8NMeUgidPxJ7duzD75wWwtbXVjm/LnTsPrK2tZU73HxHact7cWQiqWh3Ozs6Ii4vDn3t349zZM1iwaKnc0bSUcr1tLNVwyW+j/X8RexuUcs6N2IQ3eBL79oXO1kqNemWdMPPPtFNfvkrUYMfFxxj0RUk8j3+DFwlvMPCLkrj99BVO3c14JhhjEuF5CSgvZ72mbTFl8Hf43+ZVqFStDu7euobDe3/Dt9//11Hy6mUsoiKe4nn02+doanFvZ++AfPkd9J7XFJTWlvqIkBFQfs52HTqhS8d2WLF0MT7/oj6u/vMPdmzbilHjJmR+sIkpvS0/VsHBwZgwQff5MG7cOIwfPz7NvpGRkdBoNHByctJZ7+TkhCdPnug9/927d3H8+HFYW1tjx44diIyMRO/evREdHZ3lceuyF+sNGjTAokWLsGzZMtSoUQPbtm2Dj4+PdvuWLVvg4SHfWOH6DRoi9nkMlixaiGfPIuBR0hMLflmCwoWLyJbpfVs3bwQAdOvcUWf9hMk/onHT5nJE0kuEtoyKisLokUMR+ewZcufJg5IlS2HBoqX4LDBI7mhaSrneZQvnwfLOAdr/D6n/9gbX3y8+xtjfrgMA6nu/fUHb84/+F7EZe29DkyJhxtflYGVuhjP3ojFmxzXk0CyceonwvASUl7O4pxe+Hz0d21YtxO8bl6OAU2G06z4AgbXqa/e5eOoYls+ZpP3/ommjAQBN2n2HZt90M3nmVEprS31EyAgoP2dZ73L4afbPmD93NpYtXojCRYpi0NDhaPBlI7mjpaH0tvxYjRgxAgMHDtRZl9k9j4bcW5CSkgKVSoX169drZ22bNWsWWrZsiQULFsDGxkbvcTqPJ/c8648fP0ZQUBBcXFxQoUIFLFq0CAEBAShTpgxu3ryJU6dOYceOHWjY0LAblozVs57TcmKedWMz1jzrOS2n5lk3KjGa0uB51uVgrHnW6cPmWZeDseZZJzEYY571nGbMedZzktLmWf9y8Rm5I2j90aNSlvdNSkpCrly5sHXrVjRr1ky7vl+/frh06RKOHDmS5phOnTrhxIkTuHPnjnbd9evX4eXlhVu3bqFkyZKZPq7sz7LChQvj4sWLqFKlCvbu3QtJknDmzBns27cPRYsWxYkTJwwu1ImIiIiIjMnS0hIBAQHYv3+/zvr9+/ene8NoUFAQHj9+jFev/rtv69atWzAzM0PRLN5zJnuxDgD58uXD1KlTcfXqVSQkJCAxMRGhoaFYv349KlSoIHc8IiIiIiIMHDgQy5Ytw4oVK3D9+nUMGDAAYWFh6NmzJ4C3w2o6dvxvmGq7du3g4OCAzp0749q1azh69CiGDBmCLl26ZGkIDKCAMetERERE9OlQiTImVI/WrVsjKioKEydORHh4OLy9vbF79264uroCAMLDwxEWFqbdP3fu3Ni/fz++//57VKhQAQ4ODvj6668xefLkLD+m7GPWcwrHrBsPx6wbkRhNyTHrnxiOWScl4ph141HamPWvFp+VO4LWrh4V5Y6QKYVdPiIiIiL6mIn8DaZyEOMtIRERERHRJ4jFOhERERGRQnEYDBERERGZTHpfIET6sWediIiIiEihWKwTERERESkUh8EQERERkclwFIxh2LNORERERKRQLNaJiIiIiBSKw2CIiIiIyGRE+WZ0pWDPOhERERGRQrFnnYiIiIhMhh3rhmHPOhERERGRQrFYJyIiIiJSKA6DISIiIiKTUXEcjEHYs05EREREpFDsWZeZCNMXJb5JkTtCllhZ8L2nsZweU0fuCJmyrzFK7ghZEnNkitwRMuXrmk/uCB8NSZI7QeYE+LMDALBQ8zWdCGCxTkREREQmJMobRqXg21YiIiIiIoVisU5EREREpFAcBkNEREREJiPC/XpKwp51IiIiIiKFYs86EREREZkM+9UNw551IiIiIiKFYrFORERERKRQWRoGExYWZtBJXVxcPigMEREREX3cVLzB1CBZKtbd3NwMaliNRvPBgYiIiIiI6K0sFesrVqzguyAiIiIiIhPLUrH+7bff5nAMIiIiIvoUmLH/1yDZusE0ISEBjx49QnJysrHyEBERERHR//ugYv3QoUOoUqUK8uTJA1dXV/z9998AgD59+uDXX381akAiIiIiok+VwcX6wYMHUa9ePbx+/RqDBw9GSkqKdpujoyNWrVplzHxERERE9BFRqVSKWURgcLE+duxYNGzYEBcvXsTkyZN1tvn4+ODSpUvGykZERERE9EnL0g2m77p48SK2bt0KIO08mQUKFEBERIRxkhERERHRR0eQDm3FMLhn3dzcHG/evNG7LSIiAnny5Ml2KCIiIiIi+oBivWLFili7dq3ebdu2bUOVKlWyHUppNm9cjwb1aqOiXzm0adUcF86fkzuSXkrPGRcXh1nTf0TjBrVRrbIvunZsi2tX/pE7ll5Kb0tAjIyAvDkHd6iO48t6IWL/WNzfNQJbgr9BSRdH7XZztRkm9/oCZ9d8j8gD43D392FYNrolCjnqdjrMG9IEV7cMRPTB8QjbNRJbpraH5zvnMRWlX/Pz587ihz498XmtqvD1LoWDfx2QO1K62JbGo/S2BMTICIiTk0zL4GJ9+PDh2LFjB5o1a4adO3dCpVLh9OnT6Nu3L7Zt24ahQ4fmRE7Z7N2zG9OnBqNb917YvO03+PsHoHePbgh//FjuaDpEyDllwmicPhWC8ZOnYcPW31G5ShD69OyCiKdP5Y6mQ4S2FCEjIH/Oar7u+OXXU6jR/Rd81X8l1Goz7Jr9LXJZWwAAcllbwLdUYUxddQhVuixAm5EbUNLFAVunddA5z8Wbj9F9yq/wbTcHjQeugkoF7JrdGWYmnCxY7rbMioSEeHiWKoXhI8fKHSVDbEvjEaEtRcgIiJPTGOS+qVS0G0xVkiRJhh60bt069O/fH9HR0dp1+fLlw7x58/DNN98YNeCHem2kqd+/adMKZby8MHrsBO26po0aoFbtuug3YJBxHsQIcjJn4puUzHfKxOvXr1ErqAJmzJ6PqtVratd/83UzVK1eA7369s/2Y1hZZOtrA7REuOYiZARyNqd9jVEGH+OYLxce/DEKdXsvxYnLoXr3CShdBMeX94Zn8+l48DRW7z7eJZxwds0P8Pp6Ju49ita7T6qYI1MMzqlPTral4X8FMufrXQqz5i5A7Tp1jXZOY/1d/dTb0pj1iQivRSJkBHI2p7XBdyjmrI4b/pY7gtaaduXljpCpD6pu2rdvjwcPHmDfvn1Yt24d9u7diwcPHiimUDeWN0lJuH7tKqoEVtVZXyUwCJcvXZQpVVoi5NRoNNBoNLC0stJZb2VthcsXL8iUKi0R2lKEjIAyc+a1tQYAxLyIT3+f3NZISUnB85ev9W7PZW2Bjl8G4N6jaDxMp5g3NiW2pajYlsYjQluKkBEQJyfJ44Pfa9nY2KBu3ey/y//+++/x9ddfo1q1atk+l7HFPI+BRqOBg4ODznoHB0dERj6TKVVaIuS0tbVFufK+WLFkEdzdSyC/gwP27f0DV//5G8VcXOWOpyVCW4qQEVBmzmk/NMSJy6G4dk//rFVWluaY1OsLbN7/N17GJ+ps696sMqb0/gK5c1nhRmgEvhywEm+SNaaIrci2FBXb0nhEaEsRMgLi5DQWE44g/Ch8UM/6ixcvEBwcjHr16iEgIAD16tVDcHAwnj9/bvC5FixYgJo1a8LT0xPTpk3DkydPDD5HYmIiXrx4obMkJiZmfmAWvT+mSZIkRY5zUnrOCVOmQYKEL+vVQNVKPti8YR2+aPAV1Gq13NHSUHpbAmJkBJSTc/bARihXwhmdxm3Wu91cbYa1E1rDTKVCv592ptm+ad8lfNZ5Aer2Xoo7D6OwbmIbWFma9rNlpbTlx4BtaTwitKUIGQFxcpJpGVys37t3D+XLl8eoUaNw+/ZtWFpa4vbt2xg1ahR8fHxw9+5dg0Ps27cPDRs2xE8//QQXFxc0adIEu3bt0vl21IwEBwfDzs5OZ5kxLdjgHO+zz2cPtVqNyMhInfXR0VFwcDD9TBDpESVn0WIuWLx8LY6cPI//7T2IVeu3IDn5DQoXLiJ3NC0R2lKEjICycs4a8BW+qloaX3y/HI+evUiz3VxthvWT2sK1kD2+6r8iTa86ALyIS8S/D6Nw4nIo2o3aiFKuBdCkupcp4iuqLUXHtjQeEdpShIyAODmNRe6bSkW7wdTgYr1fv354/fo1Tpw4gXv37uHkyZO4d+8ejh8/jsTERPTv39/gEOXKlcOcOXPw+PFjrFu3DomJiWjatCmKFSuGUaNG4c6dOxkeP2LECMTGxuosQ4aNMDjH+ywsLVHGqyxOhZzQWX8qJAQ+vn7ZPr+xiJIzlY1NLjgWKIgXL2JxKuQEqtesI3ckLRHaUoSMgHJyzh7YCE1qlEX9H1bgfnhMmu2phXqJYg74sv8KRL9IyNJ5VSrA0tI0nwoppS0/BmxL4xGhLUXICIiTk+Rh8Ge4Bw8exNy5c9PMpx4YGIjJkyd/ULGeysLCAl9//TW+/vprhIWFYcWKFVi1ahWmTp0KjSb9saFWVlaweu/GRWPNBtOhU2eMGj4UXt7e8PHxw/atmxEeHo5WrdsY5wGMRIScJ0OOA5IEFzd3PAy7j59n/wRXN3c0atJM7mg6RGhLETIC8uecM6gxWn9eHq2Gr8Or+EQ45c8NAIh99Rqvk5KhVpthw5R28PMshOZD10JtZqbdJ/pFAt4ka+BW2B4t65TDX2fuIPJ5HAo75sWg9tWRkJiMP0NumeTnAORvy6yIj49DWFiY9v+PHj3EjRvXYWdnh0KFCsuYTBfb0nhEaEsRMgLi5CTTM7hYt7KyQrFixfRuc3FxSVM0fygXFxeMHz8e48aNw4ED8n0ZRP0GDRH7PAZLFi3Es2cR8CjpiQW/LFHU0A1AjJyvXr7EwnmzEfH0CfLa2aF2nXro1bc/zC0s5I6mQ4S2FCEjIH/OHs0rAwD2L+ims77blG1Yt/siihTIi0bVygAAzqz+Xmefen2X4djFe0hMSkaQjxv6fh0E+zzWiIh+heOXQ1Gr52I8ex5nkp8DkL8ts+LqlSvo1qWj9v8zp78djtioSTNMmjJVrlhpsC2NR4S2FCEjIE5OYxBj8IlyGDzPepcuXaBWq7F06dI027p164akpCSsXr06y+dzd3fHuXPn0twBnV3G6lkn48yzbgrGmmedxPAh86zLwVjzrOeknJgbPCeIMLxUhLYUoR3JuJQ2z3qXTcr59vIVbcrJHSFTWbp8Fy78Nw92u3bt0LVrV7Rq1Qrt2rWDs7Mznjx5gvXr1+PcuXNYvny5QQHu3btnWGIiIiIiok9Elor1ChUq6NwxK0kSHjx4gF9//VVnHQDUq1cvw/HlRERERPTpMuPHOwbJUrG+cuXKnM5BRERERETvyVKx3qlTp5zOQURERERE71HYLQdERERE9DHjKBjDfFCxHh0djQ0bNuD69etISND9AhGVSmXwTaZERERERJSWwcV6WFgYKlasiPj4eMTHx8PR0RHR0dHQaDSwt7eHnZ1dTuQkIiIioo+Ail3rBjF4Yurhw4ejbNmyePr0KSRJwp49exAXF4d58+bB2toaf/zxR07kJCIiIiL65BhcrJ88eRK9evWCtbU1gLdTNlpaWqJPnz7o2rUrhgwZYvSQRERERESfIoOL9adPn6JQoUIwMzODWq3GixcvtNtq1KiB48ePGzUgEREREX08VCrlLCIwuFh3cnJCdHQ0AMDNzQ3nzp3TbgsNDYW5OSeYISIiIiIyBoMr688++wwXL15E48aN0bx5c0ycOBGJiYmwtLTEjBkzULt27ZzISURERET0yTG4WB88eDBCQ0MBAGPHjsX169cxbtw4SJKE6tWrY86cOUaOSEREREQfCzNRxp8ohMHFekBAAAICAgAAtra22LlzJ168eAGVSoU8efIYPSARERER0afK4DHr+uTNmxd58uTB0aNHOQyGiIiIiMhIjHo36LNnz3DkyBFjnpKIiIiIPiIcBWMYo/SsExERERGR8XGeRSIiIiIyGRW71g3CnnUiIiIiIoVisU5EREREpFBZGgZTvnz5LJ3sxYsX2QpDymRlwfd0pDwxR6bIHSFLinTZKHeETD1a0VbuCFlyLyJO7giZci2QS+4ImVKBQxBIXqwqDJOlYj1//vxZGl/k4OAAd3f3bIciIiIiIqIsFuuHDx/O4RhERERERPQ+zgZDRERERCbD2WAMw2FDREREREQKxZ51IiIiIjIZM3asG4Q960RERERECsVinYiIiIhIoTgMhoiIiIhMhsNgDPPBxfqNGzdw5MgRREZGomvXrnB2dsbjx49hb28PGxsbY2YkIiIiIvokGVysazQadO/eHatWrYIkSVCpVGjQoAGcnZ3Ro0cP+Pn5YeLEiTmRlYiIiIjok2LwmPUpU6Zgw4YNmDFjBq5cuQJJkrTbGjRogL179xo1IBERERF9PFQqlWIWERjcs75q1SqMGTMGAwcOhEaj0dnm7u6Oe/fuGS0cEREREdGnzOCe9UePHqFKlSp6t1lbW+Ply5fZDkVERERERB9QrBcsWBB3797Vu+3mzZsoWrRotkMRERER0cfJTKWcRQQGF+sNGzbElClT8OjRI+06lUqF2NhY/Pzzz2jUqJFRAxIRERERfaoMLtYnTpyI5ORkeHl5oUWLFlCpVBg5ciS8vb3x+vVrjBkzJidyEhEREdFHQKVSziICg4t1JycnnD17Fm3btsX58+ehVqtx+fJlNGjQACEhIcifP39O5CQiIiIi+uR80JciOTk54ZdffjF2FiIiIiIieofBPeufos0b16NBvdqo6FcObVo1x4Xz5+SOpJcIOUXICIiRU4SMgBg55c5YpVQBrB9QHVfnNkHUmrZo6F8k3X1nflsRUWvaoscXpdJsq+DhgN+G10bY0la4u6gFfh9RG9YW6pyMnobcbfmuPb9vRb+uX6Ptl9XQ9stqGNanE86fPqHdLkkSNq76BZ1b1sPXX1TBqP7dEHbvX9nyplq+dDG+ad0SQZX8Ubt6IAb80Aeh9/RP7KAESrrm6REhIyBOzuwyU6kUs4jA4GK9S5cuGS5du3bNiZyy2btnN6ZPDUa37r2wedtv8PcPQO8e3RD++LHc0XSIkFOEjIAYOUXICIiRUwkZc1mZ42pYDIatPZ/hfg39iyCghAPCo+PTbKvg4YCtg2vi0JVwfD7+T9Qd/yeWHbiNlHe+uC6nKaEt3+VQoCA6dPsBP/2yDj/9sg7l/CoiePQAbUG+Y9Nq7Ny6Ht1/GIYZv6yFfX4HjBvSCwnxcbLkTXXh3Fm0btsOazZsxqIlK6BJTkav7t8hIT7tdZeb0q65PiJkBMTJSaankiTDXsnd3NzSfONTVFQUXr16hXz58iFfvnzpTu1oSq+TjXOeb9q0QhkvL4weO0G7rmmjBqhVuy76DRhknAcxAhFyipARECOnCBkBMXLmdMYiXTYatH/UmrboMOcodl94pLO+kL0N9o2rh5YzDmHTwBr4Zd8tLP7zpnb7n2M/x+GrTxC8/R+DMz5a0dbgY/TJ6ba8F5H9Irp945ro1KM/6jZsgi4tv0Cjlu3QvO23AIA3SUno1LwuOnX/AV80bvlB53ctkCvbGd8XHR2NOtUDsWzVWgRUqJjt8xmzN5G/48aTkzmtP2jQc84ZvvuW3BG0pjb0lDtCpgzuWQ8NDcW9e/d0lhcvXuDAgQMoWLAgfv/995zIKYs3SUm4fu0qqgRW1VlfJTAIly9dlClVWiLkFCEjIEZOETICYuQUISPwdsaCRT2qYN7u67j56EWa7Y55rFDBwxGRL15jz5i6uD6vGXaOrIPKno4my6j0ttRoNDh28E+8fp2A0mXL42n4I8RER8K3wmfafSwsLeHtE4AbV/+WMWlar169/bJBOzs7mZPoUvo1B8TICIiT01jMFLSIwGg5a9eujb59+6Jfv34GHztv3jx06tQJW7ZsAQCsXbsWXl5eKF26NEaOHInkZCN1kxso5nkMNBoNHBwcdNY7ODgiMvKZLJn0ESGnCBkBMXKKkBEQI6cIGQGg35deSNakYMk+/b1RbgVzAwCGNiuHtYf/xdc/HcbfodHYMaw2ijvlNklGpbZl6N3baNMgCK3qfYZFs6Zg+MSZKOZWHM+jowAA+ex189rZ50dMdKQcUfWSJAkzp0+Fn38APEoqqwdQqdf8XSJkBMTJSfIw6gcjXl5eGD58uEHHTJo0CTNmzEC9evXQr18/3Lt3DzNmzMCAAQNgZmaG2bNnw8LCAhMmTEj3HImJiUhMTNRZJ6mtYGVl9UE/x/veH/YjSVKadUogQk4RMgJi5BQhIyBGTiVn9HGzR/d6nqg99s9090nNuvrgHWw4dg8A8M/9GFT3csY31Utg0tbLJsn6bpZUcrdlkWJumL1sI+JevcLJo3/h56ljMWXOsv920BNNKdceAKZOmYTbt25i5ZoNckdJl9KuuT4iZATEyUmmZdRi/ciRI3B0NOxj11WrVmHVqlVo3rw5Ll++jICAAKxevRrffPMNAKB06dIYOnRohsV6cHBwmu2jxozD6LHjDf4Z3mWfzx5qtRqRkbq9LNHRUXBwMN3Hy5kRIacIGQExcoqQERAjpwgZPytVEAXyWuPy7MbadeZqM0xq64ue9TzhN+h/ePo8AQBw87HuEJlb4bEo4mD8MdT6KLUtLSwsUKiICwDAo5QXbt+4iv9t36Adp/48Ogr5HQpo94+NiU7T2y6XqT9OwpFDB7F89To4OTvLHScNpV7zd4mQERAnp7Hw/YdhPugbTN9fRo0ahUaNGmHKlClo29awG5XCw8NRoUIFAICPjw/MzMzg6+ur3e7v74/HmdwJPWLECMTGxuosQ4aNMPRHS8PC0hJlvMriVMgJnfWnQkLg4+uX7fMbiwg5RcgIiJFThIyAGDlFyLjlxD1UG7UHNUbv1S7h0fGYv/sGWs04DAAIi4xDeHQ8PArl0Tm2hHNePIw0zcwmIrQl8Lan8s2bN3AqVAT2+R1x6dwp7bY3b97gyuXzKF22vIwJ32acOmUiDh7Yj8UrVqFI0aKy5kmPCNdchIyAODlJHgb3rI8fPz7NOisrK7i5uWHixIkYMmSIQedzdnbGtWvX4OLigtu3b0Oj0eDatWsoW7YsAODq1asoWLBghuewsko75MVYs8F06NQZo4YPhZe3N3x8/LB962aEh4ejVes2xnkAIxEhpwgZATFyipARECOnEjLaWpnD/Z2x5S4FcsPbJR9i4pLwKCoeMa+SdPZ/o0nB09jXuPPkpXbdvD03MLyZN66EPceV+zFoU80dJQvlQed5ppudSwlt+a61S+fBv3IQHAs6IyE+DscP/omrl89j7LT5UKlUaNSyHbatX4HCRV1QqKgLtq1bAStra1Sv20CWvKmCJ0/Ent27MPvnBbC1tdWOWc6dOw+sra1lzfY+pV1zfUTICIiT0xhEmd9cKQwu1lNSUowaoF27dujYsSOaNGmCv/76C8OGDcPgwYMRFRUFlUqFKVOmoGXLD5tCyxjqN2iI2OcxWLJoIZ49i4BHSU8s+GUJChdO/0tL5CBCThEyAmLkFCEjIEZOJWT0dc+PnSPraP8/5Rt/AMDGY3fRd+npLJ1j8Z83YW1hhint/JAvtxWuhsWgxfRDCI14lSOZ9VFCW77reUw05vw4BjHRkbC1zQ3X4iUxdtp87Qwwzdp0QmLiayyeMxWvXr6AZxlvjJ+xEDa5bGXJm2rr5rfTfXbr3FFn/YTJP6Jx0+ZyREqX0q65PiJkBMTJSaZn0DzrCQkJ6Nq1K3r37o2qVatmfkAWaDQaTJ06FadOnULVqlUxbNgwbNq0CUOHDkV8fDwaNWqE+fPnw9bWsBdPY/WsExFlh6HzrMvBWPOs5zRjzLOe03JinnVjY6/mp0dp86yP2Xtb7ghak+qXlDtCpgy6fDY2Nvj999/Rs2dPowVQq9UYNWqUzro2bdqgTZuP72MfIiIiok8d3y8axuAbTH19fXHlypWcyEJERERERO8wuFifOnUqpk+fjiNHjuREHiIiIiIi+n9ZGgZz9OhR+Pv7I3fu3OjduzdevXqF2rVrw97eHoUKFdKZsF+lUuHyZdN9AQcRERERicOMw2AMkqVivVatWjh58iQqVaoEBwcHg7/4iIiIiIiIDJelYv3dCWMOHz6cU1mIiIiIiOgdCpvMh4iIiIg+Zpw+1DBZvsFUxYYlIiIiIjKpLPes16pVC2Zmmdf2KpUKsbGx2QpFRERERB8n9v8aJsvFes2aNVGgQIGczEJERERERO/IcrE+duxYVKpUKSezEBERERHRO3iDKRERERGZDOdZN4zB32BKRERERESmwWKdiIiIiEihsjQMJiUlJadzEBEREdEnQAWOgzEEe9aJiIiIiBSKN5gSERERkcnwBlPDsGediIiIiEihWKwTERERESkUh8EQERERkclwGIxhWKxTpuISk+WOkCUWauV/UCRCRgCIjkuSO0KmHHJbyh0hSx6taCt3hEy59domd4QsubuwhdwRMmWmYhViLJIkd4LM8XKTKYhRORARERERfYLYs05EREREJqPiRxIGYc86EREREZFCsVgnIiIiIlIoDoMhIiIiIpPhbDCGYc86EREREZFCsWediIiIiEyG95cahj3rREREREQKxWKdiIiIiEihOAyGiIiIiEyG3/RrGPasExEREREpFIt1IiIiIiKF4jAYIiIiIjIZzrNuGPasExERERFl0cKFC+Hu7g5ra2sEBATg2LFjWTruxIkTMDc3h6+vr0GPx2KdiIiIiCgLNm/ejP79+2PUqFG4ePEiqlWrhgYNGiAsLCzD42JjY9GxY0fUqVPH4MdksU5EREREJqNSKWcx1KxZs9C1a1d89913KFOmDObMmYNixYph0aJFGR7Xo0cPtGvXDlWqVDH4MVmsExEREdEnKTExES9evNBZEhMT9e6blJSE8+fPo169ejrr69Wrh5CQkHQfY+XKlfj3338xbty4D8rIYp2IiIiITMYMKsUswcHBsLOz01mCg4P15o6MjIRGo4GTk5POeicnJzx58kTvMbdv38bw4cOxfv16mJt/2LwunA0mCzZvXI9VK5cj8tkzlPAoiaHDR8I/oILcsdJQWs6L589hw5oVuHn9GiIjnyF45s+oUUt3rFbo3X+x8OdZuHjhHKSUFLgX98CkaTPhXKiwTKmBuLg4/LJgLg4fPICY6Gh4li6DQUNHoqx3OdkyvWv50sX468A+hN67Cytra/j4+qH/gMFwcy8uW6YNq5bh2OEDCLt/D1ZW1ihbzgfd+g6Ai6u7dp/alfW3X/e+A9GmQ2dTRdVLab876ZEr5/cNSuFL/yLwcM6D10kanP03CpO3/4N/n74CAJirVRje1Bt1vJ3hWsAWLxLe4Nj1CEze/g+exr7Wnse1gC3GtSqPyh6OsDQ3w6GrTzBywyVEvtTfi5UTtmzaiG2bN+Lx40cAgOIeHujesw+qVqtusgxZcf7cWaxasRzXr13Bs2fPMPvnBahdp67csfRS8u+PEl8vM6LktvxYjRgxAgMHDtRZZ2VlleExqvfGz0iSlGYdAGg0GrRr1w4TJkyAp6fnB2dkz3om9u7ZjelTg9Gtey9s3vYb/P0D0LtHN4Q/fix3NB1KzPn6dQI8PEth4LBRerc/fBCGnl07wNXNHfOXrMLqTb/i2249YZnJL0lOmzx+NE6fDMGEKdOwcdvv+KxKEPr06IKIp09lzZXq/LkzaN32G6zZsAW/LFkJTbIGvbp3RUJ8vGyZLl88hyYt22D+8vWY8fMSaDQaDP2hBxIS/su0bfchnWXI6IlQqVSoXlveAkSJvzv6yJmzimcBrDz0L74MPoSvZx+DudoMmwdUQy5LNQDAxlKNci75MPuP6/h80gF0WXQSxZ1yY03fQO05clmqsbl/NUgS0GLmETSadggWajOs/T7og8aNfignZyd8P2AQ1m/ehvWbt6FSpc8w4Ps++PfObdOFyIKEhHiUKlUKw0eNlTtKhpT++6PE18v0KL0tP1ZWVlbImzevzpJese7o6Ai1Wp2mFz0iIiJNbzsAvHz5EufOnUPfvn1hbm4Oc3NzTJw4EZcvX4a5uTkOHjyYpYwqSZIkw3805XudbJzzfNOmFcp4eWH02AnadU0bNUCt2nXRb8Ag4zyIEeRkzrjE7DdmoH/ZND3rY4YPhrm5OcZNnprt8wOAhTr77z1fv36NmoEV8NOc+ahavaZ2fbuvm6Fa9Rro1bd/ts5vjIzvi46ORu3qVbB81ToEVKhonHPGJWXr+Ocx0WhevwZm/7ISPn76e4XGDPkB8fHxmLlg2Qc9hkNuy+xE1OLvOODWa5tB+zvktsTV2Y3RdPphnLodqXcfXzd77B1VBwHD/sCj6ATU8HLChn5VUarf73j1/y/QdrkscHNuE7SadRTHrkdk+rh3F7YwKGdW1QisjP6DhqBZi5bZPldOfI26T9lSiu1Zz8nnZU5UJ8Z+vTTm5c7JtrRW2DiKhSGhckfQ6h3oZtD+lStXRkBAABYuXKhd5+XlhSZNmqQZPpOSkoJr167prFu4cCEOHjyIbdu2wd3dHba2tpk+puw96+Hh4Rg7dixq166NMmXKwNvbG40aNcLy5cuh0WhkzfYmKQnXr11FlcCqOuurBAbh8qWLMqVKS5Sc70pJScHJ40fg4uqK/r27oWGdaviuYxscOfSXrLk0Gg00Gk2a3n1rKytcunhBplQZe/XqJQDAzs5O5iT/iXv1dnhE3rz6M0VHReLUiWNo2LiZKWOlIcrvjtJy5rGxAAA8z+BNXR4bC6SkSIiNfwMAsDQ3gyRJSEpO0e6T+EYDTYqEyh6OORs4HRqNBnt3/4GEhHiUN3DeY1Le8zIrlPh6CYjZlp+qgQMHYtmyZVixYgWuX7+OAQMGICwsDD179gTwdlhNx44dAQBmZmbw9vbWWQoWLAhra2t4e3tnqVAHZC7Wz507hzJlyuB///sfXr9+jVu3bsHf3x+2trYYPHgwqlWrhpcvX8qWL+Z5DDQaDRwcHHTWOzg4IjLymUyp0hIl57tioqMQHx+PtSuX47PAqpizcAmq16qDkYP74eL5s7LlsrW1RTkfXyxfsgjPIiKg0Wiwe9dOXPnnb0Q+U15bSpKEmdOD4ecfAI+SHz4ezpgkScLCuTNQzscf7iVK6t1n3+6dyGWbC9VqyttTKMrvjtJyTvjaB6duR+LG4xd6t1uZm2F0c2/8eiZM24t+4W4U4hM1GN2iHGws1chlqcbYluWhNlOhoJ21KePj9q2bCKzoj8r+5TFl0njMnDsfJUp4mDTDx0Bpz8vMKPH1MpVobfkpa926NebMmYOJEyfC19cXR48exe7du+Hq6grgbSd0ZnOuG0rWYr1///4YMGAALl68iJCQEKxevRq3bt3Cpk2bcPfuXSQkJGD06NGZnseQaXc+RFZvJJCbKDkBIOX/P9+sVrMW2rTvBM9SZdCxczcEVauBHds2y5pt4pRpkCQJDT+vgaCKPti8YR2+aPAV1Gq1rLn0CZ4yEbdu3cLU6bPkjqL184wpuHvnFkZPmpbuPnv+twN1vvhS9vsTUonyu6OEnMHtfOFV1A69lp7Wu91crcIv3StDpVJh+Pr/egSjXiWh2+JTqFe+EP6d1xS3fm6CPDYWuHw/Bikpph2N6ebujk3bd2D1+k1o9XUbjB01HP/+e8ekGT4mSnheZoUSXy/fJ0pbZpeZSjnLh+jduzdCQ0ORmJiI8+fPo3r1/25QX7VqFQ4fPpzusePHj8elS5cMa68Pi2kcFy5cQIcOHbT/b9euHS5cuICnT5/C3t4e06dPx7ZtmY+l1Dftzoxp+qfdMYR9Pnuo1WpERuqOyYyOjoKDgzwf2+ojSs535cuXD2pzc7gVL6Gz3tW9OJ4+CZcp1VtFi7lgyYq1OHryPHb9eRCrN2xBcvIbFC5SRNZc75v64yQcOXQQy1ashpOzs9xxAAA///QjQo4dxqyFy1HASX+mvy+ex4P7ofiycc6MPzaEKL87Ssk5pa0v6vkURouZRxAek5Bmu7lahSU9PoOLoy1azz6m7VVPdeTaU3w2ai+8B/0PXgP+h+9XnEWhfDYIi4wz1Y8AALCwsISLiyvKepfDDwMGwbNUaWxct8akGT4GSnleZoUSXy/fJVJbkunJWqwXLFgQ4eH/FWZPnz5FcnIy8ubNCwAoWbIkoqOjMz3PiBEjEBsbq7MMGTYi2/ksLC1RxqssToWc0Fl/KiQEPr5+2T6/sYiS810WFpYo4+WNsNBQnfUPwu7LOm3ju2xy5YJjgYJ48SIWp06eQPWahn9FcE6QJAnBUybirwP7sGTFahQpWkzuSJAkCXNnTMGxw39h5oLlKFS4aLr77vnfr/As7YUSnqVMmFA/UX53lJDzx7a+aOhXBC1nHkVYZNqZNFIL9eIFc+PrWUcRk8F49uhXSXiR8AZBpQvAMY8V/rws82wXkoSkpOzdVP0pUsLzMjNKfL3UR4S2JPnIen9w06ZN0bNnT8yYMQNWVlaYNGkSatSoARsbGwDAzZs3USQLvZlWVlZpptkx1mwwHTp1xqjhQ+Hl7Q0fHz9s37oZ4eHhaNW6jXEewEiUmDM+Pg4PH/w3biv80UPcunkdefPawblQYXzTsTPGDB8EX/8ABFSohFMhx3Hi6GHMX7JStswAcPLEcUiQ4OrqjocP7mPu7J/g6uqOxk3kvRky1Y+TJ2DP7l2Y8/NC2Nraascz5s6dB9bWph37m2rujCn468/dmDxjLnLZ2iI66m3vkK1tbli9kynu1Ssc+Ws/evYbLEtOfZT4u6OPnDmntvNDs8rF8O2CELx6/QYF8r59vX2Z8Aav36RAbabCsp5VUM4lHzrMOwEzM5V2n+dxSXijeTvMpU2gK249eYmol4moUNwBk9r4YMmB29r52k1h3pxZCKpWHc7OzoiLi8Ofe3bj3NkzWPDLUpNlyIr4uDidca+PHj7EjevXYWdnh0KFldGhASj/90eJr5fpUXpbGlNOzJr0MZN16sZXr16ha9eu+PXXX6HRaFClShWsW7cO7u5vv0hl3759iI2NRatWrQw+t7GKdeD/v6RgxXI8exYBj5KeGDJshNGmyDOmnMr5oVM3Xjh3Bn27p/2ym4aNmmD0hB8BALt++xVrVi5FRMRTuLq6oWvPvqhes/YHPZ6xpkXc/+ceLPh5NiKePkFeOzvUrlMPvb/vj9x58mT73MbI6Outv0d6wuRgNGnaPNvnBwyfujG9LzwaOmYS6n/VVPv/XTu2YsHs6di6+yBy585eexpr6kaAv+OZTd34ZKn+KQ37rTyLzSH3UcwhF85Obah3n+YzjiDk1tsCaVRzb7QOdEM+W0s8iIrDmiN3sXh/1uc3N8bUjePHjMKZ0ycR+ewZcufJg5KepdC5y3f4LDAo2+cGjFeEnD1zGt917phmfeMmzTDpR+NMd2ssOfW8NEZ1ktOvl8auOXOqLZU2deOSU/fljqDV/TNXuSNkShHzrL9+/RrJycnInTu38c5pxGL9U2eMedZNISfmMDc2ETIC2Z9n3RSMWax/6gydZ10uOTXPujGxx9B45K9OMifK5VZasb70tHKK9W6VlV+sK+LyKe2jKCIiIiIiJRCjm4+IiIiI6BOkiJ51IiIiIvo0cLiYYdizTkRERESkUCzWiYiIiIgUisNgiIiIiMhkOArGMOxZJyIiIiJSKPasExEREZHJsKfYMGwvIiIiIiKFYrFORERERKRQHAZDRERERCaj4h2mBmHPOhERERGRQrFYJyIiIiJSKA6DISIiIiKT4SAYw7BnnYiIiIhIoVisExEREREpFIfBEBEREZHJmHE2GIOwZ52IiIiISKHYs05EREREJsN+dcOwZ52IiIiISKHYs06ZsrXi0+RT45DbUu4IH42UFEnuCJkKXdRS7ghZYh84WO4ImYo+8ZPcETIlynBhCcr/3VGxj5hMgFUYEREREZmMKG8YlYLDYIiIiIiIFIrFOhERERGRQnEYDBERERGZjIrjYAzCnnUiIiIiIoVisU5EREREpFAcBkNEREREJsOeYsOwvYiIiIiIFIo960RERERkMrzB1DDsWSciIiIiUigW60RERERECsVhMERERERkMhwEYxj2rBMRERERKRSLdSIiIiIiheIwGCIiIiIyGc4GYxj2rBMRERERKRSLdSIiIiIiheIwGCIiIiIyGfYUG4btlQWbN65Hg3q1UdGvHNq0ao4L58/JHUkvEXKKkBEQI6cIGQExcio945bNG/F188ao+lkAqn4WgI7ftMbxY0fljqWXnG05uFNtHF/VDxGHJuP+3vHYMuNblHQpoLNPk5re2PlzNzzYNwEJZ35C+ZKFdba7FLJHwpmf9C7N65Q32c9y/txZ/NCnJz6vVRW+3qVw8K8DJntsQyn592f50sX4pnVLBFXyR+3qgRjwQx+E3rsrd6x0KbktST6KKNbj4uKwdOlSdO7cGQ0aNEDDhg3RuXNnLFu2DHFxcbJm27tnN6ZPDUa37r2wedtv8PcPQO8e3RD++LGsud4nQk4RMgJi5BQhIyBGThEyOjk54fv+g7B+0zas37QNlSp/hgE/9MG/d27LHU2H3G1Zzb84ftl6AjW6zsNX3y+GWm2GXfO6I5e1pXafXDaWOHk5FGMW/KH3HA+fPodbgwk6y8TFf+JVfCL+DLlhkp8DABIS4uFZqhSGjxxrssf8EHJf88xcOHcWrdu2w5oNm7FoyQpokpPRq/t3SIiPlztaGkpvS2NSqVSKWUSgkiRJkjPAtWvX8PnnnyM+Ph41atSAk5MTJElCREQEjhw5AltbW+zbtw9eXl4Gnfd1snHyfdOmFcp4eWH02AnadU0bNUCt2nXRb8Ag4zyIEYiQU4SMgBg5RcgIiJEzpzOmpOTMS2yNoMroP2gImjVvme1zmZkZ5w9WTrelfeBgg/Z3zGeLB/smoG6PhThxUbc31aWQPW7+PgqVv5mFv29nXAydXDsAl24+RK/JWzN9zOgTPxmUMSt8vUth1twFqF2nrlHOZ8z6JCeveUoOlCfR0dGoUz0Qy1atRUCFitk+n5kRGzMn29JaYYOed/z9RO4IWs3KO8sdIVOy96z36dMH1atXx9OnT/Hbb79h8eLFWLJkCX777Tc8ffoU1atXR58+fWTJ9iYpCdevXUWVwKo666sEBuHypYuyZNJHhJwiZATEyClCRkCMnCJkfJ9Go8HePX8gISEe5X185Y6jpcS2zJvbGgAQE/vhvah+pYvAt1QRrP79jLFifTSUeM0z8+rVSwCAnZ2dzEl0idiWZDqyv9c6ffo0zp07B0tLyzTbLC0tMXLkSFSqVEmGZEDM8xhoNBo4ODjorHdwcERk5DNZMukjQk4RMgJi5BQhIyBGThEyprp96yY6tW+LpKRE2OTKhZlz5qNECQ+5Y2kpsS2n9W+ME5fu4trdD+/F69S4Mq7ffYpT/9w3YrKPgxKveUYkScLM6VPh5x8Aj5KecsfRIVpbZpcYg0+UQ/Zi3d7eHrdv3053mMudO3dgb2+f4TkSExORmJios05SW8HKysooGd8f0yRJkiLHOYmQU4SMgBg5RcgIiJFThIxu7u7YtG0HXr58gb/278PY0cOxbOVaRRXsgHLacvaQZijnUQh1ui/44HNYW5mj9Rd+mLpcuTd3KoFSrnlmpk6ZhNu3bmLlmg1yR0mXKG1JpiX7MJhu3bqhU6dO+Omnn3D58mU8efIET58+xeXLl/HTTz+hS5cu6NGjR4bnCA4Ohp2dnc4yY1pwtrPZ57OHWq1GZGSkzvro6Cg4ODhm+/zGIkJOETICYuQUISMgRk4RMqaysLCEi4srypYthx/6D4KnZ2lsXLdG7lhaSmrLWYOb4qvqZfFF71/wKCL2g8/TrHZ55LK2wPrdnJFDHyVd88xM/XESjhw6iKUr1sDJWXljlEVqSzI92Yv18ePHY8SIEZg1axb8/PxQpEgRFC5cGH5+fpg1axaGDx+OsWMzvht+xIgRiI2N1VmGDBuR7WwWlpYo41UWp0JO6Kw/FRICH1+/bJ/fWETIKUJGQIycImQExMgpQsb0SUhKSpI7hJZS2nL24GZoUrMc6vf+BfcfR2frXN82row/jl5D5HN5ZyVTKqVc84xIkoSpUybi4IH9WLxiFYoULSp3JL1EaEtjUqmUs4hA9mEwADBs2DAMGzYM9+7dw5Mnb8cWOjs7w93dPUvHW1mlHfJirNlgOnTqjFHDh8LL2xs+Pn7YvnUzwsPD0ap1G+M8gJGIkFOEjIAYOUXICIiRU4SM8+bOQlDV6nB2dkZcXBz+3Lsb586ewYJFS+WOpkPutpwztDlaf+GHVoNX4lV8Ipwc8gAAYl8l4HXi2z8K9nltUMzJHoUK5AUAeLq+nYf9afRLPI16qT1X8aIOqOrnjqb9l5sk+/vi4+MQFham/f+jRw9x48Z12NnZoVChwhkcaVpyX/PMBE+eiD27d2H2zwtga2urHf+dO3ceWFtby5xOl9LbkuSjiGI9lbu7e5oC/cGDBxg3bhxWrFghS6b6DRoi9nkMlixaiGfPIuBR0hMLflmCwoWLyJInPSLkFCEjIEZOETICYuQUIWNUVBRGjxyKyGfPkDtPHpQsWQoLFi3FZ4FBckfTIXdb9mgZCADYv7i3zvpuEzZh3R9vh7J8Wa0slo77r/hZ+2MHAMDkpfswZek+7fpOjSrh8bMXOHD6Vk7H1uvqlSvo1qWj9v8zp78d2tmoSTNMmjJVlkz6yH3NM7N180YAQLfOHXXWT5j8Ixo3bS5HpHQpvS2NyYy3mBpE9nnWM3P58mX4+/tDo9EYdJyxetaJiLIjp+ZZNyZjzbOe0wydZ10OOTHPurGJ8tF/TsyzbmzGnGc9JyltnvX//fNU7ghajco5yR0hU7Jfvp07d2a4/e5d5X4tMBERERFRTpK9WG/atClUKhUy6uDntEVEREREHweWdYaRfTaYQoUKYfv27UhJSdG7XLhwQe6IRERERESykL1YDwgIyLAgz6zXnYiIiIjoYyX7MJghQ4YgLi79OWw9PDxw6NAhEyYiIiIiopyi4mwwBpG9WK9WrVqG221tbVGjRg0TpSEiIiIiUg7Zh8EQEREREZF+svesExEREdGng7PBGIY960RERERECsWedSIiIiIyGTPeYGoQ9qwTERERESkUi3UiIiIiIoXiMBgiIiIiMhneYGoY9qwTERERESkUi3UiIiIiIoXiMBgiIiIiMhkOgzEMe9aJiIiIiBSKxToRERERkUJxGAwRERERmYyKX4pkEPasExEREREpFHvWiYhICI8OTZM7QqbyfzFF7giZitk3Su4IWWLGuxA/Wma8tAZhzzoRERERkUKxWCciIiIiUigOgyEiIiIik+ENpoZhzzoRERERkUKxWCciIiIiUigOgyEiIiIik+FEP4ZhzzoRERERkUKxZ52IiIiITIY3mBqGPetERERERArFYp2IiIiISKE4DOb/2rvzsKjKxo3j98gyLAIiKIsmKpu4C26ghFsYKqaWS5aSplnuWqhEhTvaqi1a5pY77vmapmhEGe64paSWBi6gIosKyDKc3x/+nBoZthzmnEfvz3vNdb2cOXPm65mAh4dnDkRERERkNNW4CqZSOLNORERERKRQHKwTERERESkUl8EQERERkdHwajCVw5l1IiIiIiKF4mCdiIiIiEihuAyGiIiIiIxGxVUwlcKZdSIiIiIiheJgvQJi1q9FSHAXtGnVDIP690Pi8WNyJ+klQqcIjYAYnSI0AmJ0itD4b8uWfoNWzRrho/lz5U4pQWnn8sTxY3hnwmiEBgfB37cx4uP26dw/K+pd+Ps21rmNGDqoynreeTkABxYNw82d7yB5y0RsnPkSPJ+pWWI/73oO2DS7P9J2vI2bO99B/Jev4Znattr7zc1M8Om4YFzZNgnpP4Rj0+z+qONoU2XdZVHaa66P0huPHzuKcaPfRLdOHdGiiTd+2r+v/AcJTKWgmwgUP1i/ceMGZs6cKdvz/7h7Fz6cF42Rb7yFmM3b4evrh9GjRiL1+nXZmvQRoVOERkCMThEaATE6RWj8t7O/n8HWzRvh6eUtd0oJSjyX9+/nwtPLG29Pfa/UfdoHdMTOvfHa2ydffF1lPYEt6uHr748jaOxK9ApfBxOTatj54WBYWZhp92ngWgP7Fw7FhZTb6D55DdqOXIro1Qdwv6BIu89HY55D747eGDprG7pOWIXqlubYMncgqhn5r80o8TV/lAiNeXm58Pb2xrTID+ROIQVS/GA9LS0NM2bMkO35V3+3An1ffBH9XuqPhu7umBIRCWcXZ2yMWS9bkz4idIrQCIjRKUIjIEanCI0P5ebm4N1p7+D9qFmwtbUt/wFGpsRz6d/hWYwaMwGduj5X6j7m5uZwcKylvdnZ1aiynhembcCaPaeR9Hc6zly6iVEf7kQ9Jzu08nLW7jNjeCfsOfIXIpf8hFN/3sDfqVn48fCfuJWVCwCwtVbjtZCWmLZ4H+IS/8apP29g+Nzv0bRBLXTxbVBl7foo8TV/lAiNHQODMHbCJHR7LljuFFIg2Qfrp0+fLvN2/vx52doKCwqQdO4s/AM66mz3D+iAUydPyFRVkgidIjQCYnSK0AiI0SlC479Fz5mJwMBOaO8fIHdKCaKdy39LPHYUPbp2xIA+IYie9QEyMm4b7bltrdUAgMw79wE8eOPd8+09cPFKBnbMH4TkLRPxy1evIbSDl/YxrbycYW5mgn3HLmu3pd6+h7N/30L7JnWN1i7Cay5C49OomkqlmJsIZL8aTMuWLaFSqSBJUon7Hm5XyXQyM7MyodFo4ODgoLPdwcER6em3ZGnSR4ROERoBMTpFaATE6BSh8aEfd/+AP86dw5oNm+VO0Uukc/lv/gGB6NKtO5xdXHH92lV8u/hzjBs1DCvWboa5uXmVP//80d3w2+kUnPv7wTmqXcMaNlZqvPOyP2asiMd7S+IQ3LYhNsx4Cd0nr8GB0ylwtq+O/IIiZN27r3Osm5k5cKppXeXND4nwmovQSFQe2QfrDg4OmD9/Prp27ar3/rNnzyI0NLTMY+Tn5yM/P19nm2SihlqtNkjjoz8syPkDRFlE6BShERCjU4RGQIxOpTempaXio3lzsWjJMoN9XasqSj+Xj+rWPUT7/909POHTuCn69uyKhF/jy1w6Ywifje+OZg1ro+v4VdptD9ec70y4gC82HwEAnP7rBto1qYuRvX1x4HRKqcdTAdAz71XlRHjNRWgkKo3sg3U/Pz9cv34dbm5ueu/PysrSO+v+b9HR0SXWtUe+H4X3Ppj+WG32NexhYmKC9PR0ne0ZGbfh4OD4WMc2JBE6RWgExOgUoREQo1OERgBIOnsWGRm38crAF7XbNBoNEo8fQ8z6tTh8/DRMTExkLBTnXJbHsVYtOLu44sqV5Cp9nk/HBaNXgBe6TVyFa+l3tdvTs3NRWKRBUrLueTyfnI6AZs8AANIy70Ftbooa1S10Ztdr2Vvj0NlrVdr9byK85iI0Po34Y1LlyL5mfdSoUahfv36p99erVw8rVqwo8xgRERHIzs7WuYVPjXjsNjNzc/g0boJDCb/pbD+UkIAWLVs99vENRYROERoBMTpFaATE6BShEQDatm+PTVt3YMOmbdpb4yZN0aNnKDZs2ib7QB0Q51yWJzsrCzdvpMHBsVaVPcdn47vjhcBGeP7tNUhOy9a5r7CoGMfPp8LrGd1lG57POCDlxoN9T1xIQ0GhBl39/nkzqXPN6mhSvxYOnb1aZd2PEuE1F6GRqDyyz6z37du3zPvt7e0RFhZW5j5qdcklL/eLStm5koaEDUPktClo3LQpWrRohS2bYpCamor+A6vuOrz/hQidIjQCYnSK0AiI0SlCo7V1dXh4eulss7S0hF2NGiW2y0mJ5zI3NwdXr/yzdOT6tWu4cD4JtrZ2sLWzw9JvvkLnLsFwrFULqdevYfGXC2BXwx5BnbtVSc+CCc9jYNcm6P/eJtzLLYCT/YM15tk5+dpLM34Wcwir3++LA6dTEH8iGcFt3dHD3xPdJ60GANzJycfK3Scx761uuH0nD5l38xD9Zlf8fvkWfkq8XOpzVwUlvuaPEqExNycHKSn//Hd67epV/JGUBDs7O7i4uspYRkog+2C9PFeuXEFUVBSWL18uy/M/H9ID2VmZWLJ4EW7dugkPTy989fUSuLrWkaWnNCJ0itAIiNEpQiMgRqcIjaJQ4rn849xZjHnjNe3Hn386HwDQI7QPwiM+wKWLF/Hjzh24e/cOHB1rwbdNO8ye9wmsravmjZqjXvADAMQuGKKzfeT8/2HNntMAgB0HzmPcZ7sRPjgAn4wNxoUrGXg5agsSfv9n1nzKV7HQaIqx5oO+sFSbIe7E33gjMgbFxcZdtK7E1/xRIjSePfs7Rgwbqv344w+jAQC9X+iLWXPnyZVVdbgOplJUUnkLwmV26tQp+Pr6QqPRVOpxhppZJyJ6HMYePP0Xxv5DOv9Vbn7lvg/IoU6o8gdWmXsj5U4gI7NQ2NTsob+y5E7Qau9eQ+6Ecsn+8u3YsaPM+y9dumSkEiIiIiKqaipOrVeK7IP1Pn36lHqd9Yd4eSUiIiIiehrJfjUYFxcXbNmyBcXFxXpviYmJcicSEREREclC9sG6n59fmQPy8mbdiYiIiEgcKpVybiKQfRlMeHg4cnJySr3fw8MDcXFxRiwiIiIiIlIG2QfrgYGBZd5vbW2NoKAgI9UQERERESmH7IN1IiIiInp6CLL6RDFkX7NORERERET6cbBORERERKRQXAZDRERERMbDdTCVwpl1IiIiIiKF4sw6ERERERmNilPrlcKZdSIiIiIiheJgnYiIiIhIobgMhoiIiIiMRsVVMJXCmXUiIiIiIoXiYJ2IiIiISKG4DIaIiIiIjIarYCqHM+tERERERArFmXUiIiIiMh5OrVeKSpIkSe6IqnC/SO4CIiIi5bFvM1buhArJOPKl3AnlEuWqJhYKm5pNTL4jd4KWr5ut3Anl4jIYIiIiIiKFUtjPWkRERET0JFNxHUylcGadiIiIiEihOFgnIiIiIqqgRYsWoUGDBrCwsICfnx9+/fXXUvfdunUrnnvuOdSqVQu2trbw9/fHnj17KvV8HKwTERERkdGoVMq5VVZMTAwmTpyIyMhInDhxAoGBgQgJCUFKSore/X/55Rc899xz2LVrF44fP47OnTsjNDQUJ06cqPj54tVgiIiInh68Gozh8Gow/83JlLtyJ2i1rGdTqf3btWsHX19fLF68WLvNx8cHffr0QXR0dIWO0aRJEwwcOBAffPBBhfbnzDoRERERUTkKCgpw/PhxBAcH62wPDg5GQkJChY5RXFyMu3fvombNmhV+XoX9rEVERERETzIl/UIiPz8f+fn5OtvUajXUanWJfdPT06HRaODk5KSz3cnJCWlpaRV6vk8++QQ5OTkYMGBAhRs5s05ERERET6Xo6GjY2dnp3MpbzqJ6ZP2TJEkltumzfv16TJ8+HTExMahdu3aFGzmzTkRERETGo6Cp9YiICEyePFlnm75ZdQBwdHSEiYlJiVn0mzdvlphtf1RMTAxef/11bNq0Cd26datUI2fWiYiIiOippFarYWtrq3MrbbBubm4OPz8/xMbG6myPjY1FQEBAqc+xfv16vPbaa1i3bh169uxZ6UbOrBMRERERVcDkyZMxZMgQtG7dGv7+/liyZAlSUlLw5ptvAngwU3/t2jWsWrUKwIOB+tChQ7Fw4UK0b99eOytvaWkJOzu7Cj0nB+tEREREZDQqJa2DqaSBAwfi9u3bmDlzJlJTU9G0aVPs2rULbm5uAIDU1FSda65/8803KCoqwpgxYzBmzBjt9rCwMKxcubJCz8nrrBMRET1FeJ11w+F11v+b01fuyZ2g1fyZ6nInlItr1omIiIiIFEphP2sRERER0ZNMlN9IKAVn1omIiIiIFIqDdSIiIiIiheJgvQJi1q9FSHAXtGnVDIP690Pi8WNyJ+klQqcIjYAYnSI0AmJ0itAIiNEpQiMgRqecjR183bF5wShc2jsHeSe+RGin5jr3L5nxKvJOfKlzi//ubZ199nw7ocQ+q+YNM9q/4aHjx45i/Jg38VznjmjZ1Bs/7d9n9IaKEuG/S0NQKegmAsUM1q9evYp790q+O7iwsBC//PKLDEUP/Lh7Fz6cF42Rb7yFmM3b4evrh9GjRiL1+nXZmvQRoVOERkCMThEaATE6RWgExOgUoREQo1PuRmtLNc5cuIZJ8zaWus+e386ifrcI7a3PuMUl9lm25TedfcbOXl+V2Xrl5eXCy9sb0979wOjPXRlyv+akXLIP1lNTU9G2bVu4ubmhRo0aCAsL0xm0Z2RkoHPnzrL1rf5uBfq++CL6vdQfDd3dMSUiEs4uztgYY/wvOGURoVOERkCMThEaATE6RWgExOgUoREQo1Puxr2/ncOMRTvx/U+nSt2noKAIN27f1d4y7+SW2CfvfoHOPnfu3a/KbL06BgZh7PhJ6PpcsNGfuzLkfs2NSu7pdMGm1mUfrE+bNg0mJiY4fPgwfvzxR5w7dw6dOnVCZmamdh+5LgVfWFCApHNn4R/QUWe7f0AHnDp5QpYmfUToFKEREKNThEZAjE4RGgExOkVoBMToFKERAAJbeyJ5fzROb/8AX73/MmrZl7xe9cAerXHlp3k4vjkS0ZP6orqV/j/j/rQT5TUnech+6cZ9+/Zh27ZtaN26NQAgMDAQAwcORJcuXbB//34AgEqma/xkZmVCo9HAwcFBZ7uDgyPS02/J0qSPCJ0iNAJidIrQCIjRKUIjIEanCI2AGJ0iNO797Ry2xp5ASmoG6tdxwAeje2H3kvEIGPwhCgof/FXCDbuO4u/rt3Ej/Q6aeLhi5rhQNPOqg15vKf+PHRmbCK85yUf2wXp2djbs7e21H6vVamzevBn9+/dH586dsWbNmnKPkZ+fj/z8fJ1tkokaarVhfoJ/9IcFSZJk+wGiLCJ0itAIiNEpQiMgRqcIjYAYnSI0AmJ0Krlx895E7f8/91cqEs+l4PyumQgJbKJdOrNiW4LOPn+m3ETCuqlo2aguTv5x1ejNIlDya25IKlHWnyiE7MtgGjZsiNOnT+tsMzU1xaZNm9CwYUP06tWr3GNER0fDzs5O5/bR/OjHbrOvYQ8TExOkp6frbM/IuA0HB8fHPr6hiNApQiMgRqcIjYAYnSI0AmJ0itAIiNEpQuOj0tLvICU1Ax71apW6z4mkKygoLIJHvdpGLBODiK85GY/sg/WQkBAsWbKkxPaHA/aWLVuWu2Y9IiIC2dnZOrfwqRGP3WZmbg6fxk1wKOE3ne2HEhLQomWrxz6+oYjQKUIjIEanCI2AGJ0iNAJidIrQCIjRKULjo2raWaOukz1S0++Uuk9jdxeYm5kiNT3biGViEPE1J+ORfRnMnDlzkJtb8h3kwIMB+9atW3H1atm/LlOrSy55uV9kmL4hYcMQOW0KGjdtihYtWmHLphikpqai/8BBhnkCAxGhU4RGQIxOERoBMTpFaATE6BShERCjU+5Ga0tzuD/zzyx5/ToOaO5VB5l3cpGRnYP33uyJ7ftPIvVWNtxcHTBzXChuZ93Djv9fAtOgriMG9WiNPQfOIT3zHnzcnTFvUj+cSLqCgycvGeXf8FBubg5SUlK0H1+7dhV//JEEOzs7uLi4GrWlLHK/5sb0BK7sqVKyD9ZNTU1ha2tb6v3Xr1/HjBkzsHz5ciNW/eP5kB7IzsrEksWLcOvWTXh4euGrr5fA1bWOLD2lEaFThEZAjE4RGgExOkVoBMToFKEREKNT7kbfxm7Yu3SC9uMP33kRALB6xyGMnxuDJh6uGNyrLWrYWCIt/Q7ij17AkKnLcS/3wfvHCguL0LmtN8a83BnVrcxxNS0LPx74HXO+2Y3iYuNe4e3s779j5PCh2o8/+fDBMtnQF/pi1px5Rm0pi9yvOSmXSpLruogVdOrUKfj6+kKj0VTqcYaaWSciInqS2LcZK3dChWQcUf5VY0SZIbaQfWpW17nrOXInaDV2tZY7oVyyv3w7duwo8/5Ll4z76zIiIiIiqjqC/IyjGLIP1vv06QOVSlXmm0ifxMsWERERERGVR/arwbi4uGDLli0oLi7We0tMTCz/IEREREQkBpWCbgKQfbDu5+dX5oC8vFl3IiIiIqInlezLYMLDw5GTU/obDTw8PBAXF2fEIiIiIiIiZZB9sB4YGFjm/dbW1ggKCjJSDRERERFVJZUo608UQvZlMEREREREpB8H60RERERECiX7MhgiIiIienrwityVw5l1IiIiIiKF4sw6ERERERkNJ9YrhzPrREREREQKxcE6EREREZFCcRkMERERERkP18FUCmfWiYiIiIgUioN1IiIiIiKF4jIYIiIiIjIaFdfBVApn1omIiIiIFIqDdSIiIiIiheIyGCIiIiIyGhVXwVSKSpIkSe6IqnC/SO4CopKKNGJ8upma8CupoYjwFVaUb5x5BRq5E8plYWYid0K5RPm279DrY7kTypW5K1zuhAqxUNjU7J838+RO0PKobSl3QrkU9vIRERER0ZNMkPkBxeCadSIiIiIiheJgnYiIiIhIobgMhoiIiIiMh+tgKoUz60RERERECsXBOhERERGRQnEZDBEREREZjYrrYCqFM+tERERERArFwToRERERkUJxGQwRERERGY0ofzVZKTizTkRERESkUJxZJyIiIiKj4cR65XBmnYiIiIhIoThYJyIiIiJSKC6DISIiIiLj4TqYSuHMOhERERGRQnGwTkRERESkUFwGQ0RERERGo+I6mErhzHoFxKxfi5DgLmjTqhkG9e+HxOPH5E7SS4ROERoB5Xd+s+gL+DVvpHML7txR7iy9lH4uAeU3Hj92FOPHvInnOndEy6be+Gn/PrmTSqW0c3ni+DG8PWE0ej0XhPatGiM+Tvfcxe2PxYTRI9G9cwDat2qMC+eTZCrVJcJrvjFmPQb0642O7f3Qsb0fhr4yEAd+/cVoz//OoHY48MWruLl9ApI3jsbG6X3gWddee7+pSTXMfv1ZHP3mNaTvmIBL69/C0vAecKlprd3H3sYCn47uilPLXsftHRNxYc0ofDK6C2ytzI327/g3pX3+kDIoYrB++/ZtxMXFISMjAwCQnp6O+fPnY+bMmUhKkvcL54+7d+HDedEY+cZbiNm8Hb6+fhg9aiRSr1+XtetRInSK0AiI0+nu7ok9P/2qvcVs2SF3UgkinEsRGvPycuHl7Y1p734gd0qZlHgu8/Jy4enljbenvaf3/vt5eWjeohVGj5ts5LKyifCaOzk5YdzEt7F2w2as3bAZbdu1x6TxY/DXnxeN8vyBzZ7B1ztOIGjCGvSatgkm1aphZ3R/WFmYAQCs1KZo6emEeWsPwn/0KgyasR2ede2xaWY/7TFcHKrDxaE6Ir79Ga1HrcTIj3fjudYN8PXbzxvl3/BvSvz8qSoqlXJuIlBJkiTJGXDkyBEEBwfjzp07qFGjBmJjY9G/f3+YmppCkiRcu3YNBw4cgK+vb6WOe7/IMH2vDOoPn8aN8d4HM7Tb+oSGoHOXbpgw6W3DPIkBiNApQiNQtZ1FGsN8un2z6Av8HLcf6zdtN8jxHmVqYpivYCK85lXdaOivsC2beuPThV+hS9duBjumob5hVfW5zCvQPNbj27dqjPmffo6gziXP3fXr19Cv53NYtWELvLx9/vNzWJiZPE6iXoZ+zavy235Qh3aY+HY4+vZ76bGP5dDr40rt72hniSubxqLb2+vx25mrevfx83LGgS+HwOuVr3Hl1l29+/QL9MLyqT3h0HsBNMVln6vMXeGVaixLVX7+WChs0XNKRr7cCVr1aqrlTiiX7DPrkZGR6N+/P7Kzs/Huu++iT58+6Nq1Ky5cuICLFy9i8ODBmDVrlixthQUFSDp3Fv4BussL/AM64NTJE7I06SNCpwiNgDidAJCSnIzuXQMR+nxXREyZjKtXr8idpEOEcylCoyh4Lp9uGo0GP+7+AXl5uWjeoqUsDbbWDwZdmXfvl7lPcbGErJzSB4u21mrcyS0od6BuSPz8obLI/rPW8ePH8fnnn8PGxgYTJkzA1KlTMXLkSO39Y8aMQWhoqCxtmVmZ0Gg0cHBw0Nnu4OCI9PRbsjTpI0KnCI2AOJ1Nm7XAzDnzUM+tPjIybmPZksUYPuRlbNz2P9SoYV/+AYxAhHMpQqMoeC6fThcvnEfYqy+joCAfllZW+GTBl3B395ClZf6ozvjtzFWc+ztd7/1qMxPMev1ZxMQl4W5ugd59atpYIOIVfyzbdaoqU0t42j5/BFl9ohiyD9YLCgpgaWkJADAzM4OVlRUcHR219zs4OOD27dtlHiM/Px/5+bo/JUsmaqjVhvnVhuqR3xFLklRimxKI0ClCI6D8zg6Bz+p83Lx5S7zQMxg7d2zHq0OHyVSln9LPJSBGoyh4Lp8u9Rs0wIbN23D37h3sj92LD96bhqUrVht9wP7Z2G5o1qAWuk5ep/d+U5NqWB0ZimoqFSZ8Eat3Hxsrc2yb/SKSUm5jzuqEqswtFT9/SB/Zl8E888wzuHTpkvbjDRs2wMXFRftxamqqzuBdn+joaNjZ2encPpof/dht9jXsYWJigvR03Z/SMzJuw8Gh7CZjEqFThEZAnM5HWVpZwcPTCynJyXKnaIlwLkVoFAXP5dPJzMwc9eq5oUmTZhg/8W14eTXC+jWrjNrw6eiu6OXvju5TYnAt/V6J+01NqmHte73h5mSHXtM26p1Vr25phh1zXsK9vEIMnL4dRZpiY6Rr8fOHyiL7YH3QoEG4efOm9uOePXtqZ9oBYMeOHWjbtm2Zx4iIiEB2drbOLXxqxGO3mZmbw6dxExxK+E1n+6GEBLRo2eqxj28oInSK0AiI0/mogoICXL70Fxxr1ZI7RUuEcylCoyh4LukBCQUF+peYVIXPxnTFCx098Xx4DJLTskvc/3Cg7l6nBnpO24gMPevZbazMsTN6AAqKNHgpaivyCx/vjcz/xdP2+SP3FWBEuxqM7MtgoqKiyrw/MjISJiZlv7terS655MVQV4MZEjYMkdOmoHHTpmjRohW2bIpBamoq+g8cZJgnMBAROkVoBMTo/Ozj+Xi2U2c4O7tq16zn5NxDaO8+cqfpEOFcitCYm5uDlJQU7cfXrl3FH38kwc7ODi4urjKW6VLiuczNzcHVK/+cu+vXruHC+STY2trB2cUV2dlZuJGWivT/nzRK/vtvAA/WCjs4yvfDrwiv+RcLP0WHjs/C2dkZOTk52PPjLhw7egRfLf7WKM+/YFw3DOzsg/5R23AvrxBO9g+un56dk4/7BUUwqabCuvd7o5WnE/q9vxUm1app98m4m4fComJUtzTDzuj+sFSbYdj8H2BrpYat1YPxxK3sXBQb8U2mSvz8IWWQ/dKN5bly5QqioqKwfPnySj3OUIN14MEfKVi5fBlu3boJD08vhE+NgF/rNoZ7AgMRoVOERqDqOg116caIKZORePwosjKzYF/THs2atcBbYyegoYHWiRrq0o2AGK95VTYa4ivs0SOHMXL40BLbQ1/oi1lz5j328Q05u1SV5/K/XLrx+LEjGDPytRLbe4T2wQcz52Lnjm2YHRVZ4v7XR43GyDfHVvr5DHXpxqp8zQ31bX/6B5E4cvgg0m/dQnUbG3h6emPY8BFoH9DBIMcv79KNeXv1XzZx5Ee7sCb2LOo52eL86lF69wl+ZwN+PX0Fgc2fwd6P9Q+GvYd8g5Qbd8psMOSlG4Gq+/xR2qUbr2Yq59KNde2Vf+lGxQ/WT506BV9fX2g0lfsibcjBOpGhGGqwXtUMOVh/2in7K+wDovwq+HGvs24MVXGddUNT+Ld9rcpeZ10Ohh6sVxXlDdaNt1SqPHXt5flrtZUh+8u3Y0fZf3Xx328+JSIiIiJ6msg+WO/Tpw9UKlWZP+nzskVERERETwYO6ypH9qvBuLi4YMuWLSguLtZ7S0xMlDuRiIiIiEgWsg/W/fz8yhyQlzfrTkRERET0pJJ9GUx4eDhycnJKvd/DwwNxcXFGLCIiIiKiqsJVMJUj+2A9MDCwzPutra0RFBRkpBoiIiIiIuWQfRkMERERERHpJ/vMOhERERE9PXg1mMrhzDoRERERkUJxsE5EREREpFBcBkNERERERqPi9WAqhTPrREREREQKxZl1IiIiIjIeTqxXCmfWiYiIiIgUioN1IiIiIiKF4jIYIiIiIjIaroKpHM6sExEREREpFAfrREREREQKxWUwRERERGQ0Kq6DqRTOrBMRERERKZRKkiRJ7oiqcL9I7gIiInra5BVo5E4oV7Eg3/at1cr/5b9974VyJ1RI3q4JcifouHm3UO4Erdo2ZnInlEv5nwlERERE9MRQ8XowlcJlMERERERECsWZdSIiIiIyHk6sVwpn1omIiIiIFIqDdSIiIiIiheIyGCIiIiIyGq6CqRzOrBMRERERKRQH60RERERECsVlMERERERkNCqug6kUzqwTERERESkUZ9aJiIiIyGj4F0wrhzPrREREREQKxcE6EREREZFCcRkMERERERkN32BaOZxZJyIiIiJSKA7WiYiIiIgUioN1IiIiIiKF4mCdiIiIiEihOFivgJj1axES3AVtWjXDoP79kHj8mNxJeonQKUIjIEanCI2AGJ0iNAJidIrQCCi7c8vGDXhlQB906dgGXTq2wYihLyPhwC9yZ5Vp1fJvEeDbBAs+ipY7RS+lvd6uDtZY/k53XN3wBm5vHY1DXwxGK4/a2vsjX2mHk98MQfrW0bgeMwo/zOmLNt5OMhaTnBQ7WG/YsCEuXrwodwZ+3L0LH86Lxsg33kLM5u3w9fXD6FEjkXr9utxpOkToFKEREKNThEZAjE4RGgExOkVoBJTfWdvJCWPGTcLKtZuwcu0m+LVthymTxuLSX/J/T9Tn3Nkz+H7rJnh4esmdopfSXu8a1dX46eMBKNQUo88H36PVm6sxbemvyLqXr93nz2tZmLT4Z7QevQZdwzch+eYd/G92XzjaWsrSbGgqlXJuIlBJkiTJGfD555/r3T558mRMmTIFzs7OAIDx48dX6rj3ix47DQDwyqD+8GncGO99MEO7rU9oCDp36YYJk942zJMYgAidIjQCYnSK0AiI0SlCIyBGpwiNQNV25hVoHjdPr+Cg9hg7MRy9+7742McqNuC3/dzcHAwb3B/vRLyPlUu/gaeXNyaGRxjk2NZqw1xduipfb/veCyv9mFmvdYB/Yxd0m7K5wo+xsTTHzS1vISRiK34+daXSz5m3a0KlH1OVsvKq5vPkv6hhaSJ3Qrlkv876xIkTUadOHZia6qYUFxdj1apVMDMzg0qlqvRg3RAKCwqQdO4sho94Q2e7f0AHnDp5wug9pRGhU4RGQIxOERoBMTpFaATE6BShERCn8yGNRoOfYvcgLy8PzZq3kDunhE/mzUZAx2fRpp0/Vi79Ru6cEpT4evds3wD7jqdgbUQPdGxWB9dv38OSnaexYs9ZvfubmVbD6yFNkXUvH2cu3zJybdVQQZApbYWQfbA+cuRIHDlyBOvWrYOPj492u5mZGfbu3YvGjRvL1paZlQmNRgMHBwed7Q4OjkhPV84njAidIjQCYnSK0AiI0SlCIyBGpwiNgDidf168gJFhL6OgoACWllaY/8nnaODuIXeWjtg9u3D+jyQsWx0jd0qplPh6N3C2w8iezfD5thP4MOYoWns74ZM3OyG/UIN1P/2h3S+kbQOsmvo8rNRmSMvIQa/Ibbh9574szSQv2Qfr33zzDbZv347u3btjypQpGDt2bKWPkZ+fj/z8fJ1tkokaarXaII2qRxY1SZJUYpsSiNApQiMgRqcIjYAYnSI0AmJ0itAIKL/TrX59rNqwFffu3kXc/r2Y+cG7WLz0O8UM2G+kpWLBR/OwYNESg32vrUpKer2rqVRIvHgDUd8lAABOXbqFxvUc8EbP5jqD9fhTV9Bu7Do42lpi2PNNsSYiBM9OisGt7DxZukk+iniDaZ8+fXDw4EFs27YNISEhSEtLq9Tjo6OjYWdnp3P7aP7jvyPdvoY9TExMkJ6errM9I+M2HBwcH/v4hiJCpwiNgBidIjQCYnSK0AiI0SlCIyBOp5mZOZ6p5wafJk0xevxkeHh5I2b9armztP5IOofMjNsY/soABLZpjsA2zXHi+FFs2rAWgW2aQ6NRxppkJb7eaZk5SLqSobPtjysZeKaWjc623PwiXErNxpHzaXhr4T4UaSSEdW9izNQqI/ebSkV7g6kiBusAUKdOHezbtw/PPvssWrVqhcq87zUiIgLZ2dk6t/Cpj/8GFzNzc/g0boJDCb/pbD+UkIAWLVs99vENRYROERoBMTpFaATE6BShERCjU4RGQJzOkiQUFBTKHaHVum17rN64HSvXb9HeGjVuguCQXli5fgtMTJTxpj0lvt4Hz6XCq469zjbPOvZIuXmnzMepVIDaTBnnlYxL9mUw/6ZSqRAREYHg4GAcOHAALi4uFXqcWl1yyYuhrgYzJGwYIqdNQeOmTdGiRSts2RSD1NRU9B84yDBPYCAidIrQCIjRKUIjIEanCI2AGJ0iNALK71z8xWfw7xCI2s4uyM3JQeyeXUg8dhSffbVE7jQta2truHt46myztLSCnZ1die1yU9rr/cW2E4j7pD/CB7TBll8voI23M4aHNMXYz/cDAKzUppg6qC1+OHQJaZk5qGljgTd6NUcdx+rY+qsyL99JVUtRg/WH/Pz84OfnBwC4cuUKoqKisHz5cllang/pgeysTCxZvAi3bt2Eh6cXvvp6CVxd68jSUxoROkVoBMToFKEREKNThEZAjE4RGgHld2bcvo3p703D7fRbqF7dBu6eXvjsqyVo1z5A7jQhKe31Pn7xBgbO/gEzXwvAu4Pb4u+0Owj/Jh4bfj4PANAUS/Cua49XI3vCwc4CGXfu49iFG+gWvhlJKRnlHF0Mgqw+UQzZr7NenlOnTsHX17fS698MNbNORERUUVV1nXVDMuR11quSoa6zXpX+y3XW5aC066zfvV8sd4KWjYViVoSXSvbPhB07dpR5/6VLl4xUQkRERESkLLIP1vv06QOVSlXmG0qVdDktIiIiInoMHNZViuxz/y4uLtiyZQuKi4v13hITE+VOJCIiIiKSheyDdT8/vzIH5OXNuhMRERGROFQK+p8IZF8GEx4ejpycnFLv9/DwQFxcnBGLiIiIiIiUQfbBemBgYJn3W1tbIygoyEg1RERERETKIftgnYiIiIieHrxuSOXIvmadiIiIiIj042CdiIiIiEihuAyGiIiIiIyGq2AqhzPrREREREQKxcE6EREREZFCcRkMERERERkP18FUCmfWiYiIiIgUijPrRERERGQ0Kk6tVwpn1omIiIiIKmjRokVo0KABLCws4Ofnh19//bXM/ePj4+Hn5wcLCws0bNgQX3/9daWej4N1IiIiIqIKiImJwcSJExEZGYkTJ04gMDAQISEhSElJ0bv/5cuX0aNHDwQGBuLEiRN49913MX78eGzZsqXCz6mSJEky1D9ASe4XyV1ARERPm7wCjdwJ5SoW5Nu+tVr5K3Xtey+UO6FC8nZNkDtBh5LGaBaV/M+sXbt28PX1xeLFi7XbfHx80KdPH0RHR5fYf+rUqdixYweSkpK02958802cOnUKBw8erNBzcmadiIiIiKgcBQUFOH78OIKDg3W2BwcHIyEhQe9jDh48WGL/7t2749ixYygsLKzQ8yr/x1YiIiIioiqQn5+P/Px8nW1qtRpqtbrEvunp6dBoNHByctLZ7uTkhLS0NL3HT0tL07t/UVER0tPT4eLiUn6kRBVy//59KSoqSrp//77cKaUSoVGSxOgUoVGSxOgUoVGSxOgUoVGSxOgUoVGSxOgUoVGSxOgUofFJExUVJQHQuUVFRend99q1axIAKSEhQWf77NmzJW9vb72P8fT0lObOnauz7cCBAxIAKTU1tUKNT+yadUO7c+cO7OzskJ2dDVtbW7lz9BKhERCjU4RGQIxOERoBMTpFaATE6BShERCjU4RGQIxOERqfNJWZWS8oKICVlRU2bdqEvn37ardPmDABJ0+eRHx8fInHPPvss2jVqhUWLvzn/Q3btm3DgAEDkJubCzMzs3IbuWadiIiIiJ5KarUatra2Ojd9A3UAMDc3h5+fH2JjY3W2x8bGIiAgQO9j/P39S+y/d+9etG7dukIDdYCDdSIiIiKiCpk8eTKWLl2K5cuXIykpCZMmTUJKSgrefPNNAEBERASGDh2q3f/NN99EcnIyJk+ejKSkJCxfvhzLli3DO++8U+Hn5BtMiYiIiIgqYODAgbh9+zZmzpyJ1NRUNG3aFLt27YKbmxsAIDU1Veea6w0aNMCuXbswadIkfPXVV3B1dcXnn3+OF198scLPycF6BanVakRFRZX6qxElEKEREKNThEZAjE4RGgExOkVoBMToFKEREKNThEZAjE4RGgkYPXo0Ro8erfe+lStXltgWFBSExMTE//x8fIMpEREREZFCcc06EREREZFCcbBORERERKRQHKwTERERESkUB+vl+OWXXxAaGgpXV1eoVCps375d7qQSoqOj0aZNG9jY2KB27dro06cPzp8/L3dWCYsXL0bz5s211zH19/fH7t275c4qU3R0NFQqFSZOnCh3io7p06dDpVLp3JydneXOKuHatWt49dVX4eDgACsrK7Rs2RLHjx+XO0tH/fr1S5xLlUqFMWPGyJ2mVVRUhPfeew8NGjSApaUlGjZsiJkzZ6K4uFjuNB13797FxIkT4ebmBktLSwQEBODo0aOyNpX3NVySJEyfPh2urq6wtLREp06dcPbsWUU1bt26Fd27d4ejoyNUKhVOnjxp1L6KdBYWFmLq1Klo1qwZrK2t4erqiqFDh+L69euKaQQefO1s1KgRrK2tYW9vj27duuHw4cNGbaxI57+NGjUKKpUKCxYsMFofKQsH6+XIyclBixYt8OWXX8qdUqr4+HiMGTMGhw4dQmxsLIqKihAcHIycnBy503TUrVsX8+bNw7Fjx3Ds2DF06dIFL7zwgtG/MVbU0aNHsWTJEjRv3lzuFL2aNGmC1NRU7e3MmTNyJ+nIzMxEhw4dYGZmht27d+PcuXP45JNPUKNGDbnTdBw9elTnPD784xX9+/eXuewf8+fPx9dff40vv/wSSUlJ+PDDD/HRRx/hiy++kDtNx4gRIxAbG4vVq1fjzJkzCA4ORrdu3XDt2jXZmsr7Gv7hhx/i008/xZdffomjR4/C2dkZzz33HO7evauYxpycHHTo0AHz5s0zWlNpHaV15ubmIjExEe+//z4SExOxdetWXLhwAb1791ZMIwB4eXnhyy+/xJkzZ3DgwAHUr18fwcHBuHXrlqI6H9q+fTsOHz4MV1dXI5WRIklUYQCkbdu2yZ1Rrps3b0oApPj4eLlTymVvby8tXbpU7owS7t69K3l6ekqxsbFSUFCQNGHCBLmTdERFRUktWrSQO6NMU6dOlTp27Ch3RqVNmDBBcnd3l4qLi+VO0erZs6c0fPhwnW39+vWTXn31VZmKSsrNzZVMTEyknTt36mxv0aKFFBkZKVOVrke/hhcXF0vOzs7SvHnztNvu378v2dnZSV9//bUMhWV/n7l8+bIEQDpx4oRRm/SpyPfDI0eOSACk5ORk40Q9oiKN2dnZEgBp3759xonSo7TOq1evSnXq1JF+//13yc3NTfrss8+M3kbKwJn1J1B2djYAoGbNmjKXlE6j0WDDhg3IycmBv7+/3DkljBkzBj179kS3bt3kTinVxYsX4erqigYNGmDQoEG4dOmS3Ek6duzYgdatW6N///6oXbs2WrVqhW+//VburDIVFBRgzZo1GD58OFQqldw5Wh07dsT+/ftx4cIFAMCpU6dw4MAB9OjRQ+ayfxQVFUGj0cDCwkJnu6WlJQ4cOCBTVdkuX76MtLQ0BAcHa7ep1WoEBQUhISFBxrInQ3Z2NlQqleJ+m/ZQQUEBlixZAjs7O7Ro0ULuHB3FxcUYMmQIwsPD0aRJE7lzSGb8o0hPGEmSMHnyZHTs2BFNmzaVO6eEM2fOwN/fH/fv30f16tWxbds2NG7cWO4sHRs2bEBiYqLsa23L0q5dO6xatQpeXl64ceMGZs+ejYCAAJw9exYODg5y5wEALl26hMWLF2Py5Ml49913ceTIEYwfPx5qtVrnTzEryfbt25GVlYXXXntN7hQdU6dORXZ2Nho1agQTExNoNBrMmTMHL7/8stxpWjY2NvD398esWbPg4+MDJycnrF+/HocPH4anp6fceXqlpaUBAJycnHS2Ozk5ITk5WY6kJ8b9+/cxbdo0DB48GLa2tnLn6Ni5cycGDRqE3NxcuLi4IDY2Fo6OjnJn6Zg/fz5MTU0xfvx4uVNIAThYf8KMHTsWp0+fVuxMlre3N06ePImsrCxs2bIFYWFhiI+PV8yA/cqVK5gwYQL27t1bYoZQSUJCQrT/v1mzZvD394e7uzu+++47TJ48WcayfxQXF6N169aYO3cuAKBVq1Y4e/YsFi9erNjB+rJlyxASEqK49aExMTFYs2YN1q1bhyZNmuDkyZOYOHEiXF1dERYWJnee1urVqzF8+HDUqVMHJiYm8PX1xeDBgx/rL/cZw6O/RZEkSVG/WRFNYWEhBg0ahOLiYixatEjunBI6d+6MkydPIj09Hd9++y0GDBiAw4cPo3bt2nKnAQCOHz+OhQsXIjExkf8dEgC+wfSJMm7cOOzYsQNxcXGoW7eu3Dl6mZubw8PDA61bt0Z0dDRatGiBhQsXyp2ldfz4cdy8eRN+fn4wNTWFqakp4uPj8fnnn8PU1BQajUbuRL2sra3RrFkzXLx4Ue4ULRcXlxI/hPn4+CAlJUWmorIlJydj3759GDFihNwpJYSHh2PatGkYNGgQmjVrhiFDhmDSpEmIjo6WO02Hu7s74uPjce/ePVy5cgVHjhxBYWEhGjRoIHeaXg+voPRwhv2hmzdvlphtp4opLCzEgAEDcPnyZcTGxipuVh148PXSw8MD7du3x7Jly2Bqaoply5bJnaX166+/4ubNm6hXr572+1BycjLefvtt1K9fX+48kgEH608ASZIwduxYbN26FT/99JNivzHqI0kS8vPz5c7Q6tq1K86cOYOTJ09qb61bt8Yrr7yCkydPwsTERO5EvfLz85GUlAQXFxe5U7Q6dOhQ4hKiFy5cgJubm0xFZVuxYgVq166Nnj17yp1SQm5uLqpV0/1ybWJiorhLNz5kbW0NFxcXZGZmYs+ePXjhhRfkTtKrQYMGcHZ21l4BCHiwjjk+Ph4BAQEylonp4UD94sWL2Ldvn2KW5JVHad+HhgwZgtOnT+t8H3J1dUV4eDj27Nkjdx7JgMtgynHv3j38+eef2o8vX76MkydPombNmqhXr56MZf8YM2YM1q1bh++//x42NjbaWSI7OztYWlrKXPePd999FyEhIXjmmWdw9+5dbNiwAT///DN+/PFHudO0bGxsSqz1t7a2hoODg6LeA/DOO+8gNDQU9erVw82bNzF79mzcuXNHUUsiJk2ahICAAMydOxcDBgzAkSNHsGTJEixZskTutBKKi4uxYsUKhIWFwdRUeV8WQ0NDMWfOHNSrVw9NmjTBiRMn8Omnn2L48OFyp+nYs2cPJEmCt7c3/vzzT4SHh8Pb2xvDhg2Tram8r+ETJ07E3Llz4enpCU9PT8ydOxdWVlYYPHiwYhozMjKQkpKivWb5wx+CnZ2djfr3FcrqdHV1xUsvvYTExETs3LkTGo1G+72oZs2aMDc3l73RwcEBc+bMQe/eveHi4oLbt29j0aJFuHr1qtEv1Vrea/7oDzpmZmZwdnaGt7e3UTtJIeS8FI0I4uLiJAAlbmFhYXKnaenrAyCtWLFC7jQdw4cPl9zc3CRzc3OpVq1aUteuXaW9e/fKnVUuJV66ceDAgZKLi4tkZmYmubq6Sv369ZPOnj0rd1YJ//vf/6SmTZtKarVaatSokbRkyRK5k/Tas2ePBEA6f/683Cl63blzR5owYYJUr149ycLCQmrYsKEUGRkp5efny52mIyYmRmrYsKFkbm4uOTs7S2PGjJGysrJkbSrva3hxcbEUFRUlOTs7S2q1Wnr22WelM2fOKKpxxYoVeu+PiopSTOfDy0rqu8XFxSmiMS8vT+rbt6/k6uoqmZubSy4uLlLv3r2lI0eOGK2vIp368NKNTzeVJEmS4X8EICIiIiKix8U160RERERECsXBOhERERGRQnGwTkRERESkUBysExEREREpFAfrREREREQKxcE6EREREZFCcbBORERERKRQHKwTERERESkUB+tEVKVWrlwJlUqlvZmamqJu3boYNmwYrl27ZpSG+vXr47XXXtN+/PPPP0OlUuHnn3+u1HESEhIwffp0ZGVlGbQPAF577TXUr1+/3P06deqEpk2bGuQ5H742x44dM8jx/n3Mv//+22DHJCJ6mnGwTkRGsWLFChw8eBCxsbEYOXIk1q9fj8DAQOTk5Bi9xdfXFwcPHoSvr2+lHpeQkIAZM2ZUyWCdiIhIH1O5A4jo6dC0aVO0bt0aANC5c2doNBrMmjUL27dvxyuvvKL3Mbm5ubCysjJ4i62tLdq3b2/w4xIRERkaZ9aJSBYPB8vJyckAHiwDqV69Os6cOYPg4GDY2Niga9euAICCggLMnj0bjRo1glqtRq1atTBs2DDcunVL55iFhYWYMmUKnJ2dYWVlhY4dO+LIkSMlnru0ZTCHDx9GaGgoHBwcYGFhAXd3d0ycOBEAMH36dISHhwMAGjRooF3W8+9jxMTEwN/fH9bW1qhevTq6d++OEydOlHj+lStXwtvbG2q1Gj4+Pli1atV/OoelOXbsGAYNGoT69evD0tIS9evXx8svv6w914/KzMzEsGHDULNmTVhbWyM0NBSXLl0qsd++ffvQtWtX2NrawsrKCh06dMD+/fsN2k5ERLo4WCciWfz5558AgFq1amm3FRQUoHfv3ujSpQu+//57zJgxA8XFxXjhhRcwb948DB48GD/88APmzZuH2NhYdOrUCXl5edrHjxw5Eh9//DGGDh2K77//Hi+++CL69euHzMzMcnv27NmDwMBApKSk4NNPP8Xu3bvx3nvv4caNGwCAESNGYNy4cQCArVu34uDBgzpLaebOnYuXX34ZjRs3xsaNG7F69WrcvXsXgYGBOHfunPZ5Vq5ciWHDhsHHxwdbtmzBe++9h1mzZuGnn356/JP6//7++294e3tjwYIF2LNnD+bPn4/U1FS0adMG6enpJfZ//fXXUa1aNaxbtw4LFizAkSNH0KlTJ53lPmvWrEFwcDBsbW3x3XffYePGjahZsya6d+/OATsRUVWSiIiq0IoVKyQA0qFDh6TCwkLp7t270s6dO6VatWpJNjY2UlpamiRJkhQWFiYBkJYvX67z+PXr10sApC1btuhsP3r0qARAWrRokSRJkpSUlCQBkCZNmqSz39q1ayUAUlhYmHZbXFycBECKi4vTbnN3d5fc3d2lvLy8Uv8tH330kQRAunz5ss72lJQUydTUVBo3bpzO9rt370rOzs7SgAEDJEmSJI1GI7m6ukq+vr5ScXGxdr+///5bMjMzk9zc3Ep97oeCgoKkJk2alLvfvxUVFUn37t2TrK2tpYULF2q3P3xt+vbtq7P/b7/9JgGQZs+eLUmSJOXk5Eg1a9aUQkNDdfbTaDRSixYtpLZt25Y45qPniIiI/hvOrBORUbRv3x5mZmawsbFBr1694OzsjN27d8PJyUlnvxdffFHn4507d6JGjRoIDQ1FUVGR9tayZUs4Oztrl6HExcUBQIn17wMGDICpadlvz7lw4QL++usvvP7667CwsKj0v23Pnj0oKirC0KFDdRotLCwQFBSkbTx//jyuX7+OwYMHQ6VSaR/v5uaGgICASj9vae7du4epU6fCw8MDpqamMDU1RfXq1ZGTk4OkpKQS+z96zgICAuDm5qY9pwkJCcjIyEBYWJjOv6+4uBjPP/88jh49KssbhYmIngZ8gykRGcWqVavg4+MDU1NTODk5wcXFpcQ+VlZWsLW11dl248YNZGVlwdzcXO9xHy7ruH37NgDA2dlZ535TU1M4ODiU2fZw7XvdunUr9o95xMOlMm3atNF7f7Vq1cpsfLjNUJc7HDx4MPbv34/3338fbdq0ga2tLVQqFXr06KGzbOjfz61v28Peh/++l156qdTnzMjIgLW1tUH6iYjoHxysE5FR+Pj4aK8GU5p/zzY/5OjoCAcHB/z44496H2NjYwMA2gF5Wloa6tSpo72/qKhIO+gszcN181evXi1zv9I4OjoCADZv3gw3N7dS9/t346P0bfsvsrOzsXPnTkRFRWHatGna7fn5+cjIyND7mNJ6PDw8APzz7/viiy9KvYrOo78hISIiw+BgnYgUrVevXtiwYQM0Gg3atWtX6n6dOnUCAKxduxZ+fn7a7Rs3bkRRUVGZz+Hl5QV3d3csX74ckydPhlqt1rvfw+2Pzk53794dpqam+Ouvv0os4/k3b29vuLi4YP369Zg8ebL2h5Pk5GQkJCTA1dW1zM6KUKlUkCSpxL9h6dKl0Gg0eh+zdu1ane6EhAQkJydjxIgRAIAOHTqgRo0aOHfuHMaOHfvYjUREVHEcrBORog0aNAhr165Fjx49MGHCBLRt2xZmZma4evUq4uLi8MILL6Bv377w8fHBq6++igULFsDMzAzdunXD77//jo8//rjE0hp9vvrqK4SGhqJ9+/aYNGkS6tWrh5SUFOzZswdr164FADRr1gwAsHDhQoSFhcHMzAze3t6oX78+Zs6cicjISFy6dAnPP/887O3tcePGDRw5cgTW1taYMWMGqlWrhlmzZmHEiBHo27cvRo4ciaysLEyfPl3vUpTS3LlzB5s3by6xvVatWggKCsKzzz6Ljz76CI6Ojqhfvz7i4+OxbNky1KhRQ+/xjh07hhEjRqB///64cuUKIiMjUadOHYwePRoAUL16dXzxxRcICwtDRkYGXnrpJdSuXRu3bt3CqVOncOvWLSxevLjC/UREVAlyv8OViJ5sD68OcvTo0TL3CwsLk6ytrfXeV1hYKH388cdSixYtJAsLC6l69epSo0aNpFGjRkkXL17U7pefny+9/fbbUu3atSULCwupffv20sGDByU3N7dyrwYjSZJ08OBBKSQkRLKzs5PUarXk7u5e4uoyERERkqurq1StWrUSx9i+fbvUuXNnydbWVlKr1ZKbm5v00ksvSfv27dM5xtKlSyVPT0/J3Nxc8vLykpYvXy6FhYVV+GowAPTegoKCJEmSpKtXr0ovvviiZG9vL9nY2EjPP/+89Pvvv5c4Dw9fm71790pDhgyRatSoIVlaWko9evTQOa8PxcfHSz179pRq1qwpmZmZSXXq1JF69uwpbdq0qcQxeTUYIiLDUEmSJMn0cwIREREREZWBl24kIiIiIlIoDtaJiIiIiBSKg3UiIiIiIoXiYJ2IiIiISKE4WCciIiIiUigO1omIiIiIFIqDdSIiIiIiheJgnYiIiIhIoThYJyIiIiJSKA7WiYiIiIgUioN1IiIiIiKF4mCdiIiIiEih/g8WAJLjQQzy0AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 88.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 88.58%\n"
     ]
    }
   ],
   "source": [
    "class_names = [str(i+1) for i in range(len(np.unique(y_labels)))]\n",
    "confusion_matrices_dir = 'confusion_matrices'\n",
    "os.makedirs(confusion_matrices_dir, exist_ok=True)\n",
    "print(f\"Saving confusion matrices to: {confusion_matrices_dir}\")\n",
    "plot_conf_matrix('e2e_cnn', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_mlp', class_names, confusion_matrices_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:26:53.929803Z",
     "iopub.status.busy": "2025-05-08T19:26:53.928803Z",
     "iopub.status.idle": "2025-05-08T19:26:53.936848Z",
     "shell.execute_reply": "2025-05-08T19:26:53.936848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          97.03\n",
      "1    LRM (CAE)          77.29\n",
      "2    MLP (CAE)          52.24\n",
      "3     TSCL LRM          86.06\n",
      "4     TSCL MLP          86.68\n",
      "5  SCL_SDL LRM          88.47\n",
      "6  SCL_SDL MLP          88.58\n",
      "\n",
      "In Desc. Order (Test Accu)\n",
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          97.03\n",
      "6  SCL_SDL MLP          88.58\n",
      "5  SCL_SDL LRM          88.47\n",
      "4     TSCL MLP          86.68\n",
      "3     TSCL LRM          86.06\n",
      "1    LRM (CAE)          77.29\n",
      "2    MLP (CAE)          52.24\n"
     ]
    }
   ],
   "source": [
    "final_results_df = pd.DataFrame({\n",
    "    \"Model\": [\"E2E CNN\", \"LRM (CAE)\", \"MLP (CAE)\", \"TSCL LRM\", \"TSCL MLP\", \"SCL_SDL LRM\", \"SCL_SDL MLP\"],\n",
    "    \"Test_Accuracy\": [test_accuracy, lrm_test_accuracy * 100, cae_mlp_test_accuracy_pct, \n",
    "                      tscl_lrm_test_accuracy * 100, tscl_mlp_test_accuracy_pct, \n",
    "                      sclsdl_lrm_test_accuracy * 100, sclsdl_mlp_test_accuracy_pct]\n",
    "})\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "print(final_results_df)\n",
    "print(f\"\\nIn Desc. Order (Test Accu)\\n{final_results_df.sort_values('Test_Accuracy', ascending=False)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
