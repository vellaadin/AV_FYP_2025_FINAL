{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependancy Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:26:56.337307Z",
     "iopub.status.busy": "2025-05-08T19:26:56.337307Z",
     "iopub.status.idle": "2025-05-08T19:26:56.340355Z",
     "shell.execute_reply": "2025-05-08T19:26:56.340355Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:26:56.343359Z",
     "iopub.status.busy": "2025-05-08T19:26:56.342359Z",
     "iopub.status.idle": "2025-05-08T19:26:58.403528Z",
     "shell.execute_reply": "2025-05-08T19:26:58.403528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-metric-learning in c:\\users\\vella\\anaconda3\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.5.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (2.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (4.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vella\\anaconda3\\lib\\site-packages (from tqdm->pytorch-metric-learning) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:26:58.405538Z",
     "iopub.status.busy": "2025-05-08T19:26:58.405538Z",
     "iopub.status.idle": "2025-05-08T19:27:01.797329Z",
     "shell.execute_reply": "2025-05-08T19:27:01.797329Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nbformat\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "from torch.amp import autocast, GradScaler\n",
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:01.800338Z",
     "iopub.status.busy": "2025-05-08T19:27:01.800338Z",
     "iopub.status.idle": "2025-05-08T19:27:01.817361Z",
     "shell.execute_reply": "2025-05-08T19:27:01.816852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:01.819363Z",
     "iopub.status.busy": "2025-05-08T19:27:01.819363Z",
     "iopub.status.idle": "2025-05-08T19:27:02.715314Z",
     "shell.execute_reply": "2025-05-08T19:27:02.715314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: (1476, 256)\n",
      "Hypercube shape: (1476, 256, 145)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dir = r\"C:\\Users\\vella\\Documents\\GitHub\\FYP2425_LOCAL\\FYP_DATASET\"\n",
    "\n",
    "gt_files = 'Botswana_gt.mat'\n",
    "data_files = 'Botswana.mat'\n",
    "label_files = 'Botswana_gt'\n",
    "hypercube_files = 'Botswana'\n",
    "\n",
    "def extract_Features():\n",
    "    gt_file = os.path.join(dataset_dir, gt_files)\n",
    "    data_file = os.path.join(dataset_dir, data_files)\n",
    "\n",
    "    gt = sio.loadmat(gt_file)\n",
    "    labels = gt[label_files]\n",
    "\n",
    "    data = sio.loadmat(data_file)\n",
    "    hypercube = data[hypercube_files]\n",
    "    #scaling the data in place and setting to float32 to reduce memory usage\n",
    "    max_value = np.max(hypercube)\n",
    "    hypercube = (hypercube / max_value).astype(np.float32)\n",
    "\n",
    "\n",
    "    #shapes of loaded data\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Hypercube shape: {hypercube.shape}\")\n",
    "\n",
    "    #visualisation of label map and a given band of hyperspectral data\n",
    "    plt.figure()\n",
    "    plt.imshow(labels)\n",
    "    plt.title('Labels')\n",
    "\n",
    "    band = 101\n",
    "    plt.figure()\n",
    "    plt.imshow(hypercube[:,:,band])\n",
    "    plt.title(f'Hyperspectral Band {band}')\n",
    "    plt.show()\n",
    "\n",
    "    return hypercube, labels\n",
    "\n",
    "hypercube, labels = extract_Features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:02.718138Z",
     "iopub.status.busy": "2025-05-08T19:27:02.718138Z",
     "iopub.status.idle": "2025-05-08T19:27:02.723998Z",
     "shell.execute_reply": "2025-05-08T19:27:02.723998Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_windows(data, labels, window_size):\n",
    "    extract_windows_save_dir = 'extracted_windows_labels'\n",
    "    if not os.path.exists(extract_windows_save_dir):\n",
    "        os.makedirs(extract_windows_save_dir)\n",
    "        print(f\"Created directory: {extract_windows_save_dir}\")\n",
    "\n",
    "    margin = window_size // 2\n",
    "    padded_data = np.pad(data, ((margin, margin), (margin, margin), (0, 0)), mode='constant')\n",
    "    padded_labels = np.pad(labels, ((margin, margin), (margin, margin)), mode='constant')\n",
    "\n",
    "    X_windows = []  #extracted windows\n",
    "    y_labels = []   #corresponding labels\n",
    "\n",
    "    print(\"Starting window extraction...\")\n",
    "    for i in range(margin, padded_data.shape[0] - margin):\n",
    "        for j in range(margin, padded_data.shape[1] - margin):\n",
    "            window = padded_data[i-margin:i+margin+1, j-margin:j+margin+1, :]\n",
    "            label = padded_labels[i, j]\n",
    "\n",
    "            if label != 0:\n",
    "                #print('ignoring label 0 (background)')\n",
    "                X_windows.append(window)\n",
    "                y_labels.append(label)\n",
    "\n",
    "    #convertying to numpy arrays\n",
    "    X_windows = np.array(X_windows)\n",
    "    y_labels = np.array(y_labels)\n",
    "\n",
    "    #saving extracted windows and labels\n",
    "    windows_file = os.path.join(extract_windows_save_dir, 'extracted_windows.npy')\n",
    "    labels_file = os.path.join(extract_windows_save_dir, 'extracted_labels.npy')\n",
    "\n",
    "    np.save(windows_file, X_windows)\n",
    "    np.save(labels_file, y_labels)\n",
    "\n",
    "    print(f\"Saved extracted windows to: {windows_file}\")\n",
    "    print(f\"Saved corresponding labels to: {labels_file}\")\n",
    "    print(f\"\\nTotal windows extracted: {len(X_windows)}\")\n",
    "    print(f\"Extracted windows shape: {X_windows.shape}\")\n",
    "    print(f\"Corresponding labels shape: {y_labels.shape}\")\n",
    "\n",
    "    return X_windows, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:02.726507Z",
     "iopub.status.busy": "2025-05-08T19:27:02.726507Z",
     "iopub.status.idle": "2025-05-08T19:27:03.520862Z",
     "shell.execute_reply": "2025-05-08T19:27:03.520862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: extracted_windows_labels\n",
      "Starting window extraction...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved extracted windows to: extracted_windows_labels\\extracted_windows.npy\n",
      "Saved corresponding labels to: extracted_windows_labels\\extracted_labels.npy\n",
      "\n",
      "Total windows extracted: 3248\n",
      "Extracted windows shape: (3248, 5, 5, 145)\n",
      "Corresponding labels shape: (3248,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "\n",
    "X_windows, y_labels = extract_windows(hypercube, labels, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:03.523872Z",
     "iopub.status.busy": "2025-05-08T19:27:03.522868Z",
     "iopub.status.idle": "2025-05-08T19:27:03.530364Z",
     "shell.execute_reply": "2025-05-08T19:27:03.530364Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_samples(X_windows, y_labels, samples_per_class):\n",
    "    \n",
    "    indices_save_dir = 'indices'\n",
    "    if not os.path.exists(indices_save_dir):\n",
    "        os.makedirs(indices_save_dir)\n",
    "        print(f\"Created directory: {indices_save_dir}\")\n",
    "    \n",
    "    #get unique classes\n",
    "    classes = np.unique(y_labels)\n",
    "    print(f\"Unique classes found as: {classes}\")\n",
    "\n",
    "    #init lists\n",
    "    X_sampled = [] #to store training samples\n",
    "    y_sampled = [] #to store training labels\n",
    "\n",
    "    X_val = [] # to store validation samples\n",
    "    y_val = [] # to store validation labels\n",
    "\n",
    "    selected_indices_total = [] #to store indices of selected training and validation samples\n",
    "    validation_selected = [] #temp storage for validation indices\n",
    "    validation_total = [] #to store all validation indices\n",
    "\n",
    "    print(\"\\n == STARTING SAMPLING PROCESS ==\")\n",
    "    for cls in classes:\n",
    "        if cls == 0:\n",
    "            print(f\"!! SKIPPING CLASS 0 !!\")\n",
    "            continue\n",
    "\n",
    "        #getting the indices for the current class:\n",
    "        class_indices = np.where(y_labels == cls)[0]\n",
    "        print(f\"Class: {cls}: Found {len(class_indices)} samples\")\n",
    "\n",
    "        # shuffle class-specific indices to ensure randomness\n",
    "        np.random.shuffle(class_indices)\n",
    "        print(f\"Shuffled class indices for class '{cls}'\")\n",
    "\n",
    "        #select 'samples_per_class' samples for training\n",
    "        selected_indices = class_indices[:samples_per_class]\n",
    "        #selecting 5 samples for validation\n",
    "        validation_selected = class_indices[samples_per_class:samples_per_class+5]\n",
    "\n",
    "        print(f\"Selected {len(selected_indices)} training samples and {len(validation_selected)} validation samples for class '{cls}'\\n\")\n",
    "\n",
    "        #store selected indices for training and validation\n",
    "        selected_indices_total.extend(selected_indices)\n",
    "        validation_total.extend(validation_selected)\n",
    "\n",
    "        # appending the selected samples and their labels to the lists\n",
    "        X_sampled.append(X_windows[selected_indices])\n",
    "        y_sampled.append(y_labels[selected_indices])\n",
    "\n",
    "        X_val.append(X_windows[validation_selected])\n",
    "        y_val.append(y_labels[validation_selected])\n",
    "\n",
    "    #concat the sampled arrays for training\n",
    "    X_train = np.vstack(X_sampled)\n",
    "    y_train = np.hstack(y_sampled)\n",
    "\n",
    "    # shift labels to start from 0\n",
    "    y_train = y_train - 1\n",
    "\n",
    "    print(f\"\\n -- Training set created with: \\n\\t{X_train.shape[0]} samples\\n\\tshape {X_train.shape} --\")\n",
    "\n",
    "    #concat the sampled arrays for validation\n",
    "    X_val = np.vstack(X_val)\n",
    "    y_val = np.hstack(y_val)\n",
    "    y_val = y_val - 1\n",
    "\n",
    "    print(f\"\\n -- Validation set created with: \\n\\t{X_val.shape[0]} samples\\n\\tshape {X_val.shape} --\")\n",
    "\n",
    "    #create the test set from the remaining data (i.e. that which is not selected for training or validation)\n",
    "    selected_indices_total.extend(validation_total)\n",
    "\n",
    "    #getting indices not in the training or val sets\n",
    "    test_indices = np.setdiff1d(np.arange(X_windows.shape[0]), selected_indices_total)\n",
    "    X_test = X_windows[test_indices]\n",
    "    y_test = y_labels[test_indices]\n",
    "    y_test = y_test - 1\n",
    "\n",
    "    print(f\"\\n -- Test set created with: \\n\\t{X_test.shape[0]} samples\\n\\tshape {X_test.shape} --\\n\")\n",
    "\n",
    "    # Save the datasets to the 'datasets' folder\n",
    "    np.save(os.path.join(indices_save_dir, 'X_train.npy'), X_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_train.npy'), y_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_val.npy'), X_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_val.npy'), y_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_test.npy'), X_test)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_test.npy'), y_test)\n",
    "\n",
    "    print(f\"\\nAll datasets saved to the '{indices_save_dir}' folder.\")\n",
    "\n",
    "    #return the training, val, test sets + selected indices\n",
    "    return X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:03.532372Z",
     "iopub.status.busy": "2025-05-08T19:27:03.532372Z",
     "iopub.status.idle": "2025-05-08T19:27:03.692992Z",
     "shell.execute_reply": "2025-05-08T19:27:03.692992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: indices\n",
      "Unique classes found as: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      " == STARTING SAMPLING PROCESS ==\n",
      "Class: 1: Found 270 samples\n",
      "Shuffled class indices for class '1'\n",
      "Selected 20 training samples and 5 validation samples for class '1'\n",
      "\n",
      "Class: 2: Found 101 samples\n",
      "Shuffled class indices for class '2'\n",
      "Selected 20 training samples and 5 validation samples for class '2'\n",
      "\n",
      "Class: 3: Found 251 samples\n",
      "Shuffled class indices for class '3'\n",
      "Selected 20 training samples and 5 validation samples for class '3'\n",
      "\n",
      "Class: 4: Found 215 samples\n",
      "Shuffled class indices for class '4'\n",
      "Selected 20 training samples and 5 validation samples for class '4'\n",
      "\n",
      "Class: 5: Found 269 samples\n",
      "Shuffled class indices for class '5'\n",
      "Selected 20 training samples and 5 validation samples for class '5'\n",
      "\n",
      "Class: 6: Found 269 samples\n",
      "Shuffled class indices for class '6'\n",
      "Selected 20 training samples and 5 validation samples for class '6'\n",
      "\n",
      "Class: 7: Found 259 samples\n",
      "Shuffled class indices for class '7'\n",
      "Selected 20 training samples and 5 validation samples for class '7'\n",
      "\n",
      "Class: 8: Found 203 samples\n",
      "Shuffled class indices for class '8'\n",
      "Selected 20 training samples and 5 validation samples for class '8'\n",
      "\n",
      "Class: 9: Found 314 samples\n",
      "Shuffled class indices for class '9'\n",
      "Selected 20 training samples and 5 validation samples for class '9'\n",
      "\n",
      "Class: 10: Found 248 samples\n",
      "Shuffled class indices for class '10'\n",
      "Selected 20 training samples and 5 validation samples for class '10'\n",
      "\n",
      "Class: 11: Found 305 samples\n",
      "Shuffled class indices for class '11'\n",
      "Selected 20 training samples and 5 validation samples for class '11'\n",
      "\n",
      "Class: 12: Found 181 samples\n",
      "Shuffled class indices for class '12'\n",
      "Selected 20 training samples and 5 validation samples for class '12'\n",
      "\n",
      "Class: 13: Found 268 samples\n",
      "Shuffled class indices for class '13'\n",
      "Selected 20 training samples and 5 validation samples for class '13'\n",
      "\n",
      "Class: 14: Found 95 samples\n",
      "Shuffled class indices for class '14'\n",
      "Selected 20 training samples and 5 validation samples for class '14'\n",
      "\n",
      "\n",
      " -- Training set created with: \n",
      "\t280 samples\n",
      "\tshape (280, 5, 5, 145) --\n",
      "\n",
      " -- Validation set created with: \n",
      "\t70 samples\n",
      "\tshape (70, 5, 5, 145) --\n",
      "\n",
      " -- Test set created with: \n",
      "\t2898 samples\n",
      "\tshape (2898, 5, 5, 145) --\n",
      "\n",
      "\n",
      "All datasets saved to the 'indices' folder.\n",
      "(280, 5, 5, 145)\n",
      "(70, 5, 5, 145)\n",
      "(2898, 5, 5, 145)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total = get_samples(X_windows, y_labels, 20)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:03.695233Z",
     "iopub.status.busy": "2025-05-08T19:27:03.695233Z",
     "iopub.status.idle": "2025-05-08T19:27:03.699747Z",
     "shell.execute_reply": "2025-05-08T19:27:03.699747Z"
    }
   },
   "outputs": [],
   "source": [
    "class HyperspectralDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (numpy.ndarray): Hyperspectral data of shape (num_samples, height, width, num_bands).\n",
    "            y (numpy.ndarray): Labels of shape (num_samples,).\n",
    "        \"\"\"\n",
    "        #converting to pytorch tensor\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:03.701941Z",
     "iopub.status.busy": "2025-05-08T19:27:03.701941Z",
     "iopub.status.idle": "2025-05-08T19:27:03.761633Z",
     "shell.execute_reply": "2025-05-08T19:27:03.761633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 2 applied\n",
      "DataLoaders created successfully!\n",
      "Training batch size: 280\n",
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20}\n"
     ]
    }
   ],
   "source": [
    "#loading the saved datasets\n",
    "X_train = np.load('indices/X_train.npy')\n",
    "y_train = np.load('indices/y_train.npy')\n",
    "X_val = np.load('indices/X_val.npy')\n",
    "y_val = np.load('indices/y_val.npy')\n",
    "X_test = np.load('indices/X_test.npy')\n",
    "y_test = np.load('indices/y_test.npy')\n",
    "\n",
    "\n",
    "#creating pytorch datasets\n",
    "train_dataset = HyperspectralDataset(X_train, y_train)\n",
    "val_dataset = HyperspectralDataset(X_val, y_val)\n",
    "test_dataset = HyperspectralDataset(X_test, y_test)\n",
    "\n",
    "m = 20\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "#theoretical batch size calc\n",
    "required_batch_size = m * num_classes  # 10 * 9 = 90\n",
    "\n",
    "#ensuring batch size doesn't exceed training set size\n",
    "if required_batch_size > len(train_dataset):\n",
    "    #case 1: not enough samples - reduce m proportionally\n",
    "    print(\"Case 1 applied\")\n",
    "    max_possible_m = len(train_dataset) // num_classes\n",
    "    m = max(1, max_possible_m)\n",
    "    batch_size_train = m * num_classes\n",
    "else:\n",
    "    #case 2: use full batch size\n",
    "    print(\"Case 2 applied\")\n",
    "    batch_size_train = required_batch_size\n",
    "\n",
    "sampler = MPerClassSampler(labels = y_train, m=m, batch_size = batch_size_train, length_before_new_iter = len(train_dataset))\n",
    "\n",
    "#dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size_train, sampler=sampler)\n",
    "\n",
    "batch_size = 256\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")\n",
    "\n",
    "#class dist in first batch\n",
    "for X_batch, y_batch in train_loader:\n",
    "    unique, counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(f\"Training batch size: {batch_size_train}\")\n",
    "    print(\"Class distribution in batch:\", dict(zip(unique, counts)))\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating directory for saving model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:03.764148Z",
     "iopub.status.busy": "2025-05-08T19:27:03.764148Z",
     "iopub.status.idle": "2025-05-08T19:27:03.770163Z",
     "shell.execute_reply": "2025-05-08T19:27:03.769659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dir: model_predictions\n"
     ]
    }
   ],
   "source": [
    "predictions_dir = 'model_predictions'\n",
    "os.makedirs(predictions_dir, exist_ok=True)\n",
    "print(f\"Created dir: {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset splits and Dataloaders for unsupervised tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:03.772175Z",
     "iopub.status.busy": "2025-05-08T19:27:03.772175Z",
     "iopub.status.idle": "2025-05-08T19:27:03.787541Z",
     "shell.execute_reply": "2025-05-08T19:27:03.787541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2598, 5, 5, 145)\n",
      "Validation data shape: (650, 5, 5, 145)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = train_test_split(X_windows, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:03.790548Z",
     "iopub.status.busy": "2025-05-08T19:27:03.790548Z",
     "iopub.status.idle": "2025-05-08T19:27:03.793774Z",
     "shell.execute_reply": "2025-05-08T19:27:03.793774Z"
    }
   },
   "outputs": [],
   "source": [
    "class UnsupervisedDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)  #converting to pytorch tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:03.795780Z",
     "iopub.status.busy": "2025-05-08T19:27:03.795780Z",
     "iopub.status.idle": "2025-05-08T19:27:03.804292Z",
     "shell.execute_reply": "2025-05-08T19:27:03.804292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "#creating datasets for unsupervised task\n",
    "unsup_train_dataset = UnsupervisedDataset(X_train)\n",
    "unsup_val_dataset = UnsupervisedDataset(X_val)\n",
    "\n",
    "#dataloaders for unsupervised task\n",
    "batch_size = 64\n",
    "train_loader_cae = DataLoader(unsup_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader_cae = DataLoader(unsup_val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:03.806910Z",
     "iopub.status.busy": "2025-05-08T19:27:03.806910Z",
     "iopub.status.idle": "2025-05-08T19:27:03.809933Z",
     "shell.execute_reply": "2025-05-08T19:27:03.809933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    }
   ],
   "source": [
    "window_num_channels = X_windows.shape[3]\n",
    "print(window_num_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:03.813939Z",
     "iopub.status.busy": "2025-05-08T19:27:03.812938Z",
     "iopub.status.idle": "2025-05-08T19:27:03.818883Z",
     "shell.execute_reply": "2025-05-08T19:27:03.818883Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncode(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.1):\n",
    "        super(ConvAutoEncode, self).__init__()\n",
    "\n",
    "        #encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            #Block 1\n",
    "            nn.Conv2d(window_num_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            #Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            #Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(64, window_num_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:03.821888Z",
     "iopub.status.busy": "2025-05-08T19:27:03.820889Z",
     "iopub.status.idle": "2025-05-08T19:27:26.050937Z",
     "shell.execute_reply": "2025-05-08T19:27:26.050937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1/41], Loss: 0.2187, PSNR: -10.3687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Training Loss: 0.2087, PSNR: -8.7593\n",
      "\t[Val]   Batch [1/11] Loss: 0.2030, PSNR: -6.1129\n",
      "\t[Val]   Batch [10/11] Loss: 0.2032, PSNR: -8.3518\n",
      "Epoch [1/50] Validation Loss: 0.2030, PSNR: -8.0437\n",
      "\n",
      "LOG: Epoch [2/50]\n",
      "\t Training Batch [1/41], Loss: 0.1919, PSNR: -7.4517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Training Loss: 0.1865, PSNR: -8.2105\n",
      "\t[Val]   Batch [1/11] Loss: 0.1743, PSNR: -5.4498\n",
      "\t[Val]   Batch [10/11] Loss: 0.1745, PSNR: -7.6910\n",
      "Epoch [2/50] Validation Loss: 0.1742, PSNR: -7.3789\n",
      "\n",
      "LOG: Epoch [3/50]\n",
      "\t Training Batch [1/41], Loss: 0.1735, PSNR: -9.6537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Training Loss: 0.1660, PSNR: -7.8567\n",
      "\t[Val]   Batch [1/11] Loss: 0.1504, PSNR: -4.8103\n",
      "\t[Val]   Batch [10/11] Loss: 0.1506, PSNR: -7.0510\n",
      "Epoch [3/50] Validation Loss: 0.1503, PSNR: -6.7384\n",
      "\n",
      "LOG: Epoch [4/50]\n",
      "\t Training Batch [1/41], Loss: 0.1541, PSNR: -7.8568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] Training Loss: 0.1464, PSNR: -7.3225\n",
      "\t[Val]   Batch [1/11] Loss: 0.1308, PSNR: -4.2044\n",
      "\t[Val]   Batch [10/11] Loss: 0.1310, PSNR: -6.4446\n",
      "Epoch [4/50] Validation Loss: 0.1307, PSNR: -6.1315\n",
      "\n",
      "LOG: Epoch [5/50]\n",
      "\t Training Batch [1/41], Loss: 0.1336, PSNR: -6.2315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] Training Loss: 0.1280, PSNR: -6.6232\n",
      "\t[Val]   Batch [1/11] Loss: 0.1138, PSNR: -3.5986\n",
      "\t[Val]   Batch [10/11] Loss: 0.1139, PSNR: -5.8389\n",
      "Epoch [5/50] Validation Loss: 0.1138, PSNR: -5.5280\n",
      "\n",
      "LOG: Epoch [6/50]\n",
      "\t Training Batch [1/41], Loss: 0.1171, PSNR: -5.6560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] Training Loss: 0.1111, PSNR: -6.1204\n",
      "\t[Val]   Batch [1/11] Loss: 0.0973, PSNR: -2.9179\n",
      "\t[Val]   Batch [10/11] Loss: 0.0974, PSNR: -5.1586\n",
      "Epoch [6/50] Validation Loss: 0.0973, PSNR: -4.8492\n",
      "\n",
      "LOG: Epoch [7/50]\n",
      "\t Training Batch [1/41], Loss: 0.1008, PSNR: -4.3871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] Training Loss: 0.0961, PSNR: -5.2846\n",
      "\t[Val]   Batch [1/11] Loss: 0.0866, PSNR: -2.4111\n",
      "\t[Val]   Batch [10/11] Loss: 0.0866, PSNR: -4.6485\n",
      "Epoch [7/50] Validation Loss: 0.0866, PSNR: -4.3423\n",
      "\n",
      "LOG: Epoch [8/50]\n",
      "\t Training Batch [1/41], Loss: 0.0871, PSNR: -2.4365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] Training Loss: 0.0830, PSNR: -4.5486\n",
      "\t[Val]   Batch [1/11] Loss: 0.0736, PSNR: -1.7051\n",
      "\t[Val]   Batch [10/11] Loss: 0.0736, PSNR: -3.9424\n",
      "Epoch [8/50] Validation Loss: 0.0736, PSNR: -3.6360\n",
      "\n",
      "LOG: Epoch [9/50]\n",
      "\t Training Batch [1/41], Loss: 0.0751, PSNR: -1.7937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] Training Loss: 0.0719, PSNR: -4.2008\n",
      "\t[Val]   Batch [1/11] Loss: 0.0666, PSNR: -1.2731\n",
      "\t[Val]   Batch [10/11] Loss: 0.0666, PSNR: -3.5100\n",
      "Epoch [9/50] Validation Loss: 0.0666, PSNR: -3.2049\n",
      "\n",
      "LOG: Epoch [10/50]\n",
      "\t Training Batch [1/41], Loss: 0.0659, PSNR: -4.0777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] Training Loss: 0.0625, PSNR: -3.5752\n",
      "\t[Val]   Batch [1/11] Loss: 0.0565, PSNR: -0.5590\n",
      "\t[Val]   Batch [10/11] Loss: 0.0566, PSNR: -2.7977\n",
      "Epoch [10/50] Validation Loss: 0.0565, PSNR: -2.4905\n",
      "\n",
      "LOG: Epoch [11/50]\n",
      "\t Training Batch [1/41], Loss: 0.0578, PSNR: -0.6585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] Training Loss: 0.0546, PSNR: -2.8572\n",
      "\t[Val]   Batch [1/11] Loss: 0.0521, PSNR: -0.2027\n",
      "\t[Val]   Batch [10/11] Loss: 0.0521, PSNR: -2.4418\n",
      "Epoch [11/50] Validation Loss: 0.0521, PSNR: -2.1351\n",
      "\n",
      "LOG: Epoch [12/50]\n",
      "\t Training Batch [1/41], Loss: 0.0497, PSNR: -1.5870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] Training Loss: 0.0481, PSNR: -2.3734\n",
      "\t[Val]   Batch [1/11] Loss: 0.0449, PSNR: 0.4413\n",
      "\t[Val]   Batch [10/11] Loss: 0.0449, PSNR: -1.7989\n",
      "Epoch [12/50] Validation Loss: 0.0449, PSNR: -1.4926\n",
      "\n",
      "LOG: Epoch [13/50]\n",
      "\t Training Batch [1/41], Loss: 0.0444, PSNR: -1.9321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50] Training Loss: 0.0426, PSNR: -1.6418\n",
      "\t[Val]   Batch [1/11] Loss: 0.0404, PSNR: 0.9038\n",
      "\t[Val]   Batch [10/11] Loss: 0.0404, PSNR: -1.3375\n",
      "Epoch [13/50] Validation Loss: 0.0404, PSNR: -1.0302\n",
      "\n",
      "LOG: Epoch [14/50]\n",
      "\t Training Batch [1/41], Loss: 0.0389, PSNR: -2.3611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50] Training Loss: 0.0379, PSNR: -1.3553\n",
      "\t[Val]   Batch [1/11] Loss: 0.0365, PSNR: 1.3441\n",
      "\t[Val]   Batch [10/11] Loss: 0.0365, PSNR: -0.8970\n",
      "Epoch [14/50] Validation Loss: 0.0365, PSNR: -0.5895\n",
      "\n",
      "LOG: Epoch [15/50]\n",
      "\t Training Batch [1/41], Loss: 0.0351, PSNR: 1.5039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50] Training Loss: 0.0339, PSNR: -1.0055\n",
      "\t[Val]   Batch [1/11] Loss: 0.0325, PSNR: 1.8436\n",
      "\t[Val]   Batch [10/11] Loss: 0.0325, PSNR: -0.3979\n",
      "Epoch [15/50] Validation Loss: 0.0325, PSNR: -0.0895\n",
      "\n",
      "LOG: Epoch [16/50]\n",
      "\t Training Batch [1/41], Loss: 0.0315, PSNR: 0.6618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] Training Loss: 0.0305, PSNR: -0.3534\n",
      "\t[Val]   Batch [1/11] Loss: 0.0295, PSNR: 2.2612\n",
      "\t[Val]   Batch [10/11] Loss: 0.0296, PSNR: 0.0201\n",
      "Epoch [16/50] Validation Loss: 0.0295, PSNR: 0.3283\n",
      "\n",
      "LOG: Epoch [17/50]\n",
      "\t Training Batch [1/41], Loss: 0.0283, PSNR: 0.8603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50] Training Loss: 0.0276, PSNR: 0.0065\n",
      "\t[Val]   Batch [1/11] Loss: 0.0268, PSNR: 2.6783\n",
      "\t[Val]   Batch [10/11] Loss: 0.0268, PSNR: 0.4380\n",
      "Epoch [17/50] Validation Loss: 0.0268, PSNR: 0.7453\n",
      "\n",
      "LOG: Epoch [18/50]\n",
      "\t Training Batch [1/41], Loss: 0.0258, PSNR: -1.7237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50] Training Loss: 0.0251, PSNR: 0.3131\n",
      "\t[Val]   Batch [1/11] Loss: 0.0246, PSNR: 3.0452\n",
      "\t[Val]   Batch [10/11] Loss: 0.0247, PSNR: 0.8050\n",
      "Epoch [18/50] Validation Loss: 0.0247, PSNR: 1.1125\n",
      "\n",
      "LOG: Epoch [19/50]\n",
      "\t Training Batch [1/41], Loss: 0.0242, PSNR: 0.2037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50] Training Loss: 0.0229, PSNR: 0.5635\n",
      "\t[Val]   Batch [1/11] Loss: 0.0224, PSNR: 3.4560\n",
      "\t[Val]   Batch [10/11] Loss: 0.0224, PSNR: 1.2159\n",
      "Epoch [19/50] Validation Loss: 0.0224, PSNR: 1.5234\n",
      "\n",
      "LOG: Epoch [20/50]\n",
      "\t Training Batch [1/41], Loss: 0.0213, PSNR: 1.7495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50] Training Loss: 0.0210, PSNR: 1.1352\n",
      "\t[Val]   Batch [1/11] Loss: 0.0207, PSNR: 3.7974\n",
      "\t[Val]   Batch [10/11] Loss: 0.0207, PSNR: 1.5580\n",
      "Epoch [20/50] Validation Loss: 0.0207, PSNR: 1.8650\n",
      "\n",
      "LOG: Epoch [21/50]\n",
      "\t Training Batch [1/41], Loss: 0.0198, PSNR: 2.0626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50] Training Loss: 0.0193, PSNR: 1.8460\n",
      "\t[Val]   Batch [1/11] Loss: 0.0190, PSNR: 4.1735\n",
      "\t[Val]   Batch [10/11] Loss: 0.0190, PSNR: 1.9337\n",
      "Epoch [21/50] Validation Loss: 0.0190, PSNR: 2.2415\n",
      "\n",
      "LOG: Epoch [22/50]\n",
      "\t Training Batch [1/41], Loss: 0.0181, PSNR: 0.1558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50] Training Loss: 0.0178, PSNR: 1.9118\n",
      "\t[Val]   Batch [1/11] Loss: 0.0176, PSNR: 4.5096\n",
      "\t[Val]   Batch [10/11] Loss: 0.0176, PSNR: 2.2705\n",
      "Epoch [22/50] Validation Loss: 0.0176, PSNR: 2.5781\n",
      "\n",
      "LOG: Epoch [23/50]\n",
      "\t Training Batch [1/41], Loss: 0.0171, PSNR: 2.7043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50] Training Loss: 0.0165, PSNR: 2.4713\n",
      "\t[Val]   Batch [1/11] Loss: 0.0163, PSNR: 4.8372\n",
      "\t[Val]   Batch [10/11] Loss: 0.0163, PSNR: 2.5993\n",
      "Epoch [23/50] Validation Loss: 0.0163, PSNR: 2.9061\n",
      "\n",
      "LOG: Epoch [24/50]\n",
      "\t Training Batch [1/41], Loss: 0.0155, PSNR: 3.4834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50] Training Loss: 0.0153, PSNR: 2.6508\n",
      "\t[Val]   Batch [1/11] Loss: 0.0152, PSNR: 5.1364\n",
      "\t[Val]   Batch [10/11] Loss: 0.0152, PSNR: 2.8989\n",
      "Epoch [24/50] Validation Loss: 0.0152, PSNR: 3.2054\n",
      "\n",
      "LOG: Epoch [25/50]\n",
      "\t Training Batch [1/41], Loss: 0.0145, PSNR: 5.3585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50] Training Loss: 0.0142, PSNR: 2.9238\n",
      "\t[Val]   Batch [1/11] Loss: 0.0142, PSNR: 5.4470\n",
      "\t[Val]   Batch [10/11] Loss: 0.0142, PSNR: 3.2091\n",
      "Epoch [25/50] Validation Loss: 0.0142, PSNR: 3.5160\n",
      "\n",
      "LOG: Epoch [26/50]\n",
      "\t Training Batch [1/41], Loss: 0.0138, PSNR: 3.6357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50] Training Loss: 0.0133, PSNR: 3.3295\n",
      "\t[Val]   Batch [1/11] Loss: 0.0133, PSNR: 5.7127\n",
      "\t[Val]   Batch [10/11] Loss: 0.0133, PSNR: 3.4742\n",
      "Epoch [26/50] Validation Loss: 0.0133, PSNR: 3.7814\n",
      "\n",
      "LOG: Epoch [27/50]\n",
      "\t Training Batch [1/41], Loss: 0.0125, PSNR: 3.1284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50] Training Loss: 0.0125, PSNR: 3.5802\n",
      "\t[Val]   Batch [1/11] Loss: 0.0124, PSNR: 6.0173\n",
      "\t[Val]   Batch [10/11] Loss: 0.0124, PSNR: 3.7779\n",
      "Epoch [27/50] Validation Loss: 0.0124, PSNR: 4.0863\n",
      "\n",
      "LOG: Epoch [28/50]\n",
      "\t Training Batch [1/41], Loss: 0.0114, PSNR: 5.0767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50] Training Loss: 0.0117, PSNR: 3.7298\n",
      "\t[Val]   Batch [1/11] Loss: 0.0117, PSNR: 6.2849\n",
      "\t[Val]   Batch [10/11] Loss: 0.0117, PSNR: 4.0450\n",
      "Epoch [28/50] Validation Loss: 0.0117, PSNR: 4.3547\n",
      "\n",
      "LOG: Epoch [29/50]\n",
      "\t Training Batch [1/41], Loss: 0.0116, PSNR: 6.3259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50] Training Loss: 0.0110, PSNR: 4.2708\n",
      "\t[Val]   Batch [1/11] Loss: 0.0111, PSNR: 6.5150\n",
      "\t[Val]   Batch [10/11] Loss: 0.0111, PSNR: 4.2754\n",
      "Epoch [29/50] Validation Loss: 0.0111, PSNR: 4.5844\n",
      "\n",
      "LOG: Epoch [30/50]\n",
      "\t Training Batch [1/41], Loss: 0.0105, PSNR: 4.8146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50] Training Loss: 0.0103, PSNR: 4.2722\n",
      "\t[Val]   Batch [1/11] Loss: 0.0103, PSNR: 6.8394\n",
      "\t[Val]   Batch [10/11] Loss: 0.0103, PSNR: 4.6019\n",
      "Epoch [30/50] Validation Loss: 0.0103, PSNR: 4.9093\n",
      "\n",
      "LOG: Epoch [31/50]\n",
      "\t Training Batch [1/41], Loss: 0.0097, PSNR: 5.5211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50] Training Loss: 0.0097, PSNR: 4.4971\n",
      "\t[Val]   Batch [1/11] Loss: 0.0098, PSNR: 7.0592\n",
      "\t[Val]   Batch [10/11] Loss: 0.0098, PSNR: 4.8214\n",
      "Epoch [31/50] Validation Loss: 0.0098, PSNR: 5.1294\n",
      "\n",
      "LOG: Epoch [32/50]\n",
      "\t Training Batch [1/41], Loss: 0.0094, PSNR: 5.9128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50] Training Loss: 0.0092, PSNR: 4.6749\n",
      "\t[Val]   Batch [1/11] Loss: 0.0093, PSNR: 7.2872\n",
      "\t[Val]   Batch [10/11] Loss: 0.0093, PSNR: 5.0497\n",
      "Epoch [32/50] Validation Loss: 0.0093, PSNR: 5.3580\n",
      "\n",
      "LOG: Epoch [33/50]\n",
      "\t Training Batch [1/41], Loss: 0.0090, PSNR: 5.5031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50] Training Loss: 0.0087, PSNR: 4.9800\n",
      "\t[Val]   Batch [1/11] Loss: 0.0088, PSNR: 7.5159\n",
      "\t[Val]   Batch [10/11] Loss: 0.0088, PSNR: 5.2790\n",
      "Epoch [33/50] Validation Loss: 0.0088, PSNR: 5.5867\n",
      "\n",
      "LOG: Epoch [34/50]\n",
      "\t Training Batch [1/41], Loss: 0.0083, PSNR: 6.4729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50] Training Loss: 0.0083, PSNR: 5.1585\n",
      "\t[Val]   Batch [1/11] Loss: 0.0083, PSNR: 7.7611\n",
      "\t[Val]   Batch [10/11] Loss: 0.0083, PSNR: 5.5240\n",
      "Epoch [34/50] Validation Loss: 0.0083, PSNR: 5.8322\n",
      "\n",
      "LOG: Epoch [35/50]\n",
      "\t Training Batch [1/41], Loss: 0.0081, PSNR: 4.8854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50] Training Loss: 0.0078, PSNR: 5.4780\n",
      "\t[Val]   Batch [1/11] Loss: 0.0079, PSNR: 7.9777\n",
      "\t[Val]   Batch [10/11] Loss: 0.0079, PSNR: 5.7412\n",
      "Epoch [35/50] Validation Loss: 0.0079, PSNR: 6.0498\n",
      "\n",
      "LOG: Epoch [36/50]\n",
      "\t Training Batch [1/41], Loss: 0.0073, PSNR: 8.3078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50] Training Loss: 0.0075, PSNR: 5.7635\n",
      "\t[Val]   Batch [1/11] Loss: 0.0075, PSNR: 8.1952\n",
      "\t[Val]   Batch [10/11] Loss: 0.0075, PSNR: 5.9595\n",
      "Epoch [36/50] Validation Loss: 0.0075, PSNR: 6.2680\n",
      "\n",
      "LOG: Epoch [37/50]\n",
      "\t Training Batch [1/41], Loss: 0.0072, PSNR: 8.4199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50] Training Loss: 0.0071, PSNR: 5.9364\n",
      "\t[Val]   Batch [1/11] Loss: 0.0072, PSNR: 8.4134\n",
      "\t[Val]   Batch [10/11] Loss: 0.0072, PSNR: 6.1783\n",
      "Epoch [37/50] Validation Loss: 0.0072, PSNR: 6.4866\n",
      "\n",
      "LOG: Epoch [38/50]\n",
      "\t Training Batch [1/41], Loss: 0.0068, PSNR: 6.6864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50] Training Loss: 0.0068, PSNR: 6.0889\n",
      "\t[Val]   Batch [1/11] Loss: 0.0068, PSNR: 8.6292\n",
      "\t[Val]   Batch [10/11] Loss: 0.0068, PSNR: 6.3941\n",
      "Epoch [38/50] Validation Loss: 0.0068, PSNR: 6.7033\n",
      "\n",
      "LOG: Epoch [39/50]\n",
      "\t Training Batch [1/41], Loss: 0.0066, PSNR: 6.8345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50] Training Loss: 0.0064, PSNR: 6.4054\n",
      "\t[Val]   Batch [1/11] Loss: 0.0065, PSNR: 8.8477\n",
      "\t[Val]   Batch [10/11] Loss: 0.0065, PSNR: 6.6126\n",
      "Epoch [39/50] Validation Loss: 0.0065, PSNR: 6.9217\n",
      "\n",
      "LOG: Epoch [40/50]\n",
      "\t Training Batch [1/41], Loss: 0.0063, PSNR: 6.5176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50] Training Loss: 0.0061, PSNR: 6.4279\n",
      "\t[Val]   Batch [1/11] Loss: 0.0062, PSNR: 9.0243\n",
      "\t[Val]   Batch [10/11] Loss: 0.0062, PSNR: 6.7889\n",
      "Epoch [40/50] Validation Loss: 0.0062, PSNR: 7.0982\n",
      "\n",
      "LOG: Epoch [41/50]\n",
      "\t Training Batch [1/41], Loss: 0.0060, PSNR: 7.5634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50] Training Loss: 0.0059, PSNR: 6.8642\n",
      "\t[Val]   Batch [1/11] Loss: 0.0059, PSNR: 9.2348\n",
      "\t[Val]   Batch [10/11] Loss: 0.0059, PSNR: 6.9993\n",
      "Epoch [41/50] Validation Loss: 0.0059, PSNR: 7.3089\n",
      "\n",
      "LOG: Epoch [42/50]\n",
      "\t Training Batch [1/41], Loss: 0.0059, PSNR: 7.6994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50] Training Loss: 0.0056, PSNR: 7.1263\n",
      "\t[Val]   Batch [1/11] Loss: 0.0057, PSNR: 9.4188\n",
      "\t[Val]   Batch [10/11] Loss: 0.0057, PSNR: 7.1828\n",
      "Epoch [42/50] Validation Loss: 0.0057, PSNR: 7.4938\n",
      "\n",
      "LOG: Epoch [43/50]\n",
      "\t Training Batch [1/41], Loss: 0.0055, PSNR: 7.3241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50] Training Loss: 0.0054, PSNR: 7.1212\n",
      "\t[Val]   Batch [1/11] Loss: 0.0055, PSNR: 9.5902\n",
      "\t[Val]   Batch [10/11] Loss: 0.0055, PSNR: 7.3545\n",
      "Epoch [43/50] Validation Loss: 0.0055, PSNR: 7.6660\n",
      "\n",
      "LOG: Epoch [44/50]\n",
      "\t Training Batch [1/41], Loss: 0.0053, PSNR: 5.7528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50] Training Loss: 0.0051, PSNR: 7.3192\n",
      "\t[Val]   Batch [1/11] Loss: 0.0052, PSNR: 9.8266\n",
      "\t[Val]   Batch [10/11] Loss: 0.0052, PSNR: 7.5905\n",
      "Epoch [44/50] Validation Loss: 0.0052, PSNR: 7.9022\n",
      "\n",
      "LOG: Epoch [45/50]\n",
      "\t Training Batch [1/41], Loss: 0.0049, PSNR: 5.7244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50] Training Loss: 0.0049, PSNR: 7.4760\n",
      "\t[Val]   Batch [1/11] Loss: 0.0050, PSNR: 10.0110\n",
      "\t[Val]   Batch [10/11] Loss: 0.0050, PSNR: 7.7752\n",
      "Epoch [45/50] Validation Loss: 0.0049, PSNR: 8.0868\n",
      "\n",
      "LOG: Epoch [46/50]\n",
      "\t Training Batch [1/41], Loss: 0.0048, PSNR: 5.8849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50] Training Loss: 0.0047, PSNR: 7.7366\n",
      "\t[Val]   Batch [1/11] Loss: 0.0048, PSNR: 10.1936\n",
      "\t[Val]   Batch [10/11] Loss: 0.0048, PSNR: 7.9590\n",
      "Epoch [46/50] Validation Loss: 0.0047, PSNR: 8.2690\n",
      "\n",
      "LOG: Epoch [47/50]\n",
      "\t Training Batch [1/41], Loss: 0.0046, PSNR: 6.9075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50] Training Loss: 0.0045, PSNR: 7.9867\n",
      "\t[Val]   Batch [1/11] Loss: 0.0046, PSNR: 10.3441\n",
      "\t[Val]   Batch [10/11] Loss: 0.0046, PSNR: 8.1105\n",
      "Epoch [47/50] Validation Loss: 0.0046, PSNR: 8.4197\n",
      "\n",
      "LOG: Epoch [48/50]\n",
      "\t Training Batch [1/41], Loss: 0.0043, PSNR: 7.2051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50] Training Loss: 0.0043, PSNR: 8.1519\n",
      "\t[Val]   Batch [1/11] Loss: 0.0044, PSNR: 10.5245\n",
      "\t[Val]   Batch [10/11] Loss: 0.0044, PSNR: 8.2918\n",
      "Epoch [48/50] Validation Loss: 0.0044, PSNR: 8.6001\n",
      "\n",
      "LOG: Epoch [49/50]\n",
      "\t Training Batch [1/41], Loss: 0.0040, PSNR: 7.9508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50] Training Loss: 0.0041, PSNR: 8.2573\n",
      "\t[Val]   Batch [1/11] Loss: 0.0042, PSNR: 10.7089\n",
      "\t[Val]   Batch [10/11] Loss: 0.0042, PSNR: 8.4767\n",
      "Epoch [49/50] Validation Loss: 0.0042, PSNR: 8.7854\n",
      "\n",
      "LOG: Epoch [50/50]\n",
      "\t Training Batch [1/41], Loss: 0.0039, PSNR: 9.4317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50] Training Loss: 0.0040, PSNR: 8.4866\n",
      "\t[Val]   Batch [1/11] Loss: 0.0041, PSNR: 10.8820\n",
      "\t[Val]   Batch [10/11] Loss: 0.0041, PSNR: 8.6495\n",
      "Epoch [50/50] Validation Loss: 0.0040, PSNR: 8.9589\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_cae = ConvAutoEncode()\n",
    "criterion_cae = nn.MSELoss()\n",
    "optimizer_cae = optim.Adam(model_cae.parameters(), lr=0.0001)\n",
    "\n",
    "#parameters for CAE\n",
    "num_epochs_cae = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_cae = model_cae.to(device)\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 3  # number of epochs to wait for improvement\n",
    "tolerance = 1e-4\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "#grad accumulation parameters\n",
    "accumulation_steps = 8 \n",
    "\n",
    "# for loss and metrics tracking\n",
    "autoencoder_epoch_losses_cae = []\n",
    "validation_epoch_losses_cae = []\n",
    "train_psnr = []\n",
    "val_psnr = []\n",
    "\n",
    "psnr = PeakSignalNoiseRatio().to(device)\n",
    "\n",
    "# mixed precision training\n",
    "scaler = GradScaler()  # Gradient scaler for mixed precision\n",
    "\n",
    "for epoch in range(num_epochs_cae):\n",
    "    # training\n",
    "    model_cae.train()\n",
    "    running_loss = 0.0\n",
    "    running_psnr = 0.0\n",
    "\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs_cae}]\")\n",
    "\n",
    "    optimizer_cae.zero_grad()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader_cae):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "        # mixed precision forward pass\n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            _, decoded = model_cae(data)\n",
    "            loss = criterion_cae(decoded, data) / accumulation_steps\n",
    "\n",
    "            with torch.no_grad():\n",
    "                nan_in_out = torch.isnan(decoded).any().item()\n",
    "                inf_in_out = torch.isinf(decoded).any().item()\n",
    "\n",
    "        #backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        loss_value = loss.item() * accumulation_steps\n",
    "        running_loss += loss_value\n",
    "\n",
    "        psnr_value = psnr(decoded, data).item()\n",
    "        running_psnr += psnr_value\n",
    "\n",
    "\n",
    "        # performing optimizer step and reset gradients after `accumulation_steps` batches\n",
    "        if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader_cae):\n",
    "            scaler.step(optimizer_cae)\n",
    "            scaler.update()\n",
    "            optimizer_cae.zero_grad()\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 200 == 0:\n",
    "            print(\n",
    "    f\"\\t Training Batch [{batch_idx + 1}/{len(train_loader_cae)}], \"\n",
    "    f\"Loss: {loss_value:.4f}, PSNR: {psnr_value:.4f}\"\n",
    ")\n",
    "\n",
    "\n",
    "        #delete intermediate variables and clear GPU cache\n",
    "        del data, decoded, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    #compute average metrics for the epoch\n",
    "    avg_train_loss = running_loss / len(train_loader_cae)\n",
    "    avg_train_psnr = running_psnr / len(train_loader_cae)\n",
    "\n",
    "    autoencoder_epoch_losses_cae.append(avg_train_loss)\n",
    "    train_psnr.append(avg_train_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Training Loss: {avg_train_loss:.4f}, PSNR: {avg_train_psnr:.4f}\")\n",
    "\n",
    "    #clear GPU cache after training\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    #validation\n",
    "    model_cae.eval()\n",
    "    validation_loss = 0.0\n",
    "    val_psnr_epoch = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(val_loader_cae):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # Mixed precision forward pass for validation\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                _, decoded = model_cae(data)\n",
    "                loss = criterion_cae(decoded, data)\n",
    "\n",
    "            validation_loss += loss.item()\n",
    "            val_psnr_epoch += psnr(decoded, data).item()\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                loss_val = loss.item()\n",
    "                psnr_val = psnr(decoded, data).item()\n",
    "                print(\n",
    "                    f\"\\t[Val]   Batch [{batch_idx + 1}/{len(val_loader_cae)}] \"\n",
    "                    f\"Loss: {loss_val:.4f}, PSNR: {psnr_val:.4f}\"\n",
    "                )\n",
    "\n",
    "            del data, decoded, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # average validation metrics for the epoch\n",
    "    avg_val_loss = validation_loss / len(val_loader_cae)\n",
    "    avg_val_psnr = val_psnr_epoch / len(val_loader_cae)\n",
    "\n",
    "    validation_epoch_losses_cae.append(avg_val_loss)\n",
    "    val_psnr.append(avg_val_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Validation Loss: {avg_val_loss:.4f}, PSNR: {avg_val_psnr:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss < best_val_loss - tolerance:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0  # Reset counter\n",
    "        #best model checkpoint\n",
    "        #torch.save(model_cae.state_dict(), 'best_model_cae.pth')\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "#plot for training and validation loss trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(autoencoder_epoch_losses_cae) + 1), autoencoder_epoch_losses_cae, marker='o', label=\"Training Loss\")\n",
    "plt.plot(range(1, len(validation_epoch_losses_cae) + 1), validation_epoch_losses_cae, marker='x', label=\"Validation Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#plot for PSNR trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_psnr) + 1), train_psnr, marker='o', label=\"Training PSNR\")\n",
    "plt.plot(range(1, len(val_psnr) + 1), val_psnr, marker='x', label=\"Validation PSNR\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('PSNR Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the encoder section of CAE as feature extractor to generate compact representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:26.053795Z",
     "iopub.status.busy": "2025-05-08T19:27:26.052787Z",
     "iopub.status.idle": "2025-05-08T19:27:26.186836Z",
     "shell.execute_reply": "2025-05-08T19:27:26.186836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting representations for the train dataset...\n",
      "    Processed batch 1/1 for train dataset.\n",
      "Completed encoding for the train dataset.\n",
      "\n",
      "Extracting representations for the val dataset...\n",
      "    Processed batch 1/1 for val dataset.\n",
      "Completed encoding for the val dataset.\n",
      "\n",
      "Extracting representations for the test dataset...\n",
      "    Processed batch 1/12 for test dataset.\n",
      "Completed encoding for the test dataset.\n",
      "Feature extraction completed for all subsets.\n"
     ]
    }
   ],
   "source": [
    "#dir to save encoded representations\n",
    "encoded_dir = 'encoded_representations'\n",
    "os.makedirs(encoded_dir, exist_ok=True)\n",
    "\n",
    "loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "model_cae.eval()\n",
    "\n",
    "# Feature extraction\n",
    "with torch.no_grad():\n",
    "    for subset_name, loader in loaders.items():\n",
    "        print(f\"\\nExtracting representations for the {subset_name} dataset...\")\n",
    "\n",
    "        # dir for the given subset's encoded features\n",
    "        subset_encoded_dir = os.path.join(encoded_dir, subset_name)\n",
    "        os.makedirs(subset_encoded_dir, exist_ok=True)\n",
    "\n",
    "        for batch_idx, (data, labels) in enumerate(loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # passing data through the encoder to obtain representations\n",
    "            encoded_features, _ = model_cae(data)  # latent representation\n",
    "\n",
    "            # moving to CPU and convert to NumPy\n",
    "            encoded_features = encoded_features.cpu().numpy()  \n",
    "            labels = labels.cpu().numpy() \n",
    "\n",
    "            #saving the encoded features and labels\n",
    "            np.save(os.path.join(subset_encoded_dir, f'encoded_batch_{batch_idx}.npy'), encoded_features)\n",
    "            np.save(os.path.join(subset_encoded_dir, f'labels_batch_{batch_idx}.npy'), labels)\n",
    "\n",
    "            if batch_idx % 1 == 0 and subset_name != 'test':\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "            elif subset_name == 'test' and batch_idx % 100 == 0:  # Log less frequently for the test set\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed encoding for the {subset_name} dataset.\")\n",
    "\n",
    "print(\"Feature extraction completed for all subsets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-To-End CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:26.189841Z",
     "iopub.status.busy": "2025-05-08T19:27:26.188841Z",
     "iopub.status.idle": "2025-05-08T19:27:26.193840Z",
     "shell.execute_reply": "2025-05-08T19:27:26.193840Z"
    }
   },
   "outputs": [],
   "source": [
    "class hyperspectralCNN(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(hyperspectralCNN, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #fully connected layers for classification\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),  #3D to 1D vector for input to FC layers\n",
    "            nn.Linear(16 * 2 * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:26.196627Z",
     "iopub.status.busy": "2025-05-08T19:27:26.195122Z",
     "iopub.status.idle": "2025-05-08T19:27:35.686054Z",
     "shell.execute_reply": "2025-05-08T19:27:35.686054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] completed, Average Training Loss: 2.6356\n",
      "    Validation Batch [1/1], Loss: 2.6454\n",
      "Validation Loss: 2.6454, Validation Accuracy: 7.14%\n",
      "Validation loss improved from inf to 2.6454. Saving model...\n",
      "\n",
      "LOG: Epoch [2/1000] - Training\n",
      "Epoch [2/1000] completed, Average Training Loss: 2.5906\n",
      "    Validation Batch [1/1], Loss: 2.6454\n",
      "Validation Loss: 2.6454, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6454 to 2.6454. Saving model...\n",
      "\n",
      "LOG: Epoch [3/1000] - Training\n",
      "Epoch [3/1000] completed, Average Training Loss: 2.5665\n",
      "    Validation Batch [1/1], Loss: 2.6453\n",
      "Validation Loss: 2.6453, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6454 to 2.6453. Saving model...\n",
      "\n",
      "LOG: Epoch [4/1000] - Training\n",
      "Epoch [4/1000] completed, Average Training Loss: 2.5473\n",
      "    Validation Batch [1/1], Loss: 2.6453\n",
      "Validation Loss: 2.6453, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6453 to 2.6453. Saving model...\n",
      "\n",
      "LOG: Epoch [5/1000] - Training\n",
      "Epoch [5/1000] completed, Average Training Loss: 2.5178\n",
      "    Validation Batch [1/1], Loss: 2.6453\n",
      "Validation Loss: 2.6453, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6453 to 2.6453. Saving model...\n",
      "\n",
      "LOG: Epoch [6/1000] - Training\n",
      "Epoch [6/1000] completed, Average Training Loss: 2.5104\n",
      "    Validation Batch [1/1], Loss: 2.6452\n",
      "Validation Loss: 2.6452, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6453 to 2.6452. Saving model...\n",
      "\n",
      "LOG: Epoch [7/1000] - Training\n",
      "Epoch [7/1000] completed, Average Training Loss: 2.4785\n",
      "    Validation Batch [1/1], Loss: 2.6452\n",
      "Validation Loss: 2.6452, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6452 to 2.6452. Saving model...\n",
      "\n",
      "LOG: Epoch [8/1000] - Training\n",
      "Epoch [8/1000] completed, Average Training Loss: 2.4624\n",
      "    Validation Batch [1/1], Loss: 2.6451\n",
      "Validation Loss: 2.6451, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6452 to 2.6451. Saving model...\n",
      "\n",
      "LOG: Epoch [9/1000] - Training\n",
      "Epoch [9/1000] completed, Average Training Loss: 2.4585\n",
      "    Validation Batch [1/1], Loss: 2.6450\n",
      "Validation Loss: 2.6450, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6451 to 2.6450. Saving model...\n",
      "\n",
      "LOG: Epoch [10/1000] - Training\n",
      "Epoch [10/1000] completed, Average Training Loss: 2.4359\n",
      "    Validation Batch [1/1], Loss: 2.6449\n",
      "Validation Loss: 2.6449, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6450 to 2.6449. Saving model...\n",
      "\n",
      "LOG: Epoch [11/1000] - Training\n",
      "Epoch [11/1000] completed, Average Training Loss: 2.4265\n",
      "    Validation Batch [1/1], Loss: 2.6448\n",
      "Validation Loss: 2.6448, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6449 to 2.6448. Saving model...\n",
      "\n",
      "LOG: Epoch [12/1000] - Training\n",
      "Epoch [12/1000] completed, Average Training Loss: 2.4268\n",
      "    Validation Batch [1/1], Loss: 2.6447\n",
      "Validation Loss: 2.6447, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6448 to 2.6447. Saving model...\n",
      "\n",
      "LOG: Epoch [13/1000] - Training\n",
      "Epoch [13/1000] completed, Average Training Loss: 2.4004\n",
      "    Validation Batch [1/1], Loss: 2.6446\n",
      "Validation Loss: 2.6446, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6447 to 2.6446. Saving model...\n",
      "\n",
      "LOG: Epoch [14/1000] - Training\n",
      "Epoch [14/1000] completed, Average Training Loss: 2.3916\n",
      "    Validation Batch [1/1], Loss: 2.6444\n",
      "Validation Loss: 2.6444, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6446 to 2.6444. Saving model...\n",
      "\n",
      "LOG: Epoch [15/1000] - Training\n",
      "Epoch [15/1000] completed, Average Training Loss: 2.3831\n",
      "    Validation Batch [1/1], Loss: 2.6443\n",
      "Validation Loss: 2.6443, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6444 to 2.6443. Saving model...\n",
      "\n",
      "LOG: Epoch [16/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/1000] completed, Average Training Loss: 2.3692\n",
      "    Validation Batch [1/1], Loss: 2.6441\n",
      "Validation Loss: 2.6441, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6443 to 2.6441. Saving model...\n",
      "\n",
      "LOG: Epoch [17/1000] - Training\n",
      "Epoch [17/1000] completed, Average Training Loss: 2.3641\n",
      "    Validation Batch [1/1], Loss: 2.6439\n",
      "Validation Loss: 2.6439, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6441 to 2.6439. Saving model...\n",
      "\n",
      "LOG: Epoch [18/1000] - Training\n",
      "Epoch [18/1000] completed, Average Training Loss: 2.3551\n",
      "    Validation Batch [1/1], Loss: 2.6438\n",
      "Validation Loss: 2.6438, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6439 to 2.6438. Saving model...\n",
      "\n",
      "LOG: Epoch [19/1000] - Training\n",
      "Epoch [19/1000] completed, Average Training Loss: 2.3460\n",
      "    Validation Batch [1/1], Loss: 2.6435\n",
      "Validation Loss: 2.6435, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6438 to 2.6435. Saving model...\n",
      "\n",
      "LOG: Epoch [20/1000] - Training\n",
      "Epoch [20/1000] completed, Average Training Loss: 2.3304\n",
      "    Validation Batch [1/1], Loss: 2.6435\n",
      "Validation Loss: 2.6435, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6435 to 2.6435. Saving model...\n",
      "\n",
      "LOG: Epoch [21/1000] - Training\n",
      "Epoch [21/1000] completed, Average Training Loss: 2.3294\n",
      "    Validation Batch [1/1], Loss: 2.6433\n",
      "Validation Loss: 2.6433, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6435 to 2.6433. Saving model...\n",
      "\n",
      "LOG: Epoch [22/1000] - Training\n",
      "Epoch [22/1000] completed, Average Training Loss: 2.3269\n",
      "    Validation Batch [1/1], Loss: 2.6430\n",
      "Validation Loss: 2.6430, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6433 to 2.6430. Saving model...\n",
      "\n",
      "LOG: Epoch [23/1000] - Training\n",
      "Epoch [23/1000] completed, Average Training Loss: 2.2966\n",
      "    Validation Batch [1/1], Loss: 2.6427\n",
      "Validation Loss: 2.6427, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6430 to 2.6427. Saving model...\n",
      "\n",
      "LOG: Epoch [24/1000] - Training\n",
      "Epoch [24/1000] completed, Average Training Loss: 2.2898\n",
      "    Validation Batch [1/1], Loss: 2.6423\n",
      "Validation Loss: 2.6423, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6427 to 2.6423. Saving model...\n",
      "\n",
      "LOG: Epoch [25/1000] - Training\n",
      "Epoch [25/1000] completed, Average Training Loss: 2.2854\n",
      "    Validation Batch [1/1], Loss: 2.6420\n",
      "Validation Loss: 2.6420, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6423 to 2.6420. Saving model...\n",
      "\n",
      "LOG: Epoch [26/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/1000] completed, Average Training Loss: 2.2830\n",
      "    Validation Batch [1/1], Loss: 2.6415\n",
      "Validation Loss: 2.6415, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6420 to 2.6415. Saving model...\n",
      "\n",
      "LOG: Epoch [27/1000] - Training\n",
      "Epoch [27/1000] completed, Average Training Loss: 2.2537\n",
      "    Validation Batch [1/1], Loss: 2.6411\n",
      "Validation Loss: 2.6411, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6415 to 2.6411. Saving model...\n",
      "\n",
      "LOG: Epoch [28/1000] - Training\n",
      "Epoch [28/1000] completed, Average Training Loss: 2.2517\n",
      "    Validation Batch [1/1], Loss: 2.6407\n",
      "Validation Loss: 2.6407, Validation Accuracy: 12.86%\n",
      "Validation loss improved from 2.6411 to 2.6407. Saving model...\n",
      "\n",
      "LOG: Epoch [29/1000] - Training\n",
      "Epoch [29/1000] completed, Average Training Loss: 2.2471\n",
      "    Validation Batch [1/1], Loss: 2.6403\n",
      "Validation Loss: 2.6403, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6407 to 2.6403. Saving model...\n",
      "\n",
      "LOG: Epoch [30/1000] - Training\n",
      "Epoch [30/1000] completed, Average Training Loss: 2.2301\n",
      "    Validation Batch [1/1], Loss: 2.6398\n",
      "Validation Loss: 2.6398, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6403 to 2.6398. Saving model...\n",
      "\n",
      "LOG: Epoch [31/1000] - Training\n",
      "Epoch [31/1000] completed, Average Training Loss: 2.2382\n",
      "    Validation Batch [1/1], Loss: 2.6392\n",
      "Validation Loss: 2.6392, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6398 to 2.6392. Saving model...\n",
      "\n",
      "LOG: Epoch [32/1000] - Training\n",
      "Epoch [32/1000] completed, Average Training Loss: 2.2355\n",
      "    Validation Batch [1/1], Loss: 2.6387\n",
      "Validation Loss: 2.6387, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6392 to 2.6387. Saving model...\n",
      "\n",
      "LOG: Epoch [33/1000] - Training\n",
      "Epoch [33/1000] completed, Average Training Loss: 2.2190\n",
      "    Validation Batch [1/1], Loss: 2.6381\n",
      "Validation Loss: 2.6381, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6387 to 2.6381. Saving model...\n",
      "\n",
      "LOG: Epoch [34/1000] - Training\n",
      "Epoch [34/1000] completed, Average Training Loss: 2.2023\n",
      "    Validation Batch [1/1], Loss: 2.6375\n",
      "Validation Loss: 2.6375, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6381 to 2.6375. Saving model...\n",
      "\n",
      "LOG: Epoch [35/1000] - Training\n",
      "Epoch [35/1000] completed, Average Training Loss: 2.1824\n",
      "    Validation Batch [1/1], Loss: 2.6369\n",
      "Validation Loss: 2.6369, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6375 to 2.6369. Saving model...\n",
      "\n",
      "LOG: Epoch [36/1000] - Training\n",
      "Epoch [36/1000] completed, Average Training Loss: 2.1952\n",
      "    Validation Batch [1/1], Loss: 2.6362\n",
      "Validation Loss: 2.6362, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6369 to 2.6362. Saving model...\n",
      "\n",
      "LOG: Epoch [37/1000] - Training\n",
      "Epoch [37/1000] completed, Average Training Loss: 2.1532\n",
      "    Validation Batch [1/1], Loss: 2.6355\n",
      "Validation Loss: 2.6355, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6362 to 2.6355. Saving model...\n",
      "\n",
      "LOG: Epoch [38/1000] - Training\n",
      "Epoch [38/1000] completed, Average Training Loss: 2.1633\n",
      "    Validation Batch [1/1], Loss: 2.6348\n",
      "Validation Loss: 2.6348, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6355 to 2.6348. Saving model...\n",
      "\n",
      "LOG: Epoch [39/1000] - Training\n",
      "Epoch [39/1000] completed, Average Training Loss: 2.1586\n",
      "    Validation Batch [1/1], Loss: 2.6341\n",
      "Validation Loss: 2.6341, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6348 to 2.6341. Saving model...\n",
      "\n",
      "LOG: Epoch [40/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/1000] completed, Average Training Loss: 2.1481\n",
      "    Validation Batch [1/1], Loss: 2.6331\n",
      "Validation Loss: 2.6331, Validation Accuracy: 17.14%\n",
      "Validation loss improved from 2.6341 to 2.6331. Saving model...\n",
      "\n",
      "LOG: Epoch [41/1000] - Training\n",
      "Epoch [41/1000] completed, Average Training Loss: 2.1357\n",
      "    Validation Batch [1/1], Loss: 2.6321\n",
      "Validation Loss: 2.6321, Validation Accuracy: 21.43%\n",
      "Validation loss improved from 2.6331 to 2.6321. Saving model...\n",
      "\n",
      "LOG: Epoch [42/1000] - Training\n",
      "Epoch [42/1000] completed, Average Training Loss: 2.1300\n",
      "    Validation Batch [1/1], Loss: 2.6308\n",
      "Validation Loss: 2.6308, Validation Accuracy: 17.14%\n",
      "Validation loss improved from 2.6321 to 2.6308. Saving model...\n",
      "\n",
      "LOG: Epoch [43/1000] - Training\n",
      "Epoch [43/1000] completed, Average Training Loss: 2.1351\n",
      "    Validation Batch [1/1], Loss: 2.6296\n",
      "Validation Loss: 2.6296, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6308 to 2.6296. Saving model...\n",
      "\n",
      "LOG: Epoch [44/1000] - Training\n",
      "Epoch [44/1000] completed, Average Training Loss: 2.1263\n",
      "    Validation Batch [1/1], Loss: 2.6282\n",
      "Validation Loss: 2.6282, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6296 to 2.6282. Saving model...\n",
      "\n",
      "LOG: Epoch [45/1000] - Training\n",
      "Epoch [45/1000] completed, Average Training Loss: 2.1121\n",
      "    Validation Batch [1/1], Loss: 2.6266\n",
      "Validation Loss: 2.6266, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6282 to 2.6266. Saving model...\n",
      "\n",
      "LOG: Epoch [46/1000] - Training\n",
      "Epoch [46/1000] completed, Average Training Loss: 2.0932\n",
      "    Validation Batch [1/1], Loss: 2.6250\n",
      "Validation Loss: 2.6250, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6266 to 2.6250. Saving model...\n",
      "\n",
      "LOG: Epoch [47/1000] - Training\n",
      "Epoch [47/1000] completed, Average Training Loss: 2.1017\n",
      "    Validation Batch [1/1], Loss: 2.6227\n",
      "Validation Loss: 2.6227, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6250 to 2.6227. Saving model...\n",
      "\n",
      "LOG: Epoch [48/1000] - Training\n",
      "Epoch [48/1000] completed, Average Training Loss: 2.0881\n",
      "    Validation Batch [1/1], Loss: 2.6198\n",
      "Validation Loss: 2.6198, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6227 to 2.6198. Saving model...\n",
      "\n",
      "LOG: Epoch [49/1000] - Training\n",
      "Epoch [49/1000] completed, Average Training Loss: 2.0736\n",
      "    Validation Batch [1/1], Loss: 2.6167\n",
      "Validation Loss: 2.6167, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6198 to 2.6167. Saving model...\n",
      "\n",
      "LOG: Epoch [50/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/1000] completed, Average Training Loss: 2.0742\n",
      "    Validation Batch [1/1], Loss: 2.6135\n",
      "Validation Loss: 2.6135, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6167 to 2.6135. Saving model...\n",
      "\n",
      "LOG: Epoch [51/1000] - Training\n",
      "Epoch [51/1000] completed, Average Training Loss: 2.0613\n",
      "    Validation Batch [1/1], Loss: 2.6099\n",
      "Validation Loss: 2.6099, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6135 to 2.6099. Saving model...\n",
      "\n",
      "LOG: Epoch [52/1000] - Training\n",
      "Epoch [52/1000] completed, Average Training Loss: 2.0357\n",
      "    Validation Batch [1/1], Loss: 2.6056\n",
      "Validation Loss: 2.6056, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6099 to 2.6056. Saving model...\n",
      "\n",
      "LOG: Epoch [53/1000] - Training\n",
      "Epoch [53/1000] completed, Average Training Loss: 2.0441\n",
      "    Validation Batch [1/1], Loss: 2.6007\n",
      "Validation Loss: 2.6007, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6056 to 2.6007. Saving model...\n",
      "\n",
      "LOG: Epoch [54/1000] - Training\n",
      "Epoch [54/1000] completed, Average Training Loss: 2.0361\n",
      "    Validation Batch [1/1], Loss: 2.5952\n",
      "Validation Loss: 2.5952, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.6007 to 2.5952. Saving model...\n",
      "\n",
      "LOG: Epoch [55/1000] - Training\n",
      "Epoch [55/1000] completed, Average Training Loss: 2.0232\n",
      "    Validation Batch [1/1], Loss: 2.5892\n",
      "Validation Loss: 2.5892, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.5952 to 2.5892. Saving model...\n",
      "\n",
      "LOG: Epoch [56/1000] - Training\n",
      "Epoch [56/1000] completed, Average Training Loss: 2.0209\n",
      "    Validation Batch [1/1], Loss: 2.5837\n",
      "Validation Loss: 2.5837, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.5892 to 2.5837. Saving model...\n",
      "\n",
      "LOG: Epoch [57/1000] - Training\n",
      "Epoch [57/1000] completed, Average Training Loss: 2.0100\n",
      "    Validation Batch [1/1], Loss: 2.5776\n",
      "Validation Loss: 2.5776, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.5837 to 2.5776. Saving model...\n",
      "\n",
      "LOG: Epoch [58/1000] - Training\n",
      "Epoch [58/1000] completed, Average Training Loss: 1.9942\n",
      "    Validation Batch [1/1], Loss: 2.5700\n",
      "Validation Loss: 2.5700, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.5776 to 2.5700. Saving model...\n",
      "\n",
      "LOG: Epoch [59/1000] - Training\n",
      "Epoch [59/1000] completed, Average Training Loss: 1.9767\n",
      "    Validation Batch [1/1], Loss: 2.5610\n",
      "Validation Loss: 2.5610, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.5700 to 2.5610. Saving model...\n",
      "\n",
      "LOG: Epoch [60/1000] - Training\n",
      "Epoch [60/1000] completed, Average Training Loss: 1.9629\n",
      "    Validation Batch [1/1], Loss: 2.5507\n",
      "Validation Loss: 2.5507, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.5610 to 2.5507. Saving model...\n",
      "\n",
      "LOG: Epoch [61/1000] - Training\n",
      "Epoch [61/1000] completed, Average Training Loss: 1.9668\n",
      "    Validation Batch [1/1], Loss: 2.5396\n",
      "Validation Loss: 2.5396, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.5507 to 2.5396. Saving model...\n",
      "\n",
      "LOG: Epoch [62/1000] - Training\n",
      "Epoch [62/1000] completed, Average Training Loss: 1.9579\n",
      "    Validation Batch [1/1], Loss: 2.5268\n",
      "Validation Loss: 2.5268, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.5396 to 2.5268. Saving model...\n",
      "\n",
      "LOG: Epoch [63/1000] - Training\n",
      "Epoch [63/1000] completed, Average Training Loss: 1.9602\n",
      "    Validation Batch [1/1], Loss: 2.5134\n",
      "Validation Loss: 2.5134, Validation Accuracy: 15.71%\n",
      "Validation loss improved from 2.5268 to 2.5134. Saving model...\n",
      "\n",
      "LOG: Epoch [64/1000] - Training\n",
      "Epoch [64/1000] completed, Average Training Loss: 1.9497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 2.4986\n",
      "Validation Loss: 2.4986, Validation Accuracy: 17.14%\n",
      "Validation loss improved from 2.5134 to 2.4986. Saving model...\n",
      "\n",
      "LOG: Epoch [65/1000] - Training\n",
      "Epoch [65/1000] completed, Average Training Loss: 1.9171\n",
      "    Validation Batch [1/1], Loss: 2.4798\n",
      "Validation Loss: 2.4798, Validation Accuracy: 18.57%\n",
      "Validation loss improved from 2.4986 to 2.4798. Saving model...\n",
      "\n",
      "LOG: Epoch [66/1000] - Training\n",
      "Epoch [66/1000] completed, Average Training Loss: 1.9237\n",
      "    Validation Batch [1/1], Loss: 2.4600\n",
      "Validation Loss: 2.4600, Validation Accuracy: 24.29%\n",
      "Validation loss improved from 2.4798 to 2.4600. Saving model...\n",
      "\n",
      "LOG: Epoch [67/1000] - Training\n",
      "Epoch [67/1000] completed, Average Training Loss: 1.9142\n",
      "    Validation Batch [1/1], Loss: 2.4429\n",
      "Validation Loss: 2.4429, Validation Accuracy: 30.00%\n",
      "Validation loss improved from 2.4600 to 2.4429. Saving model...\n",
      "\n",
      "LOG: Epoch [68/1000] - Training\n",
      "Epoch [68/1000] completed, Average Training Loss: 1.9167\n",
      "    Validation Batch [1/1], Loss: 2.4257\n",
      "Validation Loss: 2.4257, Validation Accuracy: 32.86%\n",
      "Validation loss improved from 2.4429 to 2.4257. Saving model...\n",
      "\n",
      "LOG: Epoch [69/1000] - Training\n",
      "Epoch [69/1000] completed, Average Training Loss: 1.9332\n",
      "    Validation Batch [1/1], Loss: 2.4061\n",
      "Validation Loss: 2.4061, Validation Accuracy: 34.29%\n",
      "Validation loss improved from 2.4257 to 2.4061. Saving model...\n",
      "\n",
      "LOG: Epoch [70/1000] - Training\n",
      "Epoch [70/1000] completed, Average Training Loss: 1.9041\n",
      "    Validation Batch [1/1], Loss: 2.3832\n",
      "Validation Loss: 2.3832, Validation Accuracy: 35.71%\n",
      "Validation loss improved from 2.4061 to 2.3832. Saving model...\n",
      "\n",
      "LOG: Epoch [71/1000] - Training\n",
      "Epoch [71/1000] completed, Average Training Loss: 1.8823\n",
      "    Validation Batch [1/1], Loss: 2.3574\n",
      "Validation Loss: 2.3574, Validation Accuracy: 40.00%\n",
      "Validation loss improved from 2.3832 to 2.3574. Saving model...\n",
      "\n",
      "LOG: Epoch [72/1000] - Training\n",
      "Epoch [72/1000] completed, Average Training Loss: 1.8582\n",
      "    Validation Batch [1/1], Loss: 2.3343\n",
      "Validation Loss: 2.3343, Validation Accuracy: 42.86%\n",
      "Validation loss improved from 2.3574 to 2.3343. Saving model...\n",
      "\n",
      "LOG: Epoch [73/1000] - Training\n",
      "Epoch [73/1000] completed, Average Training Loss: 1.8804\n",
      "    Validation Batch [1/1], Loss: 2.3121\n",
      "Validation Loss: 2.3121, Validation Accuracy: 47.14%\n",
      "Validation loss improved from 2.3343 to 2.3121. Saving model...\n",
      "\n",
      "LOG: Epoch [74/1000] - Training\n",
      "Epoch [74/1000] completed, Average Training Loss: 1.8707\n",
      "    Validation Batch [1/1], Loss: 2.2802\n",
      "Validation Loss: 2.2802, Validation Accuracy: 48.57%\n",
      "Validation loss improved from 2.3121 to 2.2802. Saving model...\n",
      "\n",
      "LOG: Epoch [75/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/1000] completed, Average Training Loss: 1.8671\n",
      "    Validation Batch [1/1], Loss: 2.2418\n",
      "Validation Loss: 2.2418, Validation Accuracy: 54.29%\n",
      "Validation loss improved from 2.2802 to 2.2418. Saving model...\n",
      "\n",
      "LOG: Epoch [76/1000] - Training\n",
      "Epoch [76/1000] completed, Average Training Loss: 1.8410\n",
      "    Validation Batch [1/1], Loss: 2.2139\n",
      "Validation Loss: 2.2139, Validation Accuracy: 55.71%\n",
      "Validation loss improved from 2.2418 to 2.2139. Saving model...\n",
      "\n",
      "LOG: Epoch [77/1000] - Training\n",
      "Epoch [77/1000] completed, Average Training Loss: 1.8343\n",
      "    Validation Batch [1/1], Loss: 2.1998\n",
      "Validation Loss: 2.1998, Validation Accuracy: 55.71%\n",
      "Validation loss improved from 2.2139 to 2.1998. Saving model...\n",
      "\n",
      "LOG: Epoch [78/1000] - Training\n",
      "Epoch [78/1000] completed, Average Training Loss: 1.8333\n",
      "    Validation Batch [1/1], Loss: 2.1887\n",
      "Validation Loss: 2.1887, Validation Accuracy: 54.29%\n",
      "Validation loss improved from 2.1998 to 2.1887. Saving model...\n",
      "\n",
      "LOG: Epoch [79/1000] - Training\n",
      "Epoch [79/1000] completed, Average Training Loss: 1.8261\n",
      "    Validation Batch [1/1], Loss: 2.1527\n",
      "Validation Loss: 2.1527, Validation Accuracy: 60.00%\n",
      "Validation loss improved from 2.1887 to 2.1527. Saving model...\n",
      "\n",
      "LOG: Epoch [80/1000] - Training\n",
      "Epoch [80/1000] completed, Average Training Loss: 1.8109\n",
      "    Validation Batch [1/1], Loss: 2.1038\n",
      "Validation Loss: 2.1038, Validation Accuracy: 61.43%\n",
      "Validation loss improved from 2.1527 to 2.1038. Saving model...\n",
      "\n",
      "LOG: Epoch [81/1000] - Training\n",
      "Epoch [81/1000] completed, Average Training Loss: 1.8225\n",
      "    Validation Batch [1/1], Loss: 2.0781\n",
      "Validation Loss: 2.0781, Validation Accuracy: 64.29%\n",
      "Validation loss improved from 2.1038 to 2.0781. Saving model...\n",
      "\n",
      "LOG: Epoch [82/1000] - Training\n",
      "Epoch [82/1000] completed, Average Training Loss: 1.8120\n",
      "    Validation Batch [1/1], Loss: 2.0824\n",
      "Validation Loss: 2.0824, Validation Accuracy: 64.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [83/1000] - Training\n",
      "Epoch [83/1000] completed, Average Training Loss: 1.7402\n",
      "    Validation Batch [1/1], Loss: 2.0773\n",
      "Validation Loss: 2.0773, Validation Accuracy: 60.00%\n",
      "Validation loss improved from 2.0781 to 2.0773. Saving model...\n",
      "\n",
      "LOG: Epoch [84/1000] - Training\n",
      "Epoch [84/1000] completed, Average Training Loss: 1.7862\n",
      "    Validation Batch [1/1], Loss: 2.0442\n",
      "Validation Loss: 2.0442, Validation Accuracy: 68.57%\n",
      "Validation loss improved from 2.0773 to 2.0442. Saving model...\n",
      "\n",
      "LOG: Epoch [85/1000] - Training\n",
      "Epoch [85/1000] completed, Average Training Loss: 1.7758\n",
      "    Validation Batch [1/1], Loss: 1.9849\n",
      "Validation Loss: 1.9849, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 2.0442 to 1.9849. Saving model...\n",
      "\n",
      "LOG: Epoch [86/1000] - Training\n",
      "Epoch [86/1000] completed, Average Training Loss: 1.7855\n",
      "    Validation Batch [1/1], Loss: 1.9456\n",
      "Validation Loss: 1.9456, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.9849 to 1.9456. Saving model...\n",
      "\n",
      "LOG: Epoch [87/1000] - Training\n",
      "Epoch [87/1000] completed, Average Training Loss: 1.7631\n",
      "    Validation Batch [1/1], Loss: 1.9454\n",
      "Validation Loss: 1.9454, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.9456 to 1.9454. Saving model...\n",
      "\n",
      "LOG: Epoch [88/1000] - Training\n",
      "Epoch [88/1000] completed, Average Training Loss: 1.7264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 1.9466\n",
      "Validation Loss: 1.9466, Validation Accuracy: 74.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [89/1000] - Training\n",
      "Epoch [89/1000] completed, Average Training Loss: 1.7299\n",
      "    Validation Batch [1/1], Loss: 1.9189\n",
      "Validation Loss: 1.9189, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.9454 to 1.9189. Saving model...\n",
      "\n",
      "LOG: Epoch [90/1000] - Training\n",
      "Epoch [90/1000] completed, Average Training Loss: 1.7614\n",
      "    Validation Batch [1/1], Loss: 1.8805\n",
      "Validation Loss: 1.8805, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.9189 to 1.8805. Saving model...\n",
      "\n",
      "LOG: Epoch [91/1000] - Training\n",
      "Epoch [91/1000] completed, Average Training Loss: 1.7176\n",
      "    Validation Batch [1/1], Loss: 1.8480\n",
      "Validation Loss: 1.8480, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.8805 to 1.8480. Saving model...\n",
      "\n",
      "LOG: Epoch [92/1000] - Training\n",
      "Epoch [92/1000] completed, Average Training Loss: 1.7282\n",
      "    Validation Batch [1/1], Loss: 1.8224\n",
      "Validation Loss: 1.8224, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.8480 to 1.8224. Saving model...\n",
      "\n",
      "LOG: Epoch [93/1000] - Training\n",
      "Epoch [93/1000] completed, Average Training Loss: 1.7053\n",
      "    Validation Batch [1/1], Loss: 1.7973\n",
      "Validation Loss: 1.7973, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.8224 to 1.7973. Saving model...\n",
      "\n",
      "LOG: Epoch [94/1000] - Training\n",
      "Epoch [94/1000] completed, Average Training Loss: 1.6815\n",
      "    Validation Batch [1/1], Loss: 1.7896\n",
      "Validation Loss: 1.7896, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.7973 to 1.7896. Saving model...\n",
      "\n",
      "LOG: Epoch [95/1000] - Training\n",
      "Epoch [95/1000] completed, Average Training Loss: 1.6689\n",
      "    Validation Batch [1/1], Loss: 1.7826\n",
      "Validation Loss: 1.7826, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.7896 to 1.7826. Saving model...\n",
      "\n",
      "LOG: Epoch [96/1000] - Training\n",
      "Epoch [96/1000] completed, Average Training Loss: 1.6653\n",
      "    Validation Batch [1/1], Loss: 1.7479\n",
      "Validation Loss: 1.7479, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.7826 to 1.7479. Saving model...\n",
      "\n",
      "LOG: Epoch [97/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/1000] completed, Average Training Loss: 1.6530\n",
      "    Validation Batch [1/1], Loss: 1.7327\n",
      "Validation Loss: 1.7327, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.7479 to 1.7327. Saving model...\n",
      "\n",
      "LOG: Epoch [98/1000] - Training\n",
      "Epoch [98/1000] completed, Average Training Loss: 1.6820\n",
      "    Validation Batch [1/1], Loss: 1.7299\n",
      "Validation Loss: 1.7299, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 1.7327 to 1.7299. Saving model...\n",
      "\n",
      "LOG: Epoch [99/1000] - Training\n",
      "Epoch [99/1000] completed, Average Training Loss: 1.6560\n",
      "    Validation Batch [1/1], Loss: 1.7047\n",
      "Validation Loss: 1.7047, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 1.7299 to 1.7047. Saving model...\n",
      "\n",
      "LOG: Epoch [100/1000] - Training\n",
      "Epoch [100/1000] completed, Average Training Loss: 1.6546\n",
      "    Validation Batch [1/1], Loss: 1.6734\n",
      "Validation Loss: 1.6734, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.7047 to 1.6734. Saving model...\n",
      "\n",
      "LOG: Epoch [101/1000] - Training\n",
      "Epoch [101/1000] completed, Average Training Loss: 1.6164\n",
      "    Validation Batch [1/1], Loss: 1.6588\n",
      "Validation Loss: 1.6588, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.6734 to 1.6588. Saving model...\n",
      "\n",
      "LOG: Epoch [102/1000] - Training\n",
      "Epoch [102/1000] completed, Average Training Loss: 1.6379\n",
      "    Validation Batch [1/1], Loss: 1.6463\n",
      "Validation Loss: 1.6463, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 1.6588 to 1.6463. Saving model...\n",
      "\n",
      "LOG: Epoch [103/1000] - Training\n",
      "Epoch [103/1000] completed, Average Training Loss: 1.6327\n",
      "    Validation Batch [1/1], Loss: 1.6398\n",
      "Validation Loss: 1.6398, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.6463 to 1.6398. Saving model...\n",
      "\n",
      "LOG: Epoch [104/1000] - Training\n",
      "Epoch [104/1000] completed, Average Training Loss: 1.6165\n",
      "    Validation Batch [1/1], Loss: 1.6198\n",
      "Validation Loss: 1.6198, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.6398 to 1.6198. Saving model...\n",
      "\n",
      "LOG: Epoch [105/1000] - Training\n",
      "Epoch [105/1000] completed, Average Training Loss: 1.5976\n",
      "    Validation Batch [1/1], Loss: 1.6066\n",
      "Validation Loss: 1.6066, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.6198 to 1.6066. Saving model...\n",
      "\n",
      "LOG: Epoch [106/1000] - Training\n",
      "Epoch [106/1000] completed, Average Training Loss: 1.5862\n",
      "    Validation Batch [1/1], Loss: 1.5955\n",
      "Validation Loss: 1.5955, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.6066 to 1.5955. Saving model...\n",
      "\n",
      "LOG: Epoch [107/1000] - Training\n",
      "Epoch [107/1000] completed, Average Training Loss: 1.5899\n",
      "    Validation Batch [1/1], Loss: 1.5828\n",
      "Validation Loss: 1.5828, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.5955 to 1.5828. Saving model...\n",
      "\n",
      "LOG: Epoch [108/1000] - Training\n",
      "Epoch [108/1000] completed, Average Training Loss: 1.5568\n",
      "    Validation Batch [1/1], Loss: 1.5665\n",
      "Validation Loss: 1.5665, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.5828 to 1.5665. Saving model...\n",
      "\n",
      "LOG: Epoch [109/1000] - Training\n",
      "Epoch [109/1000] completed, Average Training Loss: 1.5437\n",
      "    Validation Batch [1/1], Loss: 1.5541\n",
      "Validation Loss: 1.5541, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.5665 to 1.5541. Saving model...\n",
      "\n",
      "LOG: Epoch [110/1000] - Training\n",
      "Epoch [110/1000] completed, Average Training Loss: 1.5378\n",
      "    Validation Batch [1/1], Loss: 1.5437\n",
      "Validation Loss: 1.5437, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.5541 to 1.5437. Saving model...\n",
      "\n",
      "LOG: Epoch [111/1000] - Training\n",
      "Epoch [111/1000] completed, Average Training Loss: 1.5078\n",
      "    Validation Batch [1/1], Loss: 1.5315\n",
      "Validation Loss: 1.5315, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.5437 to 1.5315. Saving model...\n",
      "\n",
      "LOG: Epoch [112/1000] - Training\n",
      "Epoch [112/1000] completed, Average Training Loss: 1.5657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 1.5124\n",
      "Validation Loss: 1.5124, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.5315 to 1.5124. Saving model...\n",
      "\n",
      "LOG: Epoch [113/1000] - Training\n",
      "Epoch [113/1000] completed, Average Training Loss: 1.5077\n",
      "    Validation Batch [1/1], Loss: 1.4979\n",
      "Validation Loss: 1.4979, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.5124 to 1.4979. Saving model...\n",
      "\n",
      "LOG: Epoch [114/1000] - Training\n",
      "Epoch [114/1000] completed, Average Training Loss: 1.5236\n",
      "    Validation Batch [1/1], Loss: 1.4894\n",
      "Validation Loss: 1.4894, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.4979 to 1.4894. Saving model...\n",
      "\n",
      "LOG: Epoch [115/1000] - Training\n",
      "Epoch [115/1000] completed, Average Training Loss: 1.5191\n",
      "    Validation Batch [1/1], Loss: 1.4864\n",
      "Validation Loss: 1.4864, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.4894 to 1.4864. Saving model...\n",
      "\n",
      "LOG: Epoch [116/1000] - Training\n",
      "Epoch [116/1000] completed, Average Training Loss: 1.4603\n",
      "    Validation Batch [1/1], Loss: 1.4795\n",
      "Validation Loss: 1.4795, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.4864 to 1.4795. Saving model...\n",
      "\n",
      "LOG: Epoch [117/1000] - Training\n",
      "Epoch [117/1000] completed, Average Training Loss: 1.4680\n",
      "    Validation Batch [1/1], Loss: 1.4784\n",
      "Validation Loss: 1.4784, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.4795 to 1.4784. Saving model...\n",
      "\n",
      "LOG: Epoch [118/1000] - Training\n",
      "Epoch [118/1000] completed, Average Training Loss: 1.4569\n",
      "    Validation Batch [1/1], Loss: 1.4719\n",
      "Validation Loss: 1.4719, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.4784 to 1.4719. Saving model...\n",
      "\n",
      "LOG: Epoch [119/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [119/1000] completed, Average Training Loss: 1.4747\n",
      "    Validation Batch [1/1], Loss: 1.4567\n",
      "Validation Loss: 1.4567, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.4719 to 1.4567. Saving model...\n",
      "\n",
      "LOG: Epoch [120/1000] - Training\n",
      "Epoch [120/1000] completed, Average Training Loss: 1.4817\n",
      "    Validation Batch [1/1], Loss: 1.4471\n",
      "Validation Loss: 1.4471, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.4567 to 1.4471. Saving model...\n",
      "\n",
      "LOG: Epoch [121/1000] - Training\n",
      "Epoch [121/1000] completed, Average Training Loss: 1.4513\n",
      "    Validation Batch [1/1], Loss: 1.4378\n",
      "Validation Loss: 1.4378, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.4471 to 1.4378. Saving model...\n",
      "\n",
      "LOG: Epoch [122/1000] - Training\n",
      "Epoch [122/1000] completed, Average Training Loss: 1.4684\n",
      "    Validation Batch [1/1], Loss: 1.4232\n",
      "Validation Loss: 1.4232, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.4378 to 1.4232. Saving model...\n",
      "\n",
      "LOG: Epoch [123/1000] - Training\n",
      "Epoch [123/1000] completed, Average Training Loss: 1.4528\n",
      "    Validation Batch [1/1], Loss: 1.4271\n",
      "Validation Loss: 1.4271, Validation Accuracy: 81.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [124/1000] - Training\n",
      "Epoch [124/1000] completed, Average Training Loss: 1.4194\n",
      "    Validation Batch [1/1], Loss: 1.4263\n",
      "Validation Loss: 1.4263, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [125/1000] - Training\n",
      "Epoch [125/1000] completed, Average Training Loss: 1.4312\n",
      "    Validation Batch [1/1], Loss: 1.4153\n",
      "Validation Loss: 1.4153, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.4232 to 1.4153. Saving model...\n",
      "\n",
      "LOG: Epoch [126/1000] - Training\n",
      "Epoch [126/1000] completed, Average Training Loss: 1.4134\n",
      "    Validation Batch [1/1], Loss: 1.4060\n",
      "Validation Loss: 1.4060, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.4153 to 1.4060. Saving model...\n",
      "\n",
      "LOG: Epoch [127/1000] - Training\n",
      "Epoch [127/1000] completed, Average Training Loss: 1.3967\n",
      "    Validation Batch [1/1], Loss: 1.3978\n",
      "Validation Loss: 1.3978, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.4060 to 1.3978. Saving model...\n",
      "\n",
      "LOG: Epoch [128/1000] - Training\n",
      "Epoch [128/1000] completed, Average Training Loss: 1.4133\n",
      "    Validation Batch [1/1], Loss: 1.3834\n",
      "Validation Loss: 1.3834, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.3978 to 1.3834. Saving model...\n",
      "\n",
      "LOG: Epoch [129/1000] - Training\n",
      "Epoch [129/1000] completed, Average Training Loss: 1.4158\n",
      "    Validation Batch [1/1], Loss: 1.3633\n",
      "Validation Loss: 1.3633, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 1.3834 to 1.3633. Saving model...\n",
      "\n",
      "LOG: Epoch [130/1000] - Training\n",
      "Epoch [130/1000] completed, Average Training Loss: 1.3779\n",
      "    Validation Batch [1/1], Loss: 1.3482\n",
      "Validation Loss: 1.3482, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 1.3633 to 1.3482. Saving model...\n",
      "\n",
      "LOG: Epoch [131/1000] - Training\n",
      "Epoch [131/1000] completed, Average Training Loss: 1.3825\n",
      "    Validation Batch [1/1], Loss: 1.3402\n",
      "Validation Loss: 1.3402, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.3482 to 1.3402. Saving model...\n",
      "\n",
      "LOG: Epoch [132/1000] - Training\n",
      "Epoch [132/1000] completed, Average Training Loss: 1.3733\n",
      "    Validation Batch [1/1], Loss: 1.3550\n",
      "Validation Loss: 1.3550, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [133/1000] - Training\n",
      "Epoch [133/1000] completed, Average Training Loss: 1.3305\n",
      "    Validation Batch [1/1], Loss: 1.3606\n",
      "Validation Loss: 1.3606, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [134/1000] - Training\n",
      "Epoch [134/1000] completed, Average Training Loss: 1.3503\n",
      "    Validation Batch [1/1], Loss: 1.3362\n",
      "Validation Loss: 1.3362, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.3402 to 1.3362. Saving model...\n",
      "\n",
      "LOG: Epoch [135/1000] - Training\n",
      "Epoch [135/1000] completed, Average Training Loss: 1.3337\n",
      "    Validation Batch [1/1], Loss: 1.3114\n",
      "Validation Loss: 1.3114, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.3362 to 1.3114. Saving model...\n",
      "\n",
      "LOG: Epoch [136/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [136/1000] completed, Average Training Loss: 1.3125\n",
      "    Validation Batch [1/1], Loss: 1.3014\n",
      "Validation Loss: 1.3014, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 1.3114 to 1.3014. Saving model...\n",
      "\n",
      "LOG: Epoch [137/1000] - Training\n",
      "Epoch [137/1000] completed, Average Training Loss: 1.3043\n",
      "    Validation Batch [1/1], Loss: 1.3204\n",
      "Validation Loss: 1.3204, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [138/1000] - Training\n",
      "Epoch [138/1000] completed, Average Training Loss: 1.3112\n",
      "    Validation Batch [1/1], Loss: 1.3056\n",
      "Validation Loss: 1.3056, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [139/1000] - Training\n",
      "Epoch [139/1000] completed, Average Training Loss: 1.3033\n",
      "    Validation Batch [1/1], Loss: 1.2787\n",
      "Validation Loss: 1.2787, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 1.3014 to 1.2787. Saving model...\n",
      "\n",
      "LOG: Epoch [140/1000] - Training\n",
      "Epoch [140/1000] completed, Average Training Loss: 1.2827\n",
      "    Validation Batch [1/1], Loss: 1.2637\n",
      "Validation Loss: 1.2637, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 1.2787 to 1.2637. Saving model...\n",
      "\n",
      "LOG: Epoch [141/1000] - Training\n",
      "Epoch [141/1000] completed, Average Training Loss: 1.2948\n",
      "    Validation Batch [1/1], Loss: 1.2655\n",
      "Validation Loss: 1.2655, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [142/1000] - Training\n",
      "Epoch [142/1000] completed, Average Training Loss: 1.2750\n",
      "    Validation Batch [1/1], Loss: 1.2559\n",
      "Validation Loss: 1.2559, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 1.2637 to 1.2559. Saving model...\n",
      "\n",
      "LOG: Epoch [143/1000] - Training\n",
      "Epoch [143/1000] completed, Average Training Loss: 1.2727\n",
      "    Validation Batch [1/1], Loss: 1.2418\n",
      "Validation Loss: 1.2418, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 1.2559 to 1.2418. Saving model...\n",
      "\n",
      "LOG: Epoch [144/1000] - Training\n",
      "Epoch [144/1000] completed, Average Training Loss: 1.2608\n",
      "    Validation Batch [1/1], Loss: 1.2254\n",
      "Validation Loss: 1.2254, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 1.2418 to 1.2254. Saving model...\n",
      "\n",
      "LOG: Epoch [145/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [145/1000] completed, Average Training Loss: 1.2439\n",
      "    Validation Batch [1/1], Loss: 1.2094\n",
      "Validation Loss: 1.2094, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 1.2254 to 1.2094. Saving model...\n",
      "\n",
      "LOG: Epoch [146/1000] - Training\n",
      "Epoch [146/1000] completed, Average Training Loss: 1.2422\n",
      "    Validation Batch [1/1], Loss: 1.1977\n",
      "Validation Loss: 1.1977, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 1.2094 to 1.1977. Saving model...\n",
      "\n",
      "LOG: Epoch [147/1000] - Training\n",
      "Epoch [147/1000] completed, Average Training Loss: 1.2053\n",
      "    Validation Batch [1/1], Loss: 1.1905\n",
      "Validation Loss: 1.1905, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 1.1977 to 1.1905. Saving model...\n",
      "\n",
      "LOG: Epoch [148/1000] - Training\n",
      "Epoch [148/1000] completed, Average Training Loss: 1.2097\n",
      "    Validation Batch [1/1], Loss: 1.1956\n",
      "Validation Loss: 1.1956, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [149/1000] - Training\n",
      "Epoch [149/1000] completed, Average Training Loss: 1.2205\n",
      "    Validation Batch [1/1], Loss: 1.1859\n",
      "Validation Loss: 1.1859, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 1.1905 to 1.1859. Saving model...\n",
      "\n",
      "LOG: Epoch [150/1000] - Training\n",
      "Epoch [150/1000] completed, Average Training Loss: 1.2134\n",
      "    Validation Batch [1/1], Loss: 1.1795\n",
      "Validation Loss: 1.1795, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 1.1859 to 1.1795. Saving model...\n",
      "\n",
      "LOG: Epoch [151/1000] - Training\n",
      "Epoch [151/1000] completed, Average Training Loss: 1.2105\n",
      "    Validation Batch [1/1], Loss: 1.1471\n",
      "Validation Loss: 1.1471, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 1.1795 to 1.1471. Saving model...\n",
      "\n",
      "LOG: Epoch [152/1000] - Training\n",
      "Epoch [152/1000] completed, Average Training Loss: 1.2137\n",
      "    Validation Batch [1/1], Loss: 1.1379\n",
      "Validation Loss: 1.1379, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 1.1471 to 1.1379. Saving model...\n",
      "\n",
      "LOG: Epoch [153/1000] - Training\n",
      "Epoch [153/1000] completed, Average Training Loss: 1.1848\n",
      "    Validation Batch [1/1], Loss: 1.1407\n",
      "Validation Loss: 1.1407, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [154/1000] - Training\n",
      "Epoch [154/1000] completed, Average Training Loss: 1.1626\n",
      "    Validation Batch [1/1], Loss: 1.1259\n",
      "Validation Loss: 1.1259, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 1.1379 to 1.1259. Saving model...\n",
      "\n",
      "LOG: Epoch [155/1000] - Training\n",
      "Epoch [155/1000] completed, Average Training Loss: 1.1254\n",
      "    Validation Batch [1/1], Loss: 1.1212\n",
      "Validation Loss: 1.1212, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 1.1259 to 1.1212. Saving model...\n",
      "\n",
      "LOG: Epoch [156/1000] - Training\n",
      "Epoch [156/1000] completed, Average Training Loss: 1.1412\n",
      "    Validation Batch [1/1], Loss: 1.1072\n",
      "Validation Loss: 1.1072, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 1.1212 to 1.1072. Saving model...\n",
      "\n",
      "LOG: Epoch [157/1000] - Training\n",
      "Epoch [157/1000] completed, Average Training Loss: 1.1311\n",
      "    Validation Batch [1/1], Loss: 1.1019\n",
      "Validation Loss: 1.1019, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 1.1072 to 1.1019. Saving model...\n",
      "\n",
      "LOG: Epoch [158/1000] - Training\n",
      "Epoch [158/1000] completed, Average Training Loss: 1.1418\n",
      "    Validation Batch [1/1], Loss: 1.0958\n",
      "Validation Loss: 1.0958, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 1.1019 to 1.0958. Saving model...\n",
      "\n",
      "LOG: Epoch [159/1000] - Training\n",
      "Epoch [159/1000] completed, Average Training Loss: 1.0901\n",
      "    Validation Batch [1/1], Loss: 1.1012\n",
      "Validation Loss: 1.1012, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [160/1000] - Training\n",
      "Epoch [160/1000] completed, Average Training Loss: 1.1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 1.0940\n",
      "Validation Loss: 1.0940, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 1.0958 to 1.0940. Saving model...\n",
      "\n",
      "LOG: Epoch [161/1000] - Training\n",
      "Epoch [161/1000] completed, Average Training Loss: 1.1080\n",
      "    Validation Batch [1/1], Loss: 1.0723\n",
      "Validation Loss: 1.0723, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 1.0940 to 1.0723. Saving model...\n",
      "\n",
      "LOG: Epoch [162/1000] - Training\n",
      "Epoch [162/1000] completed, Average Training Loss: 1.1336\n",
      "    Validation Batch [1/1], Loss: 1.0559\n",
      "Validation Loss: 1.0559, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 1.0723 to 1.0559. Saving model...\n",
      "\n",
      "LOG: Epoch [163/1000] - Training\n",
      "Epoch [163/1000] completed, Average Training Loss: 1.1076\n",
      "    Validation Batch [1/1], Loss: 1.0513\n",
      "Validation Loss: 1.0513, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 1.0559 to 1.0513. Saving model...\n",
      "\n",
      "LOG: Epoch [164/1000] - Training\n",
      "Epoch [164/1000] completed, Average Training Loss: 1.0851\n",
      "    Validation Batch [1/1], Loss: 1.0584\n",
      "Validation Loss: 1.0584, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [165/1000] - Training\n",
      "Epoch [165/1000] completed, Average Training Loss: 1.0499\n",
      "    Validation Batch [1/1], Loss: 1.0418\n",
      "Validation Loss: 1.0418, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 1.0513 to 1.0418. Saving model...\n",
      "\n",
      "LOG: Epoch [166/1000] - Training\n",
      "Epoch [166/1000] completed, Average Training Loss: 1.0757\n",
      "    Validation Batch [1/1], Loss: 1.0308\n",
      "Validation Loss: 1.0308, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 1.0418 to 1.0308. Saving model...\n",
      "\n",
      "LOG: Epoch [167/1000] - Training\n",
      "Epoch [167/1000] completed, Average Training Loss: 1.0501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 1.0296\n",
      "Validation Loss: 1.0296, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 1.0308 to 1.0296. Saving model...\n",
      "\n",
      "LOG: Epoch [168/1000] - Training\n",
      "Epoch [168/1000] completed, Average Training Loss: 1.0830\n",
      "    Validation Batch [1/1], Loss: 1.0302\n",
      "Validation Loss: 1.0302, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [169/1000] - Training\n",
      "Epoch [169/1000] completed, Average Training Loss: 1.0540\n",
      "    Validation Batch [1/1], Loss: 1.0334\n",
      "Validation Loss: 1.0334, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [170/1000] - Training\n",
      "Epoch [170/1000] completed, Average Training Loss: 1.0509\n",
      "    Validation Batch [1/1], Loss: 1.0036\n",
      "Validation Loss: 1.0036, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 1.0296 to 1.0036. Saving model...\n",
      "\n",
      "LOG: Epoch [171/1000] - Training\n",
      "Epoch [171/1000] completed, Average Training Loss: 1.0029\n",
      "    Validation Batch [1/1], Loss: 0.9879\n",
      "Validation Loss: 0.9879, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 1.0036 to 0.9879. Saving model...\n",
      "\n",
      "LOG: Epoch [172/1000] - Training\n",
      "Epoch [172/1000] completed, Average Training Loss: 1.0021\n",
      "    Validation Batch [1/1], Loss: 0.9814\n",
      "Validation Loss: 0.9814, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.9879 to 0.9814. Saving model...\n",
      "\n",
      "LOG: Epoch [173/1000] - Training\n",
      "Epoch [173/1000] completed, Average Training Loss: 0.9957\n",
      "    Validation Batch [1/1], Loss: 0.9676\n",
      "Validation Loss: 0.9676, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.9814 to 0.9676. Saving model...\n",
      "\n",
      "LOG: Epoch [174/1000] - Training\n",
      "Epoch [174/1000] completed, Average Training Loss: 1.0146\n",
      "    Validation Batch [1/1], Loss: 0.9644\n",
      "Validation Loss: 0.9644, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.9676 to 0.9644. Saving model...\n",
      "\n",
      "LOG: Epoch [175/1000] - Training\n",
      "Epoch [175/1000] completed, Average Training Loss: 0.9711\n",
      "    Validation Batch [1/1], Loss: 0.9682\n",
      "Validation Loss: 0.9682, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [176/1000] - Training\n",
      "Epoch [176/1000] completed, Average Training Loss: 0.9624\n",
      "    Validation Batch [1/1], Loss: 0.9526\n",
      "Validation Loss: 0.9526, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.9644 to 0.9526. Saving model...\n",
      "\n",
      "LOG: Epoch [177/1000] - Training\n",
      "Epoch [177/1000] completed, Average Training Loss: 1.0131\n",
      "    Validation Batch [1/1], Loss: 0.9376\n",
      "Validation Loss: 0.9376, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.9526 to 0.9376. Saving model...\n",
      "\n",
      "LOG: Epoch [178/1000] - Training\n",
      "Epoch [178/1000] completed, Average Training Loss: 0.9640\n",
      "    Validation Batch [1/1], Loss: 0.9347\n",
      "Validation Loss: 0.9347, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.9376 to 0.9347. Saving model...\n",
      "\n",
      "LOG: Epoch [179/1000] - Training\n",
      "Epoch [179/1000] completed, Average Training Loss: 0.9755\n",
      "    Validation Batch [1/1], Loss: 0.9261\n",
      "Validation Loss: 0.9261, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.9347 to 0.9261. Saving model...\n",
      "\n",
      "LOG: Epoch [180/1000] - Training\n",
      "Epoch [180/1000] completed, Average Training Loss: 0.9607\n",
      "    Validation Batch [1/1], Loss: 0.9119\n",
      "Validation Loss: 0.9119, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.9261 to 0.9119. Saving model...\n",
      "\n",
      "LOG: Epoch [181/1000] - Training\n",
      "Epoch [181/1000] completed, Average Training Loss: 0.9544\n",
      "    Validation Batch [1/1], Loss: 0.9079\n",
      "Validation Loss: 0.9079, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.9119 to 0.9079. Saving model...\n",
      "\n",
      "LOG: Epoch [182/1000] - Training\n",
      "Epoch [182/1000] completed, Average Training Loss: 0.9685\n",
      "    Validation Batch [1/1], Loss: 0.9035\n",
      "Validation Loss: 0.9035, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.9079 to 0.9035. Saving model...\n",
      "\n",
      "LOG: Epoch [183/1000] - Training\n",
      "Epoch [183/1000] completed, Average Training Loss: 0.9442\n",
      "    Validation Batch [1/1], Loss: 0.8894\n",
      "Validation Loss: 0.8894, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.9035 to 0.8894. Saving model...\n",
      "\n",
      "LOG: Epoch [184/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [184/1000] completed, Average Training Loss: 0.9031\n",
      "    Validation Batch [1/1], Loss: 0.8715\n",
      "Validation Loss: 0.8715, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.8894 to 0.8715. Saving model...\n",
      "\n",
      "LOG: Epoch [185/1000] - Training\n",
      "Epoch [185/1000] completed, Average Training Loss: 0.8793\n",
      "    Validation Batch [1/1], Loss: 0.8697\n",
      "Validation Loss: 0.8697, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.8715 to 0.8697. Saving model...\n",
      "\n",
      "LOG: Epoch [186/1000] - Training\n",
      "Epoch [186/1000] completed, Average Training Loss: 0.8997\n",
      "    Validation Batch [1/1], Loss: 0.8863\n",
      "Validation Loss: 0.8863, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [187/1000] - Training\n",
      "Epoch [187/1000] completed, Average Training Loss: 0.8654\n",
      "    Validation Batch [1/1], Loss: 0.8757\n",
      "Validation Loss: 0.8757, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [188/1000] - Training\n",
      "Epoch [188/1000] completed, Average Training Loss: 0.9026\n",
      "    Validation Batch [1/1], Loss: 0.8409\n",
      "Validation Loss: 0.8409, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.8697 to 0.8409. Saving model...\n",
      "\n",
      "LOG: Epoch [189/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [189/1000] completed, Average Training Loss: 0.8430\n",
      "    Validation Batch [1/1], Loss: 0.8333\n",
      "Validation Loss: 0.8333, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.8409 to 0.8333. Saving model...\n",
      "\n",
      "LOG: Epoch [190/1000] - Training\n",
      "Epoch [190/1000] completed, Average Training Loss: 0.8796\n",
      "    Validation Batch [1/1], Loss: 0.8112\n",
      "Validation Loss: 0.8112, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.8333 to 0.8112. Saving model...\n",
      "\n",
      "LOG: Epoch [191/1000] - Training\n",
      "Epoch [191/1000] completed, Average Training Loss: 0.8477\n",
      "    Validation Batch [1/1], Loss: 0.8053\n",
      "Validation Loss: 0.8053, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.8112 to 0.8053. Saving model...\n",
      "\n",
      "LOG: Epoch [192/1000] - Training\n",
      "Epoch [192/1000] completed, Average Training Loss: 0.8683\n",
      "    Validation Batch [1/1], Loss: 0.8095\n",
      "Validation Loss: 0.8095, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [193/1000] - Training\n",
      "Epoch [193/1000] completed, Average Training Loss: 0.8444\n",
      "    Validation Batch [1/1], Loss: 0.8131\n",
      "Validation Loss: 0.8131, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [194/1000] - Training\n",
      "Epoch [194/1000] completed, Average Training Loss: 0.8265\n",
      "    Validation Batch [1/1], Loss: 0.8112\n",
      "Validation Loss: 0.8112, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [195/1000] - Training\n",
      "Epoch [195/1000] completed, Average Training Loss: 0.8434\n",
      "    Validation Batch [1/1], Loss: 0.8027\n",
      "Validation Loss: 0.8027, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.8053 to 0.8027. Saving model...\n",
      "\n",
      "LOG: Epoch [196/1000] - Training\n",
      "Epoch [196/1000] completed, Average Training Loss: 0.8573\n",
      "    Validation Batch [1/1], Loss: 0.7999\n",
      "Validation Loss: 0.7999, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.8027 to 0.7999. Saving model...\n",
      "\n",
      "LOG: Epoch [197/1000] - Training\n",
      "Epoch [197/1000] completed, Average Training Loss: 0.8310\n",
      "    Validation Batch [1/1], Loss: 0.7973\n",
      "Validation Loss: 0.7973, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.7999 to 0.7973. Saving model...\n",
      "\n",
      "LOG: Epoch [198/1000] - Training\n",
      "Epoch [198/1000] completed, Average Training Loss: 0.8207\n",
      "    Validation Batch [1/1], Loss: 0.7697\n",
      "Validation Loss: 0.7697, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.7973 to 0.7697. Saving model...\n",
      "\n",
      "LOG: Epoch [199/1000] - Training\n",
      "Epoch [199/1000] completed, Average Training Loss: 0.7969\n",
      "    Validation Batch [1/1], Loss: 0.7651\n",
      "Validation Loss: 0.7651, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.7697 to 0.7651. Saving model...\n",
      "\n",
      "LOG: Epoch [200/1000] - Training\n",
      "Epoch [200/1000] completed, Average Training Loss: 0.8136\n",
      "    Validation Batch [1/1], Loss: 0.7717\n",
      "Validation Loss: 0.7717, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [201/1000] - Training\n",
      "Epoch [201/1000] completed, Average Training Loss: 0.7832\n",
      "    Validation Batch [1/1], Loss: 0.7630\n",
      "Validation Loss: 0.7630, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.7651 to 0.7630. Saving model...\n",
      "\n",
      "LOG: Epoch [202/1000] - Training\n",
      "Epoch [202/1000] completed, Average Training Loss: 0.8035\n",
      "    Validation Batch [1/1], Loss: 0.7393\n",
      "Validation Loss: 0.7393, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.7630 to 0.7393. Saving model...\n",
      "\n",
      "LOG: Epoch [203/1000] - Training\n",
      "Epoch [203/1000] completed, Average Training Loss: 0.7603\n",
      "    Validation Batch [1/1], Loss: 0.7194\n",
      "Validation Loss: 0.7194, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.7393 to 0.7194. Saving model...\n",
      "\n",
      "LOG: Epoch [204/1000] - Training\n",
      "Epoch [204/1000] completed, Average Training Loss: 0.7513\n",
      "    Validation Batch [1/1], Loss: 0.7213\n",
      "Validation Loss: 0.7213, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [205/1000] - Training\n",
      "Epoch [205/1000] completed, Average Training Loss: 0.7719\n",
      "    Validation Batch [1/1], Loss: 0.7170\n",
      "Validation Loss: 0.7170, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.7194 to 0.7170. Saving model...\n",
      "\n",
      "LOG: Epoch [206/1000] - Training\n",
      "Epoch [206/1000] completed, Average Training Loss: 0.7589\n",
      "    Validation Batch [1/1], Loss: 0.7167\n",
      "Validation Loss: 0.7167, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.7170 to 0.7167. Saving model...\n",
      "\n",
      "LOG: Epoch [207/1000] - Training\n",
      "Epoch [207/1000] completed, Average Training Loss: 0.7553\n",
      "    Validation Batch [1/1], Loss: 0.7310\n",
      "Validation Loss: 0.7310, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [208/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [208/1000] completed, Average Training Loss: 0.7667\n",
      "    Validation Batch [1/1], Loss: 0.7087\n",
      "Validation Loss: 0.7087, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.7167 to 0.7087. Saving model...\n",
      "\n",
      "LOG: Epoch [209/1000] - Training\n",
      "Epoch [209/1000] completed, Average Training Loss: 0.7478\n",
      "    Validation Batch [1/1], Loss: 0.6893\n",
      "Validation Loss: 0.6893, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.7087 to 0.6893. Saving model...\n",
      "\n",
      "LOG: Epoch [210/1000] - Training\n",
      "Epoch [210/1000] completed, Average Training Loss: 0.7288\n",
      "    Validation Batch [1/1], Loss: 0.6960\n",
      "Validation Loss: 0.6960, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [211/1000] - Training\n",
      "Epoch [211/1000] completed, Average Training Loss: 0.7193\n",
      "    Validation Batch [1/1], Loss: 0.6935\n",
      "Validation Loss: 0.6935, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [212/1000] - Training\n",
      "Epoch [212/1000] completed, Average Training Loss: 0.7132\n",
      "    Validation Batch [1/1], Loss: 0.6844\n",
      "Validation Loss: 0.6844, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.6893 to 0.6844. Saving model...\n",
      "\n",
      "LOG: Epoch [213/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [213/1000] completed, Average Training Loss: 0.7253\n",
      "    Validation Batch [1/1], Loss: 0.6736\n",
      "Validation Loss: 0.6736, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.6844 to 0.6736. Saving model...\n",
      "\n",
      "LOG: Epoch [214/1000] - Training\n",
      "Epoch [214/1000] completed, Average Training Loss: 0.7008\n",
      "    Validation Batch [1/1], Loss: 0.6627\n",
      "Validation Loss: 0.6627, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6736 to 0.6627. Saving model...\n",
      "\n",
      "LOG: Epoch [215/1000] - Training\n",
      "Epoch [215/1000] completed, Average Training Loss: 0.7173\n",
      "    Validation Batch [1/1], Loss: 0.6473\n",
      "Validation Loss: 0.6473, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6627 to 0.6473. Saving model...\n",
      "\n",
      "LOG: Epoch [216/1000] - Training\n",
      "Epoch [216/1000] completed, Average Training Loss: 0.6986\n",
      "    Validation Batch [1/1], Loss: 0.6427\n",
      "Validation Loss: 0.6427, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.6473 to 0.6427. Saving model...\n",
      "\n",
      "LOG: Epoch [217/1000] - Training\n",
      "Epoch [217/1000] completed, Average Training Loss: 0.6665\n",
      "    Validation Batch [1/1], Loss: 0.6498\n",
      "Validation Loss: 0.6498, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [218/1000] - Training\n",
      "Epoch [218/1000] completed, Average Training Loss: 0.6641\n",
      "    Validation Batch [1/1], Loss: 0.6602\n",
      "Validation Loss: 0.6602, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [219/1000] - Training\n",
      "Epoch [219/1000] completed, Average Training Loss: 0.6727\n",
      "    Validation Batch [1/1], Loss: 0.6515\n",
      "Validation Loss: 0.6515, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [220/1000] - Training\n",
      "Epoch [220/1000] completed, Average Training Loss: 0.6421\n",
      "    Validation Batch [1/1], Loss: 0.6369\n",
      "Validation Loss: 0.6369, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.6427 to 0.6369. Saving model...\n",
      "\n",
      "LOG: Epoch [221/1000] - Training\n",
      "Epoch [221/1000] completed, Average Training Loss: 0.6576\n",
      "    Validation Batch [1/1], Loss: 0.6015\n",
      "Validation Loss: 0.6015, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6369 to 0.6015. Saving model...\n",
      "\n",
      "LOG: Epoch [222/1000] - Training\n",
      "Epoch [222/1000] completed, Average Training Loss: 0.6476\n",
      "    Validation Batch [1/1], Loss: 0.5960\n",
      "Validation Loss: 0.5960, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.6015 to 0.5960. Saving model...\n",
      "\n",
      "LOG: Epoch [223/1000] - Training\n",
      "Epoch [223/1000] completed, Average Training Loss: 0.6388\n",
      "    Validation Batch [1/1], Loss: 0.5879\n",
      "Validation Loss: 0.5879, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5960 to 0.5879. Saving model...\n",
      "\n",
      "LOG: Epoch [224/1000] - Training\n",
      "Epoch [224/1000] completed, Average Training Loss: 0.6257\n",
      "    Validation Batch [1/1], Loss: 0.5955\n",
      "Validation Loss: 0.5955, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [225/1000] - Training\n",
      "Epoch [225/1000] completed, Average Training Loss: 0.6394\n",
      "    Validation Batch [1/1], Loss: 0.5905\n",
      "Validation Loss: 0.5905, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [226/1000] - Training\n",
      "Epoch [226/1000] completed, Average Training Loss: 0.6531\n",
      "    Validation Batch [1/1], Loss: 0.5848\n",
      "Validation Loss: 0.5848, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.5879 to 0.5848. Saving model...\n",
      "\n",
      "LOG: Epoch [227/1000] - Training\n",
      "Epoch [227/1000] completed, Average Training Loss: 0.6245\n",
      "    Validation Batch [1/1], Loss: 0.5788\n",
      "Validation Loss: 0.5788, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5848 to 0.5788. Saving model...\n",
      "\n",
      "LOG: Epoch [228/1000] - Training\n",
      "Epoch [228/1000] completed, Average Training Loss: 0.6154\n",
      "    Validation Batch [1/1], Loss: 0.5761\n",
      "Validation Loss: 0.5761, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5788 to 0.5761. Saving model...\n",
      "\n",
      "LOG: Epoch [229/1000] - Training\n",
      "Epoch [229/1000] completed, Average Training Loss: 0.6089\n",
      "    Validation Batch [1/1], Loss: 0.5649\n",
      "Validation Loss: 0.5649, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5761 to 0.5649. Saving model...\n",
      "\n",
      "LOG: Epoch [230/1000] - Training\n",
      "Epoch [230/1000] completed, Average Training Loss: 0.5942\n",
      "    Validation Batch [1/1], Loss: 0.5643\n",
      "Validation Loss: 0.5643, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5649 to 0.5643. Saving model...\n",
      "\n",
      "LOG: Epoch [231/1000] - Training\n",
      "Epoch [231/1000] completed, Average Training Loss: 0.5895\n",
      "    Validation Batch [1/1], Loss: 0.5568\n",
      "Validation Loss: 0.5568, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5643 to 0.5568. Saving model...\n",
      "\n",
      "LOG: Epoch [232/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [232/1000] completed, Average Training Loss: 0.5870\n",
      "    Validation Batch [1/1], Loss: 0.5362\n",
      "Validation Loss: 0.5362, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5568 to 0.5362. Saving model...\n",
      "\n",
      "LOG: Epoch [233/1000] - Training\n",
      "Epoch [233/1000] completed, Average Training Loss: 0.5853\n",
      "    Validation Batch [1/1], Loss: 0.5395\n",
      "Validation Loss: 0.5395, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [234/1000] - Training\n",
      "Epoch [234/1000] completed, Average Training Loss: 0.5934\n",
      "    Validation Batch [1/1], Loss: 0.5386\n",
      "Validation Loss: 0.5386, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [235/1000] - Training\n",
      "Epoch [235/1000] completed, Average Training Loss: 0.6018\n",
      "    Validation Batch [1/1], Loss: 0.5299\n",
      "Validation Loss: 0.5299, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5362 to 0.5299. Saving model...\n",
      "\n",
      "LOG: Epoch [236/1000] - Training\n",
      "Epoch [236/1000] completed, Average Training Loss: 0.5719\n",
      "    Validation Batch [1/1], Loss: 0.5283\n",
      "Validation Loss: 0.5283, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5299 to 0.5283. Saving model...\n",
      "\n",
      "LOG: Epoch [237/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [237/1000] completed, Average Training Loss: 0.5694\n",
      "    Validation Batch [1/1], Loss: 0.5114\n",
      "Validation Loss: 0.5114, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5283 to 0.5114. Saving model...\n",
      "\n",
      "LOG: Epoch [238/1000] - Training\n",
      "Epoch [238/1000] completed, Average Training Loss: 0.5696\n",
      "    Validation Batch [1/1], Loss: 0.5095\n",
      "Validation Loss: 0.5095, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.5114 to 0.5095. Saving model...\n",
      "\n",
      "LOG: Epoch [239/1000] - Training\n",
      "Epoch [239/1000] completed, Average Training Loss: 0.5587\n",
      "    Validation Batch [1/1], Loss: 0.5045\n",
      "Validation Loss: 0.5045, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.5095 to 0.5045. Saving model...\n",
      "\n",
      "LOG: Epoch [240/1000] - Training\n",
      "Epoch [240/1000] completed, Average Training Loss: 0.5461\n",
      "    Validation Batch [1/1], Loss: 0.5025\n",
      "Validation Loss: 0.5025, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.5045 to 0.5025. Saving model...\n",
      "\n",
      "LOG: Epoch [241/1000] - Training\n",
      "Epoch [241/1000] completed, Average Training Loss: 0.5763\n",
      "    Validation Batch [1/1], Loss: 0.5005\n",
      "Validation Loss: 0.5005, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.5025 to 0.5005. Saving model...\n",
      "\n",
      "LOG: Epoch [242/1000] - Training\n",
      "Epoch [242/1000] completed, Average Training Loss: 0.5254\n",
      "    Validation Batch [1/1], Loss: 0.5079\n",
      "Validation Loss: 0.5079, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [243/1000] - Training\n",
      "Epoch [243/1000] completed, Average Training Loss: 0.5253\n",
      "    Validation Batch [1/1], Loss: 0.5063\n",
      "Validation Loss: 0.5063, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [244/1000] - Training\n",
      "Epoch [244/1000] completed, Average Training Loss: 0.5469\n",
      "    Validation Batch [1/1], Loss: 0.4962\n",
      "Validation Loss: 0.4962, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.5005 to 0.4962. Saving model...\n",
      "\n",
      "LOG: Epoch [245/1000] - Training\n",
      "Epoch [245/1000] completed, Average Training Loss: 0.5392\n",
      "    Validation Batch [1/1], Loss: 0.4726\n",
      "Validation Loss: 0.4726, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.4962 to 0.4726. Saving model...\n",
      "\n",
      "LOG: Epoch [246/1000] - Training\n",
      "Epoch [246/1000] completed, Average Training Loss: 0.5144\n",
      "    Validation Batch [1/1], Loss: 0.4505\n",
      "Validation Loss: 0.4505, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4726 to 0.4505. Saving model...\n",
      "\n",
      "LOG: Epoch [247/1000] - Training\n",
      "Epoch [247/1000] completed, Average Training Loss: 0.4806\n",
      "    Validation Batch [1/1], Loss: 0.4509\n",
      "Validation Loss: 0.4509, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [248/1000] - Training\n",
      "Epoch [248/1000] completed, Average Training Loss: 0.5091\n",
      "    Validation Batch [1/1], Loss: 0.4596\n",
      "Validation Loss: 0.4596, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [249/1000] - Training\n",
      "Epoch [249/1000] completed, Average Training Loss: 0.5133\n",
      "    Validation Batch [1/1], Loss: 0.4623\n",
      "Validation Loss: 0.4623, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [250/1000] - Training\n",
      "Epoch [250/1000] completed, Average Training Loss: 0.5516\n",
      "    Validation Batch [1/1], Loss: 0.4558\n",
      "Validation Loss: 0.4558, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [251/1000] - Training\n",
      "Epoch [251/1000] completed, Average Training Loss: 0.5116\n",
      "    Validation Batch [1/1], Loss: 0.4425\n",
      "Validation Loss: 0.4425, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.4505 to 0.4425. Saving model...\n",
      "\n",
      "LOG: Epoch [252/1000] - Training\n",
      "Epoch [252/1000] completed, Average Training Loss: 0.4806\n",
      "    Validation Batch [1/1], Loss: 0.4390\n",
      "Validation Loss: 0.4390, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4425 to 0.4390. Saving model...\n",
      "\n",
      "LOG: Epoch [253/1000] - Training\n",
      "Epoch [253/1000] completed, Average Training Loss: 0.5067\n",
      "    Validation Batch [1/1], Loss: 0.4363\n",
      "Validation Loss: 0.4363, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.4390 to 0.4363. Saving model...\n",
      "\n",
      "LOG: Epoch [254/1000] - Training\n",
      "Epoch [254/1000] completed, Average Training Loss: 0.4615\n",
      "    Validation Batch [1/1], Loss: 0.4326\n",
      "Validation Loss: 0.4326, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4363 to 0.4326. Saving model...\n",
      "\n",
      "LOG: Epoch [255/1000] - Training\n",
      "Epoch [255/1000] completed, Average Training Loss: 0.4927\n",
      "    Validation Batch [1/1], Loss: 0.4398\n",
      "Validation Loss: 0.4398, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [256/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [256/1000] completed, Average Training Loss: 0.4759\n",
      "    Validation Batch [1/1], Loss: 0.4405\n",
      "Validation Loss: 0.4405, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [257/1000] - Training\n",
      "Epoch [257/1000] completed, Average Training Loss: 0.4366\n",
      "    Validation Batch [1/1], Loss: 0.4196\n",
      "Validation Loss: 0.4196, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.4326 to 0.4196. Saving model...\n",
      "\n",
      "LOG: Epoch [258/1000] - Training\n",
      "Epoch [258/1000] completed, Average Training Loss: 0.4627\n",
      "    Validation Batch [1/1], Loss: 0.4082\n",
      "Validation Loss: 0.4082, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.4196 to 0.4082. Saving model...\n",
      "\n",
      "LOG: Epoch [259/1000] - Training\n",
      "Epoch [259/1000] completed, Average Training Loss: 0.4775\n",
      "    Validation Batch [1/1], Loss: 0.4114\n",
      "Validation Loss: 0.4114, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [260/1000] - Training\n",
      "Epoch [260/1000] completed, Average Training Loss: 0.4403\n",
      "    Validation Batch [1/1], Loss: 0.3989\n",
      "Validation Loss: 0.3989, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.4082 to 0.3989. Saving model...\n",
      "\n",
      "LOG: Epoch [261/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [261/1000] completed, Average Training Loss: 0.4572\n",
      "    Validation Batch [1/1], Loss: 0.3797\n",
      "Validation Loss: 0.3797, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3989 to 0.3797. Saving model...\n",
      "\n",
      "LOG: Epoch [262/1000] - Training\n",
      "Epoch [262/1000] completed, Average Training Loss: 0.4546\n",
      "    Validation Batch [1/1], Loss: 0.3744\n",
      "Validation Loss: 0.3744, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3797 to 0.3744. Saving model...\n",
      "\n",
      "LOG: Epoch [263/1000] - Training\n",
      "Epoch [263/1000] completed, Average Training Loss: 0.4147\n",
      "    Validation Batch [1/1], Loss: 0.3761\n",
      "Validation Loss: 0.3761, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [264/1000] - Training\n",
      "Epoch [264/1000] completed, Average Training Loss: 0.4304\n",
      "    Validation Batch [1/1], Loss: 0.3814\n",
      "Validation Loss: 0.3814, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [265/1000] - Training\n",
      "Epoch [265/1000] completed, Average Training Loss: 0.4518\n",
      "    Validation Batch [1/1], Loss: 0.3807\n",
      "Validation Loss: 0.3807, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [266/1000] - Training\n",
      "Epoch [266/1000] completed, Average Training Loss: 0.4448\n",
      "    Validation Batch [1/1], Loss: 0.3778\n",
      "Validation Loss: 0.3778, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [267/1000] - Training\n",
      "Epoch [267/1000] completed, Average Training Loss: 0.4126\n",
      "    Validation Batch [1/1], Loss: 0.3813\n",
      "Validation Loss: 0.3813, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [268/1000] - Training\n",
      "Epoch [268/1000] completed, Average Training Loss: 0.4091\n",
      "    Validation Batch [1/1], Loss: 0.3841\n",
      "Validation Loss: 0.3841, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [269/1000] - Training\n",
      "Epoch [269/1000] completed, Average Training Loss: 0.4191\n",
      "    Validation Batch [1/1], Loss: 0.3748\n",
      "Validation Loss: 0.3748, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [270/1000] - Training\n",
      "Epoch [270/1000] completed, Average Training Loss: 0.4376\n",
      "    Validation Batch [1/1], Loss: 0.3677\n",
      "Validation Loss: 0.3677, Validation Accuracy: 98.57%\n",
      "Validation loss improved from 0.3744 to 0.3677. Saving model...\n",
      "\n",
      "LOG: Epoch [271/1000] - Training\n",
      "Epoch [271/1000] completed, Average Training Loss: 0.4248\n",
      "    Validation Batch [1/1], Loss: 0.3603\n",
      "Validation Loss: 0.3603, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3677 to 0.3603. Saving model...\n",
      "\n",
      "LOG: Epoch [272/1000] - Training\n",
      "Epoch [272/1000] completed, Average Training Loss: 0.4144\n",
      "    Validation Batch [1/1], Loss: 0.3530\n",
      "Validation Loss: 0.3530, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3603 to 0.3530. Saving model...\n",
      "\n",
      "LOG: Epoch [273/1000] - Training\n",
      "Epoch [273/1000] completed, Average Training Loss: 0.4306\n",
      "    Validation Batch [1/1], Loss: 0.3499\n",
      "Validation Loss: 0.3499, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3530 to 0.3499. Saving model...\n",
      "\n",
      "LOG: Epoch [274/1000] - Training\n",
      "Epoch [274/1000] completed, Average Training Loss: 0.3684\n",
      "    Validation Batch [1/1], Loss: 0.3416\n",
      "Validation Loss: 0.3416, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3499 to 0.3416. Saving model...\n",
      "\n",
      "LOG: Epoch [275/1000] - Training\n",
      "Epoch [275/1000] completed, Average Training Loss: 0.3641\n",
      "    Validation Batch [1/1], Loss: 0.3358\n",
      "Validation Loss: 0.3358, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3416 to 0.3358. Saving model...\n",
      "\n",
      "LOG: Epoch [276/1000] - Training\n",
      "Epoch [276/1000] completed, Average Training Loss: 0.4318\n",
      "    Validation Batch [1/1], Loss: 0.3335\n",
      "Validation Loss: 0.3335, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3358 to 0.3335. Saving model...\n",
      "\n",
      "LOG: Epoch [277/1000] - Training\n",
      "Epoch [277/1000] completed, Average Training Loss: 0.4151\n",
      "    Validation Batch [1/1], Loss: 0.3391\n",
      "Validation Loss: 0.3391, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [278/1000] - Training\n",
      "Epoch [278/1000] completed, Average Training Loss: 0.3652\n",
      "    Validation Batch [1/1], Loss: 0.3313\n",
      "Validation Loss: 0.3313, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3335 to 0.3313. Saving model...\n",
      "\n",
      "LOG: Epoch [279/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [279/1000] completed, Average Training Loss: 0.3593\n",
      "    Validation Batch [1/1], Loss: 0.3267\n",
      "Validation Loss: 0.3267, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3313 to 0.3267. Saving model...\n",
      "\n",
      "LOG: Epoch [280/1000] - Training\n",
      "Epoch [280/1000] completed, Average Training Loss: 0.3548\n",
      "    Validation Batch [1/1], Loss: 0.3198\n",
      "Validation Loss: 0.3198, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3267 to 0.3198. Saving model...\n",
      "\n",
      "LOG: Epoch [281/1000] - Training\n",
      "Epoch [281/1000] completed, Average Training Loss: 0.3651\n",
      "    Validation Batch [1/1], Loss: 0.3224\n",
      "Validation Loss: 0.3224, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [282/1000] - Training\n",
      "Epoch [282/1000] completed, Average Training Loss: 0.3459\n",
      "    Validation Batch [1/1], Loss: 0.3301\n",
      "Validation Loss: 0.3301, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [283/1000] - Training\n",
      "Epoch [283/1000] completed, Average Training Loss: 0.3621\n",
      "    Validation Batch [1/1], Loss: 0.3225\n",
      "Validation Loss: 0.3225, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [284/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [284/1000] completed, Average Training Loss: 0.3547\n",
      "    Validation Batch [1/1], Loss: 0.3130\n",
      "Validation Loss: 0.3130, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3198 to 0.3130. Saving model...\n",
      "\n",
      "LOG: Epoch [285/1000] - Training\n",
      "Epoch [285/1000] completed, Average Training Loss: 0.3644\n",
      "    Validation Batch [1/1], Loss: 0.3111\n",
      "Validation Loss: 0.3111, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3130 to 0.3111. Saving model...\n",
      "\n",
      "LOG: Epoch [286/1000] - Training\n",
      "Epoch [286/1000] completed, Average Training Loss: 0.3330\n",
      "    Validation Batch [1/1], Loss: 0.3142\n",
      "Validation Loss: 0.3142, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [287/1000] - Training\n",
      "Epoch [287/1000] completed, Average Training Loss: 0.3642\n",
      "    Validation Batch [1/1], Loss: 0.3183\n",
      "Validation Loss: 0.3183, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [288/1000] - Training\n",
      "Epoch [288/1000] completed, Average Training Loss: 0.3412\n",
      "    Validation Batch [1/1], Loss: 0.3070\n",
      "Validation Loss: 0.3070, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3111 to 0.3070. Saving model...\n",
      "\n",
      "LOG: Epoch [289/1000] - Training\n",
      "Epoch [289/1000] completed, Average Training Loss: 0.3070\n",
      "    Validation Batch [1/1], Loss: 0.2938\n",
      "Validation Loss: 0.2938, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.3070 to 0.2938. Saving model...\n",
      "\n",
      "LOG: Epoch [290/1000] - Training\n",
      "Epoch [290/1000] completed, Average Training Loss: 0.3369\n",
      "    Validation Batch [1/1], Loss: 0.3011\n",
      "Validation Loss: 0.3011, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [291/1000] - Training\n",
      "Epoch [291/1000] completed, Average Training Loss: 0.3392\n",
      "    Validation Batch [1/1], Loss: 0.2979\n",
      "Validation Loss: 0.2979, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [292/1000] - Training\n",
      "Epoch [292/1000] completed, Average Training Loss: 0.3365\n",
      "    Validation Batch [1/1], Loss: 0.2855\n",
      "Validation Loss: 0.2855, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2938 to 0.2855. Saving model...\n",
      "\n",
      "LOG: Epoch [293/1000] - Training\n",
      "Epoch [293/1000] completed, Average Training Loss: 0.3281\n",
      "    Validation Batch [1/1], Loss: 0.2753\n",
      "Validation Loss: 0.2753, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2855 to 0.2753. Saving model...\n",
      "\n",
      "LOG: Epoch [294/1000] - Training\n",
      "Epoch [294/1000] completed, Average Training Loss: 0.3323\n",
      "    Validation Batch [1/1], Loss: 0.2710\n",
      "Validation Loss: 0.2710, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2753 to 0.2710. Saving model...\n",
      "\n",
      "LOG: Epoch [295/1000] - Training\n",
      "Epoch [295/1000] completed, Average Training Loss: 0.3171\n",
      "    Validation Batch [1/1], Loss: 0.2688\n",
      "Validation Loss: 0.2688, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2710 to 0.2688. Saving model...\n",
      "\n",
      "LOG: Epoch [296/1000] - Training\n",
      "Epoch [296/1000] completed, Average Training Loss: 0.3065\n",
      "    Validation Batch [1/1], Loss: 0.2795\n",
      "Validation Loss: 0.2795, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [297/1000] - Training\n",
      "Epoch [297/1000] completed, Average Training Loss: 0.2842\n",
      "    Validation Batch [1/1], Loss: 0.2876\n",
      "Validation Loss: 0.2876, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [298/1000] - Training\n",
      "Epoch [298/1000] completed, Average Training Loss: 0.3304\n",
      "    Validation Batch [1/1], Loss: 0.2719\n",
      "Validation Loss: 0.2719, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [299/1000] - Training\n",
      "Epoch [299/1000] completed, Average Training Loss: 0.2875\n",
      "    Validation Batch [1/1], Loss: 0.2631\n",
      "Validation Loss: 0.2631, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2688 to 0.2631. Saving model...\n",
      "\n",
      "LOG: Epoch [300/1000] - Training\n",
      "Epoch [300/1000] completed, Average Training Loss: 0.3066\n",
      "    Validation Batch [1/1], Loss: 0.2596\n",
      "Validation Loss: 0.2596, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2631 to 0.2596. Saving model...\n",
      "\n",
      "LOG: Epoch [301/1000] - Training\n",
      "Epoch [301/1000] completed, Average Training Loss: 0.3433\n",
      "    Validation Batch [1/1], Loss: 0.2650\n",
      "Validation Loss: 0.2650, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [302/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [302/1000] completed, Average Training Loss: 0.2962\n",
      "    Validation Batch [1/1], Loss: 0.2748\n",
      "Validation Loss: 0.2748, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [303/1000] - Training\n",
      "Epoch [303/1000] completed, Average Training Loss: 0.3015\n",
      "    Validation Batch [1/1], Loss: 0.2594\n",
      "Validation Loss: 0.2594, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2596 to 0.2594. Saving model...\n",
      "\n",
      "LOG: Epoch [304/1000] - Training\n",
      "Epoch [304/1000] completed, Average Training Loss: 0.3285\n",
      "    Validation Batch [1/1], Loss: 0.2550\n",
      "Validation Loss: 0.2550, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2594 to 0.2550. Saving model...\n",
      "\n",
      "LOG: Epoch [305/1000] - Training\n",
      "Epoch [305/1000] completed, Average Training Loss: 0.2994\n",
      "    Validation Batch [1/1], Loss: 0.2617\n",
      "Validation Loss: 0.2617, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [306/1000] - Training\n",
      "Epoch [306/1000] completed, Average Training Loss: 0.2862\n",
      "    Validation Batch [1/1], Loss: 0.2663\n",
      "Validation Loss: 0.2663, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [307/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [307/1000] completed, Average Training Loss: 0.3003\n",
      "    Validation Batch [1/1], Loss: 0.2680\n",
      "Validation Loss: 0.2680, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [308/1000] - Training\n",
      "Epoch [308/1000] completed, Average Training Loss: 0.2914\n",
      "    Validation Batch [1/1], Loss: 0.2663\n",
      "Validation Loss: 0.2663, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [309/1000] - Training\n",
      "Epoch [309/1000] completed, Average Training Loss: 0.2870\n",
      "    Validation Batch [1/1], Loss: 0.2582\n",
      "Validation Loss: 0.2582, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [310/1000] - Training\n",
      "Epoch [310/1000] completed, Average Training Loss: 0.2792\n",
      "    Validation Batch [1/1], Loss: 0.2455\n",
      "Validation Loss: 0.2455, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2550 to 0.2455. Saving model...\n",
      "\n",
      "LOG: Epoch [311/1000] - Training\n",
      "Epoch [311/1000] completed, Average Training Loss: 0.2825\n",
      "    Validation Batch [1/1], Loss: 0.2408\n",
      "Validation Loss: 0.2408, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2455 to 0.2408. Saving model...\n",
      "\n",
      "LOG: Epoch [312/1000] - Training\n",
      "Epoch [312/1000] completed, Average Training Loss: 0.2515\n",
      "    Validation Batch [1/1], Loss: 0.2446\n",
      "Validation Loss: 0.2446, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [313/1000] - Training\n",
      "Epoch [313/1000] completed, Average Training Loss: 0.2614\n",
      "    Validation Batch [1/1], Loss: 0.2427\n",
      "Validation Loss: 0.2427, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [314/1000] - Training\n",
      "Epoch [314/1000] completed, Average Training Loss: 0.2653\n",
      "    Validation Batch [1/1], Loss: 0.2564\n",
      "Validation Loss: 0.2564, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [315/1000] - Training\n",
      "Epoch [315/1000] completed, Average Training Loss: 0.2885\n",
      "    Validation Batch [1/1], Loss: 0.2412\n",
      "Validation Loss: 0.2412, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [316/1000] - Training\n",
      "Epoch [316/1000] completed, Average Training Loss: 0.2606\n",
      "    Validation Batch [1/1], Loss: 0.2173\n",
      "Validation Loss: 0.2173, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2408 to 0.2173. Saving model...\n",
      "\n",
      "LOG: Epoch [317/1000] - Training\n",
      "Epoch [317/1000] completed, Average Training Loss: 0.2682\n",
      "    Validation Batch [1/1], Loss: 0.2356\n",
      "Validation Loss: 0.2356, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [318/1000] - Training\n",
      "Epoch [318/1000] completed, Average Training Loss: 0.2742\n",
      "    Validation Batch [1/1], Loss: 0.2540\n",
      "Validation Loss: 0.2540, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [319/1000] - Training\n",
      "Epoch [319/1000] completed, Average Training Loss: 0.2656\n",
      "    Validation Batch [1/1], Loss: 0.2311\n",
      "Validation Loss: 0.2311, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [320/1000] - Training\n",
      "Epoch [320/1000] completed, Average Training Loss: 0.2607\n",
      "    Validation Batch [1/1], Loss: 0.2250\n",
      "Validation Loss: 0.2250, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [321/1000] - Training\n",
      "Epoch [321/1000] completed, Average Training Loss: 0.2569\n",
      "    Validation Batch [1/1], Loss: 0.2240\n",
      "Validation Loss: 0.2240, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [322/1000] - Training\n",
      "Epoch [322/1000] completed, Average Training Loss: 0.2433\n",
      "    Validation Batch [1/1], Loss: 0.2177\n",
      "Validation Loss: 0.2177, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [323/1000] - Training\n",
      "Epoch [323/1000] completed, Average Training Loss: 0.2709\n",
      "    Validation Batch [1/1], Loss: 0.2143\n",
      "Validation Loss: 0.2143, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2173 to 0.2143. Saving model...\n",
      "\n",
      "LOG: Epoch [324/1000] - Training\n",
      "Epoch [324/1000] completed, Average Training Loss: 0.2692\n",
      "    Validation Batch [1/1], Loss: 0.2197\n",
      "Validation Loss: 0.2197, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [325/1000] - Training\n",
      "Epoch [325/1000] completed, Average Training Loss: 0.2552\n",
      "    Validation Batch [1/1], Loss: 0.2040\n",
      "Validation Loss: 0.2040, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2143 to 0.2040. Saving model...\n",
      "\n",
      "LOG: Epoch [326/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [326/1000] completed, Average Training Loss: 0.2468\n",
      "    Validation Batch [1/1], Loss: 0.2023\n",
      "Validation Loss: 0.2023, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2040 to 0.2023. Saving model...\n",
      "\n",
      "LOG: Epoch [327/1000] - Training\n",
      "Epoch [327/1000] completed, Average Training Loss: 0.2498\n",
      "    Validation Batch [1/1], Loss: 0.2138\n",
      "Validation Loss: 0.2138, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [328/1000] - Training\n",
      "Epoch [328/1000] completed, Average Training Loss: 0.2512\n",
      "    Validation Batch [1/1], Loss: 0.2226\n",
      "Validation Loss: 0.2226, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [329/1000] - Training\n",
      "Epoch [329/1000] completed, Average Training Loss: 0.2389\n",
      "    Validation Batch [1/1], Loss: 0.2174\n",
      "Validation Loss: 0.2174, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [330/1000] - Training\n",
      "Epoch [330/1000] completed, Average Training Loss: 0.2376\n",
      "    Validation Batch [1/1], Loss: 0.2129\n",
      "Validation Loss: 0.2129, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [331/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [331/1000] completed, Average Training Loss: 0.2331\n",
      "    Validation Batch [1/1], Loss: 0.2131\n",
      "Validation Loss: 0.2131, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [332/1000] - Training\n",
      "Epoch [332/1000] completed, Average Training Loss: 0.2344\n",
      "    Validation Batch [1/1], Loss: 0.2067\n",
      "Validation Loss: 0.2067, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [333/1000] - Training\n",
      "Epoch [333/1000] completed, Average Training Loss: 0.2266\n",
      "    Validation Batch [1/1], Loss: 0.2059\n",
      "Validation Loss: 0.2059, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [334/1000] - Training\n",
      "Epoch [334/1000] completed, Average Training Loss: 0.2175\n",
      "    Validation Batch [1/1], Loss: 0.2078\n",
      "Validation Loss: 0.2078, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [335/1000] - Training\n",
      "Epoch [335/1000] completed, Average Training Loss: 0.2248\n",
      "    Validation Batch [1/1], Loss: 0.1978\n",
      "Validation Loss: 0.1978, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.2023 to 0.1978. Saving model...\n",
      "\n",
      "LOG: Epoch [336/1000] - Training\n",
      "Epoch [336/1000] completed, Average Training Loss: 0.2549\n",
      "    Validation Batch [1/1], Loss: 0.1933\n",
      "Validation Loss: 0.1933, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1978 to 0.1933. Saving model...\n",
      "\n",
      "LOG: Epoch [337/1000] - Training\n",
      "Epoch [337/1000] completed, Average Training Loss: 0.2242\n",
      "    Validation Batch [1/1], Loss: 0.1969\n",
      "Validation Loss: 0.1969, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [338/1000] - Training\n",
      "Epoch [338/1000] completed, Average Training Loss: 0.2177\n",
      "    Validation Batch [1/1], Loss: 0.2033\n",
      "Validation Loss: 0.2033, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [339/1000] - Training\n",
      "Epoch [339/1000] completed, Average Training Loss: 0.2260\n",
      "    Validation Batch [1/1], Loss: 0.2020\n",
      "Validation Loss: 0.2020, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [340/1000] - Training\n",
      "Epoch [340/1000] completed, Average Training Loss: 0.2097\n",
      "    Validation Batch [1/1], Loss: 0.1903\n",
      "Validation Loss: 0.1903, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1933 to 0.1903. Saving model...\n",
      "\n",
      "LOG: Epoch [341/1000] - Training\n",
      "Epoch [341/1000] completed, Average Training Loss: 0.2334\n",
      "    Validation Batch [1/1], Loss: 0.1840\n",
      "Validation Loss: 0.1840, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1903 to 0.1840. Saving model...\n",
      "\n",
      "LOG: Epoch [342/1000] - Training\n",
      "Epoch [342/1000] completed, Average Training Loss: 0.2282\n",
      "    Validation Batch [1/1], Loss: 0.1826\n",
      "Validation Loss: 0.1826, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1840 to 0.1826. Saving model...\n",
      "\n",
      "LOG: Epoch [343/1000] - Training\n",
      "Epoch [343/1000] completed, Average Training Loss: 0.2232\n",
      "    Validation Batch [1/1], Loss: 0.1784\n",
      "Validation Loss: 0.1784, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1826 to 0.1784. Saving model...\n",
      "\n",
      "LOG: Epoch [344/1000] - Training\n",
      "Epoch [344/1000] completed, Average Training Loss: 0.2250\n",
      "    Validation Batch [1/1], Loss: 0.1797\n",
      "Validation Loss: 0.1797, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [345/1000] - Training\n",
      "Epoch [345/1000] completed, Average Training Loss: 0.2083\n",
      "    Validation Batch [1/1], Loss: 0.1767\n",
      "Validation Loss: 0.1767, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1784 to 0.1767. Saving model...\n",
      "\n",
      "LOG: Epoch [346/1000] - Training\n",
      "Epoch [346/1000] completed, Average Training Loss: 0.2201\n",
      "    Validation Batch [1/1], Loss: 0.1691\n",
      "Validation Loss: 0.1691, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1767 to 0.1691. Saving model...\n",
      "\n",
      "LOG: Epoch [347/1000] - Training\n",
      "Epoch [347/1000] completed, Average Training Loss: 0.2319\n",
      "    Validation Batch [1/1], Loss: 0.1691\n",
      "Validation Loss: 0.1691, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [348/1000] - Training\n",
      "Epoch [348/1000] completed, Average Training Loss: 0.2104\n",
      "    Validation Batch [1/1], Loss: 0.1748\n",
      "Validation Loss: 0.1748, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [349/1000] - Training\n",
      "Epoch [349/1000] completed, Average Training Loss: 0.2252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1767\n",
      "Validation Loss: 0.1767, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [350/1000] - Training\n",
      "Epoch [350/1000] completed, Average Training Loss: 0.2047\n",
      "    Validation Batch [1/1], Loss: 0.1745\n",
      "Validation Loss: 0.1745, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [351/1000] - Training\n",
      "Epoch [351/1000] completed, Average Training Loss: 0.1917\n",
      "    Validation Batch [1/1], Loss: 0.1749\n",
      "Validation Loss: 0.1749, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [352/1000] - Training\n",
      "Epoch [352/1000] completed, Average Training Loss: 0.1951\n",
      "    Validation Batch [1/1], Loss: 0.1774\n",
      "Validation Loss: 0.1774, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [353/1000] - Training\n",
      "Epoch [353/1000] completed, Average Training Loss: 0.2262\n",
      "    Validation Batch [1/1], Loss: 0.1754\n",
      "Validation Loss: 0.1754, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [354/1000] - Training\n",
      "Epoch [354/1000] completed, Average Training Loss: 0.1926\n",
      "    Validation Batch [1/1], Loss: 0.1748\n",
      "Validation Loss: 0.1748, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [355/1000] - Training\n",
      "Epoch [355/1000] completed, Average Training Loss: 0.1970\n",
      "    Validation Batch [1/1], Loss: 0.1622\n",
      "Validation Loss: 0.1622, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1691 to 0.1622. Saving model...\n",
      "\n",
      "LOG: Epoch [356/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [356/1000] completed, Average Training Loss: 0.1973\n",
      "    Validation Batch [1/1], Loss: 0.1562\n",
      "Validation Loss: 0.1562, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1622 to 0.1562. Saving model...\n",
      "\n",
      "LOG: Epoch [357/1000] - Training\n",
      "Epoch [357/1000] completed, Average Training Loss: 0.1960\n",
      "    Validation Batch [1/1], Loss: 0.1628\n",
      "Validation Loss: 0.1628, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [358/1000] - Training\n",
      "Epoch [358/1000] completed, Average Training Loss: 0.1915\n",
      "    Validation Batch [1/1], Loss: 0.1657\n",
      "Validation Loss: 0.1657, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [359/1000] - Training\n",
      "Epoch [359/1000] completed, Average Training Loss: 0.1894\n",
      "    Validation Batch [1/1], Loss: 0.1665\n",
      "Validation Loss: 0.1665, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [360/1000] - Training\n",
      "Epoch [360/1000] completed, Average Training Loss: 0.1767\n",
      "    Validation Batch [1/1], Loss: 0.1765\n",
      "Validation Loss: 0.1765, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [361/1000] - Training\n",
      "Epoch [361/1000] completed, Average Training Loss: 0.1868\n",
      "    Validation Batch [1/1], Loss: 0.1964\n",
      "Validation Loss: 0.1964, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [362/1000] - Training\n",
      "Epoch [362/1000] completed, Average Training Loss: 0.1852\n",
      "    Validation Batch [1/1], Loss: 0.1869\n",
      "Validation Loss: 0.1869, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [363/1000] - Training\n",
      "Epoch [363/1000] completed, Average Training Loss: 0.1800\n",
      "    Validation Batch [1/1], Loss: 0.1587\n",
      "Validation Loss: 0.1587, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [364/1000] - Training\n",
      "Epoch [364/1000] completed, Average Training Loss: 0.1976\n",
      "    Validation Batch [1/1], Loss: 0.1510\n",
      "Validation Loss: 0.1510, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1562 to 0.1510. Saving model...\n",
      "\n",
      "LOG: Epoch [365/1000] - Training\n",
      "Epoch [365/1000] completed, Average Training Loss: 0.2002\n",
      "    Validation Batch [1/1], Loss: 0.1570\n",
      "Validation Loss: 0.1570, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [366/1000] - Training\n",
      "Epoch [366/1000] completed, Average Training Loss: 0.1980\n",
      "    Validation Batch [1/1], Loss: 0.1548\n",
      "Validation Loss: 0.1548, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [367/1000] - Training\n",
      "Epoch [367/1000] completed, Average Training Loss: 0.1879\n",
      "    Validation Batch [1/1], Loss: 0.1590\n",
      "Validation Loss: 0.1590, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [368/1000] - Training\n",
      "Epoch [368/1000] completed, Average Training Loss: 0.1894\n",
      "    Validation Batch [1/1], Loss: 0.1700\n",
      "Validation Loss: 0.1700, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [369/1000] - Training\n",
      "Epoch [369/1000] completed, Average Training Loss: 0.1810\n",
      "    Validation Batch [1/1], Loss: 0.1656\n",
      "Validation Loss: 0.1656, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [370/1000] - Training\n",
      "Epoch [370/1000] completed, Average Training Loss: 0.1776\n",
      "    Validation Batch [1/1], Loss: 0.1560\n",
      "Validation Loss: 0.1560, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [371/1000] - Training\n",
      "Epoch [371/1000] completed, Average Training Loss: 0.1811\n",
      "    Validation Batch [1/1], Loss: 0.1476\n",
      "Validation Loss: 0.1476, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1510 to 0.1476. Saving model...\n",
      "\n",
      "LOG: Epoch [372/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [372/1000] completed, Average Training Loss: 0.1661\n",
      "    Validation Batch [1/1], Loss: 0.1491\n",
      "Validation Loss: 0.1491, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [373/1000] - Training\n",
      "Epoch [373/1000] completed, Average Training Loss: 0.1589\n",
      "    Validation Batch [1/1], Loss: 0.1500\n",
      "Validation Loss: 0.1500, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [374/1000] - Training\n",
      "Epoch [374/1000] completed, Average Training Loss: 0.1556\n",
      "    Validation Batch [1/1], Loss: 0.1502\n",
      "Validation Loss: 0.1502, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [375/1000] - Training\n",
      "Epoch [375/1000] completed, Average Training Loss: 0.1724\n",
      "    Validation Batch [1/1], Loss: 0.1473\n",
      "Validation Loss: 0.1473, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1476 to 0.1473. Saving model...\n",
      "\n",
      "LOG: Epoch [376/1000] - Training\n",
      "Epoch [376/1000] completed, Average Training Loss: 0.1802\n",
      "    Validation Batch [1/1], Loss: 0.1466\n",
      "Validation Loss: 0.1466, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1473 to 0.1466. Saving model...\n",
      "\n",
      "LOG: Epoch [377/1000] - Training\n",
      "Epoch [377/1000] completed, Average Training Loss: 0.1788\n",
      "    Validation Batch [1/1], Loss: 0.1520\n",
      "Validation Loss: 0.1520, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [378/1000] - Training\n",
      "Epoch [378/1000] completed, Average Training Loss: 0.1609\n",
      "    Validation Batch [1/1], Loss: 0.1496\n",
      "Validation Loss: 0.1496, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [379/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [379/1000] completed, Average Training Loss: 0.1621\n",
      "    Validation Batch [1/1], Loss: 0.1435\n",
      "Validation Loss: 0.1435, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1466 to 0.1435. Saving model...\n",
      "\n",
      "LOG: Epoch [380/1000] - Training\n",
      "Epoch [380/1000] completed, Average Training Loss: 0.1596\n",
      "    Validation Batch [1/1], Loss: 0.1476\n",
      "Validation Loss: 0.1476, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [381/1000] - Training\n",
      "Epoch [381/1000] completed, Average Training Loss: 0.1538\n",
      "    Validation Batch [1/1], Loss: 0.1459\n",
      "Validation Loss: 0.1459, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [382/1000] - Training\n",
      "Epoch [382/1000] completed, Average Training Loss: 0.1590\n",
      "    Validation Batch [1/1], Loss: 0.1437\n",
      "Validation Loss: 0.1437, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [383/1000] - Training\n",
      "Epoch [383/1000] completed, Average Training Loss: 0.1602\n",
      "    Validation Batch [1/1], Loss: 0.1429\n",
      "Validation Loss: 0.1429, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1435 to 0.1429. Saving model...\n",
      "\n",
      "LOG: Epoch [384/1000] - Training\n",
      "Epoch [384/1000] completed, Average Training Loss: 0.1774\n",
      "    Validation Batch [1/1], Loss: 0.1439\n",
      "Validation Loss: 0.1439, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [385/1000] - Training\n",
      "Epoch [385/1000] completed, Average Training Loss: 0.1593\n",
      "    Validation Batch [1/1], Loss: 0.1526\n",
      "Validation Loss: 0.1526, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [386/1000] - Training\n",
      "Epoch [386/1000] completed, Average Training Loss: 0.1467\n",
      "    Validation Batch [1/1], Loss: 0.1466\n",
      "Validation Loss: 0.1466, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [387/1000] - Training\n",
      "Epoch [387/1000] completed, Average Training Loss: 0.1678\n",
      "    Validation Batch [1/1], Loss: 0.1309\n",
      "Validation Loss: 0.1309, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1429 to 0.1309. Saving model...\n",
      "\n",
      "LOG: Epoch [388/1000] - Training\n",
      "Epoch [388/1000] completed, Average Training Loss: 0.1570\n",
      "    Validation Batch [1/1], Loss: 0.1324\n",
      "Validation Loss: 0.1324, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [389/1000] - Training\n",
      "Epoch [389/1000] completed, Average Training Loss: 0.1601\n",
      "    Validation Batch [1/1], Loss: 0.1351\n",
      "Validation Loss: 0.1351, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [390/1000] - Training\n",
      "Epoch [390/1000] completed, Average Training Loss: 0.1672\n",
      "    Validation Batch [1/1], Loss: 0.1369\n",
      "Validation Loss: 0.1369, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [391/1000] - Training\n",
      "Epoch [391/1000] completed, Average Training Loss: 0.1358\n",
      "    Validation Batch [1/1], Loss: 0.1327\n",
      "Validation Loss: 0.1327, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [392/1000] - Training\n",
      "Epoch [392/1000] completed, Average Training Loss: 0.1624\n",
      "    Validation Batch [1/1], Loss: 0.1248\n",
      "Validation Loss: 0.1248, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1309 to 0.1248. Saving model...\n",
      "\n",
      "LOG: Epoch [393/1000] - Training\n",
      "Epoch [393/1000] completed, Average Training Loss: 0.1520\n",
      "    Validation Batch [1/1], Loss: 0.1224\n",
      "Validation Loss: 0.1224, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1248 to 0.1224. Saving model...\n",
      "\n",
      "LOG: Epoch [394/1000] - Training\n",
      "Epoch [394/1000] completed, Average Training Loss: 0.1569\n",
      "    Validation Batch [1/1], Loss: 0.1272\n",
      "Validation Loss: 0.1272, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [395/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [395/1000] completed, Average Training Loss: 0.1444\n",
      "    Validation Batch [1/1], Loss: 0.1329\n",
      "Validation Loss: 0.1329, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [396/1000] - Training\n",
      "Epoch [396/1000] completed, Average Training Loss: 0.1469\n",
      "    Validation Batch [1/1], Loss: 0.1316\n",
      "Validation Loss: 0.1316, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [397/1000] - Training\n",
      "Epoch [397/1000] completed, Average Training Loss: 0.1433\n",
      "    Validation Batch [1/1], Loss: 0.1306\n",
      "Validation Loss: 0.1306, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [398/1000] - Training\n",
      "Epoch [398/1000] completed, Average Training Loss: 0.1453\n",
      "    Validation Batch [1/1], Loss: 0.1290\n",
      "Validation Loss: 0.1290, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [399/1000] - Training\n",
      "Epoch [399/1000] completed, Average Training Loss: 0.1442\n",
      "    Validation Batch [1/1], Loss: 0.1228\n",
      "Validation Loss: 0.1228, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [400/1000] - Training\n",
      "Epoch [400/1000] completed, Average Training Loss: 0.1476\n",
      "    Validation Batch [1/1], Loss: 0.1231\n",
      "Validation Loss: 0.1231, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [401/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [401/1000] completed, Average Training Loss: 0.1622\n",
      "    Validation Batch [1/1], Loss: 0.1295\n",
      "Validation Loss: 0.1295, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [402/1000] - Training\n",
      "Epoch [402/1000] completed, Average Training Loss: 0.1337\n",
      "    Validation Batch [1/1], Loss: 0.1429\n",
      "Validation Loss: 0.1429, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [403/1000] - Training\n",
      "Epoch [403/1000] completed, Average Training Loss: 0.1403\n",
      "    Validation Batch [1/1], Loss: 0.1477\n",
      "Validation Loss: 0.1477, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [404/1000] - Training\n",
      "Epoch [404/1000] completed, Average Training Loss: 0.1431\n",
      "    Validation Batch [1/1], Loss: 0.1552\n",
      "Validation Loss: 0.1552, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [405/1000] - Training\n",
      "Epoch [405/1000] completed, Average Training Loss: 0.1387\n",
      "    Validation Batch [1/1], Loss: 0.1459\n",
      "Validation Loss: 0.1459, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [406/1000] - Training\n",
      "Epoch [406/1000] completed, Average Training Loss: 0.1426\n",
      "    Validation Batch [1/1], Loss: 0.1287\n",
      "Validation Loss: 0.1287, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [407/1000] - Training\n",
      "Epoch [407/1000] completed, Average Training Loss: 0.1442\n",
      "    Validation Batch [1/1], Loss: 0.1185\n",
      "Validation Loss: 0.1185, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1224 to 0.1185. Saving model...\n",
      "\n",
      "LOG: Epoch [408/1000] - Training\n",
      "Epoch [408/1000] completed, Average Training Loss: 0.1383\n",
      "    Validation Batch [1/1], Loss: 0.1234\n",
      "Validation Loss: 0.1234, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [409/1000] - Training\n",
      "Epoch [409/1000] completed, Average Training Loss: 0.1367\n",
      "    Validation Batch [1/1], Loss: 0.1217\n",
      "Validation Loss: 0.1217, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [410/1000] - Training\n",
      "Epoch [410/1000] completed, Average Training Loss: 0.1162\n",
      "    Validation Batch [1/1], Loss: 0.1129\n",
      "Validation Loss: 0.1129, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1185 to 0.1129. Saving model...\n",
      "\n",
      "LOG: Epoch [411/1000] - Training\n",
      "Epoch [411/1000] completed, Average Training Loss: 0.1229\n",
      "    Validation Batch [1/1], Loss: 0.1134\n",
      "Validation Loss: 0.1134, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [412/1000] - Training\n",
      "Epoch [412/1000] completed, Average Training Loss: 0.1464\n",
      "    Validation Batch [1/1], Loss: 0.1129\n",
      "Validation Loss: 0.1129, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1129 to 0.1129. Saving model...\n",
      "\n",
      "LOG: Epoch [413/1000] - Training\n",
      "Epoch [413/1000] completed, Average Training Loss: 0.1414\n",
      "    Validation Batch [1/1], Loss: 0.1091\n",
      "Validation Loss: 0.1091, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1129 to 0.1091. Saving model...\n",
      "\n",
      "LOG: Epoch [414/1000] - Training\n",
      "Epoch [414/1000] completed, Average Training Loss: 0.1288\n",
      "    Validation Batch [1/1], Loss: 0.1043\n",
      "Validation Loss: 0.1043, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1091 to 0.1043. Saving model...\n",
      "\n",
      "LOG: Epoch [415/1000] - Training\n",
      "Epoch [415/1000] completed, Average Training Loss: 0.1271\n",
      "    Validation Batch [1/1], Loss: 0.1074\n",
      "Validation Loss: 0.1074, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [416/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [416/1000] completed, Average Training Loss: 0.1144\n",
      "    Validation Batch [1/1], Loss: 0.1186\n",
      "Validation Loss: 0.1186, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [417/1000] - Training\n",
      "Epoch [417/1000] completed, Average Training Loss: 0.1374\n",
      "    Validation Batch [1/1], Loss: 0.1137\n",
      "Validation Loss: 0.1137, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [418/1000] - Training\n",
      "Epoch [418/1000] completed, Average Training Loss: 0.1228\n",
      "    Validation Batch [1/1], Loss: 0.1042\n",
      "Validation Loss: 0.1042, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1043 to 0.1042. Saving model...\n",
      "\n",
      "LOG: Epoch [419/1000] - Training\n",
      "Epoch [419/1000] completed, Average Training Loss: 0.1295\n",
      "    Validation Batch [1/1], Loss: 0.1050\n",
      "Validation Loss: 0.1050, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [420/1000] - Training\n",
      "Epoch [420/1000] completed, Average Training Loss: 0.1324\n",
      "    Validation Batch [1/1], Loss: 0.1070\n",
      "Validation Loss: 0.1070, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [421/1000] - Training\n",
      "Epoch [421/1000] completed, Average Training Loss: 0.1254\n",
      "    Validation Batch [1/1], Loss: 0.1053\n",
      "Validation Loss: 0.1053, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [422/1000] - Training\n",
      "Epoch [422/1000] completed, Average Training Loss: 0.1301\n",
      "    Validation Batch [1/1], Loss: 0.1182\n",
      "Validation Loss: 0.1182, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [423/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [423/1000] completed, Average Training Loss: 0.1235\n",
      "    Validation Batch [1/1], Loss: 0.1322\n",
      "Validation Loss: 0.1322, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [424/1000] - Training\n",
      "Epoch [424/1000] completed, Average Training Loss: 0.1370\n",
      "    Validation Batch [1/1], Loss: 0.1199\n",
      "Validation Loss: 0.1199, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [425/1000] - Training\n",
      "Epoch [425/1000] completed, Average Training Loss: 0.1201\n",
      "    Validation Batch [1/1], Loss: 0.1094\n",
      "Validation Loss: 0.1094, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [426/1000] - Training\n",
      "Epoch [426/1000] completed, Average Training Loss: 0.1340\n",
      "    Validation Batch [1/1], Loss: 0.1034\n",
      "Validation Loss: 0.1034, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1042 to 0.1034. Saving model...\n",
      "\n",
      "LOG: Epoch [427/1000] - Training\n",
      "Epoch [427/1000] completed, Average Training Loss: 0.1252\n",
      "    Validation Batch [1/1], Loss: 0.1018\n",
      "Validation Loss: 0.1018, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1034 to 0.1018. Saving model...\n",
      "\n",
      "LOG: Epoch [428/1000] - Training\n",
      "Epoch [428/1000] completed, Average Training Loss: 0.1120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1100\n",
      "Validation Loss: 0.1100, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [429/1000] - Training\n",
      "Epoch [429/1000] completed, Average Training Loss: 0.1132\n",
      "    Validation Batch [1/1], Loss: 0.1090\n",
      "Validation Loss: 0.1090, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [430/1000] - Training\n",
      "Epoch [430/1000] completed, Average Training Loss: 0.1141\n",
      "    Validation Batch [1/1], Loss: 0.1054\n",
      "Validation Loss: 0.1054, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [431/1000] - Training\n",
      "Epoch [431/1000] completed, Average Training Loss: 0.1127\n",
      "    Validation Batch [1/1], Loss: 0.1100\n",
      "Validation Loss: 0.1100, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [432/1000] - Training\n",
      "Epoch [432/1000] completed, Average Training Loss: 0.1086\n",
      "    Validation Batch [1/1], Loss: 0.1056\n",
      "Validation Loss: 0.1056, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [433/1000] - Training\n",
      "Epoch [433/1000] completed, Average Training Loss: 0.1095\n",
      "    Validation Batch [1/1], Loss: 0.0929\n",
      "Validation Loss: 0.0929, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.1018 to 0.0929. Saving model...\n",
      "\n",
      "LOG: Epoch [434/1000] - Training\n",
      "Epoch [434/1000] completed, Average Training Loss: 0.1095\n",
      "    Validation Batch [1/1], Loss: 0.0936\n",
      "Validation Loss: 0.0936, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [435/1000] - Training\n",
      "Epoch [435/1000] completed, Average Training Loss: 0.1221\n",
      "    Validation Batch [1/1], Loss: 0.1084\n",
      "Validation Loss: 0.1084, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [436/1000] - Training\n",
      "Epoch [436/1000] completed, Average Training Loss: 0.1152\n",
      "    Validation Batch [1/1], Loss: 0.1090\n",
      "Validation Loss: 0.1090, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [437/1000] - Training\n",
      "Epoch [437/1000] completed, Average Training Loss: 0.1148\n",
      "    Validation Batch [1/1], Loss: 0.0991\n",
      "Validation Loss: 0.0991, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [438/1000] - Training\n",
      "Epoch [438/1000] completed, Average Training Loss: 0.1159\n",
      "    Validation Batch [1/1], Loss: 0.0948\n",
      "Validation Loss: 0.0948, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [439/1000] - Training\n",
      "Epoch [439/1000] completed, Average Training Loss: 0.1190\n",
      "    Validation Batch [1/1], Loss: 0.0948\n",
      "Validation Loss: 0.0948, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [440/1000] - Training\n",
      "Epoch [440/1000] completed, Average Training Loss: 0.1092\n",
      "    Validation Batch [1/1], Loss: 0.0963\n",
      "Validation Loss: 0.0963, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [441/1000] - Training\n",
      "Epoch [441/1000] completed, Average Training Loss: 0.1089\n",
      "    Validation Batch [1/1], Loss: 0.1039\n",
      "Validation Loss: 0.1039, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [442/1000] - Training\n",
      "Epoch [442/1000] completed, Average Training Loss: 0.1061\n",
      "    Validation Batch [1/1], Loss: 0.1212\n",
      "Validation Loss: 0.1212, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [443/1000] - Training\n",
      "Epoch [443/1000] completed, Average Training Loss: 0.1095\n",
      "    Validation Batch [1/1], Loss: 0.1171\n",
      "Validation Loss: 0.1171, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [444/1000] - Training\n",
      "Epoch [444/1000] completed, Average Training Loss: 0.1091\n",
      "    Validation Batch [1/1], Loss: 0.1081\n",
      "Validation Loss: 0.1081, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [445/1000] - Training\n",
      "Epoch [445/1000] completed, Average Training Loss: 0.1199\n",
      "    Validation Batch [1/1], Loss: 0.1035\n",
      "Validation Loss: 0.1035, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [446/1000] - Training\n",
      "Epoch [446/1000] completed, Average Training Loss: 0.1110\n",
      "    Validation Batch [1/1], Loss: 0.1034\n",
      "Validation Loss: 0.1034, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [447/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [447/1000] completed, Average Training Loss: 0.1228\n",
      "    Validation Batch [1/1], Loss: 0.1080\n",
      "Validation Loss: 0.1080, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [448/1000] - Training\n",
      "Epoch [448/1000] completed, Average Training Loss: 0.1148\n",
      "    Validation Batch [1/1], Loss: 0.1166\n",
      "Validation Loss: 0.1166, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [449/1000] - Training\n",
      "Epoch [449/1000] completed, Average Training Loss: 0.1065\n",
      "    Validation Batch [1/1], Loss: 0.1168\n",
      "Validation Loss: 0.1168, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [450/1000] - Training\n",
      "Epoch [450/1000] completed, Average Training Loss: 0.1083\n",
      "    Validation Batch [1/1], Loss: 0.1060\n",
      "Validation Loss: 0.1060, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [451/1000] - Training\n",
      "Epoch [451/1000] completed, Average Training Loss: 0.1120\n",
      "    Validation Batch [1/1], Loss: 0.0981\n",
      "Validation Loss: 0.0981, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [452/1000] - Training\n",
      "Epoch [452/1000] completed, Average Training Loss: 0.1060\n",
      "    Validation Batch [1/1], Loss: 0.0901\n",
      "Validation Loss: 0.0901, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0929 to 0.0901. Saving model...\n",
      "\n",
      "LOG: Epoch [453/1000] - Training\n",
      "Epoch [453/1000] completed, Average Training Loss: 0.1059\n",
      "    Validation Batch [1/1], Loss: 0.0840\n",
      "Validation Loss: 0.0840, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0901 to 0.0840. Saving model...\n",
      "\n",
      "LOG: Epoch [454/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [454/1000] completed, Average Training Loss: 0.1067\n",
      "    Validation Batch [1/1], Loss: 0.0836\n",
      "Validation Loss: 0.0836, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0840 to 0.0836. Saving model...\n",
      "\n",
      "LOG: Epoch [455/1000] - Training\n",
      "Epoch [455/1000] completed, Average Training Loss: 0.1090\n",
      "    Validation Batch [1/1], Loss: 0.0872\n",
      "Validation Loss: 0.0872, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [456/1000] - Training\n",
      "Epoch [456/1000] completed, Average Training Loss: 0.0877\n",
      "    Validation Batch [1/1], Loss: 0.0926\n",
      "Validation Loss: 0.0926, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [457/1000] - Training\n",
      "Epoch [457/1000] completed, Average Training Loss: 0.0997\n",
      "    Validation Batch [1/1], Loss: 0.0930\n",
      "Validation Loss: 0.0930, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [458/1000] - Training\n",
      "Epoch [458/1000] completed, Average Training Loss: 0.0975\n",
      "    Validation Batch [1/1], Loss: 0.0996\n",
      "Validation Loss: 0.0996, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [459/1000] - Training\n",
      "Epoch [459/1000] completed, Average Training Loss: 0.0980\n",
      "    Validation Batch [1/1], Loss: 0.1060\n",
      "Validation Loss: 0.1060, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [460/1000] - Training\n",
      "Epoch [460/1000] completed, Average Training Loss: 0.1029\n",
      "    Validation Batch [1/1], Loss: 0.1008\n",
      "Validation Loss: 0.1008, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [461/1000] - Training\n",
      "Epoch [461/1000] completed, Average Training Loss: 0.1000\n",
      "    Validation Batch [1/1], Loss: 0.0902\n",
      "Validation Loss: 0.0902, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [462/1000] - Training\n",
      "Epoch [462/1000] completed, Average Training Loss: 0.0929\n",
      "    Validation Batch [1/1], Loss: 0.0841\n",
      "Validation Loss: 0.0841, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [463/1000] - Training\n",
      "Epoch [463/1000] completed, Average Training Loss: 0.1029\n",
      "    Validation Batch [1/1], Loss: 0.0814\n",
      "Validation Loss: 0.0814, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0836 to 0.0814. Saving model...\n",
      "\n",
      "LOG: Epoch [464/1000] - Training\n",
      "Epoch [464/1000] completed, Average Training Loss: 0.0945\n",
      "    Validation Batch [1/1], Loss: 0.0812\n",
      "Validation Loss: 0.0812, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0814 to 0.0812. Saving model...\n",
      "\n",
      "LOG: Epoch [465/1000] - Training\n",
      "Epoch [465/1000] completed, Average Training Loss: 0.1038\n",
      "    Validation Batch [1/1], Loss: 0.0833\n",
      "Validation Loss: 0.0833, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [466/1000] - Training\n",
      "Epoch [466/1000] completed, Average Training Loss: 0.1008\n",
      "    Validation Batch [1/1], Loss: 0.0822\n",
      "Validation Loss: 0.0822, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [467/1000] - Training\n",
      "Epoch [467/1000] completed, Average Training Loss: 0.1003\n",
      "    Validation Batch [1/1], Loss: 0.0829\n",
      "Validation Loss: 0.0829, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [468/1000] - Training\n",
      "Epoch [468/1000] completed, Average Training Loss: 0.0908\n",
      "    Validation Batch [1/1], Loss: 0.0859\n",
      "Validation Loss: 0.0859, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [469/1000] - Training\n",
      "Epoch [469/1000] completed, Average Training Loss: 0.0955\n",
      "    Validation Batch [1/1], Loss: 0.0882\n",
      "Validation Loss: 0.0882, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [470/1000] - Training\n",
      "Epoch [470/1000] completed, Average Training Loss: 0.0874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0910\n",
      "Validation Loss: 0.0910, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [471/1000] - Training\n",
      "Epoch [471/1000] completed, Average Training Loss: 0.1022\n",
      "    Validation Batch [1/1], Loss: 0.0894\n",
      "Validation Loss: 0.0894, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [472/1000] - Training\n",
      "Epoch [472/1000] completed, Average Training Loss: 0.0912\n",
      "    Validation Batch [1/1], Loss: 0.0872\n",
      "Validation Loss: 0.0872, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [473/1000] - Training\n",
      "Epoch [473/1000] completed, Average Training Loss: 0.0986\n",
      "    Validation Batch [1/1], Loss: 0.0827\n",
      "Validation Loss: 0.0827, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [474/1000] - Training\n",
      "Epoch [474/1000] completed, Average Training Loss: 0.0941\n",
      "    Validation Batch [1/1], Loss: 0.0802\n",
      "Validation Loss: 0.0802, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0812 to 0.0802. Saving model...\n",
      "\n",
      "LOG: Epoch [475/1000] - Training\n",
      "Epoch [475/1000] completed, Average Training Loss: 0.0819\n",
      "    Validation Batch [1/1], Loss: 0.0784\n",
      "Validation Loss: 0.0784, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0802 to 0.0784. Saving model...\n",
      "\n",
      "LOG: Epoch [476/1000] - Training\n",
      "Epoch [476/1000] completed, Average Training Loss: 0.0916\n",
      "    Validation Batch [1/1], Loss: 0.0783\n",
      "Validation Loss: 0.0783, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0784 to 0.0783. Saving model...\n",
      "\n",
      "LOG: Epoch [477/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [477/1000] completed, Average Training Loss: 0.1075\n",
      "    Validation Batch [1/1], Loss: 0.0786\n",
      "Validation Loss: 0.0786, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [478/1000] - Training\n",
      "Epoch [478/1000] completed, Average Training Loss: 0.0927\n",
      "    Validation Batch [1/1], Loss: 0.0825\n",
      "Validation Loss: 0.0825, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [479/1000] - Training\n",
      "Epoch [479/1000] completed, Average Training Loss: 0.0924\n",
      "    Validation Batch [1/1], Loss: 0.0856\n",
      "Validation Loss: 0.0856, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [480/1000] - Training\n",
      "Epoch [480/1000] completed, Average Training Loss: 0.0946\n",
      "    Validation Batch [1/1], Loss: 0.0857\n",
      "Validation Loss: 0.0857, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [481/1000] - Training\n",
      "Epoch [481/1000] completed, Average Training Loss: 0.1043\n",
      "    Validation Batch [1/1], Loss: 0.0833\n",
      "Validation Loss: 0.0833, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [482/1000] - Training\n",
      "Epoch [482/1000] completed, Average Training Loss: 0.1003\n",
      "    Validation Batch [1/1], Loss: 0.0827\n",
      "Validation Loss: 0.0827, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [483/1000] - Training\n",
      "Epoch [483/1000] completed, Average Training Loss: 0.0820\n",
      "    Validation Batch [1/1], Loss: 0.0863\n",
      "Validation Loss: 0.0863, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [484/1000] - Training\n",
      "Epoch [484/1000] completed, Average Training Loss: 0.0914\n",
      "    Validation Batch [1/1], Loss: 0.1021\n",
      "Validation Loss: 0.1021, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [485/1000] - Training\n",
      "Epoch [485/1000] completed, Average Training Loss: 0.0879\n",
      "    Validation Batch [1/1], Loss: 0.1153\n",
      "Validation Loss: 0.1153, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [486/1000] - Training\n",
      "Epoch [486/1000] completed, Average Training Loss: 0.0986\n",
      "    Validation Batch [1/1], Loss: 0.1145\n",
      "Validation Loss: 0.1145, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [487/1000] - Training\n",
      "Epoch [487/1000] completed, Average Training Loss: 0.0893\n",
      "    Validation Batch [1/1], Loss: 0.1057\n",
      "Validation Loss: 0.1057, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [488/1000] - Training\n",
      "Epoch [488/1000] completed, Average Training Loss: 0.0882\n",
      "    Validation Batch [1/1], Loss: 0.0939\n",
      "Validation Loss: 0.0939, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [489/1000] - Training\n",
      "Epoch [489/1000] completed, Average Training Loss: 0.0881\n",
      "    Validation Batch [1/1], Loss: 0.0808\n",
      "Validation Loss: 0.0808, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [490/1000] - Training\n",
      "Epoch [490/1000] completed, Average Training Loss: 0.0903\n",
      "    Validation Batch [1/1], Loss: 0.0723\n",
      "Validation Loss: 0.0723, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0783 to 0.0723. Saving model...\n",
      "\n",
      "LOG: Epoch [491/1000] - Training\n",
      "Epoch [491/1000] completed, Average Training Loss: 0.0899\n",
      "    Validation Batch [1/1], Loss: 0.0747\n",
      "Validation Loss: 0.0747, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [492/1000] - Training\n",
      "Epoch [492/1000] completed, Average Training Loss: 0.0804\n",
      "    Validation Batch [1/1], Loss: 0.0851\n",
      "Validation Loss: 0.0851, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [493/1000] - Training\n",
      "Epoch [493/1000] completed, Average Training Loss: 0.0809\n",
      "    Validation Batch [1/1], Loss: 0.0901\n",
      "Validation Loss: 0.0901, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [494/1000] - Training\n",
      "Epoch [494/1000] completed, Average Training Loss: 0.0865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0888\n",
      "Validation Loss: 0.0888, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [495/1000] - Training\n",
      "Epoch [495/1000] completed, Average Training Loss: 0.0851\n",
      "    Validation Batch [1/1], Loss: 0.0828\n",
      "Validation Loss: 0.0828, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [496/1000] - Training\n",
      "Epoch [496/1000] completed, Average Training Loss: 0.0807\n",
      "    Validation Batch [1/1], Loss: 0.0835\n",
      "Validation Loss: 0.0835, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [497/1000] - Training\n",
      "Epoch [497/1000] completed, Average Training Loss: 0.0796\n",
      "    Validation Batch [1/1], Loss: 0.0871\n",
      "Validation Loss: 0.0871, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [498/1000] - Training\n",
      "Epoch [498/1000] completed, Average Training Loss: 0.0801\n",
      "    Validation Batch [1/1], Loss: 0.0925\n",
      "Validation Loss: 0.0925, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [499/1000] - Training\n",
      "Epoch [499/1000] completed, Average Training Loss: 0.0759\n",
      "    Validation Batch [1/1], Loss: 0.0997\n",
      "Validation Loss: 0.0997, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [500/1000] - Training\n",
      "Epoch [500/1000] completed, Average Training Loss: 0.0783\n",
      "    Validation Batch [1/1], Loss: 0.1075\n",
      "Validation Loss: 0.1075, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [501/1000] - Training\n",
      "Epoch [501/1000] completed, Average Training Loss: 0.0923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0987\n",
      "Validation Loss: 0.0987, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [502/1000] - Training\n",
      "Epoch [502/1000] completed, Average Training Loss: 0.0840\n",
      "    Validation Batch [1/1], Loss: 0.0867\n",
      "Validation Loss: 0.0867, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [503/1000] - Training\n",
      "Epoch [503/1000] completed, Average Training Loss: 0.0822\n",
      "    Validation Batch [1/1], Loss: 0.0818\n",
      "Validation Loss: 0.0818, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [504/1000] - Training\n",
      "Epoch [504/1000] completed, Average Training Loss: 0.0826\n",
      "    Validation Batch [1/1], Loss: 0.0788\n",
      "Validation Loss: 0.0788, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [505/1000] - Training\n",
      "Epoch [505/1000] completed, Average Training Loss: 0.0717\n",
      "    Validation Batch [1/1], Loss: 0.0742\n",
      "Validation Loss: 0.0742, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [506/1000] - Training\n",
      "Epoch [506/1000] completed, Average Training Loss: 0.0814\n",
      "    Validation Batch [1/1], Loss: 0.0698\n",
      "Validation Loss: 0.0698, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0723 to 0.0698. Saving model...\n",
      "\n",
      "LOG: Epoch [507/1000] - Training\n",
      "Epoch [507/1000] completed, Average Training Loss: 0.0695\n",
      "    Validation Batch [1/1], Loss: 0.0700\n",
      "Validation Loss: 0.0700, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [508/1000] - Training\n",
      "Epoch [508/1000] completed, Average Training Loss: 0.0806\n",
      "    Validation Batch [1/1], Loss: 0.0703\n",
      "Validation Loss: 0.0703, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [509/1000] - Training\n",
      "Epoch [509/1000] completed, Average Training Loss: 0.0766\n",
      "    Validation Batch [1/1], Loss: 0.0660\n",
      "Validation Loss: 0.0660, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0698 to 0.0660. Saving model...\n",
      "\n",
      "LOG: Epoch [510/1000] - Training\n",
      "Epoch [510/1000] completed, Average Training Loss: 0.0688\n",
      "    Validation Batch [1/1], Loss: 0.0594\n",
      "Validation Loss: 0.0594, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0660 to 0.0594. Saving model...\n",
      "\n",
      "LOG: Epoch [511/1000] - Training\n",
      "Epoch [511/1000] completed, Average Training Loss: 0.0763\n",
      "    Validation Batch [1/1], Loss: 0.0603\n",
      "Validation Loss: 0.0603, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [512/1000] - Training\n",
      "Epoch [512/1000] completed, Average Training Loss: 0.0824\n",
      "    Validation Batch [1/1], Loss: 0.0675\n",
      "Validation Loss: 0.0675, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [513/1000] - Training\n",
      "Epoch [513/1000] completed, Average Training Loss: 0.0678\n",
      "    Validation Batch [1/1], Loss: 0.0740\n",
      "Validation Loss: 0.0740, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [514/1000] - Training\n",
      "Epoch [514/1000] completed, Average Training Loss: 0.0805\n",
      "    Validation Batch [1/1], Loss: 0.0803\n",
      "Validation Loss: 0.0803, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [515/1000] - Training\n",
      "Epoch [515/1000] completed, Average Training Loss: 0.0791\n",
      "    Validation Batch [1/1], Loss: 0.0829\n",
      "Validation Loss: 0.0829, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [516/1000] - Training\n",
      "Epoch [516/1000] completed, Average Training Loss: 0.0876\n",
      "    Validation Batch [1/1], Loss: 0.0764\n",
      "Validation Loss: 0.0764, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [517/1000] - Training\n",
      "Epoch [517/1000] completed, Average Training Loss: 0.0762\n",
      "    Validation Batch [1/1], Loss: 0.0681\n",
      "Validation Loss: 0.0681, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [518/1000] - Training\n",
      "Epoch [518/1000] completed, Average Training Loss: 0.0752\n",
      "    Validation Batch [1/1], Loss: 0.0637\n",
      "Validation Loss: 0.0637, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [519/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [519/1000] completed, Average Training Loss: 0.0714\n",
      "    Validation Batch [1/1], Loss: 0.0609\n",
      "Validation Loss: 0.0609, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [520/1000] - Training\n",
      "Epoch [520/1000] completed, Average Training Loss: 0.0749\n",
      "    Validation Batch [1/1], Loss: 0.0609\n",
      "Validation Loss: 0.0609, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [521/1000] - Training\n",
      "Epoch [521/1000] completed, Average Training Loss: 0.0782\n",
      "    Validation Batch [1/1], Loss: 0.0616\n",
      "Validation Loss: 0.0616, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [522/1000] - Training\n",
      "Epoch [522/1000] completed, Average Training Loss: 0.0694\n",
      "    Validation Batch [1/1], Loss: 0.0628\n",
      "Validation Loss: 0.0628, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [523/1000] - Training\n",
      "Epoch [523/1000] completed, Average Training Loss: 0.0666\n",
      "    Validation Batch [1/1], Loss: 0.0644\n",
      "Validation Loss: 0.0644, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [524/1000] - Training\n",
      "Epoch [524/1000] completed, Average Training Loss: 0.0735\n",
      "    Validation Batch [1/1], Loss: 0.0622\n",
      "Validation Loss: 0.0622, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [525/1000] - Training\n",
      "Epoch [525/1000] completed, Average Training Loss: 0.0754\n",
      "    Validation Batch [1/1], Loss: 0.0655\n",
      "Validation Loss: 0.0655, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [526/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [526/1000] completed, Average Training Loss: 0.0776\n",
      "    Validation Batch [1/1], Loss: 0.0712\n",
      "Validation Loss: 0.0712, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [527/1000] - Training\n",
      "Epoch [527/1000] completed, Average Training Loss: 0.0648\n",
      "    Validation Batch [1/1], Loss: 0.0694\n",
      "Validation Loss: 0.0694, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [528/1000] - Training\n",
      "Epoch [528/1000] completed, Average Training Loss: 0.0723\n",
      "    Validation Batch [1/1], Loss: 0.0629\n",
      "Validation Loss: 0.0629, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [529/1000] - Training\n",
      "Epoch [529/1000] completed, Average Training Loss: 0.0864\n",
      "    Validation Batch [1/1], Loss: 0.0614\n",
      "Validation Loss: 0.0614, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [530/1000] - Training\n",
      "Epoch [530/1000] completed, Average Training Loss: 0.0840\n",
      "    Validation Batch [1/1], Loss: 0.0651\n",
      "Validation Loss: 0.0651, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [531/1000] - Training\n",
      "Epoch [531/1000] completed, Average Training Loss: 0.0798\n",
      "    Validation Batch [1/1], Loss: 0.0621\n",
      "Validation Loss: 0.0621, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [532/1000] - Training\n",
      "Epoch [532/1000] completed, Average Training Loss: 0.0743\n",
      "    Validation Batch [1/1], Loss: 0.0568\n",
      "Validation Loss: 0.0568, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0594 to 0.0568. Saving model...\n",
      "\n",
      "LOG: Epoch [533/1000] - Training\n",
      "Epoch [533/1000] completed, Average Training Loss: 0.0726\n",
      "    Validation Batch [1/1], Loss: 0.0537\n",
      "Validation Loss: 0.0537, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0568 to 0.0537. Saving model...\n",
      "\n",
      "LOG: Epoch [534/1000] - Training\n",
      "Epoch [534/1000] completed, Average Training Loss: 0.0675\n",
      "    Validation Batch [1/1], Loss: 0.0519\n",
      "Validation Loss: 0.0519, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0537 to 0.0519. Saving model...\n",
      "\n",
      "LOG: Epoch [535/1000] - Training\n",
      "Epoch [535/1000] completed, Average Training Loss: 0.0685\n",
      "    Validation Batch [1/1], Loss: 0.0533\n",
      "Validation Loss: 0.0533, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [536/1000] - Training\n",
      "Epoch [536/1000] completed, Average Training Loss: 0.0668\n",
      "    Validation Batch [1/1], Loss: 0.0552\n",
      "Validation Loss: 0.0552, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [537/1000] - Training\n",
      "Epoch [537/1000] completed, Average Training Loss: 0.0784\n",
      "    Validation Batch [1/1], Loss: 0.0580\n",
      "Validation Loss: 0.0580, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [538/1000] - Training\n",
      "Epoch [538/1000] completed, Average Training Loss: 0.0709\n",
      "    Validation Batch [1/1], Loss: 0.0600\n",
      "Validation Loss: 0.0600, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [539/1000] - Training\n",
      "Epoch [539/1000] completed, Average Training Loss: 0.0725\n",
      "    Validation Batch [1/1], Loss: 0.0605\n",
      "Validation Loss: 0.0605, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [540/1000] - Training\n",
      "Epoch [540/1000] completed, Average Training Loss: 0.0616\n",
      "    Validation Batch [1/1], Loss: 0.0582\n",
      "Validation Loss: 0.0582, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [541/1000] - Training\n",
      "Epoch [541/1000] completed, Average Training Loss: 0.0704\n",
      "    Validation Batch [1/1], Loss: 0.0595\n",
      "Validation Loss: 0.0595, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [542/1000] - Training\n",
      "Epoch [542/1000] completed, Average Training Loss: 0.0613\n",
      "    Validation Batch [1/1], Loss: 0.0639\n",
      "Validation Loss: 0.0639, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [543/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [543/1000] completed, Average Training Loss: 0.0756\n",
      "    Validation Batch [1/1], Loss: 0.0645\n",
      "Validation Loss: 0.0645, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [544/1000] - Training\n",
      "Epoch [544/1000] completed, Average Training Loss: 0.0738\n",
      "    Validation Batch [1/1], Loss: 0.0615\n",
      "Validation Loss: 0.0615, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [545/1000] - Training\n",
      "Epoch [545/1000] completed, Average Training Loss: 0.0592\n",
      "    Validation Batch [1/1], Loss: 0.0562\n",
      "Validation Loss: 0.0562, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [546/1000] - Training\n",
      "Epoch [546/1000] completed, Average Training Loss: 0.0604\n",
      "    Validation Batch [1/1], Loss: 0.0541\n",
      "Validation Loss: 0.0541, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [547/1000] - Training\n",
      "Epoch [547/1000] completed, Average Training Loss: 0.0672\n",
      "    Validation Batch [1/1], Loss: 0.0541\n",
      "Validation Loss: 0.0541, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [548/1000] - Training\n",
      "Epoch [548/1000] completed, Average Training Loss: 0.0683\n",
      "    Validation Batch [1/1], Loss: 0.0549\n",
      "Validation Loss: 0.0549, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [549/1000] - Training\n",
      "Epoch [549/1000] completed, Average Training Loss: 0.0615\n",
      "    Validation Batch [1/1], Loss: 0.0569\n",
      "Validation Loss: 0.0569, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [550/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [550/1000] completed, Average Training Loss: 0.0676\n",
      "    Validation Batch [1/1], Loss: 0.0587\n",
      "Validation Loss: 0.0587, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [551/1000] - Training\n",
      "Epoch [551/1000] completed, Average Training Loss: 0.0662\n",
      "    Validation Batch [1/1], Loss: 0.0604\n",
      "Validation Loss: 0.0604, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [552/1000] - Training\n",
      "Epoch [552/1000] completed, Average Training Loss: 0.0628\n",
      "    Validation Batch [1/1], Loss: 0.0578\n",
      "Validation Loss: 0.0578, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [553/1000] - Training\n",
      "Epoch [553/1000] completed, Average Training Loss: 0.0551\n",
      "    Validation Batch [1/1], Loss: 0.0545\n",
      "Validation Loss: 0.0545, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [554/1000] - Training\n",
      "Epoch [554/1000] completed, Average Training Loss: 0.0703\n",
      "    Validation Batch [1/1], Loss: 0.0546\n",
      "Validation Loss: 0.0546, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [555/1000] - Training\n",
      "Epoch [555/1000] completed, Average Training Loss: 0.0672\n",
      "    Validation Batch [1/1], Loss: 0.0557\n",
      "Validation Loss: 0.0557, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [556/1000] - Training\n",
      "Epoch [556/1000] completed, Average Training Loss: 0.0711\n",
      "    Validation Batch [1/1], Loss: 0.0580\n",
      "Validation Loss: 0.0580, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [557/1000] - Training\n",
      "Epoch [557/1000] completed, Average Training Loss: 0.0650\n",
      "    Validation Batch [1/1], Loss: 0.0603\n",
      "Validation Loss: 0.0603, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [558/1000] - Training\n",
      "Epoch [558/1000] completed, Average Training Loss: 0.0655\n",
      "    Validation Batch [1/1], Loss: 0.0607\n",
      "Validation Loss: 0.0607, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [559/1000] - Training\n",
      "Epoch [559/1000] completed, Average Training Loss: 0.0703\n",
      "    Validation Batch [1/1], Loss: 0.0635\n",
      "Validation Loss: 0.0635, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [560/1000] - Training\n",
      "Epoch [560/1000] completed, Average Training Loss: 0.0728\n",
      "    Validation Batch [1/1], Loss: 0.0619\n",
      "Validation Loss: 0.0619, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [561/1000] - Training\n",
      "Epoch [561/1000] completed, Average Training Loss: 0.0685\n",
      "    Validation Batch [1/1], Loss: 0.0620\n",
      "Validation Loss: 0.0620, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [562/1000] - Training\n",
      "Epoch [562/1000] completed, Average Training Loss: 0.0647\n",
      "    Validation Batch [1/1], Loss: 0.0638\n",
      "Validation Loss: 0.0638, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [563/1000] - Training\n",
      "Epoch [563/1000] completed, Average Training Loss: 0.0657\n",
      "    Validation Batch [1/1], Loss: 0.0682\n",
      "Validation Loss: 0.0682, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [564/1000] - Training\n",
      "Epoch [564/1000] completed, Average Training Loss: 0.0667\n",
      "    Validation Batch [1/1], Loss: 0.0792\n",
      "Validation Loss: 0.0792, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [565/1000] - Training\n",
      "Epoch [565/1000] completed, Average Training Loss: 0.0551\n",
      "    Validation Batch [1/1], Loss: 0.0859\n",
      "Validation Loss: 0.0859, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [566/1000] - Training\n",
      "Epoch [566/1000] completed, Average Training Loss: 0.0636\n",
      "    Validation Batch [1/1], Loss: 0.0820\n",
      "Validation Loss: 0.0820, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [567/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [567/1000] completed, Average Training Loss: 0.0649\n",
      "    Validation Batch [1/1], Loss: 0.0648\n",
      "Validation Loss: 0.0648, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [568/1000] - Training\n",
      "Epoch [568/1000] completed, Average Training Loss: 0.0716\n",
      "    Validation Batch [1/1], Loss: 0.0551\n",
      "Validation Loss: 0.0551, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [569/1000] - Training\n",
      "Epoch [569/1000] completed, Average Training Loss: 0.0635\n",
      "    Validation Batch [1/1], Loss: 0.0525\n",
      "Validation Loss: 0.0525, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [570/1000] - Training\n",
      "Epoch [570/1000] completed, Average Training Loss: 0.0613\n",
      "    Validation Batch [1/1], Loss: 0.0535\n",
      "Validation Loss: 0.0535, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [571/1000] - Training\n",
      "Epoch [571/1000] completed, Average Training Loss: 0.0652\n",
      "    Validation Batch [1/1], Loss: 0.0559\n",
      "Validation Loss: 0.0559, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [572/1000] - Training\n",
      "Epoch [572/1000] completed, Average Training Loss: 0.0659\n",
      "    Validation Batch [1/1], Loss: 0.0569\n",
      "Validation Loss: 0.0569, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [573/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [573/1000] completed, Average Training Loss: 0.0747\n",
      "    Validation Batch [1/1], Loss: 0.0525\n",
      "Validation Loss: 0.0525, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [574/1000] - Training\n",
      "Epoch [574/1000] completed, Average Training Loss: 0.0614\n",
      "    Validation Batch [1/1], Loss: 0.0486\n",
      "Validation Loss: 0.0486, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0519 to 0.0486. Saving model...\n",
      "\n",
      "LOG: Epoch [575/1000] - Training\n",
      "Epoch [575/1000] completed, Average Training Loss: 0.0612\n",
      "    Validation Batch [1/1], Loss: 0.0473\n",
      "Validation Loss: 0.0473, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0486 to 0.0473. Saving model...\n",
      "\n",
      "LOG: Epoch [576/1000] - Training\n",
      "Epoch [576/1000] completed, Average Training Loss: 0.0478\n",
      "    Validation Batch [1/1], Loss: 0.0484\n",
      "Validation Loss: 0.0484, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [577/1000] - Training\n",
      "Epoch [577/1000] completed, Average Training Loss: 0.0455\n",
      "    Validation Batch [1/1], Loss: 0.0504\n",
      "Validation Loss: 0.0504, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [578/1000] - Training\n",
      "Epoch [578/1000] completed, Average Training Loss: 0.0503\n",
      "    Validation Batch [1/1], Loss: 0.0534\n",
      "Validation Loss: 0.0534, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [579/1000] - Training\n",
      "Epoch [579/1000] completed, Average Training Loss: 0.0629\n",
      "    Validation Batch [1/1], Loss: 0.0555\n",
      "Validation Loss: 0.0555, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [580/1000] - Training\n",
      "Epoch [580/1000] completed, Average Training Loss: 0.0626\n",
      "    Validation Batch [1/1], Loss: 0.0681\n",
      "Validation Loss: 0.0681, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [581/1000] - Training\n",
      "Epoch [581/1000] completed, Average Training Loss: 0.0573\n",
      "    Validation Batch [1/1], Loss: 0.0807\n",
      "Validation Loss: 0.0807, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [582/1000] - Training\n",
      "Epoch [582/1000] completed, Average Training Loss: 0.0665\n",
      "    Validation Batch [1/1], Loss: 0.0786\n",
      "Validation Loss: 0.0786, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [583/1000] - Training\n",
      "Epoch [583/1000] completed, Average Training Loss: 0.0605\n",
      "    Validation Batch [1/1], Loss: 0.0662\n",
      "Validation Loss: 0.0662, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [584/1000] - Training\n",
      "Epoch [584/1000] completed, Average Training Loss: 0.0572\n",
      "    Validation Batch [1/1], Loss: 0.0498\n",
      "Validation Loss: 0.0498, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [585/1000] - Training\n",
      "Epoch [585/1000] completed, Average Training Loss: 0.0607\n",
      "    Validation Batch [1/1], Loss: 0.0471\n",
      "Validation Loss: 0.0471, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0473 to 0.0471. Saving model...\n",
      "\n",
      "LOG: Epoch [586/1000] - Training\n",
      "Epoch [586/1000] completed, Average Training Loss: 0.0607\n",
      "    Validation Batch [1/1], Loss: 0.0512\n",
      "Validation Loss: 0.0512, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [587/1000] - Training\n",
      "Epoch [587/1000] completed, Average Training Loss: 0.0617\n",
      "    Validation Batch [1/1], Loss: 0.0564\n",
      "Validation Loss: 0.0564, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [588/1000] - Training\n",
      "Epoch [588/1000] completed, Average Training Loss: 0.0600\n",
      "    Validation Batch [1/1], Loss: 0.0639\n",
      "Validation Loss: 0.0639, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [589/1000] - Training\n",
      "Epoch [589/1000] completed, Average Training Loss: 0.0574\n",
      "    Validation Batch [1/1], Loss: 0.0720\n",
      "Validation Loss: 0.0720, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [590/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [590/1000] completed, Average Training Loss: 0.0501\n",
      "    Validation Batch [1/1], Loss: 0.0775\n",
      "Validation Loss: 0.0775, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [591/1000] - Training\n",
      "Epoch [591/1000] completed, Average Training Loss: 0.0473\n",
      "    Validation Batch [1/1], Loss: 0.0793\n",
      "Validation Loss: 0.0793, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [592/1000] - Training\n",
      "Epoch [592/1000] completed, Average Training Loss: 0.0513\n",
      "    Validation Batch [1/1], Loss: 0.0761\n",
      "Validation Loss: 0.0761, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [593/1000] - Training\n",
      "Epoch [593/1000] completed, Average Training Loss: 0.0687\n",
      "    Validation Batch [1/1], Loss: 0.0560\n",
      "Validation Loss: 0.0560, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [594/1000] - Training\n",
      "Epoch [594/1000] completed, Average Training Loss: 0.0614\n",
      "    Validation Batch [1/1], Loss: 0.0454\n",
      "Validation Loss: 0.0454, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0471 to 0.0454. Saving model...\n",
      "\n",
      "LOG: Epoch [595/1000] - Training\n",
      "Epoch [595/1000] completed, Average Training Loss: 0.0505\n",
      "    Validation Batch [1/1], Loss: 0.0406\n",
      "Validation Loss: 0.0406, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0454 to 0.0406. Saving model...\n",
      "\n",
      "LOG: Epoch [596/1000] - Training\n",
      "Epoch [596/1000] completed, Average Training Loss: 0.0608\n",
      "    Validation Batch [1/1], Loss: 0.0386\n",
      "Validation Loss: 0.0386, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0406 to 0.0386. Saving model...\n",
      "\n",
      "LOG: Epoch [597/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [597/1000] completed, Average Training Loss: 0.0615\n",
      "    Validation Batch [1/1], Loss: 0.0381\n",
      "Validation Loss: 0.0381, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0386 to 0.0381. Saving model...\n",
      "\n",
      "LOG: Epoch [598/1000] - Training\n",
      "Epoch [598/1000] completed, Average Training Loss: 0.0546\n",
      "    Validation Batch [1/1], Loss: 0.0387\n",
      "Validation Loss: 0.0387, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [599/1000] - Training\n",
      "Epoch [599/1000] completed, Average Training Loss: 0.0510\n",
      "    Validation Batch [1/1], Loss: 0.0403\n",
      "Validation Loss: 0.0403, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [600/1000] - Training\n",
      "Epoch [600/1000] completed, Average Training Loss: 0.0578\n",
      "    Validation Batch [1/1], Loss: 0.0434\n",
      "Validation Loss: 0.0434, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [601/1000] - Training\n",
      "Epoch [601/1000] completed, Average Training Loss: 0.0560\n",
      "    Validation Batch [1/1], Loss: 0.0485\n",
      "Validation Loss: 0.0485, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [602/1000] - Training\n",
      "Epoch [602/1000] completed, Average Training Loss: 0.0474\n",
      "    Validation Batch [1/1], Loss: 0.0484\n",
      "Validation Loss: 0.0484, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [603/1000] - Training\n",
      "Epoch [603/1000] completed, Average Training Loss: 0.0589\n",
      "    Validation Batch [1/1], Loss: 0.0496\n",
      "Validation Loss: 0.0496, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [604/1000] - Training\n",
      "Epoch [604/1000] completed, Average Training Loss: 0.0517\n",
      "    Validation Batch [1/1], Loss: 0.0555\n",
      "Validation Loss: 0.0555, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [605/1000] - Training\n",
      "Epoch [605/1000] completed, Average Training Loss: 0.0549\n",
      "    Validation Batch [1/1], Loss: 0.0599\n",
      "Validation Loss: 0.0599, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [606/1000] - Training\n",
      "Epoch [606/1000] completed, Average Training Loss: 0.0517\n",
      "    Validation Batch [1/1], Loss: 0.0622\n",
      "Validation Loss: 0.0622, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [607/1000] - Training\n",
      "Epoch [607/1000] completed, Average Training Loss: 0.0489\n",
      "    Validation Batch [1/1], Loss: 0.0581\n",
      "Validation Loss: 0.0581, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [608/1000] - Training\n",
      "Epoch [608/1000] completed, Average Training Loss: 0.0495\n",
      "    Validation Batch [1/1], Loss: 0.0595\n",
      "Validation Loss: 0.0595, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [609/1000] - Training\n",
      "Epoch [609/1000] completed, Average Training Loss: 0.0478\n",
      "    Validation Batch [1/1], Loss: 0.0623\n",
      "Validation Loss: 0.0623, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [610/1000] - Training\n",
      "Epoch [610/1000] completed, Average Training Loss: 0.0638\n",
      "    Validation Batch [1/1], Loss: 0.0709\n",
      "Validation Loss: 0.0709, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [611/1000] - Training\n",
      "Epoch [611/1000] completed, Average Training Loss: 0.0568\n",
      "    Validation Batch [1/1], Loss: 0.0766\n",
      "Validation Loss: 0.0766, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [612/1000] - Training\n",
      "Epoch [612/1000] completed, Average Training Loss: 0.0567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0708\n",
      "Validation Loss: 0.0708, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [613/1000] - Training\n",
      "Epoch [613/1000] completed, Average Training Loss: 0.0478\n",
      "    Validation Batch [1/1], Loss: 0.0621\n",
      "Validation Loss: 0.0621, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [614/1000] - Training\n",
      "Epoch [614/1000] completed, Average Training Loss: 0.0439\n",
      "    Validation Batch [1/1], Loss: 0.0538\n",
      "Validation Loss: 0.0538, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [615/1000] - Training\n",
      "Epoch [615/1000] completed, Average Training Loss: 0.0656\n",
      "    Validation Batch [1/1], Loss: 0.0470\n",
      "Validation Loss: 0.0470, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [616/1000] - Training\n",
      "Epoch [616/1000] completed, Average Training Loss: 0.0450\n",
      "    Validation Batch [1/1], Loss: 0.0406\n",
      "Validation Loss: 0.0406, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [617/1000] - Training\n",
      "Epoch [617/1000] completed, Average Training Loss: 0.0502\n",
      "    Validation Batch [1/1], Loss: 0.0380\n",
      "Validation Loss: 0.0380, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0381 to 0.0380. Saving model...\n",
      "\n",
      "LOG: Epoch [618/1000] - Training\n",
      "Epoch [618/1000] completed, Average Training Loss: 0.0457\n",
      "    Validation Batch [1/1], Loss: 0.0379\n",
      "Validation Loss: 0.0379, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0380 to 0.0379. Saving model...\n",
      "\n",
      "LOG: Epoch [619/1000] - Training\n",
      "Epoch [619/1000] completed, Average Training Loss: 0.0511\n",
      "    Validation Batch [1/1], Loss: 0.0380\n",
      "Validation Loss: 0.0380, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [620/1000] - Training\n",
      "Epoch [620/1000] completed, Average Training Loss: 0.0551\n",
      "    Validation Batch [1/1], Loss: 0.0376\n",
      "Validation Loss: 0.0376, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0379 to 0.0376. Saving model...\n",
      "\n",
      "LOG: Epoch [621/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [621/1000] completed, Average Training Loss: 0.0533\n",
      "    Validation Batch [1/1], Loss: 0.0391\n",
      "Validation Loss: 0.0391, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [622/1000] - Training\n",
      "Epoch [622/1000] completed, Average Training Loss: 0.0452\n",
      "    Validation Batch [1/1], Loss: 0.0412\n",
      "Validation Loss: 0.0412, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [623/1000] - Training\n",
      "Epoch [623/1000] completed, Average Training Loss: 0.0581\n",
      "    Validation Batch [1/1], Loss: 0.0417\n",
      "Validation Loss: 0.0417, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [624/1000] - Training\n",
      "Epoch [624/1000] completed, Average Training Loss: 0.0477\n",
      "    Validation Batch [1/1], Loss: 0.0437\n",
      "Validation Loss: 0.0437, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [625/1000] - Training\n",
      "Epoch [625/1000] completed, Average Training Loss: 0.0492\n",
      "    Validation Batch [1/1], Loss: 0.0470\n",
      "Validation Loss: 0.0470, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [626/1000] - Training\n",
      "Epoch [626/1000] completed, Average Training Loss: 0.0516\n",
      "    Validation Batch [1/1], Loss: 0.0439\n",
      "Validation Loss: 0.0439, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [627/1000] - Training\n",
      "Epoch [627/1000] completed, Average Training Loss: 0.0454\n",
      "    Validation Batch [1/1], Loss: 0.0483\n",
      "Validation Loss: 0.0483, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [628/1000] - Training\n",
      "Epoch [628/1000] completed, Average Training Loss: 0.0537\n",
      "    Validation Batch [1/1], Loss: 0.0513\n",
      "Validation Loss: 0.0513, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [629/1000] - Training\n",
      "Epoch [629/1000] completed, Average Training Loss: 0.0519\n",
      "    Validation Batch [1/1], Loss: 0.0543\n",
      "Validation Loss: 0.0543, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [630/1000] - Training\n",
      "Epoch [630/1000] completed, Average Training Loss: 0.0381\n",
      "    Validation Batch [1/1], Loss: 0.0541\n",
      "Validation Loss: 0.0541, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [631/1000] - Training\n",
      "Epoch [631/1000] completed, Average Training Loss: 0.0521\n",
      "    Validation Batch [1/1], Loss: 0.0500\n",
      "Validation Loss: 0.0500, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [632/1000] - Training\n",
      "Epoch [632/1000] completed, Average Training Loss: 0.0460\n",
      "    Validation Batch [1/1], Loss: 0.0489\n",
      "Validation Loss: 0.0489, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [633/1000] - Training\n",
      "Epoch [633/1000] completed, Average Training Loss: 0.0505\n",
      "    Validation Batch [1/1], Loss: 0.0501\n",
      "Validation Loss: 0.0501, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [634/1000] - Training\n",
      "Epoch [634/1000] completed, Average Training Loss: 0.0497\n",
      "    Validation Batch [1/1], Loss: 0.0535\n",
      "Validation Loss: 0.0535, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [635/1000] - Training\n",
      "Epoch [635/1000] completed, Average Training Loss: 0.0446\n",
      "    Validation Batch [1/1], Loss: 0.0536\n",
      "Validation Loss: 0.0536, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [636/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [636/1000] completed, Average Training Loss: 0.0421\n",
      "    Validation Batch [1/1], Loss: 0.0501\n",
      "Validation Loss: 0.0501, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [637/1000] - Training\n",
      "Epoch [637/1000] completed, Average Training Loss: 0.0457\n",
      "    Validation Batch [1/1], Loss: 0.0436\n",
      "Validation Loss: 0.0436, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [638/1000] - Training\n",
      "Epoch [638/1000] completed, Average Training Loss: 0.0369\n",
      "    Validation Batch [1/1], Loss: 0.0440\n",
      "Validation Loss: 0.0440, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [639/1000] - Training\n",
      "Epoch [639/1000] completed, Average Training Loss: 0.0453\n",
      "    Validation Batch [1/1], Loss: 0.0453\n",
      "Validation Loss: 0.0453, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [640/1000] - Training\n",
      "Epoch [640/1000] completed, Average Training Loss: 0.0476\n",
      "    Validation Batch [1/1], Loss: 0.0417\n",
      "Validation Loss: 0.0417, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [641/1000] - Training\n",
      "Epoch [641/1000] completed, Average Training Loss: 0.0467\n",
      "    Validation Batch [1/1], Loss: 0.0376\n",
      "Validation Loss: 0.0376, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0376 to 0.0376. Saving model...\n",
      "\n",
      "LOG: Epoch [642/1000] - Training\n",
      "Epoch [642/1000] completed, Average Training Loss: 0.0488\n",
      "    Validation Batch [1/1], Loss: 0.0379\n",
      "Validation Loss: 0.0379, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [643/1000] - Training\n",
      "Epoch [643/1000] completed, Average Training Loss: 0.0445\n",
      "    Validation Batch [1/1], Loss: 0.0404\n",
      "Validation Loss: 0.0404, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [644/1000] - Training\n",
      "Epoch [644/1000] completed, Average Training Loss: 0.0431\n",
      "    Validation Batch [1/1], Loss: 0.0418\n",
      "Validation Loss: 0.0418, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [645/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [645/1000] completed, Average Training Loss: 0.0512\n",
      "    Validation Batch [1/1], Loss: 0.0388\n",
      "Validation Loss: 0.0388, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [646/1000] - Training\n",
      "Epoch [646/1000] completed, Average Training Loss: 0.0558\n",
      "    Validation Batch [1/1], Loss: 0.0406\n",
      "Validation Loss: 0.0406, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [647/1000] - Training\n",
      "Epoch [647/1000] completed, Average Training Loss: 0.0423\n",
      "    Validation Batch [1/1], Loss: 0.0430\n",
      "Validation Loss: 0.0430, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [648/1000] - Training\n",
      "Epoch [648/1000] completed, Average Training Loss: 0.0474\n",
      "    Validation Batch [1/1], Loss: 0.0438\n",
      "Validation Loss: 0.0438, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [649/1000] - Training\n",
      "Epoch [649/1000] completed, Average Training Loss: 0.0491\n",
      "    Validation Batch [1/1], Loss: 0.0458\n",
      "Validation Loss: 0.0458, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [650/1000] - Training\n",
      "Epoch [650/1000] completed, Average Training Loss: 0.0422\n",
      "    Validation Batch [1/1], Loss: 0.0640\n",
      "Validation Loss: 0.0640, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [651/1000] - Training\n",
      "Epoch [651/1000] completed, Average Training Loss: 0.0439\n",
      "    Validation Batch [1/1], Loss: 0.0669\n",
      "Validation Loss: 0.0669, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [652/1000] - Training\n",
      "Epoch [652/1000] completed, Average Training Loss: 0.0512\n",
      "    Validation Batch [1/1], Loss: 0.0602\n",
      "Validation Loss: 0.0602, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [653/1000] - Training\n",
      "Epoch [653/1000] completed, Average Training Loss: 0.0449\n",
      "    Validation Batch [1/1], Loss: 0.0496\n",
      "Validation Loss: 0.0496, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [654/1000] - Training\n",
      "Epoch [654/1000] completed, Average Training Loss: 0.0548\n",
      "    Validation Batch [1/1], Loss: 0.0415\n",
      "Validation Loss: 0.0415, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [655/1000] - Training\n",
      "Epoch [655/1000] completed, Average Training Loss: 0.0494\n",
      "    Validation Batch [1/1], Loss: 0.0378\n",
      "Validation Loss: 0.0378, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [656/1000] - Training\n",
      "Epoch [656/1000] completed, Average Training Loss: 0.0435\n",
      "    Validation Batch [1/1], Loss: 0.0353\n",
      "Validation Loss: 0.0353, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0376 to 0.0353. Saving model...\n",
      "\n",
      "LOG: Epoch [657/1000] - Training\n",
      "Epoch [657/1000] completed, Average Training Loss: 0.0441\n",
      "    Validation Batch [1/1], Loss: 0.0365\n",
      "Validation Loss: 0.0365, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [658/1000] - Training\n",
      "Epoch [658/1000] completed, Average Training Loss: 0.0376\n",
      "    Validation Batch [1/1], Loss: 0.0388\n",
      "Validation Loss: 0.0388, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [659/1000] - Training\n",
      "Epoch [659/1000] completed, Average Training Loss: 0.0450\n",
      "    Validation Batch [1/1], Loss: 0.0401\n",
      "Validation Loss: 0.0401, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [660/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [660/1000] completed, Average Training Loss: 0.0429\n",
      "    Validation Batch [1/1], Loss: 0.0428\n",
      "Validation Loss: 0.0428, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [661/1000] - Training\n",
      "Epoch [661/1000] completed, Average Training Loss: 0.0431\n",
      "    Validation Batch [1/1], Loss: 0.0478\n",
      "Validation Loss: 0.0478, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [662/1000] - Training\n",
      "Epoch [662/1000] completed, Average Training Loss: 0.0557\n",
      "    Validation Batch [1/1], Loss: 0.0510\n",
      "Validation Loss: 0.0510, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [663/1000] - Training\n",
      "Epoch [663/1000] completed, Average Training Loss: 0.0436\n",
      "    Validation Batch [1/1], Loss: 0.0477\n",
      "Validation Loss: 0.0477, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [664/1000] - Training\n",
      "Epoch [664/1000] completed, Average Training Loss: 0.0358\n",
      "    Validation Batch [1/1], Loss: 0.0430\n",
      "Validation Loss: 0.0430, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [665/1000] - Training\n",
      "Epoch [665/1000] completed, Average Training Loss: 0.0372\n",
      "    Validation Batch [1/1], Loss: 0.0406\n",
      "Validation Loss: 0.0406, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [666/1000] - Training\n",
      "Epoch [666/1000] completed, Average Training Loss: 0.0414\n",
      "    Validation Batch [1/1], Loss: 0.0377\n",
      "Validation Loss: 0.0377, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [667/1000] - Training\n",
      "Epoch [667/1000] completed, Average Training Loss: 0.0364\n",
      "    Validation Batch [1/1], Loss: 0.0361\n",
      "Validation Loss: 0.0361, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [668/1000] - Training\n",
      "Epoch [668/1000] completed, Average Training Loss: 0.0545\n",
      "    Validation Batch [1/1], Loss: 0.0356\n",
      "Validation Loss: 0.0356, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [669/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [669/1000] completed, Average Training Loss: 0.0382\n",
      "    Validation Batch [1/1], Loss: 0.0342\n",
      "Validation Loss: 0.0342, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0353 to 0.0342. Saving model...\n",
      "\n",
      "LOG: Epoch [670/1000] - Training\n",
      "Epoch [670/1000] completed, Average Training Loss: 0.0400\n",
      "    Validation Batch [1/1], Loss: 0.0352\n",
      "Validation Loss: 0.0352, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [671/1000] - Training\n",
      "Epoch [671/1000] completed, Average Training Loss: 0.0407\n",
      "    Validation Batch [1/1], Loss: 0.0354\n",
      "Validation Loss: 0.0354, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [672/1000] - Training\n",
      "Epoch [672/1000] completed, Average Training Loss: 0.0576\n",
      "    Validation Batch [1/1], Loss: 0.0355\n",
      "Validation Loss: 0.0355, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [673/1000] - Training\n",
      "Epoch [673/1000] completed, Average Training Loss: 0.0375\n",
      "    Validation Batch [1/1], Loss: 0.0348\n",
      "Validation Loss: 0.0348, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [674/1000] - Training\n",
      "Epoch [674/1000] completed, Average Training Loss: 0.0385\n",
      "    Validation Batch [1/1], Loss: 0.0346\n",
      "Validation Loss: 0.0346, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [675/1000] - Training\n",
      "Epoch [675/1000] completed, Average Training Loss: 0.0383\n",
      "    Validation Batch [1/1], Loss: 0.0352\n",
      "Validation Loss: 0.0352, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [676/1000] - Training\n",
      "Epoch [676/1000] completed, Average Training Loss: 0.0457\n",
      "    Validation Batch [1/1], Loss: 0.0365\n",
      "Validation Loss: 0.0365, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [677/1000] - Training\n",
      "Epoch [677/1000] completed, Average Training Loss: 0.0417\n",
      "    Validation Batch [1/1], Loss: 0.0382\n",
      "Validation Loss: 0.0382, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [678/1000] - Training\n",
      "Epoch [678/1000] completed, Average Training Loss: 0.0436\n",
      "    Validation Batch [1/1], Loss: 0.0394\n",
      "Validation Loss: 0.0394, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [679/1000] - Training\n",
      "Epoch [679/1000] completed, Average Training Loss: 0.0426\n",
      "    Validation Batch [1/1], Loss: 0.0399\n",
      "Validation Loss: 0.0399, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [680/1000] - Training\n",
      "Epoch [680/1000] completed, Average Training Loss: 0.0420\n",
      "    Validation Batch [1/1], Loss: 0.0407\n",
      "Validation Loss: 0.0407, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [681/1000] - Training\n",
      "Epoch [681/1000] completed, Average Training Loss: 0.0476\n",
      "    Validation Batch [1/1], Loss: 0.0371\n",
      "Validation Loss: 0.0371, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [682/1000] - Training\n",
      "Epoch [682/1000] completed, Average Training Loss: 0.0358\n",
      "    Validation Batch [1/1], Loss: 0.0346\n",
      "Validation Loss: 0.0346, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [683/1000] - Training\n",
      "Epoch [683/1000] completed, Average Training Loss: 0.0400\n",
      "    Validation Batch [1/1], Loss: 0.0322\n",
      "Validation Loss: 0.0322, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0342 to 0.0322. Saving model...\n",
      "\n",
      "LOG: Epoch [684/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [684/1000] completed, Average Training Loss: 0.0499\n",
      "    Validation Batch [1/1], Loss: 0.0327\n",
      "Validation Loss: 0.0327, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [685/1000] - Training\n",
      "Epoch [685/1000] completed, Average Training Loss: 0.0362\n",
      "    Validation Batch [1/1], Loss: 0.0356\n",
      "Validation Loss: 0.0356, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [686/1000] - Training\n",
      "Epoch [686/1000] completed, Average Training Loss: 0.0380\n",
      "    Validation Batch [1/1], Loss: 0.0364\n",
      "Validation Loss: 0.0364, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [687/1000] - Training\n",
      "Epoch [687/1000] completed, Average Training Loss: 0.0412\n",
      "    Validation Batch [1/1], Loss: 0.0345\n",
      "Validation Loss: 0.0345, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [688/1000] - Training\n",
      "Epoch [688/1000] completed, Average Training Loss: 0.0474\n",
      "    Validation Batch [1/1], Loss: 0.0339\n",
      "Validation Loss: 0.0339, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [689/1000] - Training\n",
      "Epoch [689/1000] completed, Average Training Loss: 0.0447\n",
      "    Validation Batch [1/1], Loss: 0.0376\n",
      "Validation Loss: 0.0376, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [690/1000] - Training\n",
      "Epoch [690/1000] completed, Average Training Loss: 0.0404\n",
      "    Validation Batch [1/1], Loss: 0.0440\n",
      "Validation Loss: 0.0440, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [691/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [691/1000] completed, Average Training Loss: 0.0408\n",
      "    Validation Batch [1/1], Loss: 0.0499\n",
      "Validation Loss: 0.0499, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [692/1000] - Training\n",
      "Epoch [692/1000] completed, Average Training Loss: 0.0417\n",
      "    Validation Batch [1/1], Loss: 0.0495\n",
      "Validation Loss: 0.0495, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [693/1000] - Training\n",
      "Epoch [693/1000] completed, Average Training Loss: 0.0438\n",
      "    Validation Batch [1/1], Loss: 0.0524\n",
      "Validation Loss: 0.0524, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [694/1000] - Training\n",
      "Epoch [694/1000] completed, Average Training Loss: 0.0437\n",
      "    Validation Batch [1/1], Loss: 0.0506\n",
      "Validation Loss: 0.0506, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [695/1000] - Training\n",
      "Epoch [695/1000] completed, Average Training Loss: 0.0361\n",
      "    Validation Batch [1/1], Loss: 0.0435\n",
      "Validation Loss: 0.0435, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [696/1000] - Training\n",
      "Epoch [696/1000] completed, Average Training Loss: 0.0361\n",
      "    Validation Batch [1/1], Loss: 0.0367\n",
      "Validation Loss: 0.0367, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [697/1000] - Training\n",
      "Epoch [697/1000] completed, Average Training Loss: 0.0351\n",
      "    Validation Batch [1/1], Loss: 0.0361\n",
      "Validation Loss: 0.0361, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [698/1000] - Training\n",
      "Epoch [698/1000] completed, Average Training Loss: 0.0333\n",
      "    Validation Batch [1/1], Loss: 0.0421\n",
      "Validation Loss: 0.0421, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [699/1000] - Training\n",
      "Epoch [699/1000] completed, Average Training Loss: 0.0375\n",
      "    Validation Batch [1/1], Loss: 0.0464\n",
      "Validation Loss: 0.0464, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [700/1000] - Training\n",
      "Epoch [700/1000] completed, Average Training Loss: 0.0475\n",
      "    Validation Batch [1/1], Loss: 0.0469\n",
      "Validation Loss: 0.0469, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [701/1000] - Training\n",
      "Epoch [701/1000] completed, Average Training Loss: 0.0329\n",
      "    Validation Batch [1/1], Loss: 0.0490\n",
      "Validation Loss: 0.0490, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [702/1000] - Training\n",
      "Epoch [702/1000] completed, Average Training Loss: 0.0339\n",
      "    Validation Batch [1/1], Loss: 0.0490\n",
      "Validation Loss: 0.0490, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [703/1000] - Training\n",
      "Epoch [703/1000] completed, Average Training Loss: 0.0328\n",
      "    Validation Batch [1/1], Loss: 0.0471\n",
      "Validation Loss: 0.0471, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [704/1000] - Training\n",
      "Epoch [704/1000] completed, Average Training Loss: 0.0443\n",
      "    Validation Batch [1/1], Loss: 0.0439\n",
      "Validation Loss: 0.0439, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [705/1000] - Training\n",
      "Epoch [705/1000] completed, Average Training Loss: 0.0385\n",
      "    Validation Batch [1/1], Loss: 0.0392\n",
      "Validation Loss: 0.0392, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [706/1000] - Training\n",
      "Epoch [706/1000] completed, Average Training Loss: 0.0406\n",
      "    Validation Batch [1/1], Loss: 0.0351\n",
      "Validation Loss: 0.0351, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [707/1000] - Training\n",
      "Epoch [707/1000] completed, Average Training Loss: 0.0295\n",
      "    Validation Batch [1/1], Loss: 0.0318\n",
      "Validation Loss: 0.0318, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0322 to 0.0318. Saving model...\n",
      "\n",
      "LOG: Epoch [708/1000] - Training\n",
      "Epoch [708/1000] completed, Average Training Loss: 0.0437\n",
      "    Validation Batch [1/1], Loss: 0.0309\n",
      "Validation Loss: 0.0309, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0318 to 0.0309. Saving model...\n",
      "\n",
      "LOG: Epoch [709/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [709/1000] completed, Average Training Loss: 0.0415\n",
      "    Validation Batch [1/1], Loss: 0.0343\n",
      "Validation Loss: 0.0343, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [710/1000] - Training\n",
      "Epoch [710/1000] completed, Average Training Loss: 0.0321\n",
      "    Validation Batch [1/1], Loss: 0.0391\n",
      "Validation Loss: 0.0391, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [711/1000] - Training\n",
      "Epoch [711/1000] completed, Average Training Loss: 0.0423\n",
      "    Validation Batch [1/1], Loss: 0.0427\n",
      "Validation Loss: 0.0427, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [712/1000] - Training\n",
      "Epoch [712/1000] completed, Average Training Loss: 0.0355\n",
      "    Validation Batch [1/1], Loss: 0.0420\n",
      "Validation Loss: 0.0420, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [713/1000] - Training\n",
      "Epoch [713/1000] completed, Average Training Loss: 0.0354\n",
      "    Validation Batch [1/1], Loss: 0.0377\n",
      "Validation Loss: 0.0377, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [714/1000] - Training\n",
      "Epoch [714/1000] completed, Average Training Loss: 0.0440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0331\n",
      "Validation Loss: 0.0331, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [715/1000] - Training\n",
      "Epoch [715/1000] completed, Average Training Loss: 0.0316\n",
      "    Validation Batch [1/1], Loss: 0.0316\n",
      "Validation Loss: 0.0316, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [716/1000] - Training\n",
      "Epoch [716/1000] completed, Average Training Loss: 0.0427\n",
      "    Validation Batch [1/1], Loss: 0.0322\n",
      "Validation Loss: 0.0322, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [717/1000] - Training\n",
      "Epoch [717/1000] completed, Average Training Loss: 0.0371\n",
      "    Validation Batch [1/1], Loss: 0.0354\n",
      "Validation Loss: 0.0354, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [718/1000] - Training\n",
      "Epoch [718/1000] completed, Average Training Loss: 0.0393\n",
      "    Validation Batch [1/1], Loss: 0.0399\n",
      "Validation Loss: 0.0399, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [719/1000] - Training\n",
      "Epoch [719/1000] completed, Average Training Loss: 0.0415\n",
      "    Validation Batch [1/1], Loss: 0.0488\n",
      "Validation Loss: 0.0488, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [720/1000] - Training\n",
      "Epoch [720/1000] completed, Average Training Loss: 0.0350\n",
      "    Validation Batch [1/1], Loss: 0.0597\n",
      "Validation Loss: 0.0597, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [721/1000] - Training\n",
      "Epoch [721/1000] completed, Average Training Loss: 0.0318\n",
      "    Validation Batch [1/1], Loss: 0.0631\n",
      "Validation Loss: 0.0631, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [722/1000] - Training\n",
      "Epoch [722/1000] completed, Average Training Loss: 0.0398\n",
      "    Validation Batch [1/1], Loss: 0.0572\n",
      "Validation Loss: 0.0572, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [723/1000] - Training\n",
      "Epoch [723/1000] completed, Average Training Loss: 0.0349\n",
      "    Validation Batch [1/1], Loss: 0.0482\n",
      "Validation Loss: 0.0482, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [724/1000] - Training\n",
      "Epoch [724/1000] completed, Average Training Loss: 0.0386\n",
      "    Validation Batch [1/1], Loss: 0.0412\n",
      "Validation Loss: 0.0412, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [725/1000] - Training\n",
      "Epoch [725/1000] completed, Average Training Loss: 0.0408\n",
      "    Validation Batch [1/1], Loss: 0.0300\n",
      "Validation Loss: 0.0300, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0309 to 0.0300. Saving model...\n",
      "\n",
      "LOG: Epoch [726/1000] - Training\n",
      "Epoch [726/1000] completed, Average Training Loss: 0.0326\n",
      "    Validation Batch [1/1], Loss: 0.0272\n",
      "Validation Loss: 0.0272, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0300 to 0.0272. Saving model...\n",
      "\n",
      "LOG: Epoch [727/1000] - Training\n",
      "Epoch [727/1000] completed, Average Training Loss: 0.0436\n",
      "    Validation Batch [1/1], Loss: 0.0287\n",
      "Validation Loss: 0.0287, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [728/1000] - Training\n",
      "Epoch [728/1000] completed, Average Training Loss: 0.0431\n",
      "    Validation Batch [1/1], Loss: 0.0326\n",
      "Validation Loss: 0.0326, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [729/1000] - Training\n",
      "Epoch [729/1000] completed, Average Training Loss: 0.0331\n",
      "    Validation Batch [1/1], Loss: 0.0363\n",
      "Validation Loss: 0.0363, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [730/1000] - Training\n",
      "Epoch [730/1000] completed, Average Training Loss: 0.0428\n",
      "    Validation Batch [1/1], Loss: 0.0290\n",
      "Validation Loss: 0.0290, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [731/1000] - Training\n",
      "Epoch [731/1000] completed, Average Training Loss: 0.0350\n",
      "    Validation Batch [1/1], Loss: 0.0273\n",
      "Validation Loss: 0.0273, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [732/1000] - Training\n",
      "Epoch [732/1000] completed, Average Training Loss: 0.0341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0324\n",
      "Validation Loss: 0.0324, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [733/1000] - Training\n",
      "Epoch [733/1000] completed, Average Training Loss: 0.0358\n",
      "    Validation Batch [1/1], Loss: 0.0384\n",
      "Validation Loss: 0.0384, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [734/1000] - Training\n",
      "Epoch [734/1000] completed, Average Training Loss: 0.0368\n",
      "    Validation Batch [1/1], Loss: 0.0423\n",
      "Validation Loss: 0.0423, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [735/1000] - Training\n",
      "Epoch [735/1000] completed, Average Training Loss: 0.0348\n",
      "    Validation Batch [1/1], Loss: 0.0403\n",
      "Validation Loss: 0.0403, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [736/1000] - Training\n",
      "Epoch [736/1000] completed, Average Training Loss: 0.0281\n",
      "    Validation Batch [1/1], Loss: 0.0370\n",
      "Validation Loss: 0.0370, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [737/1000] - Training\n",
      "Epoch [737/1000] completed, Average Training Loss: 0.0365\n",
      "    Validation Batch [1/1], Loss: 0.0318\n",
      "Validation Loss: 0.0318, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [738/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [738/1000] completed, Average Training Loss: 0.0384\n",
      "    Validation Batch [1/1], Loss: 0.0333\n",
      "Validation Loss: 0.0333, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [739/1000] - Training\n",
      "Epoch [739/1000] completed, Average Training Loss: 0.0301\n",
      "    Validation Batch [1/1], Loss: 0.0371\n",
      "Validation Loss: 0.0371, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [740/1000] - Training\n",
      "Epoch [740/1000] completed, Average Training Loss: 0.0393\n",
      "    Validation Batch [1/1], Loss: 0.0378\n",
      "Validation Loss: 0.0378, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [741/1000] - Training\n",
      "Epoch [741/1000] completed, Average Training Loss: 0.0297\n",
      "    Validation Batch [1/1], Loss: 0.0382\n",
      "Validation Loss: 0.0382, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [742/1000] - Training\n",
      "Epoch [742/1000] completed, Average Training Loss: 0.0343\n",
      "    Validation Batch [1/1], Loss: 0.0368\n",
      "Validation Loss: 0.0368, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [743/1000] - Training\n",
      "Epoch [743/1000] completed, Average Training Loss: 0.0323\n",
      "    Validation Batch [1/1], Loss: 0.0313\n",
      "Validation Loss: 0.0313, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [744/1000] - Training\n",
      "Epoch [744/1000] completed, Average Training Loss: 0.0290\n",
      "    Validation Batch [1/1], Loss: 0.0258\n",
      "Validation Loss: 0.0258, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0272 to 0.0258. Saving model...\n",
      "\n",
      "LOG: Epoch [745/1000] - Training\n",
      "Epoch [745/1000] completed, Average Training Loss: 0.0329\n",
      "    Validation Batch [1/1], Loss: 0.0240\n",
      "Validation Loss: 0.0240, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0258 to 0.0240. Saving model...\n",
      "\n",
      "LOG: Epoch [746/1000] - Training\n",
      "Epoch [746/1000] completed, Average Training Loss: 0.0396\n",
      "    Validation Batch [1/1], Loss: 0.0241\n",
      "Validation Loss: 0.0241, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [747/1000] - Training\n",
      "Epoch [747/1000] completed, Average Training Loss: 0.0331\n",
      "    Validation Batch [1/1], Loss: 0.0273\n",
      "Validation Loss: 0.0273, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [748/1000] - Training\n",
      "Epoch [748/1000] completed, Average Training Loss: 0.0313\n",
      "    Validation Batch [1/1], Loss: 0.0284\n",
      "Validation Loss: 0.0284, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [749/1000] - Training\n",
      "Epoch [749/1000] completed, Average Training Loss: 0.0326\n",
      "    Validation Batch [1/1], Loss: 0.0286\n",
      "Validation Loss: 0.0286, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [750/1000] - Training\n",
      "Epoch [750/1000] completed, Average Training Loss: 0.0305\n",
      "    Validation Batch [1/1], Loss: 0.0289\n",
      "Validation Loss: 0.0289, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [751/1000] - Training\n",
      "Epoch [751/1000] completed, Average Training Loss: 0.0341\n",
      "    Validation Batch [1/1], Loss: 0.0276\n",
      "Validation Loss: 0.0276, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [752/1000] - Training\n",
      "Epoch [752/1000] completed, Average Training Loss: 0.0324\n",
      "    Validation Batch [1/1], Loss: 0.0260\n",
      "Validation Loss: 0.0260, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [753/1000] - Training\n",
      "Epoch [753/1000] completed, Average Training Loss: 0.0303\n",
      "    Validation Batch [1/1], Loss: 0.0275\n",
      "Validation Loss: 0.0275, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [754/1000] - Training\n",
      "Epoch [754/1000] completed, Average Training Loss: 0.0419\n",
      "    Validation Batch [1/1], Loss: 0.0299\n",
      "Validation Loss: 0.0299, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [755/1000] - Training\n",
      "Epoch [755/1000] completed, Average Training Loss: 0.0297\n",
      "    Validation Batch [1/1], Loss: 0.0246\n",
      "Validation Loss: 0.0246, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [756/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [756/1000] completed, Average Training Loss: 0.0328\n",
      "    Validation Batch [1/1], Loss: 0.0202\n",
      "Validation Loss: 0.0202, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0240 to 0.0202. Saving model...\n",
      "\n",
      "LOG: Epoch [757/1000] - Training\n",
      "Epoch [757/1000] completed, Average Training Loss: 0.0360\n",
      "    Validation Batch [1/1], Loss: 0.0212\n",
      "Validation Loss: 0.0212, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [758/1000] - Training\n",
      "Epoch [758/1000] completed, Average Training Loss: 0.0356\n",
      "    Validation Batch [1/1], Loss: 0.0300\n",
      "Validation Loss: 0.0300, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [759/1000] - Training\n",
      "Epoch [759/1000] completed, Average Training Loss: 0.0331\n",
      "    Validation Batch [1/1], Loss: 0.0454\n",
      "Validation Loss: 0.0454, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [760/1000] - Training\n",
      "Epoch [760/1000] completed, Average Training Loss: 0.0346\n",
      "    Validation Batch [1/1], Loss: 0.0632\n",
      "Validation Loss: 0.0632, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [761/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [761/1000] completed, Average Training Loss: 0.0346\n",
      "    Validation Batch [1/1], Loss: 0.0666\n",
      "Validation Loss: 0.0666, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [762/1000] - Training\n",
      "Epoch [762/1000] completed, Average Training Loss: 0.0320\n",
      "    Validation Batch [1/1], Loss: 0.0613\n",
      "Validation Loss: 0.0613, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [763/1000] - Training\n",
      "Epoch [763/1000] completed, Average Training Loss: 0.0286\n",
      "    Validation Batch [1/1], Loss: 0.0506\n",
      "Validation Loss: 0.0506, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [764/1000] - Training\n",
      "Epoch [764/1000] completed, Average Training Loss: 0.0339\n",
      "    Validation Batch [1/1], Loss: 0.0401\n",
      "Validation Loss: 0.0401, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [765/1000] - Training\n",
      "Epoch [765/1000] completed, Average Training Loss: 0.0366\n",
      "    Validation Batch [1/1], Loss: 0.0323\n",
      "Validation Loss: 0.0323, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [766/1000] - Training\n",
      "Epoch [766/1000] completed, Average Training Loss: 0.0369\n",
      "    Validation Batch [1/1], Loss: 0.0301\n",
      "Validation Loss: 0.0301, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [767/1000] - Training\n",
      "Epoch [767/1000] completed, Average Training Loss: 0.0303\n",
      "    Validation Batch [1/1], Loss: 0.0312\n",
      "Validation Loss: 0.0312, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [768/1000] - Training\n",
      "Epoch [768/1000] completed, Average Training Loss: 0.0289\n",
      "    Validation Batch [1/1], Loss: 0.0370\n",
      "Validation Loss: 0.0370, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [769/1000] - Training\n",
      "Epoch [769/1000] completed, Average Training Loss: 0.0265\n",
      "    Validation Batch [1/1], Loss: 0.0454\n",
      "Validation Loss: 0.0454, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [770/1000] - Training\n",
      "Epoch [770/1000] completed, Average Training Loss: 0.0436\n",
      "    Validation Batch [1/1], Loss: 0.0616\n",
      "Validation Loss: 0.0616, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [771/1000] - Training\n",
      "Epoch [771/1000] completed, Average Training Loss: 0.0361\n",
      "    Validation Batch [1/1], Loss: 0.0690\n",
      "Validation Loss: 0.0690, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [772/1000] - Training\n",
      "Epoch [772/1000] completed, Average Training Loss: 0.0274\n",
      "    Validation Batch [1/1], Loss: 0.0650\n",
      "Validation Loss: 0.0650, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [773/1000] - Training\n",
      "Epoch [773/1000] completed, Average Training Loss: 0.0301\n",
      "    Validation Batch [1/1], Loss: 0.0546\n",
      "Validation Loss: 0.0546, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [774/1000] - Training\n",
      "Epoch [774/1000] completed, Average Training Loss: 0.0280\n",
      "    Validation Batch [1/1], Loss: 0.0448\n",
      "Validation Loss: 0.0448, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [775/1000] - Training\n",
      "Epoch [775/1000] completed, Average Training Loss: 0.0388\n",
      "    Validation Batch [1/1], Loss: 0.0328\n",
      "Validation Loss: 0.0328, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [776/1000] - Training\n",
      "Epoch [776/1000] completed, Average Training Loss: 0.0216\n",
      "    Validation Batch [1/1], Loss: 0.0275\n",
      "Validation Loss: 0.0275, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [777/1000] - Training\n",
      "Epoch [777/1000] completed, Average Training Loss: 0.0309\n",
      "    Validation Batch [1/1], Loss: 0.0264\n",
      "Validation Loss: 0.0264, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [778/1000] - Training\n",
      "Epoch [778/1000] completed, Average Training Loss: 0.0293\n",
      "    Validation Batch [1/1], Loss: 0.0286\n",
      "Validation Loss: 0.0286, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [779/1000] - Training\n",
      "Epoch [779/1000] completed, Average Training Loss: 0.0316\n",
      "    Validation Batch [1/1], Loss: 0.0352\n",
      "Validation Loss: 0.0352, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [780/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [780/1000] completed, Average Training Loss: 0.0357\n",
      "    Validation Batch [1/1], Loss: 0.0449\n",
      "Validation Loss: 0.0449, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [781/1000] - Training\n",
      "Epoch [781/1000] completed, Average Training Loss: 0.0239\n",
      "    Validation Batch [1/1], Loss: 0.0542\n",
      "Validation Loss: 0.0542, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [782/1000] - Training\n",
      "Epoch [782/1000] completed, Average Training Loss: 0.0311\n",
      "    Validation Batch [1/1], Loss: 0.0520\n",
      "Validation Loss: 0.0520, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [783/1000] - Training\n",
      "Epoch [783/1000] completed, Average Training Loss: 0.0251\n",
      "    Validation Batch [1/1], Loss: 0.0430\n",
      "Validation Loss: 0.0430, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [784/1000] - Training\n",
      "Epoch [784/1000] completed, Average Training Loss: 0.0312\n",
      "    Validation Batch [1/1], Loss: 0.0355\n",
      "Validation Loss: 0.0355, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [785/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [785/1000] completed, Average Training Loss: 0.0379\n",
      "    Validation Batch [1/1], Loss: 0.0299\n",
      "Validation Loss: 0.0299, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [786/1000] - Training\n",
      "Epoch [786/1000] completed, Average Training Loss: 0.0312\n",
      "    Validation Batch [1/1], Loss: 0.0277\n",
      "Validation Loss: 0.0277, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [787/1000] - Training\n",
      "Epoch [787/1000] completed, Average Training Loss: 0.0325\n",
      "    Validation Batch [1/1], Loss: 0.0254\n",
      "Validation Loss: 0.0254, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [788/1000] - Training\n",
      "Epoch [788/1000] completed, Average Training Loss: 0.0293\n",
      "    Validation Batch [1/1], Loss: 0.0232\n",
      "Validation Loss: 0.0232, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [789/1000] - Training\n",
      "Epoch [789/1000] completed, Average Training Loss: 0.0240\n",
      "    Validation Batch [1/1], Loss: 0.0210\n",
      "Validation Loss: 0.0210, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [790/1000] - Training\n",
      "Epoch [790/1000] completed, Average Training Loss: 0.0268\n",
      "    Validation Batch [1/1], Loss: 0.0207\n",
      "Validation Loss: 0.0207, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [791/1000] - Training\n",
      "Epoch [791/1000] completed, Average Training Loss: 0.0289\n",
      "    Validation Batch [1/1], Loss: 0.0206\n",
      "Validation Loss: 0.0206, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [792/1000] - Training\n",
      "Epoch [792/1000] completed, Average Training Loss: 0.0285\n",
      "    Validation Batch [1/1], Loss: 0.0213\n",
      "Validation Loss: 0.0213, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [793/1000] - Training\n",
      "Epoch [793/1000] completed, Average Training Loss: 0.0285\n",
      "    Validation Batch [1/1], Loss: 0.0221\n",
      "Validation Loss: 0.0221, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [794/1000] - Training\n",
      "Epoch [794/1000] completed, Average Training Loss: 0.0259\n",
      "    Validation Batch [1/1], Loss: 0.0233\n",
      "Validation Loss: 0.0233, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [795/1000] - Training\n",
      "Epoch [795/1000] completed, Average Training Loss: 0.0306\n",
      "    Validation Batch [1/1], Loss: 0.0235\n",
      "Validation Loss: 0.0235, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [796/1000] - Training\n",
      "Epoch [796/1000] completed, Average Training Loss: 0.0283\n",
      "    Validation Batch [1/1], Loss: 0.0232\n",
      "Validation Loss: 0.0232, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [797/1000] - Training\n",
      "Epoch [797/1000] completed, Average Training Loss: 0.0255\n",
      "    Validation Batch [1/1], Loss: 0.0240\n",
      "Validation Loss: 0.0240, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [798/1000] - Training\n",
      "Epoch [798/1000] completed, Average Training Loss: 0.0259\n",
      "    Validation Batch [1/1], Loss: 0.0274\n",
      "Validation Loss: 0.0274, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [799/1000] - Training\n",
      "Epoch [799/1000] completed, Average Training Loss: 0.0283\n",
      "    Validation Batch [1/1], Loss: 0.0306\n",
      "Validation Loss: 0.0306, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [800/1000] - Training\n",
      "Epoch [800/1000] completed, Average Training Loss: 0.0262\n",
      "    Validation Batch [1/1], Loss: 0.0341\n",
      "Validation Loss: 0.0341, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [801/1000] - Training\n",
      "Epoch [801/1000] completed, Average Training Loss: 0.0239\n",
      "    Validation Batch [1/1], Loss: 0.0329\n",
      "Validation Loss: 0.0329, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [802/1000] - Training\n",
      "Epoch [802/1000] completed, Average Training Loss: 0.0281\n",
      "    Validation Batch [1/1], Loss: 0.0300\n",
      "Validation Loss: 0.0300, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [803/1000] - Training\n",
      "Epoch [803/1000] completed, Average Training Loss: 0.0285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0251\n",
      "Validation Loss: 0.0251, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [804/1000] - Training\n",
      "Epoch [804/1000] completed, Average Training Loss: 0.0236\n",
      "    Validation Batch [1/1], Loss: 0.0228\n",
      "Validation Loss: 0.0228, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [805/1000] - Training\n",
      "Epoch [805/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.0239\n",
      "Validation Loss: 0.0239, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [806/1000] - Training\n",
      "Epoch [806/1000] completed, Average Training Loss: 0.0263\n",
      "    Validation Batch [1/1], Loss: 0.0278\n",
      "Validation Loss: 0.0278, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [807/1000] - Training\n",
      "Epoch [807/1000] completed, Average Training Loss: 0.0280\n",
      "    Validation Batch [1/1], Loss: 0.0305\n",
      "Validation Loss: 0.0305, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [808/1000] - Training\n",
      "Epoch [808/1000] completed, Average Training Loss: 0.0291\n",
      "    Validation Batch [1/1], Loss: 0.0286\n",
      "Validation Loss: 0.0286, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [809/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [809/1000] completed, Average Training Loss: 0.0237\n",
      "    Validation Batch [1/1], Loss: 0.0268\n",
      "Validation Loss: 0.0268, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [810/1000] - Training\n",
      "Epoch [810/1000] completed, Average Training Loss: 0.0300\n",
      "    Validation Batch [1/1], Loss: 0.0293\n",
      "Validation Loss: 0.0293, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [811/1000] - Training\n",
      "Epoch [811/1000] completed, Average Training Loss: 0.0334\n",
      "    Validation Batch [1/1], Loss: 0.0431\n",
      "Validation Loss: 0.0431, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [812/1000] - Training\n",
      "Epoch [812/1000] completed, Average Training Loss: 0.0290\n",
      "    Validation Batch [1/1], Loss: 0.0645\n",
      "Validation Loss: 0.0645, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [813/1000] - Training\n",
      "Epoch [813/1000] completed, Average Training Loss: 0.0277\n",
      "    Validation Batch [1/1], Loss: 0.0899\n",
      "Validation Loss: 0.0899, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [814/1000] - Training\n",
      "Epoch [814/1000] completed, Average Training Loss: 0.0328\n",
      "    Validation Batch [1/1], Loss: 0.0977\n",
      "Validation Loss: 0.0977, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [815/1000] - Training\n",
      "Epoch [815/1000] completed, Average Training Loss: 0.0187\n",
      "    Validation Batch [1/1], Loss: 0.0779\n",
      "Validation Loss: 0.0779, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [816/1000] - Training\n",
      "Epoch [816/1000] completed, Average Training Loss: 0.0251\n",
      "    Validation Batch [1/1], Loss: 0.0531\n",
      "Validation Loss: 0.0531, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [817/1000] - Training\n",
      "Epoch [817/1000] completed, Average Training Loss: 0.0286\n",
      "    Validation Batch [1/1], Loss: 0.0371\n",
      "Validation Loss: 0.0371, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [818/1000] - Training\n",
      "Epoch [818/1000] completed, Average Training Loss: 0.0252\n",
      "    Validation Batch [1/1], Loss: 0.0306\n",
      "Validation Loss: 0.0306, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [819/1000] - Training\n",
      "Epoch [819/1000] completed, Average Training Loss: 0.0232\n",
      "    Validation Batch [1/1], Loss: 0.0309\n",
      "Validation Loss: 0.0309, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [820/1000] - Training\n",
      "Epoch [820/1000] completed, Average Training Loss: 0.0279\n",
      "    Validation Batch [1/1], Loss: 0.0306\n",
      "Validation Loss: 0.0306, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [821/1000] - Training\n",
      "Epoch [821/1000] completed, Average Training Loss: 0.0325\n",
      "    Validation Batch [1/1], Loss: 0.0266\n",
      "Validation Loss: 0.0266, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [822/1000] - Training\n",
      "Epoch [822/1000] completed, Average Training Loss: 0.0352\n",
      "    Validation Batch [1/1], Loss: 0.0240\n",
      "Validation Loss: 0.0240, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [823/1000] - Training\n",
      "Epoch [823/1000] completed, Average Training Loss: 0.0301\n",
      "    Validation Batch [1/1], Loss: 0.0191\n",
      "Validation Loss: 0.0191, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0202 to 0.0191. Saving model...\n",
      "\n",
      "LOG: Epoch [824/1000] - Training\n",
      "Epoch [824/1000] completed, Average Training Loss: 0.0321\n",
      "    Validation Batch [1/1], Loss: 0.0163\n",
      "Validation Loss: 0.0163, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0191 to 0.0163. Saving model...\n",
      "\n",
      "LOG: Epoch [825/1000] - Training\n",
      "Epoch [825/1000] completed, Average Training Loss: 0.0296\n",
      "    Validation Batch [1/1], Loss: 0.0185\n",
      "Validation Loss: 0.0185, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [826/1000] - Training\n",
      "Epoch [826/1000] completed, Average Training Loss: 0.0298\n",
      "    Validation Batch [1/1], Loss: 0.0254\n",
      "Validation Loss: 0.0254, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [827/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [827/1000] completed, Average Training Loss: 0.0285\n",
      "    Validation Batch [1/1], Loss: 0.0363\n",
      "Validation Loss: 0.0363, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [828/1000] - Training\n",
      "Epoch [828/1000] completed, Average Training Loss: 0.0319\n",
      "    Validation Batch [1/1], Loss: 0.0400\n",
      "Validation Loss: 0.0400, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [829/1000] - Training\n",
      "Epoch [829/1000] completed, Average Training Loss: 0.0294\n",
      "    Validation Batch [1/1], Loss: 0.0388\n",
      "Validation Loss: 0.0388, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [830/1000] - Training\n",
      "Epoch [830/1000] completed, Average Training Loss: 0.0294\n",
      "    Validation Batch [1/1], Loss: 0.0328\n",
      "Validation Loss: 0.0328, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [831/1000] - Training\n",
      "Epoch [831/1000] completed, Average Training Loss: 0.0245\n",
      "    Validation Batch [1/1], Loss: 0.0269\n",
      "Validation Loss: 0.0269, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [832/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [832/1000] completed, Average Training Loss: 0.0289\n",
      "    Validation Batch [1/1], Loss: 0.0263\n",
      "Validation Loss: 0.0263, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [833/1000] - Training\n",
      "Epoch [833/1000] completed, Average Training Loss: 0.0213\n",
      "    Validation Batch [1/1], Loss: 0.0258\n",
      "Validation Loss: 0.0258, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [834/1000] - Training\n",
      "Epoch [834/1000] completed, Average Training Loss: 0.0258\n",
      "    Validation Batch [1/1], Loss: 0.0257\n",
      "Validation Loss: 0.0257, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [835/1000] - Training\n",
      "Epoch [835/1000] completed, Average Training Loss: 0.0303\n",
      "    Validation Batch [1/1], Loss: 0.0240\n",
      "Validation Loss: 0.0240, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [836/1000] - Training\n",
      "Epoch [836/1000] completed, Average Training Loss: 0.0234\n",
      "    Validation Batch [1/1], Loss: 0.0222\n",
      "Validation Loss: 0.0222, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [837/1000] - Training\n",
      "Epoch [837/1000] completed, Average Training Loss: 0.0307\n",
      "    Validation Batch [1/1], Loss: 0.0209\n",
      "Validation Loss: 0.0209, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [838/1000] - Training\n",
      "Epoch [838/1000] completed, Average Training Loss: 0.0230\n",
      "    Validation Batch [1/1], Loss: 0.0203\n",
      "Validation Loss: 0.0203, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [839/1000] - Training\n",
      "Epoch [839/1000] completed, Average Training Loss: 0.0278\n",
      "    Validation Batch [1/1], Loss: 0.0210\n",
      "Validation Loss: 0.0210, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [840/1000] - Training\n",
      "Epoch [840/1000] completed, Average Training Loss: 0.0225\n",
      "    Validation Batch [1/1], Loss: 0.0212\n",
      "Validation Loss: 0.0212, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [841/1000] - Training\n",
      "Epoch [841/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.0217\n",
      "Validation Loss: 0.0217, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [842/1000] - Training\n",
      "Epoch [842/1000] completed, Average Training Loss: 0.0216\n",
      "    Validation Batch [1/1], Loss: 0.0234\n",
      "Validation Loss: 0.0234, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [843/1000] - Training\n",
      "Epoch [843/1000] completed, Average Training Loss: 0.0253\n",
      "    Validation Batch [1/1], Loss: 0.0274\n",
      "Validation Loss: 0.0274, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [844/1000] - Training\n",
      "Epoch [844/1000] completed, Average Training Loss: 0.0277\n",
      "    Validation Batch [1/1], Loss: 0.0393\n",
      "Validation Loss: 0.0393, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [845/1000] - Training\n",
      "Epoch [845/1000] completed, Average Training Loss: 0.0245\n",
      "    Validation Batch [1/1], Loss: 0.0492\n",
      "Validation Loss: 0.0492, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [846/1000] - Training\n",
      "Epoch [846/1000] completed, Average Training Loss: 0.0316\n",
      "    Validation Batch [1/1], Loss: 0.0550\n",
      "Validation Loss: 0.0550, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [847/1000] - Training\n",
      "Epoch [847/1000] completed, Average Training Loss: 0.0218\n",
      "    Validation Batch [1/1], Loss: 0.0582\n",
      "Validation Loss: 0.0582, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [848/1000] - Training\n",
      "Epoch [848/1000] completed, Average Training Loss: 0.0241\n",
      "    Validation Batch [1/1], Loss: 0.0552\n",
      "Validation Loss: 0.0552, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [849/1000] - Training\n",
      "Epoch [849/1000] completed, Average Training Loss: 0.0265\n",
      "    Validation Batch [1/1], Loss: 0.0503\n",
      "Validation Loss: 0.0503, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [850/1000] - Training\n",
      "Epoch [850/1000] completed, Average Training Loss: 0.0280\n",
      "    Validation Batch [1/1], Loss: 0.0470\n",
      "Validation Loss: 0.0470, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [851/1000] - Training\n",
      "Epoch [851/1000] completed, Average Training Loss: 0.0216\n",
      "    Validation Batch [1/1], Loss: 0.0416\n",
      "Validation Loss: 0.0416, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [852/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [852/1000] completed, Average Training Loss: 0.0190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0383\n",
      "Validation Loss: 0.0383, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [853/1000] - Training\n",
      "Epoch [853/1000] completed, Average Training Loss: 0.0232\n",
      "    Validation Batch [1/1], Loss: 0.0342\n",
      "Validation Loss: 0.0342, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [854/1000] - Training\n",
      "Epoch [854/1000] completed, Average Training Loss: 0.0247\n",
      "    Validation Batch [1/1], Loss: 0.0272\n",
      "Validation Loss: 0.0272, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [855/1000] - Training\n",
      "Epoch [855/1000] completed, Average Training Loss: 0.0245\n",
      "    Validation Batch [1/1], Loss: 0.0222\n",
      "Validation Loss: 0.0222, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [856/1000] - Training\n",
      "Epoch [856/1000] completed, Average Training Loss: 0.0272\n",
      "    Validation Batch [1/1], Loss: 0.0196\n",
      "Validation Loss: 0.0196, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [857/1000] - Training\n",
      "Epoch [857/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.0199\n",
      "Validation Loss: 0.0199, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [858/1000] - Training\n",
      "Epoch [858/1000] completed, Average Training Loss: 0.0231\n",
      "    Validation Batch [1/1], Loss: 0.0209\n",
      "Validation Loss: 0.0209, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [859/1000] - Training\n",
      "Epoch [859/1000] completed, Average Training Loss: 0.0271\n",
      "    Validation Batch [1/1], Loss: 0.0215\n",
      "Validation Loss: 0.0215, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [860/1000] - Training\n",
      "Epoch [860/1000] completed, Average Training Loss: 0.0277\n",
      "    Validation Batch [1/1], Loss: 0.0220\n",
      "Validation Loss: 0.0220, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [861/1000] - Training\n",
      "Epoch [861/1000] completed, Average Training Loss: 0.0251\n",
      "    Validation Batch [1/1], Loss: 0.0212\n",
      "Validation Loss: 0.0212, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [862/1000] - Training\n",
      "Epoch [862/1000] completed, Average Training Loss: 0.0223\n",
      "    Validation Batch [1/1], Loss: 0.0200\n",
      "Validation Loss: 0.0200, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [863/1000] - Training\n",
      "Epoch [863/1000] completed, Average Training Loss: 0.0298\n",
      "    Validation Batch [1/1], Loss: 0.0194\n",
      "Validation Loss: 0.0194, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [864/1000] - Training\n",
      "Epoch [864/1000] completed, Average Training Loss: 0.0284\n",
      "    Validation Batch [1/1], Loss: 0.0182\n",
      "Validation Loss: 0.0182, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [865/1000] - Training\n",
      "Epoch [865/1000] completed, Average Training Loss: 0.0198\n",
      "    Validation Batch [1/1], Loss: 0.0177\n",
      "Validation Loss: 0.0177, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [866/1000] - Training\n",
      "Epoch [866/1000] completed, Average Training Loss: 0.0277\n",
      "    Validation Batch [1/1], Loss: 0.0165\n",
      "Validation Loss: 0.0165, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [867/1000] - Training\n",
      "Epoch [867/1000] completed, Average Training Loss: 0.0211\n",
      "    Validation Batch [1/1], Loss: 0.0178\n",
      "Validation Loss: 0.0178, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [868/1000] - Training\n",
      "Epoch [868/1000] completed, Average Training Loss: 0.0256\n",
      "    Validation Batch [1/1], Loss: 0.0236\n",
      "Validation Loss: 0.0236, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [869/1000] - Training\n",
      "Epoch [869/1000] completed, Average Training Loss: 0.0225\n",
      "    Validation Batch [1/1], Loss: 0.0248\n",
      "Validation Loss: 0.0248, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [870/1000] - Training\n",
      "Epoch [870/1000] completed, Average Training Loss: 0.0278\n",
      "    Validation Batch [1/1], Loss: 0.0224\n",
      "Validation Loss: 0.0224, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [871/1000] - Training\n",
      "Epoch [871/1000] completed, Average Training Loss: 0.0244\n",
      "    Validation Batch [1/1], Loss: 0.0202\n",
      "Validation Loss: 0.0202, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [872/1000] - Training\n",
      "Epoch [872/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.0213\n",
      "Validation Loss: 0.0213, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [873/1000] - Training\n",
      "Epoch [873/1000] completed, Average Training Loss: 0.0241\n",
      "    Validation Batch [1/1], Loss: 0.0253\n",
      "Validation Loss: 0.0253, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [874/1000] - Training\n",
      "Epoch [874/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.0304\n",
      "Validation Loss: 0.0304, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [875/1000] - Training\n",
      "Epoch [875/1000] completed, Average Training Loss: 0.0190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0339\n",
      "Validation Loss: 0.0339, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [876/1000] - Training\n",
      "Epoch [876/1000] completed, Average Training Loss: 0.0229\n",
      "    Validation Batch [1/1], Loss: 0.0348\n",
      "Validation Loss: 0.0348, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [877/1000] - Training\n",
      "Epoch [877/1000] completed, Average Training Loss: 0.0241\n",
      "    Validation Batch [1/1], Loss: 0.0295\n",
      "Validation Loss: 0.0295, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [878/1000] - Training\n",
      "Epoch [878/1000] completed, Average Training Loss: 0.0223\n",
      "    Validation Batch [1/1], Loss: 0.0270\n",
      "Validation Loss: 0.0270, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [879/1000] - Training\n",
      "Epoch [879/1000] completed, Average Training Loss: 0.0207\n",
      "    Validation Batch [1/1], Loss: 0.0240\n",
      "Validation Loss: 0.0240, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [880/1000] - Training\n",
      "Epoch [880/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.0234\n",
      "Validation Loss: 0.0234, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [881/1000] - Training\n",
      "Epoch [881/1000] completed, Average Training Loss: 0.0248\n",
      "    Validation Batch [1/1], Loss: 0.0245\n",
      "Validation Loss: 0.0245, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [882/1000] - Training\n",
      "Epoch [882/1000] completed, Average Training Loss: 0.0189\n",
      "    Validation Batch [1/1], Loss: 0.0251\n",
      "Validation Loss: 0.0251, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [883/1000] - Training\n",
      "Epoch [883/1000] completed, Average Training Loss: 0.0221\n",
      "    Validation Batch [1/1], Loss: 0.0237\n",
      "Validation Loss: 0.0237, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [884/1000] - Training\n",
      "Epoch [884/1000] completed, Average Training Loss: 0.0152\n",
      "    Validation Batch [1/1], Loss: 0.0198\n",
      "Validation Loss: 0.0198, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [885/1000] - Training\n",
      "Epoch [885/1000] completed, Average Training Loss: 0.0228\n",
      "    Validation Batch [1/1], Loss: 0.0163\n",
      "Validation Loss: 0.0163, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [886/1000] - Training\n",
      "Epoch [886/1000] completed, Average Training Loss: 0.0252\n",
      "    Validation Batch [1/1], Loss: 0.0159\n",
      "Validation Loss: 0.0159, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0163 to 0.0159. Saving model...\n",
      "\n",
      "LOG: Epoch [887/1000] - Training\n",
      "Epoch [887/1000] completed, Average Training Loss: 0.0208\n",
      "    Validation Batch [1/1], Loss: 0.0199\n",
      "Validation Loss: 0.0199, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [888/1000] - Training\n",
      "Epoch [888/1000] completed, Average Training Loss: 0.0188\n",
      "    Validation Batch [1/1], Loss: 0.0279\n",
      "Validation Loss: 0.0279, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [889/1000] - Training\n",
      "Epoch [889/1000] completed, Average Training Loss: 0.0206\n",
      "    Validation Batch [1/1], Loss: 0.0375\n",
      "Validation Loss: 0.0375, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [890/1000] - Training\n",
      "Epoch [890/1000] completed, Average Training Loss: 0.0266\n",
      "    Validation Batch [1/1], Loss: 0.0487\n",
      "Validation Loss: 0.0487, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [891/1000] - Training\n",
      "Epoch [891/1000] completed, Average Training Loss: 0.0214\n",
      "    Validation Batch [1/1], Loss: 0.0512\n",
      "Validation Loss: 0.0512, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [892/1000] - Training\n",
      "Epoch [892/1000] completed, Average Training Loss: 0.0241\n",
      "    Validation Batch [1/1], Loss: 0.0373\n",
      "Validation Loss: 0.0373, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [893/1000] - Training\n",
      "Epoch [893/1000] completed, Average Training Loss: 0.0272\n",
      "    Validation Batch [1/1], Loss: 0.0280\n",
      "Validation Loss: 0.0280, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [894/1000] - Training\n",
      "Epoch [894/1000] completed, Average Training Loss: 0.0227\n",
      "    Validation Batch [1/1], Loss: 0.0235\n",
      "Validation Loss: 0.0235, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [895/1000] - Training\n",
      "Epoch [895/1000] completed, Average Training Loss: 0.0227\n",
      "    Validation Batch [1/1], Loss: 0.0241\n",
      "Validation Loss: 0.0241, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [896/1000] - Training\n",
      "Epoch [896/1000] completed, Average Training Loss: 0.0215\n",
      "    Validation Batch [1/1], Loss: 0.0265\n",
      "Validation Loss: 0.0265, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [897/1000] - Training\n",
      "Epoch [897/1000] completed, Average Training Loss: 0.0219\n",
      "    Validation Batch [1/1], Loss: 0.0283\n",
      "Validation Loss: 0.0283, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [898/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [898/1000] completed, Average Training Loss: 0.0184\n",
      "    Validation Batch [1/1], Loss: 0.0262\n",
      "Validation Loss: 0.0262, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [899/1000] - Training\n",
      "Epoch [899/1000] completed, Average Training Loss: 0.0274\n",
      "    Validation Batch [1/1], Loss: 0.0194\n",
      "Validation Loss: 0.0194, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [900/1000] - Training\n",
      "Epoch [900/1000] completed, Average Training Loss: 0.0210\n",
      "    Validation Batch [1/1], Loss: 0.0232\n",
      "Validation Loss: 0.0232, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [901/1000] - Training\n",
      "Epoch [901/1000] completed, Average Training Loss: 0.0228\n",
      "    Validation Batch [1/1], Loss: 0.0285\n",
      "Validation Loss: 0.0285, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [902/1000] - Training\n",
      "Epoch [902/1000] completed, Average Training Loss: 0.0181\n",
      "    Validation Batch [1/1], Loss: 0.0283\n",
      "Validation Loss: 0.0283, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [903/1000] - Training\n",
      "Epoch [903/1000] completed, Average Training Loss: 0.0202\n",
      "    Validation Batch [1/1], Loss: 0.0298\n",
      "Validation Loss: 0.0298, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [904/1000] - Training\n",
      "Epoch [904/1000] completed, Average Training Loss: 0.0218\n",
      "    Validation Batch [1/1], Loss: 0.0287\n",
      "Validation Loss: 0.0287, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [905/1000] - Training\n",
      "Epoch [905/1000] completed, Average Training Loss: 0.0230\n",
      "    Validation Batch [1/1], Loss: 0.0243\n",
      "Validation Loss: 0.0243, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [906/1000] - Training\n",
      "Epoch [906/1000] completed, Average Training Loss: 0.0201\n",
      "    Validation Batch [1/1], Loss: 0.0222\n",
      "Validation Loss: 0.0222, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [907/1000] - Training\n",
      "Epoch [907/1000] completed, Average Training Loss: 0.0165\n",
      "    Validation Batch [1/1], Loss: 0.0235\n",
      "Validation Loss: 0.0235, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [908/1000] - Training\n",
      "Epoch [908/1000] completed, Average Training Loss: 0.0246\n",
      "    Validation Batch [1/1], Loss: 0.0260\n",
      "Validation Loss: 0.0260, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [909/1000] - Training\n",
      "Epoch [909/1000] completed, Average Training Loss: 0.0227\n",
      "    Validation Batch [1/1], Loss: 0.0319\n",
      "Validation Loss: 0.0319, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [910/1000] - Training\n",
      "Epoch [910/1000] completed, Average Training Loss: 0.0230\n",
      "    Validation Batch [1/1], Loss: 0.0411\n",
      "Validation Loss: 0.0411, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [911/1000] - Training\n",
      "Epoch [911/1000] completed, Average Training Loss: 0.0198\n",
      "    Validation Batch [1/1], Loss: 0.0541\n",
      "Validation Loss: 0.0541, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [912/1000] - Training\n",
      "Epoch [912/1000] completed, Average Training Loss: 0.0236\n",
      "    Validation Batch [1/1], Loss: 0.0727\n",
      "Validation Loss: 0.0727, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [913/1000] - Training\n",
      "Epoch [913/1000] completed, Average Training Loss: 0.0237\n",
      "    Validation Batch [1/1], Loss: 0.0819\n",
      "Validation Loss: 0.0819, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [914/1000] - Training\n",
      "Epoch [914/1000] completed, Average Training Loss: 0.0168\n",
      "    Validation Batch [1/1], Loss: 0.0713\n",
      "Validation Loss: 0.0713, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [915/1000] - Training\n",
      "Epoch [915/1000] completed, Average Training Loss: 0.0219\n",
      "    Validation Batch [1/1], Loss: 0.0627\n",
      "Validation Loss: 0.0627, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [916/1000] - Training\n",
      "Epoch [916/1000] completed, Average Training Loss: 0.0221\n",
      "    Validation Batch [1/1], Loss: 0.0512\n",
      "Validation Loss: 0.0512, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [917/1000] - Training\n",
      "Epoch [917/1000] completed, Average Training Loss: 0.0272\n",
      "    Validation Batch [1/1], Loss: 0.0432\n",
      "Validation Loss: 0.0432, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [918/1000] - Training\n",
      "Epoch [918/1000] completed, Average Training Loss: 0.0266\n",
      "    Validation Batch [1/1], Loss: 0.0410\n",
      "Validation Loss: 0.0410, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [919/1000] - Training\n",
      "Epoch [919/1000] completed, Average Training Loss: 0.0259\n",
      "    Validation Batch [1/1], Loss: 0.0392\n",
      "Validation Loss: 0.0392, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [920/1000] - Training\n",
      "Epoch [920/1000] completed, Average Training Loss: 0.0203\n",
      "    Validation Batch [1/1], Loss: 0.0391\n",
      "Validation Loss: 0.0391, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [921/1000] - Training\n",
      "Epoch [921/1000] completed, Average Training Loss: 0.0239\n",
      "    Validation Batch [1/1], Loss: 0.0402\n",
      "Validation Loss: 0.0402, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [922/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [922/1000] completed, Average Training Loss: 0.0193\n",
      "    Validation Batch [1/1], Loss: 0.0371\n",
      "Validation Loss: 0.0371, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [923/1000] - Training\n",
      "Epoch [923/1000] completed, Average Training Loss: 0.0233\n",
      "    Validation Batch [1/1], Loss: 0.0332\n",
      "Validation Loss: 0.0332, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [924/1000] - Training\n",
      "Epoch [924/1000] completed, Average Training Loss: 0.0172\n",
      "    Validation Batch [1/1], Loss: 0.0284\n",
      "Validation Loss: 0.0284, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [925/1000] - Training\n",
      "Epoch [925/1000] completed, Average Training Loss: 0.0199\n",
      "    Validation Batch [1/1], Loss: 0.0238\n",
      "Validation Loss: 0.0238, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [926/1000] - Training\n",
      "Epoch [926/1000] completed, Average Training Loss: 0.0235\n",
      "    Validation Batch [1/1], Loss: 0.0235\n",
      "Validation Loss: 0.0235, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [927/1000] - Training\n",
      "Epoch [927/1000] completed, Average Training Loss: 0.0201\n",
      "    Validation Batch [1/1], Loss: 0.0253\n",
      "Validation Loss: 0.0253, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [928/1000] - Training\n",
      "Epoch [928/1000] completed, Average Training Loss: 0.0199\n",
      "    Validation Batch [1/1], Loss: 0.0293\n",
      "Validation Loss: 0.0293, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [929/1000] - Training\n",
      "Epoch [929/1000] completed, Average Training Loss: 0.0172\n",
      "    Validation Batch [1/1], Loss: 0.0297\n",
      "Validation Loss: 0.0297, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [930/1000] - Training\n",
      "Epoch [930/1000] completed, Average Training Loss: 0.0211\n",
      "    Validation Batch [1/1], Loss: 0.0249\n",
      "Validation Loss: 0.0249, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [931/1000] - Training\n",
      "Epoch [931/1000] completed, Average Training Loss: 0.0261\n",
      "    Validation Batch [1/1], Loss: 0.0241\n",
      "Validation Loss: 0.0241, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [932/1000] - Training\n",
      "Epoch [932/1000] completed, Average Training Loss: 0.0254\n",
      "    Validation Batch [1/1], Loss: 0.0251\n",
      "Validation Loss: 0.0251, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [933/1000] - Training\n",
      "Epoch [933/1000] completed, Average Training Loss: 0.0216\n",
      "    Validation Batch [1/1], Loss: 0.0266\n",
      "Validation Loss: 0.0266, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [934/1000] - Training\n",
      "Epoch [934/1000] completed, Average Training Loss: 0.0204\n",
      "    Validation Batch [1/1], Loss: 0.0244\n",
      "Validation Loss: 0.0244, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [935/1000] - Training\n",
      "Epoch [935/1000] completed, Average Training Loss: 0.0153\n",
      "    Validation Batch [1/1], Loss: 0.0251\n",
      "Validation Loss: 0.0251, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [936/1000] - Training\n",
      "Epoch [936/1000] completed, Average Training Loss: 0.0190\n",
      "    Validation Batch [1/1], Loss: 0.0266\n",
      "Validation Loss: 0.0266, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [937/1000] - Training\n",
      "Epoch [937/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.0257\n",
      "Validation Loss: 0.0257, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [938/1000] - Training\n",
      "Epoch [938/1000] completed, Average Training Loss: 0.0179\n",
      "    Validation Batch [1/1], Loss: 0.0236\n",
      "Validation Loss: 0.0236, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [939/1000] - Training\n",
      "Epoch [939/1000] completed, Average Training Loss: 0.0197\n",
      "    Validation Batch [1/1], Loss: 0.0206\n",
      "Validation Loss: 0.0206, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [940/1000] - Training\n",
      "Epoch [940/1000] completed, Average Training Loss: 0.0190\n",
      "    Validation Batch [1/1], Loss: 0.0174\n",
      "Validation Loss: 0.0174, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [941/1000] - Training\n",
      "Epoch [941/1000] completed, Average Training Loss: 0.0216\n",
      "    Validation Batch [1/1], Loss: 0.0176\n",
      "Validation Loss: 0.0176, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [942/1000] - Training\n",
      "Epoch [942/1000] completed, Average Training Loss: 0.0173\n",
      "    Validation Batch [1/1], Loss: 0.0195\n",
      "Validation Loss: 0.0195, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [943/1000] - Training\n",
      "Epoch [943/1000] completed, Average Training Loss: 0.0207\n",
      "    Validation Batch [1/1], Loss: 0.0275\n",
      "Validation Loss: 0.0275, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [944/1000] - Training\n",
      "Epoch [944/1000] completed, Average Training Loss: 0.0215\n",
      "    Validation Batch [1/1], Loss: 0.0387\n",
      "Validation Loss: 0.0387, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [945/1000] - Training\n",
      "Epoch [945/1000] completed, Average Training Loss: 0.0200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0458\n",
      "Validation Loss: 0.0458, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [946/1000] - Training\n",
      "Epoch [946/1000] completed, Average Training Loss: 0.0184\n",
      "    Validation Batch [1/1], Loss: 0.0454\n",
      "Validation Loss: 0.0454, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [947/1000] - Training\n",
      "Epoch [947/1000] completed, Average Training Loss: 0.0228\n",
      "    Validation Batch [1/1], Loss: 0.0376\n",
      "Validation Loss: 0.0376, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [948/1000] - Training\n",
      "Epoch [948/1000] completed, Average Training Loss: 0.0245\n",
      "    Validation Batch [1/1], Loss: 0.0367\n",
      "Validation Loss: 0.0367, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [949/1000] - Training\n",
      "Epoch [949/1000] completed, Average Training Loss: 0.0241\n",
      "    Validation Batch [1/1], Loss: 0.0444\n",
      "Validation Loss: 0.0444, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [950/1000] - Training\n",
      "Epoch [950/1000] completed, Average Training Loss: 0.0236\n",
      "    Validation Batch [1/1], Loss: 0.0603\n",
      "Validation Loss: 0.0603, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [951/1000] - Training\n",
      "Epoch [951/1000] completed, Average Training Loss: 0.0193\n",
      "    Validation Batch [1/1], Loss: 0.0680\n",
      "Validation Loss: 0.0680, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [952/1000] - Training\n",
      "Epoch [952/1000] completed, Average Training Loss: 0.0192\n",
      "    Validation Batch [1/1], Loss: 0.0650\n",
      "Validation Loss: 0.0650, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [953/1000] - Training\n",
      "Epoch [953/1000] completed, Average Training Loss: 0.0190\n",
      "    Validation Batch [1/1], Loss: 0.0520\n",
      "Validation Loss: 0.0520, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [954/1000] - Training\n",
      "Epoch [954/1000] completed, Average Training Loss: 0.0166\n",
      "    Validation Batch [1/1], Loss: 0.0377\n",
      "Validation Loss: 0.0377, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [955/1000] - Training\n",
      "Epoch [955/1000] completed, Average Training Loss: 0.0199\n",
      "    Validation Batch [1/1], Loss: 0.0296\n",
      "Validation Loss: 0.0296, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [956/1000] - Training\n",
      "Epoch [956/1000] completed, Average Training Loss: 0.0186\n",
      "    Validation Batch [1/1], Loss: 0.0187\n",
      "Validation Loss: 0.0187, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [957/1000] - Training\n",
      "Epoch [957/1000] completed, Average Training Loss: 0.0186\n",
      "    Validation Batch [1/1], Loss: 0.0138\n",
      "Validation Loss: 0.0138, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0159 to 0.0138. Saving model...\n",
      "\n",
      "LOG: Epoch [958/1000] - Training\n",
      "Epoch [958/1000] completed, Average Training Loss: 0.0176\n",
      "    Validation Batch [1/1], Loss: 0.0128\n",
      "Validation Loss: 0.0128, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0138 to 0.0128. Saving model...\n",
      "\n",
      "LOG: Epoch [959/1000] - Training\n",
      "Epoch [959/1000] completed, Average Training Loss: 0.0184\n",
      "    Validation Batch [1/1], Loss: 0.0128\n",
      "Validation Loss: 0.0128, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0128 to 0.0128. Saving model...\n",
      "\n",
      "LOG: Epoch [960/1000] - Training\n",
      "Epoch [960/1000] completed, Average Training Loss: 0.0214\n",
      "    Validation Batch [1/1], Loss: 0.0129\n",
      "Validation Loss: 0.0129, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [961/1000] - Training\n",
      "Epoch [961/1000] completed, Average Training Loss: 0.0252\n",
      "    Validation Batch [1/1], Loss: 0.0124\n",
      "Validation Loss: 0.0124, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0128 to 0.0124. Saving model...\n",
      "\n",
      "LOG: Epoch [962/1000] - Training\n",
      "Epoch [962/1000] completed, Average Training Loss: 0.0206\n",
      "    Validation Batch [1/1], Loss: 0.0148\n",
      "Validation Loss: 0.0148, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [963/1000] - Training\n",
      "Epoch [963/1000] completed, Average Training Loss: 0.0178\n",
      "    Validation Batch [1/1], Loss: 0.0222\n",
      "Validation Loss: 0.0222, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [964/1000] - Training\n",
      "Epoch [964/1000] completed, Average Training Loss: 0.0177\n",
      "    Validation Batch [1/1], Loss: 0.0380\n",
      "Validation Loss: 0.0380, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [965/1000] - Training\n",
      "Epoch [965/1000] completed, Average Training Loss: 0.0135\n",
      "    Validation Batch [1/1], Loss: 0.0563\n",
      "Validation Loss: 0.0563, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [966/1000] - Training\n",
      "Epoch [966/1000] completed, Average Training Loss: 0.0185\n",
      "    Validation Batch [1/1], Loss: 0.0635\n",
      "Validation Loss: 0.0635, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [967/1000] - Training\n",
      "Epoch [967/1000] completed, Average Training Loss: 0.0204\n",
      "    Validation Batch [1/1], Loss: 0.0609\n",
      "Validation Loss: 0.0609, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [968/1000] - Training\n",
      "Epoch [968/1000] completed, Average Training Loss: 0.0162\n",
      "    Validation Batch [1/1], Loss: 0.0452\n",
      "Validation Loss: 0.0452, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [969/1000] - Training\n",
      "Epoch [969/1000] completed, Average Training Loss: 0.0158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.0331\n",
      "Validation Loss: 0.0331, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [970/1000] - Training\n",
      "Epoch [970/1000] completed, Average Training Loss: 0.0225\n",
      "    Validation Batch [1/1], Loss: 0.0296\n",
      "Validation Loss: 0.0296, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [971/1000] - Training\n",
      "Epoch [971/1000] completed, Average Training Loss: 0.0161\n",
      "    Validation Batch [1/1], Loss: 0.0289\n",
      "Validation Loss: 0.0289, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [972/1000] - Training\n",
      "Epoch [972/1000] completed, Average Training Loss: 0.0194\n",
      "    Validation Batch [1/1], Loss: 0.0265\n",
      "Validation Loss: 0.0265, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [973/1000] - Training\n",
      "Epoch [973/1000] completed, Average Training Loss: 0.0170\n",
      "    Validation Batch [1/1], Loss: 0.0218\n",
      "Validation Loss: 0.0218, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [974/1000] - Training\n",
      "Epoch [974/1000] completed, Average Training Loss: 0.0145\n",
      "    Validation Batch [1/1], Loss: 0.0191\n",
      "Validation Loss: 0.0191, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [975/1000] - Training\n",
      "Epoch [975/1000] completed, Average Training Loss: 0.0153\n",
      "    Validation Batch [1/1], Loss: 0.0172\n",
      "Validation Loss: 0.0172, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [976/1000] - Training\n",
      "Epoch [976/1000] completed, Average Training Loss: 0.0181\n",
      "    Validation Batch [1/1], Loss: 0.0165\n",
      "Validation Loss: 0.0165, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [977/1000] - Training\n",
      "Epoch [977/1000] completed, Average Training Loss: 0.0183\n",
      "    Validation Batch [1/1], Loss: 0.0168\n",
      "Validation Loss: 0.0168, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [978/1000] - Training\n",
      "Epoch [978/1000] completed, Average Training Loss: 0.0188\n",
      "    Validation Batch [1/1], Loss: 0.0168\n",
      "Validation Loss: 0.0168, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [979/1000] - Training\n",
      "Epoch [979/1000] completed, Average Training Loss: 0.0190\n",
      "    Validation Batch [1/1], Loss: 0.0162\n",
      "Validation Loss: 0.0162, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [980/1000] - Training\n",
      "Epoch [980/1000] completed, Average Training Loss: 0.0170\n",
      "    Validation Batch [1/1], Loss: 0.0166\n",
      "Validation Loss: 0.0166, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [981/1000] - Training\n",
      "Epoch [981/1000] completed, Average Training Loss: 0.0206\n",
      "    Validation Batch [1/1], Loss: 0.0155\n",
      "Validation Loss: 0.0155, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [982/1000] - Training\n",
      "Epoch [982/1000] completed, Average Training Loss: 0.0198\n",
      "    Validation Batch [1/1], Loss: 0.0167\n",
      "Validation Loss: 0.0167, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [983/1000] - Training\n",
      "Epoch [983/1000] completed, Average Training Loss: 0.0197\n",
      "    Validation Batch [1/1], Loss: 0.0195\n",
      "Validation Loss: 0.0195, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [984/1000] - Training\n",
      "Epoch [984/1000] completed, Average Training Loss: 0.0173\n",
      "    Validation Batch [1/1], Loss: 0.0272\n",
      "Validation Loss: 0.0272, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [985/1000] - Training\n",
      "Epoch [985/1000] completed, Average Training Loss: 0.0211\n",
      "    Validation Batch [1/1], Loss: 0.0390\n",
      "Validation Loss: 0.0390, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [986/1000] - Training\n",
      "Epoch [986/1000] completed, Average Training Loss: 0.0124\n",
      "    Validation Batch [1/1], Loss: 0.0449\n",
      "Validation Loss: 0.0449, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [987/1000] - Training\n",
      "Epoch [987/1000] completed, Average Training Loss: 0.0148\n",
      "    Validation Batch [1/1], Loss: 0.0450\n",
      "Validation Loss: 0.0450, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [988/1000] - Training\n",
      "Epoch [988/1000] completed, Average Training Loss: 0.0202\n",
      "    Validation Batch [1/1], Loss: 0.0330\n",
      "Validation Loss: 0.0330, Validation Accuracy: 98.57%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [989/1000] - Training\n",
      "Epoch [989/1000] completed, Average Training Loss: 0.0173\n",
      "    Validation Batch [1/1], Loss: 0.0229\n",
      "Validation Loss: 0.0229, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [990/1000] - Training\n",
      "Epoch [990/1000] completed, Average Training Loss: 0.0157\n",
      "    Validation Batch [1/1], Loss: 0.0211\n",
      "Validation Loss: 0.0211, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [991/1000] - Training\n",
      "Epoch [991/1000] completed, Average Training Loss: 0.0185\n",
      "    Validation Batch [1/1], Loss: 0.0221\n",
      "Validation Loss: 0.0221, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [992/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [992/1000] completed, Average Training Loss: 0.0171\n",
      "    Validation Batch [1/1], Loss: 0.0220\n",
      "Validation Loss: 0.0220, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [993/1000] - Training\n",
      "Epoch [993/1000] completed, Average Training Loss: 0.0162\n",
      "    Validation Batch [1/1], Loss: 0.0206\n",
      "Validation Loss: 0.0206, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [994/1000] - Training\n",
      "Epoch [994/1000] completed, Average Training Loss: 0.0190\n",
      "    Validation Batch [1/1], Loss: 0.0181\n",
      "Validation Loss: 0.0181, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [995/1000] - Training\n",
      "Epoch [995/1000] completed, Average Training Loss: 0.0187\n",
      "    Validation Batch [1/1], Loss: 0.0140\n",
      "Validation Loss: 0.0140, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [996/1000] - Training\n",
      "Epoch [996/1000] completed, Average Training Loss: 0.0195\n",
      "    Validation Batch [1/1], Loss: 0.0114\n",
      "Validation Loss: 0.0114, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0124 to 0.0114. Saving model...\n",
      "\n",
      "LOG: Epoch [997/1000] - Training\n",
      "Epoch [997/1000] completed, Average Training Loss: 0.0170\n",
      "    Validation Batch [1/1], Loss: 0.0103\n",
      "Validation Loss: 0.0103, Validation Accuracy: 100.00%\n",
      "Validation loss improved from 0.0114 to 0.0103. Saving model...\n",
      "\n",
      "LOG: Epoch [998/1000] - Training\n",
      "Epoch [998/1000] completed, Average Training Loss: 0.0181\n",
      "    Validation Batch [1/1], Loss: 0.0110\n",
      "Validation Loss: 0.0110, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [999/1000] - Training\n",
      "Epoch [999/1000] completed, Average Training Loss: 0.0190\n",
      "    Validation Batch [1/1], Loss: 0.0139\n",
      "Validation Loss: 0.0139, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1000/1000] - Training\n",
      "Epoch [1000/1000] completed, Average Training Loss: 0.0188\n",
      "    Validation Batch [1/1], Loss: 0.0220\n",
      "Validation Loss: 0.0220, Validation Accuracy: 100.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "Loading the best model weights...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on the test set...\n",
      "    Test Batch [1/12], Loss: 0.0149\n",
      "\n",
      "Final Test Loss: 0.0930, Test Accuracy: 97.27%\n",
      "Saved E2E CNN predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "#init the model, CrossEntropy loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#getting unique labels from entire dataset (train, validation, test)\n",
    "all_labels = []\n",
    "for loader in [train_loader, val_loader, test_loader]:\n",
    "    for _, labels in loader:\n",
    "        all_labels.extend(labels.tolist())\n",
    "all_labels = np.unique(all_labels)\n",
    "\n",
    "# init model with correct number of classes\n",
    "num_classes = len(all_labels)\n",
    "model = hyperspectralCNN(input_channels=window_num_channels, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#lists to store losses and accuracies\n",
    "classification_epoch_losses = []\n",
    "validation_epoch_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 100\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "best_model_weights = None\n",
    "\n",
    "#training loop + validation with early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    # TRAINING\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs}] - Training\")\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2) \n",
    "        target = target.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        # backward pass + optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accum loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"    Training Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store average training loss per epoch\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    classification_epoch_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] completed, Average Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "            target = target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # accu calculation\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Validation Batch [{batch_idx + 1}/{len(val_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store validation metrics\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    validation_epoch_losses.append(avg_val_loss)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss <= best_val_loss:\n",
    "        print(f\"Validation loss improved from {best_val_loss:.4f} to {avg_val_loss:.4f}. Saving model...\")\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        best_model_weights = model.state_dict()\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {epochs_without_improvement}/{patience}\")\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "# loading the best model weights\n",
    "if best_model_weights is not None:\n",
    "    print(\"Loading the best model weights...\")\n",
    "    model.load_state_dict(best_model_weights)\n",
    "\n",
    "completed_epochs = len(classification_epoch_losses)\n",
    "\n",
    "# plot for loss and accuracy trends over epochs\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), classification_epoch_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, completed_epochs + 1), validation_epoch_losses, label=\"Validation Loss\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), val_accuracies, label=\"Validation Accuracy\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Validation Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#test Set Evaluation\n",
    "print(\"\\nEvaluating on the test set...\")\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "e2ecnn_test_predictions = []\n",
    "e2ecnn_test_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "        target = target.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        #accuracy calc\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "        e2ecnn_test_predictions.extend(predicted.cpu().numpy())\n",
    "        e2ecnn_test_true_labels.extend(target.cpu().numpy())\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 1000 == 0:\n",
    "            print(f\"    Test Batch [{batch_idx + 1}/{len(test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "#calc + print test metrics\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"\\nFinal Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Convert to numpy arrays and save\n",
    "e2e_test_predictions = np.array(e2ecnn_test_predictions)\n",
    "e2e_test_true_labels = np.array(e2ecnn_test_true_labels)\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_predictions.npy'), e2e_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_true_labels.npy'), e2e_test_true_labels)\n",
    "print(f\"Saved E2E CNN predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:35.689172Z",
     "iopub.status.busy": "2025-05-08T19:27:35.688170Z",
     "iopub.status.idle": "2025-05-08T19:27:35.767674Z",
     "shell.execute_reply": "2025-05-08T19:27:35.767674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'e2ecnn_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'e2ecnn_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/12 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'e2ecnn_representations\\test'.\n",
      "E2E CNN representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the cnn representations\n",
    "e2ecnn_rep_dir = \"e2ecnn_representations\"\n",
    "os.makedirs(e2ecnn_rep_dir, exist_ok=True)\n",
    "\n",
    "e2ecnn_loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for e2ecnn_split_name, e2ecnn_loader in e2ecnn_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {e2ecnn_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        e2ecnn_split_dir = os.path.join(e2ecnn_rep_dir, e2ecnn_split_name)\n",
    "        os.makedirs(e2ecnn_split_dir, exist_ok=True)\n",
    "\n",
    "        # processing the data batch-wise\n",
    "        for e2ecnn_batch_idx, (e2ecnn_vectors, e2ecnn_labels) in enumerate(e2ecnn_loader):\n",
    "            e2ecnn_vectors = e2ecnn_vectors.permute(0, 3, 1, 2) \n",
    "            e2ecnn_vectors = e2ecnn_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            e2ecnn_projections = model(e2ecnn_vectors)\n",
    "\n",
    "            # converting projections and labels to np arrays\n",
    "            e2ecnn_projections_np = e2ecnn_projections.cpu().numpy()\n",
    "            e2ecnn_labels_np = e2ecnn_labels.cpu().numpy()\n",
    "\n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_encoded_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_projections_np)\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_labels_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_labels_np)\n",
    "\n",
    "            if (e2ecnn_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {e2ecnn_batch_idx + 1}/{len(e2ecnn_loader)} for {e2ecnn_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {e2ecnn_split_name} dataset. Representations saved in '{e2ecnn_split_dir}'.\")\n",
    "\n",
    "print(\"E2E CNN representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:35.770679Z",
     "iopub.status.busy": "2025-05-08T19:27:35.769679Z",
     "iopub.status.idle": "2025-05-08T19:27:35.773703Z",
     "shell.execute_reply": "2025-05-08T19:27:35.773703Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_cnn_reps_and_labels(split_dir):\n",
    "    #gather all the cnn_encoded_batch npy files in sorted order\n",
    "    cnn_rep_files = sorted(glob.glob(os.path.join(split_dir, \"cnn_encoded_batch_*.npy\")))\n",
    "\n",
    "    cnn_all_reps = []\n",
    "    cnn_all_labels = []\n",
    "\n",
    "    for cnn_rep_file in cnn_rep_files:\n",
    "        #deriving label filenames\n",
    "        cnn_label_file = cnn_rep_file.replace(\"cnn_encoded_batch_\", \"cnn_labels_batch_\")\n",
    "\n",
    "        cnn_reps = np.load(cnn_rep_file)\n",
    "        cnn_labels = np.load(cnn_label_file)\n",
    "\n",
    "        cnn_all_reps.append(cnn_reps)\n",
    "        cnn_all_labels.append(cnn_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    cnn_all_reps = np.concatenate(cnn_all_reps, axis = 0)\n",
    "    cnn_all_labels = np.concatenate(cnn_all_labels, axis = 0)\n",
    "\n",
    "    return cnn_all_reps, cnn_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:35.775707Z",
     "iopub.status.busy": "2025-05-08T19:27:35.775707Z",
     "iopub.status.idle": "2025-05-08T19:27:35.908432Z",
     "shell.execute_reply": "2025-05-08T19:27:35.908432Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_train_dir = os.path.join(\"e2ecnn_representations\", \"train\")\n",
    "cnn_val_dir   = os.path.join(\"e2ecnn_representations\", \"val\")\n",
    "cnn_test_dir  = os.path.join(\"e2ecnn_representations\", \"test\")\n",
    "\n",
    "cnn_train_reps, cnn_train_labels = load_cnn_reps_and_labels(cnn_train_dir)\n",
    "cnn_val_reps, cnn_val_labels = load_cnn_reps_and_labels(cnn_val_dir)\n",
    "cnn_test_reps, cnn_test_labels = load_cnn_reps_and_labels(cnn_test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:35.911436Z",
     "iopub.status.busy": "2025-05-08T19:27:35.910438Z",
     "iopub.status.idle": "2025-05-08T19:27:35.915435Z",
     "shell.execute_reply": "2025-05-08T19:27:35.915435Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_encoded_data(encoded_dir):\n",
    "    print(f\"LOG: Loading encoded data (representations) from {encoded_dir}...\")\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    #iter through batches\n",
    "    for filename in sorted(os.listdir(encoded_dir)):\n",
    "        if filename.startswith('encoded_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load the features\n",
    "            features = np.load(os.path.join(encoded_dir, filename))\n",
    "            features_flat = features.reshape(features.shape[0], -1) #flatten features for LRM\n",
    "            features_list.append(features_flat)\n",
    "        \n",
    "        elif filename.startswith('labels_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load labels\n",
    "            labels = np.load(os.path.join(encoded_dir, filename))\n",
    "            labels_list.append(labels)\n",
    "\n",
    "    #concat all batches into a single array\n",
    "    encoded_features = np.vstack(features_list)\n",
    "    encoded_labels = np.hstack(labels_list)\n",
    "\n",
    "    print(f\"LOG: Loaded {encoded_features.shape[0]} samples with {encoded_features.shape[1]} features each\")\n",
    "    print(f\"LOG: Labels shape: {encoded_labels.shape}\")\n",
    "\n",
    "    return encoded_features, encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:35.918134Z",
     "iopub.status.busy": "2025-05-08T19:27:35.917128Z",
     "iopub.status.idle": "2025-05-08T19:27:36.115585Z",
     "shell.execute_reply": "2025-05-08T19:27:36.115585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 280 samples with 64 features each\n",
      "LOG: Labels shape: (280,)\n",
      "\n",
      "Loading validation data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "\n",
      "Loading test data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2898 samples with 64 features each\n",
      "LOG: Labels shape: (2898,)\n",
      "\n",
      "LOG: Training features shape: (280, 64), Training labels shape: (280,)\n",
      "LOG: Validation features shape: (70, 64), Validation labels shape: (70,)\n",
      "LOG: Test features shape: (2898, 64), Test labels shape: (2898,)\n",
      "\n",
      "LOG: Training Logistic Regression model...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 75.71%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       0.71      1.00      0.83         5\n",
      "           2       0.60      0.60      0.60         5\n",
      "           3       0.75      0.60      0.67         5\n",
      "           4       1.00      0.40      0.57         5\n",
      "           5       0.33      0.40      0.36         5\n",
      "           6       0.75      0.60      0.67         5\n",
      "           7       1.00      0.80      0.89         5\n",
      "           8       0.33      0.40      0.36         5\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       1.00      0.80      0.89         5\n",
      "          11       0.83      1.00      0.91         5\n",
      "          12       0.83      1.00      0.91         5\n",
      "          13       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.78      0.76      0.76        70\n",
      "weighted avg       0.78      0.76      0.76        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 77.64%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       245\n",
      "           1       0.44      0.93      0.60        76\n",
      "           2       0.75      0.82      0.78       226\n",
      "           3       0.74      0.78      0.76       190\n",
      "           4       0.89      0.52      0.66       244\n",
      "           5       0.53      0.39      0.45       244\n",
      "           6       0.88      0.84      0.86       234\n",
      "           7       0.89      0.91      0.90       178\n",
      "           8       0.65      0.62      0.63       289\n",
      "           9       0.73      0.94      0.82       223\n",
      "          10       0.98      0.85      0.91       280\n",
      "          11       0.74      1.00      0.85       156\n",
      "          12       0.78      0.72      0.75       243\n",
      "          13       0.86      0.93      0.89        70\n",
      "\n",
      "    accuracy                           0.78      2898\n",
      "   macro avg       0.77      0.80      0.77      2898\n",
      "weighted avg       0.79      0.78      0.77      2898\n",
      "\n",
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "lrm_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "lrm_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "lrm_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "print(\"\\nLoading training data for LRM...\")\n",
    "lrm_train_features, lrm_train_labels = load_encoded_data(lrm_encoded_train_dir)\n",
    "\n",
    "print(\"\\nLoading validation data for LRM...\")\n",
    "lrm_val_features, lrm_val_labels = load_encoded_data(lrm_encoded_val_dir)\n",
    "\n",
    "print(\"\\nLoading test data for LRM...\")\n",
    "lrm_test_features, lrm_test_labels = load_encoded_data(lrm_encoded_test_dir)\n",
    "\n",
    "#verify shapes\n",
    "print(f\"\\nLOG: Training features shape: {lrm_train_features.shape}, Training labels shape: {lrm_train_labels.shape}\")\n",
    "print(f\"LOG: Validation features shape: {lrm_val_features.shape}, Validation labels shape: {lrm_val_labels.shape}\")\n",
    "print(f\"LOG: Test features shape: {lrm_test_features.shape}, Test labels shape: {lrm_test_labels.shape}\")\n",
    "\n",
    "print(\"\\nLOG: Training Logistic Regression model...\")\n",
    "logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight = 'balanced')\n",
    "logistic_clf.fit(lrm_train_features, lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "#eval on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "lrm_val_predictions = logistic_clf.predict(lrm_val_features)\n",
    "lrm_val_accuracy = accuracy_score(lrm_val_labels, lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(lrm_val_labels, lrm_val_predictions))\n",
    "\n",
    "#eval on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "lrm_test_predictions = logistic_clf.predict(lrm_test_features)\n",
    "lrm_test_accuracy = accuracy_score(lrm_test_labels, lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(lrm_test_labels, lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_predictions.npy'), lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_true_labels.npy'), lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying CAE Embeddings with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:36.118104Z",
     "iopub.status.busy": "2025-05-08T19:27:36.118104Z",
     "iopub.status.idle": "2025-05-08T19:27:36.121938Z",
     "shell.execute_reply": "2025-05-08T19:27:36.121938Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:36.124944Z",
     "iopub.status.busy": "2025-05-08T19:27:36.123943Z",
     "iopub.status.idle": "2025-05-08T19:27:36.132643Z",
     "shell.execute_reply": "2025-05-08T19:27:36.132643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 280 samples with 64 features each\n",
      "LOG: Labels shape: (280,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2898 samples with 64 features each\n",
      "LOG: Labels shape: (2898,)\n",
      "Train reps shape: (280, 64)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 64)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 64)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "cae_mlp_train_dir = os.path.join(\"encoded_representations\", \"train\")\n",
    "cae_mlp_val_dir   = os.path.join(\"encoded_representations\", \"val\")\n",
    "cae_mlp_test_dir  = os.path.join(\"encoded_representations\", \"test\")\n",
    "\n",
    "cae_mlp_train_reps, cae_mlp_train_labels = load_encoded_data(cae_mlp_train_dir)\n",
    "cae_mlp_val_reps, cae_mlp_val_labels = load_encoded_data(cae_mlp_val_dir)\n",
    "cae_mlp_test_reps, cae_mlp_test_labels = load_encoded_data(cae_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",cae_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", cae_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", cae_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", cae_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", cae_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", cae_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:36.134654Z",
     "iopub.status.busy": "2025-05-08T19:27:36.134654Z",
     "iopub.status.idle": "2025-05-08T19:27:36.139336Z",
     "shell.execute_reply": "2025-05-08T19:27:36.139336Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "cae_mlp_train_embeddings_torch = torch.tensor(cae_mlp_train_reps, dtype=torch.float32)\n",
    "cae_mlp_train_labels_torch = torch.tensor(cae_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_val_embeddings_torch = torch.tensor(cae_mlp_val_reps, dtype=torch.float32)\n",
    "cae_mlp_val_labels_torch = torch.tensor(cae_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_test_embeddings_torch = torch.tensor(cae_mlp_test_reps, dtype=torch.float32)\n",
    "cae_mlp_test_labels_torch = torch.tensor(cae_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "cae_mlp_train_dataset = TensorDataset(cae_mlp_train_embeddings_torch, cae_mlp_train_labels_torch)\n",
    "cae_mlp_val_dataset = TensorDataset(cae_mlp_val_embeddings_torch, cae_mlp_val_labels_torch)\n",
    "cae_mlp_test_dataset = TensorDataset(cae_mlp_test_embeddings_torch, cae_mlp_test_labels_torch)\n",
    "\n",
    "cae_mlp_batch_size = 64\n",
    "cae_mlp_train_loader = DataLoader(cae_mlp_train_dataset, batch_size=cae_mlp_batch_size, shuffle=True)\n",
    "cae_mlp_val_loader = DataLoader(cae_mlp_val_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n",
    "cae_mlp_test_loader = DataLoader(cae_mlp_test_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:36.142341Z",
     "iopub.status.busy": "2025-05-08T19:27:36.142341Z",
     "iopub.status.idle": "2025-05-08T19:27:47.619585Z",
     "shell.execute_reply": "2025-05-08T19:27:47.619585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.6927  |  Val Loss: 2.6492\n",
      "Validation loss improved from inf to 2.6492.\n",
      "[Epoch 2/1000] Train Loss: 2.6443  |  Val Loss: 2.6344\n",
      "Validation loss improved from 2.6492 to 2.6344.\n",
      "[Epoch 3/1000] Train Loss: 2.6258  |  Val Loss: 2.6193\n",
      "Validation loss improved from 2.6344 to 2.6193.\n",
      "[Epoch 4/1000] Train Loss: 2.6199  |  Val Loss: 2.6137\n",
      "Validation loss improved from 2.6193 to 2.6137.\n",
      "[Epoch 5/1000] Train Loss: 2.6099  |  Val Loss: 2.6023\n",
      "Validation loss improved from 2.6137 to 2.6023.\n",
      "[Epoch 6/1000] Train Loss: 2.5959  |  Val Loss: 2.5870\n",
      "Validation loss improved from 2.6023 to 2.5870.\n",
      "[Epoch 7/1000] Train Loss: 2.5819  |  Val Loss: 2.5714\n",
      "Validation loss improved from 2.5870 to 2.5714.\n",
      "[Epoch 8/1000] Train Loss: 2.5657  |  Val Loss: 2.5538\n",
      "Validation loss improved from 2.5714 to 2.5538.\n",
      "[Epoch 9/1000] Train Loss: 2.5483  |  Val Loss: 2.5348\n",
      "Validation loss improved from 2.5538 to 2.5348.\n",
      "[Epoch 10/1000] Train Loss: 2.5283  |  Val Loss: 2.5167\n",
      "Validation loss improved from 2.5348 to 2.5167.\n",
      "[Epoch 11/1000] Train Loss: 2.5104  |  Val Loss: 2.4900\n",
      "Validation loss improved from 2.5167 to 2.4900.\n",
      "[Epoch 12/1000] Train Loss: 2.4878  |  Val Loss: 2.4677\n",
      "Validation loss improved from 2.4900 to 2.4677.\n",
      "[Epoch 13/1000] Train Loss: 2.4586  |  Val Loss: 2.4399\n",
      "Validation loss improved from 2.4677 to 2.4399.\n",
      "[Epoch 14/1000] Train Loss: 2.4289  |  Val Loss: 2.4116\n",
      "Validation loss improved from 2.4399 to 2.4116.\n",
      "[Epoch 15/1000] Train Loss: 2.4043  |  Val Loss: 2.3715\n",
      "Validation loss improved from 2.4116 to 2.3715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/1000] Train Loss: 2.3661  |  Val Loss: 2.3362\n",
      "Validation loss improved from 2.3715 to 2.3362.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/1000] Train Loss: 2.3310  |  Val Loss: 2.2902\n",
      "Validation loss improved from 2.3362 to 2.2902.\n",
      "[Epoch 18/1000] Train Loss: 2.2871  |  Val Loss: 2.2489\n",
      "Validation loss improved from 2.2902 to 2.2489.\n",
      "[Epoch 19/1000] Train Loss: 2.2425  |  Val Loss: 2.2044\n",
      "Validation loss improved from 2.2489 to 2.2044.\n",
      "[Epoch 20/1000] Train Loss: 2.1990  |  Val Loss: 2.1653\n",
      "Validation loss improved from 2.2044 to 2.1653.\n",
      "[Epoch 21/1000] Train Loss: 2.1530  |  Val Loss: 2.1158\n",
      "Validation loss improved from 2.1653 to 2.1158.\n",
      "[Epoch 22/1000] Train Loss: 2.1100  |  Val Loss: 2.0697\n",
      "Validation loss improved from 2.1158 to 2.0697.\n",
      "[Epoch 23/1000] Train Loss: 2.0617  |  Val Loss: 2.0246\n",
      "Validation loss improved from 2.0697 to 2.0246.\n",
      "[Epoch 24/1000] Train Loss: 2.0194  |  Val Loss: 1.9775\n",
      "Validation loss improved from 2.0246 to 1.9775.\n",
      "[Epoch 25/1000] Train Loss: 1.9737  |  Val Loss: 1.9325\n",
      "Validation loss improved from 1.9775 to 1.9325.\n",
      "[Epoch 26/1000] Train Loss: 1.9319  |  Val Loss: 1.8890\n",
      "Validation loss improved from 1.9325 to 1.8890.\n",
      "[Epoch 27/1000] Train Loss: 1.8855  |  Val Loss: 1.8482\n",
      "Validation loss improved from 1.8890 to 1.8482.\n",
      "[Epoch 28/1000] Train Loss: 1.8490  |  Val Loss: 1.8222\n",
      "Validation loss improved from 1.8482 to 1.8222.\n",
      "[Epoch 29/1000] Train Loss: 1.8178  |  Val Loss: 1.7660\n",
      "Validation loss improved from 1.8222 to 1.7660.\n",
      "[Epoch 30/1000] Train Loss: 1.7718  |  Val Loss: 1.7310\n",
      "Validation loss improved from 1.7660 to 1.7310.\n",
      "[Epoch 31/1000] Train Loss: 1.7494  |  Val Loss: 1.6992\n",
      "Validation loss improved from 1.7310 to 1.6992.\n",
      "[Epoch 32/1000] Train Loss: 1.7023  |  Val Loss: 1.6703\n",
      "Validation loss improved from 1.6992 to 1.6703.\n",
      "[Epoch 33/1000] Train Loss: 1.6803  |  Val Loss: 1.6334\n",
      "Validation loss improved from 1.6703 to 1.6334.\n",
      "[Epoch 34/1000] Train Loss: 1.6447  |  Val Loss: 1.5991\n",
      "Validation loss improved from 1.6334 to 1.5991.\n",
      "[Epoch 35/1000] Train Loss: 1.6228  |  Val Loss: 1.5740\n",
      "Validation loss improved from 1.5991 to 1.5740.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36/1000] Train Loss: 1.5968  |  Val Loss: 1.5580\n",
      "Validation loss improved from 1.5740 to 1.5580.\n",
      "[Epoch 37/1000] Train Loss: 1.5710  |  Val Loss: 1.5511\n",
      "Validation loss improved from 1.5580 to 1.5511.\n",
      "[Epoch 38/1000] Train Loss: 1.5507  |  Val Loss: 1.5036\n",
      "Validation loss improved from 1.5511 to 1.5036.\n",
      "[Epoch 39/1000] Train Loss: 1.5343  |  Val Loss: 1.4836\n",
      "Validation loss improved from 1.5036 to 1.4836.\n",
      "[Epoch 40/1000] Train Loss: 1.5066  |  Val Loss: 1.4629\n",
      "Validation loss improved from 1.4836 to 1.4629.\n",
      "[Epoch 41/1000] Train Loss: 1.4885  |  Val Loss: 1.4821\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 42/1000] Train Loss: 1.4882  |  Val Loss: 1.4377\n",
      "Validation loss improved from 1.4629 to 1.4377.\n",
      "[Epoch 43/1000] Train Loss: 1.4535  |  Val Loss: 1.4225\n",
      "Validation loss improved from 1.4377 to 1.4225.\n",
      "[Epoch 44/1000] Train Loss: 1.4441  |  Val Loss: 1.4246\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 45/1000] Train Loss: 1.4388  |  Val Loss: 1.3877\n",
      "Validation loss improved from 1.4225 to 1.3877.\n",
      "[Epoch 46/1000] Train Loss: 1.4215  |  Val Loss: 1.3794\n",
      "Validation loss improved from 1.3877 to 1.3794.\n",
      "[Epoch 47/1000] Train Loss: 1.4191  |  Val Loss: 1.3769\n",
      "Validation loss improved from 1.3794 to 1.3769.\n",
      "[Epoch 48/1000] Train Loss: 1.3950  |  Val Loss: 1.3574\n",
      "Validation loss improved from 1.3769 to 1.3574.\n",
      "[Epoch 49/1000] Train Loss: 1.3898  |  Val Loss: 1.3417\n",
      "Validation loss improved from 1.3574 to 1.3417.\n",
      "[Epoch 50/1000] Train Loss: 1.3721  |  Val Loss: 1.3923\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 51/1000] Train Loss: 1.3913  |  Val Loss: 1.3252\n",
      "Validation loss improved from 1.3417 to 1.3252.\n",
      "[Epoch 52/1000] Train Loss: 1.3476  |  Val Loss: 1.3181\n",
      "Validation loss improved from 1.3252 to 1.3181.\n",
      "[Epoch 53/1000] Train Loss: 1.3552  |  Val Loss: 1.3161\n",
      "Validation loss improved from 1.3181 to 1.3161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 54/1000] Train Loss: 1.3414  |  Val Loss: 1.3470\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 55/1000] Train Loss: 1.3430  |  Val Loss: 1.3073\n",
      "Validation loss improved from 1.3161 to 1.3073.\n",
      "[Epoch 56/1000] Train Loss: 1.3406  |  Val Loss: 1.3090\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 57/1000] Train Loss: 1.3537  |  Val Loss: 1.4133\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 58/1000] Train Loss: 1.3572  |  Val Loss: 1.2734\n",
      "Validation loss improved from 1.3073 to 1.2734.\n",
      "[Epoch 59/1000] Train Loss: 1.3511  |  Val Loss: 1.2859\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 60/1000] Train Loss: 1.3084  |  Val Loss: 1.3111\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 61/1000] Train Loss: 1.3154  |  Val Loss: 1.2704\n",
      "Validation loss improved from 1.2734 to 1.2704.\n",
      "[Epoch 62/1000] Train Loss: 1.3149  |  Val Loss: 1.2727\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 63/1000] Train Loss: 1.2937  |  Val Loss: 1.3173\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 64/1000] Train Loss: 1.3058  |  Val Loss: 1.2666\n",
      "Validation loss improved from 1.2704 to 1.2666.\n",
      "[Epoch 65/1000] Train Loss: 1.2799  |  Val Loss: 1.2486\n",
      "Validation loss improved from 1.2666 to 1.2486.\n",
      "[Epoch 66/1000] Train Loss: 1.2799  |  Val Loss: 1.2733\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 67/1000] Train Loss: 1.2748  |  Val Loss: 1.2461\n",
      "Validation loss improved from 1.2486 to 1.2461.\n",
      "[Epoch 68/1000] Train Loss: 1.2664  |  Val Loss: 1.2766\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 69/1000] Train Loss: 1.2672  |  Val Loss: 1.2301\n",
      "Validation loss improved from 1.2461 to 1.2301.\n",
      "[Epoch 70/1000] Train Loss: 1.2678  |  Val Loss: 1.2401\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 71/1000] Train Loss: 1.2918  |  Val Loss: 1.3106\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 72/1000] Train Loss: 1.2807  |  Val Loss: 1.2327\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 73/1000] Train Loss: 1.2632  |  Val Loss: 1.2253\n",
      "Validation loss improved from 1.2301 to 1.2253.\n",
      "[Epoch 74/1000] Train Loss: 1.2594  |  Val Loss: 1.2625\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 75/1000] Train Loss: 1.2520  |  Val Loss: 1.2270\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 76/1000] Train Loss: 1.2373  |  Val Loss: 1.2618\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 77/1000] Train Loss: 1.2485  |  Val Loss: 1.2255\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 78/1000] Train Loss: 1.2453  |  Val Loss: 1.2242\n",
      "Validation loss improved from 1.2253 to 1.2242.\n",
      "[Epoch 79/1000] Train Loss: 1.2307  |  Val Loss: 1.2189\n",
      "Validation loss improved from 1.2242 to 1.2189.\n",
      "[Epoch 80/1000] Train Loss: 1.2303  |  Val Loss: 1.2133\n",
      "Validation loss improved from 1.2189 to 1.2133.\n",
      "[Epoch 81/1000] Train Loss: 1.2294  |  Val Loss: 1.2190\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 82/1000] Train Loss: 1.2505  |  Val Loss: 1.2121\n",
      "Validation loss improved from 1.2133 to 1.2121.\n",
      "[Epoch 83/1000] Train Loss: 1.2206  |  Val Loss: 1.2234\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 84/1000] Train Loss: 1.2218  |  Val Loss: 1.2179\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 85/1000] Train Loss: 1.2171  |  Val Loss: 1.2188\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 86/1000] Train Loss: 1.2203  |  Val Loss: 1.2370\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 87/1000] Train Loss: 1.2376  |  Val Loss: 1.1927\n",
      "Validation loss improved from 1.2121 to 1.1927.\n",
      "[Epoch 88/1000] Train Loss: 1.2282  |  Val Loss: 1.1922\n",
      "Validation loss improved from 1.1927 to 1.1922.\n",
      "[Epoch 89/1000] Train Loss: 1.2082  |  Val Loss: 1.1958\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 90/1000] Train Loss: 1.2036  |  Val Loss: 1.2075\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 91/1000] Train Loss: 1.2071  |  Val Loss: 1.2012\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 92/1000] Train Loss: 1.2034  |  Val Loss: 1.2008\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 93/1000] Train Loss: 1.2057  |  Val Loss: 1.1926\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 94/1000] Train Loss: 1.2164  |  Val Loss: 1.1986\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 95/1000] Train Loss: 1.2124  |  Val Loss: 1.2067\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 96/1000] Train Loss: 1.1982  |  Val Loss: 1.1981\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 97/1000] Train Loss: 1.1970  |  Val Loss: 1.1916\n",
      "Validation loss improved from 1.1922 to 1.1916.\n",
      "[Epoch 98/1000] Train Loss: 1.1920  |  Val Loss: 1.1950\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 99/1000] Train Loss: 1.1915  |  Val Loss: 1.1747\n",
      "Validation loss improved from 1.1916 to 1.1747.\n",
      "[Epoch 100/1000] Train Loss: 1.2088  |  Val Loss: 1.1859\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 101/1000] Train Loss: 1.1976  |  Val Loss: 1.2066\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 102/1000] Train Loss: 1.2509  |  Val Loss: 1.2418\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 103/1000] Train Loss: 1.2158  |  Val Loss: 1.2208\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 104/1000] Train Loss: 1.2176  |  Val Loss: 1.2564\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 105/1000] Train Loss: 1.2088  |  Val Loss: 1.1731\n",
      "Validation loss improved from 1.1747 to 1.1731.\n",
      "[Epoch 106/1000] Train Loss: 1.1979  |  Val Loss: 1.1665\n",
      "Validation loss improved from 1.1731 to 1.1665.\n",
      "[Epoch 107/1000] Train Loss: 1.1959  |  Val Loss: 1.2178\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 108/1000] Train Loss: 1.1990  |  Val Loss: 1.2015\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 109/1000] Train Loss: 1.2020  |  Val Loss: 1.1907\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 110/1000] Train Loss: 1.1971  |  Val Loss: 1.3040\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 111/1000] Train Loss: 1.2376  |  Val Loss: 1.1783\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 112/1000] Train Loss: 1.2067  |  Val Loss: 1.1804\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 113/1000] Train Loss: 1.1856  |  Val Loss: 1.1930\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 114/1000] Train Loss: 1.1756  |  Val Loss: 1.1770\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 115/1000] Train Loss: 1.1723  |  Val Loss: 1.1844\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 116/1000] Train Loss: 1.1770  |  Val Loss: 1.1742\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 117/1000] Train Loss: 1.1666  |  Val Loss: 1.1679\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 118/1000] Train Loss: 1.1652  |  Val Loss: 1.1632\n",
      "Validation loss improved from 1.1665 to 1.1632.\n",
      "[Epoch 119/1000] Train Loss: 1.1651  |  Val Loss: 1.2032\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 120/1000] Train Loss: 1.1752  |  Val Loss: 1.1759\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 121/1000] Train Loss: 1.1772  |  Val Loss: 1.2579\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 122/1000] Train Loss: 1.1734  |  Val Loss: 1.1677\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 123/1000] Train Loss: 1.1753  |  Val Loss: 1.1987\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 124/1000] Train Loss: 1.1687  |  Val Loss: 1.1658\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 125/1000] Train Loss: 1.1917  |  Val Loss: 1.1609\n",
      "Validation loss improved from 1.1632 to 1.1609.\n",
      "[Epoch 126/1000] Train Loss: 1.1714  |  Val Loss: 1.1944\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 127/1000] Train Loss: 1.1616  |  Val Loss: 1.1594\n",
      "Validation loss improved from 1.1609 to 1.1594.\n",
      "[Epoch 128/1000] Train Loss: 1.1557  |  Val Loss: 1.1689\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 129/1000] Train Loss: 1.1537  |  Val Loss: 1.1645\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 130/1000] Train Loss: 1.1584  |  Val Loss: 1.1577\n",
      "Validation loss improved from 1.1594 to 1.1577.\n",
      "[Epoch 131/1000] Train Loss: 1.1793  |  Val Loss: 1.1773\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 132/1000] Train Loss: 1.1609  |  Val Loss: 1.1620\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 133/1000] Train Loss: 1.1621  |  Val Loss: 1.1997\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 134/1000] Train Loss: 1.1836  |  Val Loss: 1.1906\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 135/1000] Train Loss: 1.1546  |  Val Loss: 1.1453\n",
      "Validation loss improved from 1.1577 to 1.1453.\n",
      "[Epoch 136/1000] Train Loss: 1.1585  |  Val Loss: 1.1563\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 137/1000] Train Loss: 1.1608  |  Val Loss: 1.1543\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 138/1000] Train Loss: 1.1435  |  Val Loss: 1.1516\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 139/1000] Train Loss: 1.1522  |  Val Loss: 1.1717\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 140/1000] Train Loss: 1.1643  |  Val Loss: 1.1520\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 141/1000] Train Loss: 1.1668  |  Val Loss: 1.1726\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 142/1000] Train Loss: 1.1589  |  Val Loss: 1.1557\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 143/1000] Train Loss: 1.1558  |  Val Loss: 1.2003\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 144/1000] Train Loss: 1.1493  |  Val Loss: 1.1410\n",
      "Validation loss improved from 1.1453 to 1.1410.\n",
      "[Epoch 145/1000] Train Loss: 1.1488  |  Val Loss: 1.1481\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 146/1000] Train Loss: 1.1385  |  Val Loss: 1.1451\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 147/1000] Train Loss: 1.1489  |  Val Loss: 1.1763\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 148/1000] Train Loss: 1.1504  |  Val Loss: 1.1887\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 149/1000] Train Loss: 1.1523  |  Val Loss: 1.1402\n",
      "Validation loss improved from 1.1410 to 1.1402.\n",
      "[Epoch 150/1000] Train Loss: 1.1549  |  Val Loss: 1.1877\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 151/1000] Train Loss: 1.1539  |  Val Loss: 1.1592\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 152/1000] Train Loss: 1.1509  |  Val Loss: 1.1570\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 153/1000] Train Loss: 1.1411  |  Val Loss: 1.1507\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 154/1000] Train Loss: 1.1521  |  Val Loss: 1.1332\n",
      "Validation loss improved from 1.1402 to 1.1332.\n",
      "[Epoch 155/1000] Train Loss: 1.1381  |  Val Loss: 1.1464\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 156/1000] Train Loss: 1.1356  |  Val Loss: 1.1447\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 157/1000] Train Loss: 1.1389  |  Val Loss: 1.1833\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 158/1000] Train Loss: 1.1470  |  Val Loss: 1.1356\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 159/1000] Train Loss: 1.1286  |  Val Loss: 1.1383\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 160/1000] Train Loss: 1.1337  |  Val Loss: 1.1421\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 161/1000] Train Loss: 1.1328  |  Val Loss: 1.1368\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 162/1000] Train Loss: 1.1368  |  Val Loss: 1.1514\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 163/1000] Train Loss: 1.1355  |  Val Loss: 1.1863\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 164/1000] Train Loss: 1.1568  |  Val Loss: 1.1328\n",
      "Validation loss improved from 1.1332 to 1.1328.\n",
      "[Epoch 165/1000] Train Loss: 1.1604  |  Val Loss: 1.2847\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 166/1000] Train Loss: 1.1742  |  Val Loss: 1.1487\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 167/1000] Train Loss: 1.1550  |  Val Loss: 1.1561\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 168/1000] Train Loss: 1.1396  |  Val Loss: 1.1553\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 169/1000] Train Loss: 1.1299  |  Val Loss: 1.1346\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 170/1000] Train Loss: 1.1489  |  Val Loss: 1.1456\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 171/1000] Train Loss: 1.1460  |  Val Loss: 1.1839\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 172/1000] Train Loss: 1.1315  |  Val Loss: 1.1232\n",
      "Validation loss improved from 1.1328 to 1.1232.\n",
      "[Epoch 173/1000] Train Loss: 1.1403  |  Val Loss: 1.1260\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 174/1000] Train Loss: 1.1566  |  Val Loss: 1.2016\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 175/1000] Train Loss: 1.1560  |  Val Loss: 1.1347\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 176/1000] Train Loss: 1.1317  |  Val Loss: 1.1463\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 177/1000] Train Loss: 1.1141  |  Val Loss: 1.1540\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 178/1000] Train Loss: 1.1259  |  Val Loss: 1.1551\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 179/1000] Train Loss: 1.1245  |  Val Loss: 1.1705\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 180/1000] Train Loss: 1.1363  |  Val Loss: 1.1231\n",
      "Validation loss improved from 1.1232 to 1.1231.\n",
      "[Epoch 181/1000] Train Loss: 1.1325  |  Val Loss: 1.1308\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 182/1000] Train Loss: 1.1176  |  Val Loss: 1.1148\n",
      "Validation loss improved from 1.1231 to 1.1148.\n",
      "[Epoch 183/1000] Train Loss: 1.1449  |  Val Loss: 1.1419\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 184/1000] Train Loss: 1.1161  |  Val Loss: 1.1314\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 185/1000] Train Loss: 1.1215  |  Val Loss: 1.1332\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 186/1000] Train Loss: 1.1415  |  Val Loss: 1.1409\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 187/1000] Train Loss: 1.1306  |  Val Loss: 1.1754\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 188/1000] Train Loss: 1.1435  |  Val Loss: 1.1339\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 189/1000] Train Loss: 1.1183  |  Val Loss: 1.1185\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 190/1000] Train Loss: 1.1114  |  Val Loss: 1.1386\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 191/1000] Train Loss: 1.1147  |  Val Loss: 1.1353\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 192/1000] Train Loss: 1.1433  |  Val Loss: 1.2277\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 193/1000] Train Loss: 1.1492  |  Val Loss: 1.1204\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 194/1000] Train Loss: 1.1093  |  Val Loss: 1.1271\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 195/1000] Train Loss: 1.1265  |  Val Loss: 1.1285\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 196/1000] Train Loss: 1.1098  |  Val Loss: 1.1328\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 197/1000] Train Loss: 1.1196  |  Val Loss: 1.1141\n",
      "Validation loss improved from 1.1148 to 1.1141.\n",
      "[Epoch 198/1000] Train Loss: 1.1042  |  Val Loss: 1.1273\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 199/1000] Train Loss: 1.1158  |  Val Loss: 1.1824\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 200/1000] Train Loss: 1.1413  |  Val Loss: 1.1063\n",
      "Validation loss improved from 1.1141 to 1.1063.\n",
      "[Epoch 201/1000] Train Loss: 1.1291  |  Val Loss: 1.1219\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 202/1000] Train Loss: 1.1144  |  Val Loss: 1.1278\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 203/1000] Train Loss: 1.1161  |  Val Loss: 1.1218\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 204/1000] Train Loss: 1.1179  |  Val Loss: 1.1978\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 205/1000] Train Loss: 1.1358  |  Val Loss: 1.1064\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 206/1000] Train Loss: 1.1136  |  Val Loss: 1.1193\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 207/1000] Train Loss: 1.1445  |  Val Loss: 1.2076\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 208/1000] Train Loss: 1.1403  |  Val Loss: 1.1273\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 209/1000] Train Loss: 1.1230  |  Val Loss: 1.1876\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 210/1000] Train Loss: 1.1100  |  Val Loss: 1.1209\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 211/1000] Train Loss: 1.1419  |  Val Loss: 1.1250\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 212/1000] Train Loss: 1.1096  |  Val Loss: 1.1428\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 213/1000] Train Loss: 1.1042  |  Val Loss: 1.1341\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 214/1000] Train Loss: 1.1127  |  Val Loss: 1.1977\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 215/1000] Train Loss: 1.1192  |  Val Loss: 1.1081\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 216/1000] Train Loss: 1.1073  |  Val Loss: 1.1205\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 217/1000] Train Loss: 1.1175  |  Val Loss: 1.1825\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 218/1000] Train Loss: 1.1151  |  Val Loss: 1.1243\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 219/1000] Train Loss: 1.1094  |  Val Loss: 1.1104\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 220/1000] Train Loss: 1.1097  |  Val Loss: 1.1165\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 221/1000] Train Loss: 1.1047  |  Val Loss: 1.1749\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 222/1000] Train Loss: 1.1123  |  Val Loss: 1.1229\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 223/1000] Train Loss: 1.1049  |  Val Loss: 1.1158\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 224/1000] Train Loss: 1.1064  |  Val Loss: 1.1540\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 225/1000] Train Loss: 1.0976  |  Val Loss: 1.1097\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 226/1000] Train Loss: 1.0949  |  Val Loss: 1.1148\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 227/1000] Train Loss: 1.1041  |  Val Loss: 1.1762\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 228/1000] Train Loss: 1.1125  |  Val Loss: 1.1183\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 229/1000] Train Loss: 1.0914  |  Val Loss: 1.1407\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 230/1000] Train Loss: 1.0939  |  Val Loss: 1.1123\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 231/1000] Train Loss: 1.1065  |  Val Loss: 1.1853\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 232/1000] Train Loss: 1.1291  |  Val Loss: 1.1360\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 233/1000] Train Loss: 1.0897  |  Val Loss: 1.1339\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 234/1000] Train Loss: 1.0998  |  Val Loss: 1.1080\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 235/1000] Train Loss: 1.0986  |  Val Loss: 1.1239\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 236/1000] Train Loss: 1.0948  |  Val Loss: 1.1352\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 237/1000] Train Loss: 1.0892  |  Val Loss: 1.1112\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 238/1000] Train Loss: 1.1003  |  Val Loss: 1.1407\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 239/1000] Train Loss: 1.0937  |  Val Loss: 1.1280\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 240/1000] Train Loss: 1.0903  |  Val Loss: 1.0975\n",
      "Validation loss improved from 1.1063 to 1.0975.\n",
      "[Epoch 241/1000] Train Loss: 1.1063  |  Val Loss: 1.1477\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 242/1000] Train Loss: 1.0928  |  Val Loss: 1.1299\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 243/1000] Train Loss: 1.1049  |  Val Loss: 1.1079\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 244/1000] Train Loss: 1.0945  |  Val Loss: 1.1432\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 245/1000] Train Loss: 1.0947  |  Val Loss: 1.1290\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 246/1000] Train Loss: 1.0966  |  Val Loss: 1.1752\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 247/1000] Train Loss: 1.1043  |  Val Loss: 1.1095\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 248/1000] Train Loss: 1.1113  |  Val Loss: 1.1292\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 249/1000] Train Loss: 1.1019  |  Val Loss: 1.1510\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 250/1000] Train Loss: 1.1085  |  Val Loss: 1.1230\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 251/1000] Train Loss: 1.1698  |  Val Loss: 1.1471\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 252/1000] Train Loss: 1.0831  |  Val Loss: 1.1032\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 253/1000] Train Loss: 1.1037  |  Val Loss: 1.1123\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 254/1000] Train Loss: 1.1019  |  Val Loss: 1.1458\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 255/1000] Train Loss: 1.1006  |  Val Loss: 1.1253\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 256/1000] Train Loss: 1.0950  |  Val Loss: 1.0914\n",
      "Validation loss improved from 1.0975 to 1.0914.\n",
      "[Epoch 257/1000] Train Loss: 1.0828  |  Val Loss: 1.1433\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 258/1000] Train Loss: 1.0876  |  Val Loss: 1.1104\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 259/1000] Train Loss: 1.0917  |  Val Loss: 1.1181\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 260/1000] Train Loss: 1.0803  |  Val Loss: 1.1071\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 261/1000] Train Loss: 1.0742  |  Val Loss: 1.1546\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 262/1000] Train Loss: 1.0926  |  Val Loss: 1.1182\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 263/1000] Train Loss: 1.0706  |  Val Loss: 1.1184\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 264/1000] Train Loss: 1.0787  |  Val Loss: 1.1078\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 265/1000] Train Loss: 1.0760  |  Val Loss: 1.1604\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 266/1000] Train Loss: 1.0894  |  Val Loss: 1.1043\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 267/1000] Train Loss: 1.0776  |  Val Loss: 1.1544\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 268/1000] Train Loss: 1.1000  |  Val Loss: 1.1353\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 269/1000] Train Loss: 1.0917  |  Val Loss: 1.1004\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 270/1000] Train Loss: 1.0784  |  Val Loss: 1.1098\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 271/1000] Train Loss: 1.0755  |  Val Loss: 1.1321\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 272/1000] Train Loss: 1.0707  |  Val Loss: 1.0940\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 273/1000] Train Loss: 1.0889  |  Val Loss: 1.1429\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 274/1000] Train Loss: 1.0735  |  Val Loss: 1.0979\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 275/1000] Train Loss: 1.0939  |  Val Loss: 1.1073\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 276/1000] Train Loss: 1.1331  |  Val Loss: 1.1934\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 277/1000] Train Loss: 1.0882  |  Val Loss: 1.1113\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 278/1000] Train Loss: 1.1248  |  Val Loss: 1.0965\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 279/1000] Train Loss: 1.0977  |  Val Loss: 1.1277\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 280/1000] Train Loss: 1.0986  |  Val Loss: 1.1280\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 281/1000] Train Loss: 1.1144  |  Val Loss: 1.1278\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 282/1000] Train Loss: 1.1266  |  Val Loss: 1.1390\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 283/1000] Train Loss: 1.0831  |  Val Loss: 1.0987\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 284/1000] Train Loss: 1.0770  |  Val Loss: 1.0895\n",
      "Validation loss improved from 1.0914 to 1.0895.\n",
      "[Epoch 285/1000] Train Loss: 1.0950  |  Val Loss: 1.1541\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 286/1000] Train Loss: 1.0767  |  Val Loss: 1.0986\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 287/1000] Train Loss: 1.0845  |  Val Loss: 1.0880\n",
      "Validation loss improved from 1.0895 to 1.0880.\n",
      "[Epoch 288/1000] Train Loss: 1.0718  |  Val Loss: 1.1691\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 289/1000] Train Loss: 1.1096  |  Val Loss: 1.1194\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 290/1000] Train Loss: 1.0893  |  Val Loss: 1.0923\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 291/1000] Train Loss: 1.0920  |  Val Loss: 1.2152\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 292/1000] Train Loss: 1.1183  |  Val Loss: 1.1176\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 293/1000] Train Loss: 1.0899  |  Val Loss: 1.2312\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 294/1000] Train Loss: 1.0878  |  Val Loss: 1.1559\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 295/1000] Train Loss: 1.1452  |  Val Loss: 1.2001\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 296/1000] Train Loss: 1.0992  |  Val Loss: 1.1143\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 297/1000] Train Loss: 1.0860  |  Val Loss: 1.1161\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 298/1000] Train Loss: 1.0756  |  Val Loss: 1.1195\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 299/1000] Train Loss: 1.0740  |  Val Loss: 1.1399\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 300/1000] Train Loss: 1.0855  |  Val Loss: 1.1309\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 301/1000] Train Loss: 1.1035  |  Val Loss: 1.0925\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 302/1000] Train Loss: 1.1154  |  Val Loss: 1.2049\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 303/1000] Train Loss: 1.0861  |  Val Loss: 1.0985\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 304/1000] Train Loss: 1.0972  |  Val Loss: 1.0993\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 305/1000] Train Loss: 1.0862  |  Val Loss: 1.1190\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 306/1000] Train Loss: 1.0597  |  Val Loss: 1.1335\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 307/1000] Train Loss: 1.0822  |  Val Loss: 1.0996\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 308/1000] Train Loss: 1.1005  |  Val Loss: 1.1148\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 309/1000] Train Loss: 1.0862  |  Val Loss: 1.1358\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 310/1000] Train Loss: 1.0779  |  Val Loss: 1.0988\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 311/1000] Train Loss: 1.0611  |  Val Loss: 1.1120\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 312/1000] Train Loss: 1.0688  |  Val Loss: 1.1168\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 313/1000] Train Loss: 1.0925  |  Val Loss: 1.0932\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 314/1000] Train Loss: 1.0927  |  Val Loss: 1.1364\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 315/1000] Train Loss: 1.0626  |  Val Loss: 1.1115\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 316/1000] Train Loss: 1.0944  |  Val Loss: 1.0934\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 317/1000] Train Loss: 1.0879  |  Val Loss: 1.1670\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 318/1000] Train Loss: 1.0671  |  Val Loss: 1.0898\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 319/1000] Train Loss: 1.0647  |  Val Loss: 1.1154\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 320/1000] Train Loss: 1.0664  |  Val Loss: 1.1570\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 321/1000] Train Loss: 1.0846  |  Val Loss: 1.0877\n",
      "Validation loss improved from 1.0880 to 1.0877.\n",
      "[Epoch 322/1000] Train Loss: 1.0693  |  Val Loss: 1.2777\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 323/1000] Train Loss: 1.1302  |  Val Loss: 1.1485\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 324/1000] Train Loss: 1.1286  |  Val Loss: 1.2681\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 325/1000] Train Loss: 1.0995  |  Val Loss: 1.0890\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 326/1000] Train Loss: 1.0616  |  Val Loss: 1.1908\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 327/1000] Train Loss: 1.0748  |  Val Loss: 1.0980\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 328/1000] Train Loss: 1.0772  |  Val Loss: 1.1056\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 329/1000] Train Loss: 1.0758  |  Val Loss: 1.1416\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 330/1000] Train Loss: 1.0670  |  Val Loss: 1.1020\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 331/1000] Train Loss: 1.0792  |  Val Loss: 1.1458\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 332/1000] Train Loss: 1.0766  |  Val Loss: 1.1184\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 333/1000] Train Loss: 1.0737  |  Val Loss: 1.0894\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 334/1000] Train Loss: 1.0705  |  Val Loss: 1.1175\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 335/1000] Train Loss: 1.0588  |  Val Loss: 1.0976\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 336/1000] Train Loss: 1.0758  |  Val Loss: 1.1074\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 337/1000] Train Loss: 1.0566  |  Val Loss: 1.1054\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 338/1000] Train Loss: 1.0593  |  Val Loss: 1.1096\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 339/1000] Train Loss: 1.0590  |  Val Loss: 1.0864\n",
      "Validation loss improved from 1.0877 to 1.0864.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 340/1000] Train Loss: 1.0574  |  Val Loss: 1.1020\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 341/1000] Train Loss: 1.0623  |  Val Loss: 1.1120\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 342/1000] Train Loss: 1.0675  |  Val Loss: 1.0937\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 343/1000] Train Loss: 1.0504  |  Val Loss: 1.1062\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 344/1000] Train Loss: 1.0501  |  Val Loss: 1.0892\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 345/1000] Train Loss: 1.0622  |  Val Loss: 1.0995\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 346/1000] Train Loss: 1.0591  |  Val Loss: 1.1494\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 347/1000] Train Loss: 1.0819  |  Val Loss: 1.1071\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 348/1000] Train Loss: 1.1150  |  Val Loss: 1.2510\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 349/1000] Train Loss: 1.1351  |  Val Loss: 1.1145\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 350/1000] Train Loss: 1.0812  |  Val Loss: 1.1069\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 351/1000] Train Loss: 1.0748  |  Val Loss: 1.1944\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 352/1000] Train Loss: 1.1001  |  Val Loss: 1.0898\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 353/1000] Train Loss: 1.0746  |  Val Loss: 1.1539\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 354/1000] Train Loss: 1.0527  |  Val Loss: 1.0875\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 355/1000] Train Loss: 1.0650  |  Val Loss: 1.1662\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 356/1000] Train Loss: 1.0610  |  Val Loss: 1.0975\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 357/1000] Train Loss: 1.0888  |  Val Loss: 1.1506\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 358/1000] Train Loss: 1.0714  |  Val Loss: 1.0906\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 359/1000] Train Loss: 1.0624  |  Val Loss: 1.0925\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 360/1000] Train Loss: 1.0608  |  Val Loss: 1.0798\n",
      "Validation loss improved from 1.0864 to 1.0798.\n",
      "[Epoch 361/1000] Train Loss: 1.0595  |  Val Loss: 1.1492\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 362/1000] Train Loss: 1.0811  |  Val Loss: 1.0830\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 363/1000] Train Loss: 1.0930  |  Val Loss: 1.1943\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 364/1000] Train Loss: 1.0814  |  Val Loss: 1.1067\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 365/1000] Train Loss: 1.0614  |  Val Loss: 1.0828\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 366/1000] Train Loss: 1.0673  |  Val Loss: 1.1985\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 367/1000] Train Loss: 1.1028  |  Val Loss: 1.0793\n",
      "Validation loss improved from 1.0798 to 1.0793.\n",
      "[Epoch 368/1000] Train Loss: 1.0834  |  Val Loss: 1.2834\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 369/1000] Train Loss: 1.0855  |  Val Loss: 1.1342\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 370/1000] Train Loss: 1.1026  |  Val Loss: 1.2038\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 371/1000] Train Loss: 1.0670  |  Val Loss: 1.1000\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 372/1000] Train Loss: 1.0711  |  Val Loss: 1.1006\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 373/1000] Train Loss: 1.0500  |  Val Loss: 1.0992\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 374/1000] Train Loss: 1.0403  |  Val Loss: 1.0865\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 375/1000] Train Loss: 1.0468  |  Val Loss: 1.1500\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 376/1000] Train Loss: 1.0574  |  Val Loss: 1.0893\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 377/1000] Train Loss: 1.0484  |  Val Loss: 1.1104\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 378/1000] Train Loss: 1.0533  |  Val Loss: 1.0752\n",
      "Validation loss improved from 1.0793 to 1.0752.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 379/1000] Train Loss: 1.0505  |  Val Loss: 1.0875\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 380/1000] Train Loss: 1.0706  |  Val Loss: 1.1049\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 381/1000] Train Loss: 1.0601  |  Val Loss: 1.1057\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 382/1000] Train Loss: 1.0813  |  Val Loss: 1.0788\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 383/1000] Train Loss: 1.0719  |  Val Loss: 1.1548\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 384/1000] Train Loss: 1.0810  |  Val Loss: 1.1196\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 385/1000] Train Loss: 1.0936  |  Val Loss: 1.0959\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 386/1000] Train Loss: 1.1606  |  Val Loss: 1.2935\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 387/1000] Train Loss: 1.1161  |  Val Loss: 1.1257\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 388/1000] Train Loss: 1.0913  |  Val Loss: 1.2247\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 389/1000] Train Loss: 1.0840  |  Val Loss: 1.0771\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 390/1000] Train Loss: 1.0732  |  Val Loss: 1.1272\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 391/1000] Train Loss: 1.0682  |  Val Loss: 1.0968\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 392/1000] Train Loss: 1.0582  |  Val Loss: 1.0789\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 393/1000] Train Loss: 1.1062  |  Val Loss: 1.2076\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 394/1000] Train Loss: 1.1016  |  Val Loss: 1.1037\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 395/1000] Train Loss: 1.1214  |  Val Loss: 1.2875\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 396/1000] Train Loss: 1.1129  |  Val Loss: 1.0842\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 397/1000] Train Loss: 1.0627  |  Val Loss: 1.1804\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 398/1000] Train Loss: 1.0554  |  Val Loss: 1.0831\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 399/1000] Train Loss: 1.0682  |  Val Loss: 1.1263\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 400/1000] Train Loss: 1.0604  |  Val Loss: 1.0854\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 401/1000] Train Loss: 1.0429  |  Val Loss: 1.0935\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 402/1000] Train Loss: 1.0382  |  Val Loss: 1.0867\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 403/1000] Train Loss: 1.0576  |  Val Loss: 1.1237\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 404/1000] Train Loss: 1.0472  |  Val Loss: 1.0863\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 405/1000] Train Loss: 1.0596  |  Val Loss: 1.1477\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 406/1000] Train Loss: 1.0530  |  Val Loss: 1.0863\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 407/1000] Train Loss: 1.0381  |  Val Loss: 1.0796\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 408/1000] Train Loss: 1.0640  |  Val Loss: 1.1038\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 409/1000] Train Loss: 1.0437  |  Val Loss: 1.0926\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 410/1000] Train Loss: 1.0732  |  Val Loss: 1.0837\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 411/1000] Train Loss: 1.0487  |  Val Loss: 1.1462\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 412/1000] Train Loss: 1.0494  |  Val Loss: 1.1049\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 413/1000] Train Loss: 1.0726  |  Val Loss: 1.1382\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 414/1000] Train Loss: 1.0532  |  Val Loss: 1.0772\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 415/1000] Train Loss: 1.0400  |  Val Loss: 1.1097\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 416/1000] Train Loss: 1.0449  |  Val Loss: 1.0864\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 417/1000] Train Loss: 1.0443  |  Val Loss: 1.0866\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 418/1000] Train Loss: 1.0419  |  Val Loss: 1.0917\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 419/1000] Train Loss: 1.0362  |  Val Loss: 1.0912\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 420/1000] Train Loss: 1.0361  |  Val Loss: 1.0669\n",
      "Validation loss improved from 1.0752 to 1.0669.\n",
      "[Epoch 421/1000] Train Loss: 1.0503  |  Val Loss: 1.0935\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 422/1000] Train Loss: 1.0347  |  Val Loss: 1.0790\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 423/1000] Train Loss: 1.0399  |  Val Loss: 1.1032\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 424/1000] Train Loss: 1.0400  |  Val Loss: 1.0799\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 425/1000] Train Loss: 1.0370  |  Val Loss: 1.1191\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 426/1000] Train Loss: 1.0422  |  Val Loss: 1.1073\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 427/1000] Train Loss: 1.0359  |  Val Loss: 1.0720\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 428/1000] Train Loss: 1.0366  |  Val Loss: 1.1220\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 429/1000] Train Loss: 1.0501  |  Val Loss: 1.0958\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 430/1000] Train Loss: 1.0718  |  Val Loss: 1.1606\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 431/1000] Train Loss: 1.0462  |  Val Loss: 1.0680\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 432/1000] Train Loss: 1.0457  |  Val Loss: 1.1117\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 433/1000] Train Loss: 1.0401  |  Val Loss: 1.1079\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 434/1000] Train Loss: 1.0496  |  Val Loss: 1.0718\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 435/1000] Train Loss: 1.0317  |  Val Loss: 1.1098\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 436/1000] Train Loss: 1.0377  |  Val Loss: 1.0799\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 437/1000] Train Loss: 1.0454  |  Val Loss: 1.1267\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 438/1000] Train Loss: 1.0438  |  Val Loss: 1.0712\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 439/1000] Train Loss: 1.0806  |  Val Loss: 1.1149\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 440/1000] Train Loss: 1.0834  |  Val Loss: 1.1342\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 441/1000] Train Loss: 1.0745  |  Val Loss: 1.0597\n",
      "Validation loss improved from 1.0669 to 1.0597.\n",
      "[Epoch 442/1000] Train Loss: 1.0524  |  Val Loss: 1.2127\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 443/1000] Train Loss: 1.0736  |  Val Loss: 1.0838\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 444/1000] Train Loss: 1.0667  |  Val Loss: 1.1230\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 445/1000] Train Loss: 1.0353  |  Val Loss: 1.0757\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 446/1000] Train Loss: 1.0435  |  Val Loss: 1.0783\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 447/1000] Train Loss: 1.0283  |  Val Loss: 1.0736\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 448/1000] Train Loss: 1.0530  |  Val Loss: 1.1193\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 449/1000] Train Loss: 1.0340  |  Val Loss: 1.0754\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 450/1000] Train Loss: 1.0328  |  Val Loss: 1.0948\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 451/1000] Train Loss: 1.0240  |  Val Loss: 1.0708\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 452/1000] Train Loss: 1.0440  |  Val Loss: 1.1339\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 453/1000] Train Loss: 1.0380  |  Val Loss: 1.0608\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 454/1000] Train Loss: 1.0362  |  Val Loss: 1.0760\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 455/1000] Train Loss: 1.0454  |  Val Loss: 1.1280\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 456/1000] Train Loss: 1.0355  |  Val Loss: 1.0625\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 457/1000] Train Loss: 1.0381  |  Val Loss: 1.1264\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 458/1000] Train Loss: 1.0549  |  Val Loss: 1.0678\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 459/1000] Train Loss: 1.0270  |  Val Loss: 1.0690\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 460/1000] Train Loss: 1.0339  |  Val Loss: 1.1071\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 461/1000] Train Loss: 1.0360  |  Val Loss: 1.0650\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 462/1000] Train Loss: 1.0268  |  Val Loss: 1.1038\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 463/1000] Train Loss: 1.0308  |  Val Loss: 1.0693\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 464/1000] Train Loss: 1.0261  |  Val Loss: 1.0828\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 465/1000] Train Loss: 1.0305  |  Val Loss: 1.1099\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 466/1000] Train Loss: 1.0351  |  Val Loss: 1.0747\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 467/1000] Train Loss: 1.0292  |  Val Loss: 1.0790\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 468/1000] Train Loss: 1.0377  |  Val Loss: 1.0871\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 469/1000] Train Loss: 1.0289  |  Val Loss: 1.0525\n",
      "Validation loss improved from 1.0597 to 1.0525.\n",
      "[Epoch 470/1000] Train Loss: 1.0471  |  Val Loss: 1.1540\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 471/1000] Train Loss: 1.0445  |  Val Loss: 1.0713\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 472/1000] Train Loss: 1.0447  |  Val Loss: 1.0721\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 473/1000] Train Loss: 1.0287  |  Val Loss: 1.1299\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 474/1000] Train Loss: 1.0562  |  Val Loss: 1.1009\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 475/1000] Train Loss: 1.0476  |  Val Loss: 1.0590\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 476/1000] Train Loss: 1.0576  |  Val Loss: 1.1134\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 477/1000] Train Loss: 1.0187  |  Val Loss: 1.0954\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 478/1000] Train Loss: 1.0226  |  Val Loss: 1.0726\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 479/1000] Train Loss: 1.0454  |  Val Loss: 1.1212\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 480/1000] Train Loss: 1.0353  |  Val Loss: 1.0761\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 481/1000] Train Loss: 1.0124  |  Val Loss: 1.1179\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 482/1000] Train Loss: 1.0359  |  Val Loss: 1.0665\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 483/1000] Train Loss: 1.0383  |  Val Loss: 1.0504\n",
      "Validation loss improved from 1.0525 to 1.0504.\n",
      "[Epoch 484/1000] Train Loss: 1.0437  |  Val Loss: 1.2138\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 485/1000] Train Loss: 1.0736  |  Val Loss: 1.0726\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 486/1000] Train Loss: 1.0502  |  Val Loss: 1.0970\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 487/1000] Train Loss: 1.0382  |  Val Loss: 1.1648\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 488/1000] Train Loss: 1.0588  |  Val Loss: 1.0730\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 489/1000] Train Loss: 1.0634  |  Val Loss: 1.1001\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 490/1000] Train Loss: 1.0327  |  Val Loss: 1.0756\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 491/1000] Train Loss: 1.0290  |  Val Loss: 1.0954\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 492/1000] Train Loss: 1.0308  |  Val Loss: 1.0806\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 493/1000] Train Loss: 1.0417  |  Val Loss: 1.1256\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 494/1000] Train Loss: 1.0253  |  Val Loss: 1.0758\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 495/1000] Train Loss: 1.0320  |  Val Loss: 1.1073\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 496/1000] Train Loss: 1.0176  |  Val Loss: 1.0593\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 497/1000] Train Loss: 1.0278  |  Val Loss: 1.0838\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 498/1000] Train Loss: 1.0352  |  Val Loss: 1.1440\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 499/1000] Train Loss: 1.0272  |  Val Loss: 1.0686\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 500/1000] Train Loss: 1.0384  |  Val Loss: 1.0898\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 501/1000] Train Loss: 1.0201  |  Val Loss: 1.0750\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 502/1000] Train Loss: 1.0195  |  Val Loss: 1.0673\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 503/1000] Train Loss: 1.0294  |  Val Loss: 1.1754\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 504/1000] Train Loss: 1.0656  |  Val Loss: 1.0914\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 505/1000] Train Loss: 1.0590  |  Val Loss: 1.1476\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 506/1000] Train Loss: 1.0646  |  Val Loss: 1.1380\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 507/1000] Train Loss: 1.0796  |  Val Loss: 1.0730\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 508/1000] Train Loss: 1.0683  |  Val Loss: 1.1297\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 509/1000] Train Loss: 1.0524  |  Val Loss: 1.0966\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 510/1000] Train Loss: 1.0479  |  Val Loss: 1.0574\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 511/1000] Train Loss: 1.0379  |  Val Loss: 1.1052\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 512/1000] Train Loss: 1.0287  |  Val Loss: 1.0679\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 513/1000] Train Loss: 1.0252  |  Val Loss: 1.0798\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 514/1000] Train Loss: 1.0289  |  Val Loss: 1.1213\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 515/1000] Train Loss: 1.0294  |  Val Loss: 1.0809\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 516/1000] Train Loss: 1.0146  |  Val Loss: 1.0903\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 517/1000] Train Loss: 1.0233  |  Val Loss: 1.1015\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 518/1000] Train Loss: 1.0194  |  Val Loss: 1.0745\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 519/1000] Train Loss: 1.0353  |  Val Loss: 1.0595\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 520/1000] Train Loss: 1.0115  |  Val Loss: 1.0916\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 521/1000] Train Loss: 1.0269  |  Val Loss: 1.0800\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 522/1000] Train Loss: 1.0816  |  Val Loss: 1.1423\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 523/1000] Train Loss: 1.0334  |  Val Loss: 1.0799\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 524/1000] Train Loss: 1.0346  |  Val Loss: 1.0891\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 525/1000] Train Loss: 1.0293  |  Val Loss: 1.0825\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 526/1000] Train Loss: 1.0206  |  Val Loss: 1.0666\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 527/1000] Train Loss: 1.0170  |  Val Loss: 1.1017\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 528/1000] Train Loss: 1.0178  |  Val Loss: 1.0522\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 529/1000] Train Loss: 1.0160  |  Val Loss: 1.0651\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 530/1000] Train Loss: 1.0194  |  Val Loss: 1.0719\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 531/1000] Train Loss: 1.0157  |  Val Loss: 1.0720\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 532/1000] Train Loss: 1.0120  |  Val Loss: 1.0591\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 533/1000] Train Loss: 1.0392  |  Val Loss: 1.0541\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 534/1000] Train Loss: 1.0041  |  Val Loss: 1.0820\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 535/1000] Train Loss: 1.0084  |  Val Loss: 1.0608\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 536/1000] Train Loss: 1.0174  |  Val Loss: 1.1827\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 537/1000] Train Loss: 1.0380  |  Val Loss: 1.0725\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 538/1000] Train Loss: 1.0229  |  Val Loss: 1.1296\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 539/1000] Train Loss: 1.0377  |  Val Loss: 1.0864\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 540/1000] Train Loss: 1.0472  |  Val Loss: 1.0764\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 541/1000] Train Loss: 1.0345  |  Val Loss: 1.1131\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 542/1000] Train Loss: 1.0141  |  Val Loss: 1.0625\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 543/1000] Train Loss: 1.0034  |  Val Loss: 1.1016\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 544/1000] Train Loss: 1.0403  |  Val Loss: 1.1366\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 545/1000] Train Loss: 1.0386  |  Val Loss: 1.0671\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 546/1000] Train Loss: 1.0267  |  Val Loss: 1.2028\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 547/1000] Train Loss: 1.0513  |  Val Loss: 1.0642\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 548/1000] Train Loss: 1.0040  |  Val Loss: 1.1128\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 549/1000] Train Loss: 1.0175  |  Val Loss: 1.0550\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 550/1000] Train Loss: 1.0026  |  Val Loss: 1.1143\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 551/1000] Train Loss: 1.0188  |  Val Loss: 1.0699\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 552/1000] Train Loss: 1.0230  |  Val Loss: 1.0654\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 553/1000] Train Loss: 1.0163  |  Val Loss: 1.0922\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 554/1000] Train Loss: 1.0025  |  Val Loss: 1.0879\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 555/1000] Train Loss: 1.0489  |  Val Loss: 1.1012\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 556/1000] Train Loss: 1.0323  |  Val Loss: 1.0972\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 557/1000] Train Loss: 1.0076  |  Val Loss: 1.0998\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 558/1000] Train Loss: 1.0113  |  Val Loss: 1.0406\n",
      "Validation loss improved from 1.0504 to 1.0406.\n",
      "[Epoch 559/1000] Train Loss: 1.0065  |  Val Loss: 1.1339\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 560/1000] Train Loss: 1.0261  |  Val Loss: 1.0556\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 561/1000] Train Loss: 1.0092  |  Val Loss: 1.0552\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 562/1000] Train Loss: 1.0129  |  Val Loss: 1.1340\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 563/1000] Train Loss: 1.0230  |  Val Loss: 1.0725\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 564/1000] Train Loss: 1.0043  |  Val Loss: 1.0684\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 565/1000] Train Loss: 1.0178  |  Val Loss: 1.1146\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 566/1000] Train Loss: 1.0295  |  Val Loss: 1.0607\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 567/1000] Train Loss: 1.0074  |  Val Loss: 1.1386\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 568/1000] Train Loss: 1.0261  |  Val Loss: 1.1171\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 569/1000] Train Loss: 1.0354  |  Val Loss: 1.0598\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 570/1000] Train Loss: 1.0165  |  Val Loss: 1.0649\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 571/1000] Train Loss: 1.0122  |  Val Loss: 1.0635\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 572/1000] Train Loss: 1.0037  |  Val Loss: 1.0552\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 573/1000] Train Loss: 1.0073  |  Val Loss: 1.0670\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 574/1000] Train Loss: 1.0038  |  Val Loss: 1.1106\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 575/1000] Train Loss: 1.0119  |  Val Loss: 1.0589\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 576/1000] Train Loss: 1.0190  |  Val Loss: 1.0504\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 577/1000] Train Loss: 1.0273  |  Val Loss: 1.0817\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 578/1000] Train Loss: 1.0135  |  Val Loss: 1.0706\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 579/1000] Train Loss: 0.9996  |  Val Loss: 1.0595\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 580/1000] Train Loss: 0.9986  |  Val Loss: 1.1248\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 581/1000] Train Loss: 1.0166  |  Val Loss: 1.0521\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 582/1000] Train Loss: 1.0005  |  Val Loss: 1.0705\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 583/1000] Train Loss: 0.9952  |  Val Loss: 1.0592\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 584/1000] Train Loss: 1.0009  |  Val Loss: 1.0762\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 585/1000] Train Loss: 0.9911  |  Val Loss: 1.0652\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 586/1000] Train Loss: 1.0021  |  Val Loss: 1.1017\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 587/1000] Train Loss: 1.0046  |  Val Loss: 1.0646\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 588/1000] Train Loss: 0.9975  |  Val Loss: 1.0727\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 589/1000] Train Loss: 1.0103  |  Val Loss: 1.0832\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 590/1000] Train Loss: 1.0209  |  Val Loss: 1.1425\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 591/1000] Train Loss: 1.0053  |  Val Loss: 1.0800\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 592/1000] Train Loss: 1.0275  |  Val Loss: 1.0922\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 593/1000] Train Loss: 1.0020  |  Val Loss: 1.0681\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 594/1000] Train Loss: 1.0035  |  Val Loss: 1.0611\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 595/1000] Train Loss: 0.9952  |  Val Loss: 1.0414\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 596/1000] Train Loss: 1.0045  |  Val Loss: 1.1052\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 597/1000] Train Loss: 0.9956  |  Val Loss: 1.0525\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 598/1000] Train Loss: 1.0061  |  Val Loss: 1.0743\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 599/1000] Train Loss: 0.9920  |  Val Loss: 1.0546\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 600/1000] Train Loss: 0.9892  |  Val Loss: 1.1283\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 601/1000] Train Loss: 1.0135  |  Val Loss: 1.0552\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 602/1000] Train Loss: 1.0156  |  Val Loss: 1.0763\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 603/1000] Train Loss: 1.0044  |  Val Loss: 1.1094\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 604/1000] Train Loss: 1.0228  |  Val Loss: 1.0413\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 605/1000] Train Loss: 1.0216  |  Val Loss: 1.1396\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 606/1000] Train Loss: 1.0264  |  Val Loss: 1.0582\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 607/1000] Train Loss: 0.9991  |  Val Loss: 1.0530\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 608/1000] Train Loss: 1.0106  |  Val Loss: 1.1935\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 609/1000] Train Loss: 1.0130  |  Val Loss: 1.0804\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 610/1000] Train Loss: 1.0961  |  Val Loss: 1.1325\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 611/1000] Train Loss: 1.0264  |  Val Loss: 1.0839\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 612/1000] Train Loss: 1.0352  |  Val Loss: 1.0431\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 613/1000] Train Loss: 1.0125  |  Val Loss: 1.1988\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 614/1000] Train Loss: 1.0810  |  Val Loss: 1.0839\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 615/1000] Train Loss: 1.0697  |  Val Loss: 1.1852\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 616/1000] Train Loss: 1.0239  |  Val Loss: 1.0496\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 617/1000] Train Loss: 1.0283  |  Val Loss: 1.0532\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 618/1000] Train Loss: 0.9900  |  Val Loss: 1.0497\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 619/1000] Train Loss: 0.9887  |  Val Loss: 1.0713\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 620/1000] Train Loss: 0.9988  |  Val Loss: 1.0458\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 621/1000] Train Loss: 0.9880  |  Val Loss: 1.0814\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 622/1000] Train Loss: 1.0002  |  Val Loss: 1.0430\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 623/1000] Train Loss: 1.0031  |  Val Loss: 1.0839\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 624/1000] Train Loss: 0.9925  |  Val Loss: 1.0557\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 625/1000] Train Loss: 0.9908  |  Val Loss: 1.0459\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 626/1000] Train Loss: 1.0006  |  Val Loss: 1.0584\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 627/1000] Train Loss: 0.9902  |  Val Loss: 1.0842\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 628/1000] Train Loss: 0.9840  |  Val Loss: 1.0606\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 629/1000] Train Loss: 0.9955  |  Val Loss: 1.0421\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 630/1000] Train Loss: 1.0035  |  Val Loss: 1.0369\n",
      "Validation loss improved from 1.0406 to 1.0369.\n",
      "[Epoch 631/1000] Train Loss: 1.0283  |  Val Loss: 1.1688\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 632/1000] Train Loss: 1.0230  |  Val Loss: 1.0538\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 633/1000] Train Loss: 1.0051  |  Val Loss: 1.1218\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 634/1000] Train Loss: 1.0473  |  Val Loss: 1.0622\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 635/1000] Train Loss: 0.9834  |  Val Loss: 1.0904\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 636/1000] Train Loss: 0.9879  |  Val Loss: 1.0448\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 637/1000] Train Loss: 0.9908  |  Val Loss: 1.0584\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 638/1000] Train Loss: 0.9893  |  Val Loss: 1.0609\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 639/1000] Train Loss: 0.9826  |  Val Loss: 1.0476\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 640/1000] Train Loss: 0.9963  |  Val Loss: 1.0561\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 641/1000] Train Loss: 0.9873  |  Val Loss: 1.0788\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 642/1000] Train Loss: 0.9848  |  Val Loss: 1.0430\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 643/1000] Train Loss: 1.0075  |  Val Loss: 1.1120\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 644/1000] Train Loss: 0.9870  |  Val Loss: 1.0424\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 645/1000] Train Loss: 1.0051  |  Val Loss: 1.1612\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 646/1000] Train Loss: 1.0262  |  Val Loss: 1.0536\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 647/1000] Train Loss: 1.0008  |  Val Loss: 1.0367\n",
      "Validation loss improved from 1.0369 to 1.0367.\n",
      "[Epoch 648/1000] Train Loss: 1.0087  |  Val Loss: 1.0981\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 649/1000] Train Loss: 1.0045  |  Val Loss: 1.0425\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 650/1000] Train Loss: 0.9981  |  Val Loss: 1.1283\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 651/1000] Train Loss: 0.9954  |  Val Loss: 1.0624\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 652/1000] Train Loss: 1.0091  |  Val Loss: 1.1159\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 653/1000] Train Loss: 0.9807  |  Val Loss: 1.0410\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 654/1000] Train Loss: 0.9794  |  Val Loss: 1.0578\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 655/1000] Train Loss: 0.9744  |  Val Loss: 1.0281\n",
      "Validation loss improved from 1.0367 to 1.0281.\n",
      "[Epoch 656/1000] Train Loss: 1.0222  |  Val Loss: 1.0893\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 657/1000] Train Loss: 0.9975  |  Val Loss: 1.1013\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 658/1000] Train Loss: 1.0122  |  Val Loss: 1.0478\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 659/1000] Train Loss: 0.9857  |  Val Loss: 1.1206\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 660/1000] Train Loss: 0.9927  |  Val Loss: 1.0484\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 661/1000] Train Loss: 0.9895  |  Val Loss: 1.0524\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 662/1000] Train Loss: 0.9831  |  Val Loss: 1.0874\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 663/1000] Train Loss: 0.9945  |  Val Loss: 1.0332\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 664/1000] Train Loss: 0.9965  |  Val Loss: 1.1069\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 665/1000] Train Loss: 1.0021  |  Val Loss: 1.0663\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 666/1000] Train Loss: 0.9876  |  Val Loss: 1.0699\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 667/1000] Train Loss: 0.9823  |  Val Loss: 1.0850\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 668/1000] Train Loss: 1.0020  |  Val Loss: 1.0467\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 669/1000] Train Loss: 1.0060  |  Val Loss: 1.1539\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 670/1000] Train Loss: 1.0163  |  Val Loss: 1.0438\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 671/1000] Train Loss: 0.9774  |  Val Loss: 1.0950\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 672/1000] Train Loss: 0.9874  |  Val Loss: 1.0309\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 673/1000] Train Loss: 0.9824  |  Val Loss: 1.1112\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 674/1000] Train Loss: 0.9866  |  Val Loss: 1.0342\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 675/1000] Train Loss: 0.9762  |  Val Loss: 1.0395\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 676/1000] Train Loss: 0.9824  |  Val Loss: 1.1240\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 677/1000] Train Loss: 1.0264  |  Val Loss: 1.0391\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 678/1000] Train Loss: 0.9846  |  Val Loss: 1.0420\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 679/1000] Train Loss: 0.9923  |  Val Loss: 1.1352\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 680/1000] Train Loss: 1.0101  |  Val Loss: 1.0438\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 681/1000] Train Loss: 0.9823  |  Val Loss: 1.0460\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 682/1000] Train Loss: 0.9787  |  Val Loss: 1.0407\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 683/1000] Train Loss: 0.9716  |  Val Loss: 1.0573\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 684/1000] Train Loss: 0.9704  |  Val Loss: 1.0403\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 685/1000] Train Loss: 0.9760  |  Val Loss: 1.0720\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 686/1000] Train Loss: 0.9865  |  Val Loss: 1.0363\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 687/1000] Train Loss: 0.9717  |  Val Loss: 1.0539\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 688/1000] Train Loss: 0.9765  |  Val Loss: 1.0713\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 689/1000] Train Loss: 0.9838  |  Val Loss: 1.0334\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 690/1000] Train Loss: 0.9626  |  Val Loss: 1.0403\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 691/1000] Train Loss: 0.9801  |  Val Loss: 1.0814\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 692/1000] Train Loss: 0.9975  |  Val Loss: 1.0216\n",
      "Validation loss improved from 1.0281 to 1.0216.\n",
      "[Epoch 693/1000] Train Loss: 0.9672  |  Val Loss: 1.1007\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 694/1000] Train Loss: 0.9742  |  Val Loss: 1.0298\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 695/1000] Train Loss: 0.9976  |  Val Loss: 1.0368\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 696/1000] Train Loss: 0.9692  |  Val Loss: 1.0355\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 697/1000] Train Loss: 0.9897  |  Val Loss: 1.0584\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 698/1000] Train Loss: 0.9711  |  Val Loss: 1.0506\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 699/1000] Train Loss: 1.0142  |  Val Loss: 1.0278\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 700/1000] Train Loss: 0.9905  |  Val Loss: 1.1560\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 701/1000] Train Loss: 1.0027  |  Val Loss: 1.0424\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 702/1000] Train Loss: 0.9769  |  Val Loss: 1.0572\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 703/1000] Train Loss: 0.9850  |  Val Loss: 1.1381\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 704/1000] Train Loss: 1.0316  |  Val Loss: 1.0368\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 705/1000] Train Loss: 1.0176  |  Val Loss: 1.0254\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 706/1000] Train Loss: 1.0026  |  Val Loss: 1.1068\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 707/1000] Train Loss: 0.9710  |  Val Loss: 1.0543\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 708/1000] Train Loss: 0.9805  |  Val Loss: 1.0611\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 709/1000] Train Loss: 0.9885  |  Val Loss: 1.1121\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 710/1000] Train Loss: 0.9961  |  Val Loss: 1.0280\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 711/1000] Train Loss: 0.9688  |  Val Loss: 1.0399\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 712/1000] Train Loss: 0.9675  |  Val Loss: 1.0611\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 713/1000] Train Loss: 0.9553  |  Val Loss: 1.0323\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 714/1000] Train Loss: 0.9877  |  Val Loss: 1.0409\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 715/1000] Train Loss: 0.9702  |  Val Loss: 1.0347\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 716/1000] Train Loss: 0.9883  |  Val Loss: 1.0752\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 717/1000] Train Loss: 0.9628  |  Val Loss: 1.0489\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 718/1000] Train Loss: 0.9552  |  Val Loss: 1.0538\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 719/1000] Train Loss: 0.9493  |  Val Loss: 1.0243\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 720/1000] Train Loss: 0.9712  |  Val Loss: 1.0547\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 721/1000] Train Loss: 0.9622  |  Val Loss: 1.0456\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 722/1000] Train Loss: 0.9717  |  Val Loss: 1.0245\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 723/1000] Train Loss: 0.9462  |  Val Loss: 1.0762\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 724/1000] Train Loss: 0.9647  |  Val Loss: 1.0170\n",
      "Validation loss improved from 1.0216 to 1.0170.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 725/1000] Train Loss: 0.9833  |  Val Loss: 1.0458\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 726/1000] Train Loss: 0.9744  |  Val Loss: 1.0831\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 727/1000] Train Loss: 0.9930  |  Val Loss: 1.0140\n",
      "Validation loss improved from 1.0170 to 1.0140.\n",
      "[Epoch 728/1000] Train Loss: 0.9853  |  Val Loss: 1.1044\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 729/1000] Train Loss: 0.9717  |  Val Loss: 1.0237\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 730/1000] Train Loss: 0.9663  |  Val Loss: 1.0999\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 731/1000] Train Loss: 0.9599  |  Val Loss: 1.0387\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 732/1000] Train Loss: 0.9655  |  Val Loss: 1.0377\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 733/1000] Train Loss: 0.9657  |  Val Loss: 1.0614\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 734/1000] Train Loss: 0.9626  |  Val Loss: 1.0055\n",
      "Validation loss improved from 1.0140 to 1.0055.\n",
      "[Epoch 735/1000] Train Loss: 0.9602  |  Val Loss: 1.0539\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 736/1000] Train Loss: 0.9606  |  Val Loss: 1.0669\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 737/1000] Train Loss: 0.9611  |  Val Loss: 1.0113\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 738/1000] Train Loss: 0.9584  |  Val Loss: 1.1259\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 739/1000] Train Loss: 0.9637  |  Val Loss: 1.0136\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 740/1000] Train Loss: 0.9599  |  Val Loss: 1.0756\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 741/1000] Train Loss: 0.9867  |  Val Loss: 1.0237\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 742/1000] Train Loss: 0.9621  |  Val Loss: 1.0285\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 743/1000] Train Loss: 0.9660  |  Val Loss: 1.0477\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 744/1000] Train Loss: 0.9623  |  Val Loss: 1.0339\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 745/1000] Train Loss: 0.9569  |  Val Loss: 1.0208\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 746/1000] Train Loss: 0.9578  |  Val Loss: 1.0154\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 747/1000] Train Loss: 0.9418  |  Val Loss: 1.0561\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 748/1000] Train Loss: 0.9449  |  Val Loss: 1.0265\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 749/1000] Train Loss: 0.9403  |  Val Loss: 1.0147\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 750/1000] Train Loss: 0.9448  |  Val Loss: 1.0487\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 751/1000] Train Loss: 0.9637  |  Val Loss: 1.0232\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 752/1000] Train Loss: 0.9515  |  Val Loss: 1.0118\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 753/1000] Train Loss: 0.9720  |  Val Loss: 1.0619\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 754/1000] Train Loss: 0.9392  |  Val Loss: 1.0186\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 755/1000] Train Loss: 0.9360  |  Val Loss: 1.0638\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 756/1000] Train Loss: 0.9563  |  Val Loss: 1.0118\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 757/1000] Train Loss: 0.9533  |  Val Loss: 1.0417\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 758/1000] Train Loss: 0.9336  |  Val Loss: 1.0268\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 759/1000] Train Loss: 0.9487  |  Val Loss: 1.0004\n",
      "Validation loss improved from 1.0055 to 1.0004.\n",
      "[Epoch 760/1000] Train Loss: 0.9434  |  Val Loss: 1.0118\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 761/1000] Train Loss: 0.9355  |  Val Loss: 0.9958\n",
      "Validation loss improved from 1.0004 to 0.9958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 762/1000] Train Loss: 0.9381  |  Val Loss: 1.0286\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 763/1000] Train Loss: 0.9302  |  Val Loss: 1.0094\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 764/1000] Train Loss: 0.9751  |  Val Loss: 1.0056\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 765/1000] Train Loss: 0.9683  |  Val Loss: 1.1648\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 766/1000] Train Loss: 1.0378  |  Val Loss: 1.0121\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 767/1000] Train Loss: 0.9763  |  Val Loss: 1.1207\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 768/1000] Train Loss: 0.9641  |  Val Loss: 1.0225\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 769/1000] Train Loss: 0.9573  |  Val Loss: 1.0610\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 770/1000] Train Loss: 0.9379  |  Val Loss: 1.0106\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 771/1000] Train Loss: 0.9336  |  Val Loss: 1.0790\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 772/1000] Train Loss: 0.9550  |  Val Loss: 1.0031\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 773/1000] Train Loss: 0.9656  |  Val Loss: 0.9934\n",
      "Validation loss improved from 0.9958 to 0.9934.\n",
      "[Epoch 774/1000] Train Loss: 0.9660  |  Val Loss: 1.1374\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 775/1000] Train Loss: 1.0012  |  Val Loss: 1.0219\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 776/1000] Train Loss: 0.9775  |  Val Loss: 1.0925\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 777/1000] Train Loss: 0.9545  |  Val Loss: 1.0304\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 778/1000] Train Loss: 0.9403  |  Val Loss: 1.0301\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 779/1000] Train Loss: 0.9582  |  Val Loss: 1.0767\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 780/1000] Train Loss: 0.9519  |  Val Loss: 1.0051\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 781/1000] Train Loss: 0.9190  |  Val Loss: 1.0357\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 782/1000] Train Loss: 0.9230  |  Val Loss: 0.9909\n",
      "Validation loss improved from 0.9934 to 0.9909.\n",
      "[Epoch 783/1000] Train Loss: 0.9382  |  Val Loss: 1.0355\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 784/1000] Train Loss: 0.9409  |  Val Loss: 1.0006\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 785/1000] Train Loss: 0.9441  |  Val Loss: 1.0332\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 786/1000] Train Loss: 0.9384  |  Val Loss: 1.0189\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 787/1000] Train Loss: 0.9396  |  Val Loss: 1.0206\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 788/1000] Train Loss: 0.9165  |  Val Loss: 1.0218\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 789/1000] Train Loss: 0.9247  |  Val Loss: 0.9974\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 790/1000] Train Loss: 0.9264  |  Val Loss: 1.0477\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 791/1000] Train Loss: 0.9325  |  Val Loss: 0.9983\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 792/1000] Train Loss: 0.9142  |  Val Loss: 1.0016\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 793/1000] Train Loss: 0.9354  |  Val Loss: 1.0175\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 794/1000] Train Loss: 0.9307  |  Val Loss: 1.0107\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 795/1000] Train Loss: 0.9222  |  Val Loss: 0.9837\n",
      "Validation loss improved from 0.9909 to 0.9837.\n",
      "[Epoch 796/1000] Train Loss: 0.9136  |  Val Loss: 1.0210\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 797/1000] Train Loss: 0.9163  |  Val Loss: 0.9939\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 798/1000] Train Loss: 0.9160  |  Val Loss: 1.0036\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 799/1000] Train Loss: 0.9401  |  Val Loss: 1.0137\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 800/1000] Train Loss: 0.9237  |  Val Loss: 1.0122\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 801/1000] Train Loss: 0.9228  |  Val Loss: 1.0098\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 802/1000] Train Loss: 0.9278  |  Val Loss: 1.0396\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 803/1000] Train Loss: 0.9360  |  Val Loss: 0.9872\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 804/1000] Train Loss: 0.9216  |  Val Loss: 1.0648\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 805/1000] Train Loss: 0.9343  |  Val Loss: 0.9922\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 806/1000] Train Loss: 0.9374  |  Val Loss: 0.9847\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 807/1000] Train Loss: 0.9233  |  Val Loss: 0.9790\n",
      "Validation loss improved from 0.9837 to 0.9790.\n",
      "[Epoch 808/1000] Train Loss: 0.9300  |  Val Loss: 0.9963\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 809/1000] Train Loss: 0.9497  |  Val Loss: 1.0486\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 810/1000] Train Loss: 0.9521  |  Val Loss: 0.9807\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 811/1000] Train Loss: 0.9334  |  Val Loss: 1.0142\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 812/1000] Train Loss: 0.9112  |  Val Loss: 1.0174\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 813/1000] Train Loss: 0.9107  |  Val Loss: 1.0048\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 814/1000] Train Loss: 0.9059  |  Val Loss: 0.9928\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 815/1000] Train Loss: 0.9185  |  Val Loss: 1.0304\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 816/1000] Train Loss: 0.9124  |  Val Loss: 0.9751\n",
      "Validation loss improved from 0.9790 to 0.9751.\n",
      "[Epoch 817/1000] Train Loss: 0.9153  |  Val Loss: 1.0047\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 818/1000] Train Loss: 0.9143  |  Val Loss: 1.0127\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 819/1000] Train Loss: 0.9139  |  Val Loss: 0.9964\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 820/1000] Train Loss: 0.9034  |  Val Loss: 0.9735\n",
      "Validation loss improved from 0.9751 to 0.9735.\n",
      "[Epoch 821/1000] Train Loss: 0.9069  |  Val Loss: 0.9877\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 822/1000] Train Loss: 0.9017  |  Val Loss: 1.0128\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 823/1000] Train Loss: 0.8926  |  Val Loss: 0.9979\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 824/1000] Train Loss: 0.9151  |  Val Loss: 0.9942\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 825/1000] Train Loss: 0.9090  |  Val Loss: 1.0207\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 826/1000] Train Loss: 0.9137  |  Val Loss: 1.0018\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 827/1000] Train Loss: 0.9288  |  Val Loss: 1.0480\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 828/1000] Train Loss: 0.9157  |  Val Loss: 0.9856\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 829/1000] Train Loss: 0.9050  |  Val Loss: 1.0163\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 830/1000] Train Loss: 0.9171  |  Val Loss: 1.0354\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 831/1000] Train Loss: 0.9127  |  Val Loss: 1.0004\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 832/1000] Train Loss: 0.9062  |  Val Loss: 1.0379\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 833/1000] Train Loss: 0.9035  |  Val Loss: 0.9966\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 834/1000] Train Loss: 0.8871  |  Val Loss: 0.9984\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 835/1000] Train Loss: 0.8854  |  Val Loss: 0.9978\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 836/1000] Train Loss: 0.8897  |  Val Loss: 0.9753\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 837/1000] Train Loss: 0.9059  |  Val Loss: 1.0442\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 838/1000] Train Loss: 0.9202  |  Val Loss: 0.9723\n",
      "Validation loss improved from 0.9735 to 0.9723.\n",
      "[Epoch 839/1000] Train Loss: 0.9057  |  Val Loss: 1.0589\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 840/1000] Train Loss: 0.8939  |  Val Loss: 0.9821\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 841/1000] Train Loss: 0.9526  |  Val Loss: 1.0477\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 842/1000] Train Loss: 0.9610  |  Val Loss: 1.0172\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 843/1000] Train Loss: 0.9384  |  Val Loss: 0.9724\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 844/1000] Train Loss: 0.9118  |  Val Loss: 0.9845\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 845/1000] Train Loss: 0.8910  |  Val Loss: 0.9636\n",
      "Validation loss improved from 0.9723 to 0.9636.\n",
      "[Epoch 846/1000] Train Loss: 0.9092  |  Val Loss: 0.9819\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 847/1000] Train Loss: 0.9307  |  Val Loss: 1.0108\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 848/1000] Train Loss: 0.9075  |  Val Loss: 0.9854\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 849/1000] Train Loss: 0.9076  |  Val Loss: 1.0412\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 850/1000] Train Loss: 0.9195  |  Val Loss: 1.0330\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 851/1000] Train Loss: 0.9259  |  Val Loss: 0.9910\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 852/1000] Train Loss: 0.8964  |  Val Loss: 1.0826\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 853/1000] Train Loss: 0.9347  |  Val Loss: 0.9759\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 854/1000] Train Loss: 0.9299  |  Val Loss: 0.9796\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 855/1000] Train Loss: 0.9337  |  Val Loss: 1.0377\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 856/1000] Train Loss: 0.9139  |  Val Loss: 0.9985\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 857/1000] Train Loss: 0.9227  |  Val Loss: 0.9826\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 858/1000] Train Loss: 0.8958  |  Val Loss: 1.0072\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 859/1000] Train Loss: 0.8999  |  Val Loss: 0.9788\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 860/1000] Train Loss: 0.8897  |  Val Loss: 1.0981\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 861/1000] Train Loss: 0.9070  |  Val Loss: 0.9678\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 862/1000] Train Loss: 0.9265  |  Val Loss: 1.0725\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 863/1000] Train Loss: 0.8950  |  Val Loss: 0.9839\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 864/1000] Train Loss: 0.8816  |  Val Loss: 0.9738\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 865/1000] Train Loss: 0.8925  |  Val Loss: 0.9805\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 866/1000] Train Loss: 0.8699  |  Val Loss: 0.9503\n",
      "Validation loss improved from 0.9636 to 0.9503.\n",
      "[Epoch 867/1000] Train Loss: 0.8869  |  Val Loss: 1.0266\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 868/1000] Train Loss: 0.8888  |  Val Loss: 0.9581\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 869/1000] Train Loss: 0.8718  |  Val Loss: 0.9895\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 870/1000] Train Loss: 0.8756  |  Val Loss: 0.9633\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 871/1000] Train Loss: 0.8704  |  Val Loss: 0.9440\n",
      "Validation loss improved from 0.9503 to 0.9440.\n",
      "[Epoch 872/1000] Train Loss: 0.8916  |  Val Loss: 1.0566\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 873/1000] Train Loss: 0.9002  |  Val Loss: 0.9817\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 874/1000] Train Loss: 0.8709  |  Val Loss: 1.0256\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 875/1000] Train Loss: 0.8652  |  Val Loss: 0.9433\n",
      "Validation loss improved from 0.9440 to 0.9433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 876/1000] Train Loss: 0.8864  |  Val Loss: 1.0014\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 877/1000] Train Loss: 0.8651  |  Val Loss: 0.9799\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 878/1000] Train Loss: 0.8901  |  Val Loss: 1.0243\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 879/1000] Train Loss: 0.8596  |  Val Loss: 0.9402\n",
      "Validation loss improved from 0.9433 to 0.9402.\n",
      "[Epoch 880/1000] Train Loss: 0.8826  |  Val Loss: 1.0916\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 881/1000] Train Loss: 0.8893  |  Val Loss: 0.9786\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 882/1000] Train Loss: 0.9405  |  Val Loss: 0.9837\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 883/1000] Train Loss: 0.9554  |  Val Loss: 1.0520\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 884/1000] Train Loss: 0.9103  |  Val Loss: 0.9685\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 885/1000] Train Loss: 0.9090  |  Val Loss: 1.0577\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 886/1000] Train Loss: 0.8814  |  Val Loss: 0.9813\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 887/1000] Train Loss: 0.9179  |  Val Loss: 1.0991\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 888/1000] Train Loss: 0.9033  |  Val Loss: 0.9635\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 889/1000] Train Loss: 0.8919  |  Val Loss: 1.0140\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 890/1000] Train Loss: 0.8684  |  Val Loss: 0.9496\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 891/1000] Train Loss: 0.8765  |  Val Loss: 0.9451\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 892/1000] Train Loss: 0.9164  |  Val Loss: 1.0371\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 893/1000] Train Loss: 0.8874  |  Val Loss: 0.9617\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 894/1000] Train Loss: 0.9101  |  Val Loss: 1.1761\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 895/1000] Train Loss: 0.9115  |  Val Loss: 0.9639\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 896/1000] Train Loss: 0.8960  |  Val Loss: 1.1331\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 897/1000] Train Loss: 0.9233  |  Val Loss: 0.9495\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 898/1000] Train Loss: 0.8598  |  Val Loss: 0.9710\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 899/1000] Train Loss: 0.8495  |  Val Loss: 0.9431\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 900/1000] Train Loss: 0.8494  |  Val Loss: 0.9610\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 901/1000] Train Loss: 0.8461  |  Val Loss: 0.9614\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 902/1000] Train Loss: 0.8496  |  Val Loss: 0.9723\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 903/1000] Train Loss: 0.8574  |  Val Loss: 0.9344\n",
      "Validation loss improved from 0.9402 to 0.9344.\n",
      "[Epoch 904/1000] Train Loss: 0.8458  |  Val Loss: 0.9732\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 905/1000] Train Loss: 0.8390  |  Val Loss: 0.9500\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 906/1000] Train Loss: 0.8582  |  Val Loss: 1.0265\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 907/1000] Train Loss: 0.8827  |  Val Loss: 0.9475\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 908/1000] Train Loss: 0.8539  |  Val Loss: 1.0199\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 909/1000] Train Loss: 0.9064  |  Val Loss: 0.9882\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 910/1000] Train Loss: 0.8789  |  Val Loss: 1.0390\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 911/1000] Train Loss: 0.8718  |  Val Loss: 0.9341\n",
      "Validation loss improved from 0.9344 to 0.9341.\n",
      "[Epoch 912/1000] Train Loss: 0.8851  |  Val Loss: 1.0001\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 913/1000] Train Loss: 0.8676  |  Val Loss: 0.9832\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 914/1000] Train Loss: 0.8472  |  Val Loss: 0.9479\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 915/1000] Train Loss: 0.8646  |  Val Loss: 0.9672\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 916/1000] Train Loss: 0.8355  |  Val Loss: 0.9909\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 917/1000] Train Loss: 0.8668  |  Val Loss: 0.9929\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 918/1000] Train Loss: 0.8568  |  Val Loss: 0.9778\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 919/1000] Train Loss: 0.8684  |  Val Loss: 1.0329\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 920/1000] Train Loss: 0.8827  |  Val Loss: 0.9318\n",
      "Validation loss improved from 0.9341 to 0.9318.\n",
      "[Epoch 921/1000] Train Loss: 0.8644  |  Val Loss: 0.9643\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 922/1000] Train Loss: 0.8282  |  Val Loss: 0.9334\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 923/1000] Train Loss: 0.8439  |  Val Loss: 1.0004\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 924/1000] Train Loss: 0.8595  |  Val Loss: 0.9617\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 925/1000] Train Loss: 0.8571  |  Val Loss: 0.9309\n",
      "Validation loss improved from 0.9318 to 0.9309.\n",
      "[Epoch 926/1000] Train Loss: 0.8461  |  Val Loss: 0.9812\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 927/1000] Train Loss: 0.8442  |  Val Loss: 0.9218\n",
      "Validation loss improved from 0.9309 to 0.9218.\n",
      "[Epoch 928/1000] Train Loss: 0.8305  |  Val Loss: 1.0069\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 929/1000] Train Loss: 0.8437  |  Val Loss: 0.9769\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 930/1000] Train Loss: 0.8474  |  Val Loss: 0.9304\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 931/1000] Train Loss: 0.8656  |  Val Loss: 0.9334\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 932/1000] Train Loss: 0.8293  |  Val Loss: 0.9331\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 933/1000] Train Loss: 0.8452  |  Val Loss: 0.9918\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 934/1000] Train Loss: 0.8541  |  Val Loss: 0.9528\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 935/1000] Train Loss: 0.8572  |  Val Loss: 0.9512\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 936/1000] Train Loss: 0.8287  |  Val Loss: 0.8977\n",
      "Validation loss improved from 0.9218 to 0.8977.\n",
      "[Epoch 937/1000] Train Loss: 0.8438  |  Val Loss: 0.9553\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 938/1000] Train Loss: 0.8273  |  Val Loss: 0.9548\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 939/1000] Train Loss: 0.8298  |  Val Loss: 0.9638\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 940/1000] Train Loss: 0.8359  |  Val Loss: 0.9347\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 941/1000] Train Loss: 0.8333  |  Val Loss: 0.9638\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 942/1000] Train Loss: 0.8179  |  Val Loss: 0.9394\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 943/1000] Train Loss: 0.8427  |  Val Loss: 0.9393\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 944/1000] Train Loss: 0.8228  |  Val Loss: 0.9491\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 945/1000] Train Loss: 0.8331  |  Val Loss: 0.9236\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 946/1000] Train Loss: 0.8345  |  Val Loss: 0.9596\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 947/1000] Train Loss: 0.8345  |  Val Loss: 0.9331\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 948/1000] Train Loss: 0.8155  |  Val Loss: 0.9298\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 949/1000] Train Loss: 0.8120  |  Val Loss: 0.9171\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 950/1000] Train Loss: 0.8107  |  Val Loss: 0.9286\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 951/1000] Train Loss: 0.8248  |  Val Loss: 0.9626\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 952/1000] Train Loss: 0.8253  |  Val Loss: 0.9116\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 953/1000] Train Loss: 0.8497  |  Val Loss: 1.0477\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 954/1000] Train Loss: 0.8771  |  Val Loss: 0.9538\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 955/1000] Train Loss: 0.9071  |  Val Loss: 1.1504\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 956/1000] Train Loss: 0.9230  |  Val Loss: 0.9254\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 957/1000] Train Loss: 0.8693  |  Val Loss: 1.0261\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 958/1000] Train Loss: 0.8323  |  Val Loss: 0.9094\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 959/1000] Train Loss: 0.8315  |  Val Loss: 1.0112\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 960/1000] Train Loss: 0.8205  |  Val Loss: 0.9073\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 961/1000] Train Loss: 0.7988  |  Val Loss: 1.0041\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 962/1000] Train Loss: 0.8130  |  Val Loss: 0.9541\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 963/1000] Train Loss: 0.8244  |  Val Loss: 1.0929\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 964/1000] Train Loss: 0.8576  |  Val Loss: 0.9241\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 965/1000] Train Loss: 0.8271  |  Val Loss: 1.0502\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 966/1000] Train Loss: 0.8435  |  Val Loss: 0.9258\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 967/1000] Train Loss: 0.8065  |  Val Loss: 0.9930\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 968/1000] Train Loss: 0.8342  |  Val Loss: 0.9078\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 969/1000] Train Loss: 0.8228  |  Val Loss: 0.9394\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 970/1000] Train Loss: 0.8053  |  Val Loss: 0.9280\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 971/1000] Train Loss: 0.7970  |  Val Loss: 0.9207\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 972/1000] Train Loss: 0.8020  |  Val Loss: 0.8936\n",
      "Validation loss improved from 0.8977 to 0.8936.\n",
      "[Epoch 973/1000] Train Loss: 0.8034  |  Val Loss: 0.9630\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 974/1000] Train Loss: 0.8029  |  Val Loss: 0.9063\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 975/1000] Train Loss: 0.7916  |  Val Loss: 0.9486\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 976/1000] Train Loss: 0.8069  |  Val Loss: 0.9242\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 977/1000] Train Loss: 0.8098  |  Val Loss: 0.8905\n",
      "Validation loss improved from 0.8936 to 0.8905.\n",
      "[Epoch 978/1000] Train Loss: 0.8059  |  Val Loss: 0.9063\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 979/1000] Train Loss: 0.7949  |  Val Loss: 0.9352\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 980/1000] Train Loss: 0.7855  |  Val Loss: 0.9289\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 981/1000] Train Loss: 0.8029  |  Val Loss: 0.9087\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 982/1000] Train Loss: 0.7999  |  Val Loss: 0.9508\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 983/1000] Train Loss: 0.8124  |  Val Loss: 0.9059\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 984/1000] Train Loss: 0.7972  |  Val Loss: 0.9768\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 985/1000] Train Loss: 0.8187  |  Val Loss: 0.8840\n",
      "Validation loss improved from 0.8905 to 0.8840.\n",
      "[Epoch 986/1000] Train Loss: 0.8156  |  Val Loss: 0.9238\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 987/1000] Train Loss: 0.7797  |  Val Loss: 0.9102\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 988/1000] Train Loss: 0.7873  |  Val Loss: 0.9439\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 989/1000] Train Loss: 0.7834  |  Val Loss: 0.8838\n",
      "Validation loss improved from 0.8840 to 0.8838.\n",
      "[Epoch 990/1000] Train Loss: 0.7968  |  Val Loss: 0.9591\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 991/1000] Train Loss: 0.8236  |  Val Loss: 0.9086\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 992/1000] Train Loss: 0.7834  |  Val Loss: 0.8862\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 993/1000] Train Loss: 0.8110  |  Val Loss: 1.0197\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 994/1000] Train Loss: 0.8293  |  Val Loss: 0.9014\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 995/1000] Train Loss: 0.8155  |  Val Loss: 0.9169\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 996/1000] Train Loss: 0.7974  |  Val Loss: 0.9469\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 997/1000] Train Loss: 0.7872  |  Val Loss: 0.8994\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 998/1000] Train Loss: 0.7863  |  Val Loss: 0.9276\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 999/1000] Train Loss: 0.7872  |  Val Loss: 0.8900\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 1000/1000] Train Loss: 0.7840  |  Val Loss: 0.9326\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_input_dim = cae_mlp_train_reps.shape[1]\n",
    "cae_mlp_num_classes = len(torch.unique(cae_mlp_train_labels_torch))\n",
    "cae_mlp_model = MLPClassifier(cae_mlp_input_dim, cae_mlp_num_classes).to(device)\n",
    "\n",
    "cae_mlp_criterion = nn.CrossEntropyLoss()\n",
    "cae_mlp_optimizer = optim.Adam(cae_mlp_model.parameters(), lr=1e-3)\n",
    "\n",
    "cae_mlp_num_epochs = 1000\n",
    "cae_mlp_patience = 100\n",
    "\n",
    "cae_mlp_train_losses = []\n",
    "cae_mlp_val_losses = []\n",
    "\n",
    "cae_mlp_best_val_loss = float('inf')\n",
    "cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for cae_mlp_epoch in range(cae_mlp_num_epochs):\n",
    "    # Training\n",
    "    cae_mlp_model.train()\n",
    "    cae_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for cae_mlp_embeddings_batch, cae_mlp_labels_batch in cae_mlp_train_loader:\n",
    "        cae_mlp_embeddings_batch = cae_mlp_embeddings_batch.to(device)\n",
    "        cae_mlp_labels_batch = cae_mlp_labels_batch.to(device)\n",
    "        \n",
    "        cae_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        cae_mlp_outputs = cae_mlp_model(cae_mlp_embeddings_batch)\n",
    "        cae_mlp_loss = cae_mlp_criterion(cae_mlp_outputs, cae_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        cae_mlp_loss.backward()\n",
    "        cae_mlp_optimizer.step()\n",
    "        \n",
    "        cae_mlp_train_running_loss += cae_mlp_loss.item() * cae_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    cae_mlp_epoch_train_loss = cae_mlp_train_running_loss / len(cae_mlp_train_loader.dataset)\n",
    "    cae_mlp_train_losses.append(cae_mlp_epoch_train_loss)\n",
    "\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    cae_mlp_model.eval()\n",
    "    cae_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for cae_mlp_val_embeddings_batch, cae_mlp_val_labels_batch in cae_mlp_val_loader:\n",
    "            cae_mlp_val_embeddings_batch = cae_mlp_val_embeddings_batch.to(device)\n",
    "            cae_mlp_val_labels_batch = cae_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            cae_mlp_val_outputs = cae_mlp_model(cae_mlp_val_embeddings_batch)\n",
    "            cae_mlp_val_loss = cae_mlp_criterion(cae_mlp_val_outputs, cae_mlp_val_labels_batch)\n",
    "\n",
    "            cae_mlp_val_running_loss += cae_mlp_val_loss.item() * cae_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    cae_mlp_epoch_val_loss = cae_mlp_val_running_loss / len(cae_mlp_val_loader.dataset)\n",
    "    cae_mlp_val_losses.append(cae_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {cae_mlp_epoch+1}/{cae_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {cae_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {cae_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "\n",
    "    if cae_mlp_epoch_val_loss < cae_mlp_best_val_loss:\n",
    "        # improvement, reset patience\n",
    "        print(f\"Validation loss improved from {cae_mlp_best_val_loss:.4f} to {cae_mlp_epoch_val_loss:.4f}.\")\n",
    "        cae_mlp_best_val_loss = cae_mlp_epoch_val_loss\n",
    "        cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        cae_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {cae_mlp_epochs_without_improvement}/{cae_mlp_patience}\")\n",
    "        \n",
    "        if cae_mlp_epochs_without_improvement >= cae_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {cae_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {cae_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(cae_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(cae_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:47.622592Z",
     "iopub.status.busy": "2025-05-08T19:27:47.621603Z",
     "iopub.status.idle": "2025-05-08T19:27:47.775100Z",
     "shell.execute_reply": "2025-05-08T19:27:47.775100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CAE+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 1.0989 | Test Accuracy: 58.35%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_model.eval()\n",
    "\n",
    "cae_mlp_test_running_loss = 0.0\n",
    "cae_mlp_test_correct = 0\n",
    "cae_mlp_all_predictions = []\n",
    "cae_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cae_mlp_test_embeddings_batch, cae_mlp_test_labels_batch in cae_mlp_test_loader:\n",
    "        cae_mlp_test_embeddings_batch = cae_mlp_test_embeddings_batch.to(device)\n",
    "        cae_mlp_test_labels_batch = cae_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        cae_mlp_test_outputs = cae_mlp_model(cae_mlp_test_embeddings_batch)\n",
    "        \n",
    "        cae_mlp_test_loss_batch = cae_mlp_criterion(cae_mlp_test_outputs, cae_mlp_test_labels_batch)\n",
    "        cae_mlp_test_running_loss += cae_mlp_test_loss_batch.item() * cae_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, cae_mlp_test_predicted = torch.max(cae_mlp_test_outputs, dim=1)\n",
    "        cae_mlp_test_correct += (cae_mlp_test_predicted == cae_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        #saving predictions for conf matrix\n",
    "        cae_mlp_all_predictions.extend(cae_mlp_test_predicted.cpu().numpy())\n",
    "        cae_mlp_all_true_labels.extend(cae_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_predictions.npy'), np.array(cae_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_true_labels.npy'), np.array(cae_mlp_all_true_labels))\n",
    "print(f\"Saved CAE+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "cae_mlp_epoch_test_loss = cae_mlp_test_running_loss / len(cae_mlp_test_loader.dataset)\n",
    "cae_mlp_test_accuracy = cae_mlp_test_correct / len(cae_mlp_test_loader.dataset)\n",
    "\n",
    "cae_mlp_test_accuracy_pct = cae_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {cae_mlp_epoch_test_loss:.4f} | Test Accuracy: {cae_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "cae_mlp_num_epochs_run = len(cae_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         [cae_mlp_epoch_test_loss]*cae_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical SCL with Cosine Similarity (Supervised Contrastive Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:47.777106Z",
     "iopub.status.busy": "2025-05-08T19:27:47.777106Z",
     "iopub.status.idle": "2025-05-08T19:27:47.787304Z",
     "shell.execute_reply": "2025-05-08T19:27:47.787304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 280 samples with 64 features each\n",
      "LOG: Labels shape: (280,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2898 samples with 64 features each\n",
      "LOG: Labels shape: (2898,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (280, 64), \n",
      "Train labels shape: (280,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (70, 64), \n",
      "Val labels shape: (70,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (2898, 64), \n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "tscl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "tscl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "tscl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "tscl_train_embeddings, tscl_train_labels = load_encoded_data(tscl_encoded_train_dir)\n",
    "tscl_val_embeddings, tscl_val_labels = load_encoded_data(tscl_encoded_val_dir)\n",
    "tscl_test_embeddings, tscl_test_labels = load_encoded_data(tscl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {tscl_train_embeddings.shape}, \\nTrain labels shape: {tscl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {tscl_val_embeddings.shape}, \\nVal labels shape: {tscl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {tscl_test_embeddings.shape}, \\nTest labels shape: {tscl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:47.790501Z",
     "iopub.status.busy": "2025-05-08T19:27:47.789489Z",
     "iopub.status.idle": "2025-05-08T19:27:47.801005Z",
     "shell.execute_reply": "2025-05-08T19:27:47.801005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20}\n",
      "Training batch size: 280\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "tscl_train_embeddings = tscl_train_embeddings.reshape(tscl_train_embeddings.shape[0], -1)\n",
    "tscl_val_embeddings = tscl_val_embeddings.reshape(tscl_val_embeddings.shape[0], -1)\n",
    "tscl_test_embeddings = tscl_test_embeddings.reshape(tscl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "tscl_train_mean = np.mean(tscl_train_embeddings, axis=0)\n",
    "tscl_train_std = np.std(tscl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "tscl_train_embeddings = (tscl_train_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_val_embeddings = (tscl_val_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_test_embeddings = (tscl_test_embeddings - tscl_train_mean) / tscl_train_std\n",
    "\n",
    "tscl_train_dataset = TensorDataset(torch.tensor(tscl_train_embeddings, dtype=torch.float32), torch.tensor(tscl_train_labels, dtype=torch.long))\n",
    "tscl_val_dataset = TensorDataset(torch.tensor(tscl_val_embeddings, dtype=torch.float32), torch.tensor(tscl_val_labels, dtype=torch.long))\n",
    "tscl_test_dataset = TensorDataset(torch.tensor(tscl_test_embeddings, dtype=torch.float32), torch.tensor(tscl_test_labels, dtype=torch.long))\n",
    "\n",
    "tscl_m = 20\n",
    "tscl_num_classes = len(np.unique(tscl_train_labels))\n",
    "\n",
    "# Calculate theoretical required batch size\n",
    "tscl_required_batch_size = tscl_m * tscl_num_classes\n",
    "\n",
    "# Ensure batch size doesn't exceed training set size\n",
    "if tscl_required_batch_size > len(tscl_train_dataset):\n",
    "    #case 1: Not enough samples - reduce m proportionally\n",
    "    tscl_max_possible_m = len(tscl_train_dataset) // tscl_num_classes\n",
    "    tscl_m = max(1, tscl_max_possible_m)  # Ensure m >= 1\n",
    "    tscl_batch_size_train = tscl_m * tscl_num_classes\n",
    "else:\n",
    "    #case 2: Use full batch size\n",
    "    tscl_batch_size_train = tscl_required_batch_size\n",
    "\n",
    "tscl_sampler = MPerClassSampler(labels = tscl_train_labels, m = tscl_m, batch_size = tscl_batch_size_train, length_before_new_iter=len(tscl_train_dataset))\n",
    "tscl_train_loader = DataLoader(tscl_train_dataset, batch_size=tscl_batch_size_train, sampler=tscl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "tscl_dataloader_bs = 256\n",
    "tscl_val_loader = DataLoader(tscl_val_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "tscl_test_loader = DataLoader(tscl_test_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for tscl_X_batch, tscl_y_batch in tscl_train_loader:\n",
    "    tscl_unique, tscl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(tscl_unique, tscl_counts)))\n",
    "    print(f\"Training batch size: {tscl_batch_size_train}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:47.804011Z",
     "iopub.status.busy": "2025-05-08T19:27:47.803010Z",
     "iopub.status.idle": "2025-05-08T19:27:47.808477Z",
     "shell.execute_reply": "2025-05-08T19:27:47.808477Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature = 0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        #normalize feat vectors\n",
    "        features = F.normalize(features, p=2, dim = 1)\n",
    "\n",
    "        #compute cosine simi matrix\n",
    "        similarity_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "\n",
    "        #create a mask for +ve pairs - i.e. same class\n",
    "        labels = labels.unsqueeze(1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(features.device)\n",
    "\n",
    "        #loss computation\n",
    "        exp_sim = torch.exp(similarity_matrix)\n",
    "        log_prob = similarity_matrix - torch.log(exp_sim.sum(dim = 1, keepdim=True))\n",
    "\n",
    "        #mask out diagonal - i.e. self similarity\n",
    "        mask_self = torch.eye(mask.shape[0], dtype = torch.bool).to(features.device)\n",
    "        mask = mask * (~mask_self)\n",
    "\n",
    "        #handling edge cases when there is no +ve pair\n",
    "        mask_pos_pairs = mask.sum(dim=1)\n",
    "        mask_pos_pairs = torch.where(mask_pos_pairs < 1e-6, 1, mask_pos_pairs)\n",
    "\n",
    "        loss = -(mask * log_prob).sum(dim=1) / mask_pos_pairs\n",
    "\n",
    "        return loss.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:47.810482Z",
     "iopub.status.busy": "2025-05-08T19:27:47.810482Z",
     "iopub.status.idle": "2025-05-08T19:27:47.814503Z",
     "shell.execute_reply": "2025-05-08T19:27:47.814503Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128), #expects input of shape (batch_size, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #flattening input tensor\n",
    "        #x = x.view(x.size(0), -1)  #reshaping -> (batch_size, channels * height * width)\n",
    "        projections = self.projection_head(x)\n",
    "        return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:47.817012Z",
     "iopub.status.busy": "2025-05-08T19:27:47.817012Z",
     "iopub.status.idle": "2025-05-08T19:27:58.484040Z",
     "shell.execute_reply": "2025-05-08T19:27:58.484040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 8.1233\n",
      "Epoch [1/2000], Avg Train Loss: 8.1233\n",
      "Epoch [1/2000], Avg Val Loss: 3.7190\n",
      "Validation loss improved from inf to 3.7190. Saving model...\n",
      "\n",
      "LOG: Epoch [2/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.0691\n",
      "Epoch [2/2000], Avg Train Loss: 8.0691\n",
      "Epoch [2/2000], Avg Val Loss: 3.7041\n",
      "Validation loss improved from 3.7190 to 3.7041. Saving model...\n",
      "\n",
      "LOG: Epoch [3/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.8983\n",
      "Epoch [3/2000], Avg Train Loss: 7.8983\n",
      "Epoch [3/2000], Avg Val Loss: 3.6901\n",
      "Validation loss improved from 3.7041 to 3.6901. Saving model...\n",
      "\n",
      "LOG: Epoch [4/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.8578\n",
      "Epoch [4/2000], Avg Train Loss: 7.8578\n",
      "Epoch [4/2000], Avg Val Loss: 3.6767\n",
      "Validation loss improved from 3.6901 to 3.6767. Saving model...\n",
      "\n",
      "LOG: Epoch [5/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.7569\n",
      "Epoch [5/2000], Avg Train Loss: 7.7569\n",
      "Epoch [5/2000], Avg Val Loss: 3.6641\n",
      "Validation loss improved from 3.6767 to 3.6641. Saving model...\n",
      "\n",
      "LOG: Epoch [6/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.6761\n",
      "Epoch [6/2000], Avg Train Loss: 7.6761\n",
      "Epoch [6/2000], Avg Val Loss: 3.6521\n",
      "Validation loss improved from 3.6641 to 3.6521. Saving model...\n",
      "\n",
      "LOG: Epoch [7/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.6529\n",
      "Epoch [7/2000], Avg Train Loss: 7.6529\n",
      "Epoch [7/2000], Avg Val Loss: 3.6407\n",
      "Validation loss improved from 3.6521 to 3.6407. Saving model...\n",
      "\n",
      "LOG: Epoch [8/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.6259\n",
      "Epoch [8/2000], Avg Train Loss: 7.6259\n",
      "Epoch [8/2000], Avg Val Loss: 3.6299\n",
      "Validation loss improved from 3.6407 to 3.6299. Saving model...\n",
      "\n",
      "LOG: Epoch [9/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.4777\n",
      "Epoch [9/2000], Avg Train Loss: 7.4777\n",
      "Epoch [9/2000], Avg Val Loss: 3.6197\n",
      "Validation loss improved from 3.6299 to 3.6197. Saving model...\n",
      "\n",
      "LOG: Epoch [10/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.6313\n",
      "Epoch [10/2000], Avg Train Loss: 7.6313\n",
      "Epoch [10/2000], Avg Val Loss: 3.6099\n",
      "Validation loss improved from 3.6197 to 3.6099. Saving model...\n",
      "\n",
      "LOG: Epoch [11/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.4270\n",
      "Epoch [11/2000], Avg Train Loss: 7.4270\n",
      "Epoch [11/2000], Avg Val Loss: 3.6006\n",
      "Validation loss improved from 3.6099 to 3.6006. Saving model...\n",
      "\n",
      "LOG: Epoch [12/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.1404\n",
      "Epoch [12/2000], Avg Train Loss: 7.1404\n",
      "Epoch [12/2000], Avg Val Loss: 3.5919\n",
      "Validation loss improved from 3.6006 to 3.5919. Saving model...\n",
      "\n",
      "LOG: Epoch [13/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.3261\n",
      "Epoch [13/2000], Avg Train Loss: 7.3261\n",
      "Epoch [13/2000], Avg Val Loss: 3.5837\n",
      "Validation loss improved from 3.5919 to 3.5837. Saving model...\n",
      "\n",
      "LOG: Epoch [14/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.2127\n",
      "Epoch [14/2000], Avg Train Loss: 7.2127\n",
      "Epoch [14/2000], Avg Val Loss: 3.5760\n",
      "Validation loss improved from 3.5837 to 3.5760. Saving model...\n",
      "\n",
      "LOG: Epoch [15/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 7.0959\n",
      "Epoch [15/2000], Avg Train Loss: 7.0959\n",
      "Epoch [15/2000], Avg Val Loss: 3.5688\n",
      "Validation loss improved from 3.5760 to 3.5688. Saving model...\n",
      "\n",
      "LOG: Epoch [16/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.0736\n",
      "Epoch [16/2000], Avg Train Loss: 7.0736\n",
      "Epoch [16/2000], Avg Val Loss: 3.5620\n",
      "Validation loss improved from 3.5688 to 3.5620. Saving model...\n",
      "\n",
      "LOG: Epoch [17/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.1102\n",
      "Epoch [17/2000], Avg Train Loss: 7.1102\n",
      "Epoch [17/2000], Avg Val Loss: 3.5557\n",
      "Validation loss improved from 3.5620 to 3.5557. Saving model...\n",
      "\n",
      "LOG: Epoch [18/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.0519\n",
      "Epoch [18/2000], Avg Train Loss: 7.0519\n",
      "Epoch [18/2000], Avg Val Loss: 3.5498\n",
      "Validation loss improved from 3.5557 to 3.5498. Saving model...\n",
      "\n",
      "LOG: Epoch [19/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.7937\n",
      "Epoch [19/2000], Avg Train Loss: 6.7937\n",
      "Epoch [19/2000], Avg Val Loss: 3.5444\n",
      "Validation loss improved from 3.5498 to 3.5444. Saving model...\n",
      "\n",
      "LOG: Epoch [20/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.8660\n",
      "Epoch [20/2000], Avg Train Loss: 6.8660\n",
      "Epoch [20/2000], Avg Val Loss: 3.5393\n",
      "Validation loss improved from 3.5444 to 3.5393. Saving model...\n",
      "\n",
      "LOG: Epoch [21/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.8736\n",
      "Epoch [21/2000], Avg Train Loss: 6.8736\n",
      "Epoch [21/2000], Avg Val Loss: 3.5346\n",
      "Validation loss improved from 3.5393 to 3.5346. Saving model...\n",
      "\n",
      "LOG: Epoch [22/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.8186\n",
      "Epoch [22/2000], Avg Train Loss: 6.8186\n",
      "Epoch [22/2000], Avg Val Loss: 3.5301\n",
      "Validation loss improved from 3.5346 to 3.5301. Saving model...\n",
      "\n",
      "LOG: Epoch [23/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.7809\n",
      "Epoch [23/2000], Avg Train Loss: 6.7809\n",
      "Epoch [23/2000], Avg Val Loss: 3.5258\n",
      "Validation loss improved from 3.5301 to 3.5258. Saving model...\n",
      "\n",
      "LOG: Epoch [24/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.7739\n",
      "Epoch [24/2000], Avg Train Loss: 6.7739\n",
      "Epoch [24/2000], Avg Val Loss: 3.5218\n",
      "Validation loss improved from 3.5258 to 3.5218. Saving model...\n",
      "\n",
      "LOG: Epoch [25/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.5544\n",
      "Epoch [25/2000], Avg Train Loss: 6.5544\n",
      "Epoch [25/2000], Avg Val Loss: 3.5180\n",
      "Validation loss improved from 3.5218 to 3.5180. Saving model...\n",
      "\n",
      "LOG: Epoch [26/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 6.5561\n",
      "Epoch [26/2000], Avg Train Loss: 6.5561\n",
      "Epoch [26/2000], Avg Val Loss: 3.5145\n",
      "Validation loss improved from 3.5180 to 3.5145. Saving model...\n",
      "\n",
      "LOG: Epoch [27/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.5886\n",
      "Epoch [27/2000], Avg Train Loss: 6.5886\n",
      "Epoch [27/2000], Avg Val Loss: 3.5112\n",
      "Validation loss improved from 3.5145 to 3.5112. Saving model...\n",
      "\n",
      "LOG: Epoch [28/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.5276\n",
      "Epoch [28/2000], Avg Train Loss: 6.5276\n",
      "Epoch [28/2000], Avg Val Loss: 3.5080\n",
      "Validation loss improved from 3.5112 to 3.5080. Saving model...\n",
      "\n",
      "LOG: Epoch [29/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3932\n",
      "Epoch [29/2000], Avg Train Loss: 6.3932\n",
      "Epoch [29/2000], Avg Val Loss: 3.5050\n",
      "Validation loss improved from 3.5080 to 3.5050. Saving model...\n",
      "\n",
      "LOG: Epoch [30/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3726\n",
      "Epoch [30/2000], Avg Train Loss: 6.3726\n",
      "Epoch [30/2000], Avg Val Loss: 3.5022\n",
      "Validation loss improved from 3.5050 to 3.5022. Saving model...\n",
      "\n",
      "LOG: Epoch [31/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2386\n",
      "Epoch [31/2000], Avg Train Loss: 6.2386\n",
      "Epoch [31/2000], Avg Val Loss: 3.4995\n",
      "Validation loss improved from 3.5022 to 3.4995. Saving model...\n",
      "\n",
      "LOG: Epoch [32/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3477\n",
      "Epoch [32/2000], Avg Train Loss: 6.3477\n",
      "Epoch [32/2000], Avg Val Loss: 3.4969\n",
      "Validation loss improved from 3.4995 to 3.4969. Saving model...\n",
      "\n",
      "LOG: Epoch [33/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2895\n",
      "Epoch [33/2000], Avg Train Loss: 6.2895\n",
      "Epoch [33/2000], Avg Val Loss: 3.4945\n",
      "Validation loss improved from 3.4969 to 3.4945. Saving model...\n",
      "\n",
      "LOG: Epoch [34/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2136\n",
      "Epoch [34/2000], Avg Train Loss: 6.2136\n",
      "Epoch [34/2000], Avg Val Loss: 3.4922\n",
      "Validation loss improved from 3.4945 to 3.4922. Saving model...\n",
      "\n",
      "LOG: Epoch [35/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 6.2489\n",
      "Epoch [35/2000], Avg Train Loss: 6.2489\n",
      "Epoch [35/2000], Avg Val Loss: 3.4900\n",
      "Validation loss improved from 3.4922 to 3.4900. Saving model...\n",
      "\n",
      "LOG: Epoch [36/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2071\n",
      "Epoch [36/2000], Avg Train Loss: 6.2071\n",
      "Epoch [36/2000], Avg Val Loss: 3.4879\n",
      "Validation loss improved from 3.4900 to 3.4879. Saving model...\n",
      "\n",
      "LOG: Epoch [37/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0889\n",
      "Epoch [37/2000], Avg Train Loss: 6.0889\n",
      "Epoch [37/2000], Avg Val Loss: 3.4859\n",
      "Validation loss improved from 3.4879 to 3.4859. Saving model...\n",
      "\n",
      "LOG: Epoch [38/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1701\n",
      "Epoch [38/2000], Avg Train Loss: 6.1701\n",
      "Epoch [38/2000], Avg Val Loss: 3.4841\n",
      "Validation loss improved from 3.4859 to 3.4841. Saving model...\n",
      "\n",
      "LOG: Epoch [39/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0628\n",
      "Epoch [39/2000], Avg Train Loss: 6.0628\n",
      "Epoch [39/2000], Avg Val Loss: 3.4823\n",
      "Validation loss improved from 3.4841 to 3.4823. Saving model...\n",
      "\n",
      "LOG: Epoch [40/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1012\n",
      "Epoch [40/2000], Avg Train Loss: 6.1012\n",
      "Epoch [40/2000], Avg Val Loss: 3.4806\n",
      "Validation loss improved from 3.4823 to 3.4806. Saving model...\n",
      "\n",
      "LOG: Epoch [41/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0005\n",
      "Epoch [41/2000], Avg Train Loss: 6.0005\n",
      "Epoch [41/2000], Avg Val Loss: 3.4790\n",
      "Validation loss improved from 3.4806 to 3.4790. Saving model...\n",
      "\n",
      "LOG: Epoch [42/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1081\n",
      "Epoch [42/2000], Avg Train Loss: 6.1081\n",
      "Epoch [42/2000], Avg Val Loss: 3.4774\n",
      "Validation loss improved from 3.4790 to 3.4774. Saving model...\n",
      "\n",
      "LOG: Epoch [43/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0539\n",
      "Epoch [43/2000], Avg Train Loss: 6.0539\n",
      "Epoch [43/2000], Avg Val Loss: 3.4759\n",
      "Validation loss improved from 3.4774 to 3.4759. Saving model...\n",
      "\n",
      "LOG: Epoch [44/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0178\n",
      "Epoch [44/2000], Avg Train Loss: 6.0178\n",
      "Epoch [44/2000], Avg Val Loss: 3.4745\n",
      "Validation loss improved from 3.4759 to 3.4745. Saving model...\n",
      "\n",
      "LOG: Epoch [45/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9473\n",
      "Epoch [45/2000], Avg Train Loss: 5.9473\n",
      "Epoch [45/2000], Avg Val Loss: 3.4731\n",
      "Validation loss improved from 3.4745 to 3.4731. Saving model...\n",
      "\n",
      "LOG: Epoch [46/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9086\n",
      "Epoch [46/2000], Avg Train Loss: 5.9086\n",
      "Epoch [46/2000], Avg Val Loss: 3.4717\n",
      "Validation loss improved from 3.4731 to 3.4717. Saving model...\n",
      "\n",
      "LOG: Epoch [47/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8667\n",
      "Epoch [47/2000], Avg Train Loss: 5.8667\n",
      "Epoch [47/2000], Avg Val Loss: 3.4703\n",
      "Validation loss improved from 3.4717 to 3.4703. Saving model...\n",
      "\n",
      "LOG: Epoch [48/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9141\n",
      "Epoch [48/2000], Avg Train Loss: 5.9141\n",
      "Epoch [48/2000], Avg Val Loss: 3.4688\n",
      "Validation loss improved from 3.4703 to 3.4688. Saving model...\n",
      "\n",
      "LOG: Epoch [49/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8339\n",
      "Epoch [49/2000], Avg Train Loss: 5.8339\n",
      "Epoch [49/2000], Avg Val Loss: 3.4674\n",
      "Validation loss improved from 3.4688 to 3.4674. Saving model...\n",
      "\n",
      "LOG: Epoch [50/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7910\n",
      "Epoch [50/2000], Avg Train Loss: 5.7910\n",
      "Epoch [50/2000], Avg Val Loss: 3.4661\n",
      "Validation loss improved from 3.4674 to 3.4661. Saving model...\n",
      "\n",
      "LOG: Epoch [51/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7511\n",
      "Epoch [51/2000], Avg Train Loss: 5.7511\n",
      "Epoch [51/2000], Avg Val Loss: 3.4648\n",
      "Validation loss improved from 3.4661 to 3.4648. Saving model...\n",
      "\n",
      "LOG: Epoch [52/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.8092\n",
      "Epoch [52/2000], Avg Train Loss: 5.8092\n",
      "Epoch [52/2000], Avg Val Loss: 3.4635\n",
      "Validation loss improved from 3.4648 to 3.4635. Saving model...\n",
      "\n",
      "LOG: Epoch [53/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7108\n",
      "Epoch [53/2000], Avg Train Loss: 5.7108\n",
      "Epoch [53/2000], Avg Val Loss: 3.4623\n",
      "Validation loss improved from 3.4635 to 3.4623. Saving model...\n",
      "\n",
      "LOG: Epoch [54/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7114\n",
      "Epoch [54/2000], Avg Train Loss: 5.7114\n",
      "Epoch [54/2000], Avg Val Loss: 3.4611\n",
      "Validation loss improved from 3.4623 to 3.4611. Saving model...\n",
      "\n",
      "LOG: Epoch [55/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7791\n",
      "Epoch [55/2000], Avg Train Loss: 5.7791\n",
      "Epoch [55/2000], Avg Val Loss: 3.4598\n",
      "Validation loss improved from 3.4611 to 3.4598. Saving model...\n",
      "\n",
      "LOG: Epoch [56/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6201\n",
      "Epoch [56/2000], Avg Train Loss: 5.6201\n",
      "Epoch [56/2000], Avg Val Loss: 3.4585\n",
      "Validation loss improved from 3.4598 to 3.4585. Saving model...\n",
      "\n",
      "LOG: Epoch [57/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6881\n",
      "Epoch [57/2000], Avg Train Loss: 5.6881\n",
      "Epoch [57/2000], Avg Val Loss: 3.4573\n",
      "Validation loss improved from 3.4585 to 3.4573. Saving model...\n",
      "\n",
      "LOG: Epoch [58/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7010\n",
      "Epoch [58/2000], Avg Train Loss: 5.7010\n",
      "Epoch [58/2000], Avg Val Loss: 3.4560\n",
      "Validation loss improved from 3.4573 to 3.4560. Saving model...\n",
      "\n",
      "LOG: Epoch [59/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6486\n",
      "Epoch [59/2000], Avg Train Loss: 5.6486\n",
      "Epoch [59/2000], Avg Val Loss: 3.4548\n",
      "Validation loss improved from 3.4560 to 3.4548. Saving model...\n",
      "\n",
      "LOG: Epoch [60/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6063\n",
      "Epoch [60/2000], Avg Train Loss: 5.6063\n",
      "Epoch [60/2000], Avg Val Loss: 3.4535\n",
      "Validation loss improved from 3.4548 to 3.4535. Saving model...\n",
      "\n",
      "LOG: Epoch [61/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6348\n",
      "Epoch [61/2000], Avg Train Loss: 5.6348\n",
      "Epoch [61/2000], Avg Val Loss: 3.4522\n",
      "Validation loss improved from 3.4535 to 3.4522. Saving model...\n",
      "\n",
      "LOG: Epoch [62/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5998\n",
      "Epoch [62/2000], Avg Train Loss: 5.5998\n",
      "Epoch [62/2000], Avg Val Loss: 3.4509\n",
      "Validation loss improved from 3.4522 to 3.4509. Saving model...\n",
      "\n",
      "LOG: Epoch [63/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.5878\n",
      "Epoch [63/2000], Avg Train Loss: 5.5878\n",
      "Epoch [63/2000], Avg Val Loss: 3.4497\n",
      "Validation loss improved from 3.4509 to 3.4497. Saving model...\n",
      "\n",
      "LOG: Epoch [64/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6317\n",
      "Epoch [64/2000], Avg Train Loss: 5.6317\n",
      "Epoch [64/2000], Avg Val Loss: 3.4484\n",
      "Validation loss improved from 3.4497 to 3.4484. Saving model...\n",
      "\n",
      "LOG: Epoch [65/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5404\n",
      "Epoch [65/2000], Avg Train Loss: 5.5404\n",
      "Epoch [65/2000], Avg Val Loss: 3.4472\n",
      "Validation loss improved from 3.4484 to 3.4472. Saving model...\n",
      "\n",
      "LOG: Epoch [66/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5018\n",
      "Epoch [66/2000], Avg Train Loss: 5.5018\n",
      "Epoch [66/2000], Avg Val Loss: 3.4459\n",
      "Validation loss improved from 3.4472 to 3.4459. Saving model...\n",
      "\n",
      "LOG: Epoch [67/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4276\n",
      "Epoch [67/2000], Avg Train Loss: 5.4276\n",
      "Epoch [67/2000], Avg Val Loss: 3.4445\n",
      "Validation loss improved from 3.4459 to 3.4445. Saving model...\n",
      "\n",
      "LOG: Epoch [68/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4693\n",
      "Epoch [68/2000], Avg Train Loss: 5.4693\n",
      "Epoch [68/2000], Avg Val Loss: 3.4431\n",
      "Validation loss improved from 3.4445 to 3.4431. Saving model...\n",
      "\n",
      "LOG: Epoch [69/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4795\n",
      "Epoch [69/2000], Avg Train Loss: 5.4795\n",
      "Epoch [69/2000], Avg Val Loss: 3.4417\n",
      "Validation loss improved from 3.4431 to 3.4417. Saving model...\n",
      "\n",
      "LOG: Epoch [70/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.5043\n",
      "Epoch [70/2000], Avg Train Loss: 5.5043\n",
      "Epoch [70/2000], Avg Val Loss: 3.4403\n",
      "Validation loss improved from 3.4417 to 3.4403. Saving model...\n",
      "\n",
      "LOG: Epoch [71/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4585\n",
      "Epoch [71/2000], Avg Train Loss: 5.4585\n",
      "Epoch [71/2000], Avg Val Loss: 3.4388\n",
      "Validation loss improved from 3.4403 to 3.4388. Saving model...\n",
      "\n",
      "LOG: Epoch [72/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4807\n",
      "Epoch [72/2000], Avg Train Loss: 5.4807\n",
      "Epoch [72/2000], Avg Val Loss: 3.4374\n",
      "Validation loss improved from 3.4388 to 3.4374. Saving model...\n",
      "\n",
      "LOG: Epoch [73/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4284\n",
      "Epoch [73/2000], Avg Train Loss: 5.4284\n",
      "Epoch [73/2000], Avg Val Loss: 3.4359\n",
      "Validation loss improved from 3.4374 to 3.4359. Saving model...\n",
      "\n",
      "LOG: Epoch [74/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4256\n",
      "Epoch [74/2000], Avg Train Loss: 5.4256\n",
      "Epoch [74/2000], Avg Val Loss: 3.4345\n",
      "Validation loss improved from 3.4359 to 3.4345. Saving model...\n",
      "\n",
      "LOG: Epoch [75/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3541\n",
      "Epoch [75/2000], Avg Train Loss: 5.3541\n",
      "Epoch [75/2000], Avg Val Loss: 3.4329\n",
      "Validation loss improved from 3.4345 to 3.4329. Saving model...\n",
      "\n",
      "LOG: Epoch [76/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4452\n",
      "Epoch [76/2000], Avg Train Loss: 5.4452\n",
      "Epoch [76/2000], Avg Val Loss: 3.4314\n",
      "Validation loss improved from 3.4329 to 3.4314. Saving model...\n",
      "\n",
      "LOG: Epoch [77/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4299\n",
      "Epoch [77/2000], Avg Train Loss: 5.4299\n",
      "Epoch [77/2000], Avg Val Loss: 3.4299\n",
      "Validation loss improved from 3.4314 to 3.4299. Saving model...\n",
      "\n",
      "LOG: Epoch [78/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4115\n",
      "Epoch [78/2000], Avg Train Loss: 5.4115\n",
      "Epoch [78/2000], Avg Val Loss: 3.4283\n",
      "Validation loss improved from 3.4299 to 3.4283. Saving model...\n",
      "\n",
      "LOG: Epoch [79/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3607\n",
      "Epoch [79/2000], Avg Train Loss: 5.3607\n",
      "Epoch [79/2000], Avg Val Loss: 3.4268\n",
      "Validation loss improved from 3.4283 to 3.4268. Saving model...\n",
      "\n",
      "LOG: Epoch [80/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4254\n",
      "Epoch [80/2000], Avg Train Loss: 5.4254\n",
      "Epoch [80/2000], Avg Val Loss: 3.4253\n",
      "Validation loss improved from 3.4268 to 3.4253. Saving model...\n",
      "\n",
      "LOG: Epoch [81/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4114\n",
      "Epoch [81/2000], Avg Train Loss: 5.4114\n",
      "Epoch [81/2000], Avg Val Loss: 3.4237\n",
      "Validation loss improved from 3.4253 to 3.4237. Saving model...\n",
      "\n",
      "LOG: Epoch [82/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3790\n",
      "Epoch [82/2000], Avg Train Loss: 5.3790\n",
      "Epoch [82/2000], Avg Val Loss: 3.4222\n",
      "Validation loss improved from 3.4237 to 3.4222. Saving model...\n",
      "\n",
      "LOG: Epoch [83/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3639\n",
      "Epoch [83/2000], Avg Train Loss: 5.3639\n",
      "Epoch [83/2000], Avg Val Loss: 3.4206\n",
      "Validation loss improved from 3.4222 to 3.4206. Saving model...\n",
      "\n",
      "LOG: Epoch [84/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3269\n",
      "Epoch [84/2000], Avg Train Loss: 5.3269\n",
      "Epoch [84/2000], Avg Val Loss: 3.4190\n",
      "Validation loss improved from 3.4206 to 3.4190. Saving model...\n",
      "\n",
      "LOG: Epoch [85/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3111\n",
      "Epoch [85/2000], Avg Train Loss: 5.3111\n",
      "Epoch [85/2000], Avg Val Loss: 3.4174\n",
      "Validation loss improved from 3.4190 to 3.4174. Saving model...\n",
      "\n",
      "LOG: Epoch [86/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.3011\n",
      "Epoch [86/2000], Avg Train Loss: 5.3011\n",
      "Epoch [86/2000], Avg Val Loss: 3.4159\n",
      "Validation loss improved from 3.4174 to 3.4159. Saving model...\n",
      "\n",
      "LOG: Epoch [87/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3204\n",
      "Epoch [87/2000], Avg Train Loss: 5.3204\n",
      "Epoch [87/2000], Avg Val Loss: 3.4143\n",
      "Validation loss improved from 3.4159 to 3.4143. Saving model...\n",
      "\n",
      "LOG: Epoch [88/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2997\n",
      "Epoch [88/2000], Avg Train Loss: 5.2997\n",
      "Epoch [88/2000], Avg Val Loss: 3.4127\n",
      "Validation loss improved from 3.4143 to 3.4127. Saving model...\n",
      "\n",
      "LOG: Epoch [89/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2509\n",
      "Epoch [89/2000], Avg Train Loss: 5.2509\n",
      "Epoch [89/2000], Avg Val Loss: 3.4110\n",
      "Validation loss improved from 3.4127 to 3.4110. Saving model...\n",
      "\n",
      "LOG: Epoch [90/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2969\n",
      "Epoch [90/2000], Avg Train Loss: 5.2969\n",
      "Epoch [90/2000], Avg Val Loss: 3.4094\n",
      "Validation loss improved from 3.4110 to 3.4094. Saving model...\n",
      "\n",
      "LOG: Epoch [91/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2771\n",
      "Epoch [91/2000], Avg Train Loss: 5.2771\n",
      "Epoch [91/2000], Avg Val Loss: 3.4078\n",
      "Validation loss improved from 3.4094 to 3.4078. Saving model...\n",
      "\n",
      "LOG: Epoch [92/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2240\n",
      "Epoch [92/2000], Avg Train Loss: 5.2240\n",
      "Epoch [92/2000], Avg Val Loss: 3.4063\n",
      "Validation loss improved from 3.4078 to 3.4063. Saving model...\n",
      "\n",
      "LOG: Epoch [93/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2457\n",
      "Epoch [93/2000], Avg Train Loss: 5.2457\n",
      "Epoch [93/2000], Avg Val Loss: 3.4047\n",
      "Validation loss improved from 3.4063 to 3.4047. Saving model...\n",
      "\n",
      "LOG: Epoch [94/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2170\n",
      "Epoch [94/2000], Avg Train Loss: 5.2170\n",
      "Epoch [94/2000], Avg Val Loss: 3.4031\n",
      "Validation loss improved from 3.4047 to 3.4031. Saving model...\n",
      "\n",
      "LOG: Epoch [95/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2973\n",
      "Epoch [95/2000], Avg Train Loss: 5.2973\n",
      "Epoch [95/2000], Avg Val Loss: 3.4015\n",
      "Validation loss improved from 3.4031 to 3.4015. Saving model...\n",
      "\n",
      "LOG: Epoch [96/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2314\n",
      "Epoch [96/2000], Avg Train Loss: 5.2314\n",
      "Epoch [96/2000], Avg Val Loss: 3.3999\n",
      "Validation loss improved from 3.4015 to 3.3999. Saving model...\n",
      "\n",
      "LOG: Epoch [97/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2430\n",
      "Epoch [97/2000], Avg Train Loss: 5.2430\n",
      "Epoch [97/2000], Avg Val Loss: 3.3982\n",
      "Validation loss improved from 3.3999 to 3.3982. Saving model...\n",
      "\n",
      "LOG: Epoch [98/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2212\n",
      "Epoch [98/2000], Avg Train Loss: 5.2212\n",
      "Epoch [98/2000], Avg Val Loss: 3.3966\n",
      "Validation loss improved from 3.3982 to 3.3966. Saving model...\n",
      "\n",
      "LOG: Epoch [99/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2007\n",
      "Epoch [99/2000], Avg Train Loss: 5.2007\n",
      "Epoch [99/2000], Avg Val Loss: 3.3950\n",
      "Validation loss improved from 3.3966 to 3.3950. Saving model...\n",
      "\n",
      "LOG: Epoch [100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2458\n",
      "Epoch [100/2000], Avg Train Loss: 5.2458\n",
      "Epoch [100/2000], Avg Val Loss: 3.3934\n",
      "Validation loss improved from 3.3950 to 3.3934. Saving model...\n",
      "\n",
      "LOG: Epoch [101/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2356\n",
      "Epoch [101/2000], Avg Train Loss: 5.2356\n",
      "Epoch [101/2000], Avg Val Loss: 3.3918\n",
      "Validation loss improved from 3.3934 to 3.3918. Saving model...\n",
      "\n",
      "LOG: Epoch [102/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.2056\n",
      "Epoch [102/2000], Avg Train Loss: 5.2056\n",
      "Epoch [102/2000], Avg Val Loss: 3.3902\n",
      "Validation loss improved from 3.3918 to 3.3902. Saving model...\n",
      "\n",
      "LOG: Epoch [103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2017\n",
      "Epoch [103/2000], Avg Train Loss: 5.2017\n",
      "Epoch [103/2000], Avg Val Loss: 3.3886\n",
      "Validation loss improved from 3.3902 to 3.3886. Saving model...\n",
      "\n",
      "LOG: Epoch [104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1814\n",
      "Epoch [104/2000], Avg Train Loss: 5.1814\n",
      "Epoch [104/2000], Avg Val Loss: 3.3869\n",
      "Validation loss improved from 3.3886 to 3.3869. Saving model...\n",
      "\n",
      "LOG: Epoch [105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1660\n",
      "Epoch [105/2000], Avg Train Loss: 5.1660\n",
      "Epoch [105/2000], Avg Val Loss: 3.3852\n",
      "Validation loss improved from 3.3869 to 3.3852. Saving model...\n",
      "\n",
      "LOG: Epoch [106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1885\n",
      "Epoch [106/2000], Avg Train Loss: 5.1885\n",
      "Epoch [106/2000], Avg Val Loss: 3.3835\n",
      "Validation loss improved from 3.3852 to 3.3835. Saving model...\n",
      "\n",
      "LOG: Epoch [107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1782\n",
      "Epoch [107/2000], Avg Train Loss: 5.1782\n",
      "Epoch [107/2000], Avg Val Loss: 3.3818\n",
      "Validation loss improved from 3.3835 to 3.3818. Saving model...\n",
      "\n",
      "LOG: Epoch [108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1469\n",
      "Epoch [108/2000], Avg Train Loss: 5.1469\n",
      "Epoch [108/2000], Avg Val Loss: 3.3800\n",
      "Validation loss improved from 3.3818 to 3.3800. Saving model...\n",
      "\n",
      "LOG: Epoch [109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1457\n",
      "Epoch [109/2000], Avg Train Loss: 5.1457\n",
      "Epoch [109/2000], Avg Val Loss: 3.3783\n",
      "Validation loss improved from 3.3800 to 3.3783. Saving model...\n",
      "\n",
      "LOG: Epoch [110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1561\n",
      "Epoch [110/2000], Avg Train Loss: 5.1561\n",
      "Epoch [110/2000], Avg Val Loss: 3.3765\n",
      "Validation loss improved from 3.3783 to 3.3765. Saving model...\n",
      "\n",
      "LOG: Epoch [111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1336\n",
      "Epoch [111/2000], Avg Train Loss: 5.1336\n",
      "Epoch [111/2000], Avg Val Loss: 3.3748\n",
      "Validation loss improved from 3.3765 to 3.3748. Saving model...\n",
      "\n",
      "LOG: Epoch [112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1962\n",
      "Epoch [112/2000], Avg Train Loss: 5.1962\n",
      "Epoch [112/2000], Avg Val Loss: 3.3731\n",
      "Validation loss improved from 3.3748 to 3.3731. Saving model...\n",
      "\n",
      "LOG: Epoch [113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1355\n",
      "Epoch [113/2000], Avg Train Loss: 5.1355\n",
      "Epoch [113/2000], Avg Val Loss: 3.3714\n",
      "Validation loss improved from 3.3731 to 3.3714. Saving model...\n",
      "\n",
      "LOG: Epoch [114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1581\n",
      "Epoch [114/2000], Avg Train Loss: 5.1581\n",
      "Epoch [114/2000], Avg Val Loss: 3.3697\n",
      "Validation loss improved from 3.3714 to 3.3697. Saving model...\n",
      "\n",
      "LOG: Epoch [115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1533\n",
      "Epoch [115/2000], Avg Train Loss: 5.1533\n",
      "Epoch [115/2000], Avg Val Loss: 3.3679\n",
      "Validation loss improved from 3.3697 to 3.3679. Saving model...\n",
      "\n",
      "LOG: Epoch [116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1184\n",
      "Epoch [116/2000], Avg Train Loss: 5.1184\n",
      "Epoch [116/2000], Avg Val Loss: 3.3662\n",
      "Validation loss improved from 3.3679 to 3.3662. Saving model...\n",
      "\n",
      "LOG: Epoch [117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1517\n",
      "Epoch [117/2000], Avg Train Loss: 5.1517\n",
      "Epoch [117/2000], Avg Val Loss: 3.3645\n",
      "Validation loss improved from 3.3662 to 3.3645. Saving model...\n",
      "\n",
      "LOG: Epoch [118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1545\n",
      "Epoch [118/2000], Avg Train Loss: 5.1545\n",
      "Epoch [118/2000], Avg Val Loss: 3.3628\n",
      "Validation loss improved from 3.3645 to 3.3628. Saving model...\n",
      "\n",
      "LOG: Epoch [119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1453\n",
      "Epoch [119/2000], Avg Train Loss: 5.1453\n",
      "Epoch [119/2000], Avg Val Loss: 3.3610\n",
      "Validation loss improved from 3.3628 to 3.3610. Saving model...\n",
      "\n",
      "LOG: Epoch [120/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0960\n",
      "Epoch [120/2000], Avg Train Loss: 5.0960\n",
      "Epoch [120/2000], Avg Val Loss: 3.3593\n",
      "Validation loss improved from 3.3610 to 3.3593. Saving model...\n",
      "\n",
      "LOG: Epoch [121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1248\n",
      "Epoch [121/2000], Avg Train Loss: 5.1248\n",
      "Epoch [121/2000], Avg Val Loss: 3.3576\n",
      "Validation loss improved from 3.3593 to 3.3576. Saving model...\n",
      "\n",
      "LOG: Epoch [122/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.1046\n",
      "Epoch [122/2000], Avg Train Loss: 5.1046\n",
      "Epoch [122/2000], Avg Val Loss: 3.3559\n",
      "Validation loss improved from 3.3576 to 3.3559. Saving model...\n",
      "\n",
      "LOG: Epoch [123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1407\n",
      "Epoch [123/2000], Avg Train Loss: 5.1407\n",
      "Epoch [123/2000], Avg Val Loss: 3.3541\n",
      "Validation loss improved from 3.3559 to 3.3541. Saving model...\n",
      "\n",
      "LOG: Epoch [124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0705\n",
      "Epoch [124/2000], Avg Train Loss: 5.0705\n",
      "Epoch [124/2000], Avg Val Loss: 3.3523\n",
      "Validation loss improved from 3.3541 to 3.3523. Saving model...\n",
      "\n",
      "LOG: Epoch [125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0939\n",
      "Epoch [125/2000], Avg Train Loss: 5.0939\n",
      "Epoch [125/2000], Avg Val Loss: 3.3506\n",
      "Validation loss improved from 3.3523 to 3.3506. Saving model...\n",
      "\n",
      "LOG: Epoch [126/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1253\n",
      "Epoch [126/2000], Avg Train Loss: 5.1253\n",
      "Epoch [126/2000], Avg Val Loss: 3.3489\n",
      "Validation loss improved from 3.3506 to 3.3489. Saving model...\n",
      "\n",
      "LOG: Epoch [127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0833\n",
      "Epoch [127/2000], Avg Train Loss: 5.0833\n",
      "Epoch [127/2000], Avg Val Loss: 3.3472\n",
      "Validation loss improved from 3.3489 to 3.3472. Saving model...\n",
      "\n",
      "LOG: Epoch [128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0870\n",
      "Epoch [128/2000], Avg Train Loss: 5.0870\n",
      "Epoch [128/2000], Avg Val Loss: 3.3456\n",
      "Validation loss improved from 3.3472 to 3.3456. Saving model...\n",
      "\n",
      "LOG: Epoch [129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0742\n",
      "Epoch [129/2000], Avg Train Loss: 5.0742\n",
      "Epoch [129/2000], Avg Val Loss: 3.3439\n",
      "Validation loss improved from 3.3456 to 3.3439. Saving model...\n",
      "\n",
      "LOG: Epoch [130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1040\n",
      "Epoch [130/2000], Avg Train Loss: 5.1040\n",
      "Epoch [130/2000], Avg Val Loss: 3.3422\n",
      "Validation loss improved from 3.3439 to 3.3422. Saving model...\n",
      "\n",
      "LOG: Epoch [131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1215\n",
      "Epoch [131/2000], Avg Train Loss: 5.1215\n",
      "Epoch [131/2000], Avg Val Loss: 3.3405\n",
      "Validation loss improved from 3.3422 to 3.3405. Saving model...\n",
      "\n",
      "LOG: Epoch [132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0439\n",
      "Epoch [132/2000], Avg Train Loss: 5.0439\n",
      "Epoch [132/2000], Avg Val Loss: 3.3388\n",
      "Validation loss improved from 3.3405 to 3.3388. Saving model...\n",
      "\n",
      "LOG: Epoch [133/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0633\n",
      "Epoch [133/2000], Avg Train Loss: 5.0633\n",
      "Epoch [133/2000], Avg Val Loss: 3.3371\n",
      "Validation loss improved from 3.3388 to 3.3371. Saving model...\n",
      "\n",
      "LOG: Epoch [134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0469\n",
      "Epoch [134/2000], Avg Train Loss: 5.0469\n",
      "Epoch [134/2000], Avg Val Loss: 3.3354\n",
      "Validation loss improved from 3.3371 to 3.3354. Saving model...\n",
      "\n",
      "LOG: Epoch [135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0257\n",
      "Epoch [135/2000], Avg Train Loss: 5.0257\n",
      "Epoch [135/2000], Avg Val Loss: 3.3336\n",
      "Validation loss improved from 3.3354 to 3.3336. Saving model...\n",
      "\n",
      "LOG: Epoch [136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0627\n",
      "Epoch [136/2000], Avg Train Loss: 5.0627\n",
      "Epoch [136/2000], Avg Val Loss: 3.3319\n",
      "Validation loss improved from 3.3336 to 3.3319. Saving model...\n",
      "\n",
      "LOG: Epoch [137/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.0371\n",
      "Epoch [137/2000], Avg Train Loss: 5.0371\n",
      "Epoch [137/2000], Avg Val Loss: 3.3301\n",
      "Validation loss improved from 3.3319 to 3.3301. Saving model...\n",
      "\n",
      "LOG: Epoch [138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0849\n",
      "Epoch [138/2000], Avg Train Loss: 5.0849\n",
      "Epoch [138/2000], Avg Val Loss: 3.3283\n",
      "Validation loss improved from 3.3301 to 3.3283. Saving model...\n",
      "\n",
      "LOG: Epoch [139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0755\n",
      "Epoch [139/2000], Avg Train Loss: 5.0755\n",
      "Epoch [139/2000], Avg Val Loss: 3.3265\n",
      "Validation loss improved from 3.3283 to 3.3265. Saving model...\n",
      "\n",
      "LOG: Epoch [140/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9754\n",
      "Epoch [140/2000], Avg Train Loss: 4.9754\n",
      "Epoch [140/2000], Avg Val Loss: 3.3246\n",
      "Validation loss improved from 3.3265 to 3.3246. Saving model...\n",
      "\n",
      "LOG: Epoch [141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9768\n",
      "Epoch [141/2000], Avg Train Loss: 4.9768\n",
      "Epoch [141/2000], Avg Val Loss: 3.3228\n",
      "Validation loss improved from 3.3246 to 3.3228. Saving model...\n",
      "\n",
      "LOG: Epoch [142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0054\n",
      "Epoch [142/2000], Avg Train Loss: 5.0054\n",
      "Epoch [142/2000], Avg Val Loss: 3.3210\n",
      "Validation loss improved from 3.3228 to 3.3210. Saving model...\n",
      "\n",
      "LOG: Epoch [143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0096\n",
      "Epoch [143/2000], Avg Train Loss: 5.0096\n",
      "Epoch [143/2000], Avg Val Loss: 3.3191\n",
      "Validation loss improved from 3.3210 to 3.3191. Saving model...\n",
      "\n",
      "LOG: Epoch [144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0426\n",
      "Epoch [144/2000], Avg Train Loss: 5.0426\n",
      "Epoch [144/2000], Avg Val Loss: 3.3172\n",
      "Validation loss improved from 3.3191 to 3.3172. Saving model...\n",
      "\n",
      "LOG: Epoch [145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0707\n",
      "Epoch [145/2000], Avg Train Loss: 5.0707\n",
      "Epoch [145/2000], Avg Val Loss: 3.3154\n",
      "Validation loss improved from 3.3172 to 3.3154. Saving model...\n",
      "\n",
      "LOG: Epoch [146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0123\n",
      "Epoch [146/2000], Avg Train Loss: 5.0123\n",
      "Epoch [146/2000], Avg Val Loss: 3.3136\n",
      "Validation loss improved from 3.3154 to 3.3136. Saving model...\n",
      "\n",
      "LOG: Epoch [147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9961\n",
      "Epoch [147/2000], Avg Train Loss: 4.9961\n",
      "Epoch [147/2000], Avg Val Loss: 3.3117\n",
      "Validation loss improved from 3.3136 to 3.3117. Saving model...\n",
      "\n",
      "LOG: Epoch [148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9891\n",
      "Epoch [148/2000], Avg Train Loss: 4.9891\n",
      "Epoch [148/2000], Avg Val Loss: 3.3099\n",
      "Validation loss improved from 3.3117 to 3.3099. Saving model...\n",
      "\n",
      "LOG: Epoch [149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0247\n",
      "Epoch [149/2000], Avg Train Loss: 5.0247\n",
      "Epoch [149/2000], Avg Val Loss: 3.3081\n",
      "Validation loss improved from 3.3099 to 3.3081. Saving model...\n",
      "\n",
      "LOG: Epoch [150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0337\n",
      "Epoch [150/2000], Avg Train Loss: 5.0337\n",
      "Epoch [150/2000], Avg Val Loss: 3.3063\n",
      "Validation loss improved from 3.3081 to 3.3063. Saving model...\n",
      "\n",
      "LOG: Epoch [151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9741\n",
      "Epoch [151/2000], Avg Train Loss: 4.9741\n",
      "Epoch [151/2000], Avg Val Loss: 3.3045\n",
      "Validation loss improved from 3.3063 to 3.3045. Saving model...\n",
      "\n",
      "LOG: Epoch [152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0041\n",
      "Epoch [152/2000], Avg Train Loss: 5.0041\n",
      "Epoch [152/2000], Avg Val Loss: 3.3028\n",
      "Validation loss improved from 3.3045 to 3.3028. Saving model...\n",
      "\n",
      "LOG: Epoch [153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0313\n",
      "Epoch [153/2000], Avg Train Loss: 5.0313\n",
      "Epoch [153/2000], Avg Val Loss: 3.3010\n",
      "Validation loss improved from 3.3028 to 3.3010. Saving model...\n",
      "\n",
      "LOG: Epoch [154/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0255\n",
      "Epoch [154/2000], Avg Train Loss: 5.0255\n",
      "Epoch [154/2000], Avg Val Loss: 3.2993\n",
      "Validation loss improved from 3.3010 to 3.2993. Saving model...\n",
      "\n",
      "LOG: Epoch [155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9858\n",
      "Epoch [155/2000], Avg Train Loss: 4.9858\n",
      "Epoch [155/2000], Avg Val Loss: 3.2976\n",
      "Validation loss improved from 3.2993 to 3.2976. Saving model...\n",
      "\n",
      "LOG: Epoch [156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9971\n",
      "Epoch [156/2000], Avg Train Loss: 4.9971\n",
      "Epoch [156/2000], Avg Val Loss: 3.2958\n",
      "Validation loss improved from 3.2976 to 3.2958. Saving model...\n",
      "\n",
      "LOG: Epoch [157/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.0068\n",
      "Epoch [157/2000], Avg Train Loss: 5.0068\n",
      "Epoch [157/2000], Avg Val Loss: 3.2940\n",
      "Validation loss improved from 3.2958 to 3.2940. Saving model...\n",
      "\n",
      "LOG: Epoch [158/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9477\n",
      "Epoch [158/2000], Avg Train Loss: 4.9477\n",
      "Epoch [158/2000], Avg Val Loss: 3.2923\n",
      "Validation loss improved from 3.2940 to 3.2923. Saving model...\n",
      "\n",
      "LOG: Epoch [159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9504\n",
      "Epoch [159/2000], Avg Train Loss: 4.9504\n",
      "Epoch [159/2000], Avg Val Loss: 3.2905\n",
      "Validation loss improved from 3.2923 to 3.2905. Saving model...\n",
      "\n",
      "LOG: Epoch [160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0032\n",
      "Epoch [160/2000], Avg Train Loss: 5.0032\n",
      "Epoch [160/2000], Avg Val Loss: 3.2888\n",
      "Validation loss improved from 3.2905 to 3.2888. Saving model...\n",
      "\n",
      "LOG: Epoch [161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9975\n",
      "Epoch [161/2000], Avg Train Loss: 4.9975\n",
      "Epoch [161/2000], Avg Val Loss: 3.2870\n",
      "Validation loss improved from 3.2888 to 3.2870. Saving model...\n",
      "\n",
      "LOG: Epoch [162/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9555\n",
      "Epoch [162/2000], Avg Train Loss: 4.9555\n",
      "Epoch [162/2000], Avg Val Loss: 3.2853\n",
      "Validation loss improved from 3.2870 to 3.2853. Saving model...\n",
      "\n",
      "LOG: Epoch [163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9756\n",
      "Epoch [163/2000], Avg Train Loss: 4.9756\n",
      "Epoch [163/2000], Avg Val Loss: 3.2836\n",
      "Validation loss improved from 3.2853 to 3.2836. Saving model...\n",
      "\n",
      "LOG: Epoch [164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9608\n",
      "Epoch [164/2000], Avg Train Loss: 4.9608\n",
      "Epoch [164/2000], Avg Val Loss: 3.2818\n",
      "Validation loss improved from 3.2836 to 3.2818. Saving model...\n",
      "\n",
      "LOG: Epoch [165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9892\n",
      "Epoch [165/2000], Avg Train Loss: 4.9892\n",
      "Epoch [165/2000], Avg Val Loss: 3.2800\n",
      "Validation loss improved from 3.2818 to 3.2800. Saving model...\n",
      "\n",
      "LOG: Epoch [166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9687\n",
      "Epoch [166/2000], Avg Train Loss: 4.9687\n",
      "Epoch [166/2000], Avg Val Loss: 3.2782\n",
      "Validation loss improved from 3.2800 to 3.2782. Saving model...\n",
      "\n",
      "LOG: Epoch [167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9161\n",
      "Epoch [167/2000], Avg Train Loss: 4.9161\n",
      "Epoch [167/2000], Avg Val Loss: 3.2764\n",
      "Validation loss improved from 3.2782 to 3.2764. Saving model...\n",
      "\n",
      "LOG: Epoch [168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9410\n",
      "Epoch [168/2000], Avg Train Loss: 4.9410\n",
      "Epoch [168/2000], Avg Val Loss: 3.2746\n",
      "Validation loss improved from 3.2764 to 3.2746. Saving model...\n",
      "\n",
      "LOG: Epoch [169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9713\n",
      "Epoch [169/2000], Avg Train Loss: 4.9713\n",
      "Epoch [169/2000], Avg Val Loss: 3.2727\n",
      "Validation loss improved from 3.2746 to 3.2727. Saving model...\n",
      "\n",
      "LOG: Epoch [170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9401\n",
      "Epoch [170/2000], Avg Train Loss: 4.9401\n",
      "Epoch [170/2000], Avg Val Loss: 3.2709\n",
      "Validation loss improved from 3.2727 to 3.2709. Saving model...\n",
      "\n",
      "LOG: Epoch [171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9378\n",
      "Epoch [171/2000], Avg Train Loss: 4.9378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [171/2000], Avg Val Loss: 3.2691\n",
      "Validation loss improved from 3.2709 to 3.2691. Saving model...\n",
      "\n",
      "LOG: Epoch [172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9437\n",
      "Epoch [172/2000], Avg Train Loss: 4.9437\n",
      "Epoch [172/2000], Avg Val Loss: 3.2672\n",
      "Validation loss improved from 3.2691 to 3.2672. Saving model...\n",
      "\n",
      "LOG: Epoch [173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9082\n",
      "Epoch [173/2000], Avg Train Loss: 4.9082\n",
      "Epoch [173/2000], Avg Val Loss: 3.2654\n",
      "Validation loss improved from 3.2672 to 3.2654. Saving model...\n",
      "\n",
      "LOG: Epoch [174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9339\n",
      "Epoch [174/2000], Avg Train Loss: 4.9339\n",
      "Epoch [174/2000], Avg Val Loss: 3.2635\n",
      "Validation loss improved from 3.2654 to 3.2635. Saving model...\n",
      "\n",
      "LOG: Epoch [175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9495\n",
      "Epoch [175/2000], Avg Train Loss: 4.9495\n",
      "Epoch [175/2000], Avg Val Loss: 3.2617\n",
      "Validation loss improved from 3.2635 to 3.2617. Saving model...\n",
      "\n",
      "LOG: Epoch [176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9318\n",
      "Epoch [176/2000], Avg Train Loss: 4.9318\n",
      "Epoch [176/2000], Avg Val Loss: 3.2599\n",
      "Validation loss improved from 3.2617 to 3.2599. Saving model...\n",
      "\n",
      "LOG: Epoch [177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8939\n",
      "Epoch [177/2000], Avg Train Loss: 4.8939\n",
      "Epoch [177/2000], Avg Val Loss: 3.2581\n",
      "Validation loss improved from 3.2599 to 3.2581. Saving model...\n",
      "\n",
      "LOG: Epoch [178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9256\n",
      "Epoch [178/2000], Avg Train Loss: 4.9256\n",
      "Epoch [178/2000], Avg Val Loss: 3.2563\n",
      "Validation loss improved from 3.2581 to 3.2563. Saving model...\n",
      "\n",
      "LOG: Epoch [179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9398\n",
      "Epoch [179/2000], Avg Train Loss: 4.9398\n",
      "Epoch [179/2000], Avg Val Loss: 3.2545\n",
      "Validation loss improved from 3.2563 to 3.2545. Saving model...\n",
      "\n",
      "LOG: Epoch [180/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9056\n",
      "Epoch [180/2000], Avg Train Loss: 4.9056\n",
      "Epoch [180/2000], Avg Val Loss: 3.2527\n",
      "Validation loss improved from 3.2545 to 3.2527. Saving model...\n",
      "\n",
      "LOG: Epoch [181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9369\n",
      "Epoch [181/2000], Avg Train Loss: 4.9369\n",
      "Epoch [181/2000], Avg Val Loss: 3.2509\n",
      "Validation loss improved from 3.2527 to 3.2509. Saving model...\n",
      "\n",
      "LOG: Epoch [182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9398\n",
      "Epoch [182/2000], Avg Train Loss: 4.9398\n",
      "Epoch [182/2000], Avg Val Loss: 3.2491\n",
      "Validation loss improved from 3.2509 to 3.2491. Saving model...\n",
      "\n",
      "LOG: Epoch [183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9265\n",
      "Epoch [183/2000], Avg Train Loss: 4.9265\n",
      "Epoch [183/2000], Avg Val Loss: 3.2473\n",
      "Validation loss improved from 3.2491 to 3.2473. Saving model...\n",
      "\n",
      "LOG: Epoch [184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8884\n",
      "Epoch [184/2000], Avg Train Loss: 4.8884\n",
      "Epoch [184/2000], Avg Val Loss: 3.2455\n",
      "Validation loss improved from 3.2473 to 3.2455. Saving model...\n",
      "\n",
      "LOG: Epoch [185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9223\n",
      "Epoch [185/2000], Avg Train Loss: 4.9223\n",
      "Epoch [185/2000], Avg Val Loss: 3.2437\n",
      "Validation loss improved from 3.2455 to 3.2437. Saving model...\n",
      "\n",
      "LOG: Epoch [186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9403\n",
      "Epoch [186/2000], Avg Train Loss: 4.9403\n",
      "Epoch [186/2000], Avg Val Loss: 3.2419\n",
      "Validation loss improved from 3.2437 to 3.2419. Saving model...\n",
      "\n",
      "LOG: Epoch [187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9556\n",
      "Epoch [187/2000], Avg Train Loss: 4.9556\n",
      "Epoch [187/2000], Avg Val Loss: 3.2401\n",
      "Validation loss improved from 3.2419 to 3.2401. Saving model...\n",
      "\n",
      "LOG: Epoch [188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9031\n",
      "Epoch [188/2000], Avg Train Loss: 4.9031\n",
      "Epoch [188/2000], Avg Val Loss: 3.2384\n",
      "Validation loss improved from 3.2401 to 3.2384. Saving model...\n",
      "\n",
      "LOG: Epoch [189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8820\n",
      "Epoch [189/2000], Avg Train Loss: 4.8820\n",
      "Epoch [189/2000], Avg Val Loss: 3.2365\n",
      "Validation loss improved from 3.2384 to 3.2365. Saving model...\n",
      "\n",
      "LOG: Epoch [190/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8968\n",
      "Epoch [190/2000], Avg Train Loss: 4.8968\n",
      "Epoch [190/2000], Avg Val Loss: 3.2347\n",
      "Validation loss improved from 3.2365 to 3.2347. Saving model...\n",
      "\n",
      "LOG: Epoch [191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8886\n",
      "Epoch [191/2000], Avg Train Loss: 4.8886\n",
      "Epoch [191/2000], Avg Val Loss: 3.2328\n",
      "Validation loss improved from 3.2347 to 3.2328. Saving model...\n",
      "\n",
      "LOG: Epoch [192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8702\n",
      "Epoch [192/2000], Avg Train Loss: 4.8702\n",
      "Epoch [192/2000], Avg Val Loss: 3.2309\n",
      "Validation loss improved from 3.2328 to 3.2309. Saving model...\n",
      "\n",
      "LOG: Epoch [193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.9112\n",
      "Epoch [193/2000], Avg Train Loss: 4.9112\n",
      "Epoch [193/2000], Avg Val Loss: 3.2290\n",
      "Validation loss improved from 3.2309 to 3.2290. Saving model...\n",
      "\n",
      "LOG: Epoch [194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9242\n",
      "Epoch [194/2000], Avg Train Loss: 4.9242\n",
      "Epoch [194/2000], Avg Val Loss: 3.2271\n",
      "Validation loss improved from 3.2290 to 3.2271. Saving model...\n",
      "\n",
      "LOG: Epoch [195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8938\n",
      "Epoch [195/2000], Avg Train Loss: 4.8938\n",
      "Epoch [195/2000], Avg Val Loss: 3.2253\n",
      "Validation loss improved from 3.2271 to 3.2253. Saving model...\n",
      "\n",
      "LOG: Epoch [196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8883\n",
      "Epoch [196/2000], Avg Train Loss: 4.8883\n",
      "Epoch [196/2000], Avg Val Loss: 3.2234\n",
      "Validation loss improved from 3.2253 to 3.2234. Saving model...\n",
      "\n",
      "LOG: Epoch [197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8893\n",
      "Epoch [197/2000], Avg Train Loss: 4.8893\n",
      "Epoch [197/2000], Avg Val Loss: 3.2216\n",
      "Validation loss improved from 3.2234 to 3.2216. Saving model...\n",
      "\n",
      "LOG: Epoch [198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8714\n",
      "Epoch [198/2000], Avg Train Loss: 4.8714\n",
      "Epoch [198/2000], Avg Val Loss: 3.2198\n",
      "Validation loss improved from 3.2216 to 3.2198. Saving model...\n",
      "\n",
      "LOG: Epoch [199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8758\n",
      "Epoch [199/2000], Avg Train Loss: 4.8758\n",
      "Epoch [199/2000], Avg Val Loss: 3.2180\n",
      "Validation loss improved from 3.2198 to 3.2180. Saving model...\n",
      "\n",
      "LOG: Epoch [200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8418\n",
      "Epoch [200/2000], Avg Train Loss: 4.8418\n",
      "Epoch [200/2000], Avg Val Loss: 3.2161\n",
      "Validation loss improved from 3.2180 to 3.2161. Saving model...\n",
      "\n",
      "LOG: Epoch [201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8699\n",
      "Epoch [201/2000], Avg Train Loss: 4.8699\n",
      "Epoch [201/2000], Avg Val Loss: 3.2143\n",
      "Validation loss improved from 3.2161 to 3.2143. Saving model...\n",
      "\n",
      "LOG: Epoch [202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8467\n",
      "Epoch [202/2000], Avg Train Loss: 4.8467\n",
      "Epoch [202/2000], Avg Val Loss: 3.2124\n",
      "Validation loss improved from 3.2143 to 3.2124. Saving model...\n",
      "\n",
      "LOG: Epoch [203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8845\n",
      "Epoch [203/2000], Avg Train Loss: 4.8845\n",
      "Epoch [203/2000], Avg Val Loss: 3.2106\n",
      "Validation loss improved from 3.2124 to 3.2106. Saving model...\n",
      "\n",
      "LOG: Epoch [204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8720\n",
      "Epoch [204/2000], Avg Train Loss: 4.8720\n",
      "Epoch [204/2000], Avg Val Loss: 3.2087\n",
      "Validation loss improved from 3.2106 to 3.2087. Saving model...\n",
      "\n",
      "LOG: Epoch [205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8745\n",
      "Epoch [205/2000], Avg Train Loss: 4.8745\n",
      "Epoch [205/2000], Avg Val Loss: 3.2069\n",
      "Validation loss improved from 3.2087 to 3.2069. Saving model...\n",
      "\n",
      "LOG: Epoch [206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8640\n",
      "Epoch [206/2000], Avg Train Loss: 4.8640\n",
      "Epoch [206/2000], Avg Val Loss: 3.2051\n",
      "Validation loss improved from 3.2069 to 3.2051. Saving model...\n",
      "\n",
      "LOG: Epoch [207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8903\n",
      "Epoch [207/2000], Avg Train Loss: 4.8903\n",
      "Epoch [207/2000], Avg Val Loss: 3.2033\n",
      "Validation loss improved from 3.2051 to 3.2033. Saving model...\n",
      "\n",
      "LOG: Epoch [208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8740\n",
      "Epoch [208/2000], Avg Train Loss: 4.8740\n",
      "Epoch [208/2000], Avg Val Loss: 3.2014\n",
      "Validation loss improved from 3.2033 to 3.2014. Saving model...\n",
      "\n",
      "LOG: Epoch [209/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.8215\n",
      "Epoch [209/2000], Avg Train Loss: 4.8215\n",
      "Epoch [209/2000], Avg Val Loss: 3.1996\n",
      "Validation loss improved from 3.2014 to 3.1996. Saving model...\n",
      "\n",
      "LOG: Epoch [210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8505\n",
      "Epoch [210/2000], Avg Train Loss: 4.8505\n",
      "Epoch [210/2000], Avg Val Loss: 3.1979\n",
      "Validation loss improved from 3.1996 to 3.1979. Saving model...\n",
      "\n",
      "LOG: Epoch [211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8773\n",
      "Epoch [211/2000], Avg Train Loss: 4.8773\n",
      "Epoch [211/2000], Avg Val Loss: 3.1960\n",
      "Validation loss improved from 3.1979 to 3.1960. Saving model...\n",
      "\n",
      "LOG: Epoch [212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8570\n",
      "Epoch [212/2000], Avg Train Loss: 4.8570\n",
      "Epoch [212/2000], Avg Val Loss: 3.1942\n",
      "Validation loss improved from 3.1960 to 3.1942. Saving model...\n",
      "\n",
      "LOG: Epoch [213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8332\n",
      "Epoch [213/2000], Avg Train Loss: 4.8332\n",
      "Epoch [213/2000], Avg Val Loss: 3.1924\n",
      "Validation loss improved from 3.1942 to 3.1924. Saving model...\n",
      "\n",
      "LOG: Epoch [214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8318\n",
      "Epoch [214/2000], Avg Train Loss: 4.8318\n",
      "Epoch [214/2000], Avg Val Loss: 3.1906\n",
      "Validation loss improved from 3.1924 to 3.1906. Saving model...\n",
      "\n",
      "LOG: Epoch [215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8261\n",
      "Epoch [215/2000], Avg Train Loss: 4.8261\n",
      "Epoch [215/2000], Avg Val Loss: 3.1888\n",
      "Validation loss improved from 3.1906 to 3.1888. Saving model...\n",
      "\n",
      "LOG: Epoch [216/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8269\n",
      "Epoch [216/2000], Avg Train Loss: 4.8269\n",
      "Epoch [216/2000], Avg Val Loss: 3.1869\n",
      "Validation loss improved from 3.1888 to 3.1869. Saving model...\n",
      "\n",
      "LOG: Epoch [217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8872\n",
      "Epoch [217/2000], Avg Train Loss: 4.8872\n",
      "Epoch [217/2000], Avg Val Loss: 3.1851\n",
      "Validation loss improved from 3.1869 to 3.1851. Saving model...\n",
      "\n",
      "LOG: Epoch [218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8430\n",
      "Epoch [218/2000], Avg Train Loss: 4.8430\n",
      "Epoch [218/2000], Avg Val Loss: 3.1833\n",
      "Validation loss improved from 3.1851 to 3.1833. Saving model...\n",
      "\n",
      "LOG: Epoch [219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8063\n",
      "Epoch [219/2000], Avg Train Loss: 4.8063\n",
      "Epoch [219/2000], Avg Val Loss: 3.1815\n",
      "Validation loss improved from 3.1833 to 3.1815. Saving model...\n",
      "\n",
      "LOG: Epoch [220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8259\n",
      "Epoch [220/2000], Avg Train Loss: 4.8259\n",
      "Epoch [220/2000], Avg Val Loss: 3.1796\n",
      "Validation loss improved from 3.1815 to 3.1796. Saving model...\n",
      "\n",
      "LOG: Epoch [221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8395\n",
      "Epoch [221/2000], Avg Train Loss: 4.8395\n",
      "Epoch [221/2000], Avg Val Loss: 3.1778\n",
      "Validation loss improved from 3.1796 to 3.1778. Saving model...\n",
      "\n",
      "LOG: Epoch [222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8175\n",
      "Epoch [222/2000], Avg Train Loss: 4.8175\n",
      "Epoch [222/2000], Avg Val Loss: 3.1761\n",
      "Validation loss improved from 3.1778 to 3.1761. Saving model...\n",
      "\n",
      "LOG: Epoch [223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8542\n",
      "Epoch [223/2000], Avg Train Loss: 4.8542\n",
      "Epoch [223/2000], Avg Val Loss: 3.1743\n",
      "Validation loss improved from 3.1761 to 3.1743. Saving model...\n",
      "\n",
      "LOG: Epoch [224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7858\n",
      "Epoch [224/2000], Avg Train Loss: 4.7858\n",
      "Epoch [224/2000], Avg Val Loss: 3.1726\n",
      "Validation loss improved from 3.1743 to 3.1726. Saving model...\n",
      "\n",
      "LOG: Epoch [225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8088\n",
      "Epoch [225/2000], Avg Train Loss: 4.8088\n",
      "Epoch [225/2000], Avg Val Loss: 3.1709\n",
      "Validation loss improved from 3.1726 to 3.1709. Saving model...\n",
      "\n",
      "LOG: Epoch [226/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8283\n",
      "Epoch [226/2000], Avg Train Loss: 4.8283\n",
      "Epoch [226/2000], Avg Val Loss: 3.1691\n",
      "Validation loss improved from 3.1709 to 3.1691. Saving model...\n",
      "\n",
      "LOG: Epoch [227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8375\n",
      "Epoch [227/2000], Avg Train Loss: 4.8375\n",
      "Epoch [227/2000], Avg Val Loss: 3.1674\n",
      "Validation loss improved from 3.1691 to 3.1674. Saving model...\n",
      "\n",
      "LOG: Epoch [228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7985\n",
      "Epoch [228/2000], Avg Train Loss: 4.7985\n",
      "Epoch [228/2000], Avg Val Loss: 3.1657\n",
      "Validation loss improved from 3.1674 to 3.1657. Saving model...\n",
      "\n",
      "LOG: Epoch [229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7930\n",
      "Epoch [229/2000], Avg Train Loss: 4.7930\n",
      "Epoch [229/2000], Avg Val Loss: 3.1639\n",
      "Validation loss improved from 3.1657 to 3.1639. Saving model...\n",
      "\n",
      "LOG: Epoch [230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8278\n",
      "Epoch [230/2000], Avg Train Loss: 4.8278\n",
      "Epoch [230/2000], Avg Val Loss: 3.1622\n",
      "Validation loss improved from 3.1639 to 3.1622. Saving model...\n",
      "\n",
      "LOG: Epoch [231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8063\n",
      "Epoch [231/2000], Avg Train Loss: 4.8063\n",
      "Epoch [231/2000], Avg Val Loss: 3.1605\n",
      "Validation loss improved from 3.1622 to 3.1605. Saving model...\n",
      "\n",
      "LOG: Epoch [232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7895\n",
      "Epoch [232/2000], Avg Train Loss: 4.7895\n",
      "Epoch [232/2000], Avg Val Loss: 3.1588\n",
      "Validation loss improved from 3.1605 to 3.1588. Saving model...\n",
      "\n",
      "LOG: Epoch [233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8174\n",
      "Epoch [233/2000], Avg Train Loss: 4.8174\n",
      "Epoch [233/2000], Avg Val Loss: 3.1572\n",
      "Validation loss improved from 3.1588 to 3.1572. Saving model...\n",
      "\n",
      "LOG: Epoch [234/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.7953\n",
      "Epoch [234/2000], Avg Train Loss: 4.7953\n",
      "Epoch [234/2000], Avg Val Loss: 3.1555\n",
      "Validation loss improved from 3.1572 to 3.1555. Saving model...\n",
      "\n",
      "LOG: Epoch [235/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7795\n",
      "Epoch [235/2000], Avg Train Loss: 4.7795\n",
      "Epoch [235/2000], Avg Val Loss: 3.1538\n",
      "Validation loss improved from 3.1555 to 3.1538. Saving model...\n",
      "\n",
      "LOG: Epoch [236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8113\n",
      "Epoch [236/2000], Avg Train Loss: 4.8113\n",
      "Epoch [236/2000], Avg Val Loss: 3.1522\n",
      "Validation loss improved from 3.1538 to 3.1522. Saving model...\n",
      "\n",
      "LOG: Epoch [237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7924\n",
      "Epoch [237/2000], Avg Train Loss: 4.7924\n",
      "Epoch [237/2000], Avg Val Loss: 3.1505\n",
      "Validation loss improved from 3.1522 to 3.1505. Saving model...\n",
      "\n",
      "LOG: Epoch [238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7859\n",
      "Epoch [238/2000], Avg Train Loss: 4.7859\n",
      "Epoch [238/2000], Avg Val Loss: 3.1489\n",
      "Validation loss improved from 3.1505 to 3.1489. Saving model...\n",
      "\n",
      "LOG: Epoch [239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7753\n",
      "Epoch [239/2000], Avg Train Loss: 4.7753\n",
      "Epoch [239/2000], Avg Val Loss: 3.1472\n",
      "Validation loss improved from 3.1489 to 3.1472. Saving model...\n",
      "\n",
      "LOG: Epoch [240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7807\n",
      "Epoch [240/2000], Avg Train Loss: 4.7807\n",
      "Epoch [240/2000], Avg Val Loss: 3.1456\n",
      "Validation loss improved from 3.1472 to 3.1456. Saving model...\n",
      "\n",
      "LOG: Epoch [241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7716\n",
      "Epoch [241/2000], Avg Train Loss: 4.7716\n",
      "Epoch [241/2000], Avg Val Loss: 3.1440\n",
      "Validation loss improved from 3.1456 to 3.1440. Saving model...\n",
      "\n",
      "LOG: Epoch [242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7749\n",
      "Epoch [242/2000], Avg Train Loss: 4.7749\n",
      "Epoch [242/2000], Avg Val Loss: 3.1423\n",
      "Validation loss improved from 3.1440 to 3.1423. Saving model...\n",
      "\n",
      "LOG: Epoch [243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7863\n",
      "Epoch [243/2000], Avg Train Loss: 4.7863\n",
      "Epoch [243/2000], Avg Val Loss: 3.1407\n",
      "Validation loss improved from 3.1423 to 3.1407. Saving model...\n",
      "\n",
      "LOG: Epoch [244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7869\n",
      "Epoch [244/2000], Avg Train Loss: 4.7869\n",
      "Epoch [244/2000], Avg Val Loss: 3.1391\n",
      "Validation loss improved from 3.1407 to 3.1391. Saving model...\n",
      "\n",
      "LOG: Epoch [245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7814\n",
      "Epoch [245/2000], Avg Train Loss: 4.7814\n",
      "Epoch [245/2000], Avg Val Loss: 3.1374\n",
      "Validation loss improved from 3.1391 to 3.1374. Saving model...\n",
      "\n",
      "LOG: Epoch [246/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8021\n",
      "Epoch [246/2000], Avg Train Loss: 4.8021\n",
      "Epoch [246/2000], Avg Val Loss: 3.1358\n",
      "Validation loss improved from 3.1374 to 3.1358. Saving model...\n",
      "\n",
      "LOG: Epoch [247/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.7733\n",
      "Epoch [247/2000], Avg Train Loss: 4.7733\n",
      "Epoch [247/2000], Avg Val Loss: 3.1342\n",
      "Validation loss improved from 3.1358 to 3.1342. Saving model...\n",
      "\n",
      "LOG: Epoch [248/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7209\n",
      "Epoch [248/2000], Avg Train Loss: 4.7209\n",
      "Epoch [248/2000], Avg Val Loss: 3.1325\n",
      "Validation loss improved from 3.1342 to 3.1325. Saving model...\n",
      "\n",
      "LOG: Epoch [249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7821\n",
      "Epoch [249/2000], Avg Train Loss: 4.7821\n",
      "Epoch [249/2000], Avg Val Loss: 3.1309\n",
      "Validation loss improved from 3.1325 to 3.1309. Saving model...\n",
      "\n",
      "LOG: Epoch [250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7618\n",
      "Epoch [250/2000], Avg Train Loss: 4.7618\n",
      "Epoch [250/2000], Avg Val Loss: 3.1293\n",
      "Validation loss improved from 3.1309 to 3.1293. Saving model...\n",
      "\n",
      "LOG: Epoch [251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7619\n",
      "Epoch [251/2000], Avg Train Loss: 4.7619\n",
      "Epoch [251/2000], Avg Val Loss: 3.1277\n",
      "Validation loss improved from 3.1293 to 3.1277. Saving model...\n",
      "\n",
      "LOG: Epoch [252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7149\n",
      "Epoch [252/2000], Avg Train Loss: 4.7149\n",
      "Epoch [252/2000], Avg Val Loss: 3.1261\n",
      "Validation loss improved from 3.1277 to 3.1261. Saving model...\n",
      "\n",
      "LOG: Epoch [253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7486\n",
      "Epoch [253/2000], Avg Train Loss: 4.7486\n",
      "Epoch [253/2000], Avg Val Loss: 3.1245\n",
      "Validation loss improved from 3.1261 to 3.1245. Saving model...\n",
      "\n",
      "LOG: Epoch [254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7760\n",
      "Epoch [254/2000], Avg Train Loss: 4.7760\n",
      "Epoch [254/2000], Avg Val Loss: 3.1229\n",
      "Validation loss improved from 3.1245 to 3.1229. Saving model...\n",
      "\n",
      "LOG: Epoch [255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7588\n",
      "Epoch [255/2000], Avg Train Loss: 4.7588\n",
      "Epoch [255/2000], Avg Val Loss: 3.1214\n",
      "Validation loss improved from 3.1229 to 3.1214. Saving model...\n",
      "\n",
      "LOG: Epoch [256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7306\n",
      "Epoch [256/2000], Avg Train Loss: 4.7306\n",
      "Epoch [256/2000], Avg Val Loss: 3.1198\n",
      "Validation loss improved from 3.1214 to 3.1198. Saving model...\n",
      "\n",
      "LOG: Epoch [257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7395\n",
      "Epoch [257/2000], Avg Train Loss: 4.7395\n",
      "Epoch [257/2000], Avg Val Loss: 3.1181\n",
      "Validation loss improved from 3.1198 to 3.1181. Saving model...\n",
      "\n",
      "LOG: Epoch [258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7238\n",
      "Epoch [258/2000], Avg Train Loss: 4.7238\n",
      "Epoch [258/2000], Avg Val Loss: 3.1165\n",
      "Validation loss improved from 3.1181 to 3.1165. Saving model...\n",
      "\n",
      "LOG: Epoch [259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7359\n",
      "Epoch [259/2000], Avg Train Loss: 4.7359\n",
      "Epoch [259/2000], Avg Val Loss: 3.1149\n",
      "Validation loss improved from 3.1165 to 3.1149. Saving model...\n",
      "\n",
      "LOG: Epoch [260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7376\n",
      "Epoch [260/2000], Avg Train Loss: 4.7376\n",
      "Epoch [260/2000], Avg Val Loss: 3.1133\n",
      "Validation loss improved from 3.1149 to 3.1133. Saving model...\n",
      "\n",
      "LOG: Epoch [261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7048\n",
      "Epoch [261/2000], Avg Train Loss: 4.7048\n",
      "Epoch [261/2000], Avg Val Loss: 3.1117\n",
      "Validation loss improved from 3.1133 to 3.1117. Saving model...\n",
      "\n",
      "LOG: Epoch [262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7289\n",
      "Epoch [262/2000], Avg Train Loss: 4.7289\n",
      "Epoch [262/2000], Avg Val Loss: 3.1100\n",
      "Validation loss improved from 3.1117 to 3.1100. Saving model...\n",
      "\n",
      "LOG: Epoch [263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7184\n",
      "Epoch [263/2000], Avg Train Loss: 4.7184\n",
      "Epoch [263/2000], Avg Val Loss: 3.1084\n",
      "Validation loss improved from 3.1100 to 3.1084. Saving model...\n",
      "\n",
      "LOG: Epoch [264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7533\n",
      "Epoch [264/2000], Avg Train Loss: 4.7533\n",
      "Epoch [264/2000], Avg Val Loss: 3.1069\n",
      "Validation loss improved from 3.1084 to 3.1069. Saving model...\n",
      "\n",
      "LOG: Epoch [265/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.7282\n",
      "Epoch [265/2000], Avg Train Loss: 4.7282\n",
      "Epoch [265/2000], Avg Val Loss: 3.1053\n",
      "Validation loss improved from 3.1069 to 3.1053. Saving model...\n",
      "\n",
      "LOG: Epoch [266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6979\n",
      "Epoch [266/2000], Avg Train Loss: 4.6979\n",
      "Epoch [266/2000], Avg Val Loss: 3.1038\n",
      "Validation loss improved from 3.1053 to 3.1038. Saving model...\n",
      "\n",
      "LOG: Epoch [267/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7141\n",
      "Epoch [267/2000], Avg Train Loss: 4.7141\n",
      "Epoch [267/2000], Avg Val Loss: 3.1023\n",
      "Validation loss improved from 3.1038 to 3.1023. Saving model...\n",
      "\n",
      "LOG: Epoch [268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7343\n",
      "Epoch [268/2000], Avg Train Loss: 4.7343\n",
      "Epoch [268/2000], Avg Val Loss: 3.1008\n",
      "Validation loss improved from 3.1023 to 3.1008. Saving model...\n",
      "\n",
      "LOG: Epoch [269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7287\n",
      "Epoch [269/2000], Avg Train Loss: 4.7287\n",
      "Epoch [269/2000], Avg Val Loss: 3.0993\n",
      "Validation loss improved from 3.1008 to 3.0993. Saving model...\n",
      "\n",
      "LOG: Epoch [270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7401\n",
      "Epoch [270/2000], Avg Train Loss: 4.7401\n",
      "Epoch [270/2000], Avg Val Loss: 3.0978\n",
      "Validation loss improved from 3.0993 to 3.0978. Saving model...\n",
      "\n",
      "LOG: Epoch [271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7218\n",
      "Epoch [271/2000], Avg Train Loss: 4.7218\n",
      "Epoch [271/2000], Avg Val Loss: 3.0964\n",
      "Validation loss improved from 3.0978 to 3.0964. Saving model...\n",
      "\n",
      "LOG: Epoch [272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7373\n",
      "Epoch [272/2000], Avg Train Loss: 4.7373\n",
      "Epoch [272/2000], Avg Val Loss: 3.0949\n",
      "Validation loss improved from 3.0964 to 3.0949. Saving model...\n",
      "\n",
      "LOG: Epoch [273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7560\n",
      "Epoch [273/2000], Avg Train Loss: 4.7560\n",
      "Epoch [273/2000], Avg Val Loss: 3.0934\n",
      "Validation loss improved from 3.0949 to 3.0934. Saving model...\n",
      "\n",
      "LOG: Epoch [274/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6853\n",
      "Epoch [274/2000], Avg Train Loss: 4.6853\n",
      "Epoch [274/2000], Avg Val Loss: 3.0919\n",
      "Validation loss improved from 3.0934 to 3.0919. Saving model...\n",
      "\n",
      "LOG: Epoch [275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7396\n",
      "Epoch [275/2000], Avg Train Loss: 4.7396\n",
      "Epoch [275/2000], Avg Val Loss: 3.0904\n",
      "Validation loss improved from 3.0919 to 3.0904. Saving model...\n",
      "\n",
      "LOG: Epoch [276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7469\n",
      "Epoch [276/2000], Avg Train Loss: 4.7469\n",
      "Epoch [276/2000], Avg Val Loss: 3.0890\n",
      "Validation loss improved from 3.0904 to 3.0890. Saving model...\n",
      "\n",
      "LOG: Epoch [277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6894\n",
      "Epoch [277/2000], Avg Train Loss: 4.6894\n",
      "Epoch [277/2000], Avg Val Loss: 3.0875\n",
      "Validation loss improved from 3.0890 to 3.0875. Saving model...\n",
      "\n",
      "LOG: Epoch [278/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6898\n",
      "Epoch [278/2000], Avg Train Loss: 4.6898\n",
      "Epoch [278/2000], Avg Val Loss: 3.0861\n",
      "Validation loss improved from 3.0875 to 3.0861. Saving model...\n",
      "\n",
      "LOG: Epoch [279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7030\n",
      "Epoch [279/2000], Avg Train Loss: 4.7030\n",
      "Epoch [279/2000], Avg Val Loss: 3.0846\n",
      "Validation loss improved from 3.0861 to 3.0846. Saving model...\n",
      "\n",
      "LOG: Epoch [280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7075\n",
      "Epoch [280/2000], Avg Train Loss: 4.7075\n",
      "Epoch [280/2000], Avg Val Loss: 3.0832\n",
      "Validation loss improved from 3.0846 to 3.0832. Saving model...\n",
      "\n",
      "LOG: Epoch [281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7273\n",
      "Epoch [281/2000], Avg Train Loss: 4.7273\n",
      "Epoch [281/2000], Avg Val Loss: 3.0818\n",
      "Validation loss improved from 3.0832 to 3.0818. Saving model...\n",
      "\n",
      "LOG: Epoch [282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7475\n",
      "Epoch [282/2000], Avg Train Loss: 4.7475\n",
      "Epoch [282/2000], Avg Val Loss: 3.0804\n",
      "Validation loss improved from 3.0818 to 3.0804. Saving model...\n",
      "\n",
      "LOG: Epoch [283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7163\n",
      "Epoch [283/2000], Avg Train Loss: 4.7163\n",
      "Epoch [283/2000], Avg Val Loss: 3.0790\n",
      "Validation loss improved from 3.0804 to 3.0790. Saving model...\n",
      "\n",
      "LOG: Epoch [284/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.6912\n",
      "Epoch [284/2000], Avg Train Loss: 4.6912\n",
      "Epoch [284/2000], Avg Val Loss: 3.0776\n",
      "Validation loss improved from 3.0790 to 3.0776. Saving model...\n",
      "\n",
      "LOG: Epoch [285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6824\n",
      "Epoch [285/2000], Avg Train Loss: 4.6824\n",
      "Epoch [285/2000], Avg Val Loss: 3.0762\n",
      "Validation loss improved from 3.0776 to 3.0762. Saving model...\n",
      "\n",
      "LOG: Epoch [286/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7102\n",
      "Epoch [286/2000], Avg Train Loss: 4.7102\n",
      "Epoch [286/2000], Avg Val Loss: 3.0748\n",
      "Validation loss improved from 3.0762 to 3.0748. Saving model...\n",
      "\n",
      "LOG: Epoch [287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7099\n",
      "Epoch [287/2000], Avg Train Loss: 4.7099\n",
      "Epoch [287/2000], Avg Val Loss: 3.0735\n",
      "Validation loss improved from 3.0748 to 3.0735. Saving model...\n",
      "\n",
      "LOG: Epoch [288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6754\n",
      "Epoch [288/2000], Avg Train Loss: 4.6754\n",
      "Epoch [288/2000], Avg Val Loss: 3.0721\n",
      "Validation loss improved from 3.0735 to 3.0721. Saving model...\n",
      "\n",
      "LOG: Epoch [289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6643\n",
      "Epoch [289/2000], Avg Train Loss: 4.6643\n",
      "Epoch [289/2000], Avg Val Loss: 3.0707\n",
      "Validation loss improved from 3.0721 to 3.0707. Saving model...\n",
      "\n",
      "LOG: Epoch [290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7035\n",
      "Epoch [290/2000], Avg Train Loss: 4.7035\n",
      "Epoch [290/2000], Avg Val Loss: 3.0693\n",
      "Validation loss improved from 3.0707 to 3.0693. Saving model...\n",
      "\n",
      "LOG: Epoch [291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6814\n",
      "Epoch [291/2000], Avg Train Loss: 4.6814\n",
      "Epoch [291/2000], Avg Val Loss: 3.0679\n",
      "Validation loss improved from 3.0693 to 3.0679. Saving model...\n",
      "\n",
      "LOG: Epoch [292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6613\n",
      "Epoch [292/2000], Avg Train Loss: 4.6613\n",
      "Epoch [292/2000], Avg Val Loss: 3.0665\n",
      "Validation loss improved from 3.0679 to 3.0665. Saving model...\n",
      "\n",
      "LOG: Epoch [293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6697\n",
      "Epoch [293/2000], Avg Train Loss: 4.6697\n",
      "Epoch [293/2000], Avg Val Loss: 3.0650\n",
      "Validation loss improved from 3.0665 to 3.0650. Saving model...\n",
      "\n",
      "LOG: Epoch [294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7196\n",
      "Epoch [294/2000], Avg Train Loss: 4.7196\n",
      "Epoch [294/2000], Avg Val Loss: 3.0636\n",
      "Validation loss improved from 3.0650 to 3.0636. Saving model...\n",
      "\n",
      "LOG: Epoch [295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6614\n",
      "Epoch [295/2000], Avg Train Loss: 4.6614\n",
      "Epoch [295/2000], Avg Val Loss: 3.0621\n",
      "Validation loss improved from 3.0636 to 3.0621. Saving model...\n",
      "\n",
      "LOG: Epoch [296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6758\n",
      "Epoch [296/2000], Avg Train Loss: 4.6758\n",
      "Epoch [296/2000], Avg Val Loss: 3.0606\n",
      "Validation loss improved from 3.0621 to 3.0606. Saving model...\n",
      "\n",
      "LOG: Epoch [297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6849\n",
      "Epoch [297/2000], Avg Train Loss: 4.6849\n",
      "Epoch [297/2000], Avg Val Loss: 3.0591\n",
      "Validation loss improved from 3.0606 to 3.0591. Saving model...\n",
      "\n",
      "LOG: Epoch [298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6873\n",
      "Epoch [298/2000], Avg Train Loss: 4.6873\n",
      "Epoch [298/2000], Avg Val Loss: 3.0576\n",
      "Validation loss improved from 3.0591 to 3.0576. Saving model...\n",
      "\n",
      "LOG: Epoch [299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6847\n",
      "Epoch [299/2000], Avg Train Loss: 4.6847\n",
      "Epoch [299/2000], Avg Val Loss: 3.0561\n",
      "Validation loss improved from 3.0576 to 3.0561. Saving model...\n",
      "\n",
      "LOG: Epoch [300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6869\n",
      "Epoch [300/2000], Avg Train Loss: 4.6869\n",
      "Epoch [300/2000], Avg Val Loss: 3.0547\n",
      "Validation loss improved from 3.0561 to 3.0547. Saving model...\n",
      "\n",
      "LOG: Epoch [301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6580\n",
      "Epoch [301/2000], Avg Train Loss: 4.6580\n",
      "Epoch [301/2000], Avg Val Loss: 3.0533\n",
      "Validation loss improved from 3.0547 to 3.0533. Saving model...\n",
      "\n",
      "LOG: Epoch [302/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.6399\n",
      "Epoch [302/2000], Avg Train Loss: 4.6399\n",
      "Epoch [302/2000], Avg Val Loss: 3.0519\n",
      "Validation loss improved from 3.0533 to 3.0519. Saving model...\n",
      "\n",
      "LOG: Epoch [303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6690\n",
      "Epoch [303/2000], Avg Train Loss: 4.6690\n",
      "Epoch [303/2000], Avg Val Loss: 3.0505\n",
      "Validation loss improved from 3.0519 to 3.0505. Saving model...\n",
      "\n",
      "LOG: Epoch [304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6644\n",
      "Epoch [304/2000], Avg Train Loss: 4.6644\n",
      "Epoch [304/2000], Avg Val Loss: 3.0491\n",
      "Validation loss improved from 3.0505 to 3.0491. Saving model...\n",
      "\n",
      "LOG: Epoch [305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6518\n",
      "Epoch [305/2000], Avg Train Loss: 4.6518\n",
      "Epoch [305/2000], Avg Val Loss: 3.0478\n",
      "Validation loss improved from 3.0491 to 3.0478. Saving model...\n",
      "\n",
      "LOG: Epoch [306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6425\n",
      "Epoch [306/2000], Avg Train Loss: 4.6425\n",
      "Epoch [306/2000], Avg Val Loss: 3.0464\n",
      "Validation loss improved from 3.0478 to 3.0464. Saving model...\n",
      "\n",
      "LOG: Epoch [307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6441\n",
      "Epoch [307/2000], Avg Train Loss: 4.6441\n",
      "Epoch [307/2000], Avg Val Loss: 3.0450\n",
      "Validation loss improved from 3.0464 to 3.0450. Saving model...\n",
      "\n",
      "LOG: Epoch [308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6518\n",
      "Epoch [308/2000], Avg Train Loss: 4.6518\n",
      "Epoch [308/2000], Avg Val Loss: 3.0437\n",
      "Validation loss improved from 3.0450 to 3.0437. Saving model...\n",
      "\n",
      "LOG: Epoch [309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6467\n",
      "Epoch [309/2000], Avg Train Loss: 4.6467\n",
      "Epoch [309/2000], Avg Val Loss: 3.0424\n",
      "Validation loss improved from 3.0437 to 3.0424. Saving model...\n",
      "\n",
      "LOG: Epoch [310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6743\n",
      "Epoch [310/2000], Avg Train Loss: 4.6743\n",
      "Epoch [310/2000], Avg Val Loss: 3.0411\n",
      "Validation loss improved from 3.0424 to 3.0411. Saving model...\n",
      "\n",
      "LOG: Epoch [311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6379\n",
      "Epoch [311/2000], Avg Train Loss: 4.6379\n",
      "Epoch [311/2000], Avg Val Loss: 3.0398\n",
      "Validation loss improved from 3.0411 to 3.0398. Saving model...\n",
      "\n",
      "LOG: Epoch [312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6854\n",
      "Epoch [312/2000], Avg Train Loss: 4.6854\n",
      "Epoch [312/2000], Avg Val Loss: 3.0385\n",
      "Validation loss improved from 3.0398 to 3.0385. Saving model...\n",
      "\n",
      "LOG: Epoch [313/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6631\n",
      "Epoch [313/2000], Avg Train Loss: 4.6631\n",
      "Epoch [313/2000], Avg Val Loss: 3.0372\n",
      "Validation loss improved from 3.0385 to 3.0372. Saving model...\n",
      "\n",
      "LOG: Epoch [314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6397\n",
      "Epoch [314/2000], Avg Train Loss: 4.6397\n",
      "Epoch [314/2000], Avg Val Loss: 3.0359\n",
      "Validation loss improved from 3.0372 to 3.0359. Saving model...\n",
      "\n",
      "LOG: Epoch [315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6548\n",
      "Epoch [315/2000], Avg Train Loss: 4.6548\n",
      "Epoch [315/2000], Avg Val Loss: 3.0347\n",
      "Validation loss improved from 3.0359 to 3.0347. Saving model...\n",
      "\n",
      "LOG: Epoch [316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6725\n",
      "Epoch [316/2000], Avg Train Loss: 4.6725\n",
      "Epoch [316/2000], Avg Val Loss: 3.0334\n",
      "Validation loss improved from 3.0347 to 3.0334. Saving model...\n",
      "\n",
      "LOG: Epoch [317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6189\n",
      "Epoch [317/2000], Avg Train Loss: 4.6189\n",
      "Epoch [317/2000], Avg Val Loss: 3.0322\n",
      "Validation loss improved from 3.0334 to 3.0322. Saving model...\n",
      "\n",
      "LOG: Epoch [318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6698\n",
      "Epoch [318/2000], Avg Train Loss: 4.6698\n",
      "Epoch [318/2000], Avg Val Loss: 3.0309\n",
      "Validation loss improved from 3.0322 to 3.0309. Saving model...\n",
      "\n",
      "LOG: Epoch [319/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6349\n",
      "Epoch [319/2000], Avg Train Loss: 4.6349\n",
      "Epoch [319/2000], Avg Val Loss: 3.0297\n",
      "Validation loss improved from 3.0309 to 3.0297. Saving model...\n",
      "\n",
      "LOG: Epoch [320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6379\n",
      "Epoch [320/2000], Avg Train Loss: 4.6379\n",
      "Epoch [320/2000], Avg Val Loss: 3.0284\n",
      "Validation loss improved from 3.0297 to 3.0284. Saving model...\n",
      "\n",
      "LOG: Epoch [321/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.5965\n",
      "Epoch [321/2000], Avg Train Loss: 4.5965\n",
      "Epoch [321/2000], Avg Val Loss: 3.0270\n",
      "Validation loss improved from 3.0284 to 3.0270. Saving model...\n",
      "\n",
      "LOG: Epoch [322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6540\n",
      "Epoch [322/2000], Avg Train Loss: 4.6540\n",
      "Epoch [322/2000], Avg Val Loss: 3.0258\n",
      "Validation loss improved from 3.0270 to 3.0258. Saving model...\n",
      "\n",
      "LOG: Epoch [323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6429\n",
      "Epoch [323/2000], Avg Train Loss: 4.6429\n",
      "Epoch [323/2000], Avg Val Loss: 3.0244\n",
      "Validation loss improved from 3.0258 to 3.0244. Saving model...\n",
      "\n",
      "LOG: Epoch [324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6701\n",
      "Epoch [324/2000], Avg Train Loss: 4.6701\n",
      "Epoch [324/2000], Avg Val Loss: 3.0232\n",
      "Validation loss improved from 3.0244 to 3.0232. Saving model...\n",
      "\n",
      "LOG: Epoch [325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6610\n",
      "Epoch [325/2000], Avg Train Loss: 4.6610\n",
      "Epoch [325/2000], Avg Val Loss: 3.0219\n",
      "Validation loss improved from 3.0232 to 3.0219. Saving model...\n",
      "\n",
      "LOG: Epoch [326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6356\n",
      "Epoch [326/2000], Avg Train Loss: 4.6356\n",
      "Epoch [326/2000], Avg Val Loss: 3.0207\n",
      "Validation loss improved from 3.0219 to 3.0207. Saving model...\n",
      "\n",
      "LOG: Epoch [327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6210\n",
      "Epoch [327/2000], Avg Train Loss: 4.6210\n",
      "Epoch [327/2000], Avg Val Loss: 3.0195\n",
      "Validation loss improved from 3.0207 to 3.0195. Saving model...\n",
      "\n",
      "LOG: Epoch [328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6512\n",
      "Epoch [328/2000], Avg Train Loss: 4.6512\n",
      "Epoch [328/2000], Avg Val Loss: 3.0183\n",
      "Validation loss improved from 3.0195 to 3.0183. Saving model...\n",
      "\n",
      "LOG: Epoch [329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6243\n",
      "Epoch [329/2000], Avg Train Loss: 4.6243\n",
      "Epoch [329/2000], Avg Val Loss: 3.0172\n",
      "Validation loss improved from 3.0183 to 3.0172. Saving model...\n",
      "\n",
      "LOG: Epoch [330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6125\n",
      "Epoch [330/2000], Avg Train Loss: 4.6125\n",
      "Epoch [330/2000], Avg Val Loss: 3.0161\n",
      "Validation loss improved from 3.0172 to 3.0161. Saving model...\n",
      "\n",
      "LOG: Epoch [331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6025\n",
      "Epoch [331/2000], Avg Train Loss: 4.6025\n",
      "Epoch [331/2000], Avg Val Loss: 3.0150\n",
      "Validation loss improved from 3.0161 to 3.0150. Saving model...\n",
      "\n",
      "LOG: Epoch [332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5945\n",
      "Epoch [332/2000], Avg Train Loss: 4.5945\n",
      "Epoch [332/2000], Avg Val Loss: 3.0138\n",
      "Validation loss improved from 3.0150 to 3.0138. Saving model...\n",
      "\n",
      "LOG: Epoch [333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5781\n",
      "Epoch [333/2000], Avg Train Loss: 4.5781\n",
      "Epoch [333/2000], Avg Val Loss: 3.0127\n",
      "Validation loss improved from 3.0138 to 3.0127. Saving model...\n",
      "\n",
      "LOG: Epoch [334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6116\n",
      "Epoch [334/2000], Avg Train Loss: 4.6116\n",
      "Epoch [334/2000], Avg Val Loss: 3.0115\n",
      "Validation loss improved from 3.0127 to 3.0115. Saving model...\n",
      "\n",
      "LOG: Epoch [335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6308\n",
      "Epoch [335/2000], Avg Train Loss: 4.6308\n",
      "Epoch [335/2000], Avg Val Loss: 3.0104\n",
      "Validation loss improved from 3.0115 to 3.0104. Saving model...\n",
      "\n",
      "LOG: Epoch [336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6289\n",
      "Epoch [336/2000], Avg Train Loss: 4.6289\n",
      "Epoch [336/2000], Avg Val Loss: 3.0092\n",
      "Validation loss improved from 3.0104 to 3.0092. Saving model...\n",
      "\n",
      "LOG: Epoch [337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6075\n",
      "Epoch [337/2000], Avg Train Loss: 4.6075\n",
      "Epoch [337/2000], Avg Val Loss: 3.0081\n",
      "Validation loss improved from 3.0092 to 3.0081. Saving model...\n",
      "\n",
      "LOG: Epoch [338/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.5777\n",
      "Epoch [338/2000], Avg Train Loss: 4.5777\n",
      "Epoch [338/2000], Avg Val Loss: 3.0068\n",
      "Validation loss improved from 3.0081 to 3.0068. Saving model...\n",
      "\n",
      "LOG: Epoch [339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6119\n",
      "Epoch [339/2000], Avg Train Loss: 4.6119\n",
      "Epoch [339/2000], Avg Val Loss: 3.0056\n",
      "Validation loss improved from 3.0068 to 3.0056. Saving model...\n",
      "\n",
      "LOG: Epoch [340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6247\n",
      "Epoch [340/2000], Avg Train Loss: 4.6247\n",
      "Epoch [340/2000], Avg Val Loss: 3.0045\n",
      "Validation loss improved from 3.0056 to 3.0045. Saving model...\n",
      "\n",
      "LOG: Epoch [341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6237\n",
      "Epoch [341/2000], Avg Train Loss: 4.6237\n",
      "Epoch [341/2000], Avg Val Loss: 3.0033\n",
      "Validation loss improved from 3.0045 to 3.0033. Saving model...\n",
      "\n",
      "LOG: Epoch [342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5840\n",
      "Epoch [342/2000], Avg Train Loss: 4.5840\n",
      "Epoch [342/2000], Avg Val Loss: 3.0022\n",
      "Validation loss improved from 3.0033 to 3.0022. Saving model...\n",
      "\n",
      "LOG: Epoch [343/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5815\n",
      "Epoch [343/2000], Avg Train Loss: 4.5815\n",
      "Epoch [343/2000], Avg Val Loss: 3.0010\n",
      "Validation loss improved from 3.0022 to 3.0010. Saving model...\n",
      "\n",
      "LOG: Epoch [344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5789\n",
      "Epoch [344/2000], Avg Train Loss: 4.5789\n",
      "Epoch [344/2000], Avg Val Loss: 2.9999\n",
      "Validation loss improved from 3.0010 to 2.9999. Saving model...\n",
      "\n",
      "LOG: Epoch [345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5656\n",
      "Epoch [345/2000], Avg Train Loss: 4.5656\n",
      "Epoch [345/2000], Avg Val Loss: 2.9987\n",
      "Validation loss improved from 2.9999 to 2.9987. Saving model...\n",
      "\n",
      "LOG: Epoch [346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6061\n",
      "Epoch [346/2000], Avg Train Loss: 4.6061\n",
      "Epoch [346/2000], Avg Val Loss: 2.9975\n",
      "Validation loss improved from 2.9987 to 2.9975. Saving model...\n",
      "\n",
      "LOG: Epoch [347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6025\n",
      "Epoch [347/2000], Avg Train Loss: 4.6025\n",
      "Epoch [347/2000], Avg Val Loss: 2.9964\n",
      "Validation loss improved from 2.9975 to 2.9964. Saving model...\n",
      "\n",
      "LOG: Epoch [348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5982\n",
      "Epoch [348/2000], Avg Train Loss: 4.5982\n",
      "Epoch [348/2000], Avg Val Loss: 2.9953\n",
      "Validation loss improved from 2.9964 to 2.9953. Saving model...\n",
      "\n",
      "LOG: Epoch [349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5925\n",
      "Epoch [349/2000], Avg Train Loss: 4.5925\n",
      "Epoch [349/2000], Avg Val Loss: 2.9942\n",
      "Validation loss improved from 2.9953 to 2.9942. Saving model...\n",
      "\n",
      "LOG: Epoch [350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6018\n",
      "Epoch [350/2000], Avg Train Loss: 4.6018\n",
      "Epoch [350/2000], Avg Val Loss: 2.9931\n",
      "Validation loss improved from 2.9942 to 2.9931. Saving model...\n",
      "\n",
      "LOG: Epoch [351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5475\n",
      "Epoch [351/2000], Avg Train Loss: 4.5475\n",
      "Epoch [351/2000], Avg Val Loss: 2.9920\n",
      "Validation loss improved from 2.9931 to 2.9920. Saving model...\n",
      "\n",
      "LOG: Epoch [352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6238\n",
      "Epoch [352/2000], Avg Train Loss: 4.6238\n",
      "Epoch [352/2000], Avg Val Loss: 2.9909\n",
      "Validation loss improved from 2.9920 to 2.9909. Saving model...\n",
      "\n",
      "LOG: Epoch [353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6237\n",
      "Epoch [353/2000], Avg Train Loss: 4.6237\n",
      "Epoch [353/2000], Avg Val Loss: 2.9899\n",
      "Validation loss improved from 2.9909 to 2.9899. Saving model...\n",
      "\n",
      "LOG: Epoch [354/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6010\n",
      "Epoch [354/2000], Avg Train Loss: 4.6010\n",
      "Epoch [354/2000], Avg Val Loss: 2.9889\n",
      "Validation loss improved from 2.9899 to 2.9889. Saving model...\n",
      "\n",
      "LOG: Epoch [355/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.5524\n",
      "Epoch [355/2000], Avg Train Loss: 4.5524\n",
      "Epoch [355/2000], Avg Val Loss: 2.9878\n",
      "Validation loss improved from 2.9889 to 2.9878. Saving model...\n",
      "\n",
      "LOG: Epoch [356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5430\n",
      "Epoch [356/2000], Avg Train Loss: 4.5430\n",
      "Epoch [356/2000], Avg Val Loss: 2.9868\n",
      "Validation loss improved from 2.9878 to 2.9868. Saving model...\n",
      "\n",
      "LOG: Epoch [357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5934\n",
      "Epoch [357/2000], Avg Train Loss: 4.5934\n",
      "Epoch [357/2000], Avg Val Loss: 2.9857\n",
      "Validation loss improved from 2.9868 to 2.9857. Saving model...\n",
      "\n",
      "LOG: Epoch [358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5800\n",
      "Epoch [358/2000], Avg Train Loss: 4.5800\n",
      "Epoch [358/2000], Avg Val Loss: 2.9847\n",
      "Validation loss improved from 2.9857 to 2.9847. Saving model...\n",
      "\n",
      "LOG: Epoch [359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6271\n",
      "Epoch [359/2000], Avg Train Loss: 4.6271\n",
      "Epoch [359/2000], Avg Val Loss: 2.9836\n",
      "Validation loss improved from 2.9847 to 2.9836. Saving model...\n",
      "\n",
      "LOG: Epoch [360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5538\n",
      "Epoch [360/2000], Avg Train Loss: 4.5538\n",
      "Epoch [360/2000], Avg Val Loss: 2.9826\n",
      "Validation loss improved from 2.9836 to 2.9826. Saving model...\n",
      "\n",
      "LOG: Epoch [361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5558\n",
      "Epoch [361/2000], Avg Train Loss: 4.5558\n",
      "Epoch [361/2000], Avg Val Loss: 2.9815\n",
      "Validation loss improved from 2.9826 to 2.9815. Saving model...\n",
      "\n",
      "LOG: Epoch [362/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5995\n",
      "Epoch [362/2000], Avg Train Loss: 4.5995\n",
      "Epoch [362/2000], Avg Val Loss: 2.9804\n",
      "Validation loss improved from 2.9815 to 2.9804. Saving model...\n",
      "\n",
      "LOG: Epoch [363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5806\n",
      "Epoch [363/2000], Avg Train Loss: 4.5806\n",
      "Epoch [363/2000], Avg Val Loss: 2.9794\n",
      "Validation loss improved from 2.9804 to 2.9794. Saving model...\n",
      "\n",
      "LOG: Epoch [364/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5392\n",
      "Epoch [364/2000], Avg Train Loss: 4.5392\n",
      "Epoch [364/2000], Avg Val Loss: 2.9784\n",
      "Validation loss improved from 2.9794 to 2.9784. Saving model...\n",
      "\n",
      "LOG: Epoch [365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5872\n",
      "Epoch [365/2000], Avg Train Loss: 4.5872\n",
      "Epoch [365/2000], Avg Val Loss: 2.9773\n",
      "Validation loss improved from 2.9784 to 2.9773. Saving model...\n",
      "\n",
      "LOG: Epoch [366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5382\n",
      "Epoch [366/2000], Avg Train Loss: 4.5382\n",
      "Epoch [366/2000], Avg Val Loss: 2.9762\n",
      "Validation loss improved from 2.9773 to 2.9762. Saving model...\n",
      "\n",
      "LOG: Epoch [367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5801\n",
      "Epoch [367/2000], Avg Train Loss: 4.5801\n",
      "Epoch [367/2000], Avg Val Loss: 2.9751\n",
      "Validation loss improved from 2.9762 to 2.9751. Saving model...\n",
      "\n",
      "LOG: Epoch [368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5813\n",
      "Epoch [368/2000], Avg Train Loss: 4.5813\n",
      "Epoch [368/2000], Avg Val Loss: 2.9740\n",
      "Validation loss improved from 2.9751 to 2.9740. Saving model...\n",
      "\n",
      "LOG: Epoch [369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5452\n",
      "Epoch [369/2000], Avg Train Loss: 4.5452\n",
      "Epoch [369/2000], Avg Val Loss: 2.9728\n",
      "Validation loss improved from 2.9740 to 2.9728. Saving model...\n",
      "\n",
      "LOG: Epoch [370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5810\n",
      "Epoch [370/2000], Avg Train Loss: 4.5810\n",
      "Epoch [370/2000], Avg Val Loss: 2.9717\n",
      "Validation loss improved from 2.9728 to 2.9717. Saving model...\n",
      "\n",
      "LOG: Epoch [371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5579\n",
      "Epoch [371/2000], Avg Train Loss: 4.5579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [371/2000], Avg Val Loss: 2.9706\n",
      "Validation loss improved from 2.9717 to 2.9706. Saving model...\n",
      "\n",
      "LOG: Epoch [372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5502\n",
      "Epoch [372/2000], Avg Train Loss: 4.5502\n",
      "Epoch [372/2000], Avg Val Loss: 2.9695\n",
      "Validation loss improved from 2.9706 to 2.9695. Saving model...\n",
      "\n",
      "LOG: Epoch [373/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5515\n",
      "Epoch [373/2000], Avg Train Loss: 4.5515\n",
      "Epoch [373/2000], Avg Val Loss: 2.9684\n",
      "Validation loss improved from 2.9695 to 2.9684. Saving model...\n",
      "\n",
      "LOG: Epoch [374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5557\n",
      "Epoch [374/2000], Avg Train Loss: 4.5557\n",
      "Epoch [374/2000], Avg Val Loss: 2.9673\n",
      "Validation loss improved from 2.9684 to 2.9673. Saving model...\n",
      "\n",
      "LOG: Epoch [375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5497\n",
      "Epoch [375/2000], Avg Train Loss: 4.5497\n",
      "Epoch [375/2000], Avg Val Loss: 2.9662\n",
      "Validation loss improved from 2.9673 to 2.9662. Saving model...\n",
      "\n",
      "LOG: Epoch [376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5904\n",
      "Epoch [376/2000], Avg Train Loss: 4.5904\n",
      "Epoch [376/2000], Avg Val Loss: 2.9650\n",
      "Validation loss improved from 2.9662 to 2.9650. Saving model...\n",
      "\n",
      "LOG: Epoch [377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5531\n",
      "Epoch [377/2000], Avg Train Loss: 4.5531\n",
      "Epoch [377/2000], Avg Val Loss: 2.9640\n",
      "Validation loss improved from 2.9650 to 2.9640. Saving model...\n",
      "\n",
      "LOG: Epoch [378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5177\n",
      "Epoch [378/2000], Avg Train Loss: 4.5177\n",
      "Epoch [378/2000], Avg Val Loss: 2.9628\n",
      "Validation loss improved from 2.9640 to 2.9628. Saving model...\n",
      "\n",
      "LOG: Epoch [379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4918\n",
      "Epoch [379/2000], Avg Train Loss: 4.4918\n",
      "Epoch [379/2000], Avg Val Loss: 2.9617\n",
      "Validation loss improved from 2.9628 to 2.9617. Saving model...\n",
      "\n",
      "LOG: Epoch [380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5473\n",
      "Epoch [380/2000], Avg Train Loss: 4.5473\n",
      "Epoch [380/2000], Avg Val Loss: 2.9606\n",
      "Validation loss improved from 2.9617 to 2.9606. Saving model...\n",
      "\n",
      "LOG: Epoch [381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5362\n",
      "Epoch [381/2000], Avg Train Loss: 4.5362\n",
      "Epoch [381/2000], Avg Val Loss: 2.9594\n",
      "Validation loss improved from 2.9606 to 2.9594. Saving model...\n",
      "\n",
      "LOG: Epoch [382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5237\n",
      "Epoch [382/2000], Avg Train Loss: 4.5237\n",
      "Epoch [382/2000], Avg Val Loss: 2.9583\n",
      "Validation loss improved from 2.9594 to 2.9583. Saving model...\n",
      "\n",
      "LOG: Epoch [383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4963\n",
      "Epoch [383/2000], Avg Train Loss: 4.4963\n",
      "Epoch [383/2000], Avg Val Loss: 2.9571\n",
      "Validation loss improved from 2.9583 to 2.9571. Saving model...\n",
      "\n",
      "LOG: Epoch [384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5338\n",
      "Epoch [384/2000], Avg Train Loss: 4.5338\n",
      "Epoch [384/2000], Avg Val Loss: 2.9560\n",
      "Validation loss improved from 2.9571 to 2.9560. Saving model...\n",
      "\n",
      "LOG: Epoch [385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5243\n",
      "Epoch [385/2000], Avg Train Loss: 4.5243\n",
      "Epoch [385/2000], Avg Val Loss: 2.9548\n",
      "Validation loss improved from 2.9560 to 2.9548. Saving model...\n",
      "\n",
      "LOG: Epoch [386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5673\n",
      "Epoch [386/2000], Avg Train Loss: 4.5673\n",
      "Epoch [386/2000], Avg Val Loss: 2.9536\n",
      "Validation loss improved from 2.9548 to 2.9536. Saving model...\n",
      "\n",
      "LOG: Epoch [387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5759\n",
      "Epoch [387/2000], Avg Train Loss: 4.5759\n",
      "Epoch [387/2000], Avg Val Loss: 2.9525\n",
      "Validation loss improved from 2.9536 to 2.9525. Saving model...\n",
      "\n",
      "LOG: Epoch [388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5440\n",
      "Epoch [388/2000], Avg Train Loss: 4.5440\n",
      "Epoch [388/2000], Avg Val Loss: 2.9514\n",
      "Validation loss improved from 2.9525 to 2.9514. Saving model...\n",
      "\n",
      "LOG: Epoch [389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5198\n",
      "Epoch [389/2000], Avg Train Loss: 4.5198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [389/2000], Avg Val Loss: 2.9503\n",
      "Validation loss improved from 2.9514 to 2.9503. Saving model...\n",
      "\n",
      "LOG: Epoch [390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5135\n",
      "Epoch [390/2000], Avg Train Loss: 4.5135\n",
      "Epoch [390/2000], Avg Val Loss: 2.9493\n",
      "Validation loss improved from 2.9503 to 2.9493. Saving model...\n",
      "\n",
      "LOG: Epoch [391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5304\n",
      "Epoch [391/2000], Avg Train Loss: 4.5304\n",
      "Epoch [391/2000], Avg Val Loss: 2.9482\n",
      "Validation loss improved from 2.9493 to 2.9482. Saving model...\n",
      "\n",
      "LOG: Epoch [392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4905\n",
      "Epoch [392/2000], Avg Train Loss: 4.4905\n",
      "Epoch [392/2000], Avg Val Loss: 2.9471\n",
      "Validation loss improved from 2.9482 to 2.9471. Saving model...\n",
      "\n",
      "LOG: Epoch [393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4833\n",
      "Epoch [393/2000], Avg Train Loss: 4.4833\n",
      "Epoch [393/2000], Avg Val Loss: 2.9460\n",
      "Validation loss improved from 2.9471 to 2.9460. Saving model...\n",
      "\n",
      "LOG: Epoch [394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5207\n",
      "Epoch [394/2000], Avg Train Loss: 4.5207\n",
      "Epoch [394/2000], Avg Val Loss: 2.9449\n",
      "Validation loss improved from 2.9460 to 2.9449. Saving model...\n",
      "\n",
      "LOG: Epoch [395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4894\n",
      "Epoch [395/2000], Avg Train Loss: 4.4894\n",
      "Epoch [395/2000], Avg Val Loss: 2.9438\n",
      "Validation loss improved from 2.9449 to 2.9438. Saving model...\n",
      "\n",
      "LOG: Epoch [396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5070\n",
      "Epoch [396/2000], Avg Train Loss: 4.5070\n",
      "Epoch [396/2000], Avg Val Loss: 2.9427\n",
      "Validation loss improved from 2.9438 to 2.9427. Saving model...\n",
      "\n",
      "LOG: Epoch [397/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5149\n",
      "Epoch [397/2000], Avg Train Loss: 4.5149\n",
      "Epoch [397/2000], Avg Val Loss: 2.9416\n",
      "Validation loss improved from 2.9427 to 2.9416. Saving model...\n",
      "\n",
      "LOG: Epoch [398/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5735\n",
      "Epoch [398/2000], Avg Train Loss: 4.5735\n",
      "Epoch [398/2000], Avg Val Loss: 2.9405\n",
      "Validation loss improved from 2.9416 to 2.9405. Saving model...\n",
      "\n",
      "LOG: Epoch [399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4865\n",
      "Epoch [399/2000], Avg Train Loss: 4.4865\n",
      "Epoch [399/2000], Avg Val Loss: 2.9394\n",
      "Validation loss improved from 2.9405 to 2.9394. Saving model...\n",
      "\n",
      "LOG: Epoch [400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4984\n",
      "Epoch [400/2000], Avg Train Loss: 4.4984\n",
      "Epoch [400/2000], Avg Val Loss: 2.9383\n",
      "Validation loss improved from 2.9394 to 2.9383. Saving model...\n",
      "\n",
      "LOG: Epoch [401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5027\n",
      "Epoch [401/2000], Avg Train Loss: 4.5027\n",
      "Epoch [401/2000], Avg Val Loss: 2.9372\n",
      "Validation loss improved from 2.9383 to 2.9372. Saving model...\n",
      "\n",
      "LOG: Epoch [402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5044\n",
      "Epoch [402/2000], Avg Train Loss: 4.5044\n",
      "Epoch [402/2000], Avg Val Loss: 2.9362\n",
      "Validation loss improved from 2.9372 to 2.9362. Saving model...\n",
      "\n",
      "LOG: Epoch [403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5136\n",
      "Epoch [403/2000], Avg Train Loss: 4.5136\n",
      "Epoch [403/2000], Avg Val Loss: 2.9351\n",
      "Validation loss improved from 2.9362 to 2.9351. Saving model...\n",
      "\n",
      "LOG: Epoch [404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5494\n",
      "Epoch [404/2000], Avg Train Loss: 4.5494\n",
      "Epoch [404/2000], Avg Val Loss: 2.9340\n",
      "Validation loss improved from 2.9351 to 2.9340. Saving model...\n",
      "\n",
      "LOG: Epoch [405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5449\n",
      "Epoch [405/2000], Avg Train Loss: 4.5449\n",
      "Epoch [405/2000], Avg Val Loss: 2.9329\n",
      "Validation loss improved from 2.9340 to 2.9329. Saving model...\n",
      "\n",
      "LOG: Epoch [406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5326\n",
      "Epoch [406/2000], Avg Train Loss: 4.5326\n",
      "Epoch [406/2000], Avg Val Loss: 2.9319\n",
      "Validation loss improved from 2.9329 to 2.9319. Saving model...\n",
      "\n",
      "LOG: Epoch [407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4825\n",
      "Epoch [407/2000], Avg Train Loss: 4.4825\n",
      "Epoch [407/2000], Avg Val Loss: 2.9308\n",
      "Validation loss improved from 2.9319 to 2.9308. Saving model...\n",
      "\n",
      "LOG: Epoch [408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5173\n",
      "Epoch [408/2000], Avg Train Loss: 4.5173\n",
      "Epoch [408/2000], Avg Val Loss: 2.9298\n",
      "Validation loss improved from 2.9308 to 2.9298. Saving model...\n",
      "\n",
      "LOG: Epoch [409/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.5178\n",
      "Epoch [409/2000], Avg Train Loss: 4.5178\n",
      "Epoch [409/2000], Avg Val Loss: 2.9287\n",
      "Validation loss improved from 2.9298 to 2.9287. Saving model...\n",
      "\n",
      "LOG: Epoch [410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5266\n",
      "Epoch [410/2000], Avg Train Loss: 4.5266\n",
      "Epoch [410/2000], Avg Val Loss: 2.9277\n",
      "Validation loss improved from 2.9287 to 2.9277. Saving model...\n",
      "\n",
      "LOG: Epoch [411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5013\n",
      "Epoch [411/2000], Avg Train Loss: 4.5013\n",
      "Epoch [411/2000], Avg Val Loss: 2.9266\n",
      "Validation loss improved from 2.9277 to 2.9266. Saving model...\n",
      "\n",
      "LOG: Epoch [412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5109\n",
      "Epoch [412/2000], Avg Train Loss: 4.5109\n",
      "Epoch [412/2000], Avg Val Loss: 2.9256\n",
      "Validation loss improved from 2.9266 to 2.9256. Saving model...\n",
      "\n",
      "LOG: Epoch [413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4901\n",
      "Epoch [413/2000], Avg Train Loss: 4.4901\n",
      "Epoch [413/2000], Avg Val Loss: 2.9246\n",
      "Validation loss improved from 2.9256 to 2.9246. Saving model...\n",
      "\n",
      "LOG: Epoch [414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5152\n",
      "Epoch [414/2000], Avg Train Loss: 4.5152\n",
      "Epoch [414/2000], Avg Val Loss: 2.9235\n",
      "Validation loss improved from 2.9246 to 2.9235. Saving model...\n",
      "\n",
      "LOG: Epoch [415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4780\n",
      "Epoch [415/2000], Avg Train Loss: 4.4780\n",
      "Epoch [415/2000], Avg Val Loss: 2.9225\n",
      "Validation loss improved from 2.9235 to 2.9225. Saving model...\n",
      "\n",
      "LOG: Epoch [416/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5001\n",
      "Epoch [416/2000], Avg Train Loss: 4.5001\n",
      "Epoch [416/2000], Avg Val Loss: 2.9215\n",
      "Validation loss improved from 2.9225 to 2.9215. Saving model...\n",
      "\n",
      "LOG: Epoch [417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4525\n",
      "Epoch [417/2000], Avg Train Loss: 4.4525\n",
      "Epoch [417/2000], Avg Val Loss: 2.9205\n",
      "Validation loss improved from 2.9215 to 2.9205. Saving model...\n",
      "\n",
      "LOG: Epoch [418/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4815\n",
      "Epoch [418/2000], Avg Train Loss: 4.4815\n",
      "Epoch [418/2000], Avg Val Loss: 2.9195\n",
      "Validation loss improved from 2.9205 to 2.9195. Saving model...\n",
      "\n",
      "LOG: Epoch [419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5298\n",
      "Epoch [419/2000], Avg Train Loss: 4.5298\n",
      "Epoch [419/2000], Avg Val Loss: 2.9185\n",
      "Validation loss improved from 2.9195 to 2.9185. Saving model...\n",
      "\n",
      "LOG: Epoch [420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4558\n",
      "Epoch [420/2000], Avg Train Loss: 4.4558\n",
      "Epoch [420/2000], Avg Val Loss: 2.9175\n",
      "Validation loss improved from 2.9185 to 2.9175. Saving model...\n",
      "\n",
      "LOG: Epoch [421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4804\n",
      "Epoch [421/2000], Avg Train Loss: 4.4804\n",
      "Epoch [421/2000], Avg Val Loss: 2.9165\n",
      "Validation loss improved from 2.9175 to 2.9165. Saving model...\n",
      "\n",
      "LOG: Epoch [422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5376\n",
      "Epoch [422/2000], Avg Train Loss: 4.5376\n",
      "Epoch [422/2000], Avg Val Loss: 2.9155\n",
      "Validation loss improved from 2.9165 to 2.9155. Saving model...\n",
      "\n",
      "LOG: Epoch [423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4851\n",
      "Epoch [423/2000], Avg Train Loss: 4.4851\n",
      "Epoch [423/2000], Avg Val Loss: 2.9144\n",
      "Validation loss improved from 2.9155 to 2.9144. Saving model...\n",
      "\n",
      "LOG: Epoch [424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4458\n",
      "Epoch [424/2000], Avg Train Loss: 4.4458\n",
      "Epoch [424/2000], Avg Val Loss: 2.9134\n",
      "Validation loss improved from 2.9144 to 2.9134. Saving model...\n",
      "\n",
      "LOG: Epoch [425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4466\n",
      "Epoch [425/2000], Avg Train Loss: 4.4466\n",
      "Epoch [425/2000], Avg Val Loss: 2.9124\n",
      "Validation loss improved from 2.9134 to 2.9124. Saving model...\n",
      "\n",
      "LOG: Epoch [426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5032\n",
      "Epoch [426/2000], Avg Train Loss: 4.5032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [426/2000], Avg Val Loss: 2.9113\n",
      "Validation loss improved from 2.9124 to 2.9113. Saving model...\n",
      "\n",
      "LOG: Epoch [427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4683\n",
      "Epoch [427/2000], Avg Train Loss: 4.4683\n",
      "Epoch [427/2000], Avg Val Loss: 2.9103\n",
      "Validation loss improved from 2.9113 to 2.9103. Saving model...\n",
      "\n",
      "LOG: Epoch [428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4849\n",
      "Epoch [428/2000], Avg Train Loss: 4.4849\n",
      "Epoch [428/2000], Avg Val Loss: 2.9093\n",
      "Validation loss improved from 2.9103 to 2.9093. Saving model...\n",
      "\n",
      "LOG: Epoch [429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4548\n",
      "Epoch [429/2000], Avg Train Loss: 4.4548\n",
      "Epoch [429/2000], Avg Val Loss: 2.9083\n",
      "Validation loss improved from 2.9093 to 2.9083. Saving model...\n",
      "\n",
      "LOG: Epoch [430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4585\n",
      "Epoch [430/2000], Avg Train Loss: 4.4585\n",
      "Epoch [430/2000], Avg Val Loss: 2.9073\n",
      "Validation loss improved from 2.9083 to 2.9073. Saving model...\n",
      "\n",
      "LOG: Epoch [431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4654\n",
      "Epoch [431/2000], Avg Train Loss: 4.4654\n",
      "Epoch [431/2000], Avg Val Loss: 2.9063\n",
      "Validation loss improved from 2.9073 to 2.9063. Saving model...\n",
      "\n",
      "LOG: Epoch [432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4769\n",
      "Epoch [432/2000], Avg Train Loss: 4.4769\n",
      "Epoch [432/2000], Avg Val Loss: 2.9053\n",
      "Validation loss improved from 2.9063 to 2.9053. Saving model...\n",
      "\n",
      "LOG: Epoch [433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4757\n",
      "Epoch [433/2000], Avg Train Loss: 4.4757\n",
      "Epoch [433/2000], Avg Val Loss: 2.9044\n",
      "Validation loss improved from 2.9053 to 2.9044. Saving model...\n",
      "\n",
      "LOG: Epoch [434/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4666\n",
      "Epoch [434/2000], Avg Train Loss: 4.4666\n",
      "Epoch [434/2000], Avg Val Loss: 2.9034\n",
      "Validation loss improved from 2.9044 to 2.9034. Saving model...\n",
      "\n",
      "LOG: Epoch [435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4884\n",
      "Epoch [435/2000], Avg Train Loss: 4.4884\n",
      "Epoch [435/2000], Avg Val Loss: 2.9025\n",
      "Validation loss improved from 2.9034 to 2.9025. Saving model...\n",
      "\n",
      "LOG: Epoch [436/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5040\n",
      "Epoch [436/2000], Avg Train Loss: 4.5040\n",
      "Epoch [436/2000], Avg Val Loss: 2.9015\n",
      "Validation loss improved from 2.9025 to 2.9015. Saving model...\n",
      "\n",
      "LOG: Epoch [437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4555\n",
      "Epoch [437/2000], Avg Train Loss: 4.4555\n",
      "Epoch [437/2000], Avg Val Loss: 2.9006\n",
      "Validation loss improved from 2.9015 to 2.9006. Saving model...\n",
      "\n",
      "LOG: Epoch [438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4566\n",
      "Epoch [438/2000], Avg Train Loss: 4.4566\n",
      "Epoch [438/2000], Avg Val Loss: 2.8997\n",
      "Validation loss improved from 2.9006 to 2.8997. Saving model...\n",
      "\n",
      "LOG: Epoch [439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4693\n",
      "Epoch [439/2000], Avg Train Loss: 4.4693\n",
      "Epoch [439/2000], Avg Val Loss: 2.8988\n",
      "Validation loss improved from 2.8997 to 2.8988. Saving model...\n",
      "\n",
      "LOG: Epoch [440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4659\n",
      "Epoch [440/2000], Avg Train Loss: 4.4659\n",
      "Epoch [440/2000], Avg Val Loss: 2.8978\n",
      "Validation loss improved from 2.8988 to 2.8978. Saving model...\n",
      "\n",
      "LOG: Epoch [441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4401\n",
      "Epoch [441/2000], Avg Train Loss: 4.4401\n",
      "Epoch [441/2000], Avg Val Loss: 2.8969\n",
      "Validation loss improved from 2.8978 to 2.8969. Saving model...\n",
      "\n",
      "LOG: Epoch [442/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4428\n",
      "Epoch [442/2000], Avg Train Loss: 4.4428\n",
      "Epoch [442/2000], Avg Val Loss: 2.8959\n",
      "Validation loss improved from 2.8969 to 2.8959. Saving model...\n",
      "\n",
      "LOG: Epoch [443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4373\n",
      "Epoch [443/2000], Avg Train Loss: 4.4373\n",
      "Epoch [443/2000], Avg Val Loss: 2.8950\n",
      "Validation loss improved from 2.8959 to 2.8950. Saving model...\n",
      "\n",
      "LOG: Epoch [444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4843\n",
      "Epoch [444/2000], Avg Train Loss: 4.4843\n",
      "Epoch [444/2000], Avg Val Loss: 2.8940\n",
      "Validation loss improved from 2.8950 to 2.8940. Saving model...\n",
      "\n",
      "LOG: Epoch [445/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.4269\n",
      "Epoch [445/2000], Avg Train Loss: 4.4269\n",
      "Epoch [445/2000], Avg Val Loss: 2.8931\n",
      "Validation loss improved from 2.8940 to 2.8931. Saving model...\n",
      "\n",
      "LOG: Epoch [446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4245\n",
      "Epoch [446/2000], Avg Train Loss: 4.4245\n",
      "Epoch [446/2000], Avg Val Loss: 2.8921\n",
      "Validation loss improved from 2.8931 to 2.8921. Saving model...\n",
      "\n",
      "LOG: Epoch [447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4399\n",
      "Epoch [447/2000], Avg Train Loss: 4.4399\n",
      "Epoch [447/2000], Avg Val Loss: 2.8911\n",
      "Validation loss improved from 2.8921 to 2.8911. Saving model...\n",
      "\n",
      "LOG: Epoch [448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4346\n",
      "Epoch [448/2000], Avg Train Loss: 4.4346\n",
      "Epoch [448/2000], Avg Val Loss: 2.8901\n",
      "Validation loss improved from 2.8911 to 2.8901. Saving model...\n",
      "\n",
      "LOG: Epoch [449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4150\n",
      "Epoch [449/2000], Avg Train Loss: 4.4150\n",
      "Epoch [449/2000], Avg Val Loss: 2.8890\n",
      "Validation loss improved from 2.8901 to 2.8890. Saving model...\n",
      "\n",
      "LOG: Epoch [450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4372\n",
      "Epoch [450/2000], Avg Train Loss: 4.4372\n",
      "Epoch [450/2000], Avg Val Loss: 2.8880\n",
      "Validation loss improved from 2.8890 to 2.8880. Saving model...\n",
      "\n",
      "LOG: Epoch [451/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4334\n",
      "Epoch [451/2000], Avg Train Loss: 4.4334\n",
      "Epoch [451/2000], Avg Val Loss: 2.8869\n",
      "Validation loss improved from 2.8880 to 2.8869. Saving model...\n",
      "\n",
      "LOG: Epoch [452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4386\n",
      "Epoch [452/2000], Avg Train Loss: 4.4386\n",
      "Epoch [452/2000], Avg Val Loss: 2.8858\n",
      "Validation loss improved from 2.8869 to 2.8858. Saving model...\n",
      "\n",
      "LOG: Epoch [453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4308\n",
      "Epoch [453/2000], Avg Train Loss: 4.4308\n",
      "Epoch [453/2000], Avg Val Loss: 2.8847\n",
      "Validation loss improved from 2.8858 to 2.8847. Saving model...\n",
      "\n",
      "LOG: Epoch [454/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4716\n",
      "Epoch [454/2000], Avg Train Loss: 4.4716\n",
      "Epoch [454/2000], Avg Val Loss: 2.8836\n",
      "Validation loss improved from 2.8847 to 2.8836. Saving model...\n",
      "\n",
      "LOG: Epoch [455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4115\n",
      "Epoch [455/2000], Avg Train Loss: 4.4115\n",
      "Epoch [455/2000], Avg Val Loss: 2.8825\n",
      "Validation loss improved from 2.8836 to 2.8825. Saving model...\n",
      "\n",
      "LOG: Epoch [456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4446\n",
      "Epoch [456/2000], Avg Train Loss: 4.4446\n",
      "Epoch [456/2000], Avg Val Loss: 2.8814\n",
      "Validation loss improved from 2.8825 to 2.8814. Saving model...\n",
      "\n",
      "LOG: Epoch [457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4629\n",
      "Epoch [457/2000], Avg Train Loss: 4.4629\n",
      "Epoch [457/2000], Avg Val Loss: 2.8804\n",
      "Validation loss improved from 2.8814 to 2.8804. Saving model...\n",
      "\n",
      "LOG: Epoch [458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4262\n",
      "Epoch [458/2000], Avg Train Loss: 4.4262\n",
      "Epoch [458/2000], Avg Val Loss: 2.8793\n",
      "Validation loss improved from 2.8804 to 2.8793. Saving model...\n",
      "\n",
      "LOG: Epoch [459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4555\n",
      "Epoch [459/2000], Avg Train Loss: 4.4555\n",
      "Epoch [459/2000], Avg Val Loss: 2.8783\n",
      "Validation loss improved from 2.8793 to 2.8783. Saving model...\n",
      "\n",
      "LOG: Epoch [460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4174\n",
      "Epoch [460/2000], Avg Train Loss: 4.4174\n",
      "Epoch [460/2000], Avg Val Loss: 2.8773\n",
      "Validation loss improved from 2.8783 to 2.8773. Saving model...\n",
      "\n",
      "LOG: Epoch [461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4314\n",
      "Epoch [461/2000], Avg Train Loss: 4.4314\n",
      "Epoch [461/2000], Avg Val Loss: 2.8763\n",
      "Validation loss improved from 2.8773 to 2.8763. Saving model...\n",
      "\n",
      "LOG: Epoch [462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3777\n",
      "Epoch [462/2000], Avg Train Loss: 4.3777\n",
      "Epoch [462/2000], Avg Val Loss: 2.8753\n",
      "Validation loss improved from 2.8763 to 2.8753. Saving model...\n",
      "\n",
      "LOG: Epoch [463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4257\n",
      "Epoch [463/2000], Avg Train Loss: 4.4257\n",
      "Epoch [463/2000], Avg Val Loss: 2.8742\n",
      "Validation loss improved from 2.8753 to 2.8742. Saving model...\n",
      "\n",
      "LOG: Epoch [464/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.4024\n",
      "Epoch [464/2000], Avg Train Loss: 4.4024\n",
      "Epoch [464/2000], Avg Val Loss: 2.8732\n",
      "Validation loss improved from 2.8742 to 2.8732. Saving model...\n",
      "\n",
      "LOG: Epoch [465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3947\n",
      "Epoch [465/2000], Avg Train Loss: 4.3947\n",
      "Epoch [465/2000], Avg Val Loss: 2.8723\n",
      "Validation loss improved from 2.8732 to 2.8723. Saving model...\n",
      "\n",
      "LOG: Epoch [466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4197\n",
      "Epoch [466/2000], Avg Train Loss: 4.4197\n",
      "Epoch [466/2000], Avg Val Loss: 2.8713\n",
      "Validation loss improved from 2.8723 to 2.8713. Saving model...\n",
      "\n",
      "LOG: Epoch [467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3990\n",
      "Epoch [467/2000], Avg Train Loss: 4.3990\n",
      "Epoch [467/2000], Avg Val Loss: 2.8703\n",
      "Validation loss improved from 2.8713 to 2.8703. Saving model...\n",
      "\n",
      "LOG: Epoch [468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3436\n",
      "Epoch [468/2000], Avg Train Loss: 4.3436\n",
      "Epoch [468/2000], Avg Val Loss: 2.8693\n",
      "Validation loss improved from 2.8703 to 2.8693. Saving model...\n",
      "\n",
      "LOG: Epoch [469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4014\n",
      "Epoch [469/2000], Avg Train Loss: 4.4014\n",
      "Epoch [469/2000], Avg Val Loss: 2.8683\n",
      "Validation loss improved from 2.8693 to 2.8683. Saving model...\n",
      "\n",
      "LOG: Epoch [470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4006\n",
      "Epoch [470/2000], Avg Train Loss: 4.4006\n",
      "Epoch [470/2000], Avg Val Loss: 2.8673\n",
      "Validation loss improved from 2.8683 to 2.8673. Saving model...\n",
      "\n",
      "LOG: Epoch [471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4275\n",
      "Epoch [471/2000], Avg Train Loss: 4.4275\n",
      "Epoch [471/2000], Avg Val Loss: 2.8663\n",
      "Validation loss improved from 2.8673 to 2.8663. Saving model...\n",
      "\n",
      "LOG: Epoch [472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4123\n",
      "Epoch [472/2000], Avg Train Loss: 4.4123\n",
      "Epoch [472/2000], Avg Val Loss: 2.8653\n",
      "Validation loss improved from 2.8663 to 2.8653. Saving model...\n",
      "\n",
      "LOG: Epoch [473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4293\n",
      "Epoch [473/2000], Avg Train Loss: 4.4293\n",
      "Epoch [473/2000], Avg Val Loss: 2.8643\n",
      "Validation loss improved from 2.8653 to 2.8643. Saving model...\n",
      "\n",
      "LOG: Epoch [474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4083\n",
      "Epoch [474/2000], Avg Train Loss: 4.4083\n",
      "Epoch [474/2000], Avg Val Loss: 2.8634\n",
      "Validation loss improved from 2.8643 to 2.8634. Saving model...\n",
      "\n",
      "LOG: Epoch [475/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3922\n",
      "Epoch [475/2000], Avg Train Loss: 4.3922\n",
      "Epoch [475/2000], Avg Val Loss: 2.8624\n",
      "Validation loss improved from 2.8634 to 2.8624. Saving model...\n",
      "\n",
      "LOG: Epoch [476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3995\n",
      "Epoch [476/2000], Avg Train Loss: 4.3995\n",
      "Epoch [476/2000], Avg Val Loss: 2.8614\n",
      "Validation loss improved from 2.8624 to 2.8614. Saving model...\n",
      "\n",
      "LOG: Epoch [477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3940\n",
      "Epoch [477/2000], Avg Train Loss: 4.3940\n",
      "Epoch [477/2000], Avg Val Loss: 2.8605\n",
      "Validation loss improved from 2.8614 to 2.8605. Saving model...\n",
      "\n",
      "LOG: Epoch [478/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4404\n",
      "Epoch [478/2000], Avg Train Loss: 4.4404\n",
      "Epoch [478/2000], Avg Val Loss: 2.8596\n",
      "Validation loss improved from 2.8605 to 2.8596. Saving model...\n",
      "\n",
      "LOG: Epoch [479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3939\n",
      "Epoch [479/2000], Avg Train Loss: 4.3939\n",
      "Epoch [479/2000], Avg Val Loss: 2.8587\n",
      "Validation loss improved from 2.8596 to 2.8587. Saving model...\n",
      "\n",
      "LOG: Epoch [480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3686\n",
      "Epoch [480/2000], Avg Train Loss: 4.3686\n",
      "Epoch [480/2000], Avg Val Loss: 2.8577\n",
      "Validation loss improved from 2.8587 to 2.8577. Saving model...\n",
      "\n",
      "LOG: Epoch [481/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4112\n",
      "Epoch [481/2000], Avg Train Loss: 4.4112\n",
      "Epoch [481/2000], Avg Val Loss: 2.8567\n",
      "Validation loss improved from 2.8577 to 2.8567. Saving model...\n",
      "\n",
      "LOG: Epoch [482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3966\n",
      "Epoch [482/2000], Avg Train Loss: 4.3966\n",
      "Epoch [482/2000], Avg Val Loss: 2.8558\n",
      "Validation loss improved from 2.8567 to 2.8558. Saving model...\n",
      "\n",
      "LOG: Epoch [483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3884\n",
      "Epoch [483/2000], Avg Train Loss: 4.3884\n",
      "Epoch [483/2000], Avg Val Loss: 2.8548\n",
      "Validation loss improved from 2.8558 to 2.8548. Saving model...\n",
      "\n",
      "LOG: Epoch [484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3699\n",
      "Epoch [484/2000], Avg Train Loss: 4.3699\n",
      "Epoch [484/2000], Avg Val Loss: 2.8539\n",
      "Validation loss improved from 2.8548 to 2.8539. Saving model...\n",
      "\n",
      "LOG: Epoch [485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4030\n",
      "Epoch [485/2000], Avg Train Loss: 4.4030\n",
      "Epoch [485/2000], Avg Val Loss: 2.8529\n",
      "Validation loss improved from 2.8539 to 2.8529. Saving model...\n",
      "\n",
      "LOG: Epoch [486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4052\n",
      "Epoch [486/2000], Avg Train Loss: 4.4052\n",
      "Epoch [486/2000], Avg Val Loss: 2.8520\n",
      "Validation loss improved from 2.8529 to 2.8520. Saving model...\n",
      "\n",
      "LOG: Epoch [487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3994\n",
      "Epoch [487/2000], Avg Train Loss: 4.3994\n",
      "Epoch [487/2000], Avg Val Loss: 2.8510\n",
      "Validation loss improved from 2.8520 to 2.8510. Saving model...\n",
      "\n",
      "LOG: Epoch [488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3708\n",
      "Epoch [488/2000], Avg Train Loss: 4.3708\n",
      "Epoch [488/2000], Avg Val Loss: 2.8501\n",
      "Validation loss improved from 2.8510 to 2.8501. Saving model...\n",
      "\n",
      "LOG: Epoch [489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3384\n",
      "Epoch [489/2000], Avg Train Loss: 4.3384\n",
      "Epoch [489/2000], Avg Val Loss: 2.8491\n",
      "Validation loss improved from 2.8501 to 2.8491. Saving model...\n",
      "\n",
      "LOG: Epoch [490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4220\n",
      "Epoch [490/2000], Avg Train Loss: 4.4220\n",
      "Epoch [490/2000], Avg Val Loss: 2.8482\n",
      "Validation loss improved from 2.8491 to 2.8482. Saving model...\n",
      "\n",
      "LOG: Epoch [491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3785\n",
      "Epoch [491/2000], Avg Train Loss: 4.3785\n",
      "Epoch [491/2000], Avg Val Loss: 2.8472\n",
      "Validation loss improved from 2.8482 to 2.8472. Saving model...\n",
      "\n",
      "LOG: Epoch [492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3375\n",
      "Epoch [492/2000], Avg Train Loss: 4.3375\n",
      "Epoch [492/2000], Avg Val Loss: 2.8463\n",
      "Validation loss improved from 2.8472 to 2.8463. Saving model...\n",
      "\n",
      "LOG: Epoch [493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3998\n",
      "Epoch [493/2000], Avg Train Loss: 4.3998\n",
      "Epoch [493/2000], Avg Val Loss: 2.8453\n",
      "Validation loss improved from 2.8463 to 2.8453. Saving model...\n",
      "\n",
      "LOG: Epoch [494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3724\n",
      "Epoch [494/2000], Avg Train Loss: 4.3724\n",
      "Epoch [494/2000], Avg Val Loss: 2.8443\n",
      "Validation loss improved from 2.8453 to 2.8443. Saving model...\n",
      "\n",
      "LOG: Epoch [495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3909\n",
      "Epoch [495/2000], Avg Train Loss: 4.3909\n",
      "Epoch [495/2000], Avg Val Loss: 2.8433\n",
      "Validation loss improved from 2.8443 to 2.8433. Saving model...\n",
      "\n",
      "LOG: Epoch [496/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3764\n",
      "Epoch [496/2000], Avg Train Loss: 4.3764\n",
      "Epoch [496/2000], Avg Val Loss: 2.8424\n",
      "Validation loss improved from 2.8433 to 2.8424. Saving model...\n",
      "\n",
      "LOG: Epoch [497/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3623\n",
      "Epoch [497/2000], Avg Train Loss: 4.3623\n",
      "Epoch [497/2000], Avg Val Loss: 2.8414\n",
      "Validation loss improved from 2.8424 to 2.8414. Saving model...\n",
      "\n",
      "LOG: Epoch [498/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3974\n",
      "Epoch [498/2000], Avg Train Loss: 4.3974\n",
      "Epoch [498/2000], Avg Val Loss: 2.8404\n",
      "Validation loss improved from 2.8414 to 2.8404. Saving model...\n",
      "\n",
      "LOG: Epoch [499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3602\n",
      "Epoch [499/2000], Avg Train Loss: 4.3602\n",
      "Epoch [499/2000], Avg Val Loss: 2.8395\n",
      "Validation loss improved from 2.8404 to 2.8395. Saving model...\n",
      "\n",
      "LOG: Epoch [500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3659\n",
      "Epoch [500/2000], Avg Train Loss: 4.3659\n",
      "Epoch [500/2000], Avg Val Loss: 2.8385\n",
      "Validation loss improved from 2.8395 to 2.8385. Saving model...\n",
      "\n",
      "LOG: Epoch [501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3666\n",
      "Epoch [501/2000], Avg Train Loss: 4.3666\n",
      "Epoch [501/2000], Avg Val Loss: 2.8375\n",
      "Validation loss improved from 2.8385 to 2.8375. Saving model...\n",
      "\n",
      "LOG: Epoch [502/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3674\n",
      "Epoch [502/2000], Avg Train Loss: 4.3674\n",
      "Epoch [502/2000], Avg Val Loss: 2.8366\n",
      "Validation loss improved from 2.8375 to 2.8366. Saving model...\n",
      "\n",
      "LOG: Epoch [503/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3938\n",
      "Epoch [503/2000], Avg Train Loss: 4.3938\n",
      "Epoch [503/2000], Avg Val Loss: 2.8356\n",
      "Validation loss improved from 2.8366 to 2.8356. Saving model...\n",
      "\n",
      "LOG: Epoch [504/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3700\n",
      "Epoch [504/2000], Avg Train Loss: 4.3700\n",
      "Epoch [504/2000], Avg Val Loss: 2.8346\n",
      "Validation loss improved from 2.8356 to 2.8346. Saving model...\n",
      "\n",
      "LOG: Epoch [505/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3562\n",
      "Epoch [505/2000], Avg Train Loss: 4.3562\n",
      "Epoch [505/2000], Avg Val Loss: 2.8336\n",
      "Validation loss improved from 2.8346 to 2.8336. Saving model...\n",
      "\n",
      "LOG: Epoch [506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4181\n",
      "Epoch [506/2000], Avg Train Loss: 4.4181\n",
      "Epoch [506/2000], Avg Val Loss: 2.8326\n",
      "Validation loss improved from 2.8336 to 2.8326. Saving model...\n",
      "\n",
      "LOG: Epoch [507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3633\n",
      "Epoch [507/2000], Avg Train Loss: 4.3633\n",
      "Epoch [507/2000], Avg Val Loss: 2.8317\n",
      "Validation loss improved from 2.8326 to 2.8317. Saving model...\n",
      "\n",
      "LOG: Epoch [508/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3522\n",
      "Epoch [508/2000], Avg Train Loss: 4.3522\n",
      "Epoch [508/2000], Avg Val Loss: 2.8308\n",
      "Validation loss improved from 2.8317 to 2.8308. Saving model...\n",
      "\n",
      "LOG: Epoch [509/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3786\n",
      "Epoch [509/2000], Avg Train Loss: 4.3786\n",
      "Epoch [509/2000], Avg Val Loss: 2.8299\n",
      "Validation loss improved from 2.8308 to 2.8299. Saving model...\n",
      "\n",
      "LOG: Epoch [510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3175\n",
      "Epoch [510/2000], Avg Train Loss: 4.3175\n",
      "Epoch [510/2000], Avg Val Loss: 2.8290\n",
      "Validation loss improved from 2.8299 to 2.8290. Saving model...\n",
      "\n",
      "LOG: Epoch [511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3362\n",
      "Epoch [511/2000], Avg Train Loss: 4.3362\n",
      "Epoch [511/2000], Avg Val Loss: 2.8281\n",
      "Validation loss improved from 2.8290 to 2.8281. Saving model...\n",
      "\n",
      "LOG: Epoch [512/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3556\n",
      "Epoch [512/2000], Avg Train Loss: 4.3556\n",
      "Epoch [512/2000], Avg Val Loss: 2.8272\n",
      "Validation loss improved from 2.8281 to 2.8272. Saving model...\n",
      "\n",
      "LOG: Epoch [513/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3135\n",
      "Epoch [513/2000], Avg Train Loss: 4.3135\n",
      "Epoch [513/2000], Avg Val Loss: 2.8263\n",
      "Validation loss improved from 2.8272 to 2.8263. Saving model...\n",
      "\n",
      "LOG: Epoch [514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3583\n",
      "Epoch [514/2000], Avg Train Loss: 4.3583\n",
      "Epoch [514/2000], Avg Val Loss: 2.8254\n",
      "Validation loss improved from 2.8263 to 2.8254. Saving model...\n",
      "\n",
      "LOG: Epoch [515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3594\n",
      "Epoch [515/2000], Avg Train Loss: 4.3594\n",
      "Epoch [515/2000], Avg Val Loss: 2.8244\n",
      "Validation loss improved from 2.8254 to 2.8244. Saving model...\n",
      "\n",
      "LOG: Epoch [516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3409\n",
      "Epoch [516/2000], Avg Train Loss: 4.3409\n",
      "Epoch [516/2000], Avg Val Loss: 2.8235\n",
      "Validation loss improved from 2.8244 to 2.8235. Saving model...\n",
      "\n",
      "LOG: Epoch [517/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3388\n",
      "Epoch [517/2000], Avg Train Loss: 4.3388\n",
      "Epoch [517/2000], Avg Val Loss: 2.8226\n",
      "Validation loss improved from 2.8235 to 2.8226. Saving model...\n",
      "\n",
      "LOG: Epoch [518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3868\n",
      "Epoch [518/2000], Avg Train Loss: 4.3868\n",
      "Epoch [518/2000], Avg Val Loss: 2.8216\n",
      "Validation loss improved from 2.8226 to 2.8216. Saving model...\n",
      "\n",
      "LOG: Epoch [519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3251\n",
      "Epoch [519/2000], Avg Train Loss: 4.3251\n",
      "Epoch [519/2000], Avg Val Loss: 2.8207\n",
      "Validation loss improved from 2.8216 to 2.8207. Saving model...\n",
      "\n",
      "LOG: Epoch [520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3203\n",
      "Epoch [520/2000], Avg Train Loss: 4.3203\n",
      "Epoch [520/2000], Avg Val Loss: 2.8197\n",
      "Validation loss improved from 2.8207 to 2.8197. Saving model...\n",
      "\n",
      "LOG: Epoch [521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3514\n",
      "Epoch [521/2000], Avg Train Loss: 4.3514\n",
      "Epoch [521/2000], Avg Val Loss: 2.8188\n",
      "Validation loss improved from 2.8197 to 2.8188. Saving model...\n",
      "\n",
      "LOG: Epoch [522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3252\n",
      "Epoch [522/2000], Avg Train Loss: 4.3252\n",
      "Epoch [522/2000], Avg Val Loss: 2.8178\n",
      "Validation loss improved from 2.8188 to 2.8178. Saving model...\n",
      "\n",
      "LOG: Epoch [523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3400\n",
      "Epoch [523/2000], Avg Train Loss: 4.3400\n",
      "Epoch [523/2000], Avg Val Loss: 2.8168\n",
      "Validation loss improved from 2.8178 to 2.8168. Saving model...\n",
      "\n",
      "LOG: Epoch [524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2740\n",
      "Epoch [524/2000], Avg Train Loss: 4.2740\n",
      "Epoch [524/2000], Avg Val Loss: 2.8158\n",
      "Validation loss improved from 2.8168 to 2.8158. Saving model...\n",
      "\n",
      "LOG: Epoch [525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3215\n",
      "Epoch [525/2000], Avg Train Loss: 4.3215\n",
      "Epoch [525/2000], Avg Val Loss: 2.8147\n",
      "Validation loss improved from 2.8158 to 2.8147. Saving model...\n",
      "\n",
      "LOG: Epoch [526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3457\n",
      "Epoch [526/2000], Avg Train Loss: 4.3457\n",
      "Epoch [526/2000], Avg Val Loss: 2.8137\n",
      "Validation loss improved from 2.8147 to 2.8137. Saving model...\n",
      "\n",
      "LOG: Epoch [527/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3301\n",
      "Epoch [527/2000], Avg Train Loss: 4.3301\n",
      "Epoch [527/2000], Avg Val Loss: 2.8127\n",
      "Validation loss improved from 2.8137 to 2.8127. Saving model...\n",
      "\n",
      "LOG: Epoch [528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3448\n",
      "Epoch [528/2000], Avg Train Loss: 4.3448\n",
      "Epoch [528/2000], Avg Val Loss: 2.8117\n",
      "Validation loss improved from 2.8127 to 2.8117. Saving model...\n",
      "\n",
      "LOG: Epoch [529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3296\n",
      "Epoch [529/2000], Avg Train Loss: 4.3296\n",
      "Epoch [529/2000], Avg Val Loss: 2.8108\n",
      "Validation loss improved from 2.8117 to 2.8108. Saving model...\n",
      "\n",
      "LOG: Epoch [530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3468\n",
      "Epoch [530/2000], Avg Train Loss: 4.3468\n",
      "Epoch [530/2000], Avg Val Loss: 2.8099\n",
      "Validation loss improved from 2.8108 to 2.8099. Saving model...\n",
      "\n",
      "LOG: Epoch [531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3500\n",
      "Epoch [531/2000], Avg Train Loss: 4.3500\n",
      "Epoch [531/2000], Avg Val Loss: 2.8090\n",
      "Validation loss improved from 2.8099 to 2.8090. Saving model...\n",
      "\n",
      "LOG: Epoch [532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3415\n",
      "Epoch [532/2000], Avg Train Loss: 4.3415\n",
      "Epoch [532/2000], Avg Val Loss: 2.8082\n",
      "Validation loss improved from 2.8090 to 2.8082. Saving model...\n",
      "\n",
      "LOG: Epoch [533/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3637\n",
      "Epoch [533/2000], Avg Train Loss: 4.3637\n",
      "Epoch [533/2000], Avg Val Loss: 2.8073\n",
      "Validation loss improved from 2.8082 to 2.8073. Saving model...\n",
      "\n",
      "LOG: Epoch [534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3851\n",
      "Epoch [534/2000], Avg Train Loss: 4.3851\n",
      "Epoch [534/2000], Avg Val Loss: 2.8064\n",
      "Validation loss improved from 2.8073 to 2.8064. Saving model...\n",
      "\n",
      "LOG: Epoch [535/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3348\n",
      "Epoch [535/2000], Avg Train Loss: 4.3348\n",
      "Epoch [535/2000], Avg Val Loss: 2.8055\n",
      "Validation loss improved from 2.8064 to 2.8055. Saving model...\n",
      "\n",
      "LOG: Epoch [536/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3046\n",
      "Epoch [536/2000], Avg Train Loss: 4.3046\n",
      "Epoch [536/2000], Avg Val Loss: 2.8047\n",
      "Validation loss improved from 2.8055 to 2.8047. Saving model...\n",
      "\n",
      "LOG: Epoch [537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3142\n",
      "Epoch [537/2000], Avg Train Loss: 4.3142\n",
      "Epoch [537/2000], Avg Val Loss: 2.8038\n",
      "Validation loss improved from 2.8047 to 2.8038. Saving model...\n",
      "\n",
      "LOG: Epoch [538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3249\n",
      "Epoch [538/2000], Avg Train Loss: 4.3249\n",
      "Epoch [538/2000], Avg Val Loss: 2.8030\n",
      "Validation loss improved from 2.8038 to 2.8030. Saving model...\n",
      "\n",
      "LOG: Epoch [539/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3157\n",
      "Epoch [539/2000], Avg Train Loss: 4.3157\n",
      "Epoch [539/2000], Avg Val Loss: 2.8021\n",
      "Validation loss improved from 2.8030 to 2.8021. Saving model...\n",
      "\n",
      "LOG: Epoch [540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3429\n",
      "Epoch [540/2000], Avg Train Loss: 4.3429\n",
      "Epoch [540/2000], Avg Val Loss: 2.8012\n",
      "Validation loss improved from 2.8021 to 2.8012. Saving model...\n",
      "\n",
      "LOG: Epoch [541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3380\n",
      "Epoch [541/2000], Avg Train Loss: 4.3380\n",
      "Epoch [541/2000], Avg Val Loss: 2.8003\n",
      "Validation loss improved from 2.8012 to 2.8003. Saving model...\n",
      "\n",
      "LOG: Epoch [542/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3168\n",
      "Epoch [542/2000], Avg Train Loss: 4.3168\n",
      "Epoch [542/2000], Avg Val Loss: 2.7994\n",
      "Validation loss improved from 2.8003 to 2.7994. Saving model...\n",
      "\n",
      "LOG: Epoch [543/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3104\n",
      "Epoch [543/2000], Avg Train Loss: 4.3104\n",
      "Epoch [543/2000], Avg Val Loss: 2.7985\n",
      "Validation loss improved from 2.7994 to 2.7985. Saving model...\n",
      "\n",
      "LOG: Epoch [544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2988\n",
      "Epoch [544/2000], Avg Train Loss: 4.2988\n",
      "Epoch [544/2000], Avg Val Loss: 2.7976\n",
      "Validation loss improved from 2.7985 to 2.7976. Saving model...\n",
      "\n",
      "LOG: Epoch [545/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3497\n",
      "Epoch [545/2000], Avg Train Loss: 4.3497\n",
      "Epoch [545/2000], Avg Val Loss: 2.7968\n",
      "Validation loss improved from 2.7976 to 2.7968. Saving model...\n",
      "\n",
      "LOG: Epoch [546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3292\n",
      "Epoch [546/2000], Avg Train Loss: 4.3292\n",
      "Epoch [546/2000], Avg Val Loss: 2.7959\n",
      "Validation loss improved from 2.7968 to 2.7959. Saving model...\n",
      "\n",
      "LOG: Epoch [547/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2999\n",
      "Epoch [547/2000], Avg Train Loss: 4.2999\n",
      "Epoch [547/2000], Avg Val Loss: 2.7950\n",
      "Validation loss improved from 2.7959 to 2.7950. Saving model...\n",
      "\n",
      "LOG: Epoch [548/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2935\n",
      "Epoch [548/2000], Avg Train Loss: 4.2935\n",
      "Epoch [548/2000], Avg Val Loss: 2.7941\n",
      "Validation loss improved from 2.7950 to 2.7941. Saving model...\n",
      "\n",
      "LOG: Epoch [549/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3215\n",
      "Epoch [549/2000], Avg Train Loss: 4.3215\n",
      "Epoch [549/2000], Avg Val Loss: 2.7933\n",
      "Validation loss improved from 2.7941 to 2.7933. Saving model...\n",
      "\n",
      "LOG: Epoch [550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3055\n",
      "Epoch [550/2000], Avg Train Loss: 4.3055\n",
      "Epoch [550/2000], Avg Val Loss: 2.7924\n",
      "Validation loss improved from 2.7933 to 2.7924. Saving model...\n",
      "\n",
      "LOG: Epoch [551/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3252\n",
      "Epoch [551/2000], Avg Train Loss: 4.3252\n",
      "Epoch [551/2000], Avg Val Loss: 2.7916\n",
      "Validation loss improved from 2.7924 to 2.7916. Saving model...\n",
      "\n",
      "LOG: Epoch [552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3152\n",
      "Epoch [552/2000], Avg Train Loss: 4.3152\n",
      "Epoch [552/2000], Avg Val Loss: 2.7908\n",
      "Validation loss improved from 2.7916 to 2.7908. Saving model...\n",
      "\n",
      "LOG: Epoch [553/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3110\n",
      "Epoch [553/2000], Avg Train Loss: 4.3110\n",
      "Epoch [553/2000], Avg Val Loss: 2.7900\n",
      "Validation loss improved from 2.7908 to 2.7900. Saving model...\n",
      "\n",
      "LOG: Epoch [554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3217\n",
      "Epoch [554/2000], Avg Train Loss: 4.3217\n",
      "Epoch [554/2000], Avg Val Loss: 2.7892\n",
      "Validation loss improved from 2.7900 to 2.7892. Saving model...\n",
      "\n",
      "LOG: Epoch [555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2874\n",
      "Epoch [555/2000], Avg Train Loss: 4.2874\n",
      "Epoch [555/2000], Avg Val Loss: 2.7884\n",
      "Validation loss improved from 2.7892 to 2.7884. Saving model...\n",
      "\n",
      "LOG: Epoch [556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2890\n",
      "Epoch [556/2000], Avg Train Loss: 4.2890\n",
      "Epoch [556/2000], Avg Val Loss: 2.7876\n",
      "Validation loss improved from 2.7884 to 2.7876. Saving model...\n",
      "\n",
      "LOG: Epoch [557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2884\n",
      "Epoch [557/2000], Avg Train Loss: 4.2884\n",
      "Epoch [557/2000], Avg Val Loss: 2.7868\n",
      "Validation loss improved from 2.7876 to 2.7868. Saving model...\n",
      "\n",
      "LOG: Epoch [558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2664\n",
      "Epoch [558/2000], Avg Train Loss: 4.2664\n",
      "Epoch [558/2000], Avg Val Loss: 2.7859\n",
      "Validation loss improved from 2.7868 to 2.7859. Saving model...\n",
      "\n",
      "LOG: Epoch [559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2777\n",
      "Epoch [559/2000], Avg Train Loss: 4.2777\n",
      "Epoch [559/2000], Avg Val Loss: 2.7851\n",
      "Validation loss improved from 2.7859 to 2.7851. Saving model...\n",
      "\n",
      "LOG: Epoch [560/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2889\n",
      "Epoch [560/2000], Avg Train Loss: 4.2889\n",
      "Epoch [560/2000], Avg Val Loss: 2.7842\n",
      "Validation loss improved from 2.7851 to 2.7842. Saving model...\n",
      "\n",
      "LOG: Epoch [561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2879\n",
      "Epoch [561/2000], Avg Train Loss: 4.2879\n",
      "Epoch [561/2000], Avg Val Loss: 2.7834\n",
      "Validation loss improved from 2.7842 to 2.7834. Saving model...\n",
      "\n",
      "LOG: Epoch [562/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3151\n",
      "Epoch [562/2000], Avg Train Loss: 4.3151\n",
      "Epoch [562/2000], Avg Val Loss: 2.7826\n",
      "Validation loss improved from 2.7834 to 2.7826. Saving model...\n",
      "\n",
      "LOG: Epoch [563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3258\n",
      "Epoch [563/2000], Avg Train Loss: 4.3258\n",
      "Epoch [563/2000], Avg Val Loss: 2.7817\n",
      "Validation loss improved from 2.7826 to 2.7817. Saving model...\n",
      "\n",
      "LOG: Epoch [564/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2816\n",
      "Epoch [564/2000], Avg Train Loss: 4.2816\n",
      "Epoch [564/2000], Avg Val Loss: 2.7809\n",
      "Validation loss improved from 2.7817 to 2.7809. Saving model...\n",
      "\n",
      "LOG: Epoch [565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2831\n",
      "Epoch [565/2000], Avg Train Loss: 4.2831\n",
      "Epoch [565/2000], Avg Val Loss: 2.7802\n",
      "Validation loss improved from 2.7809 to 2.7802. Saving model...\n",
      "\n",
      "LOG: Epoch [566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2889\n",
      "Epoch [566/2000], Avg Train Loss: 4.2889\n",
      "Epoch [566/2000], Avg Val Loss: 2.7794\n",
      "Validation loss improved from 2.7802 to 2.7794. Saving model...\n",
      "\n",
      "LOG: Epoch [567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3092\n",
      "Epoch [567/2000], Avg Train Loss: 4.3092\n",
      "Epoch [567/2000], Avg Val Loss: 2.7787\n",
      "Validation loss improved from 2.7794 to 2.7787. Saving model...\n",
      "\n",
      "LOG: Epoch [568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2600\n",
      "Epoch [568/2000], Avg Train Loss: 4.2600\n",
      "Epoch [568/2000], Avg Val Loss: 2.7780\n",
      "Validation loss improved from 2.7787 to 2.7780. Saving model...\n",
      "\n",
      "LOG: Epoch [569/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3183\n",
      "Epoch [569/2000], Avg Train Loss: 4.3183\n",
      "Epoch [569/2000], Avg Val Loss: 2.7773\n",
      "Validation loss improved from 2.7780 to 2.7773. Saving model...\n",
      "\n",
      "LOG: Epoch [570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2457\n",
      "Epoch [570/2000], Avg Train Loss: 4.2457\n",
      "Epoch [570/2000], Avg Val Loss: 2.7766\n",
      "Validation loss improved from 2.7773 to 2.7766. Saving model...\n",
      "\n",
      "LOG: Epoch [571/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2636\n",
      "Epoch [571/2000], Avg Train Loss: 4.2636\n",
      "Epoch [571/2000], Avg Val Loss: 2.7759\n",
      "Validation loss improved from 2.7766 to 2.7759. Saving model...\n",
      "\n",
      "LOG: Epoch [572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2725\n",
      "Epoch [572/2000], Avg Train Loss: 4.2725\n",
      "Epoch [572/2000], Avg Val Loss: 2.7752\n",
      "Validation loss improved from 2.7759 to 2.7752. Saving model...\n",
      "\n",
      "LOG: Epoch [573/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2725\n",
      "Epoch [573/2000], Avg Train Loss: 4.2725\n",
      "Epoch [573/2000], Avg Val Loss: 2.7745\n",
      "Validation loss improved from 2.7752 to 2.7745. Saving model...\n",
      "\n",
      "LOG: Epoch [574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2927\n",
      "Epoch [574/2000], Avg Train Loss: 4.2927\n",
      "Epoch [574/2000], Avg Val Loss: 2.7738\n",
      "Validation loss improved from 2.7745 to 2.7738. Saving model...\n",
      "\n",
      "LOG: Epoch [575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2335\n",
      "Epoch [575/2000], Avg Train Loss: 4.2335\n",
      "Epoch [575/2000], Avg Val Loss: 2.7732\n",
      "Validation loss improved from 2.7738 to 2.7732. Saving model...\n",
      "\n",
      "LOG: Epoch [576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3060\n",
      "Epoch [576/2000], Avg Train Loss: 4.3060\n",
      "Epoch [576/2000], Avg Val Loss: 2.7726\n",
      "Validation loss improved from 2.7732 to 2.7726. Saving model...\n",
      "\n",
      "LOG: Epoch [577/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2822\n",
      "Epoch [577/2000], Avg Train Loss: 4.2822\n",
      "Epoch [577/2000], Avg Val Loss: 2.7719\n",
      "Validation loss improved from 2.7726 to 2.7719. Saving model...\n",
      "\n",
      "LOG: Epoch [578/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2859\n",
      "Epoch [578/2000], Avg Train Loss: 4.2859\n",
      "Epoch [578/2000], Avg Val Loss: 2.7712\n",
      "Validation loss improved from 2.7719 to 2.7712. Saving model...\n",
      "\n",
      "LOG: Epoch [579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2665\n",
      "Epoch [579/2000], Avg Train Loss: 4.2665\n",
      "Epoch [579/2000], Avg Val Loss: 2.7705\n",
      "Validation loss improved from 2.7712 to 2.7705. Saving model...\n",
      "\n",
      "LOG: Epoch [580/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2538\n",
      "Epoch [580/2000], Avg Train Loss: 4.2538\n",
      "Epoch [580/2000], Avg Val Loss: 2.7697\n",
      "Validation loss improved from 2.7705 to 2.7697. Saving model...\n",
      "\n",
      "LOG: Epoch [581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3088\n",
      "Epoch [581/2000], Avg Train Loss: 4.3088\n",
      "Epoch [581/2000], Avg Val Loss: 2.7690\n",
      "Validation loss improved from 2.7697 to 2.7690. Saving model...\n",
      "\n",
      "LOG: Epoch [582/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2646\n",
      "Epoch [582/2000], Avg Train Loss: 4.2646\n",
      "Epoch [582/2000], Avg Val Loss: 2.7683\n",
      "Validation loss improved from 2.7690 to 2.7683. Saving model...\n",
      "\n",
      "LOG: Epoch [583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2733\n",
      "Epoch [583/2000], Avg Train Loss: 4.2733\n",
      "Epoch [583/2000], Avg Val Loss: 2.7676\n",
      "Validation loss improved from 2.7683 to 2.7676. Saving model...\n",
      "\n",
      "LOG: Epoch [584/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2529\n",
      "Epoch [584/2000], Avg Train Loss: 4.2529\n",
      "Epoch [584/2000], Avg Val Loss: 2.7669\n",
      "Validation loss improved from 2.7676 to 2.7669. Saving model...\n",
      "\n",
      "LOG: Epoch [585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2391\n",
      "Epoch [585/2000], Avg Train Loss: 4.2391\n",
      "Epoch [585/2000], Avg Val Loss: 2.7662\n",
      "Validation loss improved from 2.7669 to 2.7662. Saving model...\n",
      "\n",
      "LOG: Epoch [586/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2557\n",
      "Epoch [586/2000], Avg Train Loss: 4.2557\n",
      "Epoch [586/2000], Avg Val Loss: 2.7656\n",
      "Validation loss improved from 2.7662 to 2.7656. Saving model...\n",
      "\n",
      "LOG: Epoch [587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3005\n",
      "Epoch [587/2000], Avg Train Loss: 4.3005\n",
      "Epoch [587/2000], Avg Val Loss: 2.7649\n",
      "Validation loss improved from 2.7656 to 2.7649. Saving model...\n",
      "\n",
      "LOG: Epoch [588/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2304\n",
      "Epoch [588/2000], Avg Train Loss: 4.2304\n",
      "Epoch [588/2000], Avg Val Loss: 2.7642\n",
      "Validation loss improved from 2.7649 to 2.7642. Saving model...\n",
      "\n",
      "LOG: Epoch [589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2435\n",
      "Epoch [589/2000], Avg Train Loss: 4.2435\n",
      "Epoch [589/2000], Avg Val Loss: 2.7635\n",
      "Validation loss improved from 2.7642 to 2.7635. Saving model...\n",
      "\n",
      "LOG: Epoch [590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2422\n",
      "Epoch [590/2000], Avg Train Loss: 4.2422\n",
      "Epoch [590/2000], Avg Val Loss: 2.7628\n",
      "Validation loss improved from 2.7635 to 2.7628. Saving model...\n",
      "\n",
      "LOG: Epoch [591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2440\n",
      "Epoch [591/2000], Avg Train Loss: 4.2440\n",
      "Epoch [591/2000], Avg Val Loss: 2.7620\n",
      "Validation loss improved from 2.7628 to 2.7620. Saving model...\n",
      "\n",
      "LOG: Epoch [592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2807\n",
      "Epoch [592/2000], Avg Train Loss: 4.2807\n",
      "Epoch [592/2000], Avg Val Loss: 2.7612\n",
      "Validation loss improved from 2.7620 to 2.7612. Saving model...\n",
      "\n",
      "LOG: Epoch [593/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2266\n",
      "Epoch [593/2000], Avg Train Loss: 4.2266\n",
      "Epoch [593/2000], Avg Val Loss: 2.7604\n",
      "Validation loss improved from 2.7612 to 2.7604. Saving model...\n",
      "\n",
      "LOG: Epoch [594/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2272\n",
      "Epoch [594/2000], Avg Train Loss: 4.2272\n",
      "Epoch [594/2000], Avg Val Loss: 2.7595\n",
      "Validation loss improved from 2.7604 to 2.7595. Saving model...\n",
      "\n",
      "LOG: Epoch [595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2135\n",
      "Epoch [595/2000], Avg Train Loss: 4.2135\n",
      "Epoch [595/2000], Avg Val Loss: 2.7587\n",
      "Validation loss improved from 2.7595 to 2.7587. Saving model...\n",
      "\n",
      "LOG: Epoch [596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2221\n",
      "Epoch [596/2000], Avg Train Loss: 4.2221\n",
      "Epoch [596/2000], Avg Val Loss: 2.7578\n",
      "Validation loss improved from 2.7587 to 2.7578. Saving model...\n",
      "\n",
      "LOG: Epoch [597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2707\n",
      "Epoch [597/2000], Avg Train Loss: 4.2707\n",
      "Epoch [597/2000], Avg Val Loss: 2.7570\n",
      "Validation loss improved from 2.7578 to 2.7570. Saving model...\n",
      "\n",
      "LOG: Epoch [598/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2392\n",
      "Epoch [598/2000], Avg Train Loss: 4.2392\n",
      "Epoch [598/2000], Avg Val Loss: 2.7562\n",
      "Validation loss improved from 2.7570 to 2.7562. Saving model...\n",
      "\n",
      "LOG: Epoch [599/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2510\n",
      "Epoch [599/2000], Avg Train Loss: 4.2510\n",
      "Epoch [599/2000], Avg Val Loss: 2.7554\n",
      "Validation loss improved from 2.7562 to 2.7554. Saving model...\n",
      "\n",
      "LOG: Epoch [600/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2608\n",
      "Epoch [600/2000], Avg Train Loss: 4.2608\n",
      "Epoch [600/2000], Avg Val Loss: 2.7546\n",
      "Validation loss improved from 2.7554 to 2.7546. Saving model...\n",
      "\n",
      "LOG: Epoch [601/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2317\n",
      "Epoch [601/2000], Avg Train Loss: 4.2317\n",
      "Epoch [601/2000], Avg Val Loss: 2.7538\n",
      "Validation loss improved from 2.7546 to 2.7538. Saving model...\n",
      "\n",
      "LOG: Epoch [602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2579\n",
      "Epoch [602/2000], Avg Train Loss: 4.2579\n",
      "Epoch [602/2000], Avg Val Loss: 2.7530\n",
      "Validation loss improved from 2.7538 to 2.7530. Saving model...\n",
      "\n",
      "LOG: Epoch [603/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2184\n",
      "Epoch [603/2000], Avg Train Loss: 4.2184\n",
      "Epoch [603/2000], Avg Val Loss: 2.7522\n",
      "Validation loss improved from 2.7530 to 2.7522. Saving model...\n",
      "\n",
      "LOG: Epoch [604/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2216\n",
      "Epoch [604/2000], Avg Train Loss: 4.2216\n",
      "Epoch [604/2000], Avg Val Loss: 2.7514\n",
      "Validation loss improved from 2.7522 to 2.7514. Saving model...\n",
      "\n",
      "LOG: Epoch [605/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2508\n",
      "Epoch [605/2000], Avg Train Loss: 4.2508\n",
      "Epoch [605/2000], Avg Val Loss: 2.7507\n",
      "Validation loss improved from 2.7514 to 2.7507. Saving model...\n",
      "\n",
      "LOG: Epoch [606/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2470\n",
      "Epoch [606/2000], Avg Train Loss: 4.2470\n",
      "Epoch [606/2000], Avg Val Loss: 2.7499\n",
      "Validation loss improved from 2.7507 to 2.7499. Saving model...\n",
      "\n",
      "LOG: Epoch [607/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2742\n",
      "Epoch [607/2000], Avg Train Loss: 4.2742\n",
      "Epoch [607/2000], Avg Val Loss: 2.7491\n",
      "Validation loss improved from 2.7499 to 2.7491. Saving model...\n",
      "\n",
      "LOG: Epoch [608/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2655\n",
      "Epoch [608/2000], Avg Train Loss: 4.2655\n",
      "Epoch [608/2000], Avg Val Loss: 2.7483\n",
      "Validation loss improved from 2.7491 to 2.7483. Saving model...\n",
      "\n",
      "LOG: Epoch [609/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2358\n",
      "Epoch [609/2000], Avg Train Loss: 4.2358\n",
      "Epoch [609/2000], Avg Val Loss: 2.7474\n",
      "Validation loss improved from 2.7483 to 2.7474. Saving model...\n",
      "\n",
      "LOG: Epoch [610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2515\n",
      "Epoch [610/2000], Avg Train Loss: 4.2515\n",
      "Epoch [610/2000], Avg Val Loss: 2.7466\n",
      "Validation loss improved from 2.7474 to 2.7466. Saving model...\n",
      "\n",
      "LOG: Epoch [611/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2309\n",
      "Epoch [611/2000], Avg Train Loss: 4.2309\n",
      "Epoch [611/2000], Avg Val Loss: 2.7458\n",
      "Validation loss improved from 2.7466 to 2.7458. Saving model...\n",
      "\n",
      "LOG: Epoch [612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2925\n",
      "Epoch [612/2000], Avg Train Loss: 4.2925\n",
      "Epoch [612/2000], Avg Val Loss: 2.7449\n",
      "Validation loss improved from 2.7458 to 2.7449. Saving model...\n",
      "\n",
      "LOG: Epoch [613/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2378\n",
      "Epoch [613/2000], Avg Train Loss: 4.2378\n",
      "Epoch [613/2000], Avg Val Loss: 2.7442\n",
      "Validation loss improved from 2.7449 to 2.7442. Saving model...\n",
      "\n",
      "LOG: Epoch [614/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1980\n",
      "Epoch [614/2000], Avg Train Loss: 4.1980\n",
      "Epoch [614/2000], Avg Val Loss: 2.7433\n",
      "Validation loss improved from 2.7442 to 2.7433. Saving model...\n",
      "\n",
      "LOG: Epoch [615/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2312\n",
      "Epoch [615/2000], Avg Train Loss: 4.2312\n",
      "Epoch [615/2000], Avg Val Loss: 2.7425\n",
      "Validation loss improved from 2.7433 to 2.7425. Saving model...\n",
      "\n",
      "LOG: Epoch [616/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2012\n",
      "Epoch [616/2000], Avg Train Loss: 4.2012\n",
      "Epoch [616/2000], Avg Val Loss: 2.7416\n",
      "Validation loss improved from 2.7425 to 2.7416. Saving model...\n",
      "\n",
      "LOG: Epoch [617/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1971\n",
      "Epoch [617/2000], Avg Train Loss: 4.1971\n",
      "Epoch [617/2000], Avg Val Loss: 2.7408\n",
      "Validation loss improved from 2.7416 to 2.7408. Saving model...\n",
      "\n",
      "LOG: Epoch [618/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2325\n",
      "Epoch [618/2000], Avg Train Loss: 4.2325\n",
      "Epoch [618/2000], Avg Val Loss: 2.7399\n",
      "Validation loss improved from 2.7408 to 2.7399. Saving model...\n",
      "\n",
      "LOG: Epoch [619/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2358\n",
      "Epoch [619/2000], Avg Train Loss: 4.2358\n",
      "Epoch [619/2000], Avg Val Loss: 2.7391\n",
      "Validation loss improved from 2.7399 to 2.7391. Saving model...\n",
      "\n",
      "LOG: Epoch [620/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2235\n",
      "Epoch [620/2000], Avg Train Loss: 4.2235\n",
      "Epoch [620/2000], Avg Val Loss: 2.7382\n",
      "Validation loss improved from 2.7391 to 2.7382. Saving model...\n",
      "\n",
      "LOG: Epoch [621/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2459\n",
      "Epoch [621/2000], Avg Train Loss: 4.2459\n",
      "Epoch [621/2000], Avg Val Loss: 2.7374\n",
      "Validation loss improved from 2.7382 to 2.7374. Saving model...\n",
      "\n",
      "LOG: Epoch [622/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2276\n",
      "Epoch [622/2000], Avg Train Loss: 4.2276\n",
      "Epoch [622/2000], Avg Val Loss: 2.7366\n",
      "Validation loss improved from 2.7374 to 2.7366. Saving model...\n",
      "\n",
      "LOG: Epoch [623/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1923\n",
      "Epoch [623/2000], Avg Train Loss: 4.1923\n",
      "Epoch [623/2000], Avg Val Loss: 2.7358\n",
      "Validation loss improved from 2.7366 to 2.7358. Saving model...\n",
      "\n",
      "LOG: Epoch [624/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2109\n",
      "Epoch [624/2000], Avg Train Loss: 4.2109\n",
      "Epoch [624/2000], Avg Val Loss: 2.7350\n",
      "Validation loss improved from 2.7358 to 2.7350. Saving model...\n",
      "\n",
      "LOG: Epoch [625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2095\n",
      "Epoch [625/2000], Avg Train Loss: 4.2095\n",
      "Epoch [625/2000], Avg Val Loss: 2.7342\n",
      "Validation loss improved from 2.7350 to 2.7342. Saving model...\n",
      "\n",
      "LOG: Epoch [626/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2358\n",
      "Epoch [626/2000], Avg Train Loss: 4.2358\n",
      "Epoch [626/2000], Avg Val Loss: 2.7335\n",
      "Validation loss improved from 2.7342 to 2.7335. Saving model...\n",
      "\n",
      "LOG: Epoch [627/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1482\n",
      "Epoch [627/2000], Avg Train Loss: 4.1482\n",
      "Epoch [627/2000], Avg Val Loss: 2.7328\n",
      "Validation loss improved from 2.7335 to 2.7328. Saving model...\n",
      "\n",
      "LOG: Epoch [628/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2273\n",
      "Epoch [628/2000], Avg Train Loss: 4.2273\n",
      "Epoch [628/2000], Avg Val Loss: 2.7321\n",
      "Validation loss improved from 2.7328 to 2.7321. Saving model...\n",
      "\n",
      "LOG: Epoch [629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1838\n",
      "Epoch [629/2000], Avg Train Loss: 4.1838\n",
      "Epoch [629/2000], Avg Val Loss: 2.7314\n",
      "Validation loss improved from 2.7321 to 2.7314. Saving model...\n",
      "\n",
      "LOG: Epoch [630/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2013\n",
      "Epoch [630/2000], Avg Train Loss: 4.2013\n",
      "Epoch [630/2000], Avg Val Loss: 2.7307\n",
      "Validation loss improved from 2.7314 to 2.7307. Saving model...\n",
      "\n",
      "LOG: Epoch [631/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2277\n",
      "Epoch [631/2000], Avg Train Loss: 4.2277\n",
      "Epoch [631/2000], Avg Val Loss: 2.7301\n",
      "Validation loss improved from 2.7307 to 2.7301. Saving model...\n",
      "\n",
      "LOG: Epoch [632/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2334\n",
      "Epoch [632/2000], Avg Train Loss: 4.2334\n",
      "Epoch [632/2000], Avg Val Loss: 2.7295\n",
      "Validation loss improved from 2.7301 to 2.7295. Saving model...\n",
      "\n",
      "LOG: Epoch [633/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2088\n",
      "Epoch [633/2000], Avg Train Loss: 4.2088\n",
      "Epoch [633/2000], Avg Val Loss: 2.7289\n",
      "Validation loss improved from 2.7295 to 2.7289. Saving model...\n",
      "\n",
      "LOG: Epoch [634/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1989\n",
      "Epoch [634/2000], Avg Train Loss: 4.1989\n",
      "Epoch [634/2000], Avg Val Loss: 2.7282\n",
      "Validation loss improved from 2.7289 to 2.7282. Saving model...\n",
      "\n",
      "LOG: Epoch [635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2406\n",
      "Epoch [635/2000], Avg Train Loss: 4.2406\n",
      "Epoch [635/2000], Avg Val Loss: 2.7275\n",
      "Validation loss improved from 2.7282 to 2.7275. Saving model...\n",
      "\n",
      "LOG: Epoch [636/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1565\n",
      "Epoch [636/2000], Avg Train Loss: 4.1565\n",
      "Epoch [636/2000], Avg Val Loss: 2.7268\n",
      "Validation loss improved from 2.7275 to 2.7268. Saving model...\n",
      "\n",
      "LOG: Epoch [637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1903\n",
      "Epoch [637/2000], Avg Train Loss: 4.1903\n",
      "Epoch [637/2000], Avg Val Loss: 2.7262\n",
      "Validation loss improved from 2.7268 to 2.7262. Saving model...\n",
      "\n",
      "LOG: Epoch [638/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2091\n",
      "Epoch [638/2000], Avg Train Loss: 4.2091\n",
      "Epoch [638/2000], Avg Val Loss: 2.7255\n",
      "Validation loss improved from 2.7262 to 2.7255. Saving model...\n",
      "\n",
      "LOG: Epoch [639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1721\n",
      "Epoch [639/2000], Avg Train Loss: 4.1721\n",
      "Epoch [639/2000], Avg Val Loss: 2.7248\n",
      "Validation loss improved from 2.7255 to 2.7248. Saving model...\n",
      "\n",
      "LOG: Epoch [640/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1882\n",
      "Epoch [640/2000], Avg Train Loss: 4.1882\n",
      "Epoch [640/2000], Avg Val Loss: 2.7241\n",
      "Validation loss improved from 2.7248 to 2.7241. Saving model...\n",
      "\n",
      "LOG: Epoch [641/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2027\n",
      "Epoch [641/2000], Avg Train Loss: 4.2027\n",
      "Epoch [641/2000], Avg Val Loss: 2.7233\n",
      "Validation loss improved from 2.7241 to 2.7233. Saving model...\n",
      "\n",
      "LOG: Epoch [642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1875\n",
      "Epoch [642/2000], Avg Train Loss: 4.1875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [642/2000], Avg Val Loss: 2.7226\n",
      "Validation loss improved from 2.7233 to 2.7226. Saving model...\n",
      "\n",
      "LOG: Epoch [643/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2364\n",
      "Epoch [643/2000], Avg Train Loss: 4.2364\n",
      "Epoch [643/2000], Avg Val Loss: 2.7219\n",
      "Validation loss improved from 2.7226 to 2.7219. Saving model...\n",
      "\n",
      "LOG: Epoch [644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2209\n",
      "Epoch [644/2000], Avg Train Loss: 4.2209\n",
      "Epoch [644/2000], Avg Val Loss: 2.7212\n",
      "Validation loss improved from 2.7219 to 2.7212. Saving model...\n",
      "\n",
      "LOG: Epoch [645/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1859\n",
      "Epoch [645/2000], Avg Train Loss: 4.1859\n",
      "Epoch [645/2000], Avg Val Loss: 2.7205\n",
      "Validation loss improved from 2.7212 to 2.7205. Saving model...\n",
      "\n",
      "LOG: Epoch [646/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2232\n",
      "Epoch [646/2000], Avg Train Loss: 4.2232\n",
      "Epoch [646/2000], Avg Val Loss: 2.7198\n",
      "Validation loss improved from 2.7205 to 2.7198. Saving model...\n",
      "\n",
      "LOG: Epoch [647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1768\n",
      "Epoch [647/2000], Avg Train Loss: 4.1768\n",
      "Epoch [647/2000], Avg Val Loss: 2.7191\n",
      "Validation loss improved from 2.7198 to 2.7191. Saving model...\n",
      "\n",
      "LOG: Epoch [648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1834\n",
      "Epoch [648/2000], Avg Train Loss: 4.1834\n",
      "Epoch [648/2000], Avg Val Loss: 2.7183\n",
      "Validation loss improved from 2.7191 to 2.7183. Saving model...\n",
      "\n",
      "LOG: Epoch [649/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1831\n",
      "Epoch [649/2000], Avg Train Loss: 4.1831\n",
      "Epoch [649/2000], Avg Val Loss: 2.7175\n",
      "Validation loss improved from 2.7183 to 2.7175. Saving model...\n",
      "\n",
      "LOG: Epoch [650/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1684\n",
      "Epoch [650/2000], Avg Train Loss: 4.1684\n",
      "Epoch [650/2000], Avg Val Loss: 2.7168\n",
      "Validation loss improved from 2.7175 to 2.7168. Saving model...\n",
      "\n",
      "LOG: Epoch [651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1954\n",
      "Epoch [651/2000], Avg Train Loss: 4.1954\n",
      "Epoch [651/2000], Avg Val Loss: 2.7161\n",
      "Validation loss improved from 2.7168 to 2.7161. Saving model...\n",
      "\n",
      "LOG: Epoch [652/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1931\n",
      "Epoch [652/2000], Avg Train Loss: 4.1931\n",
      "Epoch [652/2000], Avg Val Loss: 2.7155\n",
      "Validation loss improved from 2.7161 to 2.7155. Saving model...\n",
      "\n",
      "LOG: Epoch [653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1795\n",
      "Epoch [653/2000], Avg Train Loss: 4.1795\n",
      "Epoch [653/2000], Avg Val Loss: 2.7149\n",
      "Validation loss improved from 2.7155 to 2.7149. Saving model...\n",
      "\n",
      "LOG: Epoch [654/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1504\n",
      "Epoch [654/2000], Avg Train Loss: 4.1504\n",
      "Epoch [654/2000], Avg Val Loss: 2.7143\n",
      "Validation loss improved from 2.7149 to 2.7143. Saving model...\n",
      "\n",
      "LOG: Epoch [655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1602\n",
      "Epoch [655/2000], Avg Train Loss: 4.1602\n",
      "Epoch [655/2000], Avg Val Loss: 2.7137\n",
      "Validation loss improved from 2.7143 to 2.7137. Saving model...\n",
      "\n",
      "LOG: Epoch [656/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1677\n",
      "Epoch [656/2000], Avg Train Loss: 4.1677\n",
      "Epoch [656/2000], Avg Val Loss: 2.7130\n",
      "Validation loss improved from 2.7137 to 2.7130. Saving model...\n",
      "\n",
      "LOG: Epoch [657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2098\n",
      "Epoch [657/2000], Avg Train Loss: 4.2098\n",
      "Epoch [657/2000], Avg Val Loss: 2.7124\n",
      "Validation loss improved from 2.7130 to 2.7124. Saving model...\n",
      "\n",
      "LOG: Epoch [658/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1687\n",
      "Epoch [658/2000], Avg Train Loss: 4.1687\n",
      "Epoch [658/2000], Avg Val Loss: 2.7117\n",
      "Validation loss improved from 2.7124 to 2.7117. Saving model...\n",
      "\n",
      "LOG: Epoch [659/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1477\n",
      "Epoch [659/2000], Avg Train Loss: 4.1477\n",
      "Epoch [659/2000], Avg Val Loss: 2.7111\n",
      "Validation loss improved from 2.7117 to 2.7111. Saving model...\n",
      "\n",
      "LOG: Epoch [660/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1381\n",
      "Epoch [660/2000], Avg Train Loss: 4.1381\n",
      "Epoch [660/2000], Avg Val Loss: 2.7104\n",
      "Validation loss improved from 2.7111 to 2.7104. Saving model...\n",
      "\n",
      "LOG: Epoch [661/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1581\n",
      "Epoch [661/2000], Avg Train Loss: 4.1581\n",
      "Epoch [661/2000], Avg Val Loss: 2.7097\n",
      "Validation loss improved from 2.7104 to 2.7097. Saving model...\n",
      "\n",
      "LOG: Epoch [662/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1416\n",
      "Epoch [662/2000], Avg Train Loss: 4.1416\n",
      "Epoch [662/2000], Avg Val Loss: 2.7090\n",
      "Validation loss improved from 2.7097 to 2.7090. Saving model...\n",
      "\n",
      "LOG: Epoch [663/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1366\n",
      "Epoch [663/2000], Avg Train Loss: 4.1366\n",
      "Epoch [663/2000], Avg Val Loss: 2.7084\n",
      "Validation loss improved from 2.7090 to 2.7084. Saving model...\n",
      "\n",
      "LOG: Epoch [664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1953\n",
      "Epoch [664/2000], Avg Train Loss: 4.1953\n",
      "Epoch [664/2000], Avg Val Loss: 2.7077\n",
      "Validation loss improved from 2.7084 to 2.7077. Saving model...\n",
      "\n",
      "LOG: Epoch [665/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1564\n",
      "Epoch [665/2000], Avg Train Loss: 4.1564\n",
      "Epoch [665/2000], Avg Val Loss: 2.7071\n",
      "Validation loss improved from 2.7077 to 2.7071. Saving model...\n",
      "\n",
      "LOG: Epoch [666/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1928\n",
      "Epoch [666/2000], Avg Train Loss: 4.1928\n",
      "Epoch [666/2000], Avg Val Loss: 2.7064\n",
      "Validation loss improved from 2.7071 to 2.7064. Saving model...\n",
      "\n",
      "LOG: Epoch [667/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1503\n",
      "Epoch [667/2000], Avg Train Loss: 4.1503\n",
      "Epoch [667/2000], Avg Val Loss: 2.7058\n",
      "Validation loss improved from 2.7064 to 2.7058. Saving model...\n",
      "\n",
      "LOG: Epoch [668/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2188\n",
      "Epoch [668/2000], Avg Train Loss: 4.2188\n",
      "Epoch [668/2000], Avg Val Loss: 2.7053\n",
      "Validation loss improved from 2.7058 to 2.7053. Saving model...\n",
      "\n",
      "LOG: Epoch [669/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1576\n",
      "Epoch [669/2000], Avg Train Loss: 4.1576\n",
      "Epoch [669/2000], Avg Val Loss: 2.7047\n",
      "Validation loss improved from 2.7053 to 2.7047. Saving model...\n",
      "\n",
      "LOG: Epoch [670/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1559\n",
      "Epoch [670/2000], Avg Train Loss: 4.1559\n",
      "Epoch [670/2000], Avg Val Loss: 2.7043\n",
      "Validation loss improved from 2.7047 to 2.7043. Saving model...\n",
      "\n",
      "LOG: Epoch [671/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1684\n",
      "Epoch [671/2000], Avg Train Loss: 4.1684\n",
      "Epoch [671/2000], Avg Val Loss: 2.7038\n",
      "Validation loss improved from 2.7043 to 2.7038. Saving model...\n",
      "\n",
      "LOG: Epoch [672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1705\n",
      "Epoch [672/2000], Avg Train Loss: 4.1705\n",
      "Epoch [672/2000], Avg Val Loss: 2.7033\n",
      "Validation loss improved from 2.7038 to 2.7033. Saving model...\n",
      "\n",
      "LOG: Epoch [673/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1714\n",
      "Epoch [673/2000], Avg Train Loss: 4.1714\n",
      "Epoch [673/2000], Avg Val Loss: 2.7029\n",
      "Validation loss improved from 2.7033 to 2.7029. Saving model...\n",
      "\n",
      "LOG: Epoch [674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1759\n",
      "Epoch [674/2000], Avg Train Loss: 4.1759\n",
      "Epoch [674/2000], Avg Val Loss: 2.7025\n",
      "Validation loss improved from 2.7029 to 2.7025. Saving model...\n",
      "\n",
      "LOG: Epoch [675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1658\n",
      "Epoch [675/2000], Avg Train Loss: 4.1658\n",
      "Epoch [675/2000], Avg Val Loss: 2.7021\n",
      "Validation loss improved from 2.7025 to 2.7021. Saving model...\n",
      "\n",
      "LOG: Epoch [676/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1571\n",
      "Epoch [676/2000], Avg Train Loss: 4.1571\n",
      "Epoch [676/2000], Avg Val Loss: 2.7017\n",
      "Validation loss improved from 2.7021 to 2.7017. Saving model...\n",
      "\n",
      "LOG: Epoch [677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1176\n",
      "Epoch [677/2000], Avg Train Loss: 4.1176\n",
      "Epoch [677/2000], Avg Val Loss: 2.7013\n",
      "Validation loss improved from 2.7017 to 2.7013. Saving model...\n",
      "\n",
      "LOG: Epoch [678/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1457\n",
      "Epoch [678/2000], Avg Train Loss: 4.1457\n",
      "Epoch [678/2000], Avg Val Loss: 2.7009\n",
      "Validation loss improved from 2.7013 to 2.7009. Saving model...\n",
      "\n",
      "LOG: Epoch [679/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1631\n",
      "Epoch [679/2000], Avg Train Loss: 4.1631\n",
      "Epoch [679/2000], Avg Val Loss: 2.7005\n",
      "Validation loss improved from 2.7009 to 2.7005. Saving model...\n",
      "\n",
      "LOG: Epoch [680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1173\n",
      "Epoch [680/2000], Avg Train Loss: 4.1173\n",
      "Epoch [680/2000], Avg Val Loss: 2.7001\n",
      "Validation loss improved from 2.7005 to 2.7001. Saving model...\n",
      "\n",
      "LOG: Epoch [681/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1477\n",
      "Epoch [681/2000], Avg Train Loss: 4.1477\n",
      "Epoch [681/2000], Avg Val Loss: 2.6998\n",
      "Validation loss improved from 2.7001 to 2.6998. Saving model...\n",
      "\n",
      "LOG: Epoch [682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1477\n",
      "Epoch [682/2000], Avg Train Loss: 4.1477\n",
      "Epoch [682/2000], Avg Val Loss: 2.6994\n",
      "Validation loss improved from 2.6998 to 2.6994. Saving model...\n",
      "\n",
      "LOG: Epoch [683/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1560\n",
      "Epoch [683/2000], Avg Train Loss: 4.1560\n",
      "Epoch [683/2000], Avg Val Loss: 2.6989\n",
      "Validation loss improved from 2.6994 to 2.6989. Saving model...\n",
      "\n",
      "LOG: Epoch [684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1544\n",
      "Epoch [684/2000], Avg Train Loss: 4.1544\n",
      "Epoch [684/2000], Avg Val Loss: 2.6984\n",
      "Validation loss improved from 2.6989 to 2.6984. Saving model...\n",
      "\n",
      "LOG: Epoch [685/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1502\n",
      "Epoch [685/2000], Avg Train Loss: 4.1502\n",
      "Epoch [685/2000], Avg Val Loss: 2.6978\n",
      "Validation loss improved from 2.6984 to 2.6978. Saving model...\n",
      "\n",
      "LOG: Epoch [686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1627\n",
      "Epoch [686/2000], Avg Train Loss: 4.1627\n",
      "Epoch [686/2000], Avg Val Loss: 2.6973\n",
      "Validation loss improved from 2.6978 to 2.6973. Saving model...\n",
      "\n",
      "LOG: Epoch [687/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1163\n",
      "Epoch [687/2000], Avg Train Loss: 4.1163\n",
      "Epoch [687/2000], Avg Val Loss: 2.6966\n",
      "Validation loss improved from 2.6973 to 2.6966. Saving model...\n",
      "\n",
      "LOG: Epoch [688/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1670\n",
      "Epoch [688/2000], Avg Train Loss: 4.1670\n",
      "Epoch [688/2000], Avg Val Loss: 2.6960\n",
      "Validation loss improved from 2.6966 to 2.6960. Saving model...\n",
      "\n",
      "LOG: Epoch [689/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1538\n",
      "Epoch [689/2000], Avg Train Loss: 4.1538\n",
      "Epoch [689/2000], Avg Val Loss: 2.6953\n",
      "Validation loss improved from 2.6960 to 2.6953. Saving model...\n",
      "\n",
      "LOG: Epoch [690/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1510\n",
      "Epoch [690/2000], Avg Train Loss: 4.1510\n",
      "Epoch [690/2000], Avg Val Loss: 2.6945\n",
      "Validation loss improved from 2.6953 to 2.6945. Saving model...\n",
      "\n",
      "LOG: Epoch [691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1516\n",
      "Epoch [691/2000], Avg Train Loss: 4.1516\n",
      "Epoch [691/2000], Avg Val Loss: 2.6938\n",
      "Validation loss improved from 2.6945 to 2.6938. Saving model...\n",
      "\n",
      "LOG: Epoch [692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1293\n",
      "Epoch [692/2000], Avg Train Loss: 4.1293\n",
      "Epoch [692/2000], Avg Val Loss: 2.6931\n",
      "Validation loss improved from 2.6938 to 2.6931. Saving model...\n",
      "\n",
      "LOG: Epoch [693/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1025\n",
      "Epoch [693/2000], Avg Train Loss: 4.1025\n",
      "Epoch [693/2000], Avg Val Loss: 2.6924\n",
      "Validation loss improved from 2.6931 to 2.6924. Saving model...\n",
      "\n",
      "LOG: Epoch [694/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1235\n",
      "Epoch [694/2000], Avg Train Loss: 4.1235\n",
      "Epoch [694/2000], Avg Val Loss: 2.6918\n",
      "Validation loss improved from 2.6924 to 2.6918. Saving model...\n",
      "\n",
      "LOG: Epoch [695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1259\n",
      "Epoch [695/2000], Avg Train Loss: 4.1259\n",
      "Epoch [695/2000], Avg Val Loss: 2.6910\n",
      "Validation loss improved from 2.6918 to 2.6910. Saving model...\n",
      "\n",
      "LOG: Epoch [696/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1289\n",
      "Epoch [696/2000], Avg Train Loss: 4.1289\n",
      "Epoch [696/2000], Avg Val Loss: 2.6903\n",
      "Validation loss improved from 2.6910 to 2.6903. Saving model...\n",
      "\n",
      "LOG: Epoch [697/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1574\n",
      "Epoch [697/2000], Avg Train Loss: 4.1574\n",
      "Epoch [697/2000], Avg Val Loss: 2.6895\n",
      "Validation loss improved from 2.6903 to 2.6895. Saving model...\n",
      "\n",
      "LOG: Epoch [698/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1339\n",
      "Epoch [698/2000], Avg Train Loss: 4.1339\n",
      "Epoch [698/2000], Avg Val Loss: 2.6888\n",
      "Validation loss improved from 2.6895 to 2.6888. Saving model...\n",
      "\n",
      "LOG: Epoch [699/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1337\n",
      "Epoch [699/2000], Avg Train Loss: 4.1337\n",
      "Epoch [699/2000], Avg Val Loss: 2.6881\n",
      "Validation loss improved from 2.6888 to 2.6881. Saving model...\n",
      "\n",
      "LOG: Epoch [700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1151\n",
      "Epoch [700/2000], Avg Train Loss: 4.1151\n",
      "Epoch [700/2000], Avg Val Loss: 2.6875\n",
      "Validation loss improved from 2.6881 to 2.6875. Saving model...\n",
      "\n",
      "LOG: Epoch [701/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1650\n",
      "Epoch [701/2000], Avg Train Loss: 4.1650\n",
      "Epoch [701/2000], Avg Val Loss: 2.6868\n",
      "Validation loss improved from 2.6875 to 2.6868. Saving model...\n",
      "\n",
      "LOG: Epoch [702/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1320\n",
      "Epoch [702/2000], Avg Train Loss: 4.1320\n",
      "Epoch [702/2000], Avg Val Loss: 2.6862\n",
      "Validation loss improved from 2.6868 to 2.6862. Saving model...\n",
      "\n",
      "LOG: Epoch [703/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1425\n",
      "Epoch [703/2000], Avg Train Loss: 4.1425\n",
      "Epoch [703/2000], Avg Val Loss: 2.6857\n",
      "Validation loss improved from 2.6862 to 2.6857. Saving model...\n",
      "\n",
      "LOG: Epoch [704/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1280\n",
      "Epoch [704/2000], Avg Train Loss: 4.1280\n",
      "Epoch [704/2000], Avg Val Loss: 2.6851\n",
      "Validation loss improved from 2.6857 to 2.6851. Saving model...\n",
      "\n",
      "LOG: Epoch [705/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1213\n",
      "Epoch [705/2000], Avg Train Loss: 4.1213\n",
      "Epoch [705/2000], Avg Val Loss: 2.6845\n",
      "Validation loss improved from 2.6851 to 2.6845. Saving model...\n",
      "\n",
      "LOG: Epoch [706/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1154\n",
      "Epoch [706/2000], Avg Train Loss: 4.1154\n",
      "Epoch [706/2000], Avg Val Loss: 2.6839\n",
      "Validation loss improved from 2.6845 to 2.6839. Saving model...\n",
      "\n",
      "LOG: Epoch [707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1000\n",
      "Epoch [707/2000], Avg Train Loss: 4.1000\n",
      "Epoch [707/2000], Avg Val Loss: 2.6833\n",
      "Validation loss improved from 2.6839 to 2.6833. Saving model...\n",
      "\n",
      "LOG: Epoch [708/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1348\n",
      "Epoch [708/2000], Avg Train Loss: 4.1348\n",
      "Epoch [708/2000], Avg Val Loss: 2.6828\n",
      "Validation loss improved from 2.6833 to 2.6828. Saving model...\n",
      "\n",
      "LOG: Epoch [709/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1424\n",
      "Epoch [709/2000], Avg Train Loss: 4.1424\n",
      "Epoch [709/2000], Avg Val Loss: 2.6822\n",
      "Validation loss improved from 2.6828 to 2.6822. Saving model...\n",
      "\n",
      "LOG: Epoch [710/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1482\n",
      "Epoch [710/2000], Avg Train Loss: 4.1482\n",
      "Epoch [710/2000], Avg Val Loss: 2.6817\n",
      "Validation loss improved from 2.6822 to 2.6817. Saving model...\n",
      "\n",
      "LOG: Epoch [711/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1707\n",
      "Epoch [711/2000], Avg Train Loss: 4.1707\n",
      "Epoch [711/2000], Avg Val Loss: 2.6811\n",
      "Validation loss improved from 2.6817 to 2.6811. Saving model...\n",
      "\n",
      "LOG: Epoch [712/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1136\n",
      "Epoch [712/2000], Avg Train Loss: 4.1136\n",
      "Epoch [712/2000], Avg Val Loss: 2.6806\n",
      "Validation loss improved from 2.6811 to 2.6806. Saving model...\n",
      "\n",
      "LOG: Epoch [713/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1171\n",
      "Epoch [713/2000], Avg Train Loss: 4.1171\n",
      "Epoch [713/2000], Avg Val Loss: 2.6801\n",
      "Validation loss improved from 2.6806 to 2.6801. Saving model...\n",
      "\n",
      "LOG: Epoch [714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0735\n",
      "Epoch [714/2000], Avg Train Loss: 4.0735\n",
      "Epoch [714/2000], Avg Val Loss: 2.6796\n",
      "Validation loss improved from 2.6801 to 2.6796. Saving model...\n",
      "\n",
      "LOG: Epoch [715/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1008\n",
      "Epoch [715/2000], Avg Train Loss: 4.1008\n",
      "Epoch [715/2000], Avg Val Loss: 2.6790\n",
      "Validation loss improved from 2.6796 to 2.6790. Saving model...\n",
      "\n",
      "LOG: Epoch [716/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1238\n",
      "Epoch [716/2000], Avg Train Loss: 4.1238\n",
      "Epoch [716/2000], Avg Val Loss: 2.6785\n",
      "Validation loss improved from 2.6790 to 2.6785. Saving model...\n",
      "\n",
      "LOG: Epoch [717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1278\n",
      "Epoch [717/2000], Avg Train Loss: 4.1278\n",
      "Epoch [717/2000], Avg Val Loss: 2.6780\n",
      "Validation loss improved from 2.6785 to 2.6780. Saving model...\n",
      "\n",
      "LOG: Epoch [718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1313\n",
      "Epoch [718/2000], Avg Train Loss: 4.1313\n",
      "Epoch [718/2000], Avg Val Loss: 2.6774\n",
      "Validation loss improved from 2.6780 to 2.6774. Saving model...\n",
      "\n",
      "LOG: Epoch [719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1139\n",
      "Epoch [719/2000], Avg Train Loss: 4.1139\n",
      "Epoch [719/2000], Avg Val Loss: 2.6769\n",
      "Validation loss improved from 2.6774 to 2.6769. Saving model...\n",
      "\n",
      "LOG: Epoch [720/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0613\n",
      "Epoch [720/2000], Avg Train Loss: 4.0613\n",
      "Epoch [720/2000], Avg Val Loss: 2.6763\n",
      "Validation loss improved from 2.6769 to 2.6763. Saving model...\n",
      "\n",
      "LOG: Epoch [721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1368\n",
      "Epoch [721/2000], Avg Train Loss: 4.1368\n",
      "Epoch [721/2000], Avg Val Loss: 2.6757\n",
      "Validation loss improved from 2.6763 to 2.6757. Saving model...\n",
      "\n",
      "LOG: Epoch [722/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1270\n",
      "Epoch [722/2000], Avg Train Loss: 4.1270\n",
      "Epoch [722/2000], Avg Val Loss: 2.6751\n",
      "Validation loss improved from 2.6757 to 2.6751. Saving model...\n",
      "\n",
      "LOG: Epoch [723/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0766\n",
      "Epoch [723/2000], Avg Train Loss: 4.0766\n",
      "Epoch [723/2000], Avg Val Loss: 2.6745\n",
      "Validation loss improved from 2.6751 to 2.6745. Saving model...\n",
      "\n",
      "LOG: Epoch [724/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0979\n",
      "Epoch [724/2000], Avg Train Loss: 4.0979\n",
      "Epoch [724/2000], Avg Val Loss: 2.6739\n",
      "Validation loss improved from 2.6745 to 2.6739. Saving model...\n",
      "\n",
      "LOG: Epoch [725/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1543\n",
      "Epoch [725/2000], Avg Train Loss: 4.1543\n",
      "Epoch [725/2000], Avg Val Loss: 2.6732\n",
      "Validation loss improved from 2.6739 to 2.6732. Saving model...\n",
      "\n",
      "LOG: Epoch [726/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0871\n",
      "Epoch [726/2000], Avg Train Loss: 4.0871\n",
      "Epoch [726/2000], Avg Val Loss: 2.6725\n",
      "Validation loss improved from 2.6732 to 2.6725. Saving model...\n",
      "\n",
      "LOG: Epoch [727/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1194\n",
      "Epoch [727/2000], Avg Train Loss: 4.1194\n",
      "Epoch [727/2000], Avg Val Loss: 2.6719\n",
      "Validation loss improved from 2.6725 to 2.6719. Saving model...\n",
      "\n",
      "LOG: Epoch [728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0867\n",
      "Epoch [728/2000], Avg Train Loss: 4.0867\n",
      "Epoch [728/2000], Avg Val Loss: 2.6713\n",
      "Validation loss improved from 2.6719 to 2.6713. Saving model...\n",
      "\n",
      "LOG: Epoch [729/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1294\n",
      "Epoch [729/2000], Avg Train Loss: 4.1294\n",
      "Epoch [729/2000], Avg Val Loss: 2.6707\n",
      "Validation loss improved from 2.6713 to 2.6707. Saving model...\n",
      "\n",
      "LOG: Epoch [730/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0719\n",
      "Epoch [730/2000], Avg Train Loss: 4.0719\n",
      "Epoch [730/2000], Avg Val Loss: 2.6702\n",
      "Validation loss improved from 2.6707 to 2.6702. Saving model...\n",
      "\n",
      "LOG: Epoch [731/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0944\n",
      "Epoch [731/2000], Avg Train Loss: 4.0944\n",
      "Epoch [731/2000], Avg Val Loss: 2.6697\n",
      "Validation loss improved from 2.6702 to 2.6697. Saving model...\n",
      "\n",
      "LOG: Epoch [732/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0475\n",
      "Epoch [732/2000], Avg Train Loss: 4.0475\n",
      "Epoch [732/2000], Avg Val Loss: 2.6691\n",
      "Validation loss improved from 2.6697 to 2.6691. Saving model...\n",
      "\n",
      "LOG: Epoch [733/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0798\n",
      "Epoch [733/2000], Avg Train Loss: 4.0798\n",
      "Epoch [733/2000], Avg Val Loss: 2.6686\n",
      "Validation loss improved from 2.6691 to 2.6686. Saving model...\n",
      "\n",
      "LOG: Epoch [734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0897\n",
      "Epoch [734/2000], Avg Train Loss: 4.0897\n",
      "Epoch [734/2000], Avg Val Loss: 2.6680\n",
      "Validation loss improved from 2.6686 to 2.6680. Saving model...\n",
      "\n",
      "LOG: Epoch [735/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0934\n",
      "Epoch [735/2000], Avg Train Loss: 4.0934\n",
      "Epoch [735/2000], Avg Val Loss: 2.6675\n",
      "Validation loss improved from 2.6680 to 2.6675. Saving model...\n",
      "\n",
      "LOG: Epoch [736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0917\n",
      "Epoch [736/2000], Avg Train Loss: 4.0917\n",
      "Epoch [736/2000], Avg Val Loss: 2.6670\n",
      "Validation loss improved from 2.6675 to 2.6670. Saving model...\n",
      "\n",
      "LOG: Epoch [737/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0588\n",
      "Epoch [737/2000], Avg Train Loss: 4.0588\n",
      "Epoch [737/2000], Avg Val Loss: 2.6664\n",
      "Validation loss improved from 2.6670 to 2.6664. Saving model...\n",
      "\n",
      "LOG: Epoch [738/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1021\n",
      "Epoch [738/2000], Avg Train Loss: 4.1021\n",
      "Epoch [738/2000], Avg Val Loss: 2.6658\n",
      "Validation loss improved from 2.6664 to 2.6658. Saving model...\n",
      "\n",
      "LOG: Epoch [739/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0830\n",
      "Epoch [739/2000], Avg Train Loss: 4.0830\n",
      "Epoch [739/2000], Avg Val Loss: 2.6652\n",
      "Validation loss improved from 2.6658 to 2.6652. Saving model...\n",
      "\n",
      "LOG: Epoch [740/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0914\n",
      "Epoch [740/2000], Avg Train Loss: 4.0914\n",
      "Epoch [740/2000], Avg Val Loss: 2.6646\n",
      "Validation loss improved from 2.6652 to 2.6646. Saving model...\n",
      "\n",
      "LOG: Epoch [741/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0468\n",
      "Epoch [741/2000], Avg Train Loss: 4.0468\n",
      "Epoch [741/2000], Avg Val Loss: 2.6640\n",
      "Validation loss improved from 2.6646 to 2.6640. Saving model...\n",
      "\n",
      "LOG: Epoch [742/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1182\n",
      "Epoch [742/2000], Avg Train Loss: 4.1182\n",
      "Epoch [742/2000], Avg Val Loss: 2.6634\n",
      "Validation loss improved from 2.6640 to 2.6634. Saving model...\n",
      "\n",
      "LOG: Epoch [743/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1086\n",
      "Epoch [743/2000], Avg Train Loss: 4.1086\n",
      "Epoch [743/2000], Avg Val Loss: 2.6628\n",
      "Validation loss improved from 2.6634 to 2.6628. Saving model...\n",
      "\n",
      "LOG: Epoch [744/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0875\n",
      "Epoch [744/2000], Avg Train Loss: 4.0875\n",
      "Epoch [744/2000], Avg Val Loss: 2.6622\n",
      "Validation loss improved from 2.6628 to 2.6622. Saving model...\n",
      "\n",
      "LOG: Epoch [745/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0527\n",
      "Epoch [745/2000], Avg Train Loss: 4.0527\n",
      "Epoch [745/2000], Avg Val Loss: 2.6617\n",
      "Validation loss improved from 2.6622 to 2.6617. Saving model...\n",
      "\n",
      "LOG: Epoch [746/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0859\n",
      "Epoch [746/2000], Avg Train Loss: 4.0859\n",
      "Epoch [746/2000], Avg Val Loss: 2.6611\n",
      "Validation loss improved from 2.6617 to 2.6611. Saving model...\n",
      "\n",
      "LOG: Epoch [747/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0515\n",
      "Epoch [747/2000], Avg Train Loss: 4.0515\n",
      "Epoch [747/2000], Avg Val Loss: 2.6605\n",
      "Validation loss improved from 2.6611 to 2.6605. Saving model...\n",
      "\n",
      "LOG: Epoch [748/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0671\n",
      "Epoch [748/2000], Avg Train Loss: 4.0671\n",
      "Epoch [748/2000], Avg Val Loss: 2.6597\n",
      "Validation loss improved from 2.6605 to 2.6597. Saving model...\n",
      "\n",
      "LOG: Epoch [749/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0581\n",
      "Epoch [749/2000], Avg Train Loss: 4.0581\n",
      "Epoch [749/2000], Avg Val Loss: 2.6590\n",
      "Validation loss improved from 2.6597 to 2.6590. Saving model...\n",
      "\n",
      "LOG: Epoch [750/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0600\n",
      "Epoch [750/2000], Avg Train Loss: 4.0600\n",
      "Epoch [750/2000], Avg Val Loss: 2.6584\n",
      "Validation loss improved from 2.6590 to 2.6584. Saving model...\n",
      "\n",
      "LOG: Epoch [751/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0656\n",
      "Epoch [751/2000], Avg Train Loss: 4.0656\n",
      "Epoch [751/2000], Avg Val Loss: 2.6576\n",
      "Validation loss improved from 2.6584 to 2.6576. Saving model...\n",
      "\n",
      "LOG: Epoch [752/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0373\n",
      "Epoch [752/2000], Avg Train Loss: 4.0373\n",
      "Epoch [752/2000], Avg Val Loss: 2.6569\n",
      "Validation loss improved from 2.6576 to 2.6569. Saving model...\n",
      "\n",
      "LOG: Epoch [753/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0519\n",
      "Epoch [753/2000], Avg Train Loss: 4.0519\n",
      "Epoch [753/2000], Avg Val Loss: 2.6562\n",
      "Validation loss improved from 2.6569 to 2.6562. Saving model...\n",
      "\n",
      "LOG: Epoch [754/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0296\n",
      "Epoch [754/2000], Avg Train Loss: 4.0296\n",
      "Epoch [754/2000], Avg Val Loss: 2.6555\n",
      "Validation loss improved from 2.6562 to 2.6555. Saving model...\n",
      "\n",
      "LOG: Epoch [755/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0564\n",
      "Epoch [755/2000], Avg Train Loss: 4.0564\n",
      "Epoch [755/2000], Avg Val Loss: 2.6549\n",
      "Validation loss improved from 2.6555 to 2.6549. Saving model...\n",
      "\n",
      "LOG: Epoch [756/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0704\n",
      "Epoch [756/2000], Avg Train Loss: 4.0704\n",
      "Epoch [756/2000], Avg Val Loss: 2.6543\n",
      "Validation loss improved from 2.6549 to 2.6543. Saving model...\n",
      "\n",
      "LOG: Epoch [757/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0502\n",
      "Epoch [757/2000], Avg Train Loss: 4.0502\n",
      "Epoch [757/2000], Avg Val Loss: 2.6537\n",
      "Validation loss improved from 2.6543 to 2.6537. Saving model...\n",
      "\n",
      "LOG: Epoch [758/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0607\n",
      "Epoch [758/2000], Avg Train Loss: 4.0607\n",
      "Epoch [758/2000], Avg Val Loss: 2.6530\n",
      "Validation loss improved from 2.6537 to 2.6530. Saving model...\n",
      "\n",
      "LOG: Epoch [759/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0902\n",
      "Epoch [759/2000], Avg Train Loss: 4.0902\n",
      "Epoch [759/2000], Avg Val Loss: 2.6523\n",
      "Validation loss improved from 2.6530 to 2.6523. Saving model...\n",
      "\n",
      "LOG: Epoch [760/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0531\n",
      "Epoch [760/2000], Avg Train Loss: 4.0531\n",
      "Epoch [760/2000], Avg Val Loss: 2.6516\n",
      "Validation loss improved from 2.6523 to 2.6516. Saving model...\n",
      "\n",
      "LOG: Epoch [761/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0492\n",
      "Epoch [761/2000], Avg Train Loss: 4.0492\n",
      "Epoch [761/2000], Avg Val Loss: 2.6511\n",
      "Validation loss improved from 2.6516 to 2.6511. Saving model...\n",
      "\n",
      "LOG: Epoch [762/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1239\n",
      "Epoch [762/2000], Avg Train Loss: 4.1239\n",
      "Epoch [762/2000], Avg Val Loss: 2.6505\n",
      "Validation loss improved from 2.6511 to 2.6505. Saving model...\n",
      "\n",
      "LOG: Epoch [763/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0487\n",
      "Epoch [763/2000], Avg Train Loss: 4.0487\n",
      "Epoch [763/2000], Avg Val Loss: 2.6500\n",
      "Validation loss improved from 2.6505 to 2.6500. Saving model...\n",
      "\n",
      "LOG: Epoch [764/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0914\n",
      "Epoch [764/2000], Avg Train Loss: 4.0914\n",
      "Epoch [764/2000], Avg Val Loss: 2.6494\n",
      "Validation loss improved from 2.6500 to 2.6494. Saving model...\n",
      "\n",
      "LOG: Epoch [765/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0316\n",
      "Epoch [765/2000], Avg Train Loss: 4.0316\n",
      "Epoch [765/2000], Avg Val Loss: 2.6489\n",
      "Validation loss improved from 2.6494 to 2.6489. Saving model...\n",
      "\n",
      "LOG: Epoch [766/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0408\n",
      "Epoch [766/2000], Avg Train Loss: 4.0408\n",
      "Epoch [766/2000], Avg Val Loss: 2.6484\n",
      "Validation loss improved from 2.6489 to 2.6484. Saving model...\n",
      "\n",
      "LOG: Epoch [767/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0299\n",
      "Epoch [767/2000], Avg Train Loss: 4.0299\n",
      "Epoch [767/2000], Avg Val Loss: 2.6478\n",
      "Validation loss improved from 2.6484 to 2.6478. Saving model...\n",
      "\n",
      "LOG: Epoch [768/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0427\n",
      "Epoch [768/2000], Avg Train Loss: 4.0427\n",
      "Epoch [768/2000], Avg Val Loss: 2.6473\n",
      "Validation loss improved from 2.6478 to 2.6473. Saving model...\n",
      "\n",
      "LOG: Epoch [769/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0679\n",
      "Epoch [769/2000], Avg Train Loss: 4.0679\n",
      "Epoch [769/2000], Avg Val Loss: 2.6468\n",
      "Validation loss improved from 2.6473 to 2.6468. Saving model...\n",
      "\n",
      "LOG: Epoch [770/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0573\n",
      "Epoch [770/2000], Avg Train Loss: 4.0573\n",
      "Epoch [770/2000], Avg Val Loss: 2.6463\n",
      "Validation loss improved from 2.6468 to 2.6463. Saving model...\n",
      "\n",
      "LOG: Epoch [771/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0695\n",
      "Epoch [771/2000], Avg Train Loss: 4.0695\n",
      "Epoch [771/2000], Avg Val Loss: 2.6458\n",
      "Validation loss improved from 2.6463 to 2.6458. Saving model...\n",
      "\n",
      "LOG: Epoch [772/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0496\n",
      "Epoch [772/2000], Avg Train Loss: 4.0496\n",
      "Epoch [772/2000], Avg Val Loss: 2.6452\n",
      "Validation loss improved from 2.6458 to 2.6452. Saving model...\n",
      "\n",
      "LOG: Epoch [773/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0674\n",
      "Epoch [773/2000], Avg Train Loss: 4.0674\n",
      "Epoch [773/2000], Avg Val Loss: 2.6448\n",
      "Validation loss improved from 2.6452 to 2.6448. Saving model...\n",
      "\n",
      "LOG: Epoch [774/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0412\n",
      "Epoch [774/2000], Avg Train Loss: 4.0412\n",
      "Epoch [774/2000], Avg Val Loss: 2.6444\n",
      "Validation loss improved from 2.6448 to 2.6444. Saving model...\n",
      "\n",
      "LOG: Epoch [775/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0637\n",
      "Epoch [775/2000], Avg Train Loss: 4.0637\n",
      "Epoch [775/2000], Avg Val Loss: 2.6440\n",
      "Validation loss improved from 2.6444 to 2.6440. Saving model...\n",
      "\n",
      "LOG: Epoch [776/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0942\n",
      "Epoch [776/2000], Avg Train Loss: 4.0942\n",
      "Epoch [776/2000], Avg Val Loss: 2.6436\n",
      "Validation loss improved from 2.6440 to 2.6436. Saving model...\n",
      "\n",
      "LOG: Epoch [777/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0270\n",
      "Epoch [777/2000], Avg Train Loss: 4.0270\n",
      "Epoch [777/2000], Avg Val Loss: 2.6433\n",
      "Validation loss improved from 2.6436 to 2.6433. Saving model...\n",
      "\n",
      "LOG: Epoch [778/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0300\n",
      "Epoch [778/2000], Avg Train Loss: 4.0300\n",
      "Epoch [778/2000], Avg Val Loss: 2.6428\n",
      "Validation loss improved from 2.6433 to 2.6428. Saving model...\n",
      "\n",
      "LOG: Epoch [779/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0491\n",
      "Epoch [779/2000], Avg Train Loss: 4.0491\n",
      "Epoch [779/2000], Avg Val Loss: 2.6425\n",
      "Validation loss improved from 2.6428 to 2.6425. Saving model...\n",
      "\n",
      "LOG: Epoch [780/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0462\n",
      "Epoch [780/2000], Avg Train Loss: 4.0462\n",
      "Epoch [780/2000], Avg Val Loss: 2.6421\n",
      "Validation loss improved from 2.6425 to 2.6421. Saving model...\n",
      "\n",
      "LOG: Epoch [781/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0689\n",
      "Epoch [781/2000], Avg Train Loss: 4.0689\n",
      "Epoch [781/2000], Avg Val Loss: 2.6417\n",
      "Validation loss improved from 2.6421 to 2.6417. Saving model...\n",
      "\n",
      "LOG: Epoch [782/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0290\n",
      "Epoch [782/2000], Avg Train Loss: 4.0290\n",
      "Epoch [782/2000], Avg Val Loss: 2.6414\n",
      "Validation loss improved from 2.6417 to 2.6414. Saving model...\n",
      "\n",
      "LOG: Epoch [783/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0486\n",
      "Epoch [783/2000], Avg Train Loss: 4.0486\n",
      "Epoch [783/2000], Avg Val Loss: 2.6410\n",
      "Validation loss improved from 2.6414 to 2.6410. Saving model...\n",
      "\n",
      "LOG: Epoch [784/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0065\n",
      "Epoch [784/2000], Avg Train Loss: 4.0065\n",
      "Epoch [784/2000], Avg Val Loss: 2.6407\n",
      "Validation loss improved from 2.6410 to 2.6407. Saving model...\n",
      "\n",
      "LOG: Epoch [785/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0132\n",
      "Epoch [785/2000], Avg Train Loss: 4.0132\n",
      "Epoch [785/2000], Avg Val Loss: 2.6402\n",
      "Validation loss improved from 2.6407 to 2.6402. Saving model...\n",
      "\n",
      "LOG: Epoch [786/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0847\n",
      "Epoch [786/2000], Avg Train Loss: 4.0847\n",
      "Epoch [786/2000], Avg Val Loss: 2.6397\n",
      "Validation loss improved from 2.6402 to 2.6397. Saving model...\n",
      "\n",
      "LOG: Epoch [787/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0035\n",
      "Epoch [787/2000], Avg Train Loss: 4.0035\n",
      "Epoch [787/2000], Avg Val Loss: 2.6391\n",
      "Validation loss improved from 2.6397 to 2.6391. Saving model...\n",
      "\n",
      "LOG: Epoch [788/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0452\n",
      "Epoch [788/2000], Avg Train Loss: 4.0452\n",
      "Epoch [788/2000], Avg Val Loss: 2.6385\n",
      "Validation loss improved from 2.6391 to 2.6385. Saving model...\n",
      "\n",
      "LOG: Epoch [789/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0304\n",
      "Epoch [789/2000], Avg Train Loss: 4.0304\n",
      "Epoch [789/2000], Avg Val Loss: 2.6379\n",
      "Validation loss improved from 2.6385 to 2.6379. Saving model...\n",
      "\n",
      "LOG: Epoch [790/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0387\n",
      "Epoch [790/2000], Avg Train Loss: 4.0387\n",
      "Epoch [790/2000], Avg Val Loss: 2.6375\n",
      "Validation loss improved from 2.6379 to 2.6375. Saving model...\n",
      "\n",
      "LOG: Epoch [791/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0374\n",
      "Epoch [791/2000], Avg Train Loss: 4.0374\n",
      "Epoch [791/2000], Avg Val Loss: 2.6370\n",
      "Validation loss improved from 2.6375 to 2.6370. Saving model...\n",
      "\n",
      "LOG: Epoch [792/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0138\n",
      "Epoch [792/2000], Avg Train Loss: 4.0138\n",
      "Epoch [792/2000], Avg Val Loss: 2.6365\n",
      "Validation loss improved from 2.6370 to 2.6365. Saving model...\n",
      "\n",
      "LOG: Epoch [793/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0607\n",
      "Epoch [793/2000], Avg Train Loss: 4.0607\n",
      "Epoch [793/2000], Avg Val Loss: 2.6362\n",
      "Validation loss improved from 2.6365 to 2.6362. Saving model...\n",
      "\n",
      "LOG: Epoch [794/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0004\n",
      "Epoch [794/2000], Avg Train Loss: 4.0004\n",
      "Epoch [794/2000], Avg Val Loss: 2.6358\n",
      "Validation loss improved from 2.6362 to 2.6358. Saving model...\n",
      "\n",
      "LOG: Epoch [795/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0367\n",
      "Epoch [795/2000], Avg Train Loss: 4.0367\n",
      "Epoch [795/2000], Avg Val Loss: 2.6355\n",
      "Validation loss improved from 2.6358 to 2.6355. Saving model...\n",
      "\n",
      "LOG: Epoch [796/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0186\n",
      "Epoch [796/2000], Avg Train Loss: 4.0186\n",
      "Epoch [796/2000], Avg Val Loss: 2.6352\n",
      "Validation loss improved from 2.6355 to 2.6352. Saving model...\n",
      "\n",
      "LOG: Epoch [797/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0481\n",
      "Epoch [797/2000], Avg Train Loss: 4.0481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [797/2000], Avg Val Loss: 2.6349\n",
      "Validation loss improved from 2.6352 to 2.6349. Saving model...\n",
      "\n",
      "LOG: Epoch [798/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9845\n",
      "Epoch [798/2000], Avg Train Loss: 3.9845\n",
      "Epoch [798/2000], Avg Val Loss: 2.6346\n",
      "Validation loss improved from 2.6349 to 2.6346. Saving model...\n",
      "\n",
      "LOG: Epoch [799/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0290\n",
      "Epoch [799/2000], Avg Train Loss: 4.0290\n",
      "Epoch [799/2000], Avg Val Loss: 2.6344\n",
      "Validation loss improved from 2.6346 to 2.6344. Saving model...\n",
      "\n",
      "LOG: Epoch [800/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0129\n",
      "Epoch [800/2000], Avg Train Loss: 4.0129\n",
      "Epoch [800/2000], Avg Val Loss: 2.6342\n",
      "Validation loss improved from 2.6344 to 2.6342. Saving model...\n",
      "\n",
      "LOG: Epoch [801/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0083\n",
      "Epoch [801/2000], Avg Train Loss: 4.0083\n",
      "Epoch [801/2000], Avg Val Loss: 2.6340\n",
      "Validation loss improved from 2.6342 to 2.6340. Saving model...\n",
      "\n",
      "LOG: Epoch [802/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0330\n",
      "Epoch [802/2000], Avg Train Loss: 4.0330\n",
      "Epoch [802/2000], Avg Val Loss: 2.6337\n",
      "Validation loss improved from 2.6340 to 2.6337. Saving model...\n",
      "\n",
      "LOG: Epoch [803/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0353\n",
      "Epoch [803/2000], Avg Train Loss: 4.0353\n",
      "Epoch [803/2000], Avg Val Loss: 2.6334\n",
      "Validation loss improved from 2.6337 to 2.6334. Saving model...\n",
      "\n",
      "LOG: Epoch [804/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9740\n",
      "Epoch [804/2000], Avg Train Loss: 3.9740\n",
      "Epoch [804/2000], Avg Val Loss: 2.6331\n",
      "Validation loss improved from 2.6334 to 2.6331. Saving model...\n",
      "\n",
      "LOG: Epoch [805/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0127\n",
      "Epoch [805/2000], Avg Train Loss: 4.0127\n",
      "Epoch [805/2000], Avg Val Loss: 2.6327\n",
      "Validation loss improved from 2.6331 to 2.6327. Saving model...\n",
      "\n",
      "LOG: Epoch [806/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9898\n",
      "Epoch [806/2000], Avg Train Loss: 3.9898\n",
      "Epoch [806/2000], Avg Val Loss: 2.6324\n",
      "Validation loss improved from 2.6327 to 2.6324. Saving model...\n",
      "\n",
      "LOG: Epoch [807/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0284\n",
      "Epoch [807/2000], Avg Train Loss: 4.0284\n",
      "Epoch [807/2000], Avg Val Loss: 2.6320\n",
      "Validation loss improved from 2.6324 to 2.6320. Saving model...\n",
      "\n",
      "LOG: Epoch [808/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0075\n",
      "Epoch [808/2000], Avg Train Loss: 4.0075\n",
      "Epoch [808/2000], Avg Val Loss: 2.6317\n",
      "Validation loss improved from 2.6320 to 2.6317. Saving model...\n",
      "\n",
      "LOG: Epoch [809/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9962\n",
      "Epoch [809/2000], Avg Train Loss: 3.9962\n",
      "Epoch [809/2000], Avg Val Loss: 2.6313\n",
      "Validation loss improved from 2.6317 to 2.6313. Saving model...\n",
      "\n",
      "LOG: Epoch [810/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0213\n",
      "Epoch [810/2000], Avg Train Loss: 4.0213\n",
      "Epoch [810/2000], Avg Val Loss: 2.6309\n",
      "Validation loss improved from 2.6313 to 2.6309. Saving model...\n",
      "\n",
      "LOG: Epoch [811/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0068\n",
      "Epoch [811/2000], Avg Train Loss: 4.0068\n",
      "Epoch [811/2000], Avg Val Loss: 2.6305\n",
      "Validation loss improved from 2.6309 to 2.6305. Saving model...\n",
      "\n",
      "LOG: Epoch [812/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0221\n",
      "Epoch [812/2000], Avg Train Loss: 4.0221\n",
      "Epoch [812/2000], Avg Val Loss: 2.6301\n",
      "Validation loss improved from 2.6305 to 2.6301. Saving model...\n",
      "\n",
      "LOG: Epoch [813/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0400\n",
      "Epoch [813/2000], Avg Train Loss: 4.0400\n",
      "Epoch [813/2000], Avg Val Loss: 2.6295\n",
      "Validation loss improved from 2.6301 to 2.6295. Saving model...\n",
      "\n",
      "LOG: Epoch [814/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0100\n",
      "Epoch [814/2000], Avg Train Loss: 4.0100\n",
      "Epoch [814/2000], Avg Val Loss: 2.6290\n",
      "Validation loss improved from 2.6295 to 2.6290. Saving model...\n",
      "\n",
      "LOG: Epoch [815/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0243\n",
      "Epoch [815/2000], Avg Train Loss: 4.0243\n",
      "Epoch [815/2000], Avg Val Loss: 2.6284\n",
      "Validation loss improved from 2.6290 to 2.6284. Saving model...\n",
      "\n",
      "LOG: Epoch [816/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0016\n",
      "Epoch [816/2000], Avg Train Loss: 4.0016\n",
      "Epoch [816/2000], Avg Val Loss: 2.6278\n",
      "Validation loss improved from 2.6284 to 2.6278. Saving model...\n",
      "\n",
      "LOG: Epoch [817/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0011\n",
      "Epoch [817/2000], Avg Train Loss: 4.0011\n",
      "Epoch [817/2000], Avg Val Loss: 2.6273\n",
      "Validation loss improved from 2.6278 to 2.6273. Saving model...\n",
      "\n",
      "LOG: Epoch [818/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0041\n",
      "Epoch [818/2000], Avg Train Loss: 4.0041\n",
      "Epoch [818/2000], Avg Val Loss: 2.6267\n",
      "Validation loss improved from 2.6273 to 2.6267. Saving model...\n",
      "\n",
      "LOG: Epoch [819/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9612\n",
      "Epoch [819/2000], Avg Train Loss: 3.9612\n",
      "Epoch [819/2000], Avg Val Loss: 2.6261\n",
      "Validation loss improved from 2.6267 to 2.6261. Saving model...\n",
      "\n",
      "LOG: Epoch [820/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0177\n",
      "Epoch [820/2000], Avg Train Loss: 4.0177\n",
      "Epoch [820/2000], Avg Val Loss: 2.6255\n",
      "Validation loss improved from 2.6261 to 2.6255. Saving model...\n",
      "\n",
      "LOG: Epoch [821/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9950\n",
      "Epoch [821/2000], Avg Train Loss: 3.9950\n",
      "Epoch [821/2000], Avg Val Loss: 2.6248\n",
      "Validation loss improved from 2.6255 to 2.6248. Saving model...\n",
      "\n",
      "LOG: Epoch [822/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0013\n",
      "Epoch [822/2000], Avg Train Loss: 4.0013\n",
      "Epoch [822/2000], Avg Val Loss: 2.6242\n",
      "Validation loss improved from 2.6248 to 2.6242. Saving model...\n",
      "\n",
      "LOG: Epoch [823/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0235\n",
      "Epoch [823/2000], Avg Train Loss: 4.0235\n",
      "Epoch [823/2000], Avg Val Loss: 2.6236\n",
      "Validation loss improved from 2.6242 to 2.6236. Saving model...\n",
      "\n",
      "LOG: Epoch [824/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9732\n",
      "Epoch [824/2000], Avg Train Loss: 3.9732\n",
      "Epoch [824/2000], Avg Val Loss: 2.6229\n",
      "Validation loss improved from 2.6236 to 2.6229. Saving model...\n",
      "\n",
      "LOG: Epoch [825/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0093\n",
      "Epoch [825/2000], Avg Train Loss: 4.0093\n",
      "Epoch [825/2000], Avg Val Loss: 2.6221\n",
      "Validation loss improved from 2.6229 to 2.6221. Saving model...\n",
      "\n",
      "LOG: Epoch [826/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0059\n",
      "Epoch [826/2000], Avg Train Loss: 4.0059\n",
      "Epoch [826/2000], Avg Val Loss: 2.6213\n",
      "Validation loss improved from 2.6221 to 2.6213. Saving model...\n",
      "\n",
      "LOG: Epoch [827/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9660\n",
      "Epoch [827/2000], Avg Train Loss: 3.9660\n",
      "Epoch [827/2000], Avg Val Loss: 2.6204\n",
      "Validation loss improved from 2.6213 to 2.6204. Saving model...\n",
      "\n",
      "LOG: Epoch [828/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0211\n",
      "Epoch [828/2000], Avg Train Loss: 4.0211\n",
      "Epoch [828/2000], Avg Val Loss: 2.6195\n",
      "Validation loss improved from 2.6204 to 2.6195. Saving model...\n",
      "\n",
      "LOG: Epoch [829/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9634\n",
      "Epoch [829/2000], Avg Train Loss: 3.9634\n",
      "Epoch [829/2000], Avg Val Loss: 2.6186\n",
      "Validation loss improved from 2.6195 to 2.6186. Saving model...\n",
      "\n",
      "LOG: Epoch [830/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0018\n",
      "Epoch [830/2000], Avg Train Loss: 4.0018\n",
      "Epoch [830/2000], Avg Val Loss: 2.6176\n",
      "Validation loss improved from 2.6186 to 2.6176. Saving model...\n",
      "\n",
      "LOG: Epoch [831/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0119\n",
      "Epoch [831/2000], Avg Train Loss: 4.0119\n",
      "Epoch [831/2000], Avg Val Loss: 2.6166\n",
      "Validation loss improved from 2.6176 to 2.6166. Saving model...\n",
      "\n",
      "LOG: Epoch [832/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9682\n",
      "Epoch [832/2000], Avg Train Loss: 3.9682\n",
      "Epoch [832/2000], Avg Val Loss: 2.6158\n",
      "Validation loss improved from 2.6166 to 2.6158. Saving model...\n",
      "\n",
      "LOG: Epoch [833/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0398\n",
      "Epoch [833/2000], Avg Train Loss: 4.0398\n",
      "Epoch [833/2000], Avg Val Loss: 2.6149\n",
      "Validation loss improved from 2.6158 to 2.6149. Saving model...\n",
      "\n",
      "LOG: Epoch [834/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0339\n",
      "Epoch [834/2000], Avg Train Loss: 4.0339\n",
      "Epoch [834/2000], Avg Val Loss: 2.6141\n",
      "Validation loss improved from 2.6149 to 2.6141. Saving model...\n",
      "\n",
      "LOG: Epoch [835/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0173\n",
      "Epoch [835/2000], Avg Train Loss: 4.0173\n",
      "Epoch [835/2000], Avg Val Loss: 2.6133\n",
      "Validation loss improved from 2.6141 to 2.6133. Saving model...\n",
      "\n",
      "LOG: Epoch [836/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9802\n",
      "Epoch [836/2000], Avg Train Loss: 3.9802\n",
      "Epoch [836/2000], Avg Val Loss: 2.6126\n",
      "Validation loss improved from 2.6133 to 2.6126. Saving model...\n",
      "\n",
      "LOG: Epoch [837/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9885\n",
      "Epoch [837/2000], Avg Train Loss: 3.9885\n",
      "Epoch [837/2000], Avg Val Loss: 2.6119\n",
      "Validation loss improved from 2.6126 to 2.6119. Saving model...\n",
      "\n",
      "LOG: Epoch [838/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9794\n",
      "Epoch [838/2000], Avg Train Loss: 3.9794\n",
      "Epoch [838/2000], Avg Val Loss: 2.6112\n",
      "Validation loss improved from 2.6119 to 2.6112. Saving model...\n",
      "\n",
      "LOG: Epoch [839/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9604\n",
      "Epoch [839/2000], Avg Train Loss: 3.9604\n",
      "Epoch [839/2000], Avg Val Loss: 2.6106\n",
      "Validation loss improved from 2.6112 to 2.6106. Saving model...\n",
      "\n",
      "LOG: Epoch [840/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0374\n",
      "Epoch [840/2000], Avg Train Loss: 4.0374\n",
      "Epoch [840/2000], Avg Val Loss: 2.6101\n",
      "Validation loss improved from 2.6106 to 2.6101. Saving model...\n",
      "\n",
      "LOG: Epoch [841/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0140\n",
      "Epoch [841/2000], Avg Train Loss: 4.0140\n",
      "Epoch [841/2000], Avg Val Loss: 2.6096\n",
      "Validation loss improved from 2.6101 to 2.6096. Saving model...\n",
      "\n",
      "LOG: Epoch [842/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9486\n",
      "Epoch [842/2000], Avg Train Loss: 3.9486\n",
      "Epoch [842/2000], Avg Val Loss: 2.6092\n",
      "Validation loss improved from 2.6096 to 2.6092. Saving model...\n",
      "\n",
      "LOG: Epoch [843/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9692\n",
      "Epoch [843/2000], Avg Train Loss: 3.9692\n",
      "Epoch [843/2000], Avg Val Loss: 2.6087\n",
      "Validation loss improved from 2.6092 to 2.6087. Saving model...\n",
      "\n",
      "LOG: Epoch [844/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9818\n",
      "Epoch [844/2000], Avg Train Loss: 3.9818\n",
      "Epoch [844/2000], Avg Val Loss: 2.6082\n",
      "Validation loss improved from 2.6087 to 2.6082. Saving model...\n",
      "\n",
      "LOG: Epoch [845/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9999\n",
      "Epoch [845/2000], Avg Train Loss: 3.9999\n",
      "Epoch [845/2000], Avg Val Loss: 2.6077\n",
      "Validation loss improved from 2.6082 to 2.6077. Saving model...\n",
      "\n",
      "LOG: Epoch [846/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9921\n",
      "Epoch [846/2000], Avg Train Loss: 3.9921\n",
      "Epoch [846/2000], Avg Val Loss: 2.6072\n",
      "Validation loss improved from 2.6077 to 2.6072. Saving model...\n",
      "\n",
      "LOG: Epoch [847/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0376\n",
      "Epoch [847/2000], Avg Train Loss: 4.0376\n",
      "Epoch [847/2000], Avg Val Loss: 2.6067\n",
      "Validation loss improved from 2.6072 to 2.6067. Saving model...\n",
      "\n",
      "LOG: Epoch [848/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9548\n",
      "Epoch [848/2000], Avg Train Loss: 3.9548\n",
      "Epoch [848/2000], Avg Val Loss: 2.6063\n",
      "Validation loss improved from 2.6067 to 2.6063. Saving model...\n",
      "\n",
      "LOG: Epoch [849/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9819\n",
      "Epoch [849/2000], Avg Train Loss: 3.9819\n",
      "Epoch [849/2000], Avg Val Loss: 2.6059\n",
      "Validation loss improved from 2.6063 to 2.6059. Saving model...\n",
      "\n",
      "LOG: Epoch [850/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9749\n",
      "Epoch [850/2000], Avg Train Loss: 3.9749\n",
      "Epoch [850/2000], Avg Val Loss: 2.6054\n",
      "Validation loss improved from 2.6059 to 2.6054. Saving model...\n",
      "\n",
      "LOG: Epoch [851/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9638\n",
      "Epoch [851/2000], Avg Train Loss: 3.9638\n",
      "Epoch [851/2000], Avg Val Loss: 2.6048\n",
      "Validation loss improved from 2.6054 to 2.6048. Saving model...\n",
      "\n",
      "LOG: Epoch [852/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9799\n",
      "Epoch [852/2000], Avg Train Loss: 3.9799\n",
      "Epoch [852/2000], Avg Val Loss: 2.6043\n",
      "Validation loss improved from 2.6048 to 2.6043. Saving model...\n",
      "\n",
      "LOG: Epoch [853/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9989\n",
      "Epoch [853/2000], Avg Train Loss: 3.9989\n",
      "Epoch [853/2000], Avg Val Loss: 2.6038\n",
      "Validation loss improved from 2.6043 to 2.6038. Saving model...\n",
      "\n",
      "LOG: Epoch [854/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0101\n",
      "Epoch [854/2000], Avg Train Loss: 4.0101\n",
      "Epoch [854/2000], Avg Val Loss: 2.6034\n",
      "Validation loss improved from 2.6038 to 2.6034. Saving model...\n",
      "\n",
      "LOG: Epoch [855/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9733\n",
      "Epoch [855/2000], Avg Train Loss: 3.9733\n",
      "Epoch [855/2000], Avg Val Loss: 2.6030\n",
      "Validation loss improved from 2.6034 to 2.6030. Saving model...\n",
      "\n",
      "LOG: Epoch [856/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9820\n",
      "Epoch [856/2000], Avg Train Loss: 3.9820\n",
      "Epoch [856/2000], Avg Val Loss: 2.6026\n",
      "Validation loss improved from 2.6030 to 2.6026. Saving model...\n",
      "\n",
      "LOG: Epoch [857/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9783\n",
      "Epoch [857/2000], Avg Train Loss: 3.9783\n",
      "Epoch [857/2000], Avg Val Loss: 2.6022\n",
      "Validation loss improved from 2.6026 to 2.6022. Saving model...\n",
      "\n",
      "LOG: Epoch [858/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9932\n",
      "Epoch [858/2000], Avg Train Loss: 3.9932\n",
      "Epoch [858/2000], Avg Val Loss: 2.6018\n",
      "Validation loss improved from 2.6022 to 2.6018. Saving model...\n",
      "\n",
      "LOG: Epoch [859/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9813\n",
      "Epoch [859/2000], Avg Train Loss: 3.9813\n",
      "Epoch [859/2000], Avg Val Loss: 2.6014\n",
      "Validation loss improved from 2.6018 to 2.6014. Saving model...\n",
      "\n",
      "LOG: Epoch [860/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9400\n",
      "Epoch [860/2000], Avg Train Loss: 3.9400\n",
      "Epoch [860/2000], Avg Val Loss: 2.6010\n",
      "Validation loss improved from 2.6014 to 2.6010. Saving model...\n",
      "\n",
      "LOG: Epoch [861/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0134\n",
      "Epoch [861/2000], Avg Train Loss: 4.0134\n",
      "Epoch [861/2000], Avg Val Loss: 2.6005\n",
      "Validation loss improved from 2.6010 to 2.6005. Saving model...\n",
      "\n",
      "LOG: Epoch [862/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9944\n",
      "Epoch [862/2000], Avg Train Loss: 3.9944\n",
      "Epoch [862/2000], Avg Val Loss: 2.6002\n",
      "Validation loss improved from 2.6005 to 2.6002. Saving model...\n",
      "\n",
      "LOG: Epoch [863/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9732\n",
      "Epoch [863/2000], Avg Train Loss: 3.9732\n",
      "Epoch [863/2000], Avg Val Loss: 2.6000\n",
      "Validation loss improved from 2.6002 to 2.6000. Saving model...\n",
      "\n",
      "LOG: Epoch [864/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9649\n",
      "Epoch [864/2000], Avg Train Loss: 3.9649\n",
      "Epoch [864/2000], Avg Val Loss: 2.5999\n",
      "Validation loss improved from 2.6000 to 2.5999. Saving model...\n",
      "\n",
      "LOG: Epoch [865/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9558\n",
      "Epoch [865/2000], Avg Train Loss: 3.9558\n",
      "Epoch [865/2000], Avg Val Loss: 2.5995\n",
      "Validation loss improved from 2.5999 to 2.5995. Saving model...\n",
      "\n",
      "LOG: Epoch [866/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9441\n",
      "Epoch [866/2000], Avg Train Loss: 3.9441\n",
      "Epoch [866/2000], Avg Val Loss: 2.5993\n",
      "Validation loss improved from 2.5995 to 2.5993. Saving model...\n",
      "\n",
      "LOG: Epoch [867/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9881\n",
      "Epoch [867/2000], Avg Train Loss: 3.9881\n",
      "Epoch [867/2000], Avg Val Loss: 2.5989\n",
      "Validation loss improved from 2.5993 to 2.5989. Saving model...\n",
      "\n",
      "LOG: Epoch [868/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9682\n",
      "Epoch [868/2000], Avg Train Loss: 3.9682\n",
      "Epoch [868/2000], Avg Val Loss: 2.5984\n",
      "Validation loss improved from 2.5989 to 2.5984. Saving model...\n",
      "\n",
      "LOG: Epoch [869/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9420\n",
      "Epoch [869/2000], Avg Train Loss: 3.9420\n",
      "Epoch [869/2000], Avg Val Loss: 2.5979\n",
      "Validation loss improved from 2.5984 to 2.5979. Saving model...\n",
      "\n",
      "LOG: Epoch [870/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9421\n",
      "Epoch [870/2000], Avg Train Loss: 3.9421\n",
      "Epoch [870/2000], Avg Val Loss: 2.5974\n",
      "Validation loss improved from 2.5979 to 2.5974. Saving model...\n",
      "\n",
      "LOG: Epoch [871/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9900\n",
      "Epoch [871/2000], Avg Train Loss: 3.9900\n",
      "Epoch [871/2000], Avg Val Loss: 2.5968\n",
      "Validation loss improved from 2.5974 to 2.5968. Saving model...\n",
      "\n",
      "LOG: Epoch [872/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9531\n",
      "Epoch [872/2000], Avg Train Loss: 3.9531\n",
      "Epoch [872/2000], Avg Val Loss: 2.5963\n",
      "Validation loss improved from 2.5968 to 2.5963. Saving model...\n",
      "\n",
      "LOG: Epoch [873/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9462\n",
      "Epoch [873/2000], Avg Train Loss: 3.9462\n",
      "Epoch [873/2000], Avg Val Loss: 2.5958\n",
      "Validation loss improved from 2.5963 to 2.5958. Saving model...\n",
      "\n",
      "LOG: Epoch [874/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9757\n",
      "Epoch [874/2000], Avg Train Loss: 3.9757\n",
      "Epoch [874/2000], Avg Val Loss: 2.5952\n",
      "Validation loss improved from 2.5958 to 2.5952. Saving model...\n",
      "\n",
      "LOG: Epoch [875/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9798\n",
      "Epoch [875/2000], Avg Train Loss: 3.9798\n",
      "Epoch [875/2000], Avg Val Loss: 2.5946\n",
      "Validation loss improved from 2.5952 to 2.5946. Saving model...\n",
      "\n",
      "LOG: Epoch [876/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9585\n",
      "Epoch [876/2000], Avg Train Loss: 3.9585\n",
      "Epoch [876/2000], Avg Val Loss: 2.5940\n",
      "Validation loss improved from 2.5946 to 2.5940. Saving model...\n",
      "\n",
      "LOG: Epoch [877/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9524\n",
      "Epoch [877/2000], Avg Train Loss: 3.9524\n",
      "Epoch [877/2000], Avg Val Loss: 2.5933\n",
      "Validation loss improved from 2.5940 to 2.5933. Saving model...\n",
      "\n",
      "LOG: Epoch [878/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9579\n",
      "Epoch [878/2000], Avg Train Loss: 3.9579\n",
      "Epoch [878/2000], Avg Val Loss: 2.5928\n",
      "Validation loss improved from 2.5933 to 2.5928. Saving model...\n",
      "\n",
      "LOG: Epoch [879/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9511\n",
      "Epoch [879/2000], Avg Train Loss: 3.9511\n",
      "Epoch [879/2000], Avg Val Loss: 2.5923\n",
      "Validation loss improved from 2.5928 to 2.5923. Saving model...\n",
      "\n",
      "LOG: Epoch [880/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9692\n",
      "Epoch [880/2000], Avg Train Loss: 3.9692\n",
      "Epoch [880/2000], Avg Val Loss: 2.5918\n",
      "Validation loss improved from 2.5923 to 2.5918. Saving model...\n",
      "\n",
      "LOG: Epoch [881/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9737\n",
      "Epoch [881/2000], Avg Train Loss: 3.9737\n",
      "Epoch [881/2000], Avg Val Loss: 2.5912\n",
      "Validation loss improved from 2.5918 to 2.5912. Saving model...\n",
      "\n",
      "LOG: Epoch [882/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9002\n",
      "Epoch [882/2000], Avg Train Loss: 3.9002\n",
      "Epoch [882/2000], Avg Val Loss: 2.5907\n",
      "Validation loss improved from 2.5912 to 2.5907. Saving model...\n",
      "\n",
      "LOG: Epoch [883/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9780\n",
      "Epoch [883/2000], Avg Train Loss: 3.9780\n",
      "Epoch [883/2000], Avg Val Loss: 2.5901\n",
      "Validation loss improved from 2.5907 to 2.5901. Saving model...\n",
      "\n",
      "LOG: Epoch [884/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9666\n",
      "Epoch [884/2000], Avg Train Loss: 3.9666\n",
      "Epoch [884/2000], Avg Val Loss: 2.5895\n",
      "Validation loss improved from 2.5901 to 2.5895. Saving model...\n",
      "\n",
      "LOG: Epoch [885/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9429\n",
      "Epoch [885/2000], Avg Train Loss: 3.9429\n",
      "Epoch [885/2000], Avg Val Loss: 2.5888\n",
      "Validation loss improved from 2.5895 to 2.5888. Saving model...\n",
      "\n",
      "LOG: Epoch [886/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9538\n",
      "Epoch [886/2000], Avg Train Loss: 3.9538\n",
      "Epoch [886/2000], Avg Val Loss: 2.5882\n",
      "Validation loss improved from 2.5888 to 2.5882. Saving model...\n",
      "\n",
      "LOG: Epoch [887/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9292\n",
      "Epoch [887/2000], Avg Train Loss: 3.9292\n",
      "Epoch [887/2000], Avg Val Loss: 2.5875\n",
      "Validation loss improved from 2.5882 to 2.5875. Saving model...\n",
      "\n",
      "LOG: Epoch [888/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9548\n",
      "Epoch [888/2000], Avg Train Loss: 3.9548\n",
      "Epoch [888/2000], Avg Val Loss: 2.5870\n",
      "Validation loss improved from 2.5875 to 2.5870. Saving model...\n",
      "\n",
      "LOG: Epoch [889/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9365\n",
      "Epoch [889/2000], Avg Train Loss: 3.9365\n",
      "Epoch [889/2000], Avg Val Loss: 2.5866\n",
      "Validation loss improved from 2.5870 to 2.5866. Saving model...\n",
      "\n",
      "LOG: Epoch [890/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9352\n",
      "Epoch [890/2000], Avg Train Loss: 3.9352\n",
      "Epoch [890/2000], Avg Val Loss: 2.5863\n",
      "Validation loss improved from 2.5866 to 2.5863. Saving model...\n",
      "\n",
      "LOG: Epoch [891/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9257\n",
      "Epoch [891/2000], Avg Train Loss: 3.9257\n",
      "Epoch [891/2000], Avg Val Loss: 2.5860\n",
      "Validation loss improved from 2.5863 to 2.5860. Saving model...\n",
      "\n",
      "LOG: Epoch [892/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9098\n",
      "Epoch [892/2000], Avg Train Loss: 3.9098\n",
      "Epoch [892/2000], Avg Val Loss: 2.5858\n",
      "Validation loss improved from 2.5860 to 2.5858. Saving model...\n",
      "\n",
      "LOG: Epoch [893/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8969\n",
      "Epoch [893/2000], Avg Train Loss: 3.8969\n",
      "Epoch [893/2000], Avg Val Loss: 2.5856\n",
      "Validation loss improved from 2.5858 to 2.5856. Saving model...\n",
      "\n",
      "LOG: Epoch [894/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9453\n",
      "Epoch [894/2000], Avg Train Loss: 3.9453\n",
      "Epoch [894/2000], Avg Val Loss: 2.5854\n",
      "Validation loss improved from 2.5856 to 2.5854. Saving model...\n",
      "\n",
      "LOG: Epoch [895/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8883\n",
      "Epoch [895/2000], Avg Train Loss: 3.8883\n",
      "Epoch [895/2000], Avg Val Loss: 2.5852\n",
      "Validation loss improved from 2.5854 to 2.5852. Saving model...\n",
      "\n",
      "LOG: Epoch [896/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9422\n",
      "Epoch [896/2000], Avg Train Loss: 3.9422\n",
      "Epoch [896/2000], Avg Val Loss: 2.5850\n",
      "Validation loss improved from 2.5852 to 2.5850. Saving model...\n",
      "\n",
      "LOG: Epoch [897/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9300\n",
      "Epoch [897/2000], Avg Train Loss: 3.9300\n",
      "Epoch [897/2000], Avg Val Loss: 2.5849\n",
      "Validation loss improved from 2.5850 to 2.5849. Saving model...\n",
      "\n",
      "LOG: Epoch [898/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9397\n",
      "Epoch [898/2000], Avg Train Loss: 3.9397\n",
      "Epoch [898/2000], Avg Val Loss: 2.5848\n",
      "Validation loss improved from 2.5849 to 2.5848. Saving model...\n",
      "\n",
      "LOG: Epoch [899/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9515\n",
      "Epoch [899/2000], Avg Train Loss: 3.9515\n",
      "Epoch [899/2000], Avg Val Loss: 2.5849\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [900/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9851\n",
      "Epoch [900/2000], Avg Train Loss: 3.9851\n",
      "Epoch [900/2000], Avg Val Loss: 2.5850\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [901/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9268\n",
      "Epoch [901/2000], Avg Train Loss: 3.9268\n",
      "Epoch [901/2000], Avg Val Loss: 2.5851\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [902/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8943\n",
      "Epoch [902/2000], Avg Train Loss: 3.8943\n",
      "Epoch [902/2000], Avg Val Loss: 2.5850\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [903/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9275\n",
      "Epoch [903/2000], Avg Train Loss: 3.9275\n",
      "Epoch [903/2000], Avg Val Loss: 2.5850\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [904/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9211\n",
      "Epoch [904/2000], Avg Train Loss: 3.9211\n",
      "Epoch [904/2000], Avg Val Loss: 2.5850\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [905/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9365\n",
      "Epoch [905/2000], Avg Train Loss: 3.9365\n",
      "Epoch [905/2000], Avg Val Loss: 2.5848\n",
      "Validation loss improved from 2.5848 to 2.5848. Saving model...\n",
      "\n",
      "LOG: Epoch [906/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9173\n",
      "Epoch [906/2000], Avg Train Loss: 3.9173\n",
      "Epoch [906/2000], Avg Val Loss: 2.5845\n",
      "Validation loss improved from 2.5848 to 2.5845. Saving model...\n",
      "\n",
      "LOG: Epoch [907/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9716\n",
      "Epoch [907/2000], Avg Train Loss: 3.9716\n",
      "Epoch [907/2000], Avg Val Loss: 2.5842\n",
      "Validation loss improved from 2.5845 to 2.5842. Saving model...\n",
      "\n",
      "LOG: Epoch [908/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9306\n",
      "Epoch [908/2000], Avg Train Loss: 3.9306\n",
      "Epoch [908/2000], Avg Val Loss: 2.5838\n",
      "Validation loss improved from 2.5842 to 2.5838. Saving model...\n",
      "\n",
      "LOG: Epoch [909/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9134\n",
      "Epoch [909/2000], Avg Train Loss: 3.9134\n",
      "Epoch [909/2000], Avg Val Loss: 2.5834\n",
      "Validation loss improved from 2.5838 to 2.5834. Saving model...\n",
      "\n",
      "LOG: Epoch [910/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9368\n",
      "Epoch [910/2000], Avg Train Loss: 3.9368\n",
      "Epoch [910/2000], Avg Val Loss: 2.5831\n",
      "Validation loss improved from 2.5834 to 2.5831. Saving model...\n",
      "\n",
      "LOG: Epoch [911/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9651\n",
      "Epoch [911/2000], Avg Train Loss: 3.9651\n",
      "Epoch [911/2000], Avg Val Loss: 2.5827\n",
      "Validation loss improved from 2.5831 to 2.5827. Saving model...\n",
      "\n",
      "LOG: Epoch [912/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9169\n",
      "Epoch [912/2000], Avg Train Loss: 3.9169\n",
      "Epoch [912/2000], Avg Val Loss: 2.5823\n",
      "Validation loss improved from 2.5827 to 2.5823. Saving model...\n",
      "\n",
      "LOG: Epoch [913/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9002\n",
      "Epoch [913/2000], Avg Train Loss: 3.9002\n",
      "Epoch [913/2000], Avg Val Loss: 2.5821\n",
      "Validation loss improved from 2.5823 to 2.5821. Saving model...\n",
      "\n",
      "LOG: Epoch [914/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9068\n",
      "Epoch [914/2000], Avg Train Loss: 3.9068\n",
      "Epoch [914/2000], Avg Val Loss: 2.5817\n",
      "Validation loss improved from 2.5821 to 2.5817. Saving model...\n",
      "\n",
      "LOG: Epoch [915/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9392\n",
      "Epoch [915/2000], Avg Train Loss: 3.9392\n",
      "Epoch [915/2000], Avg Val Loss: 2.5812\n",
      "Validation loss improved from 2.5817 to 2.5812. Saving model...\n",
      "\n",
      "LOG: Epoch [916/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8905\n",
      "Epoch [916/2000], Avg Train Loss: 3.8905\n",
      "Epoch [916/2000], Avg Val Loss: 2.5808\n",
      "Validation loss improved from 2.5812 to 2.5808. Saving model...\n",
      "\n",
      "LOG: Epoch [917/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8926\n",
      "Epoch [917/2000], Avg Train Loss: 3.8926\n",
      "Epoch [917/2000], Avg Val Loss: 2.5802\n",
      "Validation loss improved from 2.5808 to 2.5802. Saving model...\n",
      "\n",
      "LOG: Epoch [918/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8727\n",
      "Epoch [918/2000], Avg Train Loss: 3.8727\n",
      "Epoch [918/2000], Avg Val Loss: 2.5797\n",
      "Validation loss improved from 2.5802 to 2.5797. Saving model...\n",
      "\n",
      "LOG: Epoch [919/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9161\n",
      "Epoch [919/2000], Avg Train Loss: 3.9161\n",
      "Epoch [919/2000], Avg Val Loss: 2.5791\n",
      "Validation loss improved from 2.5797 to 2.5791. Saving model...\n",
      "\n",
      "LOG: Epoch [920/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9363\n",
      "Epoch [920/2000], Avg Train Loss: 3.9363\n",
      "Epoch [920/2000], Avg Val Loss: 2.5785\n",
      "Validation loss improved from 2.5791 to 2.5785. Saving model...\n",
      "\n",
      "LOG: Epoch [921/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9643\n",
      "Epoch [921/2000], Avg Train Loss: 3.9643\n",
      "Epoch [921/2000], Avg Val Loss: 2.5780\n",
      "Validation loss improved from 2.5785 to 2.5780. Saving model...\n",
      "\n",
      "LOG: Epoch [922/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9135\n",
      "Epoch [922/2000], Avg Train Loss: 3.9135\n",
      "Epoch [922/2000], Avg Val Loss: 2.5775\n",
      "Validation loss improved from 2.5780 to 2.5775. Saving model...\n",
      "\n",
      "LOG: Epoch [923/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9626\n",
      "Epoch [923/2000], Avg Train Loss: 3.9626\n",
      "Epoch [923/2000], Avg Val Loss: 2.5771\n",
      "Validation loss improved from 2.5775 to 2.5771. Saving model...\n",
      "\n",
      "LOG: Epoch [924/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8866\n",
      "Epoch [924/2000], Avg Train Loss: 3.8866\n",
      "Epoch [924/2000], Avg Val Loss: 2.5767\n",
      "Validation loss improved from 2.5771 to 2.5767. Saving model...\n",
      "\n",
      "LOG: Epoch [925/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9023\n",
      "Epoch [925/2000], Avg Train Loss: 3.9023\n",
      "Epoch [925/2000], Avg Val Loss: 2.5762\n",
      "Validation loss improved from 2.5767 to 2.5762. Saving model...\n",
      "\n",
      "LOG: Epoch [926/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9250\n",
      "Epoch [926/2000], Avg Train Loss: 3.9250\n",
      "Epoch [926/2000], Avg Val Loss: 2.5757\n",
      "Validation loss improved from 2.5762 to 2.5757. Saving model...\n",
      "\n",
      "LOG: Epoch [927/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9106\n",
      "Epoch [927/2000], Avg Train Loss: 3.9106\n",
      "Epoch [927/2000], Avg Val Loss: 2.5752\n",
      "Validation loss improved from 2.5757 to 2.5752. Saving model...\n",
      "\n",
      "LOG: Epoch [928/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9578\n",
      "Epoch [928/2000], Avg Train Loss: 3.9578\n",
      "Epoch [928/2000], Avg Val Loss: 2.5747\n",
      "Validation loss improved from 2.5752 to 2.5747. Saving model...\n",
      "\n",
      "LOG: Epoch [929/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9163\n",
      "Epoch [929/2000], Avg Train Loss: 3.9163\n",
      "Epoch [929/2000], Avg Val Loss: 2.5741\n",
      "Validation loss improved from 2.5747 to 2.5741. Saving model...\n",
      "\n",
      "LOG: Epoch [930/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9386\n",
      "Epoch [930/2000], Avg Train Loss: 3.9386\n",
      "Epoch [930/2000], Avg Val Loss: 2.5736\n",
      "Validation loss improved from 2.5741 to 2.5736. Saving model...\n",
      "\n",
      "LOG: Epoch [931/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9138\n",
      "Epoch [931/2000], Avg Train Loss: 3.9138\n",
      "Epoch [931/2000], Avg Val Loss: 2.5729\n",
      "Validation loss improved from 2.5736 to 2.5729. Saving model...\n",
      "\n",
      "LOG: Epoch [932/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8793\n",
      "Epoch [932/2000], Avg Train Loss: 3.8793\n",
      "Epoch [932/2000], Avg Val Loss: 2.5723\n",
      "Validation loss improved from 2.5729 to 2.5723. Saving model...\n",
      "\n",
      "LOG: Epoch [933/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8938\n",
      "Epoch [933/2000], Avg Train Loss: 3.8938\n",
      "Epoch [933/2000], Avg Val Loss: 2.5719\n",
      "Validation loss improved from 2.5723 to 2.5719. Saving model...\n",
      "\n",
      "LOG: Epoch [934/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8971\n",
      "Epoch [934/2000], Avg Train Loss: 3.8971\n",
      "Epoch [934/2000], Avg Val Loss: 2.5714\n",
      "Validation loss improved from 2.5719 to 2.5714. Saving model...\n",
      "\n",
      "LOG: Epoch [935/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8762\n",
      "Epoch [935/2000], Avg Train Loss: 3.8762\n",
      "Epoch [935/2000], Avg Val Loss: 2.5710\n",
      "Validation loss improved from 2.5714 to 2.5710. Saving model...\n",
      "\n",
      "LOG: Epoch [936/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9301\n",
      "Epoch [936/2000], Avg Train Loss: 3.9301\n",
      "Epoch [936/2000], Avg Val Loss: 2.5707\n",
      "Validation loss improved from 2.5710 to 2.5707. Saving model...\n",
      "\n",
      "LOG: Epoch [937/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9358\n",
      "Epoch [937/2000], Avg Train Loss: 3.9358\n",
      "Epoch [937/2000], Avg Val Loss: 2.5703\n",
      "Validation loss improved from 2.5707 to 2.5703. Saving model...\n",
      "\n",
      "LOG: Epoch [938/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8999\n",
      "Epoch [938/2000], Avg Train Loss: 3.8999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [938/2000], Avg Val Loss: 2.5700\n",
      "Validation loss improved from 2.5703 to 2.5700. Saving model...\n",
      "\n",
      "LOG: Epoch [939/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9477\n",
      "Epoch [939/2000], Avg Train Loss: 3.9477\n",
      "Epoch [939/2000], Avg Val Loss: 2.5695\n",
      "Validation loss improved from 2.5700 to 2.5695. Saving model...\n",
      "\n",
      "LOG: Epoch [940/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8624\n",
      "Epoch [940/2000], Avg Train Loss: 3.8624\n",
      "Epoch [940/2000], Avg Val Loss: 2.5688\n",
      "Validation loss improved from 2.5695 to 2.5688. Saving model...\n",
      "\n",
      "LOG: Epoch [941/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9560\n",
      "Epoch [941/2000], Avg Train Loss: 3.9560\n",
      "Epoch [941/2000], Avg Val Loss: 2.5683\n",
      "Validation loss improved from 2.5688 to 2.5683. Saving model...\n",
      "\n",
      "LOG: Epoch [942/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8876\n",
      "Epoch [942/2000], Avg Train Loss: 3.8876\n",
      "Epoch [942/2000], Avg Val Loss: 2.5676\n",
      "Validation loss improved from 2.5683 to 2.5676. Saving model...\n",
      "\n",
      "LOG: Epoch [943/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8758\n",
      "Epoch [943/2000], Avg Train Loss: 3.8758\n",
      "Epoch [943/2000], Avg Val Loss: 2.5671\n",
      "Validation loss improved from 2.5676 to 2.5671. Saving model...\n",
      "\n",
      "LOG: Epoch [944/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8926\n",
      "Epoch [944/2000], Avg Train Loss: 3.8926\n",
      "Epoch [944/2000], Avg Val Loss: 2.5667\n",
      "Validation loss improved from 2.5671 to 2.5667. Saving model...\n",
      "\n",
      "LOG: Epoch [945/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9300\n",
      "Epoch [945/2000], Avg Train Loss: 3.9300\n",
      "Epoch [945/2000], Avg Val Loss: 2.5663\n",
      "Validation loss improved from 2.5667 to 2.5663. Saving model...\n",
      "\n",
      "LOG: Epoch [946/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8980\n",
      "Epoch [946/2000], Avg Train Loss: 3.8980\n",
      "Epoch [946/2000], Avg Val Loss: 2.5658\n",
      "Validation loss improved from 2.5663 to 2.5658. Saving model...\n",
      "\n",
      "LOG: Epoch [947/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9059\n",
      "Epoch [947/2000], Avg Train Loss: 3.9059\n",
      "Epoch [947/2000], Avg Val Loss: 2.5653\n",
      "Validation loss improved from 2.5658 to 2.5653. Saving model...\n",
      "\n",
      "LOG: Epoch [948/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8942\n",
      "Epoch [948/2000], Avg Train Loss: 3.8942\n",
      "Epoch [948/2000], Avg Val Loss: 2.5649\n",
      "Validation loss improved from 2.5653 to 2.5649. Saving model...\n",
      "\n",
      "LOG: Epoch [949/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9313\n",
      "Epoch [949/2000], Avg Train Loss: 3.9313\n",
      "Epoch [949/2000], Avg Val Loss: 2.5646\n",
      "Validation loss improved from 2.5649 to 2.5646. Saving model...\n",
      "\n",
      "LOG: Epoch [950/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8718\n",
      "Epoch [950/2000], Avg Train Loss: 3.8718\n",
      "Epoch [950/2000], Avg Val Loss: 2.5644\n",
      "Validation loss improved from 2.5646 to 2.5644. Saving model...\n",
      "\n",
      "LOG: Epoch [951/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9215\n",
      "Epoch [951/2000], Avg Train Loss: 3.9215\n",
      "Epoch [951/2000], Avg Val Loss: 2.5641\n",
      "Validation loss improved from 2.5644 to 2.5641. Saving model...\n",
      "\n",
      "LOG: Epoch [952/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9200\n",
      "Epoch [952/2000], Avg Train Loss: 3.9200\n",
      "Epoch [952/2000], Avg Val Loss: 2.5638\n",
      "Validation loss improved from 2.5641 to 2.5638. Saving model...\n",
      "\n",
      "LOG: Epoch [953/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8525\n",
      "Epoch [953/2000], Avg Train Loss: 3.8525\n",
      "Epoch [953/2000], Avg Val Loss: 2.5635\n",
      "Validation loss improved from 2.5638 to 2.5635. Saving model...\n",
      "\n",
      "LOG: Epoch [954/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8979\n",
      "Epoch [954/2000], Avg Train Loss: 3.8979\n",
      "Epoch [954/2000], Avg Val Loss: 2.5632\n",
      "Validation loss improved from 2.5635 to 2.5632. Saving model...\n",
      "\n",
      "LOG: Epoch [955/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9204\n",
      "Epoch [955/2000], Avg Train Loss: 3.9204\n",
      "Epoch [955/2000], Avg Val Loss: 2.5628\n",
      "Validation loss improved from 2.5632 to 2.5628. Saving model...\n",
      "\n",
      "LOG: Epoch [956/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9062\n",
      "Epoch [956/2000], Avg Train Loss: 3.9062\n",
      "Epoch [956/2000], Avg Val Loss: 2.5623\n",
      "Validation loss improved from 2.5628 to 2.5623. Saving model...\n",
      "\n",
      "LOG: Epoch [957/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8717\n",
      "Epoch [957/2000], Avg Train Loss: 3.8717\n",
      "Epoch [957/2000], Avg Val Loss: 2.5618\n",
      "Validation loss improved from 2.5623 to 2.5618. Saving model...\n",
      "\n",
      "LOG: Epoch [958/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8591\n",
      "Epoch [958/2000], Avg Train Loss: 3.8591\n",
      "Epoch [958/2000], Avg Val Loss: 2.5612\n",
      "Validation loss improved from 2.5618 to 2.5612. Saving model...\n",
      "\n",
      "LOG: Epoch [959/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8796\n",
      "Epoch [959/2000], Avg Train Loss: 3.8796\n",
      "Epoch [959/2000], Avg Val Loss: 2.5606\n",
      "Validation loss improved from 2.5612 to 2.5606. Saving model...\n",
      "\n",
      "LOG: Epoch [960/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8845\n",
      "Epoch [960/2000], Avg Train Loss: 3.8845\n",
      "Epoch [960/2000], Avg Val Loss: 2.5600\n",
      "Validation loss improved from 2.5606 to 2.5600. Saving model...\n",
      "\n",
      "LOG: Epoch [961/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9058\n",
      "Epoch [961/2000], Avg Train Loss: 3.9058\n",
      "Epoch [961/2000], Avg Val Loss: 2.5595\n",
      "Validation loss improved from 2.5600 to 2.5595. Saving model...\n",
      "\n",
      "LOG: Epoch [962/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9124\n",
      "Epoch [962/2000], Avg Train Loss: 3.9124\n",
      "Epoch [962/2000], Avg Val Loss: 2.5588\n",
      "Validation loss improved from 2.5595 to 2.5588. Saving model...\n",
      "\n",
      "LOG: Epoch [963/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8758\n",
      "Epoch [963/2000], Avg Train Loss: 3.8758\n",
      "Epoch [963/2000], Avg Val Loss: 2.5582\n",
      "Validation loss improved from 2.5588 to 2.5582. Saving model...\n",
      "\n",
      "LOG: Epoch [964/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9092\n",
      "Epoch [964/2000], Avg Train Loss: 3.9092\n",
      "Epoch [964/2000], Avg Val Loss: 2.5577\n",
      "Validation loss improved from 2.5582 to 2.5577. Saving model...\n",
      "\n",
      "LOG: Epoch [965/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8828\n",
      "Epoch [965/2000], Avg Train Loss: 3.8828\n",
      "Epoch [965/2000], Avg Val Loss: 2.5570\n",
      "Validation loss improved from 2.5577 to 2.5570. Saving model...\n",
      "\n",
      "LOG: Epoch [966/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8773\n",
      "Epoch [966/2000], Avg Train Loss: 3.8773\n",
      "Epoch [966/2000], Avg Val Loss: 2.5563\n",
      "Validation loss improved from 2.5570 to 2.5563. Saving model...\n",
      "\n",
      "LOG: Epoch [967/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8728\n",
      "Epoch [967/2000], Avg Train Loss: 3.8728\n",
      "Epoch [967/2000], Avg Val Loss: 2.5554\n",
      "Validation loss improved from 2.5563 to 2.5554. Saving model...\n",
      "\n",
      "LOG: Epoch [968/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8486\n",
      "Epoch [968/2000], Avg Train Loss: 3.8486\n",
      "Epoch [968/2000], Avg Val Loss: 2.5548\n",
      "Validation loss improved from 2.5554 to 2.5548. Saving model...\n",
      "\n",
      "LOG: Epoch [969/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8757\n",
      "Epoch [969/2000], Avg Train Loss: 3.8757\n",
      "Epoch [969/2000], Avg Val Loss: 2.5542\n",
      "Validation loss improved from 2.5548 to 2.5542. Saving model...\n",
      "\n",
      "LOG: Epoch [970/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8822\n",
      "Epoch [970/2000], Avg Train Loss: 3.8822\n",
      "Epoch [970/2000], Avg Val Loss: 2.5536\n",
      "Validation loss improved from 2.5542 to 2.5536. Saving model...\n",
      "\n",
      "LOG: Epoch [971/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8939\n",
      "Epoch [971/2000], Avg Train Loss: 3.8939\n",
      "Epoch [971/2000], Avg Val Loss: 2.5530\n",
      "Validation loss improved from 2.5536 to 2.5530. Saving model...\n",
      "\n",
      "LOG: Epoch [972/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8818\n",
      "Epoch [972/2000], Avg Train Loss: 3.8818\n",
      "Epoch [972/2000], Avg Val Loss: 2.5525\n",
      "Validation loss improved from 2.5530 to 2.5525. Saving model...\n",
      "\n",
      "LOG: Epoch [973/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8872\n",
      "Epoch [973/2000], Avg Train Loss: 3.8872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [973/2000], Avg Val Loss: 2.5519\n",
      "Validation loss improved from 2.5525 to 2.5519. Saving model...\n",
      "\n",
      "LOG: Epoch [974/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8702\n",
      "Epoch [974/2000], Avg Train Loss: 3.8702\n",
      "Epoch [974/2000], Avg Val Loss: 2.5513\n",
      "Validation loss improved from 2.5519 to 2.5513. Saving model...\n",
      "\n",
      "LOG: Epoch [975/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8805\n",
      "Epoch [975/2000], Avg Train Loss: 3.8805\n",
      "Epoch [975/2000], Avg Val Loss: 2.5509\n",
      "Validation loss improved from 2.5513 to 2.5509. Saving model...\n",
      "\n",
      "LOG: Epoch [976/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8811\n",
      "Epoch [976/2000], Avg Train Loss: 3.8811\n",
      "Epoch [976/2000], Avg Val Loss: 2.5505\n",
      "Validation loss improved from 2.5509 to 2.5505. Saving model...\n",
      "\n",
      "LOG: Epoch [977/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8867\n",
      "Epoch [977/2000], Avg Train Loss: 3.8867\n",
      "Epoch [977/2000], Avg Val Loss: 2.5503\n",
      "Validation loss improved from 2.5505 to 2.5503. Saving model...\n",
      "\n",
      "LOG: Epoch [978/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8440\n",
      "Epoch [978/2000], Avg Train Loss: 3.8440\n",
      "Epoch [978/2000], Avg Val Loss: 2.5501\n",
      "Validation loss improved from 2.5503 to 2.5501. Saving model...\n",
      "\n",
      "LOG: Epoch [979/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8658\n",
      "Epoch [979/2000], Avg Train Loss: 3.8658\n",
      "Epoch [979/2000], Avg Val Loss: 2.5498\n",
      "Validation loss improved from 2.5501 to 2.5498. Saving model...\n",
      "\n",
      "LOG: Epoch [980/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8592\n",
      "Epoch [980/2000], Avg Train Loss: 3.8592\n",
      "Epoch [980/2000], Avg Val Loss: 2.5496\n",
      "Validation loss improved from 2.5498 to 2.5496. Saving model...\n",
      "\n",
      "LOG: Epoch [981/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8887\n",
      "Epoch [981/2000], Avg Train Loss: 3.8887\n",
      "Epoch [981/2000], Avg Val Loss: 2.5493\n",
      "Validation loss improved from 2.5496 to 2.5493. Saving model...\n",
      "\n",
      "LOG: Epoch [982/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8700\n",
      "Epoch [982/2000], Avg Train Loss: 3.8700\n",
      "Epoch [982/2000], Avg Val Loss: 2.5489\n",
      "Validation loss improved from 2.5493 to 2.5489. Saving model...\n",
      "\n",
      "LOG: Epoch [983/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8723\n",
      "Epoch [983/2000], Avg Train Loss: 3.8723\n",
      "Epoch [983/2000], Avg Val Loss: 2.5485\n",
      "Validation loss improved from 2.5489 to 2.5485. Saving model...\n",
      "\n",
      "LOG: Epoch [984/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8634\n",
      "Epoch [984/2000], Avg Train Loss: 3.8634\n",
      "Epoch [984/2000], Avg Val Loss: 2.5482\n",
      "Validation loss improved from 2.5485 to 2.5482. Saving model...\n",
      "\n",
      "LOG: Epoch [985/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8745\n",
      "Epoch [985/2000], Avg Train Loss: 3.8745\n",
      "Epoch [985/2000], Avg Val Loss: 2.5478\n",
      "Validation loss improved from 2.5482 to 2.5478. Saving model...\n",
      "\n",
      "LOG: Epoch [986/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8759\n",
      "Epoch [986/2000], Avg Train Loss: 3.8759\n",
      "Epoch [986/2000], Avg Val Loss: 2.5474\n",
      "Validation loss improved from 2.5478 to 2.5474. Saving model...\n",
      "\n",
      "LOG: Epoch [987/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8814\n",
      "Epoch [987/2000], Avg Train Loss: 3.8814\n",
      "Epoch [987/2000], Avg Val Loss: 2.5471\n",
      "Validation loss improved from 2.5474 to 2.5471. Saving model...\n",
      "\n",
      "LOG: Epoch [988/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8604\n",
      "Epoch [988/2000], Avg Train Loss: 3.8604\n",
      "Epoch [988/2000], Avg Val Loss: 2.5467\n",
      "Validation loss improved from 2.5471 to 2.5467. Saving model...\n",
      "\n",
      "LOG: Epoch [989/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8619\n",
      "Epoch [989/2000], Avg Train Loss: 3.8619\n",
      "Epoch [989/2000], Avg Val Loss: 2.5464\n",
      "Validation loss improved from 2.5467 to 2.5464. Saving model...\n",
      "\n",
      "LOG: Epoch [990/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8481\n",
      "Epoch [990/2000], Avg Train Loss: 3.8481\n",
      "Epoch [990/2000], Avg Val Loss: 2.5460\n",
      "Validation loss improved from 2.5464 to 2.5460. Saving model...\n",
      "\n",
      "LOG: Epoch [991/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9099\n",
      "Epoch [991/2000], Avg Train Loss: 3.9099\n",
      "Epoch [991/2000], Avg Val Loss: 2.5456\n",
      "Validation loss improved from 2.5460 to 2.5456. Saving model...\n",
      "\n",
      "LOG: Epoch [992/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8839\n",
      "Epoch [992/2000], Avg Train Loss: 3.8839\n",
      "Epoch [992/2000], Avg Val Loss: 2.5454\n",
      "Validation loss improved from 2.5456 to 2.5454. Saving model...\n",
      "\n",
      "LOG: Epoch [993/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8434\n",
      "Epoch [993/2000], Avg Train Loss: 3.8434\n",
      "Epoch [993/2000], Avg Val Loss: 2.5452\n",
      "Validation loss improved from 2.5454 to 2.5452. Saving model...\n",
      "\n",
      "LOG: Epoch [994/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9344\n",
      "Epoch [994/2000], Avg Train Loss: 3.9344\n",
      "Epoch [994/2000], Avg Val Loss: 2.5450\n",
      "Validation loss improved from 2.5452 to 2.5450. Saving model...\n",
      "\n",
      "LOG: Epoch [995/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8666\n",
      "Epoch [995/2000], Avg Train Loss: 3.8666\n",
      "Epoch [995/2000], Avg Val Loss: 2.5446\n",
      "Validation loss improved from 2.5450 to 2.5446. Saving model...\n",
      "\n",
      "LOG: Epoch [996/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8264\n",
      "Epoch [996/2000], Avg Train Loss: 3.8264\n",
      "Epoch [996/2000], Avg Val Loss: 2.5444\n",
      "Validation loss improved from 2.5446 to 2.5444. Saving model...\n",
      "\n",
      "LOG: Epoch [997/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8744\n",
      "Epoch [997/2000], Avg Train Loss: 3.8744\n",
      "Epoch [997/2000], Avg Val Loss: 2.5440\n",
      "Validation loss improved from 2.5444 to 2.5440. Saving model...\n",
      "\n",
      "LOG: Epoch [998/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8446\n",
      "Epoch [998/2000], Avg Train Loss: 3.8446\n",
      "Epoch [998/2000], Avg Val Loss: 2.5438\n",
      "Validation loss improved from 2.5440 to 2.5438. Saving model...\n",
      "\n",
      "LOG: Epoch [999/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8750\n",
      "Epoch [999/2000], Avg Train Loss: 3.8750\n",
      "Epoch [999/2000], Avg Val Loss: 2.5437\n",
      "Validation loss improved from 2.5438 to 2.5437. Saving model...\n",
      "\n",
      "LOG: Epoch [1000/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8445\n",
      "Epoch [1000/2000], Avg Train Loss: 3.8445\n",
      "Epoch [1000/2000], Avg Val Loss: 2.5437\n",
      "Validation loss improved from 2.5437 to 2.5437. Saving model...\n",
      "\n",
      "LOG: Epoch [1001/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8619\n",
      "Epoch [1001/2000], Avg Train Loss: 3.8619\n",
      "Epoch [1001/2000], Avg Val Loss: 2.5436\n",
      "Validation loss improved from 2.5437 to 2.5436. Saving model...\n",
      "\n",
      "LOG: Epoch [1002/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8800\n",
      "Epoch [1002/2000], Avg Train Loss: 3.8800\n",
      "Epoch [1002/2000], Avg Val Loss: 2.5436\n",
      "Validation loss improved from 2.5436 to 2.5436. Saving model...\n",
      "\n",
      "LOG: Epoch [1003/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8900\n",
      "Epoch [1003/2000], Avg Train Loss: 3.8900\n",
      "Epoch [1003/2000], Avg Val Loss: 2.5435\n",
      "Validation loss improved from 2.5436 to 2.5435. Saving model...\n",
      "\n",
      "LOG: Epoch [1004/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8886\n",
      "Epoch [1004/2000], Avg Train Loss: 3.8886\n",
      "Epoch [1004/2000], Avg Val Loss: 2.5435\n",
      "Validation loss improved from 2.5435 to 2.5435. Saving model...\n",
      "\n",
      "LOG: Epoch [1005/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8365\n",
      "Epoch [1005/2000], Avg Train Loss: 3.8365\n",
      "Epoch [1005/2000], Avg Val Loss: 2.5434\n",
      "Validation loss improved from 2.5435 to 2.5434. Saving model...\n",
      "\n",
      "LOG: Epoch [1006/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8340\n",
      "Epoch [1006/2000], Avg Train Loss: 3.8340\n",
      "Epoch [1006/2000], Avg Val Loss: 2.5432\n",
      "Validation loss improved from 2.5434 to 2.5432. Saving model...\n",
      "\n",
      "LOG: Epoch [1007/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8862\n",
      "Epoch [1007/2000], Avg Train Loss: 3.8862\n",
      "Epoch [1007/2000], Avg Val Loss: 2.5430\n",
      "Validation loss improved from 2.5432 to 2.5430. Saving model...\n",
      "\n",
      "LOG: Epoch [1008/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8607\n",
      "Epoch [1008/2000], Avg Train Loss: 3.8607\n",
      "Epoch [1008/2000], Avg Val Loss: 2.5427\n",
      "Validation loss improved from 2.5430 to 2.5427. Saving model...\n",
      "\n",
      "LOG: Epoch [1009/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8415\n",
      "Epoch [1009/2000], Avg Train Loss: 3.8415\n",
      "Epoch [1009/2000], Avg Val Loss: 2.5425\n",
      "Validation loss improved from 2.5427 to 2.5425. Saving model...\n",
      "\n",
      "LOG: Epoch [1010/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8285\n",
      "Epoch [1010/2000], Avg Train Loss: 3.8285\n",
      "Epoch [1010/2000], Avg Val Loss: 2.5423\n",
      "Validation loss improved from 2.5425 to 2.5423. Saving model...\n",
      "\n",
      "LOG: Epoch [1011/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8599\n",
      "Epoch [1011/2000], Avg Train Loss: 3.8599\n",
      "Epoch [1011/2000], Avg Val Loss: 2.5421\n",
      "Validation loss improved from 2.5423 to 2.5421. Saving model...\n",
      "\n",
      "LOG: Epoch [1012/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8224\n",
      "Epoch [1012/2000], Avg Train Loss: 3.8224\n",
      "Epoch [1012/2000], Avg Val Loss: 2.5417\n",
      "Validation loss improved from 2.5421 to 2.5417. Saving model...\n",
      "\n",
      "LOG: Epoch [1013/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8463\n",
      "Epoch [1013/2000], Avg Train Loss: 3.8463\n",
      "Epoch [1013/2000], Avg Val Loss: 2.5415\n",
      "Validation loss improved from 2.5417 to 2.5415. Saving model...\n",
      "\n",
      "LOG: Epoch [1014/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8482\n",
      "Epoch [1014/2000], Avg Train Loss: 3.8482\n",
      "Epoch [1014/2000], Avg Val Loss: 2.5413\n",
      "Validation loss improved from 2.5415 to 2.5413. Saving model...\n",
      "\n",
      "LOG: Epoch [1015/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8443\n",
      "Epoch [1015/2000], Avg Train Loss: 3.8443\n",
      "Epoch [1015/2000], Avg Val Loss: 2.5410\n",
      "Validation loss improved from 2.5413 to 2.5410. Saving model...\n",
      "\n",
      "LOG: Epoch [1016/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8385\n",
      "Epoch [1016/2000], Avg Train Loss: 3.8385\n",
      "Epoch [1016/2000], Avg Val Loss: 2.5408\n",
      "Validation loss improved from 2.5410 to 2.5408. Saving model...\n",
      "\n",
      "LOG: Epoch [1017/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8305\n",
      "Epoch [1017/2000], Avg Train Loss: 3.8305\n",
      "Epoch [1017/2000], Avg Val Loss: 2.5404\n",
      "Validation loss improved from 2.5408 to 2.5404. Saving model...\n",
      "\n",
      "LOG: Epoch [1018/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8461\n",
      "Epoch [1018/2000], Avg Train Loss: 3.8461\n",
      "Epoch [1018/2000], Avg Val Loss: 2.5401\n",
      "Validation loss improved from 2.5404 to 2.5401. Saving model...\n",
      "\n",
      "LOG: Epoch [1019/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8588\n",
      "Epoch [1019/2000], Avg Train Loss: 3.8588\n",
      "Epoch [1019/2000], Avg Val Loss: 2.5396\n",
      "Validation loss improved from 2.5401 to 2.5396. Saving model...\n",
      "\n",
      "LOG: Epoch [1020/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7728\n",
      "Epoch [1020/2000], Avg Train Loss: 3.7728\n",
      "Epoch [1020/2000], Avg Val Loss: 2.5391\n",
      "Validation loss improved from 2.5396 to 2.5391. Saving model...\n",
      "\n",
      "LOG: Epoch [1021/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8136\n",
      "Epoch [1021/2000], Avg Train Loss: 3.8136\n",
      "Epoch [1021/2000], Avg Val Loss: 2.5386\n",
      "Validation loss improved from 2.5391 to 2.5386. Saving model...\n",
      "\n",
      "LOG: Epoch [1022/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8135\n",
      "Epoch [1022/2000], Avg Train Loss: 3.8135\n",
      "Epoch [1022/2000], Avg Val Loss: 2.5380\n",
      "Validation loss improved from 2.5386 to 2.5380. Saving model...\n",
      "\n",
      "LOG: Epoch [1023/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8294\n",
      "Epoch [1023/2000], Avg Train Loss: 3.8294\n",
      "Epoch [1023/2000], Avg Val Loss: 2.5375\n",
      "Validation loss improved from 2.5380 to 2.5375. Saving model...\n",
      "\n",
      "LOG: Epoch [1024/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8503\n",
      "Epoch [1024/2000], Avg Train Loss: 3.8503\n",
      "Epoch [1024/2000], Avg Val Loss: 2.5368\n",
      "Validation loss improved from 2.5375 to 2.5368. Saving model...\n",
      "\n",
      "LOG: Epoch [1025/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8345\n",
      "Epoch [1025/2000], Avg Train Loss: 3.8345\n",
      "Epoch [1025/2000], Avg Val Loss: 2.5361\n",
      "Validation loss improved from 2.5368 to 2.5361. Saving model...\n",
      "\n",
      "LOG: Epoch [1026/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8034\n",
      "Epoch [1026/2000], Avg Train Loss: 3.8034\n",
      "Epoch [1026/2000], Avg Val Loss: 2.5355\n",
      "Validation loss improved from 2.5361 to 2.5355. Saving model...\n",
      "\n",
      "LOG: Epoch [1027/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8556\n",
      "Epoch [1027/2000], Avg Train Loss: 3.8556\n",
      "Epoch [1027/2000], Avg Val Loss: 2.5347\n",
      "Validation loss improved from 2.5355 to 2.5347. Saving model...\n",
      "\n",
      "LOG: Epoch [1028/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8163\n",
      "Epoch [1028/2000], Avg Train Loss: 3.8163\n",
      "Epoch [1028/2000], Avg Val Loss: 2.5341\n",
      "Validation loss improved from 2.5347 to 2.5341. Saving model...\n",
      "\n",
      "LOG: Epoch [1029/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8344\n",
      "Epoch [1029/2000], Avg Train Loss: 3.8344\n",
      "Epoch [1029/2000], Avg Val Loss: 2.5337\n",
      "Validation loss improved from 2.5341 to 2.5337. Saving model...\n",
      "\n",
      "LOG: Epoch [1030/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8370\n",
      "Epoch [1030/2000], Avg Train Loss: 3.8370\n",
      "Epoch [1030/2000], Avg Val Loss: 2.5333\n",
      "Validation loss improved from 2.5337 to 2.5333. Saving model...\n",
      "\n",
      "LOG: Epoch [1031/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8051\n",
      "Epoch [1031/2000], Avg Train Loss: 3.8051\n",
      "Epoch [1031/2000], Avg Val Loss: 2.5329\n",
      "Validation loss improved from 2.5333 to 2.5329. Saving model...\n",
      "\n",
      "LOG: Epoch [1032/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8098\n",
      "Epoch [1032/2000], Avg Train Loss: 3.8098\n",
      "Epoch [1032/2000], Avg Val Loss: 2.5325\n",
      "Validation loss improved from 2.5329 to 2.5325. Saving model...\n",
      "\n",
      "LOG: Epoch [1033/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8245\n",
      "Epoch [1033/2000], Avg Train Loss: 3.8245\n",
      "Epoch [1033/2000], Avg Val Loss: 2.5323\n",
      "Validation loss improved from 2.5325 to 2.5323. Saving model...\n",
      "\n",
      "LOG: Epoch [1034/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7875\n",
      "Epoch [1034/2000], Avg Train Loss: 3.7875\n",
      "Epoch [1034/2000], Avg Val Loss: 2.5321\n",
      "Validation loss improved from 2.5323 to 2.5321. Saving model...\n",
      "\n",
      "LOG: Epoch [1035/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8602\n",
      "Epoch [1035/2000], Avg Train Loss: 3.8602\n",
      "Epoch [1035/2000], Avg Val Loss: 2.5318\n",
      "Validation loss improved from 2.5321 to 2.5318. Saving model...\n",
      "\n",
      "LOG: Epoch [1036/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7985\n",
      "Epoch [1036/2000], Avg Train Loss: 3.7985\n",
      "Epoch [1036/2000], Avg Val Loss: 2.5315\n",
      "Validation loss improved from 2.5318 to 2.5315. Saving model...\n",
      "\n",
      "LOG: Epoch [1037/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8465\n",
      "Epoch [1037/2000], Avg Train Loss: 3.8465\n",
      "Epoch [1037/2000], Avg Val Loss: 2.5312\n",
      "Validation loss improved from 2.5315 to 2.5312. Saving model...\n",
      "\n",
      "LOG: Epoch [1038/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8121\n",
      "Epoch [1038/2000], Avg Train Loss: 3.8121\n",
      "Epoch [1038/2000], Avg Val Loss: 2.5306\n",
      "Validation loss improved from 2.5312 to 2.5306. Saving model...\n",
      "\n",
      "LOG: Epoch [1039/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8279\n",
      "Epoch [1039/2000], Avg Train Loss: 3.8279\n",
      "Epoch [1039/2000], Avg Val Loss: 2.5302\n",
      "Validation loss improved from 2.5306 to 2.5302. Saving model...\n",
      "\n",
      "LOG: Epoch [1040/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8220\n",
      "Epoch [1040/2000], Avg Train Loss: 3.8220\n",
      "Epoch [1040/2000], Avg Val Loss: 2.5298\n",
      "Validation loss improved from 2.5302 to 2.5298. Saving model...\n",
      "\n",
      "LOG: Epoch [1041/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8314\n",
      "Epoch [1041/2000], Avg Train Loss: 3.8314\n",
      "Epoch [1041/2000], Avg Val Loss: 2.5293\n",
      "Validation loss improved from 2.5298 to 2.5293. Saving model...\n",
      "\n",
      "LOG: Epoch [1042/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8344\n",
      "Epoch [1042/2000], Avg Train Loss: 3.8344\n",
      "Epoch [1042/2000], Avg Val Loss: 2.5290\n",
      "Validation loss improved from 2.5293 to 2.5290. Saving model...\n",
      "\n",
      "LOG: Epoch [1043/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8238\n",
      "Epoch [1043/2000], Avg Train Loss: 3.8238\n",
      "Epoch [1043/2000], Avg Val Loss: 2.5285\n",
      "Validation loss improved from 2.5290 to 2.5285. Saving model...\n",
      "\n",
      "LOG: Epoch [1044/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7800\n",
      "Epoch [1044/2000], Avg Train Loss: 3.7800\n",
      "Epoch [1044/2000], Avg Val Loss: 2.5281\n",
      "Validation loss improved from 2.5285 to 2.5281. Saving model...\n",
      "\n",
      "LOG: Epoch [1045/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8247\n",
      "Epoch [1045/2000], Avg Train Loss: 3.8247\n",
      "Epoch [1045/2000], Avg Val Loss: 2.5276\n",
      "Validation loss improved from 2.5281 to 2.5276. Saving model...\n",
      "\n",
      "LOG: Epoch [1046/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7799\n",
      "Epoch [1046/2000], Avg Train Loss: 3.7799\n",
      "Epoch [1046/2000], Avg Val Loss: 2.5271\n",
      "Validation loss improved from 2.5276 to 2.5271. Saving model...\n",
      "\n",
      "LOG: Epoch [1047/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8145\n",
      "Epoch [1047/2000], Avg Train Loss: 3.8145\n",
      "Epoch [1047/2000], Avg Val Loss: 2.5266\n",
      "Validation loss improved from 2.5271 to 2.5266. Saving model...\n",
      "\n",
      "LOG: Epoch [1048/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8552\n",
      "Epoch [1048/2000], Avg Train Loss: 3.8552\n",
      "Epoch [1048/2000], Avg Val Loss: 2.5263\n",
      "Validation loss improved from 2.5266 to 2.5263. Saving model...\n",
      "\n",
      "LOG: Epoch [1049/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8360\n",
      "Epoch [1049/2000], Avg Train Loss: 3.8360\n",
      "Epoch [1049/2000], Avg Val Loss: 2.5261\n",
      "Validation loss improved from 2.5263 to 2.5261. Saving model...\n",
      "\n",
      "LOG: Epoch [1050/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8284\n",
      "Epoch [1050/2000], Avg Train Loss: 3.8284\n",
      "Epoch [1050/2000], Avg Val Loss: 2.5258\n",
      "Validation loss improved from 2.5261 to 2.5258. Saving model...\n",
      "\n",
      "LOG: Epoch [1051/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8160\n",
      "Epoch [1051/2000], Avg Train Loss: 3.8160\n",
      "Epoch [1051/2000], Avg Val Loss: 2.5257\n",
      "Validation loss improved from 2.5258 to 2.5257. Saving model...\n",
      "\n",
      "LOG: Epoch [1052/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7916\n",
      "Epoch [1052/2000], Avg Train Loss: 3.7916\n",
      "Epoch [1052/2000], Avg Val Loss: 2.5255\n",
      "Validation loss improved from 2.5257 to 2.5255. Saving model...\n",
      "\n",
      "LOG: Epoch [1053/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8497\n",
      "Epoch [1053/2000], Avg Train Loss: 3.8497\n",
      "Epoch [1053/2000], Avg Val Loss: 2.5253\n",
      "Validation loss improved from 2.5255 to 2.5253. Saving model...\n",
      "\n",
      "LOG: Epoch [1054/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8145\n",
      "Epoch [1054/2000], Avg Train Loss: 3.8145\n",
      "Epoch [1054/2000], Avg Val Loss: 2.5251\n",
      "Validation loss improved from 2.5253 to 2.5251. Saving model...\n",
      "\n",
      "LOG: Epoch [1055/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8174\n",
      "Epoch [1055/2000], Avg Train Loss: 3.8174\n",
      "Epoch [1055/2000], Avg Val Loss: 2.5252\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1056/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7972\n",
      "Epoch [1056/2000], Avg Train Loss: 3.7972\n",
      "Epoch [1056/2000], Avg Val Loss: 2.5252\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1057/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8121\n",
      "Epoch [1057/2000], Avg Train Loss: 3.8121\n",
      "Epoch [1057/2000], Avg Val Loss: 2.5254\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1058/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8628\n",
      "Epoch [1058/2000], Avg Train Loss: 3.8628\n",
      "Epoch [1058/2000], Avg Val Loss: 2.5255\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1059/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8033\n",
      "Epoch [1059/2000], Avg Train Loss: 3.8033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1059/2000], Avg Val Loss: 2.5256\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1060/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8038\n",
      "Epoch [1060/2000], Avg Train Loss: 3.8038\n",
      "Epoch [1060/2000], Avg Val Loss: 2.5257\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1061/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7921\n",
      "Epoch [1061/2000], Avg Train Loss: 3.7921\n",
      "Epoch [1061/2000], Avg Val Loss: 2.5257\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1062/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7999\n",
      "Epoch [1062/2000], Avg Train Loss: 3.7999\n",
      "Epoch [1062/2000], Avg Val Loss: 2.5258\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1063/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8179\n",
      "Epoch [1063/2000], Avg Train Loss: 3.8179\n",
      "Epoch [1063/2000], Avg Val Loss: 2.5257\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1064/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7826\n",
      "Epoch [1064/2000], Avg Train Loss: 3.7826\n",
      "Epoch [1064/2000], Avg Val Loss: 2.5255\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1065/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8002\n",
      "Epoch [1065/2000], Avg Train Loss: 3.8002\n",
      "Epoch [1065/2000], Avg Val Loss: 2.5252\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1066/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7868\n",
      "Epoch [1066/2000], Avg Train Loss: 3.7868\n",
      "Epoch [1066/2000], Avg Val Loss: 2.5247\n",
      "Validation loss improved from 2.5251 to 2.5247. Saving model...\n",
      "\n",
      "LOG: Epoch [1067/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8107\n",
      "Epoch [1067/2000], Avg Train Loss: 3.8107\n",
      "Epoch [1067/2000], Avg Val Loss: 2.5243\n",
      "Validation loss improved from 2.5247 to 2.5243. Saving model...\n",
      "\n",
      "LOG: Epoch [1068/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8028\n",
      "Epoch [1068/2000], Avg Train Loss: 3.8028\n",
      "Epoch [1068/2000], Avg Val Loss: 2.5238\n",
      "Validation loss improved from 2.5243 to 2.5238. Saving model...\n",
      "\n",
      "LOG: Epoch [1069/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8062\n",
      "Epoch [1069/2000], Avg Train Loss: 3.8062\n",
      "Epoch [1069/2000], Avg Val Loss: 2.5234\n",
      "Validation loss improved from 2.5238 to 2.5234. Saving model...\n",
      "\n",
      "LOG: Epoch [1070/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7955\n",
      "Epoch [1070/2000], Avg Train Loss: 3.7955\n",
      "Epoch [1070/2000], Avg Val Loss: 2.5229\n",
      "Validation loss improved from 2.5234 to 2.5229. Saving model...\n",
      "\n",
      "LOG: Epoch [1071/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7847\n",
      "Epoch [1071/2000], Avg Train Loss: 3.7847\n",
      "Epoch [1071/2000], Avg Val Loss: 2.5224\n",
      "Validation loss improved from 2.5229 to 2.5224. Saving model...\n",
      "\n",
      "LOG: Epoch [1072/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8523\n",
      "Epoch [1072/2000], Avg Train Loss: 3.8523\n",
      "Epoch [1072/2000], Avg Val Loss: 2.5220\n",
      "Validation loss improved from 2.5224 to 2.5220. Saving model...\n",
      "\n",
      "LOG: Epoch [1073/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8204\n",
      "Epoch [1073/2000], Avg Train Loss: 3.8204\n",
      "Epoch [1073/2000], Avg Val Loss: 2.5218\n",
      "Validation loss improved from 2.5220 to 2.5218. Saving model...\n",
      "\n",
      "LOG: Epoch [1074/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7991\n",
      "Epoch [1074/2000], Avg Train Loss: 3.7991\n",
      "Epoch [1074/2000], Avg Val Loss: 2.5216\n",
      "Validation loss improved from 2.5218 to 2.5216. Saving model...\n",
      "\n",
      "LOG: Epoch [1075/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8032\n",
      "Epoch [1075/2000], Avg Train Loss: 3.8032\n",
      "Epoch [1075/2000], Avg Val Loss: 2.5214\n",
      "Validation loss improved from 2.5216 to 2.5214. Saving model...\n",
      "\n",
      "LOG: Epoch [1076/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7701\n",
      "Epoch [1076/2000], Avg Train Loss: 3.7701\n",
      "Epoch [1076/2000], Avg Val Loss: 2.5212\n",
      "Validation loss improved from 2.5214 to 2.5212. Saving model...\n",
      "\n",
      "LOG: Epoch [1077/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7676\n",
      "Epoch [1077/2000], Avg Train Loss: 3.7676\n",
      "Epoch [1077/2000], Avg Val Loss: 2.5208\n",
      "Validation loss improved from 2.5212 to 2.5208. Saving model...\n",
      "\n",
      "LOG: Epoch [1078/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7805\n",
      "Epoch [1078/2000], Avg Train Loss: 3.7805\n",
      "Epoch [1078/2000], Avg Val Loss: 2.5205\n",
      "Validation loss improved from 2.5208 to 2.5205. Saving model...\n",
      "\n",
      "LOG: Epoch [1079/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7569\n",
      "Epoch [1079/2000], Avg Train Loss: 3.7569\n",
      "Epoch [1079/2000], Avg Val Loss: 2.5202\n",
      "Validation loss improved from 2.5205 to 2.5202. Saving model...\n",
      "\n",
      "LOG: Epoch [1080/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7915\n",
      "Epoch [1080/2000], Avg Train Loss: 3.7915\n",
      "Epoch [1080/2000], Avg Val Loss: 2.5198\n",
      "Validation loss improved from 2.5202 to 2.5198. Saving model...\n",
      "\n",
      "LOG: Epoch [1081/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8159\n",
      "Epoch [1081/2000], Avg Train Loss: 3.8159\n",
      "Epoch [1081/2000], Avg Val Loss: 2.5193\n",
      "Validation loss improved from 2.5198 to 2.5193. Saving model...\n",
      "\n",
      "LOG: Epoch [1082/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7910\n",
      "Epoch [1082/2000], Avg Train Loss: 3.7910\n",
      "Epoch [1082/2000], Avg Val Loss: 2.5187\n",
      "Validation loss improved from 2.5193 to 2.5187. Saving model...\n",
      "\n",
      "LOG: Epoch [1083/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7816\n",
      "Epoch [1083/2000], Avg Train Loss: 3.7816\n",
      "Epoch [1083/2000], Avg Val Loss: 2.5179\n",
      "Validation loss improved from 2.5187 to 2.5179. Saving model...\n",
      "\n",
      "LOG: Epoch [1084/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8233\n",
      "Epoch [1084/2000], Avg Train Loss: 3.8233\n",
      "Epoch [1084/2000], Avg Val Loss: 2.5172\n",
      "Validation loss improved from 2.5179 to 2.5172. Saving model...\n",
      "\n",
      "LOG: Epoch [1085/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7693\n",
      "Epoch [1085/2000], Avg Train Loss: 3.7693\n",
      "Epoch [1085/2000], Avg Val Loss: 2.5166\n",
      "Validation loss improved from 2.5172 to 2.5166. Saving model...\n",
      "\n",
      "LOG: Epoch [1086/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7954\n",
      "Epoch [1086/2000], Avg Train Loss: 3.7954\n",
      "Epoch [1086/2000], Avg Val Loss: 2.5160\n",
      "Validation loss improved from 2.5166 to 2.5160. Saving model...\n",
      "\n",
      "LOG: Epoch [1087/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7879\n",
      "Epoch [1087/2000], Avg Train Loss: 3.7879\n",
      "Epoch [1087/2000], Avg Val Loss: 2.5154\n",
      "Validation loss improved from 2.5160 to 2.5154. Saving model...\n",
      "\n",
      "LOG: Epoch [1088/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8009\n",
      "Epoch [1088/2000], Avg Train Loss: 3.8009\n",
      "Epoch [1088/2000], Avg Val Loss: 2.5148\n",
      "Validation loss improved from 2.5154 to 2.5148. Saving model...\n",
      "\n",
      "LOG: Epoch [1089/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7640\n",
      "Epoch [1089/2000], Avg Train Loss: 3.7640\n",
      "Epoch [1089/2000], Avg Val Loss: 2.5141\n",
      "Validation loss improved from 2.5148 to 2.5141. Saving model...\n",
      "\n",
      "LOG: Epoch [1090/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8037\n",
      "Epoch [1090/2000], Avg Train Loss: 3.8037\n",
      "Epoch [1090/2000], Avg Val Loss: 2.5135\n",
      "Validation loss improved from 2.5141 to 2.5135. Saving model...\n",
      "\n",
      "LOG: Epoch [1091/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7647\n",
      "Epoch [1091/2000], Avg Train Loss: 3.7647\n",
      "Epoch [1091/2000], Avg Val Loss: 2.5130\n",
      "Validation loss improved from 2.5135 to 2.5130. Saving model...\n",
      "\n",
      "LOG: Epoch [1092/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7665\n",
      "Epoch [1092/2000], Avg Train Loss: 3.7665\n",
      "Epoch [1092/2000], Avg Val Loss: 2.5125\n",
      "Validation loss improved from 2.5130 to 2.5125. Saving model...\n",
      "\n",
      "LOG: Epoch [1093/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7781\n",
      "Epoch [1093/2000], Avg Train Loss: 3.7781\n",
      "Epoch [1093/2000], Avg Val Loss: 2.5121\n",
      "Validation loss improved from 2.5125 to 2.5121. Saving model...\n",
      "\n",
      "LOG: Epoch [1094/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7508\n",
      "Epoch [1094/2000], Avg Train Loss: 3.7508\n",
      "Epoch [1094/2000], Avg Val Loss: 2.5116\n",
      "Validation loss improved from 2.5121 to 2.5116. Saving model...\n",
      "\n",
      "LOG: Epoch [1095/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8108\n",
      "Epoch [1095/2000], Avg Train Loss: 3.8108\n",
      "Epoch [1095/2000], Avg Val Loss: 2.5112\n",
      "Validation loss improved from 2.5116 to 2.5112. Saving model...\n",
      "\n",
      "LOG: Epoch [1096/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7741\n",
      "Epoch [1096/2000], Avg Train Loss: 3.7741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1096/2000], Avg Val Loss: 2.5110\n",
      "Validation loss improved from 2.5112 to 2.5110. Saving model...\n",
      "\n",
      "LOG: Epoch [1097/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7859\n",
      "Epoch [1097/2000], Avg Train Loss: 3.7859\n",
      "Epoch [1097/2000], Avg Val Loss: 2.5110\n",
      "Validation loss improved from 2.5110 to 2.5110. Saving model...\n",
      "\n",
      "LOG: Epoch [1098/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8180\n",
      "Epoch [1098/2000], Avg Train Loss: 3.8180\n",
      "Epoch [1098/2000], Avg Val Loss: 2.5109\n",
      "Validation loss improved from 2.5110 to 2.5109. Saving model...\n",
      "\n",
      "LOG: Epoch [1099/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8146\n",
      "Epoch [1099/2000], Avg Train Loss: 3.8146\n",
      "Epoch [1099/2000], Avg Val Loss: 2.5110\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7869\n",
      "Epoch [1100/2000], Avg Train Loss: 3.7869\n",
      "Epoch [1100/2000], Avg Val Loss: 2.5113\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1101/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7751\n",
      "Epoch [1101/2000], Avg Train Loss: 3.7751\n",
      "Epoch [1101/2000], Avg Val Loss: 2.5117\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1102/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7697\n",
      "Epoch [1102/2000], Avg Train Loss: 3.7697\n",
      "Epoch [1102/2000], Avg Val Loss: 2.5120\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8108\n",
      "Epoch [1103/2000], Avg Train Loss: 3.8108\n",
      "Epoch [1103/2000], Avg Val Loss: 2.5125\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7614\n",
      "Epoch [1104/2000], Avg Train Loss: 3.7614\n",
      "Epoch [1104/2000], Avg Val Loss: 2.5130\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7744\n",
      "Epoch [1105/2000], Avg Train Loss: 3.7744\n",
      "Epoch [1105/2000], Avg Val Loss: 2.5134\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7672\n",
      "Epoch [1106/2000], Avg Train Loss: 3.7672\n",
      "Epoch [1106/2000], Avg Val Loss: 2.5138\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7632\n",
      "Epoch [1107/2000], Avg Train Loss: 3.7632\n",
      "Epoch [1107/2000], Avg Val Loss: 2.5142\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8157\n",
      "Epoch [1108/2000], Avg Train Loss: 3.8157\n",
      "Epoch [1108/2000], Avg Val Loss: 2.5144\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7699\n",
      "Epoch [1109/2000], Avg Train Loss: 3.7699\n",
      "Epoch [1109/2000], Avg Val Loss: 2.5145\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7828\n",
      "Epoch [1110/2000], Avg Train Loss: 3.7828\n",
      "Epoch [1110/2000], Avg Val Loss: 2.5145\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7508\n",
      "Epoch [1111/2000], Avg Train Loss: 3.7508\n",
      "Epoch [1111/2000], Avg Val Loss: 2.5145\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8281\n",
      "Epoch [1112/2000], Avg Train Loss: 3.8281\n",
      "Epoch [1112/2000], Avg Val Loss: 2.5145\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7847\n",
      "Epoch [1113/2000], Avg Train Loss: 3.7847\n",
      "Epoch [1113/2000], Avg Val Loss: 2.5146\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7554\n",
      "Epoch [1114/2000], Avg Train Loss: 3.7554\n",
      "Epoch [1114/2000], Avg Val Loss: 2.5147\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7873\n",
      "Epoch [1115/2000], Avg Train Loss: 3.7873\n",
      "Epoch [1115/2000], Avg Val Loss: 2.5146\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7919\n",
      "Epoch [1116/2000], Avg Train Loss: 3.7919\n",
      "Epoch [1116/2000], Avg Val Loss: 2.5146\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7873\n",
      "Epoch [1117/2000], Avg Train Loss: 3.7873\n",
      "Epoch [1117/2000], Avg Val Loss: 2.5144\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7709\n",
      "Epoch [1118/2000], Avg Train Loss: 3.7709\n",
      "Epoch [1118/2000], Avg Val Loss: 2.5140\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7546\n",
      "Epoch [1119/2000], Avg Train Loss: 3.7546\n",
      "Epoch [1119/2000], Avg Val Loss: 2.5136\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7544\n",
      "Epoch [1120/2000], Avg Train Loss: 3.7544\n",
      "Epoch [1120/2000], Avg Val Loss: 2.5130\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7777\n",
      "Epoch [1121/2000], Avg Train Loss: 3.7777\n",
      "Epoch [1121/2000], Avg Val Loss: 2.5125\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7767\n",
      "Epoch [1122/2000], Avg Train Loss: 3.7767\n",
      "Epoch [1122/2000], Avg Val Loss: 2.5119\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7695\n",
      "Epoch [1123/2000], Avg Train Loss: 3.7695\n",
      "Epoch [1123/2000], Avg Val Loss: 2.5111\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7681\n",
      "Epoch [1124/2000], Avg Train Loss: 3.7681\n",
      "Epoch [1124/2000], Avg Val Loss: 2.5104\n",
      "Validation loss improved from 2.5109 to 2.5104. Saving model...\n",
      "\n",
      "LOG: Epoch [1125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8182\n",
      "Epoch [1125/2000], Avg Train Loss: 3.8182\n",
      "Epoch [1125/2000], Avg Val Loss: 2.5095\n",
      "Validation loss improved from 2.5104 to 2.5095. Saving model...\n",
      "\n",
      "LOG: Epoch [1126/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7593\n",
      "Epoch [1126/2000], Avg Train Loss: 3.7593\n",
      "Epoch [1126/2000], Avg Val Loss: 2.5089\n",
      "Validation loss improved from 2.5095 to 2.5089. Saving model...\n",
      "\n",
      "LOG: Epoch [1127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7702\n",
      "Epoch [1127/2000], Avg Train Loss: 3.7702\n",
      "Epoch [1127/2000], Avg Val Loss: 2.5083\n",
      "Validation loss improved from 2.5089 to 2.5083. Saving model...\n",
      "\n",
      "LOG: Epoch [1128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7452\n",
      "Epoch [1128/2000], Avg Train Loss: 3.7452\n",
      "Epoch [1128/2000], Avg Val Loss: 2.5077\n",
      "Validation loss improved from 2.5083 to 2.5077. Saving model...\n",
      "\n",
      "LOG: Epoch [1129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7447\n",
      "Epoch [1129/2000], Avg Train Loss: 3.7447\n",
      "Epoch [1129/2000], Avg Val Loss: 2.5072\n",
      "Validation loss improved from 2.5077 to 2.5072. Saving model...\n",
      "\n",
      "LOG: Epoch [1130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7463\n",
      "Epoch [1130/2000], Avg Train Loss: 3.7463\n",
      "Epoch [1130/2000], Avg Val Loss: 2.5066\n",
      "Validation loss improved from 2.5072 to 2.5066. Saving model...\n",
      "\n",
      "LOG: Epoch [1131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7861\n",
      "Epoch [1131/2000], Avg Train Loss: 3.7861\n",
      "Epoch [1131/2000], Avg Val Loss: 2.5061\n",
      "Validation loss improved from 2.5066 to 2.5061. Saving model...\n",
      "\n",
      "LOG: Epoch [1132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7578\n",
      "Epoch [1132/2000], Avg Train Loss: 3.7578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1132/2000], Avg Val Loss: 2.5054\n",
      "Validation loss improved from 2.5061 to 2.5054. Saving model...\n",
      "\n",
      "LOG: Epoch [1133/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7645\n",
      "Epoch [1133/2000], Avg Train Loss: 3.7645\n",
      "Epoch [1133/2000], Avg Val Loss: 2.5047\n",
      "Validation loss improved from 2.5054 to 2.5047. Saving model...\n",
      "\n",
      "LOG: Epoch [1134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7632\n",
      "Epoch [1134/2000], Avg Train Loss: 3.7632\n",
      "Epoch [1134/2000], Avg Val Loss: 2.5042\n",
      "Validation loss improved from 2.5047 to 2.5042. Saving model...\n",
      "\n",
      "LOG: Epoch [1135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7306\n",
      "Epoch [1135/2000], Avg Train Loss: 3.7306\n",
      "Epoch [1135/2000], Avg Val Loss: 2.5039\n",
      "Validation loss improved from 2.5042 to 2.5039. Saving model...\n",
      "\n",
      "LOG: Epoch [1136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7366\n",
      "Epoch [1136/2000], Avg Train Loss: 3.7366\n",
      "Epoch [1136/2000], Avg Val Loss: 2.5035\n",
      "Validation loss improved from 2.5039 to 2.5035. Saving model...\n",
      "\n",
      "LOG: Epoch [1137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7621\n",
      "Epoch [1137/2000], Avg Train Loss: 3.7621\n",
      "Epoch [1137/2000], Avg Val Loss: 2.5032\n",
      "Validation loss improved from 2.5035 to 2.5032. Saving model...\n",
      "\n",
      "LOG: Epoch [1138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7753\n",
      "Epoch [1138/2000], Avg Train Loss: 3.7753\n",
      "Epoch [1138/2000], Avg Val Loss: 2.5029\n",
      "Validation loss improved from 2.5032 to 2.5029. Saving model...\n",
      "\n",
      "LOG: Epoch [1139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7526\n",
      "Epoch [1139/2000], Avg Train Loss: 3.7526\n",
      "Epoch [1139/2000], Avg Val Loss: 2.5027\n",
      "Validation loss improved from 2.5029 to 2.5027. Saving model...\n",
      "\n",
      "LOG: Epoch [1140/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7336\n",
      "Epoch [1140/2000], Avg Train Loss: 3.7336\n",
      "Epoch [1140/2000], Avg Val Loss: 2.5025\n",
      "Validation loss improved from 2.5027 to 2.5025. Saving model...\n",
      "\n",
      "LOG: Epoch [1141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7247\n",
      "Epoch [1141/2000], Avg Train Loss: 3.7247\n",
      "Epoch [1141/2000], Avg Val Loss: 2.5022\n",
      "Validation loss improved from 2.5025 to 2.5022. Saving model...\n",
      "\n",
      "LOG: Epoch [1142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7347\n",
      "Epoch [1142/2000], Avg Train Loss: 3.7347\n",
      "Epoch [1142/2000], Avg Val Loss: 2.5016\n",
      "Validation loss improved from 2.5022 to 2.5016. Saving model...\n",
      "\n",
      "LOG: Epoch [1143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7264\n",
      "Epoch [1143/2000], Avg Train Loss: 3.7264\n",
      "Epoch [1143/2000], Avg Val Loss: 2.5011\n",
      "Validation loss improved from 2.5016 to 2.5011. Saving model...\n",
      "\n",
      "LOG: Epoch [1144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7563\n",
      "Epoch [1144/2000], Avg Train Loss: 3.7563\n",
      "Epoch [1144/2000], Avg Val Loss: 2.5005\n",
      "Validation loss improved from 2.5011 to 2.5005. Saving model...\n",
      "\n",
      "LOG: Epoch [1145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7606\n",
      "Epoch [1145/2000], Avg Train Loss: 3.7606\n",
      "Epoch [1145/2000], Avg Val Loss: 2.5001\n",
      "Validation loss improved from 2.5005 to 2.5001. Saving model...\n",
      "\n",
      "LOG: Epoch [1146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7661\n",
      "Epoch [1146/2000], Avg Train Loss: 3.7661\n",
      "Epoch [1146/2000], Avg Val Loss: 2.4998\n",
      "Validation loss improved from 2.5001 to 2.4998. Saving model...\n",
      "\n",
      "LOG: Epoch [1147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7739\n",
      "Epoch [1147/2000], Avg Train Loss: 3.7739\n",
      "Epoch [1147/2000], Avg Val Loss: 2.4996\n",
      "Validation loss improved from 2.4998 to 2.4996. Saving model...\n",
      "\n",
      "LOG: Epoch [1148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7277\n",
      "Epoch [1148/2000], Avg Train Loss: 3.7277\n",
      "Epoch [1148/2000], Avg Val Loss: 2.4994\n",
      "Validation loss improved from 2.4996 to 2.4994. Saving model...\n",
      "\n",
      "LOG: Epoch [1149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7503\n",
      "Epoch [1149/2000], Avg Train Loss: 3.7503\n",
      "Epoch [1149/2000], Avg Val Loss: 2.4993\n",
      "Validation loss improved from 2.4994 to 2.4993. Saving model...\n",
      "\n",
      "LOG: Epoch [1150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7503\n",
      "Epoch [1150/2000], Avg Train Loss: 3.7503\n",
      "Epoch [1150/2000], Avg Val Loss: 2.4991\n",
      "Validation loss improved from 2.4993 to 2.4991. Saving model...\n",
      "\n",
      "LOG: Epoch [1151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7896\n",
      "Epoch [1151/2000], Avg Train Loss: 3.7896\n",
      "Epoch [1151/2000], Avg Val Loss: 2.4991\n",
      "Validation loss improved from 2.4991 to 2.4991. Saving model...\n",
      "\n",
      "LOG: Epoch [1152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7464\n",
      "Epoch [1152/2000], Avg Train Loss: 3.7464\n",
      "Epoch [1152/2000], Avg Val Loss: 2.4991\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7300\n",
      "Epoch [1153/2000], Avg Train Loss: 3.7300\n",
      "Epoch [1153/2000], Avg Val Loss: 2.4991\n",
      "Validation loss improved from 2.4991 to 2.4991. Saving model...\n",
      "\n",
      "LOG: Epoch [1154/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7838\n",
      "Epoch [1154/2000], Avg Train Loss: 3.7838\n",
      "Epoch [1154/2000], Avg Val Loss: 2.4990\n",
      "Validation loss improved from 2.4991 to 2.4990. Saving model...\n",
      "\n",
      "LOG: Epoch [1155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7005\n",
      "Epoch [1155/2000], Avg Train Loss: 3.7005\n",
      "Epoch [1155/2000], Avg Val Loss: 2.4988\n",
      "Validation loss improved from 2.4990 to 2.4988. Saving model...\n",
      "\n",
      "LOG: Epoch [1156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7540\n",
      "Epoch [1156/2000], Avg Train Loss: 3.7540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1156/2000], Avg Val Loss: 2.4985\n",
      "Validation loss improved from 2.4988 to 2.4985. Saving model...\n",
      "\n",
      "LOG: Epoch [1157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6993\n",
      "Epoch [1157/2000], Avg Train Loss: 3.6993\n",
      "Epoch [1157/2000], Avg Val Loss: 2.4981\n",
      "Validation loss improved from 2.4985 to 2.4981. Saving model...\n",
      "\n",
      "LOG: Epoch [1158/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7596\n",
      "Epoch [1158/2000], Avg Train Loss: 3.7596\n",
      "Epoch [1158/2000], Avg Val Loss: 2.4978\n",
      "Validation loss improved from 2.4981 to 2.4978. Saving model...\n",
      "\n",
      "LOG: Epoch [1159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7422\n",
      "Epoch [1159/2000], Avg Train Loss: 3.7422\n",
      "Epoch [1159/2000], Avg Val Loss: 2.4975\n",
      "Validation loss improved from 2.4978 to 2.4975. Saving model...\n",
      "\n",
      "LOG: Epoch [1160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7873\n",
      "Epoch [1160/2000], Avg Train Loss: 3.7873\n",
      "Epoch [1160/2000], Avg Val Loss: 2.4973\n",
      "Validation loss improved from 2.4975 to 2.4973. Saving model...\n",
      "\n",
      "LOG: Epoch [1161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7629\n",
      "Epoch [1161/2000], Avg Train Loss: 3.7629\n",
      "Epoch [1161/2000], Avg Val Loss: 2.4969\n",
      "Validation loss improved from 2.4973 to 2.4969. Saving model...\n",
      "\n",
      "LOG: Epoch [1162/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7010\n",
      "Epoch [1162/2000], Avg Train Loss: 3.7010\n",
      "Epoch [1162/2000], Avg Val Loss: 2.4966\n",
      "Validation loss improved from 2.4969 to 2.4966. Saving model...\n",
      "\n",
      "LOG: Epoch [1163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7498\n",
      "Epoch [1163/2000], Avg Train Loss: 3.7498\n",
      "Epoch [1163/2000], Avg Val Loss: 2.4965\n",
      "Validation loss improved from 2.4966 to 2.4965. Saving model...\n",
      "\n",
      "LOG: Epoch [1164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7444\n",
      "Epoch [1164/2000], Avg Train Loss: 3.7444\n",
      "Epoch [1164/2000], Avg Val Loss: 2.4963\n",
      "Validation loss improved from 2.4965 to 2.4963. Saving model...\n",
      "\n",
      "LOG: Epoch [1165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7379\n",
      "Epoch [1165/2000], Avg Train Loss: 3.7379\n",
      "Epoch [1165/2000], Avg Val Loss: 2.4963\n",
      "Validation loss improved from 2.4963 to 2.4963. Saving model...\n",
      "\n",
      "LOG: Epoch [1166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7593\n",
      "Epoch [1166/2000], Avg Train Loss: 3.7593\n",
      "Epoch [1166/2000], Avg Val Loss: 2.4964\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7355\n",
      "Epoch [1167/2000], Avg Train Loss: 3.7355\n",
      "Epoch [1167/2000], Avg Val Loss: 2.4964\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7075\n",
      "Epoch [1168/2000], Avg Train Loss: 3.7075\n",
      "Epoch [1168/2000], Avg Val Loss: 2.4965\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1169/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7204\n",
      "Epoch [1169/2000], Avg Train Loss: 3.7204\n",
      "Epoch [1169/2000], Avg Val Loss: 2.4967\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7483\n",
      "Epoch [1170/2000], Avg Train Loss: 3.7483\n",
      "Epoch [1170/2000], Avg Val Loss: 2.4969\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7492\n",
      "Epoch [1171/2000], Avg Train Loss: 3.7492\n",
      "Epoch [1171/2000], Avg Val Loss: 2.4970\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7304\n",
      "Epoch [1172/2000], Avg Train Loss: 3.7304\n",
      "Epoch [1172/2000], Avg Val Loss: 2.4970\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7401\n",
      "Epoch [1173/2000], Avg Train Loss: 3.7401\n",
      "Epoch [1173/2000], Avg Val Loss: 2.4969\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7106\n",
      "Epoch [1174/2000], Avg Train Loss: 3.7106\n",
      "Epoch [1174/2000], Avg Val Loss: 2.4968\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7288\n",
      "Epoch [1175/2000], Avg Train Loss: 3.7288\n",
      "Epoch [1175/2000], Avg Val Loss: 2.4968\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7297\n",
      "Epoch [1176/2000], Avg Train Loss: 3.7297\n",
      "Epoch [1176/2000], Avg Val Loss: 2.4967\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7279\n",
      "Epoch [1177/2000], Avg Train Loss: 3.7279\n",
      "Epoch [1177/2000], Avg Val Loss: 2.4968\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7198\n",
      "Epoch [1178/2000], Avg Train Loss: 3.7198\n",
      "Epoch [1178/2000], Avg Val Loss: 2.4968\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6985\n",
      "Epoch [1179/2000], Avg Train Loss: 3.6985\n",
      "Epoch [1179/2000], Avg Val Loss: 2.4966\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1180/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7199\n",
      "Epoch [1180/2000], Avg Train Loss: 3.7199\n",
      "Epoch [1180/2000], Avg Val Loss: 2.4961\n",
      "Validation loss improved from 2.4963 to 2.4961. Saving model...\n",
      "\n",
      "LOG: Epoch [1181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7043\n",
      "Epoch [1181/2000], Avg Train Loss: 3.7043\n",
      "Epoch [1181/2000], Avg Val Loss: 2.4957\n",
      "Validation loss improved from 2.4961 to 2.4957. Saving model...\n",
      "\n",
      "LOG: Epoch [1182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7379\n",
      "Epoch [1182/2000], Avg Train Loss: 3.7379\n",
      "Epoch [1182/2000], Avg Val Loss: 2.4954\n",
      "Validation loss improved from 2.4957 to 2.4954. Saving model...\n",
      "\n",
      "LOG: Epoch [1183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7711\n",
      "Epoch [1183/2000], Avg Train Loss: 3.7711\n",
      "Epoch [1183/2000], Avg Val Loss: 2.4951\n",
      "Validation loss improved from 2.4954 to 2.4951. Saving model...\n",
      "\n",
      "LOG: Epoch [1184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7325\n",
      "Epoch [1184/2000], Avg Train Loss: 3.7325\n",
      "Epoch [1184/2000], Avg Val Loss: 2.4948\n",
      "Validation loss improved from 2.4951 to 2.4948. Saving model...\n",
      "\n",
      "LOG: Epoch [1185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7017\n",
      "Epoch [1185/2000], Avg Train Loss: 3.7017\n",
      "Epoch [1185/2000], Avg Val Loss: 2.4943\n",
      "Validation loss improved from 2.4948 to 2.4943. Saving model...\n",
      "\n",
      "LOG: Epoch [1186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7310\n",
      "Epoch [1186/2000], Avg Train Loss: 3.7310\n",
      "Epoch [1186/2000], Avg Val Loss: 2.4939\n",
      "Validation loss improved from 2.4943 to 2.4939. Saving model...\n",
      "\n",
      "LOG: Epoch [1187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7370\n",
      "Epoch [1187/2000], Avg Train Loss: 3.7370\n",
      "Epoch [1187/2000], Avg Val Loss: 2.4937\n",
      "Validation loss improved from 2.4939 to 2.4937. Saving model...\n",
      "\n",
      "LOG: Epoch [1188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7363\n",
      "Epoch [1188/2000], Avg Train Loss: 3.7363\n",
      "Epoch [1188/2000], Avg Val Loss: 2.4932\n",
      "Validation loss improved from 2.4937 to 2.4932. Saving model...\n",
      "\n",
      "LOG: Epoch [1189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7122\n",
      "Epoch [1189/2000], Avg Train Loss: 3.7122\n",
      "Epoch [1189/2000], Avg Val Loss: 2.4926\n",
      "Validation loss improved from 2.4932 to 2.4926. Saving model...\n",
      "\n",
      "LOG: Epoch [1190/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7067\n",
      "Epoch [1190/2000], Avg Train Loss: 3.7067\n",
      "Epoch [1190/2000], Avg Val Loss: 2.4920\n",
      "Validation loss improved from 2.4926 to 2.4920. Saving model...\n",
      "\n",
      "LOG: Epoch [1191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7392\n",
      "Epoch [1191/2000], Avg Train Loss: 3.7392\n",
      "Epoch [1191/2000], Avg Val Loss: 2.4914\n",
      "Validation loss improved from 2.4920 to 2.4914. Saving model...\n",
      "\n",
      "LOG: Epoch [1192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7436\n",
      "Epoch [1192/2000], Avg Train Loss: 3.7436\n",
      "Epoch [1192/2000], Avg Val Loss: 2.4908\n",
      "Validation loss improved from 2.4914 to 2.4908. Saving model...\n",
      "\n",
      "LOG: Epoch [1193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7441\n",
      "Epoch [1193/2000], Avg Train Loss: 3.7441\n",
      "Epoch [1193/2000], Avg Val Loss: 2.4902\n",
      "Validation loss improved from 2.4908 to 2.4902. Saving model...\n",
      "\n",
      "LOG: Epoch [1194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7114\n",
      "Epoch [1194/2000], Avg Train Loss: 3.7114\n",
      "Epoch [1194/2000], Avg Val Loss: 2.4896\n",
      "Validation loss improved from 2.4902 to 2.4896. Saving model...\n",
      "\n",
      "LOG: Epoch [1195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7343\n",
      "Epoch [1195/2000], Avg Train Loss: 3.7343\n",
      "Epoch [1195/2000], Avg Val Loss: 2.4890\n",
      "Validation loss improved from 2.4896 to 2.4890. Saving model...\n",
      "\n",
      "LOG: Epoch [1196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7407\n",
      "Epoch [1196/2000], Avg Train Loss: 3.7407\n",
      "Epoch [1196/2000], Avg Val Loss: 2.4887\n",
      "Validation loss improved from 2.4890 to 2.4887. Saving model...\n",
      "\n",
      "LOG: Epoch [1197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7091\n",
      "Epoch [1197/2000], Avg Train Loss: 3.7091\n",
      "Epoch [1197/2000], Avg Val Loss: 2.4883\n",
      "Validation loss improved from 2.4887 to 2.4883. Saving model...\n",
      "\n",
      "LOG: Epoch [1198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6957\n",
      "Epoch [1198/2000], Avg Train Loss: 3.6957\n",
      "Epoch [1198/2000], Avg Val Loss: 2.4881\n",
      "Validation loss improved from 2.4883 to 2.4881. Saving model...\n",
      "\n",
      "LOG: Epoch [1199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6769\n",
      "Epoch [1199/2000], Avg Train Loss: 3.6769\n",
      "Epoch [1199/2000], Avg Val Loss: 2.4878\n",
      "Validation loss improved from 2.4881 to 2.4878. Saving model...\n",
      "\n",
      "LOG: Epoch [1200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7044\n",
      "Epoch [1200/2000], Avg Train Loss: 3.7044\n",
      "Epoch [1200/2000], Avg Val Loss: 2.4877\n",
      "Validation loss improved from 2.4878 to 2.4877. Saving model...\n",
      "\n",
      "LOG: Epoch [1201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7749\n",
      "Epoch [1201/2000], Avg Train Loss: 3.7749\n",
      "Epoch [1201/2000], Avg Val Loss: 2.4875\n",
      "Validation loss improved from 2.4877 to 2.4875. Saving model...\n",
      "\n",
      "LOG: Epoch [1202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7387\n",
      "Epoch [1202/2000], Avg Train Loss: 3.7387\n",
      "Epoch [1202/2000], Avg Val Loss: 2.4874\n",
      "Validation loss improved from 2.4875 to 2.4874. Saving model...\n",
      "\n",
      "LOG: Epoch [1203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7071\n",
      "Epoch [1203/2000], Avg Train Loss: 3.7071\n",
      "Epoch [1203/2000], Avg Val Loss: 2.4872\n",
      "Validation loss improved from 2.4874 to 2.4872. Saving model...\n",
      "\n",
      "LOG: Epoch [1204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7426\n",
      "Epoch [1204/2000], Avg Train Loss: 3.7426\n",
      "Epoch [1204/2000], Avg Val Loss: 2.4871\n",
      "Validation loss improved from 2.4872 to 2.4871. Saving model...\n",
      "\n",
      "LOG: Epoch [1205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7273\n",
      "Epoch [1205/2000], Avg Train Loss: 3.7273\n",
      "Epoch [1205/2000], Avg Val Loss: 2.4869\n",
      "Validation loss improved from 2.4871 to 2.4869. Saving model...\n",
      "\n",
      "LOG: Epoch [1206/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7001\n",
      "Epoch [1206/2000], Avg Train Loss: 3.7001\n",
      "Epoch [1206/2000], Avg Val Loss: 2.4867\n",
      "Validation loss improved from 2.4869 to 2.4867. Saving model...\n",
      "\n",
      "LOG: Epoch [1207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6761\n",
      "Epoch [1207/2000], Avg Train Loss: 3.6761\n",
      "Epoch [1207/2000], Avg Val Loss: 2.4863\n",
      "Validation loss improved from 2.4867 to 2.4863. Saving model...\n",
      "\n",
      "LOG: Epoch [1208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7444\n",
      "Epoch [1208/2000], Avg Train Loss: 3.7444\n",
      "Epoch [1208/2000], Avg Val Loss: 2.4862\n",
      "Validation loss improved from 2.4863 to 2.4862. Saving model...\n",
      "\n",
      "LOG: Epoch [1209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7153\n",
      "Epoch [1209/2000], Avg Train Loss: 3.7153\n",
      "Epoch [1209/2000], Avg Val Loss: 2.4861\n",
      "Validation loss improved from 2.4862 to 2.4861. Saving model...\n",
      "\n",
      "LOG: Epoch [1210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7104\n",
      "Epoch [1210/2000], Avg Train Loss: 3.7104\n",
      "Epoch [1210/2000], Avg Val Loss: 2.4859\n",
      "Validation loss improved from 2.4861 to 2.4859. Saving model...\n",
      "\n",
      "LOG: Epoch [1211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7098\n",
      "Epoch [1211/2000], Avg Train Loss: 3.7098\n",
      "Epoch [1211/2000], Avg Val Loss: 2.4857\n",
      "Validation loss improved from 2.4859 to 2.4857. Saving model...\n",
      "\n",
      "LOG: Epoch [1212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7084\n",
      "Epoch [1212/2000], Avg Train Loss: 3.7084\n",
      "Epoch [1212/2000], Avg Val Loss: 2.4855\n",
      "Validation loss improved from 2.4857 to 2.4855. Saving model...\n",
      "\n",
      "LOG: Epoch [1213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7310\n",
      "Epoch [1213/2000], Avg Train Loss: 3.7310\n",
      "Epoch [1213/2000], Avg Val Loss: 2.4851\n",
      "Validation loss improved from 2.4855 to 2.4851. Saving model...\n",
      "\n",
      "LOG: Epoch [1214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7353\n",
      "Epoch [1214/2000], Avg Train Loss: 3.7353\n",
      "Epoch [1214/2000], Avg Val Loss: 2.4846\n",
      "Validation loss improved from 2.4851 to 2.4846. Saving model...\n",
      "\n",
      "LOG: Epoch [1215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6855\n",
      "Epoch [1215/2000], Avg Train Loss: 3.6855\n",
      "Epoch [1215/2000], Avg Val Loss: 2.4839\n",
      "Validation loss improved from 2.4846 to 2.4839. Saving model...\n",
      "\n",
      "LOG: Epoch [1216/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7333\n",
      "Epoch [1216/2000], Avg Train Loss: 3.7333\n",
      "Epoch [1216/2000], Avg Val Loss: 2.4830\n",
      "Validation loss improved from 2.4839 to 2.4830. Saving model...\n",
      "\n",
      "LOG: Epoch [1217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6906\n",
      "Epoch [1217/2000], Avg Train Loss: 3.6906\n",
      "Epoch [1217/2000], Avg Val Loss: 2.4822\n",
      "Validation loss improved from 2.4830 to 2.4822. Saving model...\n",
      "\n",
      "LOG: Epoch [1218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6812\n",
      "Epoch [1218/2000], Avg Train Loss: 3.6812\n",
      "Epoch [1218/2000], Avg Val Loss: 2.4814\n",
      "Validation loss improved from 2.4822 to 2.4814. Saving model...\n",
      "\n",
      "LOG: Epoch [1219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7679\n",
      "Epoch [1219/2000], Avg Train Loss: 3.7679\n",
      "Epoch [1219/2000], Avg Val Loss: 2.4808\n",
      "Validation loss improved from 2.4814 to 2.4808. Saving model...\n",
      "\n",
      "LOG: Epoch [1220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7112\n",
      "Epoch [1220/2000], Avg Train Loss: 3.7112\n",
      "Epoch [1220/2000], Avg Val Loss: 2.4802\n",
      "Validation loss improved from 2.4808 to 2.4802. Saving model...\n",
      "\n",
      "LOG: Epoch [1221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7091\n",
      "Epoch [1221/2000], Avg Train Loss: 3.7091\n",
      "Epoch [1221/2000], Avg Val Loss: 2.4796\n",
      "Validation loss improved from 2.4802 to 2.4796. Saving model...\n",
      "\n",
      "LOG: Epoch [1222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7354\n",
      "Epoch [1222/2000], Avg Train Loss: 3.7354\n",
      "Epoch [1222/2000], Avg Val Loss: 2.4791\n",
      "Validation loss improved from 2.4796 to 2.4791. Saving model...\n",
      "\n",
      "LOG: Epoch [1223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6729\n",
      "Epoch [1223/2000], Avg Train Loss: 3.6729\n",
      "Epoch [1223/2000], Avg Val Loss: 2.4786\n",
      "Validation loss improved from 2.4791 to 2.4786. Saving model...\n",
      "\n",
      "LOG: Epoch [1224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7308\n",
      "Epoch [1224/2000], Avg Train Loss: 3.7308\n",
      "Epoch [1224/2000], Avg Val Loss: 2.4781\n",
      "Validation loss improved from 2.4786 to 2.4781. Saving model...\n",
      "\n",
      "LOG: Epoch [1225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6971\n",
      "Epoch [1225/2000], Avg Train Loss: 3.6971\n",
      "Epoch [1225/2000], Avg Val Loss: 2.4774\n",
      "Validation loss improved from 2.4781 to 2.4774. Saving model...\n",
      "\n",
      "LOG: Epoch [1226/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6797\n",
      "Epoch [1226/2000], Avg Train Loss: 3.6797\n",
      "Epoch [1226/2000], Avg Val Loss: 2.4767\n",
      "Validation loss improved from 2.4774 to 2.4767. Saving model...\n",
      "\n",
      "LOG: Epoch [1227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7141\n",
      "Epoch [1227/2000], Avg Train Loss: 3.7141\n",
      "Epoch [1227/2000], Avg Val Loss: 2.4763\n",
      "Validation loss improved from 2.4767 to 2.4763. Saving model...\n",
      "\n",
      "LOG: Epoch [1228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6728\n",
      "Epoch [1228/2000], Avg Train Loss: 3.6728\n",
      "Epoch [1228/2000], Avg Val Loss: 2.4757\n",
      "Validation loss improved from 2.4763 to 2.4757. Saving model...\n",
      "\n",
      "LOG: Epoch [1229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7164\n",
      "Epoch [1229/2000], Avg Train Loss: 3.7164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1229/2000], Avg Val Loss: 2.4755\n",
      "Validation loss improved from 2.4757 to 2.4755. Saving model...\n",
      "\n",
      "LOG: Epoch [1230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7163\n",
      "Epoch [1230/2000], Avg Train Loss: 3.7163\n",
      "Epoch [1230/2000], Avg Val Loss: 2.4754\n",
      "Validation loss improved from 2.4755 to 2.4754. Saving model...\n",
      "\n",
      "LOG: Epoch [1231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6652\n",
      "Epoch [1231/2000], Avg Train Loss: 3.6652\n",
      "Epoch [1231/2000], Avg Val Loss: 2.4752\n",
      "Validation loss improved from 2.4754 to 2.4752. Saving model...\n",
      "\n",
      "LOG: Epoch [1232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6582\n",
      "Epoch [1232/2000], Avg Train Loss: 3.6582\n",
      "Epoch [1232/2000], Avg Val Loss: 2.4753\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7013\n",
      "Epoch [1233/2000], Avg Train Loss: 3.7013\n",
      "Epoch [1233/2000], Avg Val Loss: 2.4751\n",
      "Validation loss improved from 2.4752 to 2.4751. Saving model...\n",
      "\n",
      "LOG: Epoch [1234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7500\n",
      "Epoch [1234/2000], Avg Train Loss: 3.7500\n",
      "Epoch [1234/2000], Avg Val Loss: 2.4751\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1235/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7073\n",
      "Epoch [1235/2000], Avg Train Loss: 3.7073\n",
      "Epoch [1235/2000], Avg Val Loss: 2.4751\n",
      "Validation loss improved from 2.4751 to 2.4751. Saving model...\n",
      "\n",
      "LOG: Epoch [1236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7655\n",
      "Epoch [1236/2000], Avg Train Loss: 3.7655\n",
      "Epoch [1236/2000], Avg Val Loss: 2.4753\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6826\n",
      "Epoch [1237/2000], Avg Train Loss: 3.6826\n",
      "Epoch [1237/2000], Avg Val Loss: 2.4753\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6527\n",
      "Epoch [1238/2000], Avg Train Loss: 3.6527\n",
      "Epoch [1238/2000], Avg Val Loss: 2.4753\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6941\n",
      "Epoch [1239/2000], Avg Train Loss: 3.6941\n",
      "Epoch [1239/2000], Avg Val Loss: 2.4755\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6804\n",
      "Epoch [1240/2000], Avg Train Loss: 3.6804\n",
      "Epoch [1240/2000], Avg Val Loss: 2.4757\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7338\n",
      "Epoch [1241/2000], Avg Train Loss: 3.7338\n",
      "Epoch [1241/2000], Avg Val Loss: 2.4758\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7008\n",
      "Epoch [1242/2000], Avg Train Loss: 3.7008\n",
      "Epoch [1242/2000], Avg Val Loss: 2.4758\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1243/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7029\n",
      "Epoch [1243/2000], Avg Train Loss: 3.7029\n",
      "Epoch [1243/2000], Avg Val Loss: 2.4758\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6901\n",
      "Epoch [1244/2000], Avg Train Loss: 3.6901\n",
      "Epoch [1244/2000], Avg Val Loss: 2.4758\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6884\n",
      "Epoch [1245/2000], Avg Train Loss: 3.6884\n",
      "Epoch [1245/2000], Avg Val Loss: 2.4758\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1246/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6770\n",
      "Epoch [1246/2000], Avg Train Loss: 3.6770\n",
      "Epoch [1246/2000], Avg Val Loss: 2.4759\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6612\n",
      "Epoch [1247/2000], Avg Train Loss: 3.6612\n",
      "Epoch [1247/2000], Avg Val Loss: 2.4757\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1248/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6751\n",
      "Epoch [1248/2000], Avg Train Loss: 3.6751\n",
      "Epoch [1248/2000], Avg Val Loss: 2.4755\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6819\n",
      "Epoch [1249/2000], Avg Train Loss: 3.6819\n",
      "Epoch [1249/2000], Avg Val Loss: 2.4752\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6719\n",
      "Epoch [1250/2000], Avg Train Loss: 3.6719\n",
      "Epoch [1250/2000], Avg Val Loss: 2.4749\n",
      "Validation loss improved from 2.4751 to 2.4749. Saving model...\n",
      "\n",
      "LOG: Epoch [1251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6794\n",
      "Epoch [1251/2000], Avg Train Loss: 3.6794\n",
      "Epoch [1251/2000], Avg Val Loss: 2.4748\n",
      "Validation loss improved from 2.4749 to 2.4748. Saving model...\n",
      "\n",
      "LOG: Epoch [1252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6847\n",
      "Epoch [1252/2000], Avg Train Loss: 3.6847\n",
      "Epoch [1252/2000], Avg Val Loss: 2.4748\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6970\n",
      "Epoch [1253/2000], Avg Train Loss: 3.6970\n",
      "Epoch [1253/2000], Avg Val Loss: 2.4747\n",
      "Validation loss improved from 2.4748 to 2.4747. Saving model...\n",
      "\n",
      "LOG: Epoch [1254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7327\n",
      "Epoch [1254/2000], Avg Train Loss: 3.7327\n",
      "Epoch [1254/2000], Avg Val Loss: 2.4745\n",
      "Validation loss improved from 2.4747 to 2.4745. Saving model...\n",
      "\n",
      "LOG: Epoch [1255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7075\n",
      "Epoch [1255/2000], Avg Train Loss: 3.7075\n",
      "Epoch [1255/2000], Avg Val Loss: 2.4741\n",
      "Validation loss improved from 2.4745 to 2.4741. Saving model...\n",
      "\n",
      "LOG: Epoch [1256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7013\n",
      "Epoch [1256/2000], Avg Train Loss: 3.7013\n",
      "Epoch [1256/2000], Avg Val Loss: 2.4736\n",
      "Validation loss improved from 2.4741 to 2.4736. Saving model...\n",
      "\n",
      "LOG: Epoch [1257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6810\n",
      "Epoch [1257/2000], Avg Train Loss: 3.6810\n",
      "Epoch [1257/2000], Avg Val Loss: 2.4734\n",
      "Validation loss improved from 2.4736 to 2.4734. Saving model...\n",
      "\n",
      "LOG: Epoch [1258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6898\n",
      "Epoch [1258/2000], Avg Train Loss: 3.6898\n",
      "Epoch [1258/2000], Avg Val Loss: 2.4733\n",
      "Validation loss improved from 2.4734 to 2.4733. Saving model...\n",
      "\n",
      "LOG: Epoch [1259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6728\n",
      "Epoch [1259/2000], Avg Train Loss: 3.6728\n",
      "Epoch [1259/2000], Avg Val Loss: 2.4732\n",
      "Validation loss improved from 2.4733 to 2.4732. Saving model...\n",
      "\n",
      "LOG: Epoch [1260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7288\n",
      "Epoch [1260/2000], Avg Train Loss: 3.7288\n",
      "Epoch [1260/2000], Avg Val Loss: 2.4734\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7157\n",
      "Epoch [1261/2000], Avg Train Loss: 3.7157\n",
      "Epoch [1261/2000], Avg Val Loss: 2.4733\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6708\n",
      "Epoch [1262/2000], Avg Train Loss: 3.6708\n",
      "Epoch [1262/2000], Avg Val Loss: 2.4730\n",
      "Validation loss improved from 2.4732 to 2.4730. Saving model...\n",
      "\n",
      "LOG: Epoch [1263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6999\n",
      "Epoch [1263/2000], Avg Train Loss: 3.6999\n",
      "Epoch [1263/2000], Avg Val Loss: 2.4729\n",
      "Validation loss improved from 2.4730 to 2.4729. Saving model...\n",
      "\n",
      "LOG: Epoch [1264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7127\n",
      "Epoch [1264/2000], Avg Train Loss: 3.7127\n",
      "Epoch [1264/2000], Avg Val Loss: 2.4727\n",
      "Validation loss improved from 2.4729 to 2.4727. Saving model...\n",
      "\n",
      "LOG: Epoch [1265/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6426\n",
      "Epoch [1265/2000], Avg Train Loss: 3.6426\n",
      "Epoch [1265/2000], Avg Val Loss: 2.4725\n",
      "Validation loss improved from 2.4727 to 2.4725. Saving model...\n",
      "\n",
      "LOG: Epoch [1266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6731\n",
      "Epoch [1266/2000], Avg Train Loss: 3.6731\n",
      "Epoch [1266/2000], Avg Val Loss: 2.4724\n",
      "Validation loss improved from 2.4725 to 2.4724. Saving model...\n",
      "\n",
      "LOG: Epoch [1267/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6843\n",
      "Epoch [1267/2000], Avg Train Loss: 3.6843\n",
      "Epoch [1267/2000], Avg Val Loss: 2.4722\n",
      "Validation loss improved from 2.4724 to 2.4722. Saving model...\n",
      "\n",
      "LOG: Epoch [1268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7086\n",
      "Epoch [1268/2000], Avg Train Loss: 3.7086\n",
      "Epoch [1268/2000], Avg Val Loss: 2.4721\n",
      "Validation loss improved from 2.4722 to 2.4721. Saving model...\n",
      "\n",
      "LOG: Epoch [1269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6821\n",
      "Epoch [1269/2000], Avg Train Loss: 3.6821\n",
      "Epoch [1269/2000], Avg Val Loss: 2.4719\n",
      "Validation loss improved from 2.4721 to 2.4719. Saving model...\n",
      "\n",
      "LOG: Epoch [1270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7098\n",
      "Epoch [1270/2000], Avg Train Loss: 3.7098\n",
      "Epoch [1270/2000], Avg Val Loss: 2.4719\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7125\n",
      "Epoch [1271/2000], Avg Train Loss: 3.7125\n",
      "Epoch [1271/2000], Avg Val Loss: 2.4719\n",
      "Validation loss improved from 2.4719 to 2.4719. Saving model...\n",
      "\n",
      "LOG: Epoch [1272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6820\n",
      "Epoch [1272/2000], Avg Train Loss: 3.6820\n",
      "Epoch [1272/2000], Avg Val Loss: 2.4719\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6408\n",
      "Epoch [1273/2000], Avg Train Loss: 3.6408\n",
      "Epoch [1273/2000], Avg Val Loss: 2.4717\n",
      "Validation loss improved from 2.4719 to 2.4717. Saving model...\n",
      "\n",
      "LOG: Epoch [1274/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6646\n",
      "Epoch [1274/2000], Avg Train Loss: 3.6646\n",
      "Epoch [1274/2000], Avg Val Loss: 2.4715\n",
      "Validation loss improved from 2.4717 to 2.4715. Saving model...\n",
      "\n",
      "LOG: Epoch [1275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6590\n",
      "Epoch [1275/2000], Avg Train Loss: 3.6590\n",
      "Epoch [1275/2000], Avg Val Loss: 2.4712\n",
      "Validation loss improved from 2.4715 to 2.4712. Saving model...\n",
      "\n",
      "LOG: Epoch [1276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6993\n",
      "Epoch [1276/2000], Avg Train Loss: 3.6993\n",
      "Epoch [1276/2000], Avg Val Loss: 2.4709\n",
      "Validation loss improved from 2.4712 to 2.4709. Saving model...\n",
      "\n",
      "LOG: Epoch [1277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6919\n",
      "Epoch [1277/2000], Avg Train Loss: 3.6919\n",
      "Epoch [1277/2000], Avg Val Loss: 2.4706\n",
      "Validation loss improved from 2.4709 to 2.4706. Saving model...\n",
      "\n",
      "LOG: Epoch [1278/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6284\n",
      "Epoch [1278/2000], Avg Train Loss: 3.6284\n",
      "Epoch [1278/2000], Avg Val Loss: 2.4705\n",
      "Validation loss improved from 2.4706 to 2.4705. Saving model...\n",
      "\n",
      "LOG: Epoch [1279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6247\n",
      "Epoch [1279/2000], Avg Train Loss: 3.6247\n",
      "Epoch [1279/2000], Avg Val Loss: 2.4702\n",
      "Validation loss improved from 2.4705 to 2.4702. Saving model...\n",
      "\n",
      "LOG: Epoch [1280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6553\n",
      "Epoch [1280/2000], Avg Train Loss: 3.6553\n",
      "Epoch [1280/2000], Avg Val Loss: 2.4698\n",
      "Validation loss improved from 2.4702 to 2.4698. Saving model...\n",
      "\n",
      "LOG: Epoch [1281/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6718\n",
      "Epoch [1281/2000], Avg Train Loss: 3.6718\n",
      "Epoch [1281/2000], Avg Val Loss: 2.4697\n",
      "Validation loss improved from 2.4698 to 2.4697. Saving model...\n",
      "\n",
      "LOG: Epoch [1282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6852\n",
      "Epoch [1282/2000], Avg Train Loss: 3.6852\n",
      "Epoch [1282/2000], Avg Val Loss: 2.4696\n",
      "Validation loss improved from 2.4697 to 2.4696. Saving model...\n",
      "\n",
      "LOG: Epoch [1283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6821\n",
      "Epoch [1283/2000], Avg Train Loss: 3.6821\n",
      "Epoch [1283/2000], Avg Val Loss: 2.4694\n",
      "Validation loss improved from 2.4696 to 2.4694. Saving model...\n",
      "\n",
      "LOG: Epoch [1284/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6871\n",
      "Epoch [1284/2000], Avg Train Loss: 3.6871\n",
      "Epoch [1284/2000], Avg Val Loss: 2.4693\n",
      "Validation loss improved from 2.4694 to 2.4693. Saving model...\n",
      "\n",
      "LOG: Epoch [1285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6510\n",
      "Epoch [1285/2000], Avg Train Loss: 3.6510\n",
      "Epoch [1285/2000], Avg Val Loss: 2.4691\n",
      "Validation loss improved from 2.4693 to 2.4691. Saving model...\n",
      "\n",
      "LOG: Epoch [1286/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7232\n",
      "Epoch [1286/2000], Avg Train Loss: 3.7232\n",
      "Epoch [1286/2000], Avg Val Loss: 2.4691\n",
      "Validation loss improved from 2.4691 to 2.4691. Saving model...\n",
      "\n",
      "LOG: Epoch [1287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6603\n",
      "Epoch [1287/2000], Avg Train Loss: 3.6603\n",
      "Epoch [1287/2000], Avg Val Loss: 2.4689\n",
      "Validation loss improved from 2.4691 to 2.4689. Saving model...\n",
      "\n",
      "LOG: Epoch [1288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6433\n",
      "Epoch [1288/2000], Avg Train Loss: 3.6433\n",
      "Epoch [1288/2000], Avg Val Loss: 2.4686\n",
      "Validation loss improved from 2.4689 to 2.4686. Saving model...\n",
      "\n",
      "LOG: Epoch [1289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6915\n",
      "Epoch [1289/2000], Avg Train Loss: 3.6915\n",
      "Epoch [1289/2000], Avg Val Loss: 2.4685\n",
      "Validation loss improved from 2.4686 to 2.4685. Saving model...\n",
      "\n",
      "LOG: Epoch [1290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6548\n",
      "Epoch [1290/2000], Avg Train Loss: 3.6548\n",
      "Epoch [1290/2000], Avg Val Loss: 2.4683\n",
      "Validation loss improved from 2.4685 to 2.4683. Saving model...\n",
      "\n",
      "LOG: Epoch [1291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6468\n",
      "Epoch [1291/2000], Avg Train Loss: 3.6468\n",
      "Epoch [1291/2000], Avg Val Loss: 2.4683\n",
      "Validation loss improved from 2.4683 to 2.4683. Saving model...\n",
      "\n",
      "LOG: Epoch [1292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6651\n",
      "Epoch [1292/2000], Avg Train Loss: 3.6651\n",
      "Epoch [1292/2000], Avg Val Loss: 2.4682\n",
      "Validation loss improved from 2.4683 to 2.4682. Saving model...\n",
      "\n",
      "LOG: Epoch [1293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6471\n",
      "Epoch [1293/2000], Avg Train Loss: 3.6471\n",
      "Epoch [1293/2000], Avg Val Loss: 2.4680\n",
      "Validation loss improved from 2.4682 to 2.4680. Saving model...\n",
      "\n",
      "LOG: Epoch [1294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6360\n",
      "Epoch [1294/2000], Avg Train Loss: 3.6360\n",
      "Epoch [1294/2000], Avg Val Loss: 2.4676\n",
      "Validation loss improved from 2.4680 to 2.4676. Saving model...\n",
      "\n",
      "LOG: Epoch [1295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6419\n",
      "Epoch [1295/2000], Avg Train Loss: 3.6419\n",
      "Epoch [1295/2000], Avg Val Loss: 2.4671\n",
      "Validation loss improved from 2.4676 to 2.4671. Saving model...\n",
      "\n",
      "LOG: Epoch [1296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6570\n",
      "Epoch [1296/2000], Avg Train Loss: 3.6570\n",
      "Epoch [1296/2000], Avg Val Loss: 2.4665\n",
      "Validation loss improved from 2.4671 to 2.4665. Saving model...\n",
      "\n",
      "LOG: Epoch [1297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6499\n",
      "Epoch [1297/2000], Avg Train Loss: 3.6499\n",
      "Epoch [1297/2000], Avg Val Loss: 2.4659\n",
      "Validation loss improved from 2.4665 to 2.4659. Saving model...\n",
      "\n",
      "LOG: Epoch [1298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6669\n",
      "Epoch [1298/2000], Avg Train Loss: 3.6669\n",
      "Epoch [1298/2000], Avg Val Loss: 2.4656\n",
      "Validation loss improved from 2.4659 to 2.4656. Saving model...\n",
      "\n",
      "LOG: Epoch [1299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6533\n",
      "Epoch [1299/2000], Avg Train Loss: 3.6533\n",
      "Epoch [1299/2000], Avg Val Loss: 2.4651\n",
      "Validation loss improved from 2.4656 to 2.4651. Saving model...\n",
      "\n",
      "LOG: Epoch [1300/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6442\n",
      "Epoch [1300/2000], Avg Train Loss: 3.6442\n",
      "Epoch [1300/2000], Avg Val Loss: 2.4647\n",
      "Validation loss improved from 2.4651 to 2.4647. Saving model...\n",
      "\n",
      "LOG: Epoch [1301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6650\n",
      "Epoch [1301/2000], Avg Train Loss: 3.6650\n",
      "Epoch [1301/2000], Avg Val Loss: 2.4643\n",
      "Validation loss improved from 2.4647 to 2.4643. Saving model...\n",
      "\n",
      "LOG: Epoch [1302/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6588\n",
      "Epoch [1302/2000], Avg Train Loss: 3.6588\n",
      "Epoch [1302/2000], Avg Val Loss: 2.4639\n",
      "Validation loss improved from 2.4643 to 2.4639. Saving model...\n",
      "\n",
      "LOG: Epoch [1303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6983\n",
      "Epoch [1303/2000], Avg Train Loss: 3.6983\n",
      "Epoch [1303/2000], Avg Val Loss: 2.4636\n",
      "Validation loss improved from 2.4639 to 2.4636. Saving model...\n",
      "\n",
      "LOG: Epoch [1304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6593\n",
      "Epoch [1304/2000], Avg Train Loss: 3.6593\n",
      "Epoch [1304/2000], Avg Val Loss: 2.4633\n",
      "Validation loss improved from 2.4636 to 2.4633. Saving model...\n",
      "\n",
      "LOG: Epoch [1305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6404\n",
      "Epoch [1305/2000], Avg Train Loss: 3.6404\n",
      "Epoch [1305/2000], Avg Val Loss: 2.4630\n",
      "Validation loss improved from 2.4633 to 2.4630. Saving model...\n",
      "\n",
      "LOG: Epoch [1306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6603\n",
      "Epoch [1306/2000], Avg Train Loss: 3.6603\n",
      "Epoch [1306/2000], Avg Val Loss: 2.4629\n",
      "Validation loss improved from 2.4630 to 2.4629. Saving model...\n",
      "\n",
      "LOG: Epoch [1307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6359\n",
      "Epoch [1307/2000], Avg Train Loss: 3.6359\n",
      "Epoch [1307/2000], Avg Val Loss: 2.4627\n",
      "Validation loss improved from 2.4629 to 2.4627. Saving model...\n",
      "\n",
      "LOG: Epoch [1308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6802\n",
      "Epoch [1308/2000], Avg Train Loss: 3.6802\n",
      "Epoch [1308/2000], Avg Val Loss: 2.4626\n",
      "Validation loss improved from 2.4627 to 2.4626. Saving model...\n",
      "\n",
      "LOG: Epoch [1309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7000\n",
      "Epoch [1309/2000], Avg Train Loss: 3.7000\n",
      "Epoch [1309/2000], Avg Val Loss: 2.4627\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6452\n",
      "Epoch [1310/2000], Avg Train Loss: 3.6452\n",
      "Epoch [1310/2000], Avg Val Loss: 2.4626\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6870\n",
      "Epoch [1311/2000], Avg Train Loss: 3.6870\n",
      "Epoch [1311/2000], Avg Val Loss: 2.4626\n",
      "Validation loss improved from 2.4626 to 2.4626. Saving model...\n",
      "\n",
      "LOG: Epoch [1312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6402\n",
      "Epoch [1312/2000], Avg Train Loss: 3.6402\n",
      "Epoch [1312/2000], Avg Val Loss: 2.4627\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1313/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6624\n",
      "Epoch [1313/2000], Avg Train Loss: 3.6624\n",
      "Epoch [1313/2000], Avg Val Loss: 2.4627\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6847\n",
      "Epoch [1314/2000], Avg Train Loss: 3.6847\n",
      "Epoch [1314/2000], Avg Val Loss: 2.4627\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1315/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6771\n",
      "Epoch [1315/2000], Avg Train Loss: 3.6771\n",
      "Epoch [1315/2000], Avg Val Loss: 2.4627\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6473\n",
      "Epoch [1316/2000], Avg Train Loss: 3.6473\n",
      "Epoch [1316/2000], Avg Val Loss: 2.4626\n",
      "Validation loss improved from 2.4626 to 2.4626. Saving model...\n",
      "\n",
      "LOG: Epoch [1317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6294\n",
      "Epoch [1317/2000], Avg Train Loss: 3.6294\n",
      "Epoch [1317/2000], Avg Val Loss: 2.4624\n",
      "Validation loss improved from 2.4626 to 2.4624. Saving model...\n",
      "\n",
      "LOG: Epoch [1318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6510\n",
      "Epoch [1318/2000], Avg Train Loss: 3.6510\n",
      "Epoch [1318/2000], Avg Val Loss: 2.4623\n",
      "Validation loss improved from 2.4624 to 2.4623. Saving model...\n",
      "\n",
      "LOG: Epoch [1319/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6407\n",
      "Epoch [1319/2000], Avg Train Loss: 3.6407\n",
      "Epoch [1319/2000], Avg Val Loss: 2.4622\n",
      "Validation loss improved from 2.4623 to 2.4622. Saving model...\n",
      "\n",
      "LOG: Epoch [1320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6666\n",
      "Epoch [1320/2000], Avg Train Loss: 3.6666\n",
      "Epoch [1320/2000], Avg Val Loss: 2.4621\n",
      "Validation loss improved from 2.4622 to 2.4621. Saving model...\n",
      "\n",
      "LOG: Epoch [1321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6369\n",
      "Epoch [1321/2000], Avg Train Loss: 3.6369\n",
      "Epoch [1321/2000], Avg Val Loss: 2.4620\n",
      "Validation loss improved from 2.4621 to 2.4620. Saving model...\n",
      "\n",
      "LOG: Epoch [1322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6459\n",
      "Epoch [1322/2000], Avg Train Loss: 3.6459\n",
      "Epoch [1322/2000], Avg Val Loss: 2.4620\n",
      "Validation loss improved from 2.4620 to 2.4620. Saving model...\n",
      "\n",
      "LOG: Epoch [1323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6639\n",
      "Epoch [1323/2000], Avg Train Loss: 3.6639\n",
      "Epoch [1323/2000], Avg Val Loss: 2.4620\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6310\n",
      "Epoch [1324/2000], Avg Train Loss: 3.6310\n",
      "Epoch [1324/2000], Avg Val Loss: 2.4621\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6620\n",
      "Epoch [1325/2000], Avg Train Loss: 3.6620\n",
      "Epoch [1325/2000], Avg Val Loss: 2.4623\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6266\n",
      "Epoch [1326/2000], Avg Train Loss: 3.6266\n",
      "Epoch [1326/2000], Avg Val Loss: 2.4624\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6592\n",
      "Epoch [1327/2000], Avg Train Loss: 3.6592\n",
      "Epoch [1327/2000], Avg Val Loss: 2.4624\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6376\n",
      "Epoch [1328/2000], Avg Train Loss: 3.6376\n",
      "Epoch [1328/2000], Avg Val Loss: 2.4622\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6278\n",
      "Epoch [1329/2000], Avg Train Loss: 3.6278\n",
      "Epoch [1329/2000], Avg Val Loss: 2.4621\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6507\n",
      "Epoch [1330/2000], Avg Train Loss: 3.6507\n",
      "Epoch [1330/2000], Avg Val Loss: 2.4621\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6479\n",
      "Epoch [1331/2000], Avg Train Loss: 3.6479\n",
      "Epoch [1331/2000], Avg Val Loss: 2.4620\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6328\n",
      "Epoch [1332/2000], Avg Train Loss: 3.6328\n",
      "Epoch [1332/2000], Avg Val Loss: 2.4620\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6345\n",
      "Epoch [1333/2000], Avg Train Loss: 3.6345\n",
      "Epoch [1333/2000], Avg Val Loss: 2.4620\n",
      "Validation loss improved from 2.4620 to 2.4620. Saving model...\n",
      "\n",
      "LOG: Epoch [1334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6567\n",
      "Epoch [1334/2000], Avg Train Loss: 3.6567\n",
      "Epoch [1334/2000], Avg Val Loss: 2.4618\n",
      "Validation loss improved from 2.4620 to 2.4618. Saving model...\n",
      "\n",
      "LOG: Epoch [1335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6224\n",
      "Epoch [1335/2000], Avg Train Loss: 3.6224\n",
      "Epoch [1335/2000], Avg Val Loss: 2.4617\n",
      "Validation loss improved from 2.4618 to 2.4617. Saving model...\n",
      "\n",
      "LOG: Epoch [1336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6205\n",
      "Epoch [1336/2000], Avg Train Loss: 3.6205\n",
      "Epoch [1336/2000], Avg Val Loss: 2.4615\n",
      "Validation loss improved from 2.4617 to 2.4615. Saving model...\n",
      "\n",
      "LOG: Epoch [1337/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6352\n",
      "Epoch [1337/2000], Avg Train Loss: 3.6352\n",
      "Epoch [1337/2000], Avg Val Loss: 2.4613\n",
      "Validation loss improved from 2.4615 to 2.4613. Saving model...\n",
      "\n",
      "LOG: Epoch [1338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6288\n",
      "Epoch [1338/2000], Avg Train Loss: 3.6288\n",
      "Epoch [1338/2000], Avg Val Loss: 2.4607\n",
      "Validation loss improved from 2.4613 to 2.4607. Saving model...\n",
      "\n",
      "LOG: Epoch [1339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6534\n",
      "Epoch [1339/2000], Avg Train Loss: 3.6534\n",
      "Epoch [1339/2000], Avg Val Loss: 2.4602\n",
      "Validation loss improved from 2.4607 to 2.4602. Saving model...\n",
      "\n",
      "LOG: Epoch [1340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6388\n",
      "Epoch [1340/2000], Avg Train Loss: 3.6388\n",
      "Epoch [1340/2000], Avg Val Loss: 2.4598\n",
      "Validation loss improved from 2.4602 to 2.4598. Saving model...\n",
      "\n",
      "LOG: Epoch [1341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6695\n",
      "Epoch [1341/2000], Avg Train Loss: 3.6695\n",
      "Epoch [1341/2000], Avg Val Loss: 2.4593\n",
      "Validation loss improved from 2.4598 to 2.4593. Saving model...\n",
      "\n",
      "LOG: Epoch [1342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6505\n",
      "Epoch [1342/2000], Avg Train Loss: 3.6505\n",
      "Epoch [1342/2000], Avg Val Loss: 2.4589\n",
      "Validation loss improved from 2.4593 to 2.4589. Saving model...\n",
      "\n",
      "LOG: Epoch [1343/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6494\n",
      "Epoch [1343/2000], Avg Train Loss: 3.6494\n",
      "Epoch [1343/2000], Avg Val Loss: 2.4584\n",
      "Validation loss improved from 2.4589 to 2.4584. Saving model...\n",
      "\n",
      "LOG: Epoch [1344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6508\n",
      "Epoch [1344/2000], Avg Train Loss: 3.6508\n",
      "Epoch [1344/2000], Avg Val Loss: 2.4582\n",
      "Validation loss improved from 2.4584 to 2.4582. Saving model...\n",
      "\n",
      "LOG: Epoch [1345/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6730\n",
      "Epoch [1345/2000], Avg Train Loss: 3.6730\n",
      "Epoch [1345/2000], Avg Val Loss: 2.4581\n",
      "Validation loss improved from 2.4582 to 2.4581. Saving model...\n",
      "\n",
      "LOG: Epoch [1346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6417\n",
      "Epoch [1346/2000], Avg Train Loss: 3.6417\n",
      "Epoch [1346/2000], Avg Val Loss: 2.4581\n",
      "Validation loss improved from 2.4581 to 2.4581. Saving model...\n",
      "\n",
      "LOG: Epoch [1347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6763\n",
      "Epoch [1347/2000], Avg Train Loss: 3.6763\n",
      "Epoch [1347/2000], Avg Val Loss: 2.4582\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6206\n",
      "Epoch [1348/2000], Avg Train Loss: 3.6206\n",
      "Epoch [1348/2000], Avg Val Loss: 2.4583\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6554\n",
      "Epoch [1349/2000], Avg Train Loss: 3.6554\n",
      "Epoch [1349/2000], Avg Val Loss: 2.4582\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6234\n",
      "Epoch [1350/2000], Avg Train Loss: 3.6234\n",
      "Epoch [1350/2000], Avg Val Loss: 2.4583\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6953\n",
      "Epoch [1351/2000], Avg Train Loss: 3.6953\n",
      "Epoch [1351/2000], Avg Val Loss: 2.4585\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6806\n",
      "Epoch [1352/2000], Avg Train Loss: 3.6806\n",
      "Epoch [1352/2000], Avg Val Loss: 2.4586\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6157\n",
      "Epoch [1353/2000], Avg Train Loss: 3.6157\n",
      "Epoch [1353/2000], Avg Val Loss: 2.4587\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1354/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6552\n",
      "Epoch [1354/2000], Avg Train Loss: 3.6552\n",
      "Epoch [1354/2000], Avg Val Loss: 2.4587\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6899\n",
      "Epoch [1355/2000], Avg Train Loss: 3.6899\n",
      "Epoch [1355/2000], Avg Val Loss: 2.4586\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6413\n",
      "Epoch [1356/2000], Avg Train Loss: 3.6413\n",
      "Epoch [1356/2000], Avg Val Loss: 2.4585\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6465\n",
      "Epoch [1357/2000], Avg Train Loss: 3.6465\n",
      "Epoch [1357/2000], Avg Val Loss: 2.4583\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6361\n",
      "Epoch [1358/2000], Avg Train Loss: 3.6361\n",
      "Epoch [1358/2000], Avg Val Loss: 2.4579\n",
      "Validation loss improved from 2.4581 to 2.4579. Saving model...\n",
      "\n",
      "LOG: Epoch [1359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6253\n",
      "Epoch [1359/2000], Avg Train Loss: 3.6253\n",
      "Epoch [1359/2000], Avg Val Loss: 2.4573\n",
      "Validation loss improved from 2.4579 to 2.4573. Saving model...\n",
      "\n",
      "LOG: Epoch [1360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6485\n",
      "Epoch [1360/2000], Avg Train Loss: 3.6485\n",
      "Epoch [1360/2000], Avg Val Loss: 2.4567\n",
      "Validation loss improved from 2.4573 to 2.4567. Saving model...\n",
      "\n",
      "LOG: Epoch [1361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6465\n",
      "Epoch [1361/2000], Avg Train Loss: 3.6465\n",
      "Epoch [1361/2000], Avg Val Loss: 2.4559\n",
      "Validation loss improved from 2.4567 to 2.4559. Saving model...\n",
      "\n",
      "LOG: Epoch [1362/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6274\n",
      "Epoch [1362/2000], Avg Train Loss: 3.6274\n",
      "Epoch [1362/2000], Avg Val Loss: 2.4551\n",
      "Validation loss improved from 2.4559 to 2.4551. Saving model...\n",
      "\n",
      "LOG: Epoch [1363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6501\n",
      "Epoch [1363/2000], Avg Train Loss: 3.6501\n",
      "Epoch [1363/2000], Avg Val Loss: 2.4545\n",
      "Validation loss improved from 2.4551 to 2.4545. Saving model...\n",
      "\n",
      "LOG: Epoch [1364/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5858\n",
      "Epoch [1364/2000], Avg Train Loss: 3.5858\n",
      "Epoch [1364/2000], Avg Val Loss: 2.4538\n",
      "Validation loss improved from 2.4545 to 2.4538. Saving model...\n",
      "\n",
      "LOG: Epoch [1365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6537\n",
      "Epoch [1365/2000], Avg Train Loss: 3.6537\n",
      "Epoch [1365/2000], Avg Val Loss: 2.4531\n",
      "Validation loss improved from 2.4538 to 2.4531. Saving model...\n",
      "\n",
      "LOG: Epoch [1366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6178\n",
      "Epoch [1366/2000], Avg Train Loss: 3.6178\n",
      "Epoch [1366/2000], Avg Val Loss: 2.4522\n",
      "Validation loss improved from 2.4531 to 2.4522. Saving model...\n",
      "\n",
      "LOG: Epoch [1367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6138\n",
      "Epoch [1367/2000], Avg Train Loss: 3.6138\n",
      "Epoch [1367/2000], Avg Val Loss: 2.4514\n",
      "Validation loss improved from 2.4522 to 2.4514. Saving model...\n",
      "\n",
      "LOG: Epoch [1368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6341\n",
      "Epoch [1368/2000], Avg Train Loss: 3.6341\n",
      "Epoch [1368/2000], Avg Val Loss: 2.4505\n",
      "Validation loss improved from 2.4514 to 2.4505. Saving model...\n",
      "\n",
      "LOG: Epoch [1369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6207\n",
      "Epoch [1369/2000], Avg Train Loss: 3.6207\n",
      "Epoch [1369/2000], Avg Val Loss: 2.4496\n",
      "Validation loss improved from 2.4505 to 2.4496. Saving model...\n",
      "\n",
      "LOG: Epoch [1370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6626\n",
      "Epoch [1370/2000], Avg Train Loss: 3.6626\n",
      "Epoch [1370/2000], Avg Val Loss: 2.4489\n",
      "Validation loss improved from 2.4496 to 2.4489. Saving model...\n",
      "\n",
      "LOG: Epoch [1371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6747\n",
      "Epoch [1371/2000], Avg Train Loss: 3.6747\n",
      "Epoch [1371/2000], Avg Val Loss: 2.4485\n",
      "Validation loss improved from 2.4489 to 2.4485. Saving model...\n",
      "\n",
      "LOG: Epoch [1372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6198\n",
      "Epoch [1372/2000], Avg Train Loss: 3.6198\n",
      "Epoch [1372/2000], Avg Val Loss: 2.4480\n",
      "Validation loss improved from 2.4485 to 2.4480. Saving model...\n",
      "\n",
      "LOG: Epoch [1373/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6006\n",
      "Epoch [1373/2000], Avg Train Loss: 3.6006\n",
      "Epoch [1373/2000], Avg Val Loss: 2.4477\n",
      "Validation loss improved from 2.4480 to 2.4477. Saving model...\n",
      "\n",
      "LOG: Epoch [1374/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6421\n",
      "Epoch [1374/2000], Avg Train Loss: 3.6421\n",
      "Epoch [1374/2000], Avg Val Loss: 2.4475\n",
      "Validation loss improved from 2.4477 to 2.4475. Saving model...\n",
      "\n",
      "LOG: Epoch [1375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6308\n",
      "Epoch [1375/2000], Avg Train Loss: 3.6308\n",
      "Epoch [1375/2000], Avg Val Loss: 2.4474\n",
      "Validation loss improved from 2.4475 to 2.4474. Saving model...\n",
      "\n",
      "LOG: Epoch [1376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6319\n",
      "Epoch [1376/2000], Avg Train Loss: 3.6319\n",
      "Epoch [1376/2000], Avg Val Loss: 2.4473\n",
      "Validation loss improved from 2.4474 to 2.4473. Saving model...\n",
      "\n",
      "LOG: Epoch [1377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6296\n",
      "Epoch [1377/2000], Avg Train Loss: 3.6296\n",
      "Epoch [1377/2000], Avg Val Loss: 2.4472\n",
      "Validation loss improved from 2.4473 to 2.4472. Saving model...\n",
      "\n",
      "LOG: Epoch [1378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6518\n",
      "Epoch [1378/2000], Avg Train Loss: 3.6518\n",
      "Epoch [1378/2000], Avg Val Loss: 2.4471\n",
      "Validation loss improved from 2.4472 to 2.4471. Saving model...\n",
      "\n",
      "LOG: Epoch [1379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6508\n",
      "Epoch [1379/2000], Avg Train Loss: 3.6508\n",
      "Epoch [1379/2000], Avg Val Loss: 2.4469\n",
      "Validation loss improved from 2.4471 to 2.4469. Saving model...\n",
      "\n",
      "LOG: Epoch [1380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5833\n",
      "Epoch [1380/2000], Avg Train Loss: 3.5833\n",
      "Epoch [1380/2000], Avg Val Loss: 2.4468\n",
      "Validation loss improved from 2.4469 to 2.4468. Saving model...\n",
      "\n",
      "LOG: Epoch [1381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6128\n",
      "Epoch [1381/2000], Avg Train Loss: 3.6128\n",
      "Epoch [1381/2000], Avg Val Loss: 2.4467\n",
      "Validation loss improved from 2.4468 to 2.4467. Saving model...\n",
      "\n",
      "LOG: Epoch [1382/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6313\n",
      "Epoch [1382/2000], Avg Train Loss: 3.6313\n",
      "Epoch [1382/2000], Avg Val Loss: 2.4465\n",
      "Validation loss improved from 2.4467 to 2.4465. Saving model...\n",
      "\n",
      "LOG: Epoch [1383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6347\n",
      "Epoch [1383/2000], Avg Train Loss: 3.6347\n",
      "Epoch [1383/2000], Avg Val Loss: 2.4465\n",
      "Validation loss improved from 2.4465 to 2.4465. Saving model...\n",
      "\n",
      "LOG: Epoch [1384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6025\n",
      "Epoch [1384/2000], Avg Train Loss: 3.6025\n",
      "Epoch [1384/2000], Avg Val Loss: 2.4464\n",
      "Validation loss improved from 2.4465 to 2.4464. Saving model...\n",
      "\n",
      "LOG: Epoch [1385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6198\n",
      "Epoch [1385/2000], Avg Train Loss: 3.6198\n",
      "Epoch [1385/2000], Avg Val Loss: 2.4466\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6381\n",
      "Epoch [1386/2000], Avg Train Loss: 3.6381\n",
      "Epoch [1386/2000], Avg Val Loss: 2.4467\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6248\n",
      "Epoch [1387/2000], Avg Train Loss: 3.6248\n",
      "Epoch [1387/2000], Avg Val Loss: 2.4467\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5906\n",
      "Epoch [1388/2000], Avg Train Loss: 3.5906\n",
      "Epoch [1388/2000], Avg Val Loss: 2.4466\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5992\n",
      "Epoch [1389/2000], Avg Train Loss: 3.5992\n",
      "Epoch [1389/2000], Avg Val Loss: 2.4466\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5736\n",
      "Epoch [1390/2000], Avg Train Loss: 3.5736\n",
      "Epoch [1390/2000], Avg Val Loss: 2.4467\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6353\n",
      "Epoch [1391/2000], Avg Train Loss: 3.6353\n",
      "Epoch [1391/2000], Avg Val Loss: 2.4466\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6182\n",
      "Epoch [1392/2000], Avg Train Loss: 3.6182\n",
      "Epoch [1392/2000], Avg Val Loss: 2.4466\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6106\n",
      "Epoch [1393/2000], Avg Train Loss: 3.6106\n",
      "Epoch [1393/2000], Avg Val Loss: 2.4467\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6047\n",
      "Epoch [1394/2000], Avg Train Loss: 3.6047\n",
      "Epoch [1394/2000], Avg Val Loss: 2.4468\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6041\n",
      "Epoch [1395/2000], Avg Train Loss: 3.6041\n",
      "Epoch [1395/2000], Avg Val Loss: 2.4468\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6310\n",
      "Epoch [1396/2000], Avg Train Loss: 3.6310\n",
      "Epoch [1396/2000], Avg Val Loss: 2.4467\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1397/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5970\n",
      "Epoch [1397/2000], Avg Train Loss: 3.5970\n",
      "Epoch [1397/2000], Avg Val Loss: 2.4467\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1398/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6216\n",
      "Epoch [1398/2000], Avg Train Loss: 3.6216\n",
      "Epoch [1398/2000], Avg Val Loss: 2.4466\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6378\n",
      "Epoch [1399/2000], Avg Train Loss: 3.6378\n",
      "Epoch [1399/2000], Avg Val Loss: 2.4466\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5872\n",
      "Epoch [1400/2000], Avg Train Loss: 3.5872\n",
      "Epoch [1400/2000], Avg Val Loss: 2.4468\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5970\n",
      "Epoch [1401/2000], Avg Train Loss: 3.5970\n",
      "Epoch [1401/2000], Avg Val Loss: 2.4468\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5904\n",
      "Epoch [1402/2000], Avg Train Loss: 3.5904\n",
      "Epoch [1402/2000], Avg Val Loss: 2.4467\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5713\n",
      "Epoch [1403/2000], Avg Train Loss: 3.5713\n",
      "Epoch [1403/2000], Avg Val Loss: 2.4464\n",
      "Validation loss improved from 2.4464 to 2.4464. Saving model...\n",
      "\n",
      "LOG: Epoch [1404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6296\n",
      "Epoch [1404/2000], Avg Train Loss: 3.6296\n",
      "Epoch [1404/2000], Avg Val Loss: 2.4463\n",
      "Validation loss improved from 2.4464 to 2.4463. Saving model...\n",
      "\n",
      "LOG: Epoch [1405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6278\n",
      "Epoch [1405/2000], Avg Train Loss: 3.6278\n",
      "Epoch [1405/2000], Avg Val Loss: 2.4462\n",
      "Validation loss improved from 2.4463 to 2.4462. Saving model...\n",
      "\n",
      "LOG: Epoch [1406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6012\n",
      "Epoch [1406/2000], Avg Train Loss: 3.6012\n",
      "Epoch [1406/2000], Avg Val Loss: 2.4463\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6155\n",
      "Epoch [1407/2000], Avg Train Loss: 3.6155\n",
      "Epoch [1407/2000], Avg Val Loss: 2.4465\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6172\n",
      "Epoch [1408/2000], Avg Train Loss: 3.6172\n",
      "Epoch [1408/2000], Avg Val Loss: 2.4468\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1409/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5879\n",
      "Epoch [1409/2000], Avg Train Loss: 3.5879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1409/2000], Avg Val Loss: 2.4469\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6489\n",
      "Epoch [1410/2000], Avg Train Loss: 3.6489\n",
      "Epoch [1410/2000], Avg Val Loss: 2.4471\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6415\n",
      "Epoch [1411/2000], Avg Train Loss: 3.6415\n",
      "Epoch [1411/2000], Avg Val Loss: 2.4471\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6591\n",
      "Epoch [1412/2000], Avg Train Loss: 3.6591\n",
      "Epoch [1412/2000], Avg Val Loss: 2.4472\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6353\n",
      "Epoch [1413/2000], Avg Train Loss: 3.6353\n",
      "Epoch [1413/2000], Avg Val Loss: 2.4472\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6298\n",
      "Epoch [1414/2000], Avg Train Loss: 3.6298\n",
      "Epoch [1414/2000], Avg Val Loss: 2.4472\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5987\n",
      "Epoch [1415/2000], Avg Train Loss: 3.5987\n",
      "Epoch [1415/2000], Avg Val Loss: 2.4471\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1416/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5912\n",
      "Epoch [1416/2000], Avg Train Loss: 3.5912\n",
      "Epoch [1416/2000], Avg Val Loss: 2.4470\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5815\n",
      "Epoch [1417/2000], Avg Train Loss: 3.5815\n",
      "Epoch [1417/2000], Avg Val Loss: 2.4470\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1418/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6029\n",
      "Epoch [1418/2000], Avg Train Loss: 3.6029\n",
      "Epoch [1418/2000], Avg Val Loss: 2.4469\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6409\n",
      "Epoch [1419/2000], Avg Train Loss: 3.6409\n",
      "Epoch [1419/2000], Avg Val Loss: 2.4468\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5954\n",
      "Epoch [1420/2000], Avg Train Loss: 3.5954\n",
      "Epoch [1420/2000], Avg Val Loss: 2.4465\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6265\n",
      "Epoch [1421/2000], Avg Train Loss: 3.6265\n",
      "Epoch [1421/2000], Avg Val Loss: 2.4461\n",
      "Validation loss improved from 2.4462 to 2.4461. Saving model...\n",
      "\n",
      "LOG: Epoch [1422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5964\n",
      "Epoch [1422/2000], Avg Train Loss: 3.5964\n",
      "Epoch [1422/2000], Avg Val Loss: 2.4458\n",
      "Validation loss improved from 2.4461 to 2.4458. Saving model...\n",
      "\n",
      "LOG: Epoch [1423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6102\n",
      "Epoch [1423/2000], Avg Train Loss: 3.6102\n",
      "Epoch [1423/2000], Avg Val Loss: 2.4454\n",
      "Validation loss improved from 2.4458 to 2.4454. Saving model...\n",
      "\n",
      "LOG: Epoch [1424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5956\n",
      "Epoch [1424/2000], Avg Train Loss: 3.5956\n",
      "Epoch [1424/2000], Avg Val Loss: 2.4450\n",
      "Validation loss improved from 2.4454 to 2.4450. Saving model...\n",
      "\n",
      "LOG: Epoch [1425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6491\n",
      "Epoch [1425/2000], Avg Train Loss: 3.6491\n",
      "Epoch [1425/2000], Avg Val Loss: 2.4447\n",
      "Validation loss improved from 2.4450 to 2.4447. Saving model...\n",
      "\n",
      "LOG: Epoch [1426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5670\n",
      "Epoch [1426/2000], Avg Train Loss: 3.5670\n",
      "Epoch [1426/2000], Avg Val Loss: 2.4443\n",
      "Validation loss improved from 2.4447 to 2.4443. Saving model...\n",
      "\n",
      "LOG: Epoch [1427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6071\n",
      "Epoch [1427/2000], Avg Train Loss: 3.6071\n",
      "Epoch [1427/2000], Avg Val Loss: 2.4440\n",
      "Validation loss improved from 2.4443 to 2.4440. Saving model...\n",
      "\n",
      "LOG: Epoch [1428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6000\n",
      "Epoch [1428/2000], Avg Train Loss: 3.6000\n",
      "Epoch [1428/2000], Avg Val Loss: 2.4437\n",
      "Validation loss improved from 2.4440 to 2.4437. Saving model...\n",
      "\n",
      "LOG: Epoch [1429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5663\n",
      "Epoch [1429/2000], Avg Train Loss: 3.5663\n",
      "Epoch [1429/2000], Avg Val Loss: 2.4433\n",
      "Validation loss improved from 2.4437 to 2.4433. Saving model...\n",
      "\n",
      "LOG: Epoch [1430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6134\n",
      "Epoch [1430/2000], Avg Train Loss: 3.6134\n",
      "Epoch [1430/2000], Avg Val Loss: 2.4429\n",
      "Validation loss improved from 2.4433 to 2.4429. Saving model...\n",
      "\n",
      "LOG: Epoch [1431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5943\n",
      "Epoch [1431/2000], Avg Train Loss: 3.5943\n",
      "Epoch [1431/2000], Avg Val Loss: 2.4425\n",
      "Validation loss improved from 2.4429 to 2.4425. Saving model...\n",
      "\n",
      "LOG: Epoch [1432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5620\n",
      "Epoch [1432/2000], Avg Train Loss: 3.5620\n",
      "Epoch [1432/2000], Avg Val Loss: 2.4418\n",
      "Validation loss improved from 2.4425 to 2.4418. Saving model...\n",
      "\n",
      "LOG: Epoch [1433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6482\n",
      "Epoch [1433/2000], Avg Train Loss: 3.6482\n",
      "Epoch [1433/2000], Avg Val Loss: 2.4413\n",
      "Validation loss improved from 2.4418 to 2.4413. Saving model...\n",
      "\n",
      "LOG: Epoch [1434/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5898\n",
      "Epoch [1434/2000], Avg Train Loss: 3.5898\n",
      "Epoch [1434/2000], Avg Val Loss: 2.4408\n",
      "Validation loss improved from 2.4413 to 2.4408. Saving model...\n",
      "\n",
      "LOG: Epoch [1435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5869\n",
      "Epoch [1435/2000], Avg Train Loss: 3.5869\n",
      "Epoch [1435/2000], Avg Val Loss: 2.4403\n",
      "Validation loss improved from 2.4408 to 2.4403. Saving model...\n",
      "\n",
      "LOG: Epoch [1436/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6117\n",
      "Epoch [1436/2000], Avg Train Loss: 3.6117\n",
      "Epoch [1436/2000], Avg Val Loss: 2.4399\n",
      "Validation loss improved from 2.4403 to 2.4399. Saving model...\n",
      "\n",
      "LOG: Epoch [1437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5702\n",
      "Epoch [1437/2000], Avg Train Loss: 3.5702\n",
      "Epoch [1437/2000], Avg Val Loss: 2.4397\n",
      "Validation loss improved from 2.4399 to 2.4397. Saving model...\n",
      "\n",
      "LOG: Epoch [1438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5718\n",
      "Epoch [1438/2000], Avg Train Loss: 3.5718\n",
      "Epoch [1438/2000], Avg Val Loss: 2.4393\n",
      "Validation loss improved from 2.4397 to 2.4393. Saving model...\n",
      "\n",
      "LOG: Epoch [1439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6072\n",
      "Epoch [1439/2000], Avg Train Loss: 3.6072\n",
      "Epoch [1439/2000], Avg Val Loss: 2.4391\n",
      "Validation loss improved from 2.4393 to 2.4391. Saving model...\n",
      "\n",
      "LOG: Epoch [1440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5803\n",
      "Epoch [1440/2000], Avg Train Loss: 3.5803\n",
      "Epoch [1440/2000], Avg Val Loss: 2.4389\n",
      "Validation loss improved from 2.4391 to 2.4389. Saving model...\n",
      "\n",
      "LOG: Epoch [1441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5812\n",
      "Epoch [1441/2000], Avg Train Loss: 3.5812\n",
      "Epoch [1441/2000], Avg Val Loss: 2.4387\n",
      "Validation loss improved from 2.4389 to 2.4387. Saving model...\n",
      "\n",
      "LOG: Epoch [1442/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5711\n",
      "Epoch [1442/2000], Avg Train Loss: 3.5711\n",
      "Epoch [1442/2000], Avg Val Loss: 2.4386\n",
      "Validation loss improved from 2.4387 to 2.4386. Saving model...\n",
      "\n",
      "LOG: Epoch [1443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6022\n",
      "Epoch [1443/2000], Avg Train Loss: 3.6022\n",
      "Epoch [1443/2000], Avg Val Loss: 2.4387\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6151\n",
      "Epoch [1444/2000], Avg Train Loss: 3.6151\n",
      "Epoch [1444/2000], Avg Val Loss: 2.4390\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6072\n",
      "Epoch [1445/2000], Avg Train Loss: 3.6072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1445/2000], Avg Val Loss: 2.4394\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6104\n",
      "Epoch [1446/2000], Avg Train Loss: 3.6104\n",
      "Epoch [1446/2000], Avg Val Loss: 2.4400\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6135\n",
      "Epoch [1447/2000], Avg Train Loss: 3.6135\n",
      "Epoch [1447/2000], Avg Val Loss: 2.4407\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5829\n",
      "Epoch [1448/2000], Avg Train Loss: 3.5829\n",
      "Epoch [1448/2000], Avg Val Loss: 2.4415\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6410\n",
      "Epoch [1449/2000], Avg Train Loss: 3.6410\n",
      "Epoch [1449/2000], Avg Val Loss: 2.4419\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5795\n",
      "Epoch [1450/2000], Avg Train Loss: 3.5795\n",
      "Epoch [1450/2000], Avg Val Loss: 2.4424\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5628\n",
      "Epoch [1451/2000], Avg Train Loss: 3.5628\n",
      "Epoch [1451/2000], Avg Val Loss: 2.4427\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5911\n",
      "Epoch [1452/2000], Avg Train Loss: 3.5911\n",
      "Epoch [1452/2000], Avg Val Loss: 2.4431\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5894\n",
      "Epoch [1453/2000], Avg Train Loss: 3.5894\n",
      "Epoch [1453/2000], Avg Val Loss: 2.4435\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1454/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5815\n",
      "Epoch [1454/2000], Avg Train Loss: 3.5815\n",
      "Epoch [1454/2000], Avg Val Loss: 2.4440\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5670\n",
      "Epoch [1455/2000], Avg Train Loss: 3.5670\n",
      "Epoch [1455/2000], Avg Val Loss: 2.4444\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6278\n",
      "Epoch [1456/2000], Avg Train Loss: 3.6278\n",
      "Epoch [1456/2000], Avg Val Loss: 2.4447\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6157\n",
      "Epoch [1457/2000], Avg Train Loss: 3.6157\n",
      "Epoch [1457/2000], Avg Val Loss: 2.4452\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5772\n",
      "Epoch [1458/2000], Avg Train Loss: 3.5772\n",
      "Epoch [1458/2000], Avg Val Loss: 2.4454\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5818\n",
      "Epoch [1459/2000], Avg Train Loss: 3.5818\n",
      "Epoch [1459/2000], Avg Val Loss: 2.4456\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5869\n",
      "Epoch [1460/2000], Avg Train Loss: 3.5869\n",
      "Epoch [1460/2000], Avg Val Loss: 2.4458\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6067\n",
      "Epoch [1461/2000], Avg Train Loss: 3.6067\n",
      "Epoch [1461/2000], Avg Val Loss: 2.4461\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5644\n",
      "Epoch [1462/2000], Avg Train Loss: 3.5644\n",
      "Epoch [1462/2000], Avg Val Loss: 2.4462\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5967\n",
      "Epoch [1463/2000], Avg Train Loss: 3.5967\n",
      "Epoch [1463/2000], Avg Val Loss: 2.4462\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5921\n",
      "Epoch [1464/2000], Avg Train Loss: 3.5921\n",
      "Epoch [1464/2000], Avg Val Loss: 2.4464\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5491\n",
      "Epoch [1465/2000], Avg Train Loss: 3.5491\n",
      "Epoch [1465/2000], Avg Val Loss: 2.4466\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5758\n",
      "Epoch [1466/2000], Avg Train Loss: 3.5758\n",
      "Epoch [1466/2000], Avg Val Loss: 2.4469\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5341\n",
      "Epoch [1467/2000], Avg Train Loss: 3.5341\n",
      "Epoch [1467/2000], Avg Val Loss: 2.4469\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5746\n",
      "Epoch [1468/2000], Avg Train Loss: 3.5746\n",
      "Epoch [1468/2000], Avg Val Loss: 2.4469\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5814\n",
      "Epoch [1469/2000], Avg Train Loss: 3.5814\n",
      "Epoch [1469/2000], Avg Val Loss: 2.4469\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6219\n",
      "Epoch [1470/2000], Avg Train Loss: 3.6219\n",
      "Epoch [1470/2000], Avg Val Loss: 2.4469\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5899\n",
      "Epoch [1471/2000], Avg Train Loss: 3.5899\n",
      "Epoch [1471/2000], Avg Val Loss: 2.4468\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5799\n",
      "Epoch [1472/2000], Avg Train Loss: 3.5799\n",
      "Epoch [1472/2000], Avg Val Loss: 2.4466\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5709\n",
      "Epoch [1473/2000], Avg Train Loss: 3.5709\n",
      "Epoch [1473/2000], Avg Val Loss: 2.4466\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5723\n",
      "Epoch [1474/2000], Avg Train Loss: 3.5723\n",
      "Epoch [1474/2000], Avg Val Loss: 2.4464\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1475/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5915\n",
      "Epoch [1475/2000], Avg Train Loss: 3.5915\n",
      "Epoch [1475/2000], Avg Val Loss: 2.4462\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5594\n",
      "Epoch [1476/2000], Avg Train Loss: 3.5594\n",
      "Epoch [1476/2000], Avg Val Loss: 2.4460\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1477/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5607\n",
      "Epoch [1477/2000], Avg Train Loss: 3.5607\n",
      "Epoch [1477/2000], Avg Val Loss: 2.4456\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1478/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6025\n",
      "Epoch [1478/2000], Avg Train Loss: 3.6025\n",
      "Epoch [1478/2000], Avg Val Loss: 2.4452\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5966\n",
      "Epoch [1479/2000], Avg Train Loss: 3.5966\n",
      "Epoch [1479/2000], Avg Val Loss: 2.4449\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5507\n",
      "Epoch [1480/2000], Avg Train Loss: 3.5507\n",
      "Epoch [1480/2000], Avg Val Loss: 2.4446\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1481/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6108\n",
      "Epoch [1481/2000], Avg Train Loss: 3.6108\n",
      "Epoch [1481/2000], Avg Val Loss: 2.4442\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5755\n",
      "Epoch [1482/2000], Avg Train Loss: 3.5755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1482/2000], Avg Val Loss: 2.4436\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5685\n",
      "Epoch [1483/2000], Avg Train Loss: 3.5685\n",
      "Epoch [1483/2000], Avg Val Loss: 2.4431\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5659\n",
      "Epoch [1484/2000], Avg Train Loss: 3.5659\n",
      "Epoch [1484/2000], Avg Val Loss: 2.4428\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5609\n",
      "Epoch [1485/2000], Avg Train Loss: 3.5609\n",
      "Epoch [1485/2000], Avg Val Loss: 2.4425\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5786\n",
      "Epoch [1486/2000], Avg Train Loss: 3.5786\n",
      "Epoch [1486/2000], Avg Val Loss: 2.4423\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5599\n",
      "Epoch [1487/2000], Avg Train Loss: 3.5599\n",
      "Epoch [1487/2000], Avg Val Loss: 2.4421\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5594\n",
      "Epoch [1488/2000], Avg Train Loss: 3.5594\n",
      "Epoch [1488/2000], Avg Val Loss: 2.4420\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5783\n",
      "Epoch [1489/2000], Avg Train Loss: 3.5783\n",
      "Epoch [1489/2000], Avg Val Loss: 2.4418\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5707\n",
      "Epoch [1490/2000], Avg Train Loss: 3.5707\n",
      "Epoch [1490/2000], Avg Val Loss: 2.4417\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5976\n",
      "Epoch [1491/2000], Avg Train Loss: 3.5976\n",
      "Epoch [1491/2000], Avg Val Loss: 2.4418\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5440\n",
      "Epoch [1492/2000], Avg Train Loss: 3.5440\n",
      "Epoch [1492/2000], Avg Val Loss: 2.4419\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5587\n",
      "Epoch [1493/2000], Avg Train Loss: 3.5587\n",
      "Epoch [1493/2000], Avg Val Loss: 2.4419\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5662\n",
      "Epoch [1494/2000], Avg Train Loss: 3.5662\n",
      "Epoch [1494/2000], Avg Val Loss: 2.4420\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5927\n",
      "Epoch [1495/2000], Avg Train Loss: 3.5927\n",
      "Epoch [1495/2000], Avg Val Loss: 2.4422\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1496/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5487\n",
      "Epoch [1496/2000], Avg Train Loss: 3.5487\n",
      "Epoch [1496/2000], Avg Val Loss: 2.4425\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1497/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5658\n",
      "Epoch [1497/2000], Avg Train Loss: 3.5658\n",
      "Epoch [1497/2000], Avg Val Loss: 2.4429\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1498/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5590\n",
      "Epoch [1498/2000], Avg Train Loss: 3.5590\n",
      "Epoch [1498/2000], Avg Val Loss: 2.4431\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5557\n",
      "Epoch [1499/2000], Avg Train Loss: 3.5557\n",
      "Epoch [1499/2000], Avg Val Loss: 2.4432\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5766\n",
      "Epoch [1500/2000], Avg Train Loss: 3.5766\n",
      "Epoch [1500/2000], Avg Val Loss: 2.4434\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5863\n",
      "Epoch [1501/2000], Avg Train Loss: 3.5863\n",
      "Epoch [1501/2000], Avg Val Loss: 2.4437\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1502/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5772\n",
      "Epoch [1502/2000], Avg Train Loss: 3.5772\n",
      "Epoch [1502/2000], Avg Val Loss: 2.4440\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1503/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5604\n",
      "Epoch [1503/2000], Avg Train Loss: 3.5604\n",
      "Epoch [1503/2000], Avg Val Loss: 2.4443\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1504/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5291\n",
      "Epoch [1504/2000], Avg Train Loss: 3.5291\n",
      "Epoch [1504/2000], Avg Val Loss: 2.4446\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1505/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5522\n",
      "Epoch [1505/2000], Avg Train Loss: 3.5522\n",
      "Epoch [1505/2000], Avg Val Loss: 2.4448\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5829\n",
      "Epoch [1506/2000], Avg Train Loss: 3.5829\n",
      "Epoch [1506/2000], Avg Val Loss: 2.4448\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5424\n",
      "Epoch [1507/2000], Avg Train Loss: 3.5424\n",
      "Epoch [1507/2000], Avg Val Loss: 2.4449\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1508/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5633\n",
      "Epoch [1508/2000], Avg Train Loss: 3.5633\n",
      "Epoch [1508/2000], Avg Val Loss: 2.4448\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1509/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5823\n",
      "Epoch [1509/2000], Avg Train Loss: 3.5823\n",
      "Epoch [1509/2000], Avg Val Loss: 2.4445\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5686\n",
      "Epoch [1510/2000], Avg Train Loss: 3.5686\n",
      "Epoch [1510/2000], Avg Val Loss: 2.4443\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [1511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5620\n",
      "Epoch [1511/2000], Avg Train Loss: 3.5620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1511/2000], Avg Val Loss: 2.4441\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [1512/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5299\n",
      "Epoch [1512/2000], Avg Train Loss: 3.5299\n",
      "Epoch [1512/2000], Avg Val Loss: 2.4439\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [1513/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5954\n",
      "Epoch [1513/2000], Avg Train Loss: 3.5954\n",
      "Epoch [1513/2000], Avg Val Loss: 2.4436\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [1514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5565\n",
      "Epoch [1514/2000], Avg Train Loss: 3.5565\n",
      "Epoch [1514/2000], Avg Val Loss: 2.4436\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [1515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5402\n",
      "Epoch [1515/2000], Avg Train Loss: 3.5402\n",
      "Epoch [1515/2000], Avg Val Loss: 2.4435\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [1516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5561\n",
      "Epoch [1516/2000], Avg Train Loss: 3.5561\n",
      "Epoch [1516/2000], Avg Val Loss: 2.4433\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [1517/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5892\n",
      "Epoch [1517/2000], Avg Train Loss: 3.5892\n",
      "Epoch [1517/2000], Avg Val Loss: 2.4433\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [1518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5648\n",
      "Epoch [1518/2000], Avg Train Loss: 3.5648\n",
      "Epoch [1518/2000], Avg Val Loss: 2.4431\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [1519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5537\n",
      "Epoch [1519/2000], Avg Train Loss: 3.5537\n",
      "Epoch [1519/2000], Avg Val Loss: 2.4429\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [1520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5874\n",
      "Epoch [1520/2000], Avg Train Loss: 3.5874\n",
      "Epoch [1520/2000], Avg Val Loss: 2.4425\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [1521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5817\n",
      "Epoch [1521/2000], Avg Train Loss: 3.5817\n",
      "Epoch [1521/2000], Avg Val Loss: 2.4421\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [1522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6040\n",
      "Epoch [1522/2000], Avg Train Loss: 3.6040\n",
      "Epoch [1522/2000], Avg Val Loss: 2.4420\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [1523/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5440\n",
      "Epoch [1523/2000], Avg Train Loss: 3.5440\n",
      "Epoch [1523/2000], Avg Val Loss: 2.4420\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [1524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5843\n",
      "Epoch [1524/2000], Avg Train Loss: 3.5843\n",
      "Epoch [1524/2000], Avg Val Loss: 2.4416\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [1525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5497\n",
      "Epoch [1525/2000], Avg Train Loss: 3.5497\n",
      "Epoch [1525/2000], Avg Val Loss: 2.4415\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [1526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5906\n",
      "Epoch [1526/2000], Avg Train Loss: 3.5906\n",
      "Epoch [1526/2000], Avg Val Loss: 2.4412\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [1527/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5858\n",
      "Epoch [1527/2000], Avg Train Loss: 3.5858\n",
      "Epoch [1527/2000], Avg Val Loss: 2.4410\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [1528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6011\n",
      "Epoch [1528/2000], Avg Train Loss: 3.6011\n",
      "Epoch [1528/2000], Avg Val Loss: 2.4410\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [1529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5417\n",
      "Epoch [1529/2000], Avg Train Loss: 3.5417\n",
      "Epoch [1529/2000], Avg Val Loss: 2.4411\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [1530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5933\n",
      "Epoch [1530/2000], Avg Train Loss: 3.5933\n",
      "Epoch [1530/2000], Avg Val Loss: 2.4412\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [1531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5300\n",
      "Epoch [1531/2000], Avg Train Loss: 3.5300\n",
      "Epoch [1531/2000], Avg Val Loss: 2.4413\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [1532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5767\n",
      "Epoch [1532/2000], Avg Train Loss: 3.5767\n",
      "Epoch [1532/2000], Avg Val Loss: 2.4414\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [1533/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5645\n",
      "Epoch [1533/2000], Avg Train Loss: 3.5645\n",
      "Epoch [1533/2000], Avg Val Loss: 2.4413\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [1534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5738\n",
      "Epoch [1534/2000], Avg Train Loss: 3.5738\n",
      "Epoch [1534/2000], Avg Val Loss: 2.4411\n",
      "Validation loss did not improve. Patience: 92/100\n",
      "\n",
      "LOG: Epoch [1535/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5195\n",
      "Epoch [1535/2000], Avg Train Loss: 3.5195\n",
      "Epoch [1535/2000], Avg Val Loss: 2.4408\n",
      "Validation loss did not improve. Patience: 93/100\n",
      "\n",
      "LOG: Epoch [1536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5411\n",
      "Epoch [1536/2000], Avg Train Loss: 3.5411\n",
      "Epoch [1536/2000], Avg Val Loss: 2.4404\n",
      "Validation loss did not improve. Patience: 94/100\n",
      "\n",
      "LOG: Epoch [1537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5690\n",
      "Epoch [1537/2000], Avg Train Loss: 3.5690\n",
      "Epoch [1537/2000], Avg Val Loss: 2.4401\n",
      "Validation loss did not improve. Patience: 95/100\n",
      "\n",
      "LOG: Epoch [1538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5353\n",
      "Epoch [1538/2000], Avg Train Loss: 3.5353\n",
      "Epoch [1538/2000], Avg Val Loss: 2.4398\n",
      "Validation loss did not improve. Patience: 96/100\n",
      "\n",
      "LOG: Epoch [1539/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5713\n",
      "Epoch [1539/2000], Avg Train Loss: 3.5713\n",
      "Epoch [1539/2000], Avg Val Loss: 2.4395\n",
      "Validation loss did not improve. Patience: 97/100\n",
      "\n",
      "LOG: Epoch [1540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5430\n",
      "Epoch [1540/2000], Avg Train Loss: 3.5430\n",
      "Epoch [1540/2000], Avg Val Loss: 2.4390\n",
      "Validation loss did not improve. Patience: 98/100\n",
      "\n",
      "LOG: Epoch [1541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5513\n",
      "Epoch [1541/2000], Avg Train Loss: 3.5513\n",
      "Epoch [1541/2000], Avg Val Loss: 2.4385\n",
      "Validation loss improved from 2.4386 to 2.4385. Saving model...\n",
      "\n",
      "LOG: Epoch [1542/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5519\n",
      "Epoch [1542/2000], Avg Train Loss: 3.5519\n",
      "Epoch [1542/2000], Avg Val Loss: 2.4380\n",
      "Validation loss improved from 2.4385 to 2.4380. Saving model...\n",
      "\n",
      "LOG: Epoch [1543/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5609\n",
      "Epoch [1543/2000], Avg Train Loss: 3.5609\n",
      "Epoch [1543/2000], Avg Val Loss: 2.4377\n",
      "Validation loss improved from 2.4380 to 2.4377. Saving model...\n",
      "\n",
      "LOG: Epoch [1544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5445\n",
      "Epoch [1544/2000], Avg Train Loss: 3.5445\n",
      "Epoch [1544/2000], Avg Val Loss: 2.4372\n",
      "Validation loss improved from 2.4377 to 2.4372. Saving model...\n",
      "\n",
      "LOG: Epoch [1545/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5287\n",
      "Epoch [1545/2000], Avg Train Loss: 3.5287\n",
      "Epoch [1545/2000], Avg Val Loss: 2.4367\n",
      "Validation loss improved from 2.4372 to 2.4367. Saving model...\n",
      "\n",
      "LOG: Epoch [1546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5509\n",
      "Epoch [1546/2000], Avg Train Loss: 3.5509\n",
      "Epoch [1546/2000], Avg Val Loss: 2.4361\n",
      "Validation loss improved from 2.4367 to 2.4361. Saving model...\n",
      "\n",
      "LOG: Epoch [1547/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5282\n",
      "Epoch [1547/2000], Avg Train Loss: 3.5282\n",
      "Epoch [1547/2000], Avg Val Loss: 2.4356\n",
      "Validation loss improved from 2.4361 to 2.4356. Saving model...\n",
      "\n",
      "LOG: Epoch [1548/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5887\n",
      "Epoch [1548/2000], Avg Train Loss: 3.5887\n",
      "Epoch [1548/2000], Avg Val Loss: 2.4353\n",
      "Validation loss improved from 2.4356 to 2.4353. Saving model...\n",
      "\n",
      "LOG: Epoch [1549/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5804\n",
      "Epoch [1549/2000], Avg Train Loss: 3.5804\n",
      "Epoch [1549/2000], Avg Val Loss: 2.4351\n",
      "Validation loss improved from 2.4353 to 2.4351. Saving model...\n",
      "\n",
      "LOG: Epoch [1550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5609\n",
      "Epoch [1550/2000], Avg Train Loss: 3.5609\n",
      "Epoch [1550/2000], Avg Val Loss: 2.4348\n",
      "Validation loss improved from 2.4351 to 2.4348. Saving model...\n",
      "\n",
      "LOG: Epoch [1551/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5181\n",
      "Epoch [1551/2000], Avg Train Loss: 3.5181\n",
      "Epoch [1551/2000], Avg Val Loss: 2.4344\n",
      "Validation loss improved from 2.4348 to 2.4344. Saving model...\n",
      "\n",
      "LOG: Epoch [1552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5798\n",
      "Epoch [1552/2000], Avg Train Loss: 3.5798\n",
      "Epoch [1552/2000], Avg Val Loss: 2.4341\n",
      "Validation loss improved from 2.4344 to 2.4341. Saving model...\n",
      "\n",
      "LOG: Epoch [1553/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5201\n",
      "Epoch [1553/2000], Avg Train Loss: 3.5201\n",
      "Epoch [1553/2000], Avg Val Loss: 2.4337\n",
      "Validation loss improved from 2.4341 to 2.4337. Saving model...\n",
      "\n",
      "LOG: Epoch [1554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5366\n",
      "Epoch [1554/2000], Avg Train Loss: 3.5366\n",
      "Epoch [1554/2000], Avg Val Loss: 2.4334\n",
      "Validation loss improved from 2.4337 to 2.4334. Saving model...\n",
      "\n",
      "LOG: Epoch [1555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5506\n",
      "Epoch [1555/2000], Avg Train Loss: 3.5506\n",
      "Epoch [1555/2000], Avg Val Loss: 2.4330\n",
      "Validation loss improved from 2.4334 to 2.4330. Saving model...\n",
      "\n",
      "LOG: Epoch [1556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5650\n",
      "Epoch [1556/2000], Avg Train Loss: 3.5650\n",
      "Epoch [1556/2000], Avg Val Loss: 2.4327\n",
      "Validation loss improved from 2.4330 to 2.4327. Saving model...\n",
      "\n",
      "LOG: Epoch [1557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5036\n",
      "Epoch [1557/2000], Avg Train Loss: 3.5036\n",
      "Epoch [1557/2000], Avg Val Loss: 2.4325\n",
      "Validation loss improved from 2.4327 to 2.4325. Saving model...\n",
      "\n",
      "LOG: Epoch [1558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5600\n",
      "Epoch [1558/2000], Avg Train Loss: 3.5600\n",
      "Epoch [1558/2000], Avg Val Loss: 2.4324\n",
      "Validation loss improved from 2.4325 to 2.4324. Saving model...\n",
      "\n",
      "LOG: Epoch [1559/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5559\n",
      "Epoch [1559/2000], Avg Train Loss: 3.5559\n",
      "Epoch [1559/2000], Avg Val Loss: 2.4327\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1560/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5642\n",
      "Epoch [1560/2000], Avg Train Loss: 3.5642\n",
      "Epoch [1560/2000], Avg Val Loss: 2.4332\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5795\n",
      "Epoch [1561/2000], Avg Train Loss: 3.5795\n",
      "Epoch [1561/2000], Avg Val Loss: 2.4338\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1562/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5558\n",
      "Epoch [1562/2000], Avg Train Loss: 3.5558\n",
      "Epoch [1562/2000], Avg Val Loss: 2.4344\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5656\n",
      "Epoch [1563/2000], Avg Train Loss: 3.5656\n",
      "Epoch [1563/2000], Avg Val Loss: 2.4354\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1564/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5536\n",
      "Epoch [1564/2000], Avg Train Loss: 3.5536\n",
      "Epoch [1564/2000], Avg Val Loss: 2.4362\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5722\n",
      "Epoch [1565/2000], Avg Train Loss: 3.5722\n",
      "Epoch [1565/2000], Avg Val Loss: 2.4368\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5330\n",
      "Epoch [1566/2000], Avg Train Loss: 3.5330\n",
      "Epoch [1566/2000], Avg Val Loss: 2.4376\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5351\n",
      "Epoch [1567/2000], Avg Train Loss: 3.5351\n",
      "Epoch [1567/2000], Avg Val Loss: 2.4383\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5687\n",
      "Epoch [1568/2000], Avg Train Loss: 3.5687\n",
      "Epoch [1568/2000], Avg Val Loss: 2.4388\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1569/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5299\n",
      "Epoch [1569/2000], Avg Train Loss: 3.5299\n",
      "Epoch [1569/2000], Avg Val Loss: 2.4392\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5511\n",
      "Epoch [1570/2000], Avg Train Loss: 3.5511\n",
      "Epoch [1570/2000], Avg Val Loss: 2.4397\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1571/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5204\n",
      "Epoch [1571/2000], Avg Train Loss: 3.5204\n",
      "Epoch [1571/2000], Avg Val Loss: 2.4399\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5124\n",
      "Epoch [1572/2000], Avg Train Loss: 3.5124\n",
      "Epoch [1572/2000], Avg Val Loss: 2.4401\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1573/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5764\n",
      "Epoch [1573/2000], Avg Train Loss: 3.5764\n",
      "Epoch [1573/2000], Avg Val Loss: 2.4403\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5599\n",
      "Epoch [1574/2000], Avg Train Loss: 3.5599\n",
      "Epoch [1574/2000], Avg Val Loss: 2.4403\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5159\n",
      "Epoch [1575/2000], Avg Train Loss: 3.5159\n",
      "Epoch [1575/2000], Avg Val Loss: 2.4405\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5812\n",
      "Epoch [1576/2000], Avg Train Loss: 3.5812\n",
      "Epoch [1576/2000], Avg Val Loss: 2.4405\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1577/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5722\n",
      "Epoch [1577/2000], Avg Train Loss: 3.5722\n",
      "Epoch [1577/2000], Avg Val Loss: 2.4402\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1578/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5973\n",
      "Epoch [1578/2000], Avg Train Loss: 3.5973\n",
      "Epoch [1578/2000], Avg Val Loss: 2.4400\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5169\n",
      "Epoch [1579/2000], Avg Train Loss: 3.5169\n",
      "Epoch [1579/2000], Avg Val Loss: 2.4399\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1580/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5023\n",
      "Epoch [1580/2000], Avg Train Loss: 3.5023\n",
      "Epoch [1580/2000], Avg Val Loss: 2.4398\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5135\n",
      "Epoch [1581/2000], Avg Train Loss: 3.5135\n",
      "Epoch [1581/2000], Avg Val Loss: 2.4395\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1582/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5271\n",
      "Epoch [1582/2000], Avg Train Loss: 3.5271\n",
      "Epoch [1582/2000], Avg Val Loss: 2.4392\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5944\n",
      "Epoch [1583/2000], Avg Train Loss: 3.5944\n",
      "Epoch [1583/2000], Avg Val Loss: 2.4390\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1584/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5366\n",
      "Epoch [1584/2000], Avg Train Loss: 3.5366\n",
      "Epoch [1584/2000], Avg Val Loss: 2.4388\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1585/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5293\n",
      "Epoch [1585/2000], Avg Train Loss: 3.5293\n",
      "Epoch [1585/2000], Avg Val Loss: 2.4385\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1586/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5167\n",
      "Epoch [1586/2000], Avg Train Loss: 3.5167\n",
      "Epoch [1586/2000], Avg Val Loss: 2.4381\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5091\n",
      "Epoch [1587/2000], Avg Train Loss: 3.5091\n",
      "Epoch [1587/2000], Avg Val Loss: 2.4377\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1588/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5251\n",
      "Epoch [1588/2000], Avg Train Loss: 3.5251\n",
      "Epoch [1588/2000], Avg Val Loss: 2.4375\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5667\n",
      "Epoch [1589/2000], Avg Train Loss: 3.5667\n",
      "Epoch [1589/2000], Avg Val Loss: 2.4374\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5619\n",
      "Epoch [1590/2000], Avg Train Loss: 3.5619\n",
      "Epoch [1590/2000], Avg Val Loss: 2.4374\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5582\n",
      "Epoch [1591/2000], Avg Train Loss: 3.5582\n",
      "Epoch [1591/2000], Avg Val Loss: 2.4372\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4906\n",
      "Epoch [1592/2000], Avg Train Loss: 3.4906\n",
      "Epoch [1592/2000], Avg Val Loss: 2.4370\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1593/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5484\n",
      "Epoch [1593/2000], Avg Train Loss: 3.5484\n",
      "Epoch [1593/2000], Avg Val Loss: 2.4367\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1594/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5839\n",
      "Epoch [1594/2000], Avg Train Loss: 3.5839\n",
      "Epoch [1594/2000], Avg Val Loss: 2.4366\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5873\n",
      "Epoch [1595/2000], Avg Train Loss: 3.5873\n",
      "Epoch [1595/2000], Avg Val Loss: 2.4365\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5433\n",
      "Epoch [1596/2000], Avg Train Loss: 3.5433\n",
      "Epoch [1596/2000], Avg Val Loss: 2.4366\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5072\n",
      "Epoch [1597/2000], Avg Train Loss: 3.5072\n",
      "Epoch [1597/2000], Avg Val Loss: 2.4366\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1598/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5189\n",
      "Epoch [1598/2000], Avg Train Loss: 3.5189\n",
      "Epoch [1598/2000], Avg Val Loss: 2.4365\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1599/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5237\n",
      "Epoch [1599/2000], Avg Train Loss: 3.5237\n",
      "Epoch [1599/2000], Avg Val Loss: 2.4363\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1600/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5018\n",
      "Epoch [1600/2000], Avg Train Loss: 3.5018\n",
      "Epoch [1600/2000], Avg Val Loss: 2.4361\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1601/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5565\n",
      "Epoch [1601/2000], Avg Train Loss: 3.5565\n",
      "Epoch [1601/2000], Avg Val Loss: 2.4360\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5377\n",
      "Epoch [1602/2000], Avg Train Loss: 3.5377\n",
      "Epoch [1602/2000], Avg Val Loss: 2.4360\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1603/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5662\n",
      "Epoch [1603/2000], Avg Train Loss: 3.5662\n",
      "Epoch [1603/2000], Avg Val Loss: 2.4360\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1604/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5429\n",
      "Epoch [1604/2000], Avg Train Loss: 3.5429\n",
      "Epoch [1604/2000], Avg Val Loss: 2.4362\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1605/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5366\n",
      "Epoch [1605/2000], Avg Train Loss: 3.5366\n",
      "Epoch [1605/2000], Avg Val Loss: 2.4363\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1606/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5342\n",
      "Epoch [1606/2000], Avg Train Loss: 3.5342\n",
      "Epoch [1606/2000], Avg Val Loss: 2.4363\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1607/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5571\n",
      "Epoch [1607/2000], Avg Train Loss: 3.5571\n",
      "Epoch [1607/2000], Avg Val Loss: 2.4362\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1608/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5361\n",
      "Epoch [1608/2000], Avg Train Loss: 3.5361\n",
      "Epoch [1608/2000], Avg Val Loss: 2.4361\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1609/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5762\n",
      "Epoch [1609/2000], Avg Train Loss: 3.5762\n",
      "Epoch [1609/2000], Avg Val Loss: 2.4361\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5127\n",
      "Epoch [1610/2000], Avg Train Loss: 3.5127\n",
      "Epoch [1610/2000], Avg Val Loss: 2.4361\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1611/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5451\n",
      "Epoch [1611/2000], Avg Train Loss: 3.5451\n",
      "Epoch [1611/2000], Avg Val Loss: 2.4362\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5248\n",
      "Epoch [1612/2000], Avg Train Loss: 3.5248\n",
      "Epoch [1612/2000], Avg Val Loss: 2.4362\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1613/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5337\n",
      "Epoch [1613/2000], Avg Train Loss: 3.5337\n",
      "Epoch [1613/2000], Avg Val Loss: 2.4364\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1614/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5087\n",
      "Epoch [1614/2000], Avg Train Loss: 3.5087\n",
      "Epoch [1614/2000], Avg Val Loss: 2.4366\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1615/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5316\n",
      "Epoch [1615/2000], Avg Train Loss: 3.5316\n",
      "Epoch [1615/2000], Avg Val Loss: 2.4367\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1616/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5557\n",
      "Epoch [1616/2000], Avg Train Loss: 3.5557\n",
      "Epoch [1616/2000], Avg Val Loss: 2.4367\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1617/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5452\n",
      "Epoch [1617/2000], Avg Train Loss: 3.5452\n",
      "Epoch [1617/2000], Avg Val Loss: 2.4367\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1618/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5338\n",
      "Epoch [1618/2000], Avg Train Loss: 3.5338\n",
      "Epoch [1618/2000], Avg Val Loss: 2.4365\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1619/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5782\n",
      "Epoch [1619/2000], Avg Train Loss: 3.5782\n",
      "Epoch [1619/2000], Avg Val Loss: 2.4364\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1620/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5419\n",
      "Epoch [1620/2000], Avg Train Loss: 3.5419\n",
      "Epoch [1620/2000], Avg Val Loss: 2.4361\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1621/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5240\n",
      "Epoch [1621/2000], Avg Train Loss: 3.5240\n",
      "Epoch [1621/2000], Avg Val Loss: 2.4358\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1622/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5564\n",
      "Epoch [1622/2000], Avg Train Loss: 3.5564\n",
      "Epoch [1622/2000], Avg Val Loss: 2.4354\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1623/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4915\n",
      "Epoch [1623/2000], Avg Train Loss: 3.4915\n",
      "Epoch [1623/2000], Avg Val Loss: 2.4349\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1624/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5411\n",
      "Epoch [1624/2000], Avg Train Loss: 3.5411\n",
      "Epoch [1624/2000], Avg Val Loss: 2.4345\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5523\n",
      "Epoch [1625/2000], Avg Train Loss: 3.5523\n",
      "Epoch [1625/2000], Avg Val Loss: 2.4340\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1626/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5451\n",
      "Epoch [1626/2000], Avg Train Loss: 3.5451\n",
      "Epoch [1626/2000], Avg Val Loss: 2.4335\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [1627/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5356\n",
      "Epoch [1627/2000], Avg Train Loss: 3.5356\n",
      "Epoch [1627/2000], Avg Val Loss: 2.4328\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [1628/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5210\n",
      "Epoch [1628/2000], Avg Train Loss: 3.5210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1628/2000], Avg Val Loss: 2.4323\n",
      "Validation loss improved from 2.4324 to 2.4323. Saving model...\n",
      "\n",
      "LOG: Epoch [1629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5682\n",
      "Epoch [1629/2000], Avg Train Loss: 3.5682\n",
      "Epoch [1629/2000], Avg Val Loss: 2.4318\n",
      "Validation loss improved from 2.4323 to 2.4318. Saving model...\n",
      "\n",
      "LOG: Epoch [1630/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5480\n",
      "Epoch [1630/2000], Avg Train Loss: 3.5480\n",
      "Epoch [1630/2000], Avg Val Loss: 2.4313\n",
      "Validation loss improved from 2.4318 to 2.4313. Saving model...\n",
      "\n",
      "LOG: Epoch [1631/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5286\n",
      "Epoch [1631/2000], Avg Train Loss: 3.5286\n",
      "Epoch [1631/2000], Avg Val Loss: 2.4309\n",
      "Validation loss improved from 2.4313 to 2.4309. Saving model...\n",
      "\n",
      "LOG: Epoch [1632/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5429\n",
      "Epoch [1632/2000], Avg Train Loss: 3.5429\n",
      "Epoch [1632/2000], Avg Val Loss: 2.4304\n",
      "Validation loss improved from 2.4309 to 2.4304. Saving model...\n",
      "\n",
      "LOG: Epoch [1633/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5335\n",
      "Epoch [1633/2000], Avg Train Loss: 3.5335\n",
      "Epoch [1633/2000], Avg Val Loss: 2.4300\n",
      "Validation loss improved from 2.4304 to 2.4300. Saving model...\n",
      "\n",
      "LOG: Epoch [1634/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4976\n",
      "Epoch [1634/2000], Avg Train Loss: 3.4976\n",
      "Epoch [1634/2000], Avg Val Loss: 2.4296\n",
      "Validation loss improved from 2.4300 to 2.4296. Saving model...\n",
      "\n",
      "LOG: Epoch [1635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5181\n",
      "Epoch [1635/2000], Avg Train Loss: 3.5181\n",
      "Epoch [1635/2000], Avg Val Loss: 2.4293\n",
      "Validation loss improved from 2.4296 to 2.4293. Saving model...\n",
      "\n",
      "LOG: Epoch [1636/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5327\n",
      "Epoch [1636/2000], Avg Train Loss: 3.5327\n",
      "Epoch [1636/2000], Avg Val Loss: 2.4290\n",
      "Validation loss improved from 2.4293 to 2.4290. Saving model...\n",
      "\n",
      "LOG: Epoch [1637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5049\n",
      "Epoch [1637/2000], Avg Train Loss: 3.5049\n",
      "Epoch [1637/2000], Avg Val Loss: 2.4289\n",
      "Validation loss improved from 2.4290 to 2.4289. Saving model...\n",
      "\n",
      "LOG: Epoch [1638/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5458\n",
      "Epoch [1638/2000], Avg Train Loss: 3.5458\n",
      "Epoch [1638/2000], Avg Val Loss: 2.4290\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5618\n",
      "Epoch [1639/2000], Avg Train Loss: 3.5618\n",
      "Epoch [1639/2000], Avg Val Loss: 2.4292\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1640/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4997\n",
      "Epoch [1640/2000], Avg Train Loss: 3.4997\n",
      "Epoch [1640/2000], Avg Val Loss: 2.4294\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1641/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5242\n",
      "Epoch [1641/2000], Avg Train Loss: 3.5242\n",
      "Epoch [1641/2000], Avg Val Loss: 2.4297\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5551\n",
      "Epoch [1642/2000], Avg Train Loss: 3.5551\n",
      "Epoch [1642/2000], Avg Val Loss: 2.4300\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1643/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5292\n",
      "Epoch [1643/2000], Avg Train Loss: 3.5292\n",
      "Epoch [1643/2000], Avg Val Loss: 2.4303\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5233\n",
      "Epoch [1644/2000], Avg Train Loss: 3.5233\n",
      "Epoch [1644/2000], Avg Val Loss: 2.4304\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1645/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4979\n",
      "Epoch [1645/2000], Avg Train Loss: 3.4979\n",
      "Epoch [1645/2000], Avg Val Loss: 2.4305\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1646/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5034\n",
      "Epoch [1646/2000], Avg Train Loss: 3.5034\n",
      "Epoch [1646/2000], Avg Val Loss: 2.4305\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4956\n",
      "Epoch [1647/2000], Avg Train Loss: 3.4956\n",
      "Epoch [1647/2000], Avg Val Loss: 2.4306\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5166\n",
      "Epoch [1648/2000], Avg Train Loss: 3.5166\n",
      "Epoch [1648/2000], Avg Val Loss: 2.4307\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1649/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5511\n",
      "Epoch [1649/2000], Avg Train Loss: 3.5511\n",
      "Epoch [1649/2000], Avg Val Loss: 2.4309\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1650/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5331\n",
      "Epoch [1650/2000], Avg Train Loss: 3.5331\n",
      "Epoch [1650/2000], Avg Val Loss: 2.4312\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5402\n",
      "Epoch [1651/2000], Avg Train Loss: 3.5402\n",
      "Epoch [1651/2000], Avg Val Loss: 2.4315\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1652/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5352\n",
      "Epoch [1652/2000], Avg Train Loss: 3.5352\n",
      "Epoch [1652/2000], Avg Val Loss: 2.4319\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5034\n",
      "Epoch [1653/2000], Avg Train Loss: 3.5034\n",
      "Epoch [1653/2000], Avg Val Loss: 2.4321\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1654/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5283\n",
      "Epoch [1654/2000], Avg Train Loss: 3.5283\n",
      "Epoch [1654/2000], Avg Val Loss: 2.4323\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5524\n",
      "Epoch [1655/2000], Avg Train Loss: 3.5524\n",
      "Epoch [1655/2000], Avg Val Loss: 2.4324\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1656/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5279\n",
      "Epoch [1656/2000], Avg Train Loss: 3.5279\n",
      "Epoch [1656/2000], Avg Val Loss: 2.4325\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5313\n",
      "Epoch [1657/2000], Avg Train Loss: 3.5313\n",
      "Epoch [1657/2000], Avg Val Loss: 2.4327\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1658/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5530\n",
      "Epoch [1658/2000], Avg Train Loss: 3.5530\n",
      "Epoch [1658/2000], Avg Val Loss: 2.4329\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1659/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5547\n",
      "Epoch [1659/2000], Avg Train Loss: 3.5547\n",
      "Epoch [1659/2000], Avg Val Loss: 2.4329\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1660/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5318\n",
      "Epoch [1660/2000], Avg Train Loss: 3.5318\n",
      "Epoch [1660/2000], Avg Val Loss: 2.4326\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1661/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5111\n",
      "Epoch [1661/2000], Avg Train Loss: 3.5111\n",
      "Epoch [1661/2000], Avg Val Loss: 2.4323\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1662/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5327\n",
      "Epoch [1662/2000], Avg Train Loss: 3.5327\n",
      "Epoch [1662/2000], Avg Val Loss: 2.4318\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1663/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5110\n",
      "Epoch [1663/2000], Avg Train Loss: 3.5110\n",
      "Epoch [1663/2000], Avg Val Loss: 2.4314\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5479\n",
      "Epoch [1664/2000], Avg Train Loss: 3.5479\n",
      "Epoch [1664/2000], Avg Val Loss: 2.4311\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1665/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4650\n",
      "Epoch [1665/2000], Avg Train Loss: 3.4650\n",
      "Epoch [1665/2000], Avg Val Loss: 2.4309\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1666/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4990\n",
      "Epoch [1666/2000], Avg Train Loss: 3.4990\n",
      "Epoch [1666/2000], Avg Val Loss: 2.4307\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1667/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5024\n",
      "Epoch [1667/2000], Avg Train Loss: 3.5024\n",
      "Epoch [1667/2000], Avg Val Loss: 2.4304\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1668/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5179\n",
      "Epoch [1668/2000], Avg Train Loss: 3.5179\n",
      "Epoch [1668/2000], Avg Val Loss: 2.4300\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1669/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5601\n",
      "Epoch [1669/2000], Avg Train Loss: 3.5601\n",
      "Epoch [1669/2000], Avg Val Loss: 2.4299\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1670/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5259\n",
      "Epoch [1670/2000], Avg Train Loss: 3.5259\n",
      "Epoch [1670/2000], Avg Val Loss: 2.4299\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1671/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5446\n",
      "Epoch [1671/2000], Avg Train Loss: 3.5446\n",
      "Epoch [1671/2000], Avg Val Loss: 2.4297\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4916\n",
      "Epoch [1672/2000], Avg Train Loss: 3.4916\n",
      "Epoch [1672/2000], Avg Val Loss: 2.4297\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1673/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5111\n",
      "Epoch [1673/2000], Avg Train Loss: 3.5111\n",
      "Epoch [1673/2000], Avg Val Loss: 2.4298\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5064\n",
      "Epoch [1674/2000], Avg Train Loss: 3.5064\n",
      "Epoch [1674/2000], Avg Val Loss: 2.4299\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5688\n",
      "Epoch [1675/2000], Avg Train Loss: 3.5688\n",
      "Epoch [1675/2000], Avg Val Loss: 2.4302\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1676/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5076\n",
      "Epoch [1676/2000], Avg Train Loss: 3.5076\n",
      "Epoch [1676/2000], Avg Val Loss: 2.4306\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4726\n",
      "Epoch [1677/2000], Avg Train Loss: 3.4726\n",
      "Epoch [1677/2000], Avg Val Loss: 2.4309\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1678/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4856\n",
      "Epoch [1678/2000], Avg Train Loss: 3.4856\n",
      "Epoch [1678/2000], Avg Val Loss: 2.4310\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1679/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4961\n",
      "Epoch [1679/2000], Avg Train Loss: 3.4961\n",
      "Epoch [1679/2000], Avg Val Loss: 2.4311\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5096\n",
      "Epoch [1680/2000], Avg Train Loss: 3.5096\n",
      "Epoch [1680/2000], Avg Val Loss: 2.4314\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1681/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4951\n",
      "Epoch [1681/2000], Avg Train Loss: 3.4951\n",
      "Epoch [1681/2000], Avg Val Loss: 2.4319\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5030\n",
      "Epoch [1682/2000], Avg Train Loss: 3.5030\n",
      "Epoch [1682/2000], Avg Val Loss: 2.4325\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1683/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5018\n",
      "Epoch [1683/2000], Avg Train Loss: 3.5018\n",
      "Epoch [1683/2000], Avg Val Loss: 2.4332\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4805\n",
      "Epoch [1684/2000], Avg Train Loss: 3.4805\n",
      "Epoch [1684/2000], Avg Val Loss: 2.4337\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1685/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5219\n",
      "Epoch [1685/2000], Avg Train Loss: 3.5219\n",
      "Epoch [1685/2000], Avg Val Loss: 2.4342\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4924\n",
      "Epoch [1686/2000], Avg Train Loss: 3.4924\n",
      "Epoch [1686/2000], Avg Val Loss: 2.4347\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1687/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4849\n",
      "Epoch [1687/2000], Avg Train Loss: 3.4849\n",
      "Epoch [1687/2000], Avg Val Loss: 2.4352\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1688/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5049\n",
      "Epoch [1688/2000], Avg Train Loss: 3.5049\n",
      "Epoch [1688/2000], Avg Val Loss: 2.4358\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1689/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5129\n",
      "Epoch [1689/2000], Avg Train Loss: 3.5129\n",
      "Epoch [1689/2000], Avg Val Loss: 2.4363\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1690/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4984\n",
      "Epoch [1690/2000], Avg Train Loss: 3.4984\n",
      "Epoch [1690/2000], Avg Val Loss: 2.4369\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4941\n",
      "Epoch [1691/2000], Avg Train Loss: 3.4941\n",
      "Epoch [1691/2000], Avg Val Loss: 2.4373\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5002\n",
      "Epoch [1692/2000], Avg Train Loss: 3.5002\n",
      "Epoch [1692/2000], Avg Val Loss: 2.4376\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1693/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4935\n",
      "Epoch [1693/2000], Avg Train Loss: 3.4935\n",
      "Epoch [1693/2000], Avg Val Loss: 2.4381\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1694/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5353\n",
      "Epoch [1694/2000], Avg Train Loss: 3.5353\n",
      "Epoch [1694/2000], Avg Val Loss: 2.4384\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4983\n",
      "Epoch [1695/2000], Avg Train Loss: 3.4983\n",
      "Epoch [1695/2000], Avg Val Loss: 2.4386\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1696/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4865\n",
      "Epoch [1696/2000], Avg Train Loss: 3.4865\n",
      "Epoch [1696/2000], Avg Val Loss: 2.4388\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1697/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4959\n",
      "Epoch [1697/2000], Avg Train Loss: 3.4959\n",
      "Epoch [1697/2000], Avg Val Loss: 2.4391\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1698/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4620\n",
      "Epoch [1698/2000], Avg Train Loss: 3.4620\n",
      "Epoch [1698/2000], Avg Val Loss: 2.4394\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1699/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4811\n",
      "Epoch [1699/2000], Avg Train Loss: 3.4811\n",
      "Epoch [1699/2000], Avg Val Loss: 2.4398\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5062\n",
      "Epoch [1700/2000], Avg Train Loss: 3.5062\n",
      "Epoch [1700/2000], Avg Val Loss: 2.4399\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1701/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5354\n",
      "Epoch [1701/2000], Avg Train Loss: 3.5354\n",
      "Epoch [1701/2000], Avg Val Loss: 2.4398\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1702/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5111\n",
      "Epoch [1702/2000], Avg Train Loss: 3.5111\n",
      "Epoch [1702/2000], Avg Val Loss: 2.4395\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1703/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5141\n",
      "Epoch [1703/2000], Avg Train Loss: 3.5141\n",
      "Epoch [1703/2000], Avg Val Loss: 2.4393\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1704/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5135\n",
      "Epoch [1704/2000], Avg Train Loss: 3.5135\n",
      "Epoch [1704/2000], Avg Val Loss: 2.4386\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1705/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4794\n",
      "Epoch [1705/2000], Avg Train Loss: 3.4794\n",
      "Epoch [1705/2000], Avg Val Loss: 2.4379\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [1706/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5088\n",
      "Epoch [1706/2000], Avg Train Loss: 3.5088\n",
      "Epoch [1706/2000], Avg Val Loss: 2.4375\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [1707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4718\n",
      "Epoch [1707/2000], Avg Train Loss: 3.4718\n",
      "Epoch [1707/2000], Avg Val Loss: 2.4370\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [1708/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4987\n",
      "Epoch [1708/2000], Avg Train Loss: 3.4987\n",
      "Epoch [1708/2000], Avg Val Loss: 2.4366\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [1709/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5289\n",
      "Epoch [1709/2000], Avg Train Loss: 3.5289\n",
      "Epoch [1709/2000], Avg Val Loss: 2.4364\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [1710/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5249\n",
      "Epoch [1710/2000], Avg Train Loss: 3.5249\n",
      "Epoch [1710/2000], Avg Val Loss: 2.4363\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [1711/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5006\n",
      "Epoch [1711/2000], Avg Train Loss: 3.5006\n",
      "Epoch [1711/2000], Avg Val Loss: 2.4361\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [1712/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4984\n",
      "Epoch [1712/2000], Avg Train Loss: 3.4984\n",
      "Epoch [1712/2000], Avg Val Loss: 2.4360\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [1713/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4943\n",
      "Epoch [1713/2000], Avg Train Loss: 3.4943\n",
      "Epoch [1713/2000], Avg Val Loss: 2.4360\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [1714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5060\n",
      "Epoch [1714/2000], Avg Train Loss: 3.5060\n",
      "Epoch [1714/2000], Avg Val Loss: 2.4360\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [1715/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4986\n",
      "Epoch [1715/2000], Avg Train Loss: 3.4986\n",
      "Epoch [1715/2000], Avg Val Loss: 2.4362\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [1716/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5392\n",
      "Epoch [1716/2000], Avg Train Loss: 3.5392\n",
      "Epoch [1716/2000], Avg Val Loss: 2.4363\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [1717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5349\n",
      "Epoch [1717/2000], Avg Train Loss: 3.5349\n",
      "Epoch [1717/2000], Avg Val Loss: 2.4366\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [1718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4984\n",
      "Epoch [1718/2000], Avg Train Loss: 3.4984\n",
      "Epoch [1718/2000], Avg Val Loss: 2.4367\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [1719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4850\n",
      "Epoch [1719/2000], Avg Train Loss: 3.4850\n",
      "Epoch [1719/2000], Avg Val Loss: 2.4370\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [1720/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4961\n",
      "Epoch [1720/2000], Avg Train Loss: 3.4961\n",
      "Epoch [1720/2000], Avg Val Loss: 2.4373\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [1721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4943\n",
      "Epoch [1721/2000], Avg Train Loss: 3.4943\n",
      "Epoch [1721/2000], Avg Val Loss: 2.4374\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [1722/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4867\n",
      "Epoch [1722/2000], Avg Train Loss: 3.4867\n",
      "Epoch [1722/2000], Avg Val Loss: 2.4377\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [1723/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5429\n",
      "Epoch [1723/2000], Avg Train Loss: 3.5429\n",
      "Epoch [1723/2000], Avg Val Loss: 2.4380\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [1724/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4919\n",
      "Epoch [1724/2000], Avg Train Loss: 3.4919\n",
      "Epoch [1724/2000], Avg Val Loss: 2.4382\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [1725/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5015\n",
      "Epoch [1725/2000], Avg Train Loss: 3.5015\n",
      "Epoch [1725/2000], Avg Val Loss: 2.4387\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [1726/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5142\n",
      "Epoch [1726/2000], Avg Train Loss: 3.5142\n",
      "Epoch [1726/2000], Avg Val Loss: 2.4391\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [1727/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4965\n",
      "Epoch [1727/2000], Avg Train Loss: 3.4965\n",
      "Epoch [1727/2000], Avg Val Loss: 2.4398\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [1728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4772\n",
      "Epoch [1728/2000], Avg Train Loss: 3.4772\n",
      "Epoch [1728/2000], Avg Val Loss: 2.4402\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [1729/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4786\n",
      "Epoch [1729/2000], Avg Train Loss: 3.4786\n",
      "Epoch [1729/2000], Avg Val Loss: 2.4407\n",
      "Validation loss did not improve. Patience: 92/100\n",
      "\n",
      "LOG: Epoch [1730/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5584\n",
      "Epoch [1730/2000], Avg Train Loss: 3.5584\n",
      "Epoch [1730/2000], Avg Val Loss: 2.4409\n",
      "Validation loss did not improve. Patience: 93/100\n",
      "\n",
      "LOG: Epoch [1731/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4871\n",
      "Epoch [1731/2000], Avg Train Loss: 3.4871\n",
      "Epoch [1731/2000], Avg Val Loss: 2.4413\n",
      "Validation loss did not improve. Patience: 94/100\n",
      "\n",
      "LOG: Epoch [1732/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4901\n",
      "Epoch [1732/2000], Avg Train Loss: 3.4901\n",
      "Epoch [1732/2000], Avg Val Loss: 2.4417\n",
      "Validation loss did not improve. Patience: 95/100\n",
      "\n",
      "LOG: Epoch [1733/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4977\n",
      "Epoch [1733/2000], Avg Train Loss: 3.4977\n",
      "Epoch [1733/2000], Avg Val Loss: 2.4418\n",
      "Validation loss did not improve. Patience: 96/100\n",
      "\n",
      "LOG: Epoch [1734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4970\n",
      "Epoch [1734/2000], Avg Train Loss: 3.4970\n",
      "Epoch [1734/2000], Avg Val Loss: 2.4421\n",
      "Validation loss did not improve. Patience: 97/100\n",
      "\n",
      "LOG: Epoch [1735/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5237\n",
      "Epoch [1735/2000], Avg Train Loss: 3.5237\n",
      "Epoch [1735/2000], Avg Val Loss: 2.4424\n",
      "Validation loss did not improve. Patience: 98/100\n",
      "\n",
      "LOG: Epoch [1736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4742\n",
      "Epoch [1736/2000], Avg Train Loss: 3.4742\n",
      "Epoch [1736/2000], Avg Val Loss: 2.4425\n",
      "Validation loss did not improve. Patience: 99/100\n",
      "\n",
      "LOG: Epoch [1737/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4783\n",
      "Epoch [1737/2000], Avg Train Loss: 3.4783\n",
      "Epoch [1737/2000], Avg Val Loss: 2.4424\n",
      "Validation loss did not improve. Patience: 100/100\n",
      "Early stopping triggered at epoch 1737. No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_model = SupConNet().to(device)\n",
    "tscl_criterion = SupConLoss(temperature=0.07).to(device)\n",
    "tscl_optimizer = optim.Adam(tscl_model.parameters(), lr=1e-4, weight_decay=1e-5)  # Increased learning rate\n",
    "\n",
    "tscl_patience = 100\n",
    "tscl_best_val_loss = float('inf')\n",
    "tscl_epochs_without_improvement = 0\n",
    "\n",
    "tscl_num_epochs = 2000\n",
    "tscl_train_losses = []\n",
    "tscl_val_losses = []\n",
    "\n",
    "# TRAINING\n",
    "for tscl_epoch in range(tscl_num_epochs):\n",
    "    print(f\"\\nLOG: Epoch [{tscl_epoch + 1}/{tscl_num_epochs}] - Training\")\n",
    "    tscl_model.train()\n",
    "    tscl_total_loss = 0\n",
    "\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_train_loader):\n",
    "        vectors = vectors.to(device).float()  # moving input tensors to GPU\n",
    "        labels = labels.to(device)  # moving labels to GPU\n",
    "\n",
    "        # forward pass to get projections\n",
    "        projections = tscl_model(vectors)\n",
    "\n",
    "        # calc contrastive loss\n",
    "        loss = tscl_criterion(projections, labels)\n",
    "\n",
    "        # backprop and optimization\n",
    "        tscl_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        tscl_optimizer.step()\n",
    "\n",
    "        tscl_total_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 1 == 0:\n",
    "            print(f\"    Batch [{batch_idx + 1}/{len(tscl_train_loader)}], \"\n",
    "                  f\"Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc avg training loss for the epoch\n",
    "    tscl_avg_train_loss = tscl_total_loss / len(tscl_train_loader)\n",
    "    tscl_train_losses.append(tscl_avg_train_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {tscl_avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    tscl_model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (vectors, labels) in enumerate(tscl_val_loader):\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            projections = tscl_model(vectors)\n",
    "\n",
    "            loss = tscl_criterion(projections, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Batch [{batch_idx + 1}/{len(tscl_val_loader)}], \"\n",
    "                      f\"Val Loss: {loss.item():.4f}\")\n",
    "\n",
    "    tscl_avg_val_loss = total_val_loss / len(tscl_val_loader)\n",
    "    tscl_val_losses.append(tscl_avg_val_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Val Loss: {tscl_avg_val_loss:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if tscl_avg_val_loss < tscl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_best_val_loss:.4f} to {tscl_avg_val_loss:.4f}. Saving model...\")\n",
    "        tscl_best_val_loss = tscl_avg_val_loss\n",
    "        tscl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        tscl_epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {tscl_epochs_without_improvement}/{tscl_patience}\")\n",
    "\n",
    "    # stopping training if validation loss hasn't improved for patience amount of epochs\n",
    "    if tscl_epochs_without_improvement >= tscl_patience:\n",
    "        print(f\"Early stopping triggered at epoch {tscl_epoch + 1}. No improvement for {tscl_patience} epochs.\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(tscl_train_losses) + 1), tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, len(tscl_val_losses) + 1), tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:58.487046Z",
     "iopub.status.busy": "2025-05-08T19:27:58.486045Z",
     "iopub.status.idle": "2025-05-08T19:27:58.620237Z",
     "shell.execute_reply": "2025-05-08T19:27:58.620237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/12], Loss: 5.4912\n",
      "\n",
      "Test Loss: 5.0846\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "tscl_model.eval()\n",
    "total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = tscl_model(vectors)\n",
    "        loss = criterion(projections, labels)\n",
    "        total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(tscl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "avg_test_loss = total_test_loss / len(tscl_test_loader)\n",
    "print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs = range(1, len(tscl_train_losses) + 1)\n",
    "plt.plot(epochs, tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(epochs, tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving representations learnt by Typical SCL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:58.622243Z",
     "iopub.status.busy": "2025-05-08T19:27:58.622243Z",
     "iopub.status.idle": "2025-05-08T19:27:58.686222Z",
     "shell.execute_reply": "2025-05-08T19:27:58.686222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'tscl_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'tscl_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/12 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'tscl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "tscl_rep_dir = \"tscl_representations\"\n",
    "os.makedirs(tscl_rep_dir, exist_ok=True)\n",
    "\n",
    "tscl_loaders = {\n",
    "    'train': tscl_train_loader,\n",
    "    'val': tscl_val_loader,\n",
    "    'test': tscl_test_loader\n",
    "}\n",
    "\n",
    "tscl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_split_name, tscl_loader in tscl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {tscl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        tscl_split_dir = os.path.join(tscl_rep_dir, tscl_split_name)\n",
    "        os.makedirs(tscl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for tscl_batch_idx, (tscl_vectors, tscl_labels) in enumerate(tscl_loader):\n",
    "            tscl_vectors = tscl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            tscl_projections = tscl_model(tscl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            tscl_projections_np = tscl_projections.cpu().numpy()\n",
    "            tscl_labels_np = tscl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_encoded_batch_{tscl_batch_idx}.npy\"), tscl_projections_np)\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_labels_batch_{tscl_batch_idx}.npy\"), tscl_labels_np)\n",
    "            \n",
    "            if (tscl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {tscl_batch_idx + 1}/{len(tscl_loader)} for {tscl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {tscl_split_name} dataset. Representations saved in '{tscl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying representations learnt by SCL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:58.688763Z",
     "iopub.status.busy": "2025-05-08T19:27:58.688763Z",
     "iopub.status.idle": "2025-05-08T19:27:58.692773Z",
     "shell.execute_reply": "2025-05-08T19:27:58.692773Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_tscl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    tscl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    tscl_all_reps = []\n",
    "    tscl_all_labels = []\n",
    "\n",
    "    for tscl_rep_file in tscl_rep_files:\n",
    "        #deriving label filenames\n",
    "        tscl_label_file = tscl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        tscl_reps = np.load(tscl_rep_file)\n",
    "        tscl_labels = np.load(tscl_label_file)\n",
    "\n",
    "        tscl_all_reps.append(tscl_reps)\n",
    "        tscl_all_labels.append(tscl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    tscl_all_reps = np.concatenate(tscl_all_reps, axis = 0)\n",
    "    tscl_all_labels = np.concatenate(tscl_all_labels, axis = 0)\n",
    "\n",
    "    return tscl_all_reps, tscl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:58.695065Z",
     "iopub.status.busy": "2025-05-08T19:27:58.695065Z",
     "iopub.status.idle": "2025-05-08T19:27:58.825574Z",
     "shell.execute_reply": "2025-05-08T19:27:58.825574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (280, 128)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 128)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "tscl_lrm_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_lrm_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_lrm_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_lrm_train_reps, tscl_lrm_train_labels = load_tscl_reps_and_labels(tscl_lrm_train_dir)\n",
    "tscl_lrm_val_reps, tscl_lrm_val_labels = load_tscl_reps_and_labels(tscl_lrm_val_dir)\n",
    "tscl_lrm_test_reps, tscl_lrm_test_labels = load_tscl_reps_and_labels(tscl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", tscl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:58.828083Z",
     "iopub.status.busy": "2025-05-08T19:27:58.828083Z",
     "iopub.status.idle": "2025-05-08T19:27:58.882774Z",
     "shell.execute_reply": "2025-05-08T19:27:58.882774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 91.43%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       0.83      1.00      0.91         5\n",
      "           3       1.00      0.80      0.89         5\n",
      "           4       1.00      0.60      0.75         5\n",
      "           5       0.80      0.80      0.80         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      0.80      0.89         5\n",
      "           8       0.67      0.80      0.73         5\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       0.83      1.00      0.91         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       0.83      1.00      0.91         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.91        70\n",
      "   macro avg       0.93      0.91      0.91        70\n",
      "weighted avg       0.93      0.91      0.91        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 84.30%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       245\n",
      "           1       0.82      0.83      0.82        76\n",
      "           2       0.92      0.93      0.93       226\n",
      "           3       0.77      0.98      0.86       190\n",
      "           4       0.82      0.74      0.78       244\n",
      "           5       0.71      0.72      0.71       244\n",
      "           6       1.00      0.91      0.95       234\n",
      "           7       0.78      0.79      0.78       178\n",
      "           8       0.76      0.62      0.68       289\n",
      "           9       0.77      0.97      0.86       223\n",
      "          10       0.89      0.79      0.84       280\n",
      "          11       0.86      0.99      0.92       156\n",
      "          12       0.82      0.80      0.81       243\n",
      "          13       1.00      0.94      0.97        70\n",
      "\n",
      "    accuracy                           0.84      2898\n",
      "   macro avg       0.85      0.86      0.85      2898\n",
      "weighted avg       0.85      0.84      0.84      2898\n",
      "\n",
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# training LRM on the tscl representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "tscl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "tscl_logistic_clf.fit(tscl_lrm_train_reps, tscl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# eval on val set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "tscl_lrm_val_predictions = tscl_logistic_clf.predict(tscl_lrm_val_reps)\n",
    "tscl_lrm_val_accuracy = accuracy_score(tscl_lrm_val_labels, tscl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {tscl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(tscl_lrm_val_labels, tscl_lrm_val_predictions))\n",
    "\n",
    "# eval on test\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "tscl_lrm_test_predictions = tscl_logistic_clf.predict(tscl_lrm_test_reps)\n",
    "tscl_lrm_test_accuracy = accuracy_score(tscl_lrm_test_labels, tscl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {tscl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(tscl_lrm_test_labels, tscl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_predictions.npy'), tscl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_true_labels.npy'), tscl_lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by Typical SCL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:58.884782Z",
     "iopub.status.busy": "2025-05-08T19:27:58.884782Z",
     "iopub.status.idle": "2025-05-08T19:27:58.889133Z",
     "shell.execute_reply": "2025-05-08T19:27:58.889133Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:58.891139Z",
     "iopub.status.busy": "2025-05-08T19:27:58.891139Z",
     "iopub.status.idle": "2025-05-08T19:27:58.899326Z",
     "shell.execute_reply": "2025-05-08T19:27:58.899326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (280, 128)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 128)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "tscl_mlp_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_mlp_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_mlp_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_mlp_train_reps, tscl_mlp_train_labels = load_tscl_reps_and_labels(tscl_mlp_train_dir)\n",
    "tscl_mlp_val_reps, tscl_mlp_val_labels = load_tscl_reps_and_labels(tscl_mlp_val_dir)\n",
    "tscl_mlp_test_reps, tscl_mlp_test_labels = load_tscl_reps_and_labels(tscl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",tscl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:58.902371Z",
     "iopub.status.busy": "2025-05-08T19:27:58.901371Z",
     "iopub.status.idle": "2025-05-08T19:27:58.907947Z",
     "shell.execute_reply": "2025-05-08T19:27:58.907436Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "tscl_mlp_train_embeddings_torch = torch.tensor(tscl_mlp_train_reps, dtype=torch.float32)\n",
    "tscl_mlp_train_labels_torch = torch.tensor(tscl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_val_embeddings_torch = torch.tensor(tscl_mlp_val_reps, dtype=torch.float32)\n",
    "tscl_mlp_val_labels_torch = torch.tensor(tscl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_test_embeddings_torch = torch.tensor(tscl_mlp_test_reps, dtype=torch.float32)\n",
    "tscl_mlp_test_labels_torch = torch.tensor(tscl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "tscl_mlp_train_dataset = TensorDataset(tscl_mlp_train_embeddings_torch, tscl_mlp_train_labels_torch)\n",
    "tscl_mlp_val_dataset = TensorDataset(tscl_mlp_val_embeddings_torch, tscl_mlp_val_labels_torch)\n",
    "tscl_mlp_test_dataset = TensorDataset(tscl_mlp_test_embeddings_torch, tscl_mlp_test_labels_torch)\n",
    "\n",
    "tscl_mlp_batch_size = 64\n",
    "tscl_mlp_train_loader = DataLoader(tscl_mlp_train_dataset, batch_size=tscl_mlp_batch_size, shuffle=True)\n",
    "tscl_mlp_val_loader = DataLoader(tscl_mlp_val_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n",
    "tscl_mlp_test_loader = DataLoader(tscl_mlp_test_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:27:58.909953Z",
     "iopub.status.busy": "2025-05-08T19:27:58.909953Z",
     "iopub.status.idle": "2025-05-08T19:28:04.314739Z",
     "shell.execute_reply": "2025-05-08T19:28:04.314455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.8569  |  Val Loss: 2.8501\n",
      "Validation loss improved from inf to 2.8501.\n",
      "[Epoch 2/1000] Train Loss: 2.8064  |  Val Loss: 2.7970\n",
      "Validation loss improved from 2.8501 to 2.7970.\n",
      "[Epoch 3/1000] Train Loss: 2.7583  |  Val Loss: 2.7494\n",
      "Validation loss improved from 2.7970 to 2.7494.\n",
      "[Epoch 4/1000] Train Loss: 2.7115  |  Val Loss: 2.7052\n",
      "Validation loss improved from 2.7494 to 2.7052.\n",
      "[Epoch 5/1000] Train Loss: 2.6694  |  Val Loss: 2.6619\n",
      "Validation loss improved from 2.7052 to 2.6619.\n",
      "[Epoch 6/1000] Train Loss: 2.6333  |  Val Loss: 2.6227\n",
      "Validation loss improved from 2.6619 to 2.6227.\n",
      "[Epoch 7/1000] Train Loss: 2.5997  |  Val Loss: 2.5899\n",
      "Validation loss improved from 2.6227 to 2.5899.\n",
      "[Epoch 8/1000] Train Loss: 2.5677  |  Val Loss: 2.5637\n",
      "Validation loss improved from 2.5899 to 2.5637.\n",
      "[Epoch 9/1000] Train Loss: 2.5403  |  Val Loss: 2.5388\n",
      "Validation loss improved from 2.5637 to 2.5388.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/1000] Train Loss: 2.5150  |  Val Loss: 2.5144\n",
      "Validation loss improved from 2.5388 to 2.5144.\n",
      "[Epoch 11/1000] Train Loss: 2.4901  |  Val Loss: 2.4911\n",
      "Validation loss improved from 2.5144 to 2.4911.\n",
      "[Epoch 12/1000] Train Loss: 2.4663  |  Val Loss: 2.4691\n",
      "Validation loss improved from 2.4911 to 2.4691.\n",
      "[Epoch 13/1000] Train Loss: 2.4435  |  Val Loss: 2.4477\n",
      "Validation loss improved from 2.4691 to 2.4477.\n",
      "[Epoch 14/1000] Train Loss: 2.4213  |  Val Loss: 2.4265\n",
      "Validation loss improved from 2.4477 to 2.4265.\n",
      "[Epoch 15/1000] Train Loss: 2.3995  |  Val Loss: 2.4056\n",
      "Validation loss improved from 2.4265 to 2.4056.\n",
      "[Epoch 16/1000] Train Loss: 2.3786  |  Val Loss: 2.3851\n",
      "Validation loss improved from 2.4056 to 2.3851.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/1000] Train Loss: 2.3574  |  Val Loss: 2.3654\n",
      "Validation loss improved from 2.3851 to 2.3654.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/1000] Train Loss: 2.3374  |  Val Loss: 2.3454\n",
      "Validation loss improved from 2.3654 to 2.3454.\n",
      "[Epoch 19/1000] Train Loss: 2.3163  |  Val Loss: 2.3257\n",
      "Validation loss improved from 2.3454 to 2.3257.\n",
      "[Epoch 20/1000] Train Loss: 2.2955  |  Val Loss: 2.3056\n",
      "Validation loss improved from 2.3257 to 2.3056.\n",
      "[Epoch 21/1000] Train Loss: 2.2752  |  Val Loss: 2.2855\n",
      "Validation loss improved from 2.3056 to 2.2855.\n",
      "[Epoch 22/1000] Train Loss: 2.2543  |  Val Loss: 2.2648\n",
      "Validation loss improved from 2.2855 to 2.2648.\n",
      "[Epoch 23/1000] Train Loss: 2.2318  |  Val Loss: 2.2443\n",
      "Validation loss improved from 2.2648 to 2.2443.\n",
      "[Epoch 24/1000] Train Loss: 2.2102  |  Val Loss: 2.2233\n",
      "Validation loss improved from 2.2443 to 2.2233.\n",
      "[Epoch 25/1000] Train Loss: 2.1875  |  Val Loss: 2.2021\n",
      "Validation loss improved from 2.2233 to 2.2021.\n",
      "[Epoch 26/1000] Train Loss: 2.1647  |  Val Loss: 2.1807\n",
      "Validation loss improved from 2.2021 to 2.1807.\n",
      "[Epoch 27/1000] Train Loss: 2.1419  |  Val Loss: 2.1597\n",
      "Validation loss improved from 2.1807 to 2.1597.\n",
      "[Epoch 28/1000] Train Loss: 2.1191  |  Val Loss: 2.1389\n",
      "Validation loss improved from 2.1597 to 2.1389.\n",
      "[Epoch 29/1000] Train Loss: 2.0961  |  Val Loss: 2.1176\n",
      "Validation loss improved from 2.1389 to 2.1176.\n",
      "[Epoch 30/1000] Train Loss: 2.0735  |  Val Loss: 2.0963\n",
      "Validation loss improved from 2.1176 to 2.0963.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31/1000] Train Loss: 2.0501  |  Val Loss: 2.0752\n",
      "Validation loss improved from 2.0963 to 2.0752.\n",
      "[Epoch 32/1000] Train Loss: 2.0272  |  Val Loss: 2.0542\n",
      "Validation loss improved from 2.0752 to 2.0542.\n",
      "[Epoch 33/1000] Train Loss: 2.0037  |  Val Loss: 2.0325\n",
      "Validation loss improved from 2.0542 to 2.0325.\n",
      "[Epoch 34/1000] Train Loss: 1.9794  |  Val Loss: 2.0102\n",
      "Validation loss improved from 2.0325 to 2.0102.\n",
      "[Epoch 35/1000] Train Loss: 1.9552  |  Val Loss: 1.9871\n",
      "Validation loss improved from 2.0102 to 1.9871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36/1000] Train Loss: 1.9301  |  Val Loss: 1.9642\n",
      "Validation loss improved from 1.9871 to 1.9642.\n",
      "[Epoch 37/1000] Train Loss: 1.9060  |  Val Loss: 1.9417\n",
      "Validation loss improved from 1.9642 to 1.9417.\n",
      "[Epoch 38/1000] Train Loss: 1.8817  |  Val Loss: 1.9192\n",
      "Validation loss improved from 1.9417 to 1.9192.\n",
      "[Epoch 39/1000] Train Loss: 1.8574  |  Val Loss: 1.8968\n",
      "Validation loss improved from 1.9192 to 1.8968.\n",
      "[Epoch 40/1000] Train Loss: 1.8335  |  Val Loss: 1.8747\n",
      "Validation loss improved from 1.8968 to 1.8747.\n",
      "[Epoch 41/1000] Train Loss: 1.8094  |  Val Loss: 1.8531\n",
      "Validation loss improved from 1.8747 to 1.8531.\n",
      "[Epoch 42/1000] Train Loss: 1.7860  |  Val Loss: 1.8321\n",
      "Validation loss improved from 1.8531 to 1.8321.\n",
      "[Epoch 43/1000] Train Loss: 1.7626  |  Val Loss: 1.8110\n",
      "Validation loss improved from 1.8321 to 1.8110.\n",
      "[Epoch 44/1000] Train Loss: 1.7400  |  Val Loss: 1.7902\n",
      "Validation loss improved from 1.8110 to 1.7902.\n",
      "[Epoch 45/1000] Train Loss: 1.7180  |  Val Loss: 1.7691\n",
      "Validation loss improved from 1.7902 to 1.7691.\n",
      "[Epoch 46/1000] Train Loss: 1.6959  |  Val Loss: 1.7491\n",
      "Validation loss improved from 1.7691 to 1.7491.\n",
      "[Epoch 47/1000] Train Loss: 1.6748  |  Val Loss: 1.7295\n",
      "Validation loss improved from 1.7491 to 1.7295.\n",
      "[Epoch 48/1000] Train Loss: 1.6543  |  Val Loss: 1.7107\n",
      "Validation loss improved from 1.7295 to 1.7107.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 49/1000] Train Loss: 1.6338  |  Val Loss: 1.6922\n",
      "Validation loss improved from 1.7107 to 1.6922.\n",
      "[Epoch 50/1000] Train Loss: 1.6138  |  Val Loss: 1.6737\n",
      "Validation loss improved from 1.6922 to 1.6737.\n",
      "[Epoch 51/1000] Train Loss: 1.5945  |  Val Loss: 1.6556\n",
      "Validation loss improved from 1.6737 to 1.6556.\n",
      "[Epoch 52/1000] Train Loss: 1.5751  |  Val Loss: 1.6383\n",
      "Validation loss improved from 1.6556 to 1.6383.\n",
      "[Epoch 53/1000] Train Loss: 1.5564  |  Val Loss: 1.6214\n",
      "Validation loss improved from 1.6383 to 1.6214.\n",
      "[Epoch 54/1000] Train Loss: 1.5384  |  Val Loss: 1.6048\n",
      "Validation loss improved from 1.6214 to 1.6048.\n",
      "[Epoch 55/1000] Train Loss: 1.5205  |  Val Loss: 1.5884\n",
      "Validation loss improved from 1.6048 to 1.5884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 56/1000] Train Loss: 1.5032  |  Val Loss: 1.5725\n",
      "Validation loss improved from 1.5884 to 1.5725.\n",
      "[Epoch 57/1000] Train Loss: 1.4861  |  Val Loss: 1.5561\n",
      "Validation loss improved from 1.5725 to 1.5561.\n",
      "[Epoch 58/1000] Train Loss: 1.4692  |  Val Loss: 1.5402\n",
      "Validation loss improved from 1.5561 to 1.5402.\n",
      "[Epoch 59/1000] Train Loss: 1.4525  |  Val Loss: 1.5249\n",
      "Validation loss improved from 1.5402 to 1.5249.\n",
      "[Epoch 60/1000] Train Loss: 1.4366  |  Val Loss: 1.5097\n",
      "Validation loss improved from 1.5249 to 1.5097.\n",
      "[Epoch 61/1000] Train Loss: 1.4206  |  Val Loss: 1.4948\n",
      "Validation loss improved from 1.5097 to 1.4948.\n",
      "[Epoch 62/1000] Train Loss: 1.4049  |  Val Loss: 1.4802\n",
      "Validation loss improved from 1.4948 to 1.4802.\n",
      "[Epoch 63/1000] Train Loss: 1.3896  |  Val Loss: 1.4654\n",
      "Validation loss improved from 1.4802 to 1.4654.\n",
      "[Epoch 64/1000] Train Loss: 1.3743  |  Val Loss: 1.4509\n",
      "Validation loss improved from 1.4654 to 1.4509.\n",
      "[Epoch 65/1000] Train Loss: 1.3594  |  Val Loss: 1.4365\n",
      "Validation loss improved from 1.4509 to 1.4365.\n",
      "[Epoch 66/1000] Train Loss: 1.3447  |  Val Loss: 1.4226\n",
      "Validation loss improved from 1.4365 to 1.4226.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 67/1000] Train Loss: 1.3301  |  Val Loss: 1.4087\n",
      "Validation loss improved from 1.4226 to 1.4087.\n",
      "[Epoch 68/1000] Train Loss: 1.3157  |  Val Loss: 1.3953\n",
      "Validation loss improved from 1.4087 to 1.3953.\n",
      "[Epoch 69/1000] Train Loss: 1.3014  |  Val Loss: 1.3818\n",
      "Validation loss improved from 1.3953 to 1.3818.\n",
      "[Epoch 70/1000] Train Loss: 1.2870  |  Val Loss: 1.3686\n",
      "Validation loss improved from 1.3818 to 1.3686.\n",
      "[Epoch 71/1000] Train Loss: 1.2734  |  Val Loss: 1.3557\n",
      "Validation loss improved from 1.3686 to 1.3557.\n",
      "[Epoch 72/1000] Train Loss: 1.2592  |  Val Loss: 1.3433\n",
      "Validation loss improved from 1.3557 to 1.3433.\n",
      "[Epoch 73/1000] Train Loss: 1.2459  |  Val Loss: 1.3312\n",
      "Validation loss improved from 1.3433 to 1.3312.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 74/1000] Train Loss: 1.2329  |  Val Loss: 1.3183\n",
      "Validation loss improved from 1.3312 to 1.3183.\n",
      "[Epoch 75/1000] Train Loss: 1.2198  |  Val Loss: 1.3059\n",
      "Validation loss improved from 1.3183 to 1.3059.\n",
      "[Epoch 76/1000] Train Loss: 1.2071  |  Val Loss: 1.2940\n",
      "Validation loss improved from 1.3059 to 1.2940.\n",
      "[Epoch 77/1000] Train Loss: 1.1946  |  Val Loss: 1.2814\n",
      "Validation loss improved from 1.2940 to 1.2814.\n",
      "[Epoch 78/1000] Train Loss: 1.1820  |  Val Loss: 1.2692\n",
      "Validation loss improved from 1.2814 to 1.2692.\n",
      "[Epoch 79/1000] Train Loss: 1.1700  |  Val Loss: 1.2571\n",
      "Validation loss improved from 1.2692 to 1.2571.\n",
      "[Epoch 80/1000] Train Loss: 1.1578  |  Val Loss: 1.2455\n",
      "Validation loss improved from 1.2571 to 1.2455.\n",
      "[Epoch 81/1000] Train Loss: 1.1458  |  Val Loss: 1.2337\n",
      "Validation loss improved from 1.2455 to 1.2337.\n",
      "[Epoch 82/1000] Train Loss: 1.1340  |  Val Loss: 1.2226\n",
      "Validation loss improved from 1.2337 to 1.2226.\n",
      "[Epoch 83/1000] Train Loss: 1.1228  |  Val Loss: 1.2118\n",
      "Validation loss improved from 1.2226 to 1.2118.\n",
      "[Epoch 84/1000] Train Loss: 1.1109  |  Val Loss: 1.2007\n",
      "Validation loss improved from 1.2118 to 1.2007.\n",
      "[Epoch 85/1000] Train Loss: 1.0999  |  Val Loss: 1.1894\n",
      "Validation loss improved from 1.2007 to 1.1894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 86/1000] Train Loss: 1.0887  |  Val Loss: 1.1790\n",
      "Validation loss improved from 1.1894 to 1.1790.\n",
      "[Epoch 87/1000] Train Loss: 1.0776  |  Val Loss: 1.1685\n",
      "Validation loss improved from 1.1790 to 1.1685.\n",
      "[Epoch 88/1000] Train Loss: 1.0666  |  Val Loss: 1.1578\n",
      "Validation loss improved from 1.1685 to 1.1578.\n",
      "[Epoch 89/1000] Train Loss: 1.0561  |  Val Loss: 1.1472\n",
      "Validation loss improved from 1.1578 to 1.1472.\n",
      "[Epoch 90/1000] Train Loss: 1.0455  |  Val Loss: 1.1367\n",
      "Validation loss improved from 1.1472 to 1.1367.\n",
      "[Epoch 91/1000] Train Loss: 1.0350  |  Val Loss: 1.1266\n",
      "Validation loss improved from 1.1367 to 1.1266.\n",
      "[Epoch 92/1000] Train Loss: 1.0244  |  Val Loss: 1.1164\n",
      "Validation loss improved from 1.1266 to 1.1164.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 93/1000] Train Loss: 1.0141  |  Val Loss: 1.1067\n",
      "Validation loss improved from 1.1164 to 1.1067.\n",
      "[Epoch 94/1000] Train Loss: 1.0039  |  Val Loss: 1.0970\n",
      "Validation loss improved from 1.1067 to 1.0970.\n",
      "[Epoch 95/1000] Train Loss: 0.9937  |  Val Loss: 1.0875\n",
      "Validation loss improved from 1.0970 to 1.0875.\n",
      "[Epoch 96/1000] Train Loss: 0.9840  |  Val Loss: 1.0778\n",
      "Validation loss improved from 1.0875 to 1.0778.\n",
      "[Epoch 97/1000] Train Loss: 0.9739  |  Val Loss: 1.0683\n",
      "Validation loss improved from 1.0778 to 1.0683.\n",
      "[Epoch 98/1000] Train Loss: 0.9639  |  Val Loss: 1.0585\n",
      "Validation loss improved from 1.0683 to 1.0585.\n",
      "[Epoch 99/1000] Train Loss: 0.9543  |  Val Loss: 1.0491\n",
      "Validation loss improved from 1.0585 to 1.0491.\n",
      "[Epoch 100/1000] Train Loss: 0.9448  |  Val Loss: 1.0402\n",
      "Validation loss improved from 1.0491 to 1.0402.\n",
      "[Epoch 101/1000] Train Loss: 0.9347  |  Val Loss: 1.0309\n",
      "Validation loss improved from 1.0402 to 1.0309.\n",
      "[Epoch 102/1000] Train Loss: 0.9252  |  Val Loss: 1.0215\n",
      "Validation loss improved from 1.0309 to 1.0215.\n",
      "[Epoch 103/1000] Train Loss: 0.9156  |  Val Loss: 1.0125\n",
      "Validation loss improved from 1.0215 to 1.0125.\n",
      "[Epoch 104/1000] Train Loss: 0.9062  |  Val Loss: 1.0035\n",
      "Validation loss improved from 1.0125 to 1.0035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 105/1000] Train Loss: 0.8971  |  Val Loss: 0.9951\n",
      "Validation loss improved from 1.0035 to 0.9951.\n",
      "[Epoch 106/1000] Train Loss: 0.8878  |  Val Loss: 0.9868\n",
      "Validation loss improved from 0.9951 to 0.9868.\n",
      "[Epoch 107/1000] Train Loss: 0.8789  |  Val Loss: 0.9778\n",
      "Validation loss improved from 0.9868 to 0.9778.\n",
      "[Epoch 108/1000] Train Loss: 0.8696  |  Val Loss: 0.9686\n",
      "Validation loss improved from 0.9778 to 0.9686.\n",
      "[Epoch 109/1000] Train Loss: 0.8609  |  Val Loss: 0.9594\n",
      "Validation loss improved from 0.9686 to 0.9594.\n",
      "[Epoch 110/1000] Train Loss: 0.8517  |  Val Loss: 0.9505\n",
      "Validation loss improved from 0.9594 to 0.9505.\n",
      "[Epoch 111/1000] Train Loss: 0.8428  |  Val Loss: 0.9418\n",
      "Validation loss improved from 0.9505 to 0.9418.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 112/1000] Train Loss: 0.8341  |  Val Loss: 0.9334\n",
      "Validation loss improved from 0.9418 to 0.9334.\n",
      "[Epoch 113/1000] Train Loss: 0.8251  |  Val Loss: 0.9253\n",
      "Validation loss improved from 0.9334 to 0.9253.\n",
      "[Epoch 114/1000] Train Loss: 0.8163  |  Val Loss: 0.9168\n",
      "Validation loss improved from 0.9253 to 0.9168.\n",
      "[Epoch 115/1000] Train Loss: 0.8078  |  Val Loss: 0.9085\n",
      "Validation loss improved from 0.9168 to 0.9085.\n",
      "[Epoch 116/1000] Train Loss: 0.7988  |  Val Loss: 0.8994\n",
      "Validation loss improved from 0.9085 to 0.8994.\n",
      "[Epoch 117/1000] Train Loss: 0.7900  |  Val Loss: 0.8910\n",
      "Validation loss improved from 0.8994 to 0.8910.\n",
      "[Epoch 118/1000] Train Loss: 0.7813  |  Val Loss: 0.8822\n",
      "Validation loss improved from 0.8910 to 0.8822.\n",
      "[Epoch 119/1000] Train Loss: 0.7727  |  Val Loss: 0.8737\n",
      "Validation loss improved from 0.8822 to 0.8737.\n",
      "[Epoch 120/1000] Train Loss: 0.7635  |  Val Loss: 0.8657\n",
      "Validation loss improved from 0.8737 to 0.8657.\n",
      "[Epoch 121/1000] Train Loss: 0.7549  |  Val Loss: 0.8579\n",
      "Validation loss improved from 0.8657 to 0.8579.\n",
      "[Epoch 122/1000] Train Loss: 0.7464  |  Val Loss: 0.8503\n",
      "Validation loss improved from 0.8579 to 0.8503.\n",
      "[Epoch 123/1000] Train Loss: 0.7381  |  Val Loss: 0.8429\n",
      "Validation loss improved from 0.8503 to 0.8429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 124/1000] Train Loss: 0.7299  |  Val Loss: 0.8349\n",
      "Validation loss improved from 0.8429 to 0.8349.\n",
      "[Epoch 125/1000] Train Loss: 0.7216  |  Val Loss: 0.8271\n",
      "Validation loss improved from 0.8349 to 0.8271.\n",
      "[Epoch 126/1000] Train Loss: 0.7133  |  Val Loss: 0.8191\n",
      "Validation loss improved from 0.8271 to 0.8191.\n",
      "[Epoch 127/1000] Train Loss: 0.7054  |  Val Loss: 0.8110\n",
      "Validation loss improved from 0.8191 to 0.8110.\n",
      "[Epoch 128/1000] Train Loss: 0.6973  |  Val Loss: 0.8028\n",
      "Validation loss improved from 0.8110 to 0.8028.\n",
      "[Epoch 129/1000] Train Loss: 0.6891  |  Val Loss: 0.7947\n",
      "Validation loss improved from 0.8028 to 0.7947.\n",
      "[Epoch 130/1000] Train Loss: 0.6810  |  Val Loss: 0.7874\n",
      "Validation loss improved from 0.7947 to 0.7874.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 131/1000] Train Loss: 0.6734  |  Val Loss: 0.7801\n",
      "Validation loss improved from 0.7874 to 0.7801.\n",
      "[Epoch 132/1000] Train Loss: 0.6652  |  Val Loss: 0.7735\n",
      "Validation loss improved from 0.7801 to 0.7735.\n",
      "[Epoch 133/1000] Train Loss: 0.6575  |  Val Loss: 0.7670\n",
      "Validation loss improved from 0.7735 to 0.7670.\n",
      "[Epoch 134/1000] Train Loss: 0.6499  |  Val Loss: 0.7604\n",
      "Validation loss improved from 0.7670 to 0.7604.\n",
      "[Epoch 135/1000] Train Loss: 0.6420  |  Val Loss: 0.7536\n",
      "Validation loss improved from 0.7604 to 0.7536.\n",
      "[Epoch 136/1000] Train Loss: 0.6346  |  Val Loss: 0.7471\n",
      "Validation loss improved from 0.7536 to 0.7471.\n",
      "[Epoch 137/1000] Train Loss: 0.6271  |  Val Loss: 0.7391\n",
      "Validation loss improved from 0.7471 to 0.7391.\n",
      "[Epoch 138/1000] Train Loss: 0.6190  |  Val Loss: 0.7311\n",
      "Validation loss improved from 0.7391 to 0.7311.\n",
      "[Epoch 139/1000] Train Loss: 0.6119  |  Val Loss: 0.7239\n",
      "Validation loss improved from 0.7311 to 0.7239.\n",
      "[Epoch 140/1000] Train Loss: 0.6040  |  Val Loss: 0.7174\n",
      "Validation loss improved from 0.7239 to 0.7174.\n",
      "[Epoch 141/1000] Train Loss: 0.5966  |  Val Loss: 0.7101\n",
      "Validation loss improved from 0.7174 to 0.7101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 142/1000] Train Loss: 0.5893  |  Val Loss: 0.7037\n",
      "Validation loss improved from 0.7101 to 0.7037.\n",
      "[Epoch 143/1000] Train Loss: 0.5820  |  Val Loss: 0.6976\n",
      "Validation loss improved from 0.7037 to 0.6976.\n",
      "[Epoch 144/1000] Train Loss: 0.5748  |  Val Loss: 0.6919\n",
      "Validation loss improved from 0.6976 to 0.6919.\n",
      "[Epoch 145/1000] Train Loss: 0.5680  |  Val Loss: 0.6865\n",
      "Validation loss improved from 0.6919 to 0.6865.\n",
      "[Epoch 146/1000] Train Loss: 0.5615  |  Val Loss: 0.6811\n",
      "Validation loss improved from 0.6865 to 0.6811.\n",
      "[Epoch 147/1000] Train Loss: 0.5547  |  Val Loss: 0.6750\n",
      "Validation loss improved from 0.6811 to 0.6750.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 148/1000] Train Loss: 0.5475  |  Val Loss: 0.6689\n",
      "Validation loss improved from 0.6750 to 0.6689.\n",
      "[Epoch 149/1000] Train Loss: 0.5406  |  Val Loss: 0.6626\n",
      "Validation loss improved from 0.6689 to 0.6626.\n",
      "[Epoch 150/1000] Train Loss: 0.5340  |  Val Loss: 0.6567\n",
      "Validation loss improved from 0.6626 to 0.6567.\n",
      "[Epoch 151/1000] Train Loss: 0.5276  |  Val Loss: 0.6506\n",
      "Validation loss improved from 0.6567 to 0.6506.\n",
      "[Epoch 152/1000] Train Loss: 0.5210  |  Val Loss: 0.6443\n",
      "Validation loss improved from 0.6506 to 0.6443.\n",
      "[Epoch 153/1000] Train Loss: 0.5144  |  Val Loss: 0.6381\n",
      "Validation loss improved from 0.6443 to 0.6381.\n",
      "[Epoch 154/1000] Train Loss: 0.5078  |  Val Loss: 0.6313\n",
      "Validation loss improved from 0.6381 to 0.6313.\n",
      "[Epoch 155/1000] Train Loss: 0.5014  |  Val Loss: 0.6256\n",
      "Validation loss improved from 0.6313 to 0.6256.\n",
      "[Epoch 156/1000] Train Loss: 0.4946  |  Val Loss: 0.6201\n",
      "Validation loss improved from 0.6256 to 0.6201.\n",
      "[Epoch 157/1000] Train Loss: 0.4884  |  Val Loss: 0.6149\n",
      "Validation loss improved from 0.6201 to 0.6149.\n",
      "[Epoch 158/1000] Train Loss: 0.4823  |  Val Loss: 0.6090\n",
      "Validation loss improved from 0.6149 to 0.6090.\n",
      "[Epoch 159/1000] Train Loss: 0.4758  |  Val Loss: 0.6026\n",
      "Validation loss improved from 0.6090 to 0.6026.\n",
      "[Epoch 160/1000] Train Loss: 0.4698  |  Val Loss: 0.5969\n",
      "Validation loss improved from 0.6026 to 0.5969.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 161/1000] Train Loss: 0.4644  |  Val Loss: 0.5914\n",
      "Validation loss improved from 0.5969 to 0.5914.\n",
      "[Epoch 162/1000] Train Loss: 0.4588  |  Val Loss: 0.5862\n",
      "Validation loss improved from 0.5914 to 0.5862.\n",
      "[Epoch 163/1000] Train Loss: 0.4530  |  Val Loss: 0.5811\n",
      "Validation loss improved from 0.5862 to 0.5811.\n",
      "[Epoch 164/1000] Train Loss: 0.4469  |  Val Loss: 0.5765\n",
      "Validation loss improved from 0.5811 to 0.5765.\n",
      "[Epoch 165/1000] Train Loss: 0.4412  |  Val Loss: 0.5710\n",
      "Validation loss improved from 0.5765 to 0.5710.\n",
      "[Epoch 166/1000] Train Loss: 0.4361  |  Val Loss: 0.5658\n",
      "Validation loss improved from 0.5710 to 0.5658.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 167/1000] Train Loss: 0.4309  |  Val Loss: 0.5604\n",
      "Validation loss improved from 0.5658 to 0.5604.\n",
      "[Epoch 168/1000] Train Loss: 0.4258  |  Val Loss: 0.5555\n",
      "Validation loss improved from 0.5604 to 0.5555.\n",
      "[Epoch 169/1000] Train Loss: 0.4202  |  Val Loss: 0.5510\n",
      "Validation loss improved from 0.5555 to 0.5510.\n",
      "[Epoch 170/1000] Train Loss: 0.4153  |  Val Loss: 0.5471\n",
      "Validation loss improved from 0.5510 to 0.5471.\n",
      "[Epoch 171/1000] Train Loss: 0.4102  |  Val Loss: 0.5425\n",
      "Validation loss improved from 0.5471 to 0.5425.\n",
      "[Epoch 172/1000] Train Loss: 0.4049  |  Val Loss: 0.5377\n",
      "Validation loss improved from 0.5425 to 0.5377.\n",
      "[Epoch 173/1000] Train Loss: 0.3999  |  Val Loss: 0.5332\n",
      "Validation loss improved from 0.5377 to 0.5332.\n",
      "[Epoch 174/1000] Train Loss: 0.3948  |  Val Loss: 0.5289\n",
      "Validation loss improved from 0.5332 to 0.5289.\n",
      "[Epoch 175/1000] Train Loss: 0.3900  |  Val Loss: 0.5246\n",
      "Validation loss improved from 0.5289 to 0.5246.\n",
      "[Epoch 176/1000] Train Loss: 0.3851  |  Val Loss: 0.5194\n",
      "Validation loss improved from 0.5246 to 0.5194.\n",
      "[Epoch 177/1000] Train Loss: 0.3800  |  Val Loss: 0.5145\n",
      "Validation loss improved from 0.5194 to 0.5145.\n",
      "[Epoch 178/1000] Train Loss: 0.3751  |  Val Loss: 0.5106\n",
      "Validation loss improved from 0.5145 to 0.5106.\n",
      "[Epoch 179/1000] Train Loss: 0.3705  |  Val Loss: 0.5075\n",
      "Validation loss improved from 0.5106 to 0.5075.\n",
      "[Epoch 180/1000] Train Loss: 0.3651  |  Val Loss: 0.5042\n",
      "Validation loss improved from 0.5075 to 0.5042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 181/1000] Train Loss: 0.3602  |  Val Loss: 0.5010\n",
      "Validation loss improved from 0.5042 to 0.5010.\n",
      "[Epoch 182/1000] Train Loss: 0.3551  |  Val Loss: 0.4969\n",
      "Validation loss improved from 0.5010 to 0.4969.\n",
      "[Epoch 183/1000] Train Loss: 0.3500  |  Val Loss: 0.4926\n",
      "Validation loss improved from 0.4969 to 0.4926.\n",
      "[Epoch 184/1000] Train Loss: 0.3457  |  Val Loss: 0.4884\n",
      "Validation loss improved from 0.4926 to 0.4884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 185/1000] Train Loss: 0.3415  |  Val Loss: 0.4843\n",
      "Validation loss improved from 0.4884 to 0.4843.\n",
      "[Epoch 186/1000] Train Loss: 0.3372  |  Val Loss: 0.4814\n",
      "Validation loss improved from 0.4843 to 0.4814.\n",
      "[Epoch 187/1000] Train Loss: 0.3330  |  Val Loss: 0.4786\n",
      "Validation loss improved from 0.4814 to 0.4786.\n",
      "[Epoch 188/1000] Train Loss: 0.3290  |  Val Loss: 0.4765\n",
      "Validation loss improved from 0.4786 to 0.4765.\n",
      "[Epoch 189/1000] Train Loss: 0.3258  |  Val Loss: 0.4751\n",
      "Validation loss improved from 0.4765 to 0.4751.\n",
      "[Epoch 190/1000] Train Loss: 0.3220  |  Val Loss: 0.4722\n",
      "Validation loss improved from 0.4751 to 0.4722.\n",
      "[Epoch 191/1000] Train Loss: 0.3183  |  Val Loss: 0.4680\n",
      "Validation loss improved from 0.4722 to 0.4680.\n",
      "[Epoch 192/1000] Train Loss: 0.3145  |  Val Loss: 0.4629\n",
      "Validation loss improved from 0.4680 to 0.4629.\n",
      "[Epoch 193/1000] Train Loss: 0.3109  |  Val Loss: 0.4594\n",
      "Validation loss improved from 0.4629 to 0.4594.\n",
      "[Epoch 194/1000] Train Loss: 0.3072  |  Val Loss: 0.4566\n",
      "Validation loss improved from 0.4594 to 0.4566.\n",
      "[Epoch 195/1000] Train Loss: 0.3041  |  Val Loss: 0.4537\n",
      "Validation loss improved from 0.4566 to 0.4537.\n",
      "[Epoch 196/1000] Train Loss: 0.3004  |  Val Loss: 0.4519\n",
      "Validation loss improved from 0.4537 to 0.4519.\n",
      "[Epoch 197/1000] Train Loss: 0.2975  |  Val Loss: 0.4488\n",
      "Validation loss improved from 0.4519 to 0.4488.\n",
      "[Epoch 198/1000] Train Loss: 0.2944  |  Val Loss: 0.4442\n",
      "Validation loss improved from 0.4488 to 0.4442.\n",
      "[Epoch 199/1000] Train Loss: 0.2908  |  Val Loss: 0.4409\n",
      "Validation loss improved from 0.4442 to 0.4409.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 200/1000] Train Loss: 0.2877  |  Val Loss: 0.4384\n",
      "Validation loss improved from 0.4409 to 0.4384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 201/1000] Train Loss: 0.2848  |  Val Loss: 0.4351\n",
      "Validation loss improved from 0.4384 to 0.4351.\n",
      "[Epoch 202/1000] Train Loss: 0.2815  |  Val Loss: 0.4321\n",
      "Validation loss improved from 0.4351 to 0.4321.\n",
      "[Epoch 203/1000] Train Loss: 0.2796  |  Val Loss: 0.4285\n",
      "Validation loss improved from 0.4321 to 0.4285.\n",
      "[Epoch 204/1000] Train Loss: 0.2757  |  Val Loss: 0.4263\n",
      "Validation loss improved from 0.4285 to 0.4263.\n",
      "[Epoch 205/1000] Train Loss: 0.2727  |  Val Loss: 0.4245\n",
      "Validation loss improved from 0.4263 to 0.4245.\n",
      "[Epoch 206/1000] Train Loss: 0.2699  |  Val Loss: 0.4231\n",
      "Validation loss improved from 0.4245 to 0.4231.\n",
      "[Epoch 207/1000] Train Loss: 0.2673  |  Val Loss: 0.4219\n",
      "Validation loss improved from 0.4231 to 0.4219.\n",
      "[Epoch 208/1000] Train Loss: 0.2646  |  Val Loss: 0.4210\n",
      "Validation loss improved from 0.4219 to 0.4210.\n",
      "[Epoch 209/1000] Train Loss: 0.2626  |  Val Loss: 0.4196\n",
      "Validation loss improved from 0.4210 to 0.4196.\n",
      "[Epoch 210/1000] Train Loss: 0.2596  |  Val Loss: 0.4158\n",
      "Validation loss improved from 0.4196 to 0.4158.\n",
      "[Epoch 211/1000] Train Loss: 0.2566  |  Val Loss: 0.4123\n",
      "Validation loss improved from 0.4158 to 0.4123.\n",
      "[Epoch 212/1000] Train Loss: 0.2538  |  Val Loss: 0.4102\n",
      "Validation loss improved from 0.4123 to 0.4102.\n",
      "[Epoch 213/1000] Train Loss: 0.2511  |  Val Loss: 0.4089\n",
      "Validation loss improved from 0.4102 to 0.4089.\n",
      "[Epoch 214/1000] Train Loss: 0.2486  |  Val Loss: 0.4075\n",
      "Validation loss improved from 0.4089 to 0.4075.\n",
      "[Epoch 215/1000] Train Loss: 0.2467  |  Val Loss: 0.4057\n",
      "Validation loss improved from 0.4075 to 0.4057.\n",
      "[Epoch 216/1000] Train Loss: 0.2440  |  Val Loss: 0.4041\n",
      "Validation loss improved from 0.4057 to 0.4041.\n",
      "[Epoch 217/1000] Train Loss: 0.2416  |  Val Loss: 0.4016\n",
      "Validation loss improved from 0.4041 to 0.4016.\n",
      "[Epoch 218/1000] Train Loss: 0.2392  |  Val Loss: 0.3981\n",
      "Validation loss improved from 0.4016 to 0.3981.\n",
      "[Epoch 219/1000] Train Loss: 0.2370  |  Val Loss: 0.3956\n",
      "Validation loss improved from 0.3981 to 0.3956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 220/1000] Train Loss: 0.2343  |  Val Loss: 0.3944\n",
      "Validation loss improved from 0.3956 to 0.3944.\n",
      "[Epoch 221/1000] Train Loss: 0.2326  |  Val Loss: 0.3922\n",
      "Validation loss improved from 0.3944 to 0.3922.\n",
      "[Epoch 222/1000] Train Loss: 0.2304  |  Val Loss: 0.3901\n",
      "Validation loss improved from 0.3922 to 0.3901.\n",
      "[Epoch 223/1000] Train Loss: 0.2282  |  Val Loss: 0.3877\n",
      "Validation loss improved from 0.3901 to 0.3877.\n",
      "[Epoch 224/1000] Train Loss: 0.2261  |  Val Loss: 0.3861\n",
      "Validation loss improved from 0.3877 to 0.3861.\n",
      "[Epoch 225/1000] Train Loss: 0.2240  |  Val Loss: 0.3846\n",
      "Validation loss improved from 0.3861 to 0.3846.\n",
      "[Epoch 226/1000] Train Loss: 0.2220  |  Val Loss: 0.3827\n",
      "Validation loss improved from 0.3846 to 0.3827.\n",
      "[Epoch 227/1000] Train Loss: 0.2199  |  Val Loss: 0.3822\n",
      "Validation loss improved from 0.3827 to 0.3822.\n",
      "[Epoch 228/1000] Train Loss: 0.2176  |  Val Loss: 0.3805\n",
      "Validation loss improved from 0.3822 to 0.3805.\n",
      "[Epoch 229/1000] Train Loss: 0.2158  |  Val Loss: 0.3793\n",
      "Validation loss improved from 0.3805 to 0.3793.\n",
      "[Epoch 230/1000] Train Loss: 0.2140  |  Val Loss: 0.3777\n",
      "Validation loss improved from 0.3793 to 0.3777.\n",
      "[Epoch 231/1000] Train Loss: 0.2122  |  Val Loss: 0.3768\n",
      "Validation loss improved from 0.3777 to 0.3768.\n",
      "[Epoch 232/1000] Train Loss: 0.2100  |  Val Loss: 0.3761\n",
      "Validation loss improved from 0.3768 to 0.3761.\n",
      "[Epoch 233/1000] Train Loss: 0.2082  |  Val Loss: 0.3750\n",
      "Validation loss improved from 0.3761 to 0.3750.\n",
      "[Epoch 234/1000] Train Loss: 0.2063  |  Val Loss: 0.3736\n",
      "Validation loss improved from 0.3750 to 0.3736.\n",
      "[Epoch 235/1000] Train Loss: 0.2044  |  Val Loss: 0.3722\n",
      "Validation loss improved from 0.3736 to 0.3722.\n",
      "[Epoch 236/1000] Train Loss: 0.2028  |  Val Loss: 0.3712\n",
      "Validation loss improved from 0.3722 to 0.3712.\n",
      "[Epoch 237/1000] Train Loss: 0.2010  |  Val Loss: 0.3701\n",
      "Validation loss improved from 0.3712 to 0.3701.\n",
      "[Epoch 238/1000] Train Loss: 0.1996  |  Val Loss: 0.3693\n",
      "Validation loss improved from 0.3701 to 0.3693.\n",
      "[Epoch 239/1000] Train Loss: 0.1977  |  Val Loss: 0.3682\n",
      "Validation loss improved from 0.3693 to 0.3682.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 240/1000] Train Loss: 0.1959  |  Val Loss: 0.3673\n",
      "Validation loss improved from 0.3682 to 0.3673.\n",
      "[Epoch 241/1000] Train Loss: 0.1946  |  Val Loss: 0.3657\n",
      "Validation loss improved from 0.3673 to 0.3657.\n",
      "[Epoch 242/1000] Train Loss: 0.1932  |  Val Loss: 0.3636\n",
      "Validation loss improved from 0.3657 to 0.3636.\n",
      "[Epoch 243/1000] Train Loss: 0.1911  |  Val Loss: 0.3614\n",
      "Validation loss improved from 0.3636 to 0.3614.\n",
      "[Epoch 244/1000] Train Loss: 0.1897  |  Val Loss: 0.3595\n",
      "Validation loss improved from 0.3614 to 0.3595.\n",
      "[Epoch 245/1000] Train Loss: 0.1885  |  Val Loss: 0.3580\n",
      "Validation loss improved from 0.3595 to 0.3580.\n",
      "[Epoch 246/1000] Train Loss: 0.1869  |  Val Loss: 0.3576\n",
      "Validation loss improved from 0.3580 to 0.3576.\n",
      "[Epoch 247/1000] Train Loss: 0.1856  |  Val Loss: 0.3577\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 248/1000] Train Loss: 0.1836  |  Val Loss: 0.3570\n",
      "Validation loss improved from 0.3576 to 0.3570.\n",
      "[Epoch 249/1000] Train Loss: 0.1829  |  Val Loss: 0.3574\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 250/1000] Train Loss: 0.1811  |  Val Loss: 0.3553\n",
      "Validation loss improved from 0.3570 to 0.3553.\n",
      "[Epoch 251/1000] Train Loss: 0.1795  |  Val Loss: 0.3538\n",
      "Validation loss improved from 0.3553 to 0.3538.\n",
      "[Epoch 252/1000] Train Loss: 0.1782  |  Val Loss: 0.3526\n",
      "Validation loss improved from 0.3538 to 0.3526.\n",
      "[Epoch 253/1000] Train Loss: 0.1771  |  Val Loss: 0.3513\n",
      "Validation loss improved from 0.3526 to 0.3513.\n",
      "[Epoch 254/1000] Train Loss: 0.1756  |  Val Loss: 0.3498\n",
      "Validation loss improved from 0.3513 to 0.3498.\n",
      "[Epoch 255/1000] Train Loss: 0.1739  |  Val Loss: 0.3482\n",
      "Validation loss improved from 0.3498 to 0.3482.\n",
      "[Epoch 256/1000] Train Loss: 0.1730  |  Val Loss: 0.3475\n",
      "Validation loss improved from 0.3482 to 0.3475.\n",
      "[Epoch 257/1000] Train Loss: 0.1720  |  Val Loss: 0.3466\n",
      "Validation loss improved from 0.3475 to 0.3466.\n",
      "[Epoch 258/1000] Train Loss: 0.1710  |  Val Loss: 0.3456\n",
      "Validation loss improved from 0.3466 to 0.3456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 259/1000] Train Loss: 0.1695  |  Val Loss: 0.3451\n",
      "Validation loss improved from 0.3456 to 0.3451.\n",
      "[Epoch 260/1000] Train Loss: 0.1679  |  Val Loss: 0.3450\n",
      "Validation loss improved from 0.3451 to 0.3450.\n",
      "[Epoch 261/1000] Train Loss: 0.1665  |  Val Loss: 0.3456\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 262/1000] Train Loss: 0.1657  |  Val Loss: 0.3460\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 263/1000] Train Loss: 0.1644  |  Val Loss: 0.3448\n",
      "Validation loss improved from 0.3450 to 0.3448.\n",
      "[Epoch 264/1000] Train Loss: 0.1635  |  Val Loss: 0.3441\n",
      "Validation loss improved from 0.3448 to 0.3441.\n",
      "[Epoch 265/1000] Train Loss: 0.1626  |  Val Loss: 0.3420\n",
      "Validation loss improved from 0.3441 to 0.3420.\n",
      "[Epoch 266/1000] Train Loss: 0.1612  |  Val Loss: 0.3413\n",
      "Validation loss improved from 0.3420 to 0.3413.\n",
      "[Epoch 267/1000] Train Loss: 0.1598  |  Val Loss: 0.3397\n",
      "Validation loss improved from 0.3413 to 0.3397.\n",
      "[Epoch 268/1000] Train Loss: 0.1595  |  Val Loss: 0.3386\n",
      "Validation loss improved from 0.3397 to 0.3386.\n",
      "[Epoch 269/1000] Train Loss: 0.1579  |  Val Loss: 0.3382\n",
      "Validation loss improved from 0.3386 to 0.3382.\n",
      "[Epoch 270/1000] Train Loss: 0.1569  |  Val Loss: 0.3389\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 271/1000] Train Loss: 0.1554  |  Val Loss: 0.3394\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 272/1000] Train Loss: 0.1553  |  Val Loss: 0.3401\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 273/1000] Train Loss: 0.1542  |  Val Loss: 0.3378\n",
      "Validation loss improved from 0.3382 to 0.3378.\n",
      "[Epoch 274/1000] Train Loss: 0.1527  |  Val Loss: 0.3371\n",
      "Validation loss improved from 0.3378 to 0.3371.\n",
      "[Epoch 275/1000] Train Loss: 0.1518  |  Val Loss: 0.3363\n",
      "Validation loss improved from 0.3371 to 0.3363.\n",
      "[Epoch 276/1000] Train Loss: 0.1513  |  Val Loss: 0.3361\n",
      "Validation loss improved from 0.3363 to 0.3361.\n",
      "[Epoch 277/1000] Train Loss: 0.1498  |  Val Loss: 0.3345\n",
      "Validation loss improved from 0.3361 to 0.3345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 278/1000] Train Loss: 0.1492  |  Val Loss: 0.3334\n",
      "Validation loss improved from 0.3345 to 0.3334.\n",
      "[Epoch 279/1000] Train Loss: 0.1482  |  Val Loss: 0.3332\n",
      "Validation loss improved from 0.3334 to 0.3332.\n",
      "[Epoch 280/1000] Train Loss: 0.1472  |  Val Loss: 0.3330\n",
      "Validation loss improved from 0.3332 to 0.3330.\n",
      "[Epoch 281/1000] Train Loss: 0.1462  |  Val Loss: 0.3328\n",
      "Validation loss improved from 0.3330 to 0.3328.\n",
      "[Epoch 282/1000] Train Loss: 0.1454  |  Val Loss: 0.3327\n",
      "Validation loss improved from 0.3328 to 0.3327.\n",
      "[Epoch 283/1000] Train Loss: 0.1444  |  Val Loss: 0.3323\n",
      "Validation loss improved from 0.3327 to 0.3323.\n",
      "[Epoch 284/1000] Train Loss: 0.1436  |  Val Loss: 0.3313\n",
      "Validation loss improved from 0.3323 to 0.3313.\n",
      "[Epoch 285/1000] Train Loss: 0.1425  |  Val Loss: 0.3302\n",
      "Validation loss improved from 0.3313 to 0.3302.\n",
      "[Epoch 286/1000] Train Loss: 0.1418  |  Val Loss: 0.3290\n",
      "Validation loss improved from 0.3302 to 0.3290.\n",
      "[Epoch 287/1000] Train Loss: 0.1421  |  Val Loss: 0.3283\n",
      "Validation loss improved from 0.3290 to 0.3283.\n",
      "[Epoch 288/1000] Train Loss: 0.1412  |  Val Loss: 0.3280\n",
      "Validation loss improved from 0.3283 to 0.3280.\n",
      "[Epoch 289/1000] Train Loss: 0.1397  |  Val Loss: 0.3287\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 290/1000] Train Loss: 0.1392  |  Val Loss: 0.3305\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 291/1000] Train Loss: 0.1384  |  Val Loss: 0.3300\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 292/1000] Train Loss: 0.1376  |  Val Loss: 0.3303\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 293/1000] Train Loss: 0.1366  |  Val Loss: 0.3292\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 294/1000] Train Loss: 0.1356  |  Val Loss: 0.3290\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 295/1000] Train Loss: 0.1351  |  Val Loss: 0.3283\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 296/1000] Train Loss: 0.1343  |  Val Loss: 0.3282\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 297/1000] Train Loss: 0.1342  |  Val Loss: 0.3272\n",
      "Validation loss improved from 0.3280 to 0.3272.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 298/1000] Train Loss: 0.1328  |  Val Loss: 0.3274\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 299/1000] Train Loss: 0.1320  |  Val Loss: 0.3270\n",
      "Validation loss improved from 0.3272 to 0.3270.\n",
      "[Epoch 300/1000] Train Loss: 0.1312  |  Val Loss: 0.3271\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 301/1000] Train Loss: 0.1307  |  Val Loss: 0.3265\n",
      "Validation loss improved from 0.3270 to 0.3265.\n",
      "[Epoch 302/1000] Train Loss: 0.1302  |  Val Loss: 0.3253\n",
      "Validation loss improved from 0.3265 to 0.3253.\n",
      "[Epoch 303/1000] Train Loss: 0.1292  |  Val Loss: 0.3248\n",
      "Validation loss improved from 0.3253 to 0.3248.\n",
      "[Epoch 304/1000] Train Loss: 0.1285  |  Val Loss: 0.3245\n",
      "Validation loss improved from 0.3248 to 0.3245.\n",
      "[Epoch 305/1000] Train Loss: 0.1278  |  Val Loss: 0.3245\n",
      "Validation loss improved from 0.3245 to 0.3245.\n",
      "[Epoch 306/1000] Train Loss: 0.1272  |  Val Loss: 0.3245\n",
      "Validation loss improved from 0.3245 to 0.3245.\n",
      "[Epoch 307/1000] Train Loss: 0.1264  |  Val Loss: 0.3242\n",
      "Validation loss improved from 0.3245 to 0.3242.\n",
      "[Epoch 308/1000] Train Loss: 0.1258  |  Val Loss: 0.3242\n",
      "Validation loss improved from 0.3242 to 0.3242.\n",
      "[Epoch 309/1000] Train Loss: 0.1251  |  Val Loss: 0.3237\n",
      "Validation loss improved from 0.3242 to 0.3237.\n",
      "[Epoch 310/1000] Train Loss: 0.1246  |  Val Loss: 0.3236\n",
      "Validation loss improved from 0.3237 to 0.3236.\n",
      "[Epoch 311/1000] Train Loss: 0.1242  |  Val Loss: 0.3232\n",
      "Validation loss improved from 0.3236 to 0.3232.\n",
      "[Epoch 312/1000] Train Loss: 0.1235  |  Val Loss: 0.3234\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 313/1000] Train Loss: 0.1228  |  Val Loss: 0.3236\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 314/1000] Train Loss: 0.1219  |  Val Loss: 0.3235\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 315/1000] Train Loss: 0.1215  |  Val Loss: 0.3243\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 316/1000] Train Loss: 0.1214  |  Val Loss: 0.3243\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 317/1000] Train Loss: 0.1208  |  Val Loss: 0.3241\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 318/1000] Train Loss: 0.1200  |  Val Loss: 0.3219\n",
      "Validation loss improved from 0.3232 to 0.3219.\n",
      "[Epoch 319/1000] Train Loss: 0.1191  |  Val Loss: 0.3212\n",
      "Validation loss improved from 0.3219 to 0.3212.\n",
      "[Epoch 320/1000] Train Loss: 0.1187  |  Val Loss: 0.3214\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 321/1000] Train Loss: 0.1180  |  Val Loss: 0.3215\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 322/1000] Train Loss: 0.1175  |  Val Loss: 0.3217\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 323/1000] Train Loss: 0.1167  |  Val Loss: 0.3219\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 324/1000] Train Loss: 0.1164  |  Val Loss: 0.3225\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 325/1000] Train Loss: 0.1161  |  Val Loss: 0.3220\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 326/1000] Train Loss: 0.1154  |  Val Loss: 0.3224\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 327/1000] Train Loss: 0.1149  |  Val Loss: 0.3225\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 328/1000] Train Loss: 0.1145  |  Val Loss: 0.3229\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 329/1000] Train Loss: 0.1145  |  Val Loss: 0.3220\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 330/1000] Train Loss: 0.1134  |  Val Loss: 0.3226\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 331/1000] Train Loss: 0.1128  |  Val Loss: 0.3222\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 332/1000] Train Loss: 0.1121  |  Val Loss: 0.3211\n",
      "Validation loss improved from 0.3212 to 0.3211.\n",
      "[Epoch 333/1000] Train Loss: 0.1120  |  Val Loss: 0.3203\n",
      "Validation loss improved from 0.3211 to 0.3203.\n",
      "[Epoch 334/1000] Train Loss: 0.1113  |  Val Loss: 0.3202\n",
      "Validation loss improved from 0.3203 to 0.3202.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 335/1000] Train Loss: 0.1108  |  Val Loss: 0.3206\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 336/1000] Train Loss: 0.1105  |  Val Loss: 0.3206\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 337/1000] Train Loss: 0.1098  |  Val Loss: 0.3209\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 338/1000] Train Loss: 0.1094  |  Val Loss: 0.3220\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 339/1000] Train Loss: 0.1090  |  Val Loss: 0.3222\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 340/1000] Train Loss: 0.1088  |  Val Loss: 0.3211\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 341/1000] Train Loss: 0.1078  |  Val Loss: 0.3210\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 342/1000] Train Loss: 0.1075  |  Val Loss: 0.3213\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 343/1000] Train Loss: 0.1072  |  Val Loss: 0.3210\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 344/1000] Train Loss: 0.1068  |  Val Loss: 0.3209\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 345/1000] Train Loss: 0.1064  |  Val Loss: 0.3203\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 346/1000] Train Loss: 0.1060  |  Val Loss: 0.3204\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 347/1000] Train Loss: 0.1052  |  Val Loss: 0.3210\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 348/1000] Train Loss: 0.1052  |  Val Loss: 0.3216\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 349/1000] Train Loss: 0.1051  |  Val Loss: 0.3202\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 350/1000] Train Loss: 0.1042  |  Val Loss: 0.3197\n",
      "Validation loss improved from 0.3202 to 0.3197.\n",
      "[Epoch 351/1000] Train Loss: 0.1037  |  Val Loss: 0.3200\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 352/1000] Train Loss: 0.1031  |  Val Loss: 0.3200\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 353/1000] Train Loss: 0.1028  |  Val Loss: 0.3207\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 354/1000] Train Loss: 0.1026  |  Val Loss: 0.3203\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 355/1000] Train Loss: 0.1019  |  Val Loss: 0.3202\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 356/1000] Train Loss: 0.1017  |  Val Loss: 0.3206\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 357/1000] Train Loss: 0.1015  |  Val Loss: 0.3203\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 358/1000] Train Loss: 0.1009  |  Val Loss: 0.3208\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 359/1000] Train Loss: 0.1005  |  Val Loss: 0.3209\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 360/1000] Train Loss: 0.1002  |  Val Loss: 0.3209\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 361/1000] Train Loss: 0.0997  |  Val Loss: 0.3209\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 362/1000] Train Loss: 0.0994  |  Val Loss: 0.3208\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 363/1000] Train Loss: 0.0987  |  Val Loss: 0.3197\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 364/1000] Train Loss: 0.0991  |  Val Loss: 0.3194\n",
      "Validation loss improved from 0.3197 to 0.3194.\n",
      "[Epoch 365/1000] Train Loss: 0.0989  |  Val Loss: 0.3195\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 366/1000] Train Loss: 0.0991  |  Val Loss: 0.3193\n",
      "Validation loss improved from 0.3194 to 0.3193.\n",
      "[Epoch 367/1000] Train Loss: 0.0984  |  Val Loss: 0.3198\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 368/1000] Train Loss: 0.0974  |  Val Loss: 0.3208\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 369/1000] Train Loss: 0.0967  |  Val Loss: 0.3214\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 370/1000] Train Loss: 0.0964  |  Val Loss: 0.3216\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 371/1000] Train Loss: 0.0961  |  Val Loss: 0.3213\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 372/1000] Train Loss: 0.0956  |  Val Loss: 0.3212\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 373/1000] Train Loss: 0.0953  |  Val Loss: 0.3212\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 374/1000] Train Loss: 0.0952  |  Val Loss: 0.3207\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 375/1000] Train Loss: 0.0947  |  Val Loss: 0.3213\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 376/1000] Train Loss: 0.0945  |  Val Loss: 0.3207\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 377/1000] Train Loss: 0.0941  |  Val Loss: 0.3207\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 378/1000] Train Loss: 0.0941  |  Val Loss: 0.3206\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 379/1000] Train Loss: 0.0939  |  Val Loss: 0.3213\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 380/1000] Train Loss: 0.0932  |  Val Loss: 0.3215\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 381/1000] Train Loss: 0.0927  |  Val Loss: 0.3220\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 382/1000] Train Loss: 0.0924  |  Val Loss: 0.3222\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 383/1000] Train Loss: 0.0926  |  Val Loss: 0.3229\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 384/1000] Train Loss: 0.0926  |  Val Loss: 0.3230\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 385/1000] Train Loss: 0.0916  |  Val Loss: 0.3221\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 386/1000] Train Loss: 0.0914  |  Val Loss: 0.3213\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 387/1000] Train Loss: 0.0916  |  Val Loss: 0.3211\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 388/1000] Train Loss: 0.0914  |  Val Loss: 0.3213\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 389/1000] Train Loss: 0.0906  |  Val Loss: 0.3210\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 390/1000] Train Loss: 0.0900  |  Val Loss: 0.3199\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 391/1000] Train Loss: 0.0906  |  Val Loss: 0.3199\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 392/1000] Train Loss: 0.0900  |  Val Loss: 0.3203\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 393/1000] Train Loss: 0.0898  |  Val Loss: 0.3212\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 394/1000] Train Loss: 0.0895  |  Val Loss: 0.3221\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 395/1000] Train Loss: 0.0894  |  Val Loss: 0.3232\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 396/1000] Train Loss: 0.0890  |  Val Loss: 0.3217\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 397/1000] Train Loss: 0.0885  |  Val Loss: 0.3214\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 398/1000] Train Loss: 0.0881  |  Val Loss: 0.3218\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 399/1000] Train Loss: 0.0877  |  Val Loss: 0.3222\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 400/1000] Train Loss: 0.0875  |  Val Loss: 0.3224\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 401/1000] Train Loss: 0.0878  |  Val Loss: 0.3235\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 402/1000] Train Loss: 0.0875  |  Val Loss: 0.3243\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 403/1000] Train Loss: 0.0870  |  Val Loss: 0.3238\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 404/1000] Train Loss: 0.0868  |  Val Loss: 0.3241\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 405/1000] Train Loss: 0.0859  |  Val Loss: 0.3234\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 406/1000] Train Loss: 0.0860  |  Val Loss: 0.3230\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 407/1000] Train Loss: 0.0857  |  Val Loss: 0.3233\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 408/1000] Train Loss: 0.0855  |  Val Loss: 0.3236\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 409/1000] Train Loss: 0.0853  |  Val Loss: 0.3238\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 410/1000] Train Loss: 0.0854  |  Val Loss: 0.3250\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 411/1000] Train Loss: 0.0848  |  Val Loss: 0.3247\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 412/1000] Train Loss: 0.0844  |  Val Loss: 0.3243\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 413/1000] Train Loss: 0.0836  |  Val Loss: 0.3232\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 414/1000] Train Loss: 0.0841  |  Val Loss: 0.3228\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 415/1000] Train Loss: 0.0841  |  Val Loss: 0.3229\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 416/1000] Train Loss: 0.0839  |  Val Loss: 0.3233\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 417/1000] Train Loss: 0.0836  |  Val Loss: 0.3241\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 418/1000] Train Loss: 0.0830  |  Val Loss: 0.3246\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 419/1000] Train Loss: 0.0827  |  Val Loss: 0.3249\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 420/1000] Train Loss: 0.0824  |  Val Loss: 0.3247\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 421/1000] Train Loss: 0.0821  |  Val Loss: 0.3243\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 422/1000] Train Loss: 0.0819  |  Val Loss: 0.3245\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 423/1000] Train Loss: 0.0817  |  Val Loss: 0.3249\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 424/1000] Train Loss: 0.0819  |  Val Loss: 0.3252\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 425/1000] Train Loss: 0.0818  |  Val Loss: 0.3249\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 426/1000] Train Loss: 0.0813  |  Val Loss: 0.3254\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 427/1000] Train Loss: 0.0808  |  Val Loss: 0.3254\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 428/1000] Train Loss: 0.0807  |  Val Loss: 0.3252\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 429/1000] Train Loss: 0.0812  |  Val Loss: 0.3247\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 430/1000] Train Loss: 0.0802  |  Val Loss: 0.3248\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 431/1000] Train Loss: 0.0801  |  Val Loss: 0.3251\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 432/1000] Train Loss: 0.0796  |  Val Loss: 0.3256\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 433/1000] Train Loss: 0.0794  |  Val Loss: 0.3256\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 434/1000] Train Loss: 0.0793  |  Val Loss: 0.3261\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 435/1000] Train Loss: 0.0791  |  Val Loss: 0.3264\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 436/1000] Train Loss: 0.0792  |  Val Loss: 0.3270\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 437/1000] Train Loss: 0.0787  |  Val Loss: 0.3270\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 438/1000] Train Loss: 0.0786  |  Val Loss: 0.3269\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 439/1000] Train Loss: 0.0784  |  Val Loss: 0.3272\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 440/1000] Train Loss: 0.0782  |  Val Loss: 0.3277\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 441/1000] Train Loss: 0.0782  |  Val Loss: 0.3277\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 442/1000] Train Loss: 0.0775  |  Val Loss: 0.3263\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 443/1000] Train Loss: 0.0781  |  Val Loss: 0.3259\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 444/1000] Train Loss: 0.0780  |  Val Loss: 0.3264\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 445/1000] Train Loss: 0.0774  |  Val Loss: 0.3263\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 446/1000] Train Loss: 0.0774  |  Val Loss: 0.3271\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 447/1000] Train Loss: 0.0773  |  Val Loss: 0.3269\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 448/1000] Train Loss: 0.0771  |  Val Loss: 0.3282\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 449/1000] Train Loss: 0.0762  |  Val Loss: 0.3292\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 450/1000] Train Loss: 0.0765  |  Val Loss: 0.3293\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 451/1000] Train Loss: 0.0763  |  Val Loss: 0.3292\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 452/1000] Train Loss: 0.0762  |  Val Loss: 0.3293\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 453/1000] Train Loss: 0.0759  |  Val Loss: 0.3286\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 454/1000] Train Loss: 0.0760  |  Val Loss: 0.3271\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 455/1000] Train Loss: 0.0758  |  Val Loss: 0.3268\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 456/1000] Train Loss: 0.0752  |  Val Loss: 0.3274\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 457/1000] Train Loss: 0.0755  |  Val Loss: 0.3287\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 458/1000] Train Loss: 0.0753  |  Val Loss: 0.3294\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 459/1000] Train Loss: 0.0743  |  Val Loss: 0.3283\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 460/1000] Train Loss: 0.0742  |  Val Loss: 0.3279\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 461/1000] Train Loss: 0.0746  |  Val Loss: 0.3278\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 462/1000] Train Loss: 0.0746  |  Val Loss: 0.3283\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 463/1000] Train Loss: 0.0736  |  Val Loss: 0.3292\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 464/1000] Train Loss: 0.0745  |  Val Loss: 0.3311\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 465/1000] Train Loss: 0.0736  |  Val Loss: 0.3306\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 466/1000] Train Loss: 0.0734  |  Val Loss: 0.3301\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 466 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_input_dim = tscl_mlp_train_reps.shape[1]\n",
    "tscl_mlp_num_classes = len(torch.unique(tscl_mlp_train_labels_torch))\n",
    "tscl_mlp_model = MLPClassifier(tscl_mlp_input_dim, tscl_mlp_num_classes).to(device)\n",
    "\n",
    "tscl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "tscl_mlp_optimizer = optim.Adam(tscl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "tscl_mlp_num_epochs = 1000\n",
    "tscl_mlp_patience = 100\n",
    "\n",
    "tscl_mlp_train_losses = []\n",
    "tscl_mlp_val_losses = []\n",
    "\n",
    "tscl_mlp_best_val_loss = float('inf')\n",
    "tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for tscl_mlp_epoch in range(tscl_mlp_num_epochs):\n",
    "    # Training\n",
    "    tscl_mlp_model.train()\n",
    "    tscl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for tscl_mlp_embeddings_batch, tscl_mlp_labels_batch in tscl_mlp_train_loader:\n",
    "        tscl_mlp_embeddings_batch = tscl_mlp_embeddings_batch.to(device)\n",
    "        tscl_mlp_labels_batch = tscl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        tscl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        tscl_mlp_outputs = tscl_mlp_model(tscl_mlp_embeddings_batch)\n",
    "        tscl_mlp_loss = tscl_mlp_criterion(tscl_mlp_outputs, tscl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        tscl_mlp_loss.backward()\n",
    "        tscl_mlp_optimizer.step()\n",
    "        \n",
    "        tscl_mlp_train_running_loss += tscl_mlp_loss.item() * tscl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    tscl_mlp_epoch_train_loss = tscl_mlp_train_running_loss / len(tscl_mlp_train_loader.dataset)\n",
    "    tscl_mlp_train_losses.append(tscl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    tscl_mlp_model.eval()\n",
    "    tscl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for tscl_mlp_val_embeddings_batch, tscl_mlp_val_labels_batch in tscl_mlp_val_loader:\n",
    "            tscl_mlp_val_embeddings_batch = tscl_mlp_val_embeddings_batch.to(device)\n",
    "            tscl_mlp_val_labels_batch = tscl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            tscl_mlp_val_outputs = tscl_mlp_model(tscl_mlp_val_embeddings_batch)\n",
    "            tscl_mlp_val_loss = tscl_mlp_criterion(tscl_mlp_val_outputs, tscl_mlp_val_labels_batch)\n",
    "\n",
    "            tscl_mlp_val_running_loss += tscl_mlp_val_loss.item() * tscl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    tscl_mlp_epoch_val_loss = tscl_mlp_val_running_loss / len(tscl_mlp_val_loader.dataset)\n",
    "    tscl_mlp_val_losses.append(tscl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {tscl_mlp_epoch+1}/{tscl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {tscl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {tscl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if tscl_mlp_epoch_val_loss < tscl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_mlp_best_val_loss:.4f} to {tscl_mlp_epoch_val_loss:.4f}.\")\n",
    "        tscl_mlp_best_val_loss = tscl_mlp_epoch_val_loss\n",
    "        tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        tscl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {tscl_mlp_epochs_without_improvement}/{tscl_mlp_patience}\")\n",
    "        \n",
    "        if tscl_mlp_epochs_without_improvement >= tscl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {tscl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {tscl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(tscl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(tscl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:28:04.317745Z",
     "iopub.status.busy": "2025-05-08T19:28:04.316745Z",
     "iopub.status.idle": "2025-05-08T19:28:04.450953Z",
     "shell.execute_reply": "2025-05-08T19:28:04.450953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TSCL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.4953 | Test Accuracy: 84.44%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_model.eval()\n",
    "\n",
    "tscl_mlp_test_running_loss = 0.0\n",
    "tscl_mlp_test_correct = 0\n",
    "tscl_mlp_all_predictions = []\n",
    "tscl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_mlp_test_embeddings_batch, tscl_mlp_test_labels_batch in tscl_mlp_test_loader:\n",
    "        tscl_mlp_test_embeddings_batch = tscl_mlp_test_embeddings_batch.to(device)\n",
    "        tscl_mlp_test_labels_batch = tscl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        tscl_mlp_test_outputs = tscl_mlp_model(tscl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        tscl_mlp_test_loss_batch = tscl_mlp_criterion(tscl_mlp_test_outputs, tscl_mlp_test_labels_batch)\n",
    "        tscl_mlp_test_running_loss += tscl_mlp_test_loss_batch.item() * tscl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, tscl_mlp_test_predicted = torch.max(tscl_mlp_test_outputs, dim=1)\n",
    "        tscl_mlp_test_correct += (tscl_mlp_test_predicted == tscl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        tscl_mlp_all_predictions.extend(tscl_mlp_test_predicted.cpu().numpy())\n",
    "        tscl_mlp_all_true_labels.extend(tscl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_predictions.npy'), np.array(tscl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_true_labels.npy'), np.array(tscl_mlp_all_true_labels))\n",
    "print(f\"Saved TSCL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "tscl_mlp_epoch_test_loss = tscl_mlp_test_running_loss / len(tscl_mlp_test_loader.dataset)\n",
    "tscl_mlp_test_accuracy = tscl_mlp_test_correct / len(tscl_mlp_test_loader.dataset)\n",
    "\n",
    "tscl_mlp_test_accuracy_pct = tscl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {tscl_mlp_epoch_test_loss:.4f} | Test Accuracy: {tscl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "tscl_mlp_num_epochs_run = len(tscl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         [tscl_mlp_epoch_test_loss]*tscl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Supervised Contrastive Learning with Silhouette Distance Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:28:04.454016Z",
     "iopub.status.busy": "2025-05-08T19:28:04.454016Z",
     "iopub.status.idle": "2025-05-08T19:28:04.462582Z",
     "shell.execute_reply": "2025-05-08T19:28:04.462582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 280 samples with 64 features each\n",
      "LOG: Labels shape: (280,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2898 samples with 64 features each\n",
      "LOG: Labels shape: (2898,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (280, 64), \n",
      "Train labels shape: (280,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (70, 64), \n",
      "Val labels shape: (70,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (2898, 64), \n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "sclsdl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "sclsdl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "sclsdl_train_embeddings, sclsdl_train_labels = load_encoded_data(sclsdl_encoded_train_dir)\n",
    "sclsdl_val_embeddings, sclsdl_val_labels = load_encoded_data(sclsdl_encoded_val_dir)\n",
    "sclsdl_test_embeddings, sclsdl_test_labels = load_encoded_data(sclsdl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {sclsdl_train_embeddings.shape}, \\nTrain labels shape: {sclsdl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {sclsdl_val_embeddings.shape}, \\nVal labels shape: {sclsdl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {sclsdl_test_embeddings.shape}, \\nTest labels shape: {sclsdl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:28:04.464601Z",
     "iopub.status.busy": "2025-05-08T19:28:04.464601Z",
     "iopub.status.idle": "2025-05-08T19:28:04.475628Z",
     "shell.execute_reply": "2025-05-08T19:28:04.475124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20}\n",
      "Training batch size: 280\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "sclsdl_train_embeddings = sclsdl_train_embeddings.reshape(sclsdl_train_embeddings.shape[0], -1)\n",
    "sclsdl_val_embeddings = sclsdl_val_embeddings.reshape(sclsdl_val_embeddings.shape[0], -1)\n",
    "sclsdl_test_embeddings = sclsdl_test_embeddings.reshape(sclsdl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "sclsdl_train_mean = np.mean(sclsdl_train_embeddings, axis=0)\n",
    "sclsdl_train_std = np.std(sclsdl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "#sclsdl_train_embeddings = (sclsdl_train_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_val_embeddings = (sclsdl_val_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_test_embeddings = (sclsdl_test_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "\n",
    "sclsdl_train_dataset = TensorDataset(torch.tensor(sclsdl_train_embeddings, dtype=torch.float32), torch.tensor(sclsdl_train_labels, dtype=torch.long))\n",
    "sclsdl_val_dataset = TensorDataset(torch.tensor(sclsdl_val_embeddings, dtype=torch.float32), torch.tensor(sclsdl_val_labels, dtype=torch.long))\n",
    "sclsdl_test_dataset = TensorDataset(torch.tensor(sclsdl_test_embeddings, dtype=torch.float32), torch.tensor(sclsdl_test_labels, dtype=torch.long))\n",
    "\n",
    "\n",
    "sclsdl_m = 20\n",
    "sclsdl_num_classes = len(np.unique(sclsdl_train_labels))\n",
    "\n",
    "# calc theoretical required batch size\n",
    "sclsdl_required_batch_size = sclsdl_m * sclsdl_num_classes\n",
    "\n",
    "if sclsdl_required_batch_size > len(sclsdl_train_dataset):\n",
    "    sclsdl_max_possible_m = len(sclsdl_train_dataset) // sclsdl_num_classes\n",
    "    sclsdl_m = max(1, sclsdl_max_possible_m)\n",
    "    sclsdl_batch_size_train = sclsdl_m * sclsdl_num_classes\n",
    "else:\n",
    "    sclsdl_batch_size_train = sclsdl_required_batch_size\n",
    "\n",
    "sclsdl_sampler = MPerClassSampler(labels = sclsdl_train_labels, m = sclsdl_m, batch_size = sclsdl_batch_size_train, length_before_new_iter=len(sclsdl_train_dataset))\n",
    "sclsdl_train_loader = DataLoader(sclsdl_train_dataset, batch_size=sclsdl_batch_size_train, sampler=sclsdl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "sclsdl_dataloader_bs = 64\n",
    "sclsdl_val_loader = DataLoader(sclsdl_val_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "sclsdl_test_loader = DataLoader(sclsdl_test_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for sclsdl_X_batch, sclsdl_y_batch in sclsdl_train_loader:\n",
    "    sclsdl_unique, sclsdl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(sclsdl_unique, sclsdl_counts)))\n",
    "    print(f\"Training batch size: {sclsdl_batch_size_train}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:28:04.478139Z",
     "iopub.status.busy": "2025-05-08T19:28:04.476633Z",
     "iopub.status.idle": "2025-05-08T19:28:04.481454Z",
     "shell.execute_reply": "2025-05-08T19:28:04.481454Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.projection_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:28:04.484460Z",
     "iopub.status.busy": "2025-05-08T19:28:04.483459Z",
     "iopub.status.idle": "2025-05-08T19:28:04.490005Z",
     "shell.execute_reply": "2025-05-08T19:28:04.490005Z"
    }
   },
   "outputs": [],
   "source": [
    "class SilhouetteDistanceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SilhouetteDistanceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        return self.score(features, labels, True,True)\n",
    "\n",
    "    def score(self,X, labels,feature_norm=True, loss=False):\n",
    "        unique_labels = torch.unique(labels)\n",
    "        if feature_norm:\n",
    "            X= F.normalize(X, p=2, dim=1)\n",
    "\n",
    "\n",
    "        A, B = self._compute_distances(X, labels, unique_labels)\n",
    "\n",
    "        # A= scale*A\n",
    "        # B = (1-scale)*B\n",
    "        sil_samples = (B - A) / torch.clamp(torch.maximum(A, B), min=0.0001)\n",
    "\n",
    "        # nan values are for clusters of size 1, and should be 0\n",
    "        mean_sil_score = torch.mean(torch.nan_to_num(sil_samples))\n",
    "        if loss:\n",
    "            return (1 - mean_sil_score) / 2\n",
    "        else:\n",
    "            return mean_sil_score.item()\n",
    "\n",
    "\n",
    "    def _compute_distances(self,X, labels, unique_labels):\n",
    "        intra_dist = torch.zeros_like(labels, dtype=torch.float32)\n",
    "        inter_dist = torch.full_like(labels, torch.inf, dtype=torch.float32)\n",
    "\n",
    "        for i, label_a in enumerate(unique_labels):\n",
    "            cluster_indices_a = (labels == label_a)\n",
    "            subX_a = X[cluster_indices_a]\n",
    "\n",
    "\n",
    "            intra_distances_a = torch.cdist(subX_a, subX_a)\n",
    "            div = (subX_a.size(0) - 1) if subX_a.shape[0]>1 else 1\n",
    "            intra_dist[cluster_indices_a] = intra_distances_a.sum(dim=1) / div\n",
    "\n",
    "            for label_b in unique_labels[i + 1:]:\n",
    "                cluster_indices_b = (labels == label_b)\n",
    "                subX_b = X[cluster_indices_b]\n",
    "                inter_distances_ab = torch.cdist(subX_a, subX_b)\n",
    "                inter_distances_ba = torch.cdist(subX_b, subX_a)\n",
    "\n",
    "                inter_dist[cluster_indices_a] = torch.minimum(inter_distances_ab.mean(dim=1), inter_dist[cluster_indices_a])\n",
    "                inter_dist[cluster_indices_b] = torch.minimum(inter_distances_ba.mean(dim=1), inter_dist[cluster_indices_b])\n",
    "\n",
    "        return intra_dist, inter_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:28:04.493011Z",
     "iopub.status.busy": "2025-05-08T19:28:04.493011Z",
     "iopub.status.idle": "2025-05-08T19:36:24.730232Z",
     "shell.execute_reply": "2025-05-08T19:36:24.730232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Epoch [1/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4918\n",
      "LOG: Epoch [1/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4698\n",
      "    Batch [2/2], Val Loss: 0.1180\n",
      "Epoch [1/2000], Avg Train Loss: 0.4918, Avg Val Loss: 0.2939\n",
      "\n",
      "Validation loss improved from inf to 0.2939. Saving model...\n",
      "LOG: Epoch [2/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4917\n",
      "LOG: Epoch [2/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4704\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [2/2000], Avg Train Loss: 0.4917, Avg Val Loss: 0.2947\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [3/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4900\n",
      "LOG: Epoch [3/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4708\n",
      "    Batch [2/2], Val Loss: 0.1194\n",
      "Epoch [3/2000], Avg Train Loss: 0.4900, Avg Val Loss: 0.2951\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [4/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4881\n",
      "LOG: Epoch [4/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4710\n",
      "    Batch [2/2], Val Loss: 0.1198\n",
      "Epoch [4/2000], Avg Train Loss: 0.4881, Avg Val Loss: 0.2954\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [5/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4879\n",
      "LOG: Epoch [5/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4711\n",
      "    Batch [2/2], Val Loss: 0.1200\n",
      "Epoch [5/2000], Avg Train Loss: 0.4879, Avg Val Loss: 0.2955\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [6/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4890\n",
      "LOG: Epoch [6/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4710\n",
      "    Batch [2/2], Val Loss: 0.1204\n",
      "Epoch [6/2000], Avg Train Loss: 0.4890, Avg Val Loss: 0.2957\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [7/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4879\n",
      "LOG: Epoch [7/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4707\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [7/2000], Avg Train Loss: 0.4879, Avg Val Loss: 0.2947\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [8/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4847\n",
      "LOG: Epoch [8/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4704\n",
      "    Batch [2/2], Val Loss: 0.1158\n",
      "Epoch [8/2000], Avg Train Loss: 0.4847, Avg Val Loss: 0.2931\n",
      "\n",
      "Validation loss improved from 0.2939 to 0.2931. Saving model...\n",
      "LOG: Epoch [9/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4833\n",
      "LOG: Epoch [9/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4702\n",
      "    Batch [2/2], Val Loss: 0.1121\n",
      "Epoch [9/2000], Avg Train Loss: 0.4833, Avg Val Loss: 0.2912\n",
      "\n",
      "Validation loss improved from 0.2931 to 0.2912. Saving model...\n",
      "LOG: Epoch [10/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4813\n",
      "LOG: Epoch [10/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4701\n",
      "    Batch [2/2], Val Loss: 0.1084\n",
      "Epoch [10/2000], Avg Train Loss: 0.4813, Avg Val Loss: 0.2893\n",
      "\n",
      "Validation loss improved from 0.2912 to 0.2893. Saving model...\n",
      "LOG: Epoch [11/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4840\n",
      "LOG: Epoch [11/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4702\n",
      "    Batch [2/2], Val Loss: 0.1065\n",
      "Epoch [11/2000], Avg Train Loss: 0.4840, Avg Val Loss: 0.2883\n",
      "\n",
      "Validation loss improved from 0.2893 to 0.2883. Saving model...\n",
      "LOG: Epoch [12/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4814\n",
      "LOG: Epoch [12/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4703\n",
      "    Batch [2/2], Val Loss: 0.1051\n",
      "Epoch [12/2000], Avg Train Loss: 0.4814, Avg Val Loss: 0.2877\n",
      "\n",
      "Validation loss improved from 0.2883 to 0.2877. Saving model...\n",
      "LOG: Epoch [13/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4831\n",
      "LOG: Epoch [13/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4699\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [13/2000], Avg Train Loss: 0.4831, Avg Val Loss: 0.2868\n",
      "\n",
      "Validation loss improved from 0.2877 to 0.2868. Saving model...\n",
      "LOG: Epoch [14/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4812\n",
      "LOG: Epoch [14/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4699\n",
      "    Batch [2/2], Val Loss: 0.1006\n",
      "Epoch [14/2000], Avg Train Loss: 0.4812, Avg Val Loss: 0.2853\n",
      "\n",
      "Validation loss improved from 0.2868 to 0.2853. Saving model...\n",
      "LOG: Epoch [15/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4774\n",
      "LOG: Epoch [15/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4699\n",
      "    Batch [2/2], Val Loss: 0.0961\n",
      "Epoch [15/2000], Avg Train Loss: 0.4774, Avg Val Loss: 0.2830\n",
      "\n",
      "Validation loss improved from 0.2853 to 0.2830. Saving model...\n",
      "LOG: Epoch [16/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4778\n",
      "LOG: Epoch [16/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4693\n",
      "    Batch [2/2], Val Loss: 0.0927\n",
      "Epoch [16/2000], Avg Train Loss: 0.4778, Avg Val Loss: 0.2810\n",
      "\n",
      "Validation loss improved from 0.2830 to 0.2810. Saving model...\n",
      "LOG: Epoch [17/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4819\n",
      "LOG: Epoch [17/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4687\n",
      "    Batch [2/2], Val Loss: 0.0908\n",
      "Epoch [17/2000], Avg Train Loss: 0.4819, Avg Val Loss: 0.2797\n",
      "\n",
      "Validation loss improved from 0.2810 to 0.2797. Saving model...\n",
      "LOG: Epoch [18/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4783\n",
      "LOG: Epoch [18/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4683\n",
      "    Batch [2/2], Val Loss: 0.0892\n",
      "Epoch [18/2000], Avg Train Loss: 0.4783, Avg Val Loss: 0.2787\n",
      "\n",
      "Validation loss improved from 0.2797 to 0.2787. Saving model...\n",
      "LOG: Epoch [19/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4739\n",
      "LOG: Epoch [19/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4682\n",
      "    Batch [2/2], Val Loss: 0.0875\n",
      "Epoch [19/2000], Avg Train Loss: 0.4739, Avg Val Loss: 0.2779\n",
      "\n",
      "Validation loss improved from 0.2787 to 0.2779. Saving model...\n",
      "LOG: Epoch [20/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4757\n",
      "LOG: Epoch [20/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4675\n",
      "    Batch [2/2], Val Loss: 0.0849\n",
      "Epoch [20/2000], Avg Train Loss: 0.4757, Avg Val Loss: 0.2762\n",
      "\n",
      "Validation loss improved from 0.2779 to 0.2762. Saving model...\n",
      "LOG: Epoch [21/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4753\n",
      "LOG: Epoch [21/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4668\n",
      "    Batch [2/2], Val Loss: 0.0808\n",
      "Epoch [21/2000], Avg Train Loss: 0.4753, Avg Val Loss: 0.2738\n",
      "\n",
      "Validation loss improved from 0.2762 to 0.2738. Saving model...\n",
      "LOG: Epoch [22/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4777\n",
      "LOG: Epoch [22/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4659\n",
      "    Batch [2/2], Val Loss: 0.0772\n",
      "Epoch [22/2000], Avg Train Loss: 0.4777, Avg Val Loss: 0.2715\n",
      "\n",
      "Validation loss improved from 0.2738 to 0.2715. Saving model...\n",
      "LOG: Epoch [23/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4761\n",
      "LOG: Epoch [23/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4646\n",
      "    Batch [2/2], Val Loss: 0.0744\n",
      "Epoch [23/2000], Avg Train Loss: 0.4761, Avg Val Loss: 0.2695\n",
      "\n",
      "Validation loss improved from 0.2715 to 0.2695. Saving model...\n",
      "LOG: Epoch [24/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4740\n",
      "LOG: Epoch [24/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4639\n",
      "    Batch [2/2], Val Loss: 0.0729\n",
      "Epoch [24/2000], Avg Train Loss: 0.4740, Avg Val Loss: 0.2684\n",
      "\n",
      "Validation loss improved from 0.2695 to 0.2684. Saving model...\n",
      "LOG: Epoch [25/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4745\n",
      "LOG: Epoch [25/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4631\n",
      "    Batch [2/2], Val Loss: 0.0715\n",
      "Epoch [25/2000], Avg Train Loss: 0.4745, Avg Val Loss: 0.2673\n",
      "\n",
      "Validation loss improved from 0.2684 to 0.2673. Saving model...\n",
      "LOG: Epoch [26/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4752\n",
      "LOG: Epoch [26/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4622\n",
      "    Batch [2/2], Val Loss: 0.0698\n",
      "Epoch [26/2000], Avg Train Loss: 0.4752, Avg Val Loss: 0.2660\n",
      "\n",
      "Validation loss improved from 0.2673 to 0.2660. Saving model...\n",
      "LOG: Epoch [27/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4708\n",
      "LOG: Epoch [27/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4606\n",
      "    Batch [2/2], Val Loss: 0.0681\n",
      "Epoch [27/2000], Avg Train Loss: 0.4708, Avg Val Loss: 0.2644\n",
      "\n",
      "Validation loss improved from 0.2660 to 0.2644. Saving model...\n",
      "LOG: Epoch [28/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4689\n",
      "LOG: Epoch [28/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4593\n",
      "    Batch [2/2], Val Loss: 0.0669\n",
      "Epoch [28/2000], Avg Train Loss: 0.4689, Avg Val Loss: 0.2631\n",
      "\n",
      "Validation loss improved from 0.2644 to 0.2631. Saving model...\n",
      "LOG: Epoch [29/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4677\n",
      "LOG: Epoch [29/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4580\n",
      "    Batch [2/2], Val Loss: 0.0662\n",
      "Epoch [29/2000], Avg Train Loss: 0.4677, Avg Val Loss: 0.2621\n",
      "\n",
      "Validation loss improved from 0.2631 to 0.2621. Saving model...\n",
      "LOG: Epoch [30/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4678\n",
      "LOG: Epoch [30/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4569\n",
      "    Batch [2/2], Val Loss: 0.0658\n",
      "Epoch [30/2000], Avg Train Loss: 0.4678, Avg Val Loss: 0.2614\n",
      "\n",
      "Validation loss improved from 0.2621 to 0.2614. Saving model...\n",
      "LOG: Epoch [31/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4641\n",
      "LOG: Epoch [31/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4557\n",
      "    Batch [2/2], Val Loss: 0.0658\n",
      "Epoch [31/2000], Avg Train Loss: 0.4641, Avg Val Loss: 0.2608\n",
      "\n",
      "Validation loss improved from 0.2614 to 0.2608. Saving model...\n",
      "LOG: Epoch [32/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4703\n",
      "LOG: Epoch [32/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4547\n",
      "    Batch [2/2], Val Loss: 0.0659\n",
      "Epoch [32/2000], Avg Train Loss: 0.4703, Avg Val Loss: 0.2603\n",
      "\n",
      "Validation loss improved from 0.2608 to 0.2603. Saving model...\n",
      "LOG: Epoch [33/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4709\n",
      "LOG: Epoch [33/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4540\n",
      "    Batch [2/2], Val Loss: 0.0661\n",
      "Epoch [33/2000], Avg Train Loss: 0.4709, Avg Val Loss: 0.2600\n",
      "\n",
      "Validation loss improved from 0.2603 to 0.2600. Saving model...\n",
      "LOG: Epoch [34/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4659\n",
      "LOG: Epoch [34/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4532\n",
      "    Batch [2/2], Val Loss: 0.0665\n",
      "Epoch [34/2000], Avg Train Loss: 0.4659, Avg Val Loss: 0.2598\n",
      "\n",
      "Validation loss improved from 0.2600 to 0.2598. Saving model...\n",
      "LOG: Epoch [35/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4646\n",
      "LOG: Epoch [35/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4524\n",
      "    Batch [2/2], Val Loss: 0.0669\n",
      "Epoch [35/2000], Avg Train Loss: 0.4646, Avg Val Loss: 0.2597\n",
      "\n",
      "Validation loss improved from 0.2598 to 0.2597. Saving model...\n",
      "LOG: Epoch [36/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4690\n",
      "LOG: Epoch [36/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4518\n",
      "    Batch [2/2], Val Loss: 0.0674\n",
      "Epoch [36/2000], Avg Train Loss: 0.4690, Avg Val Loss: 0.2596\n",
      "\n",
      "Validation loss improved from 0.2597 to 0.2596. Saving model...\n",
      "LOG: Epoch [37/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4660\n",
      "LOG: Epoch [37/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4510\n",
      "    Batch [2/2], Val Loss: 0.0680\n",
      "Epoch [37/2000], Avg Train Loss: 0.4660, Avg Val Loss: 0.2595\n",
      "\n",
      "Validation loss improved from 0.2596 to 0.2595. Saving model...\n",
      "LOG: Epoch [38/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4630\n",
      "LOG: Epoch [38/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4502\n",
      "    Batch [2/2], Val Loss: 0.0688\n",
      "Epoch [38/2000], Avg Train Loss: 0.4630, Avg Val Loss: 0.2595\n",
      "\n",
      "Validation loss improved from 0.2595 to 0.2595. Saving model...\n",
      "LOG: Epoch [39/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4619\n",
      "LOG: Epoch [39/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4490\n",
      "    Batch [2/2], Val Loss: 0.0695\n",
      "Epoch [39/2000], Avg Train Loss: 0.4619, Avg Val Loss: 0.2592\n",
      "\n",
      "Validation loss improved from 0.2595 to 0.2592. Saving model...\n",
      "LOG: Epoch [40/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4616\n",
      "LOG: Epoch [40/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4476\n",
      "    Batch [2/2], Val Loss: 0.0700\n",
      "Epoch [40/2000], Avg Train Loss: 0.4616, Avg Val Loss: 0.2588\n",
      "\n",
      "Validation loss improved from 0.2592 to 0.2588. Saving model...\n",
      "LOG: Epoch [41/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4593\n",
      "LOG: Epoch [41/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4463\n",
      "    Batch [2/2], Val Loss: 0.0705\n",
      "Epoch [41/2000], Avg Train Loss: 0.4593, Avg Val Loss: 0.2584\n",
      "\n",
      "Validation loss improved from 0.2588 to 0.2584. Saving model...\n",
      "LOG: Epoch [42/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4630\n",
      "LOG: Epoch [42/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4451\n",
      "    Batch [2/2], Val Loss: 0.0710\n",
      "Epoch [42/2000], Avg Train Loss: 0.4630, Avg Val Loss: 0.2581\n",
      "\n",
      "Validation loss improved from 0.2584 to 0.2581. Saving model...\n",
      "LOG: Epoch [43/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4603\n",
      "LOG: Epoch [43/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4439\n",
      "    Batch [2/2], Val Loss: 0.0713\n",
      "Epoch [43/2000], Avg Train Loss: 0.4603, Avg Val Loss: 0.2576\n",
      "\n",
      "Validation loss improved from 0.2581 to 0.2576. Saving model...\n",
      "LOG: Epoch [44/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4646\n",
      "LOG: Epoch [44/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4427\n",
      "    Batch [2/2], Val Loss: 0.0718\n",
      "Epoch [44/2000], Avg Train Loss: 0.4646, Avg Val Loss: 0.2572\n",
      "\n",
      "Validation loss improved from 0.2576 to 0.2572. Saving model...\n",
      "LOG: Epoch [45/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4589\n",
      "LOG: Epoch [45/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4415\n",
      "    Batch [2/2], Val Loss: 0.0722\n",
      "Epoch [45/2000], Avg Train Loss: 0.4589, Avg Val Loss: 0.2569\n",
      "\n",
      "Validation loss improved from 0.2572 to 0.2569. Saving model...\n",
      "LOG: Epoch [46/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4596\n",
      "LOG: Epoch [46/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4406\n",
      "    Batch [2/2], Val Loss: 0.0728\n",
      "Epoch [46/2000], Avg Train Loss: 0.4596, Avg Val Loss: 0.2567\n",
      "\n",
      "Validation loss improved from 0.2569 to 0.2567. Saving model...\n",
      "LOG: Epoch [47/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4595\n",
      "LOG: Epoch [47/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4396\n",
      "    Batch [2/2], Val Loss: 0.0733\n",
      "Epoch [47/2000], Avg Train Loss: 0.4595, Avg Val Loss: 0.2565\n",
      "\n",
      "Validation loss improved from 0.2567 to 0.2565. Saving model...\n",
      "LOG: Epoch [48/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4581\n",
      "LOG: Epoch [48/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4386\n",
      "    Batch [2/2], Val Loss: 0.0739\n",
      "Epoch [48/2000], Avg Train Loss: 0.4581, Avg Val Loss: 0.2562\n",
      "\n",
      "Validation loss improved from 0.2565 to 0.2562. Saving model...\n",
      "LOG: Epoch [49/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4557\n",
      "LOG: Epoch [49/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4376\n",
      "    Batch [2/2], Val Loss: 0.0743\n",
      "Epoch [49/2000], Avg Train Loss: 0.4557, Avg Val Loss: 0.2560\n",
      "\n",
      "Validation loss improved from 0.2562 to 0.2560. Saving model...\n",
      "LOG: Epoch [50/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4545\n",
      "LOG: Epoch [50/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4367\n",
      "    Batch [2/2], Val Loss: 0.0748\n",
      "Epoch [50/2000], Avg Train Loss: 0.4545, Avg Val Loss: 0.2557\n",
      "\n",
      "Validation loss improved from 0.2560 to 0.2557. Saving model...\n",
      "LOG: Epoch [51/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4537\n",
      "LOG: Epoch [51/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4359\n",
      "    Batch [2/2], Val Loss: 0.0753\n",
      "Epoch [51/2000], Avg Train Loss: 0.4537, Avg Val Loss: 0.2556\n",
      "\n",
      "Validation loss improved from 0.2557 to 0.2556. Saving model...\n",
      "LOG: Epoch [52/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4564\n",
      "LOG: Epoch [52/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4350\n",
      "    Batch [2/2], Val Loss: 0.0757\n",
      "Epoch [52/2000], Avg Train Loss: 0.4564, Avg Val Loss: 0.2554\n",
      "\n",
      "Validation loss improved from 0.2556 to 0.2554. Saving model...\n",
      "LOG: Epoch [53/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4574\n",
      "LOG: Epoch [53/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4342\n",
      "    Batch [2/2], Val Loss: 0.0761\n",
      "Epoch [53/2000], Avg Train Loss: 0.4574, Avg Val Loss: 0.2552\n",
      "\n",
      "Validation loss improved from 0.2554 to 0.2552. Saving model...\n",
      "LOG: Epoch [54/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4524\n",
      "LOG: Epoch [54/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4334\n",
      "    Batch [2/2], Val Loss: 0.0765\n",
      "Epoch [54/2000], Avg Train Loss: 0.4524, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2552 to 0.2549. Saving model...\n",
      "LOG: Epoch [55/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4549\n",
      "LOG: Epoch [55/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4327\n",
      "    Batch [2/2], Val Loss: 0.0769\n",
      "Epoch [55/2000], Avg Train Loss: 0.4549, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2548. Saving model...\n",
      "LOG: Epoch [56/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4544\n",
      "LOG: Epoch [56/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4322\n",
      "    Batch [2/2], Val Loss: 0.0774\n",
      "Epoch [56/2000], Avg Train Loss: 0.4544, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [57/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4514\n",
      "LOG: Epoch [57/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4318\n",
      "    Batch [2/2], Val Loss: 0.0781\n",
      "Epoch [57/2000], Avg Train Loss: 0.4514, Avg Val Loss: 0.2549\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [58/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4505\n",
      "LOG: Epoch [58/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4310\n",
      "    Batch [2/2], Val Loss: 0.0787\n",
      "Epoch [58/2000], Avg Train Loss: 0.4505, Avg Val Loss: 0.2549\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [59/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4505\n",
      "LOG: Epoch [59/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4303\n",
      "    Batch [2/2], Val Loss: 0.0791\n",
      "Epoch [59/2000], Avg Train Loss: 0.4505, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2547. Saving model...\n",
      "LOG: Epoch [60/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4505\n",
      "LOG: Epoch [60/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4296\n",
      "    Batch [2/2], Val Loss: 0.0795\n",
      "Epoch [60/2000], Avg Train Loss: 0.4505, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2546. Saving model...\n",
      "LOG: Epoch [61/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4489\n",
      "LOG: Epoch [61/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4291\n",
      "    Batch [2/2], Val Loss: 0.0798\n",
      "Epoch [61/2000], Avg Train Loss: 0.4489, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2544. Saving model...\n",
      "LOG: Epoch [62/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4523\n",
      "LOG: Epoch [62/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4286\n",
      "    Batch [2/2], Val Loss: 0.0800\n",
      "Epoch [62/2000], Avg Train Loss: 0.4523, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2543. Saving model...\n",
      "LOG: Epoch [63/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4470\n",
      "LOG: Epoch [63/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4281\n",
      "    Batch [2/2], Val Loss: 0.0801\n",
      "Epoch [63/2000], Avg Train Loss: 0.4470, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2541. Saving model...\n",
      "LOG: Epoch [64/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4494\n",
      "LOG: Epoch [64/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4277\n",
      "    Batch [2/2], Val Loss: 0.0801\n",
      "Epoch [64/2000], Avg Train Loss: 0.4494, Avg Val Loss: 0.2539\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2539. Saving model...\n",
      "LOG: Epoch [65/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4484\n",
      "LOG: Epoch [65/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4275\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [65/2000], Avg Train Loss: 0.4484, Avg Val Loss: 0.2538\n",
      "\n",
      "Validation loss improved from 0.2539 to 0.2538. Saving model...\n",
      "LOG: Epoch [66/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4475\n",
      "LOG: Epoch [66/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4273\n",
      "    Batch [2/2], Val Loss: 0.0805\n",
      "Epoch [66/2000], Avg Train Loss: 0.4475, Avg Val Loss: 0.2539\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [67/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4451\n",
      "LOG: Epoch [67/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4273\n",
      "    Batch [2/2], Val Loss: 0.0809\n",
      "Epoch [67/2000], Avg Train Loss: 0.4451, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [68/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4486\n",
      "LOG: Epoch [68/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4272\n",
      "    Batch [2/2], Val Loss: 0.0815\n",
      "Epoch [68/2000], Avg Train Loss: 0.4486, Avg Val Loss: 0.2544\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [69/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4441\n",
      "LOG: Epoch [69/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4272\n",
      "    Batch [2/2], Val Loss: 0.0822\n",
      "Epoch [69/2000], Avg Train Loss: 0.4441, Avg Val Loss: 0.2547\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [70/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4439\n",
      "LOG: Epoch [70/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4271\n",
      "    Batch [2/2], Val Loss: 0.0828\n",
      "Epoch [70/2000], Avg Train Loss: 0.4439, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [71/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4420\n",
      "LOG: Epoch [71/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4269\n",
      "    Batch [2/2], Val Loss: 0.0834\n",
      "Epoch [71/2000], Avg Train Loss: 0.4420, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [72/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4425\n",
      "LOG: Epoch [72/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4268\n",
      "    Batch [2/2], Val Loss: 0.0838\n",
      "Epoch [72/2000], Avg Train Loss: 0.4425, Avg Val Loss: 0.2553\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [73/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4409\n",
      "LOG: Epoch [73/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4269\n",
      "    Batch [2/2], Val Loss: 0.0841\n",
      "Epoch [73/2000], Avg Train Loss: 0.4409, Avg Val Loss: 0.2555\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [74/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4406\n",
      "LOG: Epoch [74/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4273\n",
      "    Batch [2/2], Val Loss: 0.0845\n",
      "Epoch [74/2000], Avg Train Loss: 0.4406, Avg Val Loss: 0.2559\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [75/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4416\n",
      "LOG: Epoch [75/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4275\n",
      "    Batch [2/2], Val Loss: 0.0847\n",
      "Epoch [75/2000], Avg Train Loss: 0.4416, Avg Val Loss: 0.2561\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [76/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4346\n",
      "LOG: Epoch [76/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4279\n",
      "    Batch [2/2], Val Loss: 0.0849\n",
      "Epoch [76/2000], Avg Train Loss: 0.4346, Avg Val Loss: 0.2564\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [77/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4405\n",
      "LOG: Epoch [77/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4281\n",
      "    Batch [2/2], Val Loss: 0.0852\n",
      "Epoch [77/2000], Avg Train Loss: 0.4405, Avg Val Loss: 0.2566\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [78/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4378\n",
      "LOG: Epoch [78/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4280\n",
      "    Batch [2/2], Val Loss: 0.0854\n",
      "Epoch [78/2000], Avg Train Loss: 0.4378, Avg Val Loss: 0.2567\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [79/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4342\n",
      "LOG: Epoch [79/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4277\n",
      "    Batch [2/2], Val Loss: 0.0856\n",
      "Epoch [79/2000], Avg Train Loss: 0.4342, Avg Val Loss: 0.2566\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [80/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4395\n",
      "LOG: Epoch [80/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4274\n",
      "    Batch [2/2], Val Loss: 0.0859\n",
      "Epoch [80/2000], Avg Train Loss: 0.4395, Avg Val Loss: 0.2566\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [81/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4382\n",
      "LOG: Epoch [81/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4272\n",
      "    Batch [2/2], Val Loss: 0.0860\n",
      "Epoch [81/2000], Avg Train Loss: 0.4382, Avg Val Loss: 0.2566\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [82/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4381\n",
      "LOG: Epoch [82/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4268\n",
      "    Batch [2/2], Val Loss: 0.0861\n",
      "Epoch [82/2000], Avg Train Loss: 0.4381, Avg Val Loss: 0.2565\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [83/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4392\n",
      "LOG: Epoch [83/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4263\n",
      "    Batch [2/2], Val Loss: 0.0862\n",
      "Epoch [83/2000], Avg Train Loss: 0.4392, Avg Val Loss: 0.2563\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [84/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4327\n",
      "LOG: Epoch [84/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4256\n",
      "    Batch [2/2], Val Loss: 0.0863\n",
      "Epoch [84/2000], Avg Train Loss: 0.4327, Avg Val Loss: 0.2560\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [85/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4344\n",
      "LOG: Epoch [85/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4251\n",
      "    Batch [2/2], Val Loss: 0.0865\n",
      "Epoch [85/2000], Avg Train Loss: 0.4344, Avg Val Loss: 0.2558\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [86/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4322\n",
      "LOG: Epoch [86/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4245\n",
      "    Batch [2/2], Val Loss: 0.0868\n",
      "Epoch [86/2000], Avg Train Loss: 0.4322, Avg Val Loss: 0.2557\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [87/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4283\n",
      "LOG: Epoch [87/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4236\n",
      "    Batch [2/2], Val Loss: 0.0871\n",
      "Epoch [87/2000], Avg Train Loss: 0.4283, Avg Val Loss: 0.2553\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [88/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4326\n",
      "LOG: Epoch [88/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4230\n",
      "    Batch [2/2], Val Loss: 0.0875\n",
      "Epoch [88/2000], Avg Train Loss: 0.4326, Avg Val Loss: 0.2552\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [89/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4340\n",
      "LOG: Epoch [89/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4230\n",
      "    Batch [2/2], Val Loss: 0.0880\n",
      "Epoch [89/2000], Avg Train Loss: 0.4340, Avg Val Loss: 0.2555\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [90/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4307\n",
      "LOG: Epoch [90/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4227\n",
      "    Batch [2/2], Val Loss: 0.0887\n",
      "Epoch [90/2000], Avg Train Loss: 0.4307, Avg Val Loss: 0.2557\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [91/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4308\n",
      "LOG: Epoch [91/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4228\n",
      "    Batch [2/2], Val Loss: 0.0894\n",
      "Epoch [91/2000], Avg Train Loss: 0.4308, Avg Val Loss: 0.2561\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [92/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4278\n",
      "LOG: Epoch [92/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4206\n",
      "    Batch [2/2], Val Loss: 0.0882\n",
      "Epoch [92/2000], Avg Train Loss: 0.4278, Avg Val Loss: 0.2544\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [93/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4306\n",
      "LOG: Epoch [93/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4185\n",
      "    Batch [2/2], Val Loss: 0.0871\n",
      "Epoch [93/2000], Avg Train Loss: 0.4306, Avg Val Loss: 0.2528\n",
      "\n",
      "Validation loss improved from 0.2538 to 0.2528. Saving model...\n",
      "LOG: Epoch [94/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4317\n",
      "LOG: Epoch [94/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4165\n",
      "    Batch [2/2], Val Loss: 0.0862\n",
      "Epoch [94/2000], Avg Train Loss: 0.4317, Avg Val Loss: 0.2513\n",
      "\n",
      "Validation loss improved from 0.2528 to 0.2513. Saving model...\n",
      "LOG: Epoch [95/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4280\n",
      "LOG: Epoch [95/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4147\n",
      "    Batch [2/2], Val Loss: 0.0853\n",
      "Epoch [95/2000], Avg Train Loss: 0.4280, Avg Val Loss: 0.2500\n",
      "\n",
      "Validation loss improved from 0.2513 to 0.2500. Saving model...\n",
      "LOG: Epoch [96/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4290\n",
      "LOG: Epoch [96/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4130\n",
      "    Batch [2/2], Val Loss: 0.0844\n",
      "Epoch [96/2000], Avg Train Loss: 0.4290, Avg Val Loss: 0.2487\n",
      "\n",
      "Validation loss improved from 0.2500 to 0.2487. Saving model...\n",
      "LOG: Epoch [97/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4291\n",
      "LOG: Epoch [97/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4114\n",
      "    Batch [2/2], Val Loss: 0.0835\n",
      "Epoch [97/2000], Avg Train Loss: 0.4291, Avg Val Loss: 0.2474\n",
      "\n",
      "Validation loss improved from 0.2487 to 0.2474. Saving model...\n",
      "LOG: Epoch [98/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4297\n",
      "LOG: Epoch [98/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4099\n",
      "    Batch [2/2], Val Loss: 0.0825\n",
      "Epoch [98/2000], Avg Train Loss: 0.4297, Avg Val Loss: 0.2462\n",
      "\n",
      "Validation loss improved from 0.2474 to 0.2462. Saving model...\n",
      "LOG: Epoch [99/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4322\n",
      "LOG: Epoch [99/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4084\n",
      "    Batch [2/2], Val Loss: 0.0816\n",
      "Epoch [99/2000], Avg Train Loss: 0.4322, Avg Val Loss: 0.2450\n",
      "\n",
      "Validation loss improved from 0.2462 to 0.2450. Saving model...\n",
      "LOG: Epoch [100/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4245\n",
      "LOG: Epoch [100/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4070\n",
      "    Batch [2/2], Val Loss: 0.0808\n",
      "Epoch [100/2000], Avg Train Loss: 0.4245, Avg Val Loss: 0.2439\n",
      "\n",
      "Validation loss improved from 0.2450 to 0.2439. Saving model...\n",
      "LOG: Epoch [101/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4290\n",
      "LOG: Epoch [101/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.0801\n",
      "Epoch [101/2000], Avg Train Loss: 0.4290, Avg Val Loss: 0.2430\n",
      "\n",
      "Validation loss improved from 0.2439 to 0.2430. Saving model...\n",
      "LOG: Epoch [102/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4320\n",
      "LOG: Epoch [102/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.0796\n",
      "Epoch [102/2000], Avg Train Loss: 0.4320, Avg Val Loss: 0.2422\n",
      "\n",
      "Validation loss improved from 0.2430 to 0.2422. Saving model...\n",
      "LOG: Epoch [103/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4279\n",
      "LOG: Epoch [103/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4040\n",
      "    Batch [2/2], Val Loss: 0.0790\n",
      "Epoch [103/2000], Avg Train Loss: 0.4279, Avg Val Loss: 0.2415\n",
      "\n",
      "Validation loss improved from 0.2422 to 0.2415. Saving model...\n",
      "LOG: Epoch [104/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4325\n",
      "LOG: Epoch [104/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4032\n",
      "    Batch [2/2], Val Loss: 0.0785\n",
      "Epoch [104/2000], Avg Train Loss: 0.4325, Avg Val Loss: 0.2408\n",
      "\n",
      "Validation loss improved from 0.2415 to 0.2408. Saving model...\n",
      "LOG: Epoch [105/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4299\n",
      "LOG: Epoch [105/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4025\n",
      "    Batch [2/2], Val Loss: 0.0780\n",
      "Epoch [105/2000], Avg Train Loss: 0.4299, Avg Val Loss: 0.2402\n",
      "\n",
      "Validation loss improved from 0.2408 to 0.2402. Saving model...\n",
      "LOG: Epoch [106/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4290\n",
      "LOG: Epoch [106/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4019\n",
      "    Batch [2/2], Val Loss: 0.0775\n",
      "Epoch [106/2000], Avg Train Loss: 0.4290, Avg Val Loss: 0.2397\n",
      "\n",
      "Validation loss improved from 0.2402 to 0.2397. Saving model...\n",
      "LOG: Epoch [107/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4265\n",
      "LOG: Epoch [107/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4013\n",
      "    Batch [2/2], Val Loss: 0.0771\n",
      "Epoch [107/2000], Avg Train Loss: 0.4265, Avg Val Loss: 0.2392\n",
      "\n",
      "Validation loss improved from 0.2397 to 0.2392. Saving model...\n",
      "LOG: Epoch [108/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4328\n",
      "LOG: Epoch [108/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4009\n",
      "    Batch [2/2], Val Loss: 0.0767\n",
      "Epoch [108/2000], Avg Train Loss: 0.4328, Avg Val Loss: 0.2388\n",
      "\n",
      "Validation loss improved from 0.2392 to 0.2388. Saving model...\n",
      "LOG: Epoch [109/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4286\n",
      "LOG: Epoch [109/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4003\n",
      "    Batch [2/2], Val Loss: 0.0763\n",
      "Epoch [109/2000], Avg Train Loss: 0.4286, Avg Val Loss: 0.2383\n",
      "\n",
      "Validation loss improved from 0.2388 to 0.2383. Saving model...\n",
      "LOG: Epoch [110/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4286\n",
      "LOG: Epoch [110/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3998\n",
      "    Batch [2/2], Val Loss: 0.0760\n",
      "Epoch [110/2000], Avg Train Loss: 0.4286, Avg Val Loss: 0.2379\n",
      "\n",
      "Validation loss improved from 0.2383 to 0.2379. Saving model...\n",
      "LOG: Epoch [111/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4288\n",
      "LOG: Epoch [111/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3993\n",
      "    Batch [2/2], Val Loss: 0.0758\n",
      "Epoch [111/2000], Avg Train Loss: 0.4288, Avg Val Loss: 0.2375\n",
      "\n",
      "Validation loss improved from 0.2379 to 0.2375. Saving model...\n",
      "LOG: Epoch [112/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4304\n",
      "LOG: Epoch [112/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3989\n",
      "    Batch [2/2], Val Loss: 0.0755\n",
      "Epoch [112/2000], Avg Train Loss: 0.4304, Avg Val Loss: 0.2372\n",
      "\n",
      "Validation loss improved from 0.2375 to 0.2372. Saving model...\n",
      "LOG: Epoch [113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4240\n",
      "LOG: Epoch [113/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3984\n",
      "    Batch [2/2], Val Loss: 0.0753\n",
      "Epoch [113/2000], Avg Train Loss: 0.4240, Avg Val Loss: 0.2369\n",
      "\n",
      "Validation loss improved from 0.2372 to 0.2369. Saving model...\n",
      "LOG: Epoch [114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4311\n",
      "LOG: Epoch [114/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3980\n",
      "    Batch [2/2], Val Loss: 0.0752\n",
      "Epoch [114/2000], Avg Train Loss: 0.4311, Avg Val Loss: 0.2366\n",
      "\n",
      "Validation loss improved from 0.2369 to 0.2366. Saving model...\n",
      "LOG: Epoch [115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 0.4280\n",
      "LOG: Epoch [115/2000] - Validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/2], Val Loss: 0.3975\n",
      "    Batch [2/2], Val Loss: 0.0750\n",
      "Epoch [115/2000], Avg Train Loss: 0.4280, Avg Val Loss: 0.2363\n",
      "\n",
      "Validation loss improved from 0.2366 to 0.2363. Saving model...\n",
      "LOG: Epoch [116/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4280\n",
      "LOG: Epoch [116/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3971\n",
      "    Batch [2/2], Val Loss: 0.0749\n",
      "Epoch [116/2000], Avg Train Loss: 0.4280, Avg Val Loss: 0.2360\n",
      "\n",
      "Validation loss improved from 0.2363 to 0.2360. Saving model...\n",
      "LOG: Epoch [117/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4229\n",
      "LOG: Epoch [117/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3967\n",
      "    Batch [2/2], Val Loss: 0.0748\n",
      "Epoch [117/2000], Avg Train Loss: 0.4229, Avg Val Loss: 0.2357\n",
      "\n",
      "Validation loss improved from 0.2360 to 0.2357. Saving model...\n",
      "LOG: Epoch [118/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4259\n",
      "LOG: Epoch [118/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3963\n",
      "    Batch [2/2], Val Loss: 0.0747\n",
      "Epoch [118/2000], Avg Train Loss: 0.4259, Avg Val Loss: 0.2355\n",
      "\n",
      "Validation loss improved from 0.2357 to 0.2355. Saving model...\n",
      "LOG: Epoch [119/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4263\n",
      "LOG: Epoch [119/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3960\n",
      "    Batch [2/2], Val Loss: 0.0745\n",
      "Epoch [119/2000], Avg Train Loss: 0.4263, Avg Val Loss: 0.2353\n",
      "\n",
      "Validation loss improved from 0.2355 to 0.2353. Saving model...\n",
      "LOG: Epoch [120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4247\n",
      "LOG: Epoch [120/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3957\n",
      "    Batch [2/2], Val Loss: 0.0744\n",
      "Epoch [120/2000], Avg Train Loss: 0.4247, Avg Val Loss: 0.2350\n",
      "\n",
      "Validation loss improved from 0.2353 to 0.2350. Saving model...\n",
      "LOG: Epoch [121/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4251\n",
      "LOG: Epoch [121/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3954\n",
      "    Batch [2/2], Val Loss: 0.0743\n",
      "Epoch [121/2000], Avg Train Loss: 0.4251, Avg Val Loss: 0.2348\n",
      "\n",
      "Validation loss improved from 0.2350 to 0.2348. Saving model...\n",
      "LOG: Epoch [122/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4253\n",
      "LOG: Epoch [122/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3951\n",
      "    Batch [2/2], Val Loss: 0.0741\n",
      "Epoch [122/2000], Avg Train Loss: 0.4253, Avg Val Loss: 0.2346\n",
      "\n",
      "Validation loss improved from 0.2348 to 0.2346. Saving model...\n",
      "LOG: Epoch [123/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4277\n",
      "LOG: Epoch [123/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3949\n",
      "    Batch [2/2], Val Loss: 0.0741\n",
      "Epoch [123/2000], Avg Train Loss: 0.4277, Avg Val Loss: 0.2345\n",
      "\n",
      "Validation loss improved from 0.2346 to 0.2345. Saving model...\n",
      "LOG: Epoch [124/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4247\n",
      "LOG: Epoch [124/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3946\n",
      "    Batch [2/2], Val Loss: 0.0740\n",
      "Epoch [124/2000], Avg Train Loss: 0.4247, Avg Val Loss: 0.2343\n",
      "\n",
      "Validation loss improved from 0.2345 to 0.2343. Saving model...\n",
      "LOG: Epoch [125/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4259\n",
      "LOG: Epoch [125/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3944\n",
      "    Batch [2/2], Val Loss: 0.0739\n",
      "Epoch [125/2000], Avg Train Loss: 0.4259, Avg Val Loss: 0.2341\n",
      "\n",
      "Validation loss improved from 0.2343 to 0.2341. Saving model...\n",
      "LOG: Epoch [126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4241\n",
      "LOG: Epoch [126/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3942\n",
      "    Batch [2/2], Val Loss: 0.0738\n",
      "Epoch [126/2000], Avg Train Loss: 0.4241, Avg Val Loss: 0.2340\n",
      "\n",
      "Validation loss improved from 0.2341 to 0.2340. Saving model...\n",
      "LOG: Epoch [127/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4277\n",
      "LOG: Epoch [127/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3939\n",
      "    Batch [2/2], Val Loss: 0.0737\n",
      "Epoch [127/2000], Avg Train Loss: 0.4277, Avg Val Loss: 0.2338\n",
      "\n",
      "Validation loss improved from 0.2340 to 0.2338. Saving model...\n",
      "LOG: Epoch [128/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4268\n",
      "LOG: Epoch [128/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3938\n",
      "    Batch [2/2], Val Loss: 0.0736\n",
      "Epoch [128/2000], Avg Train Loss: 0.4268, Avg Val Loss: 0.2337\n",
      "\n",
      "Validation loss improved from 0.2338 to 0.2337. Saving model...\n",
      "LOG: Epoch [129/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4268\n",
      "LOG: Epoch [129/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3937\n",
      "    Batch [2/2], Val Loss: 0.0736\n",
      "Epoch [129/2000], Avg Train Loss: 0.4268, Avg Val Loss: 0.2336\n",
      "\n",
      "Validation loss improved from 0.2337 to 0.2336. Saving model...\n",
      "LOG: Epoch [130/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4265\n",
      "LOG: Epoch [130/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3935\n",
      "    Batch [2/2], Val Loss: 0.0735\n",
      "Epoch [130/2000], Avg Train Loss: 0.4265, Avg Val Loss: 0.2335\n",
      "\n",
      "Validation loss improved from 0.2336 to 0.2335. Saving model...\n",
      "LOG: Epoch [131/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4290\n",
      "LOG: Epoch [131/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3934\n",
      "    Batch [2/2], Val Loss: 0.0735\n",
      "Epoch [131/2000], Avg Train Loss: 0.4290, Avg Val Loss: 0.2334\n",
      "\n",
      "Validation loss improved from 0.2335 to 0.2334. Saving model...\n",
      "LOG: Epoch [132/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4257\n",
      "LOG: Epoch [132/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3933\n",
      "    Batch [2/2], Val Loss: 0.0734\n",
      "Epoch [132/2000], Avg Train Loss: 0.4257, Avg Val Loss: 0.2334\n",
      "\n",
      "Validation loss improved from 0.2334 to 0.2334. Saving model...\n",
      "LOG: Epoch [133/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4270\n",
      "LOG: Epoch [133/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3932\n",
      "    Batch [2/2], Val Loss: 0.0734\n",
      "Epoch [133/2000], Avg Train Loss: 0.4270, Avg Val Loss: 0.2333\n",
      "\n",
      "Validation loss improved from 0.2334 to 0.2333. Saving model...\n",
      "LOG: Epoch [134/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4280\n",
      "LOG: Epoch [134/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3931\n",
      "    Batch [2/2], Val Loss: 0.0733\n",
      "Epoch [134/2000], Avg Train Loss: 0.4280, Avg Val Loss: 0.2332\n",
      "\n",
      "Validation loss improved from 0.2333 to 0.2332. Saving model...\n",
      "LOG: Epoch [135/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4247\n",
      "LOG: Epoch [135/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3930\n",
      "    Batch [2/2], Val Loss: 0.0733\n",
      "Epoch [135/2000], Avg Train Loss: 0.4247, Avg Val Loss: 0.2332\n",
      "\n",
      "Validation loss improved from 0.2332 to 0.2332. Saving model...\n",
      "LOG: Epoch [136/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4265\n",
      "LOG: Epoch [136/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3929\n",
      "    Batch [2/2], Val Loss: 0.0733\n",
      "Epoch [136/2000], Avg Train Loss: 0.4265, Avg Val Loss: 0.2331\n",
      "\n",
      "Validation loss improved from 0.2332 to 0.2331. Saving model...\n",
      "LOG: Epoch [137/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4266\n",
      "LOG: Epoch [137/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3928\n",
      "    Batch [2/2], Val Loss: 0.0733\n",
      "Epoch [137/2000], Avg Train Loss: 0.4266, Avg Val Loss: 0.2331\n",
      "\n",
      "Validation loss improved from 0.2331 to 0.2331. Saving model...\n",
      "LOG: Epoch [138/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4271\n",
      "LOG: Epoch [138/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3928\n",
      "    Batch [2/2], Val Loss: 0.0733\n",
      "Epoch [138/2000], Avg Train Loss: 0.4271, Avg Val Loss: 0.2330\n",
      "\n",
      "Validation loss improved from 0.2331 to 0.2330. Saving model...\n",
      "LOG: Epoch [139/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4251\n",
      "LOG: Epoch [139/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3927\n",
      "    Batch [2/2], Val Loss: 0.0733\n",
      "Epoch [139/2000], Avg Train Loss: 0.4251, Avg Val Loss: 0.2330\n",
      "\n",
      "Validation loss improved from 0.2330 to 0.2330. Saving model...\n",
      "LOG: Epoch [140/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4225\n",
      "LOG: Epoch [140/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3926\n",
      "    Batch [2/2], Val Loss: 0.0732\n",
      "Epoch [140/2000], Avg Train Loss: 0.4225, Avg Val Loss: 0.2329\n",
      "\n",
      "Validation loss improved from 0.2330 to 0.2329. Saving model...\n",
      "LOG: Epoch [141/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4292\n",
      "LOG: Epoch [141/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3925\n",
      "    Batch [2/2], Val Loss: 0.0732\n",
      "Epoch [141/2000], Avg Train Loss: 0.4292, Avg Val Loss: 0.2329\n",
      "\n",
      "Validation loss improved from 0.2329 to 0.2329. Saving model...\n",
      "LOG: Epoch [142/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4240\n",
      "LOG: Epoch [142/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3924\n",
      "    Batch [2/2], Val Loss: 0.0732\n",
      "Epoch [142/2000], Avg Train Loss: 0.4240, Avg Val Loss: 0.2328\n",
      "\n",
      "Validation loss improved from 0.2329 to 0.2328. Saving model...\n",
      "LOG: Epoch [143/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4280\n",
      "LOG: Epoch [143/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3924\n",
      "    Batch [2/2], Val Loss: 0.0732\n",
      "Epoch [143/2000], Avg Train Loss: 0.4280, Avg Val Loss: 0.2328\n",
      "\n",
      "Validation loss improved from 0.2328 to 0.2328. Saving model...\n",
      "LOG: Epoch [144/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4275\n",
      "LOG: Epoch [144/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3923\n",
      "    Batch [2/2], Val Loss: 0.0732\n",
      "Epoch [144/2000], Avg Train Loss: 0.4275, Avg Val Loss: 0.2327\n",
      "\n",
      "Validation loss improved from 0.2328 to 0.2327. Saving model...\n",
      "LOG: Epoch [145/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4277\n",
      "LOG: Epoch [145/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3921\n",
      "    Batch [2/2], Val Loss: 0.0731\n",
      "Epoch [145/2000], Avg Train Loss: 0.4277, Avg Val Loss: 0.2326\n",
      "\n",
      "Validation loss improved from 0.2327 to 0.2326. Saving model...\n",
      "LOG: Epoch [146/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4240\n",
      "LOG: Epoch [146/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3920\n",
      "    Batch [2/2], Val Loss: 0.0731\n",
      "Epoch [146/2000], Avg Train Loss: 0.4240, Avg Val Loss: 0.2325\n",
      "\n",
      "Validation loss improved from 0.2326 to 0.2325. Saving model...\n",
      "LOG: Epoch [147/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4284\n",
      "LOG: Epoch [147/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3919\n",
      "    Batch [2/2], Val Loss: 0.0730\n",
      "Epoch [147/2000], Avg Train Loss: 0.4284, Avg Val Loss: 0.2325\n",
      "\n",
      "Validation loss improved from 0.2325 to 0.2325. Saving model...\n",
      "LOG: Epoch [148/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4238\n",
      "LOG: Epoch [148/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3919\n",
      "    Batch [2/2], Val Loss: 0.0729\n",
      "Epoch [148/2000], Avg Train Loss: 0.4238, Avg Val Loss: 0.2324\n",
      "\n",
      "Validation loss improved from 0.2325 to 0.2324. Saving model...\n",
      "LOG: Epoch [149/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4265\n",
      "LOG: Epoch [149/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3918\n",
      "    Batch [2/2], Val Loss: 0.0729\n",
      "Epoch [149/2000], Avg Train Loss: 0.4265, Avg Val Loss: 0.2323\n",
      "\n",
      "Validation loss improved from 0.2324 to 0.2323. Saving model...\n",
      "LOG: Epoch [150/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4219\n",
      "LOG: Epoch [150/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3917\n",
      "    Batch [2/2], Val Loss: 0.0728\n",
      "Epoch [150/2000], Avg Train Loss: 0.4219, Avg Val Loss: 0.2323\n",
      "\n",
      "Validation loss improved from 0.2323 to 0.2323. Saving model...\n",
      "LOG: Epoch [151/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4246\n",
      "LOG: Epoch [151/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3916\n",
      "    Batch [2/2], Val Loss: 0.0727\n",
      "Epoch [151/2000], Avg Train Loss: 0.4246, Avg Val Loss: 0.2322\n",
      "\n",
      "Validation loss improved from 0.2323 to 0.2322. Saving model...\n",
      "LOG: Epoch [152/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4260\n",
      "LOG: Epoch [152/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3915\n",
      "    Batch [2/2], Val Loss: 0.0726\n",
      "Epoch [152/2000], Avg Train Loss: 0.4260, Avg Val Loss: 0.2321\n",
      "\n",
      "Validation loss improved from 0.2322 to 0.2321. Saving model...\n",
      "LOG: Epoch [153/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4228\n",
      "LOG: Epoch [153/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3914\n",
      "    Batch [2/2], Val Loss: 0.0726\n",
      "Epoch [153/2000], Avg Train Loss: 0.4228, Avg Val Loss: 0.2320\n",
      "\n",
      "Validation loss improved from 0.2321 to 0.2320. Saving model...\n",
      "LOG: Epoch [154/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4268\n",
      "LOG: Epoch [154/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3913\n",
      "    Batch [2/2], Val Loss: 0.0725\n",
      "Epoch [154/2000], Avg Train Loss: 0.4268, Avg Val Loss: 0.2319\n",
      "\n",
      "Validation loss improved from 0.2320 to 0.2319. Saving model...\n",
      "LOG: Epoch [155/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4236\n",
      "LOG: Epoch [155/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3912\n",
      "    Batch [2/2], Val Loss: 0.0725\n",
      "Epoch [155/2000], Avg Train Loss: 0.4236, Avg Val Loss: 0.2318\n",
      "\n",
      "Validation loss improved from 0.2319 to 0.2318. Saving model...\n",
      "LOG: Epoch [156/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4261\n",
      "LOG: Epoch [156/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3911\n",
      "    Batch [2/2], Val Loss: 0.0724\n",
      "Epoch [156/2000], Avg Train Loss: 0.4261, Avg Val Loss: 0.2318\n",
      "\n",
      "Validation loss improved from 0.2318 to 0.2318. Saving model...\n",
      "LOG: Epoch [157/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4246\n",
      "LOG: Epoch [157/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3910\n",
      "    Batch [2/2], Val Loss: 0.0724\n",
      "Epoch [157/2000], Avg Train Loss: 0.4246, Avg Val Loss: 0.2317\n",
      "\n",
      "Validation loss improved from 0.2318 to 0.2317. Saving model...\n",
      "LOG: Epoch [158/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4232\n",
      "LOG: Epoch [158/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3908\n",
      "    Batch [2/2], Val Loss: 0.0723\n",
      "Epoch [158/2000], Avg Train Loss: 0.4232, Avg Val Loss: 0.2316\n",
      "\n",
      "Validation loss improved from 0.2317 to 0.2316. Saving model...\n",
      "LOG: Epoch [159/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4260\n",
      "LOG: Epoch [159/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3907\n",
      "    Batch [2/2], Val Loss: 0.0723\n",
      "Epoch [159/2000], Avg Train Loss: 0.4260, Avg Val Loss: 0.2315\n",
      "\n",
      "Validation loss improved from 0.2316 to 0.2315. Saving model...\n",
      "LOG: Epoch [160/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4212\n",
      "LOG: Epoch [160/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3906\n",
      "    Batch [2/2], Val Loss: 0.0722\n",
      "Epoch [160/2000], Avg Train Loss: 0.4212, Avg Val Loss: 0.2314\n",
      "\n",
      "Validation loss improved from 0.2315 to 0.2314. Saving model...\n",
      "LOG: Epoch [161/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4261\n",
      "LOG: Epoch [161/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3906\n",
      "    Batch [2/2], Val Loss: 0.0722\n",
      "Epoch [161/2000], Avg Train Loss: 0.4261, Avg Val Loss: 0.2314\n",
      "\n",
      "Validation loss improved from 0.2314 to 0.2314. Saving model...\n",
      "LOG: Epoch [162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4253\n",
      "LOG: Epoch [162/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3905\n",
      "    Batch [2/2], Val Loss: 0.0721\n",
      "Epoch [162/2000], Avg Train Loss: 0.4253, Avg Val Loss: 0.2313\n",
      "\n",
      "Validation loss improved from 0.2314 to 0.2313. Saving model...\n",
      "LOG: Epoch [163/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4189\n",
      "LOG: Epoch [163/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3904\n",
      "    Batch [2/2], Val Loss: 0.0720\n",
      "Epoch [163/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2312\n",
      "\n",
      "Validation loss improved from 0.2313 to 0.2312. Saving model...\n",
      "LOG: Epoch [164/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4255\n",
      "LOG: Epoch [164/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3903\n",
      "    Batch [2/2], Val Loss: 0.0719\n",
      "Epoch [164/2000], Avg Train Loss: 0.4255, Avg Val Loss: 0.2311\n",
      "\n",
      "Validation loss improved from 0.2312 to 0.2311. Saving model...\n",
      "LOG: Epoch [165/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4220\n",
      "LOG: Epoch [165/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3903\n",
      "    Batch [2/2], Val Loss: 0.0719\n",
      "Epoch [165/2000], Avg Train Loss: 0.4220, Avg Val Loss: 0.2311\n",
      "\n",
      "Validation loss improved from 0.2311 to 0.2311. Saving model...\n",
      "LOG: Epoch [166/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4207\n",
      "LOG: Epoch [166/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3902\n",
      "    Batch [2/2], Val Loss: 0.0718\n",
      "Epoch [166/2000], Avg Train Loss: 0.4207, Avg Val Loss: 0.2310\n",
      "\n",
      "Validation loss improved from 0.2311 to 0.2310. Saving model...\n",
      "LOG: Epoch [167/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4239\n",
      "LOG: Epoch [167/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3902\n",
      "    Batch [2/2], Val Loss: 0.0717\n",
      "Epoch [167/2000], Avg Train Loss: 0.4239, Avg Val Loss: 0.2310\n",
      "\n",
      "Validation loss improved from 0.2310 to 0.2310. Saving model...\n",
      "LOG: Epoch [168/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4244\n",
      "LOG: Epoch [168/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3902\n",
      "    Batch [2/2], Val Loss: 0.0716\n",
      "Epoch [168/2000], Avg Train Loss: 0.4244, Avg Val Loss: 0.2309\n",
      "\n",
      "Validation loss improved from 0.2310 to 0.2309. Saving model...\n",
      "LOG: Epoch [169/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4229\n",
      "LOG: Epoch [169/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3902\n",
      "    Batch [2/2], Val Loss: 0.0716\n",
      "Epoch [169/2000], Avg Train Loss: 0.4229, Avg Val Loss: 0.2309\n",
      "\n",
      "Validation loss improved from 0.2309 to 0.2309. Saving model...\n",
      "LOG: Epoch [170/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4246\n",
      "LOG: Epoch [170/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3902\n",
      "    Batch [2/2], Val Loss: 0.0715\n",
      "Epoch [170/2000], Avg Train Loss: 0.4246, Avg Val Loss: 0.2308\n",
      "\n",
      "Validation loss improved from 0.2309 to 0.2308. Saving model...\n",
      "LOG: Epoch [171/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4248\n",
      "LOG: Epoch [171/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3901\n",
      "    Batch [2/2], Val Loss: 0.0715\n",
      "Epoch [171/2000], Avg Train Loss: 0.4248, Avg Val Loss: 0.2308\n",
      "\n",
      "Validation loss improved from 0.2308 to 0.2308. Saving model...\n",
      "LOG: Epoch [172/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4264\n",
      "LOG: Epoch [172/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3901\n",
      "    Batch [2/2], Val Loss: 0.0714\n",
      "Epoch [172/2000], Avg Train Loss: 0.4264, Avg Val Loss: 0.2308\n",
      "\n",
      "Validation loss improved from 0.2308 to 0.2308. Saving model...\n",
      "LOG: Epoch [173/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4272\n",
      "LOG: Epoch [173/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3901\n",
      "    Batch [2/2], Val Loss: 0.0714\n",
      "Epoch [173/2000], Avg Train Loss: 0.4272, Avg Val Loss: 0.2307\n",
      "\n",
      "Validation loss improved from 0.2308 to 0.2307. Saving model...\n",
      "LOG: Epoch [174/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4253\n",
      "LOG: Epoch [174/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3901\n",
      "    Batch [2/2], Val Loss: 0.0714\n",
      "Epoch [174/2000], Avg Train Loss: 0.4253, Avg Val Loss: 0.2307\n",
      "\n",
      "Validation loss improved from 0.2307 to 0.2307. Saving model...\n",
      "LOG: Epoch [175/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4227\n",
      "LOG: Epoch [175/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3900\n",
      "    Batch [2/2], Val Loss: 0.0713\n",
      "Epoch [175/2000], Avg Train Loss: 0.4227, Avg Val Loss: 0.2307\n",
      "\n",
      "Validation loss improved from 0.2307 to 0.2307. Saving model...\n",
      "LOG: Epoch [176/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4221\n",
      "LOG: Epoch [176/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3900\n",
      "    Batch [2/2], Val Loss: 0.0713\n",
      "Epoch [176/2000], Avg Train Loss: 0.4221, Avg Val Loss: 0.2306\n",
      "\n",
      "Validation loss improved from 0.2307 to 0.2306. Saving model...\n",
      "LOG: Epoch [177/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4240\n",
      "LOG: Epoch [177/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3899\n",
      "    Batch [2/2], Val Loss: 0.0712\n",
      "Epoch [177/2000], Avg Train Loss: 0.4240, Avg Val Loss: 0.2306\n",
      "\n",
      "Validation loss improved from 0.2306 to 0.2306. Saving model...\n",
      "LOG: Epoch [178/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4230\n",
      "LOG: Epoch [178/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3898\n",
      "    Batch [2/2], Val Loss: 0.0712\n",
      "Epoch [178/2000], Avg Train Loss: 0.4230, Avg Val Loss: 0.2305\n",
      "\n",
      "Validation loss improved from 0.2306 to 0.2305. Saving model...\n",
      "LOG: Epoch [179/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4260\n",
      "LOG: Epoch [179/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3898\n",
      "    Batch [2/2], Val Loss: 0.0712\n",
      "Epoch [179/2000], Avg Train Loss: 0.4260, Avg Val Loss: 0.2305\n",
      "\n",
      "Validation loss improved from 0.2305 to 0.2305. Saving model...\n",
      "LOG: Epoch [180/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4274\n",
      "LOG: Epoch [180/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3896\n",
      "    Batch [2/2], Val Loss: 0.0711\n",
      "Epoch [180/2000], Avg Train Loss: 0.4274, Avg Val Loss: 0.2304\n",
      "\n",
      "Validation loss improved from 0.2305 to 0.2304. Saving model...\n",
      "LOG: Epoch [181/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4194\n",
      "LOG: Epoch [181/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3896\n",
      "    Batch [2/2], Val Loss: 0.0711\n",
      "Epoch [181/2000], Avg Train Loss: 0.4194, Avg Val Loss: 0.2303\n",
      "\n",
      "Validation loss improved from 0.2304 to 0.2303. Saving model...\n",
      "LOG: Epoch [182/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4217\n",
      "LOG: Epoch [182/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3895\n",
      "    Batch [2/2], Val Loss: 0.0710\n",
      "Epoch [182/2000], Avg Train Loss: 0.4217, Avg Val Loss: 0.2302\n",
      "\n",
      "Validation loss improved from 0.2303 to 0.2302. Saving model...\n",
      "LOG: Epoch [183/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4269\n",
      "LOG: Epoch [183/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3894\n",
      "    Batch [2/2], Val Loss: 0.0710\n",
      "Epoch [183/2000], Avg Train Loss: 0.4269, Avg Val Loss: 0.2302\n",
      "\n",
      "Validation loss improved from 0.2302 to 0.2302. Saving model...\n",
      "LOG: Epoch [184/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4269\n",
      "LOG: Epoch [184/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3893\n",
      "    Batch [2/2], Val Loss: 0.0709\n",
      "Epoch [184/2000], Avg Train Loss: 0.4269, Avg Val Loss: 0.2301\n",
      "\n",
      "Validation loss improved from 0.2302 to 0.2301. Saving model...\n",
      "LOG: Epoch [185/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4202\n",
      "LOG: Epoch [185/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3892\n",
      "    Batch [2/2], Val Loss: 0.0709\n",
      "Epoch [185/2000], Avg Train Loss: 0.4202, Avg Val Loss: 0.2300\n",
      "\n",
      "Validation loss improved from 0.2301 to 0.2300. Saving model...\n",
      "LOG: Epoch [186/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4211\n",
      "LOG: Epoch [186/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3892\n",
      "    Batch [2/2], Val Loss: 0.0708\n",
      "Epoch [186/2000], Avg Train Loss: 0.4211, Avg Val Loss: 0.2300\n",
      "\n",
      "Validation loss improved from 0.2300 to 0.2300. Saving model...\n",
      "LOG: Epoch [187/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4248\n",
      "LOG: Epoch [187/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3891\n",
      "    Batch [2/2], Val Loss: 0.0708\n",
      "Epoch [187/2000], Avg Train Loss: 0.4248, Avg Val Loss: 0.2299\n",
      "\n",
      "Validation loss improved from 0.2300 to 0.2299. Saving model...\n",
      "LOG: Epoch [188/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4232\n",
      "LOG: Epoch [188/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3890\n",
      "    Batch [2/2], Val Loss: 0.0707\n",
      "Epoch [188/2000], Avg Train Loss: 0.4232, Avg Val Loss: 0.2298\n",
      "\n",
      "Validation loss improved from 0.2299 to 0.2298. Saving model...\n",
      "LOG: Epoch [189/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4193\n",
      "LOG: Epoch [189/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3888\n",
      "    Batch [2/2], Val Loss: 0.0707\n",
      "Epoch [189/2000], Avg Train Loss: 0.4193, Avg Val Loss: 0.2298\n",
      "\n",
      "Validation loss improved from 0.2298 to 0.2298. Saving model...\n",
      "LOG: Epoch [190/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4189\n",
      "LOG: Epoch [190/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3887\n",
      "    Batch [2/2], Val Loss: 0.0707\n",
      "Epoch [190/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2297\n",
      "\n",
      "Validation loss improved from 0.2298 to 0.2297. Saving model...\n",
      "LOG: Epoch [191/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4254\n",
      "LOG: Epoch [191/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3886\n",
      "    Batch [2/2], Val Loss: 0.0707\n",
      "Epoch [191/2000], Avg Train Loss: 0.4254, Avg Val Loss: 0.2296\n",
      "\n",
      "Validation loss improved from 0.2297 to 0.2296. Saving model...\n",
      "LOG: Epoch [192/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4195\n",
      "LOG: Epoch [192/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3885\n",
      "    Batch [2/2], Val Loss: 0.0706\n",
      "Epoch [192/2000], Avg Train Loss: 0.4195, Avg Val Loss: 0.2296\n",
      "\n",
      "Validation loss improved from 0.2296 to 0.2296. Saving model...\n",
      "LOG: Epoch [193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4222\n",
      "LOG: Epoch [193/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3883\n",
      "    Batch [2/2], Val Loss: 0.0706\n",
      "Epoch [193/2000], Avg Train Loss: 0.4222, Avg Val Loss: 0.2295\n",
      "\n",
      "Validation loss improved from 0.2296 to 0.2295. Saving model...\n",
      "LOG: Epoch [194/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4206\n",
      "LOG: Epoch [194/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3882\n",
      "    Batch [2/2], Val Loss: 0.0706\n",
      "Epoch [194/2000], Avg Train Loss: 0.4206, Avg Val Loss: 0.2294\n",
      "\n",
      "Validation loss improved from 0.2295 to 0.2294. Saving model...\n",
      "LOG: Epoch [195/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4214\n",
      "LOG: Epoch [195/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3881\n",
      "    Batch [2/2], Val Loss: 0.0706\n",
      "Epoch [195/2000], Avg Train Loss: 0.4214, Avg Val Loss: 0.2293\n",
      "\n",
      "Validation loss improved from 0.2294 to 0.2293. Saving model...\n",
      "LOG: Epoch [196/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4245\n",
      "LOG: Epoch [196/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3880\n",
      "    Batch [2/2], Val Loss: 0.0706\n",
      "Epoch [196/2000], Avg Train Loss: 0.4245, Avg Val Loss: 0.2293\n",
      "\n",
      "Validation loss improved from 0.2293 to 0.2293. Saving model...\n",
      "LOG: Epoch [197/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4212\n",
      "LOG: Epoch [197/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3879\n",
      "    Batch [2/2], Val Loss: 0.0705\n",
      "Epoch [197/2000], Avg Train Loss: 0.4212, Avg Val Loss: 0.2292\n",
      "\n",
      "Validation loss improved from 0.2293 to 0.2292. Saving model...\n",
      "LOG: Epoch [198/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4230\n",
      "LOG: Epoch [198/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3878\n",
      "    Batch [2/2], Val Loss: 0.0705\n",
      "Epoch [198/2000], Avg Train Loss: 0.4230, Avg Val Loss: 0.2292\n",
      "\n",
      "Validation loss improved from 0.2292 to 0.2292. Saving model...\n",
      "LOG: Epoch [199/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4231\n",
      "LOG: Epoch [199/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3877\n",
      "    Batch [2/2], Val Loss: 0.0705\n",
      "Epoch [199/2000], Avg Train Loss: 0.4231, Avg Val Loss: 0.2291\n",
      "\n",
      "Validation loss improved from 0.2292 to 0.2291. Saving model...\n",
      "LOG: Epoch [200/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4210\n",
      "LOG: Epoch [200/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3877\n",
      "    Batch [2/2], Val Loss: 0.0705\n",
      "Epoch [200/2000], Avg Train Loss: 0.4210, Avg Val Loss: 0.2291\n",
      "\n",
      "Validation loss improved from 0.2291 to 0.2291. Saving model...\n",
      "LOG: Epoch [201/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4232\n",
      "LOG: Epoch [201/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3876\n",
      "    Batch [2/2], Val Loss: 0.0705\n",
      "Epoch [201/2000], Avg Train Loss: 0.4232, Avg Val Loss: 0.2290\n",
      "\n",
      "Validation loss improved from 0.2291 to 0.2290. Saving model...\n",
      "LOG: Epoch [202/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4189\n",
      "LOG: Epoch [202/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3875\n",
      "    Batch [2/2], Val Loss: 0.0705\n",
      "Epoch [202/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2290\n",
      "\n",
      "Validation loss improved from 0.2290 to 0.2290. Saving model...\n",
      "LOG: Epoch [203/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4214\n",
      "LOG: Epoch [203/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3873\n",
      "    Batch [2/2], Val Loss: 0.0704\n",
      "Epoch [203/2000], Avg Train Loss: 0.4214, Avg Val Loss: 0.2289\n",
      "\n",
      "Validation loss improved from 0.2290 to 0.2289. Saving model...\n",
      "LOG: Epoch [204/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4216\n",
      "LOG: Epoch [204/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3872\n",
      "    Batch [2/2], Val Loss: 0.0704\n",
      "Epoch [204/2000], Avg Train Loss: 0.4216, Avg Val Loss: 0.2288\n",
      "\n",
      "Validation loss improved from 0.2289 to 0.2288. Saving model...\n",
      "LOG: Epoch [205/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4200\n",
      "LOG: Epoch [205/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3871\n",
      "    Batch [2/2], Val Loss: 0.0704\n",
      "Epoch [205/2000], Avg Train Loss: 0.4200, Avg Val Loss: 0.2288\n",
      "\n",
      "Validation loss improved from 0.2288 to 0.2288. Saving model...\n",
      "LOG: Epoch [206/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4246\n",
      "LOG: Epoch [206/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3870\n",
      "    Batch [2/2], Val Loss: 0.0704\n",
      "Epoch [206/2000], Avg Train Loss: 0.4246, Avg Val Loss: 0.2287\n",
      "\n",
      "Validation loss improved from 0.2288 to 0.2287. Saving model...\n",
      "LOG: Epoch [207/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4218\n",
      "LOG: Epoch [207/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3869\n",
      "    Batch [2/2], Val Loss: 0.0705\n",
      "Epoch [207/2000], Avg Train Loss: 0.4218, Avg Val Loss: 0.2287\n",
      "\n",
      "Validation loss improved from 0.2287 to 0.2287. Saving model...\n",
      "LOG: Epoch [208/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4195\n",
      "LOG: Epoch [208/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3869\n",
      "    Batch [2/2], Val Loss: 0.0705\n",
      "Epoch [208/2000], Avg Train Loss: 0.4195, Avg Val Loss: 0.2287\n",
      "\n",
      "Validation loss improved from 0.2287 to 0.2287. Saving model...\n",
      "LOG: Epoch [209/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4211\n",
      "LOG: Epoch [209/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3868\n",
      "    Batch [2/2], Val Loss: 0.0705\n",
      "Epoch [209/2000], Avg Train Loss: 0.4211, Avg Val Loss: 0.2286\n",
      "\n",
      "Validation loss improved from 0.2287 to 0.2286. Saving model...\n",
      "LOG: Epoch [210/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4225\n",
      "LOG: Epoch [210/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3867\n",
      "    Batch [2/2], Val Loss: 0.0705\n",
      "Epoch [210/2000], Avg Train Loss: 0.4225, Avg Val Loss: 0.2286\n",
      "\n",
      "Validation loss improved from 0.2286 to 0.2286. Saving model...\n",
      "LOG: Epoch [211/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4222\n",
      "LOG: Epoch [211/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3865\n",
      "    Batch [2/2], Val Loss: 0.0705\n",
      "Epoch [211/2000], Avg Train Loss: 0.4222, Avg Val Loss: 0.2285\n",
      "\n",
      "Validation loss improved from 0.2286 to 0.2285. Saving model...\n",
      "LOG: Epoch [212/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4203\n",
      "LOG: Epoch [212/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3864\n",
      "    Batch [2/2], Val Loss: 0.0704\n",
      "Epoch [212/2000], Avg Train Loss: 0.4203, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2285 to 0.2284. Saving model...\n",
      "LOG: Epoch [213/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4228\n",
      "LOG: Epoch [213/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3862\n",
      "    Batch [2/2], Val Loss: 0.0704\n",
      "Epoch [213/2000], Avg Train Loss: 0.4228, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2283. Saving model...\n",
      "LOG: Epoch [214/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4212\n",
      "LOG: Epoch [214/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3862\n",
      "    Batch [2/2], Val Loss: 0.0704\n",
      "Epoch [214/2000], Avg Train Loss: 0.4212, Avg Val Loss: 0.2283\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2283. Saving model...\n",
      "LOG: Epoch [215/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4235\n",
      "LOG: Epoch [215/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3861\n",
      "    Batch [2/2], Val Loss: 0.0703\n",
      "Epoch [215/2000], Avg Train Loss: 0.4235, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2283 to 0.2282. Saving model...\n",
      "LOG: Epoch [216/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4203\n",
      "LOG: Epoch [216/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3860\n",
      "    Batch [2/2], Val Loss: 0.0703\n",
      "Epoch [216/2000], Avg Train Loss: 0.4203, Avg Val Loss: 0.2282\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2282. Saving model...\n",
      "LOG: Epoch [217/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4196\n",
      "LOG: Epoch [217/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3860\n",
      "    Batch [2/2], Val Loss: 0.0703\n",
      "Epoch [217/2000], Avg Train Loss: 0.4196, Avg Val Loss: 0.2281\n",
      "\n",
      "Validation loss improved from 0.2282 to 0.2281. Saving model...\n",
      "LOG: Epoch [218/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4195\n",
      "LOG: Epoch [218/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3859\n",
      "    Batch [2/2], Val Loss: 0.0703\n",
      "Epoch [218/2000], Avg Train Loss: 0.4195, Avg Val Loss: 0.2281\n",
      "\n",
      "Validation loss improved from 0.2281 to 0.2281. Saving model...\n",
      "LOG: Epoch [219/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4217\n",
      "LOG: Epoch [219/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3858\n",
      "    Batch [2/2], Val Loss: 0.0702\n",
      "Epoch [219/2000], Avg Train Loss: 0.4217, Avg Val Loss: 0.2280\n",
      "\n",
      "Validation loss improved from 0.2281 to 0.2280. Saving model...\n",
      "LOG: Epoch [220/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4232\n",
      "LOG: Epoch [220/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3857\n",
      "    Batch [2/2], Val Loss: 0.0701\n",
      "Epoch [220/2000], Avg Train Loss: 0.4232, Avg Val Loss: 0.2279\n",
      "\n",
      "Validation loss improved from 0.2280 to 0.2279. Saving model...\n",
      "LOG: Epoch [221/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4160\n",
      "LOG: Epoch [221/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3856\n",
      "    Batch [2/2], Val Loss: 0.0701\n",
      "Epoch [221/2000], Avg Train Loss: 0.4160, Avg Val Loss: 0.2279\n",
      "\n",
      "Validation loss improved from 0.2279 to 0.2279. Saving model...\n",
      "LOG: Epoch [222/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4182\n",
      "LOG: Epoch [222/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3855\n",
      "    Batch [2/2], Val Loss: 0.0701\n",
      "Epoch [222/2000], Avg Train Loss: 0.4182, Avg Val Loss: 0.2278\n",
      "\n",
      "Validation loss improved from 0.2279 to 0.2278. Saving model...\n",
      "LOG: Epoch [223/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4246\n",
      "LOG: Epoch [223/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3855\n",
      "    Batch [2/2], Val Loss: 0.0700\n",
      "Epoch [223/2000], Avg Train Loss: 0.4246, Avg Val Loss: 0.2277\n",
      "\n",
      "Validation loss improved from 0.2278 to 0.2277. Saving model...\n",
      "LOG: Epoch [224/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4196\n",
      "LOG: Epoch [224/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3854\n",
      "    Batch [2/2], Val Loss: 0.0700\n",
      "Epoch [224/2000], Avg Train Loss: 0.4196, Avg Val Loss: 0.2277\n",
      "\n",
      "Validation loss improved from 0.2277 to 0.2277. Saving model...\n",
      "LOG: Epoch [225/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4220\n",
      "LOG: Epoch [225/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3854\n",
      "    Batch [2/2], Val Loss: 0.0700\n",
      "Epoch [225/2000], Avg Train Loss: 0.4220, Avg Val Loss: 0.2277\n",
      "\n",
      "Validation loss improved from 0.2277 to 0.2277. Saving model...\n",
      "LOG: Epoch [226/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4194\n",
      "LOG: Epoch [226/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3853\n",
      "    Batch [2/2], Val Loss: 0.0699\n",
      "Epoch [226/2000], Avg Train Loss: 0.4194, Avg Val Loss: 0.2276\n",
      "\n",
      "Validation loss improved from 0.2277 to 0.2276. Saving model...\n",
      "LOG: Epoch [227/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4203\n",
      "LOG: Epoch [227/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3854\n",
      "    Batch [2/2], Val Loss: 0.0699\n",
      "Epoch [227/2000], Avg Train Loss: 0.4203, Avg Val Loss: 0.2276\n",
      "\n",
      "Validation loss improved from 0.2276 to 0.2276. Saving model...\n",
      "LOG: Epoch [228/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4241\n",
      "LOG: Epoch [228/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3854\n",
      "    Batch [2/2], Val Loss: 0.0699\n",
      "Epoch [228/2000], Avg Train Loss: 0.4241, Avg Val Loss: 0.2276\n",
      "\n",
      "Validation loss improved from 0.2276 to 0.2276. Saving model...\n",
      "LOG: Epoch [229/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4213\n",
      "LOG: Epoch [229/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3854\n",
      "    Batch [2/2], Val Loss: 0.0698\n",
      "Epoch [229/2000], Avg Train Loss: 0.4213, Avg Val Loss: 0.2276\n",
      "\n",
      "Validation loss improved from 0.2276 to 0.2276. Saving model...\n",
      "LOG: Epoch [230/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4196\n",
      "LOG: Epoch [230/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3853\n",
      "    Batch [2/2], Val Loss: 0.0698\n",
      "Epoch [230/2000], Avg Train Loss: 0.4196, Avg Val Loss: 0.2275\n",
      "\n",
      "Validation loss improved from 0.2276 to 0.2275. Saving model...\n",
      "LOG: Epoch [231/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4193\n",
      "LOG: Epoch [231/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3853\n",
      "    Batch [2/2], Val Loss: 0.0697\n",
      "Epoch [231/2000], Avg Train Loss: 0.4193, Avg Val Loss: 0.2275\n",
      "\n",
      "Validation loss improved from 0.2275 to 0.2275. Saving model...\n",
      "LOG: Epoch [232/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4189\n",
      "LOG: Epoch [232/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3853\n",
      "    Batch [2/2], Val Loss: 0.0697\n",
      "Epoch [232/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2275\n",
      "\n",
      "Validation loss improved from 0.2275 to 0.2275. Saving model...\n",
      "LOG: Epoch [233/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4187\n",
      "LOG: Epoch [233/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3853\n",
      "    Batch [2/2], Val Loss: 0.0696\n",
      "Epoch [233/2000], Avg Train Loss: 0.4187, Avg Val Loss: 0.2275\n",
      "\n",
      "Validation loss improved from 0.2275 to 0.2275. Saving model...\n",
      "LOG: Epoch [234/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4186\n",
      "LOG: Epoch [234/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3853\n",
      "    Batch [2/2], Val Loss: 0.0696\n",
      "Epoch [234/2000], Avg Train Loss: 0.4186, Avg Val Loss: 0.2274\n",
      "\n",
      "Validation loss improved from 0.2275 to 0.2274. Saving model...\n",
      "LOG: Epoch [235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4187\n",
      "LOG: Epoch [235/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3852\n",
      "    Batch [2/2], Val Loss: 0.0695\n",
      "Epoch [235/2000], Avg Train Loss: 0.4187, Avg Val Loss: 0.2274\n",
      "\n",
      "Validation loss improved from 0.2274 to 0.2274. Saving model...\n",
      "LOG: Epoch [236/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4214\n",
      "LOG: Epoch [236/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3852\n",
      "    Batch [2/2], Val Loss: 0.0695\n",
      "Epoch [236/2000], Avg Train Loss: 0.4214, Avg Val Loss: 0.2273\n",
      "\n",
      "Validation loss improved from 0.2274 to 0.2273. Saving model...\n",
      "LOG: Epoch [237/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4181\n",
      "LOG: Epoch [237/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3852\n",
      "    Batch [2/2], Val Loss: 0.0694\n",
      "Epoch [237/2000], Avg Train Loss: 0.4181, Avg Val Loss: 0.2273\n",
      "\n",
      "Validation loss improved from 0.2273 to 0.2273. Saving model...\n",
      "LOG: Epoch [238/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4202\n",
      "LOG: Epoch [238/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3851\n",
      "    Batch [2/2], Val Loss: 0.0694\n",
      "Epoch [238/2000], Avg Train Loss: 0.4202, Avg Val Loss: 0.2273\n",
      "\n",
      "Validation loss improved from 0.2273 to 0.2273. Saving model...\n",
      "LOG: Epoch [239/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4187\n",
      "LOG: Epoch [239/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3851\n",
      "    Batch [2/2], Val Loss: 0.0693\n",
      "Epoch [239/2000], Avg Train Loss: 0.4187, Avg Val Loss: 0.2272\n",
      "\n",
      "Validation loss improved from 0.2273 to 0.2272. Saving model...\n",
      "LOG: Epoch [240/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4210\n",
      "LOG: Epoch [240/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3850\n",
      "    Batch [2/2], Val Loss: 0.0693\n",
      "Epoch [240/2000], Avg Train Loss: 0.4210, Avg Val Loss: 0.2272\n",
      "\n",
      "Validation loss improved from 0.2272 to 0.2272. Saving model...\n",
      "LOG: Epoch [241/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4226\n",
      "LOG: Epoch [241/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3850\n",
      "    Batch [2/2], Val Loss: 0.0692\n",
      "Epoch [241/2000], Avg Train Loss: 0.4226, Avg Val Loss: 0.2271\n",
      "\n",
      "Validation loss improved from 0.2272 to 0.2271. Saving model...\n",
      "LOG: Epoch [242/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4165\n",
      "LOG: Epoch [242/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3850\n",
      "    Batch [2/2], Val Loss: 0.0692\n",
      "Epoch [242/2000], Avg Train Loss: 0.4165, Avg Val Loss: 0.2271\n",
      "\n",
      "Validation loss improved from 0.2271 to 0.2271. Saving model...\n",
      "LOG: Epoch [243/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4194\n",
      "LOG: Epoch [243/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3850\n",
      "    Batch [2/2], Val Loss: 0.0691\n",
      "Epoch [243/2000], Avg Train Loss: 0.4194, Avg Val Loss: 0.2270\n",
      "\n",
      "Validation loss improved from 0.2271 to 0.2270. Saving model...\n",
      "LOG: Epoch [244/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4170\n",
      "LOG: Epoch [244/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3850\n",
      "    Batch [2/2], Val Loss: 0.0691\n",
      "Epoch [244/2000], Avg Train Loss: 0.4170, Avg Val Loss: 0.2270\n",
      "\n",
      "Validation loss improved from 0.2270 to 0.2270. Saving model...\n",
      "LOG: Epoch [245/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4221\n",
      "LOG: Epoch [245/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3850\n",
      "    Batch [2/2], Val Loss: 0.0690\n",
      "Epoch [245/2000], Avg Train Loss: 0.4221, Avg Val Loss: 0.2270\n",
      "\n",
      "Validation loss improved from 0.2270 to 0.2270. Saving model...\n",
      "LOG: Epoch [246/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4224\n",
      "LOG: Epoch [246/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3849\n",
      "    Batch [2/2], Val Loss: 0.0690\n",
      "Epoch [246/2000], Avg Train Loss: 0.4224, Avg Val Loss: 0.2270\n",
      "\n",
      "Validation loss improved from 0.2270 to 0.2270. Saving model...\n",
      "LOG: Epoch [247/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4148\n",
      "LOG: Epoch [247/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3849\n",
      "    Batch [2/2], Val Loss: 0.0690\n",
      "Epoch [247/2000], Avg Train Loss: 0.4148, Avg Val Loss: 0.2269\n",
      "\n",
      "Validation loss improved from 0.2270 to 0.2269. Saving model...\n",
      "LOG: Epoch [248/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4190\n",
      "LOG: Epoch [248/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3848\n",
      "    Batch [2/2], Val Loss: 0.0690\n",
      "Epoch [248/2000], Avg Train Loss: 0.4190, Avg Val Loss: 0.2269\n",
      "\n",
      "Validation loss improved from 0.2269 to 0.2269. Saving model...\n",
      "LOG: Epoch [249/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4198\n",
      "LOG: Epoch [249/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3847\n",
      "    Batch [2/2], Val Loss: 0.0690\n",
      "Epoch [249/2000], Avg Train Loss: 0.4198, Avg Val Loss: 0.2268\n",
      "\n",
      "Validation loss improved from 0.2269 to 0.2268. Saving model...\n",
      "LOG: Epoch [250/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4164\n",
      "LOG: Epoch [250/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3847\n",
      "    Batch [2/2], Val Loss: 0.0689\n",
      "Epoch [250/2000], Avg Train Loss: 0.4164, Avg Val Loss: 0.2268\n",
      "\n",
      "Validation loss improved from 0.2268 to 0.2268. Saving model...\n",
      "LOG: Epoch [251/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4172\n",
      "LOG: Epoch [251/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3846\n",
      "    Batch [2/2], Val Loss: 0.0689\n",
      "Epoch [251/2000], Avg Train Loss: 0.4172, Avg Val Loss: 0.2268\n",
      "\n",
      "Validation loss improved from 0.2268 to 0.2268. Saving model...\n",
      "LOG: Epoch [252/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4165\n",
      "LOG: Epoch [252/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3846\n",
      "    Batch [2/2], Val Loss: 0.0689\n",
      "Epoch [252/2000], Avg Train Loss: 0.4165, Avg Val Loss: 0.2267\n",
      "\n",
      "Validation loss improved from 0.2268 to 0.2267. Saving model...\n",
      "LOG: Epoch [253/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4195\n",
      "LOG: Epoch [253/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3845\n",
      "    Batch [2/2], Val Loss: 0.0688\n",
      "Epoch [253/2000], Avg Train Loss: 0.4195, Avg Val Loss: 0.2267\n",
      "\n",
      "Validation loss improved from 0.2267 to 0.2267. Saving model...\n",
      "LOG: Epoch [254/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4169\n",
      "LOG: Epoch [254/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3844\n",
      "    Batch [2/2], Val Loss: 0.0688\n",
      "Epoch [254/2000], Avg Train Loss: 0.4169, Avg Val Loss: 0.2266\n",
      "\n",
      "Validation loss improved from 0.2267 to 0.2266. Saving model...\n",
      "LOG: Epoch [255/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4203\n",
      "LOG: Epoch [255/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3844\n",
      "    Batch [2/2], Val Loss: 0.0687\n",
      "Epoch [255/2000], Avg Train Loss: 0.4203, Avg Val Loss: 0.2266\n",
      "\n",
      "Validation loss improved from 0.2266 to 0.2266. Saving model...\n",
      "LOG: Epoch [256/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4159\n",
      "LOG: Epoch [256/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3843\n",
      "    Batch [2/2], Val Loss: 0.0687\n",
      "Epoch [256/2000], Avg Train Loss: 0.4159, Avg Val Loss: 0.2265\n",
      "\n",
      "Validation loss improved from 0.2266 to 0.2265. Saving model...\n",
      "LOG: Epoch [257/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4210\n",
      "LOG: Epoch [257/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3843\n",
      "    Batch [2/2], Val Loss: 0.0687\n",
      "Epoch [257/2000], Avg Train Loss: 0.4210, Avg Val Loss: 0.2265\n",
      "\n",
      "Validation loss improved from 0.2265 to 0.2265. Saving model...\n",
      "LOG: Epoch [258/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4155\n",
      "LOG: Epoch [258/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3843\n",
      "    Batch [2/2], Val Loss: 0.0687\n",
      "Epoch [258/2000], Avg Train Loss: 0.4155, Avg Val Loss: 0.2265\n",
      "\n",
      "Validation loss improved from 0.2265 to 0.2265. Saving model...\n",
      "LOG: Epoch [259/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4179\n",
      "LOG: Epoch [259/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3843\n",
      "    Batch [2/2], Val Loss: 0.0686\n",
      "Epoch [259/2000], Avg Train Loss: 0.4179, Avg Val Loss: 0.2264\n",
      "\n",
      "Validation loss improved from 0.2265 to 0.2264. Saving model...\n",
      "LOG: Epoch [260/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4182\n",
      "LOG: Epoch [260/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3842\n",
      "    Batch [2/2], Val Loss: 0.0686\n",
      "Epoch [260/2000], Avg Train Loss: 0.4182, Avg Val Loss: 0.2264\n",
      "\n",
      "Validation loss improved from 0.2264 to 0.2264. Saving model...\n",
      "LOG: Epoch [261/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4206\n",
      "LOG: Epoch [261/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3841\n",
      "    Batch [2/2], Val Loss: 0.0686\n",
      "Epoch [261/2000], Avg Train Loss: 0.4206, Avg Val Loss: 0.2263\n",
      "\n",
      "Validation loss improved from 0.2264 to 0.2263. Saving model...\n",
      "LOG: Epoch [262/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4181\n",
      "LOG: Epoch [262/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3839\n",
      "    Batch [2/2], Val Loss: 0.0685\n",
      "Epoch [262/2000], Avg Train Loss: 0.4181, Avg Val Loss: 0.2262\n",
      "\n",
      "Validation loss improved from 0.2263 to 0.2262. Saving model...\n",
      "LOG: Epoch [263/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4186\n",
      "LOG: Epoch [263/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3839\n",
      "    Batch [2/2], Val Loss: 0.0685\n",
      "Epoch [263/2000], Avg Train Loss: 0.4186, Avg Val Loss: 0.2262\n",
      "\n",
      "Validation loss improved from 0.2262 to 0.2262. Saving model...\n",
      "LOG: Epoch [264/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4192\n",
      "LOG: Epoch [264/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3837\n",
      "    Batch [2/2], Val Loss: 0.0685\n",
      "Epoch [264/2000], Avg Train Loss: 0.4192, Avg Val Loss: 0.2261\n",
      "\n",
      "Validation loss improved from 0.2262 to 0.2261. Saving model...\n",
      "LOG: Epoch [265/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4169\n",
      "LOG: Epoch [265/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3836\n",
      "    Batch [2/2], Val Loss: 0.0684\n",
      "Epoch [265/2000], Avg Train Loss: 0.4169, Avg Val Loss: 0.2260\n",
      "\n",
      "Validation loss improved from 0.2261 to 0.2260. Saving model...\n",
      "LOG: Epoch [266/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4228\n",
      "LOG: Epoch [266/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3835\n",
      "    Batch [2/2], Val Loss: 0.0684\n",
      "Epoch [266/2000], Avg Train Loss: 0.4228, Avg Val Loss: 0.2259\n",
      "\n",
      "Validation loss improved from 0.2260 to 0.2259. Saving model...\n",
      "LOG: Epoch [267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4204\n",
      "LOG: Epoch [267/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3833\n",
      "    Batch [2/2], Val Loss: 0.0683\n",
      "Epoch [267/2000], Avg Train Loss: 0.4204, Avg Val Loss: 0.2258\n",
      "\n",
      "Validation loss improved from 0.2259 to 0.2258. Saving model...\n",
      "LOG: Epoch [268/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4192\n",
      "LOG: Epoch [268/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3831\n",
      "    Batch [2/2], Val Loss: 0.0683\n",
      "Epoch [268/2000], Avg Train Loss: 0.4192, Avg Val Loss: 0.2257\n",
      "\n",
      "Validation loss improved from 0.2258 to 0.2257. Saving model...\n",
      "LOG: Epoch [269/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4167\n",
      "LOG: Epoch [269/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3830\n",
      "    Batch [2/2], Val Loss: 0.0682\n",
      "Epoch [269/2000], Avg Train Loss: 0.4167, Avg Val Loss: 0.2256\n",
      "\n",
      "Validation loss improved from 0.2257 to 0.2256. Saving model...\n",
      "LOG: Epoch [270/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4205\n",
      "LOG: Epoch [270/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3829\n",
      "    Batch [2/2], Val Loss: 0.0682\n",
      "Epoch [270/2000], Avg Train Loss: 0.4205, Avg Val Loss: 0.2255\n",
      "\n",
      "Validation loss improved from 0.2256 to 0.2255. Saving model...\n",
      "LOG: Epoch [271/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4194\n",
      "LOG: Epoch [271/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3828\n",
      "    Batch [2/2], Val Loss: 0.0682\n",
      "Epoch [271/2000], Avg Train Loss: 0.4194, Avg Val Loss: 0.2255\n",
      "\n",
      "Validation loss improved from 0.2255 to 0.2255. Saving model...\n",
      "LOG: Epoch [272/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4167\n",
      "LOG: Epoch [272/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3826\n",
      "    Batch [2/2], Val Loss: 0.0682\n",
      "Epoch [272/2000], Avg Train Loss: 0.4167, Avg Val Loss: 0.2254\n",
      "\n",
      "Validation loss improved from 0.2255 to 0.2254. Saving model...\n",
      "LOG: Epoch [273/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4187\n",
      "LOG: Epoch [273/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3825\n",
      "    Batch [2/2], Val Loss: 0.0682\n",
      "Epoch [273/2000], Avg Train Loss: 0.4187, Avg Val Loss: 0.2254\n",
      "\n",
      "Validation loss improved from 0.2254 to 0.2254. Saving model...\n",
      "LOG: Epoch [274/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4179\n",
      "LOG: Epoch [274/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3823\n",
      "    Batch [2/2], Val Loss: 0.0682\n",
      "Epoch [274/2000], Avg Train Loss: 0.4179, Avg Val Loss: 0.2253\n",
      "\n",
      "Validation loss improved from 0.2254 to 0.2253. Saving model...\n",
      "LOG: Epoch [275/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4153\n",
      "LOG: Epoch [275/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3822\n",
      "    Batch [2/2], Val Loss: 0.0682\n",
      "Epoch [275/2000], Avg Train Loss: 0.4153, Avg Val Loss: 0.2252\n",
      "\n",
      "Validation loss improved from 0.2253 to 0.2252. Saving model...\n",
      "LOG: Epoch [276/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4163\n",
      "LOG: Epoch [276/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3821\n",
      "    Batch [2/2], Val Loss: 0.0682\n",
      "Epoch [276/2000], Avg Train Loss: 0.4163, Avg Val Loss: 0.2252\n",
      "\n",
      "Validation loss improved from 0.2252 to 0.2252. Saving model...\n",
      "LOG: Epoch [277/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4143\n",
      "LOG: Epoch [277/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3820\n",
      "    Batch [2/2], Val Loss: 0.0682\n",
      "Epoch [277/2000], Avg Train Loss: 0.4143, Avg Val Loss: 0.2251\n",
      "\n",
      "Validation loss improved from 0.2252 to 0.2251. Saving model...\n",
      "LOG: Epoch [278/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4200\n",
      "LOG: Epoch [278/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3819\n",
      "    Batch [2/2], Val Loss: 0.0682\n",
      "Epoch [278/2000], Avg Train Loss: 0.4200, Avg Val Loss: 0.2250\n",
      "\n",
      "Validation loss improved from 0.2251 to 0.2250. Saving model...\n",
      "LOG: Epoch [279/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4165\n",
      "LOG: Epoch [279/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3817\n",
      "    Batch [2/2], Val Loss: 0.0682\n",
      "Epoch [279/2000], Avg Train Loss: 0.4165, Avg Val Loss: 0.2250\n",
      "\n",
      "Validation loss improved from 0.2250 to 0.2250. Saving model...\n",
      "LOG: Epoch [280/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4199\n",
      "LOG: Epoch [280/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3816\n",
      "    Batch [2/2], Val Loss: 0.0682\n",
      "Epoch [280/2000], Avg Train Loss: 0.4199, Avg Val Loss: 0.2249\n",
      "\n",
      "Validation loss improved from 0.2250 to 0.2249. Saving model...\n",
      "LOG: Epoch [281/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4186\n",
      "LOG: Epoch [281/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3815\n",
      "    Batch [2/2], Val Loss: 0.0683\n",
      "Epoch [281/2000], Avg Train Loss: 0.4186, Avg Val Loss: 0.2249\n",
      "\n",
      "Validation loss improved from 0.2249 to 0.2249. Saving model...\n",
      "LOG: Epoch [282/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4164\n",
      "LOG: Epoch [282/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3814\n",
      "    Batch [2/2], Val Loss: 0.0682\n",
      "Epoch [282/2000], Avg Train Loss: 0.4164, Avg Val Loss: 0.2248\n",
      "\n",
      "Validation loss improved from 0.2249 to 0.2248. Saving model...\n",
      "LOG: Epoch [283/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4189\n",
      "LOG: Epoch [283/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3813\n",
      "    Batch [2/2], Val Loss: 0.0683\n",
      "Epoch [283/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2248\n",
      "\n",
      "Validation loss improved from 0.2248 to 0.2248. Saving model...\n",
      "LOG: Epoch [284/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4209\n",
      "LOG: Epoch [284/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3812\n",
      "    Batch [2/2], Val Loss: 0.0683\n",
      "Epoch [284/2000], Avg Train Loss: 0.4209, Avg Val Loss: 0.2247\n",
      "\n",
      "Validation loss improved from 0.2248 to 0.2247. Saving model...\n",
      "LOG: Epoch [285/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4213\n",
      "LOG: Epoch [285/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3810\n",
      "    Batch [2/2], Val Loss: 0.0683\n",
      "Epoch [285/2000], Avg Train Loss: 0.4213, Avg Val Loss: 0.2247\n",
      "\n",
      "Validation loss improved from 0.2247 to 0.2247. Saving model...\n",
      "LOG: Epoch [286/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4186\n",
      "LOG: Epoch [286/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3809\n",
      "    Batch [2/2], Val Loss: 0.0684\n",
      "Epoch [286/2000], Avg Train Loss: 0.4186, Avg Val Loss: 0.2247\n",
      "\n",
      "Validation loss improved from 0.2247 to 0.2247. Saving model...\n",
      "LOG: Epoch [287/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4161\n",
      "LOG: Epoch [287/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3809\n",
      "    Batch [2/2], Val Loss: 0.0684\n",
      "Epoch [287/2000], Avg Train Loss: 0.4161, Avg Val Loss: 0.2246\n",
      "\n",
      "Validation loss improved from 0.2247 to 0.2246. Saving model...\n",
      "LOG: Epoch [288/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4189\n",
      "LOG: Epoch [288/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3809\n",
      "    Batch [2/2], Val Loss: 0.0684\n",
      "Epoch [288/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2246\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [289/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4171\n",
      "LOG: Epoch [289/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3809\n",
      "    Batch [2/2], Val Loss: 0.0684\n",
      "Epoch [289/2000], Avg Train Loss: 0.4171, Avg Val Loss: 0.2246\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [290/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4178\n",
      "LOG: Epoch [290/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3809\n",
      "    Batch [2/2], Val Loss: 0.0684\n",
      "Epoch [290/2000], Avg Train Loss: 0.4178, Avg Val Loss: 0.2246\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [291/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4214\n",
      "LOG: Epoch [291/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3808\n",
      "    Batch [2/2], Val Loss: 0.0684\n",
      "Epoch [291/2000], Avg Train Loss: 0.4214, Avg Val Loss: 0.2246\n",
      "\n",
      "Validation loss improved from 0.2246 to 0.2246. Saving model...\n",
      "LOG: Epoch [292/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4130\n",
      "LOG: Epoch [292/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3808\n",
      "    Batch [2/2], Val Loss: 0.0684\n",
      "Epoch [292/2000], Avg Train Loss: 0.4130, Avg Val Loss: 0.2246\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [293/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4185\n",
      "LOG: Epoch [293/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3808\n",
      "    Batch [2/2], Val Loss: 0.0684\n",
      "Epoch [293/2000], Avg Train Loss: 0.4185, Avg Val Loss: 0.2246\n",
      "\n",
      "Validation loss improved from 0.2246 to 0.2246. Saving model...\n",
      "LOG: Epoch [294/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4218\n",
      "LOG: Epoch [294/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.0684\n",
      "Epoch [294/2000], Avg Train Loss: 0.4218, Avg Val Loss: 0.2245\n",
      "\n",
      "Validation loss improved from 0.2246 to 0.2245. Saving model...\n",
      "LOG: Epoch [295/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4162\n",
      "LOG: Epoch [295/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.0684\n",
      "Epoch [295/2000], Avg Train Loss: 0.4162, Avg Val Loss: 0.2245\n",
      "\n",
      "Validation loss improved from 0.2245 to 0.2245. Saving model...\n",
      "LOG: Epoch [296/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4130\n",
      "LOG: Epoch [296/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.0683\n",
      "Epoch [296/2000], Avg Train Loss: 0.4130, Avg Val Loss: 0.2245\n",
      "\n",
      "Validation loss improved from 0.2245 to 0.2245. Saving model...\n",
      "LOG: Epoch [297/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4209\n",
      "LOG: Epoch [297/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.0683\n",
      "Epoch [297/2000], Avg Train Loss: 0.4209, Avg Val Loss: 0.2245\n",
      "\n",
      "Validation loss improved from 0.2245 to 0.2245. Saving model...\n",
      "LOG: Epoch [298/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4174\n",
      "LOG: Epoch [298/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.0683\n",
      "Epoch [298/2000], Avg Train Loss: 0.4174, Avg Val Loss: 0.2245\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [299/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4141\n",
      "LOG: Epoch [299/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.0683\n",
      "Epoch [299/2000], Avg Train Loss: 0.4141, Avg Val Loss: 0.2245\n",
      "\n",
      "Validation loss improved from 0.2245 to 0.2245. Saving model...\n",
      "LOG: Epoch [300/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4185\n",
      "LOG: Epoch [300/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.0683\n",
      "Epoch [300/2000], Avg Train Loss: 0.4185, Avg Val Loss: 0.2245\n",
      "\n",
      "Validation loss improved from 0.2245 to 0.2245. Saving model...\n",
      "LOG: Epoch [301/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4134\n",
      "LOG: Epoch [301/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.0683\n",
      "Epoch [301/2000], Avg Train Loss: 0.4134, Avg Val Loss: 0.2245\n",
      "\n",
      "Validation loss improved from 0.2245 to 0.2245. Saving model...\n",
      "LOG: Epoch [302/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4164\n",
      "LOG: Epoch [302/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.0682\n",
      "Epoch [302/2000], Avg Train Loss: 0.4164, Avg Val Loss: 0.2245\n",
      "\n",
      "Validation loss improved from 0.2245 to 0.2245. Saving model...\n",
      "LOG: Epoch [303/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4166\n",
      "LOG: Epoch [303/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.0682\n",
      "Epoch [303/2000], Avg Train Loss: 0.4166, Avg Val Loss: 0.2245\n",
      "\n",
      "Validation loss improved from 0.2245 to 0.2245. Saving model...\n",
      "LOG: Epoch [304/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4160\n",
      "LOG: Epoch [304/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.0681\n",
      "Epoch [304/2000], Avg Train Loss: 0.4160, Avg Val Loss: 0.2244\n",
      "\n",
      "Validation loss improved from 0.2245 to 0.2244. Saving model...\n",
      "LOG: Epoch [305/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4153\n",
      "LOG: Epoch [305/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3806\n",
      "    Batch [2/2], Val Loss: 0.0681\n",
      "Epoch [305/2000], Avg Train Loss: 0.4153, Avg Val Loss: 0.2244\n",
      "\n",
      "Validation loss improved from 0.2244 to 0.2244. Saving model...\n",
      "LOG: Epoch [306/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4165\n",
      "LOG: Epoch [306/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3805\n",
      "    Batch [2/2], Val Loss: 0.0680\n",
      "Epoch [306/2000], Avg Train Loss: 0.4165, Avg Val Loss: 0.2243\n",
      "\n",
      "Validation loss improved from 0.2244 to 0.2243. Saving model...\n",
      "LOG: Epoch [307/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4153\n",
      "LOG: Epoch [307/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3804\n",
      "    Batch [2/2], Val Loss: 0.0680\n",
      "Epoch [307/2000], Avg Train Loss: 0.4153, Avg Val Loss: 0.2242\n",
      "\n",
      "Validation loss improved from 0.2243 to 0.2242. Saving model...\n",
      "LOG: Epoch [308/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4158\n",
      "LOG: Epoch [308/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3804\n",
      "    Batch [2/2], Val Loss: 0.0679\n",
      "Epoch [308/2000], Avg Train Loss: 0.4158, Avg Val Loss: 0.2241\n",
      "\n",
      "Validation loss improved from 0.2242 to 0.2241. Saving model...\n",
      "LOG: Epoch [309/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4164\n",
      "LOG: Epoch [309/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3803\n",
      "    Batch [2/2], Val Loss: 0.0679\n",
      "Epoch [309/2000], Avg Train Loss: 0.4164, Avg Val Loss: 0.2241\n",
      "\n",
      "Validation loss improved from 0.2241 to 0.2241. Saving model...\n",
      "LOG: Epoch [310/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4158\n",
      "LOG: Epoch [310/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3802\n",
      "    Batch [2/2], Val Loss: 0.0678\n",
      "Epoch [310/2000], Avg Train Loss: 0.4158, Avg Val Loss: 0.2240\n",
      "\n",
      "Validation loss improved from 0.2241 to 0.2240. Saving model...\n",
      "LOG: Epoch [311/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4140\n",
      "LOG: Epoch [311/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3802\n",
      "    Batch [2/2], Val Loss: 0.0678\n",
      "Epoch [311/2000], Avg Train Loss: 0.4140, Avg Val Loss: 0.2240\n",
      "\n",
      "Validation loss improved from 0.2240 to 0.2240. Saving model...\n",
      "LOG: Epoch [312/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4125\n",
      "LOG: Epoch [312/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3802\n",
      "    Batch [2/2], Val Loss: 0.0678\n",
      "Epoch [312/2000], Avg Train Loss: 0.4125, Avg Val Loss: 0.2240\n",
      "\n",
      "Validation loss improved from 0.2240 to 0.2240. Saving model...\n",
      "LOG: Epoch [313/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4167\n",
      "LOG: Epoch [313/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3801\n",
      "    Batch [2/2], Val Loss: 0.0677\n",
      "Epoch [313/2000], Avg Train Loss: 0.4167, Avg Val Loss: 0.2239\n",
      "\n",
      "Validation loss improved from 0.2240 to 0.2239. Saving model...\n",
      "LOG: Epoch [314/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4193\n",
      "LOG: Epoch [314/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3800\n",
      "    Batch [2/2], Val Loss: 0.0677\n",
      "Epoch [314/2000], Avg Train Loss: 0.4193, Avg Val Loss: 0.2238\n",
      "\n",
      "Validation loss improved from 0.2239 to 0.2238. Saving model...\n",
      "LOG: Epoch [315/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4114\n",
      "LOG: Epoch [315/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3799\n",
      "    Batch [2/2], Val Loss: 0.0676\n",
      "Epoch [315/2000], Avg Train Loss: 0.4114, Avg Val Loss: 0.2238\n",
      "\n",
      "Validation loss improved from 0.2238 to 0.2238. Saving model...\n",
      "LOG: Epoch [316/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4133\n",
      "LOG: Epoch [316/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3798\n",
      "    Batch [2/2], Val Loss: 0.0676\n",
      "Epoch [316/2000], Avg Train Loss: 0.4133, Avg Val Loss: 0.2237\n",
      "\n",
      "Validation loss improved from 0.2238 to 0.2237. Saving model...\n",
      "LOG: Epoch [317/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4160\n",
      "LOG: Epoch [317/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3798\n",
      "    Batch [2/2], Val Loss: 0.0676\n",
      "Epoch [317/2000], Avg Train Loss: 0.4160, Avg Val Loss: 0.2237\n",
      "\n",
      "Validation loss improved from 0.2237 to 0.2237. Saving model...\n",
      "LOG: Epoch [318/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4125\n",
      "LOG: Epoch [318/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3798\n",
      "    Batch [2/2], Val Loss: 0.0676\n",
      "Epoch [318/2000], Avg Train Loss: 0.4125, Avg Val Loss: 0.2237\n",
      "\n",
      "Validation loss improved from 0.2237 to 0.2237. Saving model...\n",
      "LOG: Epoch [319/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4150\n",
      "LOG: Epoch [319/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3798\n",
      "    Batch [2/2], Val Loss: 0.0675\n",
      "Epoch [319/2000], Avg Train Loss: 0.4150, Avg Val Loss: 0.2236\n",
      "\n",
      "Validation loss improved from 0.2237 to 0.2236. Saving model...\n",
      "LOG: Epoch [320/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4116\n",
      "LOG: Epoch [320/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3797\n",
      "    Batch [2/2], Val Loss: 0.0674\n",
      "Epoch [320/2000], Avg Train Loss: 0.4116, Avg Val Loss: 0.2236\n",
      "\n",
      "Validation loss improved from 0.2236 to 0.2236. Saving model...\n",
      "LOG: Epoch [321/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4083\n",
      "LOG: Epoch [321/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3798\n",
      "    Batch [2/2], Val Loss: 0.0674\n",
      "Epoch [321/2000], Avg Train Loss: 0.4083, Avg Val Loss: 0.2236\n",
      "\n",
      "Validation loss improved from 0.2236 to 0.2236. Saving model...\n",
      "LOG: Epoch [322/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4153\n",
      "LOG: Epoch [322/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3798\n",
      "    Batch [2/2], Val Loss: 0.0673\n",
      "Epoch [322/2000], Avg Train Loss: 0.4153, Avg Val Loss: 0.2235\n",
      "\n",
      "Validation loss improved from 0.2236 to 0.2235. Saving model...\n",
      "LOG: Epoch [323/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4152\n",
      "LOG: Epoch [323/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3798\n",
      "    Batch [2/2], Val Loss: 0.0672\n",
      "Epoch [323/2000], Avg Train Loss: 0.4152, Avg Val Loss: 0.2235\n",
      "\n",
      "Validation loss improved from 0.2235 to 0.2235. Saving model...\n",
      "LOG: Epoch [324/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4158\n",
      "LOG: Epoch [324/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3799\n",
      "    Batch [2/2], Val Loss: 0.0672\n",
      "Epoch [324/2000], Avg Train Loss: 0.4158, Avg Val Loss: 0.2235\n",
      "\n",
      "Validation loss improved from 0.2235 to 0.2235. Saving model...\n",
      "LOG: Epoch [325/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4154\n",
      "LOG: Epoch [325/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3798\n",
      "    Batch [2/2], Val Loss: 0.0671\n",
      "Epoch [325/2000], Avg Train Loss: 0.4154, Avg Val Loss: 0.2235\n",
      "\n",
      "Validation loss improved from 0.2235 to 0.2235. Saving model...\n",
      "LOG: Epoch [326/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4163\n",
      "LOG: Epoch [326/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3798\n",
      "    Batch [2/2], Val Loss: 0.0670\n",
      "Epoch [326/2000], Avg Train Loss: 0.4163, Avg Val Loss: 0.2234\n",
      "\n",
      "Validation loss improved from 0.2235 to 0.2234. Saving model...\n",
      "LOG: Epoch [327/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4174\n",
      "LOG: Epoch [327/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3798\n",
      "    Batch [2/2], Val Loss: 0.0670\n",
      "Epoch [327/2000], Avg Train Loss: 0.4174, Avg Val Loss: 0.2234\n",
      "\n",
      "Validation loss improved from 0.2234 to 0.2234. Saving model...\n",
      "LOG: Epoch [328/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4162\n",
      "LOG: Epoch [328/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3799\n",
      "    Batch [2/2], Val Loss: 0.0670\n",
      "Epoch [328/2000], Avg Train Loss: 0.4162, Avg Val Loss: 0.2234\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [329/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4107\n",
      "LOG: Epoch [329/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3799\n",
      "    Batch [2/2], Val Loss: 0.0670\n",
      "Epoch [329/2000], Avg Train Loss: 0.4107, Avg Val Loss: 0.2234\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [330/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4134\n",
      "LOG: Epoch [330/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3799\n",
      "    Batch [2/2], Val Loss: 0.0669\n",
      "Epoch [330/2000], Avg Train Loss: 0.4134, Avg Val Loss: 0.2234\n",
      "\n",
      "Validation loss improved from 0.2234 to 0.2234. Saving model...\n",
      "LOG: Epoch [331/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4143\n",
      "LOG: Epoch [331/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3800\n",
      "    Batch [2/2], Val Loss: 0.0668\n",
      "Epoch [331/2000], Avg Train Loss: 0.4143, Avg Val Loss: 0.2234\n",
      "\n",
      "Validation loss improved from 0.2234 to 0.2234. Saving model...\n",
      "LOG: Epoch [332/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4102\n",
      "LOG: Epoch [332/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3799\n",
      "    Batch [2/2], Val Loss: 0.0668\n",
      "Epoch [332/2000], Avg Train Loss: 0.4102, Avg Val Loss: 0.2234\n",
      "\n",
      "Validation loss improved from 0.2234 to 0.2234. Saving model...\n",
      "LOG: Epoch [333/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4132\n",
      "LOG: Epoch [333/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3800\n",
      "    Batch [2/2], Val Loss: 0.0668\n",
      "Epoch [333/2000], Avg Train Loss: 0.4132, Avg Val Loss: 0.2234\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [334/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4161\n",
      "LOG: Epoch [334/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3800\n",
      "    Batch [2/2], Val Loss: 0.0668\n",
      "Epoch [334/2000], Avg Train Loss: 0.4161, Avg Val Loss: 0.2234\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [335/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4123\n",
      "LOG: Epoch [335/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3800\n",
      "    Batch [2/2], Val Loss: 0.0668\n",
      "Epoch [335/2000], Avg Train Loss: 0.4123, Avg Val Loss: 0.2234\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [336/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4156\n",
      "LOG: Epoch [336/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3799\n",
      "    Batch [2/2], Val Loss: 0.0668\n",
      "Epoch [336/2000], Avg Train Loss: 0.4156, Avg Val Loss: 0.2233\n",
      "\n",
      "Validation loss improved from 0.2234 to 0.2233. Saving model...\n",
      "LOG: Epoch [337/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4148\n",
      "LOG: Epoch [337/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3799\n",
      "    Batch [2/2], Val Loss: 0.0668\n",
      "Epoch [337/2000], Avg Train Loss: 0.4148, Avg Val Loss: 0.2233\n",
      "\n",
      "Validation loss improved from 0.2233 to 0.2233. Saving model...\n",
      "LOG: Epoch [338/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4130\n",
      "LOG: Epoch [338/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3798\n",
      "    Batch [2/2], Val Loss: 0.0668\n",
      "Epoch [338/2000], Avg Train Loss: 0.4130, Avg Val Loss: 0.2233\n",
      "\n",
      "Validation loss improved from 0.2233 to 0.2233. Saving model...\n",
      "LOG: Epoch [339/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4141\n",
      "LOG: Epoch [339/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3797\n",
      "    Batch [2/2], Val Loss: 0.0668\n",
      "Epoch [339/2000], Avg Train Loss: 0.4141, Avg Val Loss: 0.2232\n",
      "\n",
      "Validation loss improved from 0.2233 to 0.2232. Saving model...\n",
      "LOG: Epoch [340/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4169\n",
      "LOG: Epoch [340/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3796\n",
      "    Batch [2/2], Val Loss: 0.0668\n",
      "Epoch [340/2000], Avg Train Loss: 0.4169, Avg Val Loss: 0.2232\n",
      "\n",
      "Validation loss improved from 0.2232 to 0.2232. Saving model...\n",
      "LOG: Epoch [341/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4143\n",
      "LOG: Epoch [341/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3795\n",
      "    Batch [2/2], Val Loss: 0.0668\n",
      "Epoch [341/2000], Avg Train Loss: 0.4143, Avg Val Loss: 0.2231\n",
      "\n",
      "Validation loss improved from 0.2232 to 0.2231. Saving model...\n",
      "LOG: Epoch [342/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4149\n",
      "LOG: Epoch [342/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3793\n",
      "    Batch [2/2], Val Loss: 0.0667\n",
      "Epoch [342/2000], Avg Train Loss: 0.4149, Avg Val Loss: 0.2230\n",
      "\n",
      "Validation loss improved from 0.2231 to 0.2230. Saving model...\n",
      "LOG: Epoch [343/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4163\n",
      "LOG: Epoch [343/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3792\n",
      "    Batch [2/2], Val Loss: 0.0667\n",
      "Epoch [343/2000], Avg Train Loss: 0.4163, Avg Val Loss: 0.2230\n",
      "\n",
      "Validation loss improved from 0.2230 to 0.2230. Saving model...\n",
      "LOG: Epoch [344/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4141\n",
      "LOG: Epoch [344/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3791\n",
      "    Batch [2/2], Val Loss: 0.0667\n",
      "Epoch [344/2000], Avg Train Loss: 0.4141, Avg Val Loss: 0.2229\n",
      "\n",
      "Validation loss improved from 0.2230 to 0.2229. Saving model...\n",
      "LOG: Epoch [345/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4126\n",
      "LOG: Epoch [345/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3789\n",
      "    Batch [2/2], Val Loss: 0.0667\n",
      "Epoch [345/2000], Avg Train Loss: 0.4126, Avg Val Loss: 0.2228\n",
      "\n",
      "Validation loss improved from 0.2229 to 0.2228. Saving model...\n",
      "LOG: Epoch [346/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4165\n",
      "LOG: Epoch [346/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3788\n",
      "    Batch [2/2], Val Loss: 0.0666\n",
      "Epoch [346/2000], Avg Train Loss: 0.4165, Avg Val Loss: 0.2227\n",
      "\n",
      "Validation loss improved from 0.2228 to 0.2227. Saving model...\n",
      "LOG: Epoch [347/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4124\n",
      "LOG: Epoch [347/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3787\n",
      "    Batch [2/2], Val Loss: 0.0666\n",
      "Epoch [347/2000], Avg Train Loss: 0.4124, Avg Val Loss: 0.2226\n",
      "\n",
      "Validation loss improved from 0.2227 to 0.2226. Saving model...\n",
      "LOG: Epoch [348/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4186\n",
      "LOG: Epoch [348/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3786\n",
      "    Batch [2/2], Val Loss: 0.0665\n",
      "Epoch [348/2000], Avg Train Loss: 0.4186, Avg Val Loss: 0.2225\n",
      "\n",
      "Validation loss improved from 0.2226 to 0.2225. Saving model...\n",
      "LOG: Epoch [349/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4148\n",
      "LOG: Epoch [349/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3785\n",
      "    Batch [2/2], Val Loss: 0.0664\n",
      "Epoch [349/2000], Avg Train Loss: 0.4148, Avg Val Loss: 0.2224\n",
      "\n",
      "Validation loss improved from 0.2225 to 0.2224. Saving model...\n",
      "LOG: Epoch [350/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4140\n",
      "LOG: Epoch [350/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3784\n",
      "    Batch [2/2], Val Loss: 0.0663\n",
      "Epoch [350/2000], Avg Train Loss: 0.4140, Avg Val Loss: 0.2223\n",
      "\n",
      "Validation loss improved from 0.2224 to 0.2223. Saving model...\n",
      "LOG: Epoch [351/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4180\n",
      "LOG: Epoch [351/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3782\n",
      "    Batch [2/2], Val Loss: 0.0663\n",
      "Epoch [351/2000], Avg Train Loss: 0.4180, Avg Val Loss: 0.2222\n",
      "\n",
      "Validation loss improved from 0.2223 to 0.2222. Saving model...\n",
      "LOG: Epoch [352/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4119\n",
      "LOG: Epoch [352/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3781\n",
      "    Batch [2/2], Val Loss: 0.0662\n",
      "Epoch [352/2000], Avg Train Loss: 0.4119, Avg Val Loss: 0.2222\n",
      "\n",
      "Validation loss improved from 0.2222 to 0.2222. Saving model...\n",
      "LOG: Epoch [353/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4125\n",
      "LOG: Epoch [353/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3780\n",
      "    Batch [2/2], Val Loss: 0.0662\n",
      "Epoch [353/2000], Avg Train Loss: 0.4125, Avg Val Loss: 0.2221\n",
      "\n",
      "Validation loss improved from 0.2222 to 0.2221. Saving model...\n",
      "LOG: Epoch [354/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4125\n",
      "LOG: Epoch [354/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.0662\n",
      "Epoch [354/2000], Avg Train Loss: 0.4125, Avg Val Loss: 0.2221\n",
      "\n",
      "Validation loss improved from 0.2221 to 0.2221. Saving model...\n",
      "LOG: Epoch [355/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4117\n",
      "LOG: Epoch [355/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.0662\n",
      "Epoch [355/2000], Avg Train Loss: 0.4117, Avg Val Loss: 0.2221\n",
      "\n",
      "Validation loss improved from 0.2221 to 0.2221. Saving model...\n",
      "LOG: Epoch [356/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4098\n",
      "LOG: Epoch [356/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.0662\n",
      "Epoch [356/2000], Avg Train Loss: 0.4098, Avg Val Loss: 0.2220\n",
      "\n",
      "Validation loss improved from 0.2221 to 0.2220. Saving model...\n",
      "LOG: Epoch [357/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4142\n",
      "LOG: Epoch [357/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.0662\n",
      "Epoch [357/2000], Avg Train Loss: 0.4142, Avg Val Loss: 0.2220\n",
      "\n",
      "Validation loss improved from 0.2220 to 0.2220. Saving model...\n",
      "LOG: Epoch [358/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4157\n",
      "LOG: Epoch [358/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3778\n",
      "    Batch [2/2], Val Loss: 0.0662\n",
      "Epoch [358/2000], Avg Train Loss: 0.4157, Avg Val Loss: 0.2220\n",
      "\n",
      "Validation loss improved from 0.2220 to 0.2220. Saving model...\n",
      "LOG: Epoch [359/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4131\n",
      "LOG: Epoch [359/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3778\n",
      "    Batch [2/2], Val Loss: 0.0662\n",
      "Epoch [359/2000], Avg Train Loss: 0.4131, Avg Val Loss: 0.2220\n",
      "\n",
      "Validation loss improved from 0.2220 to 0.2220. Saving model...\n",
      "LOG: Epoch [360/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4130\n",
      "LOG: Epoch [360/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3778\n",
      "    Batch [2/2], Val Loss: 0.0662\n",
      "Epoch [360/2000], Avg Train Loss: 0.4130, Avg Val Loss: 0.2220\n",
      "\n",
      "Validation loss improved from 0.2220 to 0.2220. Saving model...\n",
      "LOG: Epoch [361/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4150\n",
      "LOG: Epoch [361/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3777\n",
      "    Batch [2/2], Val Loss: 0.0662\n",
      "Epoch [361/2000], Avg Train Loss: 0.4150, Avg Val Loss: 0.2220\n",
      "\n",
      "Validation loss improved from 0.2220 to 0.2220. Saving model...\n",
      "LOG: Epoch [362/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4147\n",
      "LOG: Epoch [362/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3778\n",
      "    Batch [2/2], Val Loss: 0.0661\n",
      "Epoch [362/2000], Avg Train Loss: 0.4147, Avg Val Loss: 0.2220\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [363/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4131\n",
      "LOG: Epoch [363/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.0661\n",
      "Epoch [363/2000], Avg Train Loss: 0.4131, Avg Val Loss: 0.2220\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [364/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4150\n",
      "LOG: Epoch [364/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.0660\n",
      "Epoch [364/2000], Avg Train Loss: 0.4150, Avg Val Loss: 0.2219\n",
      "\n",
      "Validation loss improved from 0.2220 to 0.2219. Saving model...\n",
      "LOG: Epoch [365/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4111\n",
      "LOG: Epoch [365/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3778\n",
      "    Batch [2/2], Val Loss: 0.0660\n",
      "Epoch [365/2000], Avg Train Loss: 0.4111, Avg Val Loss: 0.2219\n",
      "\n",
      "Validation loss improved from 0.2219 to 0.2219. Saving model...\n",
      "LOG: Epoch [366/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4157\n",
      "LOG: Epoch [366/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3778\n",
      "    Batch [2/2], Val Loss: 0.0660\n",
      "Epoch [366/2000], Avg Train Loss: 0.4157, Avg Val Loss: 0.2219\n",
      "\n",
      "Validation loss improved from 0.2219 to 0.2219. Saving model...\n",
      "LOG: Epoch [367/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4132\n",
      "LOG: Epoch [367/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3778\n",
      "    Batch [2/2], Val Loss: 0.0660\n",
      "Epoch [367/2000], Avg Train Loss: 0.4132, Avg Val Loss: 0.2219\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [368/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4137\n",
      "LOG: Epoch [368/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.0660\n",
      "Epoch [368/2000], Avg Train Loss: 0.4137, Avg Val Loss: 0.2219\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [369/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4194\n",
      "LOG: Epoch [369/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.0660\n",
      "Epoch [369/2000], Avg Train Loss: 0.4194, Avg Val Loss: 0.2219\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [370/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4136\n",
      "LOG: Epoch [370/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.0660\n",
      "Epoch [370/2000], Avg Train Loss: 0.4136, Avg Val Loss: 0.2219\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [371/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4120\n",
      "LOG: Epoch [371/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.0660\n",
      "Epoch [371/2000], Avg Train Loss: 0.4120, Avg Val Loss: 0.2220\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [372/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4150\n",
      "LOG: Epoch [372/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.0660\n",
      "Epoch [372/2000], Avg Train Loss: 0.4150, Avg Val Loss: 0.2220\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [373/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4131\n",
      "LOG: Epoch [373/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.0660\n",
      "Epoch [373/2000], Avg Train Loss: 0.4131, Avg Val Loss: 0.2219\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [374/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4133\n",
      "LOG: Epoch [374/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.0660\n",
      "Epoch [374/2000], Avg Train Loss: 0.4133, Avg Val Loss: 0.2219\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [375/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4136\n",
      "LOG: Epoch [375/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.0660\n",
      "Epoch [375/2000], Avg Train Loss: 0.4136, Avg Val Loss: 0.2219\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [376/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4143\n",
      "LOG: Epoch [376/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3779\n",
      "    Batch [2/2], Val Loss: 0.0659\n",
      "Epoch [376/2000], Avg Train Loss: 0.4143, Avg Val Loss: 0.2219\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [377/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4143\n",
      "LOG: Epoch [377/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3778\n",
      "    Batch [2/2], Val Loss: 0.0659\n",
      "Epoch [377/2000], Avg Train Loss: 0.4143, Avg Val Loss: 0.2219\n",
      "\n",
      "Validation loss improved from 0.2219 to 0.2219. Saving model...\n",
      "LOG: Epoch [378/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4115\n",
      "LOG: Epoch [378/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3777\n",
      "    Batch [2/2], Val Loss: 0.0659\n",
      "Epoch [378/2000], Avg Train Loss: 0.4115, Avg Val Loss: 0.2218\n",
      "\n",
      "Validation loss improved from 0.2219 to 0.2218. Saving model...\n",
      "LOG: Epoch [379/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4131\n",
      "LOG: Epoch [379/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3776\n",
      "    Batch [2/2], Val Loss: 0.0659\n",
      "Epoch [379/2000], Avg Train Loss: 0.4131, Avg Val Loss: 0.2217\n",
      "\n",
      "Validation loss improved from 0.2218 to 0.2217. Saving model...\n",
      "LOG: Epoch [380/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4135\n",
      "LOG: Epoch [380/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3775\n",
      "    Batch [2/2], Val Loss: 0.0659\n",
      "Epoch [380/2000], Avg Train Loss: 0.4135, Avg Val Loss: 0.2217\n",
      "\n",
      "Validation loss improved from 0.2217 to 0.2217. Saving model...\n",
      "LOG: Epoch [381/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [381/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3774\n",
      "    Batch [2/2], Val Loss: 0.0659\n",
      "Epoch [381/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.2216\n",
      "\n",
      "Validation loss improved from 0.2217 to 0.2216. Saving model...\n",
      "LOG: Epoch [382/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4137\n",
      "LOG: Epoch [382/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3773\n",
      "    Batch [2/2], Val Loss: 0.0658\n",
      "Epoch [382/2000], Avg Train Loss: 0.4137, Avg Val Loss: 0.2216\n",
      "\n",
      "Validation loss improved from 0.2216 to 0.2216. Saving model...\n",
      "LOG: Epoch [383/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4166\n",
      "LOG: Epoch [383/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3772\n",
      "    Batch [2/2], Val Loss: 0.0658\n",
      "Epoch [383/2000], Avg Train Loss: 0.4166, Avg Val Loss: 0.2215\n",
      "\n",
      "Validation loss improved from 0.2216 to 0.2215. Saving model...\n",
      "LOG: Epoch [384/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4105\n",
      "LOG: Epoch [384/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3771\n",
      "    Batch [2/2], Val Loss: 0.0657\n",
      "Epoch [384/2000], Avg Train Loss: 0.4105, Avg Val Loss: 0.2214\n",
      "\n",
      "Validation loss improved from 0.2215 to 0.2214. Saving model...\n",
      "LOG: Epoch [385/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4122\n",
      "LOG: Epoch [385/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3769\n",
      "    Batch [2/2], Val Loss: 0.0657\n",
      "Epoch [385/2000], Avg Train Loss: 0.4122, Avg Val Loss: 0.2213\n",
      "\n",
      "Validation loss improved from 0.2214 to 0.2213. Saving model...\n",
      "LOG: Epoch [386/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4095\n",
      "LOG: Epoch [386/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3768\n",
      "    Batch [2/2], Val Loss: 0.0657\n",
      "Epoch [386/2000], Avg Train Loss: 0.4095, Avg Val Loss: 0.2212\n",
      "\n",
      "Validation loss improved from 0.2213 to 0.2212. Saving model...\n",
      "LOG: Epoch [387/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4103\n",
      "LOG: Epoch [387/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3767\n",
      "    Batch [2/2], Val Loss: 0.0656\n",
      "Epoch [387/2000], Avg Train Loss: 0.4103, Avg Val Loss: 0.2212\n",
      "\n",
      "Validation loss improved from 0.2212 to 0.2212. Saving model...\n",
      "LOG: Epoch [388/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4094\n",
      "LOG: Epoch [388/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3766\n",
      "    Batch [2/2], Val Loss: 0.0656\n",
      "Epoch [388/2000], Avg Train Loss: 0.4094, Avg Val Loss: 0.2211\n",
      "\n",
      "Validation loss improved from 0.2212 to 0.2211. Saving model...\n",
      "LOG: Epoch [389/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4134\n",
      "LOG: Epoch [389/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3766\n",
      "    Batch [2/2], Val Loss: 0.0655\n",
      "Epoch [389/2000], Avg Train Loss: 0.4134, Avg Val Loss: 0.2211\n",
      "\n",
      "Validation loss improved from 0.2211 to 0.2211. Saving model...\n",
      "LOG: Epoch [390/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [390/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3765\n",
      "    Batch [2/2], Val Loss: 0.0654\n",
      "Epoch [390/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2210\n",
      "\n",
      "Validation loss improved from 0.2211 to 0.2210. Saving model...\n",
      "LOG: Epoch [391/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4112\n",
      "LOG: Epoch [391/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3765\n",
      "    Batch [2/2], Val Loss: 0.0654\n",
      "Epoch [391/2000], Avg Train Loss: 0.4112, Avg Val Loss: 0.2209\n",
      "\n",
      "Validation loss improved from 0.2210 to 0.2209. Saving model...\n",
      "LOG: Epoch [392/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4095\n",
      "LOG: Epoch [392/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3765\n",
      "    Batch [2/2], Val Loss: 0.0653\n",
      "Epoch [392/2000], Avg Train Loss: 0.4095, Avg Val Loss: 0.2209\n",
      "\n",
      "Validation loss improved from 0.2209 to 0.2209. Saving model...\n",
      "LOG: Epoch [393/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4158\n",
      "LOG: Epoch [393/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3765\n",
      "    Batch [2/2], Val Loss: 0.0652\n",
      "Epoch [393/2000], Avg Train Loss: 0.4158, Avg Val Loss: 0.2208\n",
      "\n",
      "Validation loss improved from 0.2209 to 0.2208. Saving model...\n",
      "LOG: Epoch [394/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4088\n",
      "LOG: Epoch [394/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.0652\n",
      "Epoch [394/2000], Avg Train Loss: 0.4088, Avg Val Loss: 0.2208\n",
      "\n",
      "Validation loss improved from 0.2208 to 0.2208. Saving model...\n",
      "LOG: Epoch [395/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4093\n",
      "LOG: Epoch [395/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.0651\n",
      "Epoch [395/2000], Avg Train Loss: 0.4093, Avg Val Loss: 0.2207\n",
      "\n",
      "Validation loss improved from 0.2208 to 0.2207. Saving model...\n",
      "LOG: Epoch [396/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4094\n",
      "LOG: Epoch [396/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.0650\n",
      "Epoch [396/2000], Avg Train Loss: 0.4094, Avg Val Loss: 0.2207\n",
      "\n",
      "Validation loss improved from 0.2207 to 0.2207. Saving model...\n",
      "LOG: Epoch [397/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4125\n",
      "LOG: Epoch [397/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.0650\n",
      "Epoch [397/2000], Avg Train Loss: 0.4125, Avg Val Loss: 0.2207\n",
      "\n",
      "Validation loss improved from 0.2207 to 0.2207. Saving model...\n",
      "LOG: Epoch [398/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4132\n",
      "LOG: Epoch [398/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.0649\n",
      "Epoch [398/2000], Avg Train Loss: 0.4132, Avg Val Loss: 0.2206\n",
      "\n",
      "Validation loss improved from 0.2207 to 0.2206. Saving model...\n",
      "LOG: Epoch [399/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4121\n",
      "LOG: Epoch [399/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3763\n",
      "    Batch [2/2], Val Loss: 0.0648\n",
      "Epoch [399/2000], Avg Train Loss: 0.4121, Avg Val Loss: 0.2206\n",
      "\n",
      "Validation loss improved from 0.2206 to 0.2206. Saving model...\n",
      "LOG: Epoch [400/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4112\n",
      "LOG: Epoch [400/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3762\n",
      "    Batch [2/2], Val Loss: 0.0648\n",
      "Epoch [400/2000], Avg Train Loss: 0.4112, Avg Val Loss: 0.2205\n",
      "\n",
      "Validation loss improved from 0.2206 to 0.2205. Saving model...\n",
      "LOG: Epoch [401/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4079\n",
      "LOG: Epoch [401/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.0648\n",
      "Epoch [401/2000], Avg Train Loss: 0.4079, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2205 to 0.2204. Saving model...\n",
      "LOG: Epoch [402/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4117\n",
      "LOG: Epoch [402/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3760\n",
      "    Batch [2/2], Val Loss: 0.0647\n",
      "Epoch [402/2000], Avg Train Loss: 0.4117, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2204. Saving model...\n",
      "LOG: Epoch [403/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4125\n",
      "LOG: Epoch [403/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3759\n",
      "    Batch [2/2], Val Loss: 0.0647\n",
      "Epoch [403/2000], Avg Train Loss: 0.4125, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2203. Saving model...\n",
      "LOG: Epoch [404/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4094\n",
      "LOG: Epoch [404/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3759\n",
      "    Batch [2/2], Val Loss: 0.0647\n",
      "Epoch [404/2000], Avg Train Loss: 0.4094, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [405/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4095\n",
      "LOG: Epoch [405/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3759\n",
      "    Batch [2/2], Val Loss: 0.0647\n",
      "Epoch [405/2000], Avg Train Loss: 0.4095, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [406/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4079\n",
      "LOG: Epoch [406/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3759\n",
      "    Batch [2/2], Val Loss: 0.0647\n",
      "Epoch [406/2000], Avg Train Loss: 0.4079, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [407/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4126\n",
      "LOG: Epoch [407/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3760\n",
      "    Batch [2/2], Val Loss: 0.0647\n",
      "Epoch [407/2000], Avg Train Loss: 0.4126, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [408/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4109\n",
      "LOG: Epoch [408/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3760\n",
      "    Batch [2/2], Val Loss: 0.0647\n",
      "Epoch [408/2000], Avg Train Loss: 0.4109, Avg Val Loss: 0.2204\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [409/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4096\n",
      "LOG: Epoch [409/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.0647\n",
      "Epoch [409/2000], Avg Train Loss: 0.4096, Avg Val Loss: 0.2204\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [410/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4105\n",
      "LOG: Epoch [410/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.0647\n",
      "Epoch [410/2000], Avg Train Loss: 0.4105, Avg Val Loss: 0.2204\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [411/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4064\n",
      "LOG: Epoch [411/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.0646\n",
      "Epoch [411/2000], Avg Train Loss: 0.4064, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [412/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4093\n",
      "LOG: Epoch [412/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3760\n",
      "    Batch [2/2], Val Loss: 0.0646\n",
      "Epoch [412/2000], Avg Train Loss: 0.4093, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [413/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4096\n",
      "LOG: Epoch [413/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.0646\n",
      "Epoch [413/2000], Avg Train Loss: 0.4096, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [414/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4090\n",
      "LOG: Epoch [414/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.0646\n",
      "Epoch [414/2000], Avg Train Loss: 0.4090, Avg Val Loss: 0.2204\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [415/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4093\n",
      "LOG: Epoch [415/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3762\n",
      "    Batch [2/2], Val Loss: 0.0646\n",
      "Epoch [415/2000], Avg Train Loss: 0.4093, Avg Val Loss: 0.2204\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [416/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4102\n",
      "LOG: Epoch [416/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3763\n",
      "    Batch [2/2], Val Loss: 0.0645\n",
      "Epoch [416/2000], Avg Train Loss: 0.4102, Avg Val Loss: 0.2204\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [417/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [417/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.0645\n",
      "Epoch [417/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2204\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [418/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [418/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.0645\n",
      "Epoch [418/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2204\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [419/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4056\n",
      "LOG: Epoch [419/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.0644\n",
      "Epoch [419/2000], Avg Train Loss: 0.4056, Avg Val Loss: 0.2204\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [420/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4105\n",
      "LOG: Epoch [420/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3764\n",
      "    Batch [2/2], Val Loss: 0.0643\n",
      "Epoch [420/2000], Avg Train Loss: 0.4105, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [421/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4119\n",
      "LOG: Epoch [421/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3763\n",
      "    Batch [2/2], Val Loss: 0.0642\n",
      "Epoch [421/2000], Avg Train Loss: 0.4119, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [422/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4092\n",
      "LOG: Epoch [422/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3763\n",
      "    Batch [2/2], Val Loss: 0.0641\n",
      "Epoch [422/2000], Avg Train Loss: 0.4092, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2202. Saving model...\n",
      "LOG: Epoch [423/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4094\n",
      "LOG: Epoch [423/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3762\n",
      "    Batch [2/2], Val Loss: 0.0641\n",
      "Epoch [423/2000], Avg Train Loss: 0.4094, Avg Val Loss: 0.2201\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2201. Saving model...\n",
      "LOG: Epoch [424/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4095\n",
      "LOG: Epoch [424/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.0640\n",
      "Epoch [424/2000], Avg Train Loss: 0.4095, Avg Val Loss: 0.2201\n",
      "\n",
      "Validation loss improved from 0.2201 to 0.2201. Saving model...\n",
      "LOG: Epoch [425/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4094\n",
      "LOG: Epoch [425/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.0639\n",
      "Epoch [425/2000], Avg Train Loss: 0.4094, Avg Val Loss: 0.2200\n",
      "\n",
      "Validation loss improved from 0.2201 to 0.2200. Saving model...\n",
      "LOG: Epoch [426/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4100\n",
      "LOG: Epoch [426/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.0639\n",
      "Epoch [426/2000], Avg Train Loss: 0.4100, Avg Val Loss: 0.2200\n",
      "\n",
      "Validation loss improved from 0.2200 to 0.2200. Saving model...\n",
      "LOG: Epoch [427/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [427/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.0638\n",
      "Epoch [427/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2200\n",
      "\n",
      "Validation loss improved from 0.2200 to 0.2200. Saving model...\n",
      "LOG: Epoch [428/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [428/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.0638\n",
      "Epoch [428/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2200\n",
      "\n",
      "Validation loss improved from 0.2200 to 0.2200. Saving model...\n",
      "LOG: Epoch [429/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4091\n",
      "LOG: Epoch [429/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.0638\n",
      "Epoch [429/2000], Avg Train Loss: 0.4091, Avg Val Loss: 0.2200\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [430/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4057\n",
      "LOG: Epoch [430/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3760\n",
      "    Batch [2/2], Val Loss: 0.0639\n",
      "Epoch [430/2000], Avg Train Loss: 0.4057, Avg Val Loss: 0.2200\n",
      "\n",
      "Validation loss improved from 0.2200 to 0.2200. Saving model...\n",
      "LOG: Epoch [431/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4086\n",
      "LOG: Epoch [431/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3760\n",
      "    Batch [2/2], Val Loss: 0.0639\n",
      "Epoch [431/2000], Avg Train Loss: 0.4086, Avg Val Loss: 0.2200\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [432/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4085\n",
      "LOG: Epoch [432/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.0639\n",
      "Epoch [432/2000], Avg Train Loss: 0.4085, Avg Val Loss: 0.2200\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [433/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4108\n",
      "LOG: Epoch [433/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3761\n",
      "    Batch [2/2], Val Loss: 0.0639\n",
      "Epoch [433/2000], Avg Train Loss: 0.4108, Avg Val Loss: 0.2200\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [434/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4071\n",
      "LOG: Epoch [434/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3760\n",
      "    Batch [2/2], Val Loss: 0.0640\n",
      "Epoch [434/2000], Avg Train Loss: 0.4071, Avg Val Loss: 0.2200\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [435/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4093\n",
      "LOG: Epoch [435/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3760\n",
      "    Batch [2/2], Val Loss: 0.0640\n",
      "Epoch [435/2000], Avg Train Loss: 0.4093, Avg Val Loss: 0.2200\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4083\n",
      "LOG: Epoch [436/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3760\n",
      "    Batch [2/2], Val Loss: 0.0640\n",
      "Epoch [436/2000], Avg Train Loss: 0.4083, Avg Val Loss: 0.2200\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [437/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4084\n",
      "LOG: Epoch [437/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3759\n",
      "    Batch [2/2], Val Loss: 0.0641\n",
      "Epoch [437/2000], Avg Train Loss: 0.4084, Avg Val Loss: 0.2200\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [438/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4079\n",
      "LOG: Epoch [438/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3759\n",
      "    Batch [2/2], Val Loss: 0.0641\n",
      "Epoch [438/2000], Avg Train Loss: 0.4079, Avg Val Loss: 0.2200\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [439/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4096\n",
      "LOG: Epoch [439/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3758\n",
      "    Batch [2/2], Val Loss: 0.0642\n",
      "Epoch [439/2000], Avg Train Loss: 0.4096, Avg Val Loss: 0.2200\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [440/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [440/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3757\n",
      "    Batch [2/2], Val Loss: 0.0642\n",
      "Epoch [440/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2199\n",
      "\n",
      "Validation loss improved from 0.2200 to 0.2199. Saving model...\n",
      "LOG: Epoch [441/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4060\n",
      "LOG: Epoch [441/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3756\n",
      "    Batch [2/2], Val Loss: 0.0643\n",
      "Epoch [441/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.2199\n",
      "\n",
      "Validation loss improved from 0.2199 to 0.2199. Saving model...\n",
      "LOG: Epoch [442/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4076\n",
      "LOG: Epoch [442/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3755\n",
      "    Batch [2/2], Val Loss: 0.0643\n",
      "Epoch [442/2000], Avg Train Loss: 0.4076, Avg Val Loss: 0.2199\n",
      "\n",
      "Validation loss improved from 0.2199 to 0.2199. Saving model...\n",
      "LOG: Epoch [443/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [443/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3754\n",
      "    Batch [2/2], Val Loss: 0.0644\n",
      "Epoch [443/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2199\n",
      "\n",
      "Validation loss improved from 0.2199 to 0.2199. Saving model...\n",
      "LOG: Epoch [444/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [444/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3754\n",
      "    Batch [2/2], Val Loss: 0.0644\n",
      "Epoch [444/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2199\n",
      "\n",
      "Validation loss improved from 0.2199 to 0.2199. Saving model...\n",
      "LOG: Epoch [445/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4098\n",
      "LOG: Epoch [445/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3753\n",
      "    Batch [2/2], Val Loss: 0.0644\n",
      "Epoch [445/2000], Avg Train Loss: 0.4098, Avg Val Loss: 0.2199\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [446/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4070\n",
      "LOG: Epoch [446/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3753\n",
      "    Batch [2/2], Val Loss: 0.0645\n",
      "Epoch [446/2000], Avg Train Loss: 0.4070, Avg Val Loss: 0.2199\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [447/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [447/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3753\n",
      "    Batch [2/2], Val Loss: 0.0645\n",
      "Epoch [447/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2199\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [448/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4110\n",
      "LOG: Epoch [448/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3753\n",
      "    Batch [2/2], Val Loss: 0.0645\n",
      "Epoch [448/2000], Avg Train Loss: 0.4110, Avg Val Loss: 0.2199\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [449/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [449/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3752\n",
      "    Batch [2/2], Val Loss: 0.0645\n",
      "Epoch [449/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2199\n",
      "\n",
      "Validation loss improved from 0.2199 to 0.2199. Saving model...\n",
      "LOG: Epoch [450/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4091\n",
      "LOG: Epoch [450/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3752\n",
      "    Batch [2/2], Val Loss: 0.0645\n",
      "Epoch [450/2000], Avg Train Loss: 0.4091, Avg Val Loss: 0.2199\n",
      "\n",
      "Validation loss improved from 0.2199 to 0.2199. Saving model...\n",
      "LOG: Epoch [451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [451/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3752\n",
      "    Batch [2/2], Val Loss: 0.0645\n",
      "Epoch [451/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2198\n",
      "\n",
      "Validation loss improved from 0.2199 to 0.2198. Saving model...\n",
      "LOG: Epoch [452/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4089\n",
      "LOG: Epoch [452/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3752\n",
      "    Batch [2/2], Val Loss: 0.0645\n",
      "Epoch [452/2000], Avg Train Loss: 0.4089, Avg Val Loss: 0.2198\n",
      "\n",
      "Validation loss improved from 0.2198 to 0.2198. Saving model...\n",
      "LOG: Epoch [453/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4078\n",
      "LOG: Epoch [453/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3751\n",
      "    Batch [2/2], Val Loss: 0.0644\n",
      "Epoch [453/2000], Avg Train Loss: 0.4078, Avg Val Loss: 0.2198\n",
      "\n",
      "Validation loss improved from 0.2198 to 0.2198. Saving model...\n",
      "LOG: Epoch [454/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [454/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3750\n",
      "    Batch [2/2], Val Loss: 0.0644\n",
      "Epoch [454/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2197\n",
      "\n",
      "Validation loss improved from 0.2198 to 0.2197. Saving model...\n",
      "LOG: Epoch [455/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4058\n",
      "LOG: Epoch [455/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3750\n",
      "    Batch [2/2], Val Loss: 0.0644\n",
      "Epoch [455/2000], Avg Train Loss: 0.4058, Avg Val Loss: 0.2197\n",
      "\n",
      "Validation loss improved from 0.2197 to 0.2197. Saving model...\n",
      "LOG: Epoch [456/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4092\n",
      "LOG: Epoch [456/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3749\n",
      "    Batch [2/2], Val Loss: 0.0643\n",
      "Epoch [456/2000], Avg Train Loss: 0.4092, Avg Val Loss: 0.2196\n",
      "\n",
      "Validation loss improved from 0.2197 to 0.2196. Saving model...\n",
      "LOG: Epoch [457/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4087\n",
      "LOG: Epoch [457/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3749\n",
      "    Batch [2/2], Val Loss: 0.0643\n",
      "Epoch [457/2000], Avg Train Loss: 0.4087, Avg Val Loss: 0.2196\n",
      "\n",
      "Validation loss improved from 0.2196 to 0.2196. Saving model...\n",
      "LOG: Epoch [458/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4086\n",
      "LOG: Epoch [458/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3749\n",
      "    Batch [2/2], Val Loss: 0.0643\n",
      "Epoch [458/2000], Avg Train Loss: 0.4086, Avg Val Loss: 0.2196\n",
      "\n",
      "Validation loss improved from 0.2196 to 0.2196. Saving model...\n",
      "LOG: Epoch [459/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4113\n",
      "LOG: Epoch [459/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3748\n",
      "    Batch [2/2], Val Loss: 0.0642\n",
      "Epoch [459/2000], Avg Train Loss: 0.4113, Avg Val Loss: 0.2195\n",
      "\n",
      "Validation loss improved from 0.2196 to 0.2195. Saving model...\n",
      "LOG: Epoch [460/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4075\n",
      "LOG: Epoch [460/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3748\n",
      "    Batch [2/2], Val Loss: 0.0642\n",
      "Epoch [460/2000], Avg Train Loss: 0.4075, Avg Val Loss: 0.2195\n",
      "\n",
      "Validation loss improved from 0.2195 to 0.2195. Saving model...\n",
      "LOG: Epoch [461/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [461/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3748\n",
      "    Batch [2/2], Val Loss: 0.0641\n",
      "Epoch [461/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2194\n",
      "\n",
      "Validation loss improved from 0.2195 to 0.2194. Saving model...\n",
      "LOG: Epoch [462/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4108\n",
      "LOG: Epoch [462/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3747\n",
      "    Batch [2/2], Val Loss: 0.0641\n",
      "Epoch [462/2000], Avg Train Loss: 0.4108, Avg Val Loss: 0.2194\n",
      "\n",
      "Validation loss improved from 0.2194 to 0.2194. Saving model...\n",
      "LOG: Epoch [463/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4078\n",
      "LOG: Epoch [463/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3747\n",
      "    Batch [2/2], Val Loss: 0.0641\n",
      "Epoch [463/2000], Avg Train Loss: 0.4078, Avg Val Loss: 0.2194\n",
      "\n",
      "Validation loss improved from 0.2194 to 0.2194. Saving model...\n",
      "LOG: Epoch [464/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [464/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3746\n",
      "    Batch [2/2], Val Loss: 0.0641\n",
      "Epoch [464/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2194\n",
      "\n",
      "Validation loss improved from 0.2194 to 0.2194. Saving model...\n",
      "LOG: Epoch [465/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [465/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3745\n",
      "    Batch [2/2], Val Loss: 0.0641\n",
      "Epoch [465/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2193\n",
      "\n",
      "Validation loss improved from 0.2194 to 0.2193. Saving model...\n",
      "LOG: Epoch [466/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4077\n",
      "LOG: Epoch [466/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3744\n",
      "    Batch [2/2], Val Loss: 0.0642\n",
      "Epoch [466/2000], Avg Train Loss: 0.4077, Avg Val Loss: 0.2193\n",
      "\n",
      "Validation loss improved from 0.2193 to 0.2193. Saving model...\n",
      "LOG: Epoch [467/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4062\n",
      "LOG: Epoch [467/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3744\n",
      "    Batch [2/2], Val Loss: 0.0641\n",
      "Epoch [467/2000], Avg Train Loss: 0.4062, Avg Val Loss: 0.2193\n",
      "\n",
      "Validation loss improved from 0.2193 to 0.2193. Saving model...\n",
      "LOG: Epoch [468/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4120\n",
      "LOG: Epoch [468/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3744\n",
      "    Batch [2/2], Val Loss: 0.0641\n",
      "Epoch [468/2000], Avg Train Loss: 0.4120, Avg Val Loss: 0.2192\n",
      "\n",
      "Validation loss improved from 0.2193 to 0.2192. Saving model...\n",
      "LOG: Epoch [469/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4077\n",
      "LOG: Epoch [469/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3743\n",
      "    Batch [2/2], Val Loss: 0.0641\n",
      "Epoch [469/2000], Avg Train Loss: 0.4077, Avg Val Loss: 0.2192\n",
      "\n",
      "Validation loss improved from 0.2192 to 0.2192. Saving model...\n",
      "LOG: Epoch [470/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4119\n",
      "LOG: Epoch [470/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3743\n",
      "    Batch [2/2], Val Loss: 0.0641\n",
      "Epoch [470/2000], Avg Train Loss: 0.4119, Avg Val Loss: 0.2192\n",
      "\n",
      "Validation loss improved from 0.2192 to 0.2192. Saving model...\n",
      "LOG: Epoch [471/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [471/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3742\n",
      "    Batch [2/2], Val Loss: 0.0640\n",
      "Epoch [471/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2191\n",
      "\n",
      "Validation loss improved from 0.2192 to 0.2191. Saving model...\n",
      "LOG: Epoch [472/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4083\n",
      "LOG: Epoch [472/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3742\n",
      "    Batch [2/2], Val Loss: 0.0640\n",
      "Epoch [472/2000], Avg Train Loss: 0.4083, Avg Val Loss: 0.2191\n",
      "\n",
      "Validation loss improved from 0.2191 to 0.2191. Saving model...\n",
      "LOG: Epoch [473/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [473/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3741\n",
      "    Batch [2/2], Val Loss: 0.0639\n",
      "Epoch [473/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2190\n",
      "\n",
      "Validation loss improved from 0.2191 to 0.2190. Saving model...\n",
      "LOG: Epoch [474/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [474/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3742\n",
      "    Batch [2/2], Val Loss: 0.0638\n",
      "Epoch [474/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2190\n",
      "\n",
      "Validation loss improved from 0.2190 to 0.2190. Saving model...\n",
      "LOG: Epoch [475/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4105\n",
      "LOG: Epoch [475/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3742\n",
      "    Batch [2/2], Val Loss: 0.0638\n",
      "Epoch [475/2000], Avg Train Loss: 0.4105, Avg Val Loss: 0.2190\n",
      "\n",
      "Validation loss improved from 0.2190 to 0.2190. Saving model...\n",
      "LOG: Epoch [476/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4003\n",
      "LOG: Epoch [476/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3741\n",
      "    Batch [2/2], Val Loss: 0.0637\n",
      "Epoch [476/2000], Avg Train Loss: 0.4003, Avg Val Loss: 0.2189\n",
      "\n",
      "Validation loss improved from 0.2190 to 0.2189. Saving model...\n",
      "LOG: Epoch [477/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [477/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3741\n",
      "    Batch [2/2], Val Loss: 0.0637\n",
      "Epoch [477/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2189\n",
      "\n",
      "Validation loss improved from 0.2189 to 0.2189. Saving model...\n",
      "LOG: Epoch [478/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4079\n",
      "LOG: Epoch [478/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3741\n",
      "    Batch [2/2], Val Loss: 0.0636\n",
      "Epoch [478/2000], Avg Train Loss: 0.4079, Avg Val Loss: 0.2188\n",
      "\n",
      "Validation loss improved from 0.2189 to 0.2188. Saving model...\n",
      "LOG: Epoch [479/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4048\n",
      "LOG: Epoch [479/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3740\n",
      "    Batch [2/2], Val Loss: 0.0635\n",
      "Epoch [479/2000], Avg Train Loss: 0.4048, Avg Val Loss: 0.2188\n",
      "\n",
      "Validation loss improved from 0.2188 to 0.2188. Saving model...\n",
      "LOG: Epoch [480/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4082\n",
      "LOG: Epoch [480/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3740\n",
      "    Batch [2/2], Val Loss: 0.0635\n",
      "Epoch [480/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2187\n",
      "\n",
      "Validation loss improved from 0.2188 to 0.2187. Saving model...\n",
      "LOG: Epoch [481/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4081\n",
      "LOG: Epoch [481/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3739\n",
      "    Batch [2/2], Val Loss: 0.0634\n",
      "Epoch [481/2000], Avg Train Loss: 0.4081, Avg Val Loss: 0.2187\n",
      "\n",
      "Validation loss improved from 0.2187 to 0.2187. Saving model...\n",
      "LOG: Epoch [482/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4078\n",
      "LOG: Epoch [482/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3739\n",
      "    Batch [2/2], Val Loss: 0.0634\n",
      "Epoch [482/2000], Avg Train Loss: 0.4078, Avg Val Loss: 0.2186\n",
      "\n",
      "Validation loss improved from 0.2187 to 0.2186. Saving model...\n",
      "LOG: Epoch [483/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4086\n",
      "LOG: Epoch [483/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3738\n",
      "    Batch [2/2], Val Loss: 0.0634\n",
      "Epoch [483/2000], Avg Train Loss: 0.4086, Avg Val Loss: 0.2186\n",
      "\n",
      "Validation loss improved from 0.2186 to 0.2186. Saving model...\n",
      "LOG: Epoch [484/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [484/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3737\n",
      "    Batch [2/2], Val Loss: 0.0633\n",
      "Epoch [484/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2185\n",
      "\n",
      "Validation loss improved from 0.2186 to 0.2185. Saving model...\n",
      "LOG: Epoch [485/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4048\n",
      "LOG: Epoch [485/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3736\n",
      "    Batch [2/2], Val Loss: 0.0633\n",
      "Epoch [485/2000], Avg Train Loss: 0.4048, Avg Val Loss: 0.2185\n",
      "\n",
      "Validation loss improved from 0.2185 to 0.2185. Saving model...\n",
      "LOG: Epoch [486/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4074\n",
      "LOG: Epoch [486/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3735\n",
      "    Batch [2/2], Val Loss: 0.0633\n",
      "Epoch [486/2000], Avg Train Loss: 0.4074, Avg Val Loss: 0.2184\n",
      "\n",
      "Validation loss improved from 0.2185 to 0.2184. Saving model...\n",
      "LOG: Epoch [487/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4075\n",
      "LOG: Epoch [487/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3735\n",
      "    Batch [2/2], Val Loss: 0.0633\n",
      "Epoch [487/2000], Avg Train Loss: 0.4075, Avg Val Loss: 0.2184\n",
      "\n",
      "Validation loss improved from 0.2184 to 0.2184. Saving model...\n",
      "LOG: Epoch [488/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [488/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3734\n",
      "    Batch [2/2], Val Loss: 0.0633\n",
      "Epoch [488/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2183\n",
      "\n",
      "Validation loss improved from 0.2184 to 0.2183. Saving model...\n",
      "LOG: Epoch [489/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4094\n",
      "LOG: Epoch [489/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3733\n",
      "    Batch [2/2], Val Loss: 0.0633\n",
      "Epoch [489/2000], Avg Train Loss: 0.4094, Avg Val Loss: 0.2183\n",
      "\n",
      "Validation loss improved from 0.2183 to 0.2183. Saving model...\n",
      "LOG: Epoch [490/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [490/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3732\n",
      "    Batch [2/2], Val Loss: 0.0632\n",
      "Epoch [490/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2182\n",
      "\n",
      "Validation loss improved from 0.2183 to 0.2182. Saving model...\n",
      "LOG: Epoch [491/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [491/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3731\n",
      "    Batch [2/2], Val Loss: 0.0632\n",
      "Epoch [491/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2182\n",
      "\n",
      "Validation loss improved from 0.2182 to 0.2182. Saving model...\n",
      "LOG: Epoch [492/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [492/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3731\n",
      "    Batch [2/2], Val Loss: 0.0632\n",
      "Epoch [492/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2181\n",
      "\n",
      "Validation loss improved from 0.2182 to 0.2181. Saving model...\n",
      "LOG: Epoch [493/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4077\n",
      "LOG: Epoch [493/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3730\n",
      "    Batch [2/2], Val Loss: 0.0631\n",
      "Epoch [493/2000], Avg Train Loss: 0.4077, Avg Val Loss: 0.2180\n",
      "\n",
      "Validation loss improved from 0.2181 to 0.2180. Saving model...\n",
      "LOG: Epoch [494/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [494/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3729\n",
      "    Batch [2/2], Val Loss: 0.0631\n",
      "Epoch [494/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2180\n",
      "\n",
      "Validation loss improved from 0.2180 to 0.2180. Saving model...\n",
      "LOG: Epoch [495/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4049\n",
      "LOG: Epoch [495/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3729\n",
      "    Batch [2/2], Val Loss: 0.0630\n",
      "Epoch [495/2000], Avg Train Loss: 0.4049, Avg Val Loss: 0.2180\n",
      "\n",
      "Validation loss improved from 0.2180 to 0.2180. Saving model...\n",
      "LOG: Epoch [496/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4006\n",
      "LOG: Epoch [496/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3729\n",
      "    Batch [2/2], Val Loss: 0.0630\n",
      "Epoch [496/2000], Avg Train Loss: 0.4006, Avg Val Loss: 0.2179\n",
      "\n",
      "Validation loss improved from 0.2180 to 0.2179. Saving model...\n",
      "LOG: Epoch [497/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4084\n",
      "LOG: Epoch [497/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3729\n",
      "    Batch [2/2], Val Loss: 0.0629\n",
      "Epoch [497/2000], Avg Train Loss: 0.4084, Avg Val Loss: 0.2179\n",
      "\n",
      "Validation loss improved from 0.2179 to 0.2179. Saving model...\n",
      "LOG: Epoch [498/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [498/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3728\n",
      "    Batch [2/2], Val Loss: 0.0628\n",
      "Epoch [498/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2178\n",
      "\n",
      "Validation loss improved from 0.2179 to 0.2178. Saving model...\n",
      "LOG: Epoch [499/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4099\n",
      "LOG: Epoch [499/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.0627\n",
      "Epoch [499/2000], Avg Train Loss: 0.4099, Avg Val Loss: 0.2177\n",
      "\n",
      "Validation loss improved from 0.2178 to 0.2177. Saving model...\n",
      "LOG: Epoch [500/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [500/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.0626\n",
      "Epoch [500/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2177\n",
      "\n",
      "Validation loss improved from 0.2177 to 0.2177. Saving model...\n",
      "LOG: Epoch [501/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [501/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.0626\n",
      "Epoch [501/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2176\n",
      "\n",
      "Validation loss improved from 0.2177 to 0.2176. Saving model...\n",
      "LOG: Epoch [502/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4059\n",
      "LOG: Epoch [502/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.0625\n",
      "Epoch [502/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2176\n",
      "\n",
      "Validation loss improved from 0.2176 to 0.2176. Saving model...\n",
      "LOG: Epoch [503/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [503/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.0625\n",
      "Epoch [503/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2176\n",
      "\n",
      "Validation loss improved from 0.2176 to 0.2176. Saving model...\n",
      "LOG: Epoch [504/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [504/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.0624\n",
      "Epoch [504/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2176\n",
      "\n",
      "Validation loss improved from 0.2176 to 0.2176. Saving model...\n",
      "LOG: Epoch [505/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [505/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3728\n",
      "    Batch [2/2], Val Loss: 0.0623\n",
      "Epoch [505/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2175\n",
      "\n",
      "Validation loss improved from 0.2176 to 0.2175. Saving model...\n",
      "LOG: Epoch [506/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [506/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.0622\n",
      "Epoch [506/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2175\n",
      "\n",
      "Validation loss improved from 0.2175 to 0.2175. Saving model...\n",
      "LOG: Epoch [507/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4012\n",
      "LOG: Epoch [507/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3727\n",
      "    Batch [2/2], Val Loss: 0.0621\n",
      "Epoch [507/2000], Avg Train Loss: 0.4012, Avg Val Loss: 0.2174\n",
      "\n",
      "Validation loss improved from 0.2175 to 0.2174. Saving model...\n",
      "LOG: Epoch [508/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [508/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3726\n",
      "    Batch [2/2], Val Loss: 0.0621\n",
      "Epoch [508/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2174\n",
      "\n",
      "Validation loss improved from 0.2174 to 0.2174. Saving model...\n",
      "LOG: Epoch [509/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [509/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3726\n",
      "    Batch [2/2], Val Loss: 0.0621\n",
      "Epoch [509/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2173\n",
      "\n",
      "Validation loss improved from 0.2174 to 0.2173. Saving model...\n",
      "LOG: Epoch [510/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4079\n",
      "LOG: Epoch [510/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3725\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [510/2000], Avg Train Loss: 0.4079, Avg Val Loss: 0.2172\n",
      "\n",
      "Validation loss improved from 0.2173 to 0.2172. Saving model...\n",
      "LOG: Epoch [511/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [511/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3723\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [511/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2172\n",
      "\n",
      "Validation loss improved from 0.2172 to 0.2172. Saving model...\n",
      "LOG: Epoch [512/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [512/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3722\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [512/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2171\n",
      "\n",
      "Validation loss improved from 0.2172 to 0.2171. Saving model...\n",
      "LOG: Epoch [513/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [513/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3721\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [513/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2170\n",
      "\n",
      "Validation loss improved from 0.2171 to 0.2170. Saving model...\n",
      "LOG: Epoch [514/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4062\n",
      "LOG: Epoch [514/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3721\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [514/2000], Avg Train Loss: 0.4062, Avg Val Loss: 0.2170\n",
      "\n",
      "Validation loss improved from 0.2170 to 0.2170. Saving model...\n",
      "LOG: Epoch [515/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [515/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3720\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [515/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2169\n",
      "\n",
      "Validation loss improved from 0.2170 to 0.2169. Saving model...\n",
      "LOG: Epoch [516/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [516/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3720\n",
      "    Batch [2/2], Val Loss: 0.0618\n",
      "Epoch [516/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2169\n",
      "\n",
      "Validation loss improved from 0.2169 to 0.2169. Saving model...\n",
      "LOG: Epoch [517/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [517/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3718\n",
      "    Batch [2/2], Val Loss: 0.0618\n",
      "Epoch [517/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2168\n",
      "\n",
      "Validation loss improved from 0.2169 to 0.2168. Saving model...\n",
      "LOG: Epoch [518/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [518/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3717\n",
      "    Batch [2/2], Val Loss: 0.0618\n",
      "Epoch [518/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2167\n",
      "\n",
      "Validation loss improved from 0.2168 to 0.2167. Saving model...\n",
      "LOG: Epoch [519/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [519/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3715\n",
      "    Batch [2/2], Val Loss: 0.0618\n",
      "Epoch [519/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2167\n",
      "\n",
      "Validation loss improved from 0.2167 to 0.2167. Saving model...\n",
      "LOG: Epoch [520/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [520/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3714\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [520/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2166\n",
      "\n",
      "Validation loss improved from 0.2167 to 0.2166. Saving model...\n",
      "LOG: Epoch [521/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [521/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3713\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [521/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2166\n",
      "\n",
      "Validation loss improved from 0.2166 to 0.2166. Saving model...\n",
      "LOG: Epoch [522/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4059\n",
      "LOG: Epoch [522/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3711\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [522/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2165\n",
      "\n",
      "Validation loss improved from 0.2166 to 0.2165. Saving model...\n",
      "LOG: Epoch [523/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [523/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3710\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [523/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2165\n",
      "\n",
      "Validation loss improved from 0.2165 to 0.2165. Saving model...\n",
      "LOG: Epoch [524/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4097\n",
      "LOG: Epoch [524/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3709\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [524/2000], Avg Train Loss: 0.4097, Avg Val Loss: 0.2165\n",
      "\n",
      "Validation loss improved from 0.2165 to 0.2165. Saving model...\n",
      "LOG: Epoch [525/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4074\n",
      "LOG: Epoch [525/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3708\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [525/2000], Avg Train Loss: 0.4074, Avg Val Loss: 0.2164\n",
      "\n",
      "Validation loss improved from 0.2165 to 0.2164. Saving model...\n",
      "LOG: Epoch [526/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [526/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3707\n",
      "    Batch [2/2], Val Loss: 0.0621\n",
      "Epoch [526/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2164\n",
      "\n",
      "Validation loss improved from 0.2164 to 0.2164. Saving model...\n",
      "LOG: Epoch [527/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [527/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3705\n",
      "    Batch [2/2], Val Loss: 0.0621\n",
      "Epoch [527/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2163\n",
      "\n",
      "Validation loss improved from 0.2164 to 0.2163. Saving model...\n",
      "LOG: Epoch [528/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [528/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3704\n",
      "    Batch [2/2], Val Loss: 0.0621\n",
      "Epoch [528/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2163\n",
      "\n",
      "Validation loss improved from 0.2163 to 0.2163. Saving model...\n",
      "LOG: Epoch [529/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [529/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3703\n",
      "    Batch [2/2], Val Loss: 0.0622\n",
      "Epoch [529/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2162\n",
      "\n",
      "Validation loss improved from 0.2163 to 0.2162. Saving model...\n",
      "LOG: Epoch [530/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [530/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3702\n",
      "    Batch [2/2], Val Loss: 0.0622\n",
      "Epoch [530/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2162\n",
      "\n",
      "Validation loss improved from 0.2162 to 0.2162. Saving model...\n",
      "LOG: Epoch [531/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [531/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.0622\n",
      "Epoch [531/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2162\n",
      "\n",
      "Validation loss improved from 0.2162 to 0.2162. Saving model...\n",
      "LOG: Epoch [532/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4010\n",
      "LOG: Epoch [532/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.0623\n",
      "Epoch [532/2000], Avg Train Loss: 0.4010, Avg Val Loss: 0.2162\n",
      "\n",
      "Validation loss improved from 0.2162 to 0.2162. Saving model...\n",
      "LOG: Epoch [533/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [533/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.0623\n",
      "Epoch [533/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2162\n",
      "\n",
      "Validation loss improved from 0.2162 to 0.2162. Saving model...\n",
      "LOG: Epoch [534/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [534/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.0623\n",
      "Epoch [534/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2162\n",
      "\n",
      "Validation loss improved from 0.2162 to 0.2162. Saving model...\n",
      "LOG: Epoch [535/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4054\n",
      "LOG: Epoch [535/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.0623\n",
      "Epoch [535/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2161\n",
      "\n",
      "Validation loss improved from 0.2162 to 0.2161. Saving model...\n",
      "LOG: Epoch [536/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [536/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3699\n",
      "    Batch [2/2], Val Loss: 0.0623\n",
      "Epoch [536/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2161\n",
      "\n",
      "Validation loss improved from 0.2161 to 0.2161. Saving model...\n",
      "LOG: Epoch [537/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [537/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3699\n",
      "    Batch [2/2], Val Loss: 0.0623\n",
      "Epoch [537/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2161\n",
      "\n",
      "Validation loss improved from 0.2161 to 0.2161. Saving model...\n",
      "LOG: Epoch [538/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4003\n",
      "LOG: Epoch [538/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3699\n",
      "    Batch [2/2], Val Loss: 0.0624\n",
      "Epoch [538/2000], Avg Train Loss: 0.4003, Avg Val Loss: 0.2161\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [539/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [539/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3699\n",
      "    Batch [2/2], Val Loss: 0.0624\n",
      "Epoch [539/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2161\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [540/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4057\n",
      "LOG: Epoch [540/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3699\n",
      "    Batch [2/2], Val Loss: 0.0624\n",
      "Epoch [540/2000], Avg Train Loss: 0.4057, Avg Val Loss: 0.2161\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [541/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [541/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.0623\n",
      "Epoch [541/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2162\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [542/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [542/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.0623\n",
      "Epoch [542/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2162\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [543/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4057\n",
      "LOG: Epoch [543/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.0623\n",
      "Epoch [543/2000], Avg Train Loss: 0.4057, Avg Val Loss: 0.2162\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [544/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [544/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.0623\n",
      "Epoch [544/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2162\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [545/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [545/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.0622\n",
      "Epoch [545/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2162\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [546/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [546/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.0622\n",
      "Epoch [546/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2162\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [547/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4048\n",
      "LOG: Epoch [547/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.0622\n",
      "Epoch [547/2000], Avg Train Loss: 0.4048, Avg Val Loss: 0.2161\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [548/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4008\n",
      "LOG: Epoch [548/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.0621\n",
      "Epoch [548/2000], Avg Train Loss: 0.4008, Avg Val Loss: 0.2161\n",
      "\n",
      "Validation loss improved from 0.2161 to 0.2161. Saving model...\n",
      "LOG: Epoch [549/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [549/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.0621\n",
      "Epoch [549/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2161\n",
      "\n",
      "Validation loss improved from 0.2161 to 0.2161. Saving model...\n",
      "LOG: Epoch [550/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [550/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.0621\n",
      "Epoch [550/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2160\n",
      "\n",
      "Validation loss improved from 0.2161 to 0.2160. Saving model...\n",
      "LOG: Epoch [551/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [551/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [551/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2160\n",
      "\n",
      "Validation loss improved from 0.2160 to 0.2160. Saving model...\n",
      "LOG: Epoch [552/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [552/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [552/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2160\n",
      "\n",
      "Validation loss improved from 0.2160 to 0.2160. Saving model...\n",
      "LOG: Epoch [553/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [553/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [553/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2160\n",
      "\n",
      "Validation loss improved from 0.2160 to 0.2160. Saving model...\n",
      "LOG: Epoch [554/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4005\n",
      "LOG: Epoch [554/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [554/2000], Avg Train Loss: 0.4005, Avg Val Loss: 0.2160\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [555/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [555/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [555/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2160\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [556/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [556/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3702\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [556/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2160\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [557/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4038\n",
      "LOG: Epoch [557/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [557/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.2160\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [558/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [558/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [558/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2160\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [559/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [559/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [559/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2160\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [560/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3978\n",
      "LOG: Epoch [560/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3699\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [560/2000], Avg Train Loss: 0.3978, Avg Val Loss: 0.2160\n",
      "\n",
      "Validation loss improved from 0.2160 to 0.2160. Saving model...\n",
      "LOG: Epoch [561/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [561/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3698\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [561/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2159\n",
      "\n",
      "Validation loss improved from 0.2160 to 0.2159. Saving model...\n",
      "LOG: Epoch [562/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [562/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3698\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [562/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2159\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [563/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4012\n",
      "LOG: Epoch [563/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3699\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [563/2000], Avg Train Loss: 0.4012, Avg Val Loss: 0.2159\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [564/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [564/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3699\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [564/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2160\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [565/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [565/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [565/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2160\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [566/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [566/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [566/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2161\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [567/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [567/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3702\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [567/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2161\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [568/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [568/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3702\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [568/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2161\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [569/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4002\n",
      "LOG: Epoch [569/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3702\n",
      "    Batch [2/2], Val Loss: 0.0620\n",
      "Epoch [569/2000], Avg Train Loss: 0.4002, Avg Val Loss: 0.2161\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [570/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [570/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3701\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [570/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2160\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [571/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [571/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [571/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2160\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [572/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [572/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3700\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [572/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2159\n",
      "\n",
      "Validation loss improved from 0.2159 to 0.2159. Saving model...\n",
      "LOG: Epoch [573/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [573/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3699\n",
      "    Batch [2/2], Val Loss: 0.0619\n",
      "Epoch [573/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2159\n",
      "\n",
      "Validation loss improved from 0.2159 to 0.2159. Saving model...\n",
      "LOG: Epoch [574/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [574/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3698\n",
      "    Batch [2/2], Val Loss: 0.0618\n",
      "Epoch [574/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2158\n",
      "\n",
      "Validation loss improved from 0.2159 to 0.2158. Saving model...\n",
      "LOG: Epoch [575/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4007\n",
      "LOG: Epoch [575/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3697\n",
      "    Batch [2/2], Val Loss: 0.0618\n",
      "Epoch [575/2000], Avg Train Loss: 0.4007, Avg Val Loss: 0.2158\n",
      "\n",
      "Validation loss improved from 0.2158 to 0.2158. Saving model...\n",
      "LOG: Epoch [576/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [576/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3697\n",
      "    Batch [2/2], Val Loss: 0.0618\n",
      "Epoch [576/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2157\n",
      "\n",
      "Validation loss improved from 0.2158 to 0.2157. Saving model...\n",
      "LOG: Epoch [577/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [577/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3696\n",
      "    Batch [2/2], Val Loss: 0.0617\n",
      "Epoch [577/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2157\n",
      "\n",
      "Validation loss improved from 0.2157 to 0.2157. Saving model...\n",
      "LOG: Epoch [578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4056\n",
      "LOG: Epoch [578/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3696\n",
      "    Batch [2/2], Val Loss: 0.0617\n",
      "Epoch [578/2000], Avg Train Loss: 0.4056, Avg Val Loss: 0.2157\n",
      "\n",
      "Validation loss improved from 0.2157 to 0.2157. Saving model...\n",
      "LOG: Epoch [579/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3985\n",
      "LOG: Epoch [579/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3696\n",
      "    Batch [2/2], Val Loss: 0.0616\n",
      "Epoch [579/2000], Avg Train Loss: 0.3985, Avg Val Loss: 0.2156\n",
      "\n",
      "Validation loss improved from 0.2157 to 0.2156. Saving model...\n",
      "LOG: Epoch [580/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [580/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3696\n",
      "    Batch [2/2], Val Loss: 0.0616\n",
      "Epoch [580/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2156\n",
      "\n",
      "Validation loss improved from 0.2156 to 0.2156. Saving model...\n",
      "LOG: Epoch [581/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [581/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3696\n",
      "    Batch [2/2], Val Loss: 0.0616\n",
      "Epoch [581/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2156\n",
      "\n",
      "Validation loss improved from 0.2156 to 0.2156. Saving model...\n",
      "LOG: Epoch [582/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [582/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3696\n",
      "    Batch [2/2], Val Loss: 0.0615\n",
      "Epoch [582/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2155\n",
      "\n",
      "Validation loss improved from 0.2156 to 0.2155. Saving model...\n",
      "LOG: Epoch [583/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3970\n",
      "LOG: Epoch [583/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3695\n",
      "    Batch [2/2], Val Loss: 0.0615\n",
      "Epoch [583/2000], Avg Train Loss: 0.3970, Avg Val Loss: 0.2155\n",
      "\n",
      "Validation loss improved from 0.2155 to 0.2155. Saving model...\n",
      "LOG: Epoch [584/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4012\n",
      "LOG: Epoch [584/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3695\n",
      "    Batch [2/2], Val Loss: 0.0615\n",
      "Epoch [584/2000], Avg Train Loss: 0.4012, Avg Val Loss: 0.2155\n",
      "\n",
      "Validation loss improved from 0.2155 to 0.2155. Saving model...\n",
      "LOG: Epoch [585/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4044\n",
      "LOG: Epoch [585/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3694\n",
      "    Batch [2/2], Val Loss: 0.0614\n",
      "Epoch [585/2000], Avg Train Loss: 0.4044, Avg Val Loss: 0.2154\n",
      "\n",
      "Validation loss improved from 0.2155 to 0.2154. Saving model...\n",
      "LOG: Epoch [586/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3999\n",
      "LOG: Epoch [586/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3693\n",
      "    Batch [2/2], Val Loss: 0.0613\n",
      "Epoch [586/2000], Avg Train Loss: 0.3999, Avg Val Loss: 0.2153\n",
      "\n",
      "Validation loss improved from 0.2154 to 0.2153. Saving model...\n",
      "LOG: Epoch [587/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [587/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3692\n",
      "    Batch [2/2], Val Loss: 0.0613\n",
      "Epoch [587/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2152\n",
      "\n",
      "Validation loss improved from 0.2153 to 0.2152. Saving model...\n",
      "LOG: Epoch [588/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [588/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3690\n",
      "    Batch [2/2], Val Loss: 0.0613\n",
      "Epoch [588/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2151\n",
      "\n",
      "Validation loss improved from 0.2152 to 0.2151. Saving model...\n",
      "LOG: Epoch [589/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [589/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3689\n",
      "    Batch [2/2], Val Loss: 0.0613\n",
      "Epoch [589/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2151\n",
      "\n",
      "Validation loss improved from 0.2151 to 0.2151. Saving model...\n",
      "LOG: Epoch [590/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3975\n",
      "LOG: Epoch [590/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3687\n",
      "    Batch [2/2], Val Loss: 0.0612\n",
      "Epoch [590/2000], Avg Train Loss: 0.3975, Avg Val Loss: 0.2150\n",
      "\n",
      "Validation loss improved from 0.2151 to 0.2150. Saving model...\n",
      "LOG: Epoch [591/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3976\n",
      "LOG: Epoch [591/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3685\n",
      "    Batch [2/2], Val Loss: 0.0612\n",
      "Epoch [591/2000], Avg Train Loss: 0.3976, Avg Val Loss: 0.2149\n",
      "\n",
      "Validation loss improved from 0.2150 to 0.2149. Saving model...\n",
      "LOG: Epoch [592/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [592/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3684\n",
      "    Batch [2/2], Val Loss: 0.0613\n",
      "Epoch [592/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2148\n",
      "\n",
      "Validation loss improved from 0.2149 to 0.2148. Saving model...\n",
      "LOG: Epoch [593/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4006\n",
      "LOG: Epoch [593/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3684\n",
      "    Batch [2/2], Val Loss: 0.0613\n",
      "Epoch [593/2000], Avg Train Loss: 0.4006, Avg Val Loss: 0.2148\n",
      "\n",
      "Validation loss improved from 0.2148 to 0.2148. Saving model...\n",
      "LOG: Epoch [594/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3972\n",
      "LOG: Epoch [594/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3683\n",
      "    Batch [2/2], Val Loss: 0.0613\n",
      "Epoch [594/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2148\n",
      "\n",
      "Validation loss improved from 0.2148 to 0.2148. Saving model...\n",
      "LOG: Epoch [595/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4007\n",
      "LOG: Epoch [595/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3684\n",
      "    Batch [2/2], Val Loss: 0.0613\n",
      "Epoch [595/2000], Avg Train Loss: 0.4007, Avg Val Loss: 0.2148\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [596/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4001\n",
      "LOG: Epoch [596/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3684\n",
      "    Batch [2/2], Val Loss: 0.0613\n",
      "Epoch [596/2000], Avg Train Loss: 0.4001, Avg Val Loss: 0.2148\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [597/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4006\n",
      "LOG: Epoch [597/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3684\n",
      "    Batch [2/2], Val Loss: 0.0613\n",
      "Epoch [597/2000], Avg Train Loss: 0.4006, Avg Val Loss: 0.2148\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [598/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4010\n",
      "LOG: Epoch [598/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3684\n",
      "    Batch [2/2], Val Loss: 0.0613\n",
      "Epoch [598/2000], Avg Train Loss: 0.4010, Avg Val Loss: 0.2148\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [599/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [599/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3684\n",
      "    Batch [2/2], Val Loss: 0.0613\n",
      "Epoch [599/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2148\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [600/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [600/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3684\n",
      "    Batch [2/2], Val Loss: 0.0612\n",
      "Epoch [600/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2148\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [601/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [601/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3684\n",
      "    Batch [2/2], Val Loss: 0.0612\n",
      "Epoch [601/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2148\n",
      "\n",
      "Validation loss improved from 0.2148 to 0.2148. Saving model...\n",
      "LOG: Epoch [602/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [602/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3683\n",
      "    Batch [2/2], Val Loss: 0.0611\n",
      "Epoch [602/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2147\n",
      "\n",
      "Validation loss improved from 0.2148 to 0.2147. Saving model...\n",
      "LOG: Epoch [603/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3985\n",
      "LOG: Epoch [603/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3684\n",
      "    Batch [2/2], Val Loss: 0.0611\n",
      "Epoch [603/2000], Avg Train Loss: 0.3985, Avg Val Loss: 0.2147\n",
      "\n",
      "Validation loss improved from 0.2147 to 0.2147. Saving model...\n",
      "LOG: Epoch [604/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3998\n",
      "LOG: Epoch [604/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3683\n",
      "    Batch [2/2], Val Loss: 0.0611\n",
      "Epoch [604/2000], Avg Train Loss: 0.3998, Avg Val Loss: 0.2147\n",
      "\n",
      "Validation loss improved from 0.2147 to 0.2147. Saving model...\n",
      "LOG: Epoch [605/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [605/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3683\n",
      "    Batch [2/2], Val Loss: 0.0610\n",
      "Epoch [605/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2146\n",
      "\n",
      "Validation loss improved from 0.2147 to 0.2146. Saving model...\n",
      "LOG: Epoch [606/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3985\n",
      "LOG: Epoch [606/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3682\n",
      "    Batch [2/2], Val Loss: 0.0610\n",
      "Epoch [606/2000], Avg Train Loss: 0.3985, Avg Val Loss: 0.2146\n",
      "\n",
      "Validation loss improved from 0.2146 to 0.2146. Saving model...\n",
      "LOG: Epoch [607/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3957\n",
      "LOG: Epoch [607/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3681\n",
      "    Batch [2/2], Val Loss: 0.0610\n",
      "Epoch [607/2000], Avg Train Loss: 0.3957, Avg Val Loss: 0.2145\n",
      "\n",
      "Validation loss improved from 0.2146 to 0.2145. Saving model...\n",
      "LOG: Epoch [608/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [608/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3680\n",
      "    Batch [2/2], Val Loss: 0.0610\n",
      "Epoch [608/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2145\n",
      "\n",
      "Validation loss improved from 0.2145 to 0.2145. Saving model...\n",
      "LOG: Epoch [609/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3986\n",
      "LOG: Epoch [609/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3679\n",
      "    Batch [2/2], Val Loss: 0.0609\n",
      "Epoch [609/2000], Avg Train Loss: 0.3986, Avg Val Loss: 0.2144\n",
      "\n",
      "Validation loss improved from 0.2145 to 0.2144. Saving model...\n",
      "LOG: Epoch [610/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3998\n",
      "LOG: Epoch [610/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3678\n",
      "    Batch [2/2], Val Loss: 0.0609\n",
      "Epoch [610/2000], Avg Train Loss: 0.3998, Avg Val Loss: 0.2144\n",
      "\n",
      "Validation loss improved from 0.2144 to 0.2144. Saving model...\n",
      "LOG: Epoch [611/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [611/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3677\n",
      "    Batch [2/2], Val Loss: 0.0609\n",
      "Epoch [611/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2143\n",
      "\n",
      "Validation loss improved from 0.2144 to 0.2143. Saving model...\n",
      "LOG: Epoch [612/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [612/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3677\n",
      "    Batch [2/2], Val Loss: 0.0608\n",
      "Epoch [612/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2142\n",
      "\n",
      "Validation loss improved from 0.2143 to 0.2142. Saving model...\n",
      "LOG: Epoch [613/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [613/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3676\n",
      "    Batch [2/2], Val Loss: 0.0608\n",
      "Epoch [613/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2142\n",
      "\n",
      "Validation loss improved from 0.2142 to 0.2142. Saving model...\n",
      "LOG: Epoch [614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [614/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3675\n",
      "    Batch [2/2], Val Loss: 0.0608\n",
      "Epoch [614/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2141\n",
      "\n",
      "Validation loss improved from 0.2142 to 0.2141. Saving model...\n",
      "LOG: Epoch [615/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3983\n",
      "LOG: Epoch [615/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3674\n",
      "    Batch [2/2], Val Loss: 0.0607\n",
      "Epoch [615/2000], Avg Train Loss: 0.3983, Avg Val Loss: 0.2141\n",
      "\n",
      "Validation loss improved from 0.2141 to 0.2141. Saving model...\n",
      "LOG: Epoch [616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3983\n",
      "LOG: Epoch [616/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3673\n",
      "    Batch [2/2], Val Loss: 0.0607\n",
      "Epoch [616/2000], Avg Train Loss: 0.3983, Avg Val Loss: 0.2140\n",
      "\n",
      "Validation loss improved from 0.2141 to 0.2140. Saving model...\n",
      "LOG: Epoch [617/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3969\n",
      "LOG: Epoch [617/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3673\n",
      "    Batch [2/2], Val Loss: 0.0607\n",
      "Epoch [617/2000], Avg Train Loss: 0.3969, Avg Val Loss: 0.2140\n",
      "\n",
      "Validation loss improved from 0.2140 to 0.2140. Saving model...\n",
      "LOG: Epoch [618/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3992\n",
      "LOG: Epoch [618/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3673\n",
      "    Batch [2/2], Val Loss: 0.0607\n",
      "Epoch [618/2000], Avg Train Loss: 0.3992, Avg Val Loss: 0.2140\n",
      "\n",
      "Validation loss improved from 0.2140 to 0.2140. Saving model...\n",
      "LOG: Epoch [619/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [619/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3672\n",
      "    Batch [2/2], Val Loss: 0.0606\n",
      "Epoch [619/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2139\n",
      "\n",
      "Validation loss improved from 0.2140 to 0.2139. Saving model...\n",
      "LOG: Epoch [620/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [620/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3671\n",
      "    Batch [2/2], Val Loss: 0.0606\n",
      "Epoch [620/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2138\n",
      "\n",
      "Validation loss improved from 0.2139 to 0.2138. Saving model...\n",
      "LOG: Epoch [621/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3989\n",
      "LOG: Epoch [621/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3670\n",
      "    Batch [2/2], Val Loss: 0.0605\n",
      "Epoch [621/2000], Avg Train Loss: 0.3989, Avg Val Loss: 0.2138\n",
      "\n",
      "Validation loss improved from 0.2138 to 0.2138. Saving model...\n",
      "LOG: Epoch [622/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [622/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3669\n",
      "    Batch [2/2], Val Loss: 0.0605\n",
      "Epoch [622/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2137\n",
      "\n",
      "Validation loss improved from 0.2138 to 0.2137. Saving model...\n",
      "LOG: Epoch [623/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4002\n",
      "LOG: Epoch [623/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3668\n",
      "    Batch [2/2], Val Loss: 0.0605\n",
      "Epoch [623/2000], Avg Train Loss: 0.4002, Avg Val Loss: 0.2137\n",
      "\n",
      "Validation loss improved from 0.2137 to 0.2137. Saving model...\n",
      "LOG: Epoch [624/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3988\n",
      "LOG: Epoch [624/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3667\n",
      "    Batch [2/2], Val Loss: 0.0605\n",
      "Epoch [624/2000], Avg Train Loss: 0.3988, Avg Val Loss: 0.2136\n",
      "\n",
      "Validation loss improved from 0.2137 to 0.2136. Saving model...\n",
      "LOG: Epoch [625/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3952\n",
      "LOG: Epoch [625/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3667\n",
      "    Batch [2/2], Val Loss: 0.0605\n",
      "Epoch [625/2000], Avg Train Loss: 0.3952, Avg Val Loss: 0.2136\n",
      "\n",
      "Validation loss improved from 0.2136 to 0.2136. Saving model...\n",
      "LOG: Epoch [626/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3990\n",
      "LOG: Epoch [626/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3666\n",
      "    Batch [2/2], Val Loss: 0.0605\n",
      "Epoch [626/2000], Avg Train Loss: 0.3990, Avg Val Loss: 0.2135\n",
      "\n",
      "Validation loss improved from 0.2136 to 0.2135. Saving model...\n",
      "LOG: Epoch [627/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4013\n",
      "LOG: Epoch [627/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3665\n",
      "    Batch [2/2], Val Loss: 0.0605\n",
      "Epoch [627/2000], Avg Train Loss: 0.4013, Avg Val Loss: 0.2135\n",
      "\n",
      "Validation loss improved from 0.2135 to 0.2135. Saving model...\n",
      "LOG: Epoch [628/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3980\n",
      "LOG: Epoch [628/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3665\n",
      "    Batch [2/2], Val Loss: 0.0605\n",
      "Epoch [628/2000], Avg Train Loss: 0.3980, Avg Val Loss: 0.2135\n",
      "\n",
      "Validation loss improved from 0.2135 to 0.2135. Saving model...\n",
      "LOG: Epoch [629/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3989\n",
      "LOG: Epoch [629/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3664\n",
      "    Batch [2/2], Val Loss: 0.0605\n",
      "Epoch [629/2000], Avg Train Loss: 0.3989, Avg Val Loss: 0.2135\n",
      "\n",
      "Validation loss improved from 0.2135 to 0.2135. Saving model...\n",
      "LOG: Epoch [630/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3984\n",
      "LOG: Epoch [630/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3664\n",
      "    Batch [2/2], Val Loss: 0.0606\n",
      "Epoch [630/2000], Avg Train Loss: 0.3984, Avg Val Loss: 0.2135\n",
      "\n",
      "Validation loss improved from 0.2135 to 0.2135. Saving model...\n",
      "LOG: Epoch [631/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3995\n",
      "LOG: Epoch [631/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3663\n",
      "    Batch [2/2], Val Loss: 0.0606\n",
      "Epoch [631/2000], Avg Train Loss: 0.3995, Avg Val Loss: 0.2135\n",
      "\n",
      "Validation loss improved from 0.2135 to 0.2135. Saving model...\n",
      "LOG: Epoch [632/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3959\n",
      "LOG: Epoch [632/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3663\n",
      "    Batch [2/2], Val Loss: 0.0606\n",
      "Epoch [632/2000], Avg Train Loss: 0.3959, Avg Val Loss: 0.2135\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [633/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3958\n",
      "LOG: Epoch [633/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3662\n",
      "    Batch [2/2], Val Loss: 0.0607\n",
      "Epoch [633/2000], Avg Train Loss: 0.3958, Avg Val Loss: 0.2134\n",
      "\n",
      "Validation loss improved from 0.2135 to 0.2134. Saving model...\n",
      "LOG: Epoch [634/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3959\n",
      "LOG: Epoch [634/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3661\n",
      "    Batch [2/2], Val Loss: 0.0607\n",
      "Epoch [634/2000], Avg Train Loss: 0.3959, Avg Val Loss: 0.2134\n",
      "\n",
      "Validation loss improved from 0.2134 to 0.2134. Saving model...\n",
      "LOG: Epoch [635/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3970\n",
      "LOG: Epoch [635/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3661\n",
      "    Batch [2/2], Val Loss: 0.0607\n",
      "Epoch [635/2000], Avg Train Loss: 0.3970, Avg Val Loss: 0.2134\n",
      "\n",
      "Validation loss improved from 0.2134 to 0.2134. Saving model...\n",
      "LOG: Epoch [636/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3943\n",
      "LOG: Epoch [636/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3661\n",
      "    Batch [2/2], Val Loss: 0.0607\n",
      "Epoch [636/2000], Avg Train Loss: 0.3943, Avg Val Loss: 0.2134\n",
      "\n",
      "Validation loss improved from 0.2134 to 0.2134. Saving model...\n",
      "LOG: Epoch [637/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3985\n",
      "LOG: Epoch [637/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3660\n",
      "    Batch [2/2], Val Loss: 0.0607\n",
      "Epoch [637/2000], Avg Train Loss: 0.3985, Avg Val Loss: 0.2134\n",
      "\n",
      "Validation loss improved from 0.2134 to 0.2134. Saving model...\n",
      "LOG: Epoch [638/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3977\n",
      "LOG: Epoch [638/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3660\n",
      "    Batch [2/2], Val Loss: 0.0607\n",
      "Epoch [638/2000], Avg Train Loss: 0.3977, Avg Val Loss: 0.2133\n",
      "\n",
      "Validation loss improved from 0.2134 to 0.2133. Saving model...\n",
      "LOG: Epoch [639/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3996\n",
      "LOG: Epoch [639/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3660\n",
      "    Batch [2/2], Val Loss: 0.0606\n",
      "Epoch [639/2000], Avg Train Loss: 0.3996, Avg Val Loss: 0.2133\n",
      "\n",
      "Validation loss improved from 0.2133 to 0.2133. Saving model...\n",
      "LOG: Epoch [640/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3981\n",
      "LOG: Epoch [640/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3660\n",
      "    Batch [2/2], Val Loss: 0.0606\n",
      "Epoch [640/2000], Avg Train Loss: 0.3981, Avg Val Loss: 0.2133\n",
      "\n",
      "Validation loss improved from 0.2133 to 0.2133. Saving model...\n",
      "LOG: Epoch [641/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3971\n",
      "LOG: Epoch [641/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3660\n",
      "    Batch [2/2], Val Loss: 0.0605\n",
      "Epoch [641/2000], Avg Train Loss: 0.3971, Avg Val Loss: 0.2133\n",
      "\n",
      "Validation loss improved from 0.2133 to 0.2133. Saving model...\n",
      "LOG: Epoch [642/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3969\n",
      "LOG: Epoch [642/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3660\n",
      "    Batch [2/2], Val Loss: 0.0605\n",
      "Epoch [642/2000], Avg Train Loss: 0.3969, Avg Val Loss: 0.2133\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [643/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3988\n",
      "LOG: Epoch [643/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3661\n",
      "    Batch [2/2], Val Loss: 0.0605\n",
      "Epoch [643/2000], Avg Train Loss: 0.3988, Avg Val Loss: 0.2133\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [644/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [644/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3661\n",
      "    Batch [2/2], Val Loss: 0.0605\n",
      "Epoch [644/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2133\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [645/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3961\n",
      "LOG: Epoch [645/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3661\n",
      "    Batch [2/2], Val Loss: 0.0604\n",
      "Epoch [645/2000], Avg Train Loss: 0.3961, Avg Val Loss: 0.2133\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [646/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4003\n",
      "LOG: Epoch [646/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3661\n",
      "    Batch [2/2], Val Loss: 0.0604\n",
      "Epoch [646/2000], Avg Train Loss: 0.4003, Avg Val Loss: 0.2132\n",
      "\n",
      "Validation loss improved from 0.2133 to 0.2132. Saving model...\n",
      "LOG: Epoch [647/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3955\n",
      "LOG: Epoch [647/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3661\n",
      "    Batch [2/2], Val Loss: 0.0604\n",
      "Epoch [647/2000], Avg Train Loss: 0.3955, Avg Val Loss: 0.2132\n",
      "\n",
      "Validation loss improved from 0.2132 to 0.2132. Saving model...\n",
      "LOG: Epoch [648/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3970\n",
      "LOG: Epoch [648/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3660\n",
      "    Batch [2/2], Val Loss: 0.0603\n",
      "Epoch [648/2000], Avg Train Loss: 0.3970, Avg Val Loss: 0.2132\n",
      "\n",
      "Validation loss improved from 0.2132 to 0.2132. Saving model...\n",
      "LOG: Epoch [649/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4002\n",
      "LOG: Epoch [649/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3660\n",
      "    Batch [2/2], Val Loss: 0.0602\n",
      "Epoch [649/2000], Avg Train Loss: 0.4002, Avg Val Loss: 0.2131\n",
      "\n",
      "Validation loss improved from 0.2132 to 0.2131. Saving model...\n",
      "LOG: Epoch [650/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3948\n",
      "LOG: Epoch [650/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3660\n",
      "    Batch [2/2], Val Loss: 0.0602\n",
      "Epoch [650/2000], Avg Train Loss: 0.3948, Avg Val Loss: 0.2131\n",
      "\n",
      "Validation loss improved from 0.2131 to 0.2131. Saving model...\n",
      "LOG: Epoch [651/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3964\n",
      "LOG: Epoch [651/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3659\n",
      "    Batch [2/2], Val Loss: 0.0601\n",
      "Epoch [651/2000], Avg Train Loss: 0.3964, Avg Val Loss: 0.2130\n",
      "\n",
      "Validation loss improved from 0.2131 to 0.2130. Saving model...\n",
      "LOG: Epoch [652/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3960\n",
      "LOG: Epoch [652/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3658\n",
      "    Batch [2/2], Val Loss: 0.0600\n",
      "Epoch [652/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2129\n",
      "\n",
      "Validation loss improved from 0.2130 to 0.2129. Saving model...\n",
      "LOG: Epoch [653/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3966\n",
      "LOG: Epoch [653/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3658\n",
      "    Batch [2/2], Val Loss: 0.0599\n",
      "Epoch [653/2000], Avg Train Loss: 0.3966, Avg Val Loss: 0.2128\n",
      "\n",
      "Validation loss improved from 0.2129 to 0.2128. Saving model...\n",
      "LOG: Epoch [654/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3962\n",
      "LOG: Epoch [654/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3658\n",
      "    Batch [2/2], Val Loss: 0.0598\n",
      "Epoch [654/2000], Avg Train Loss: 0.3962, Avg Val Loss: 0.2128\n",
      "\n",
      "Validation loss improved from 0.2128 to 0.2128. Saving model...\n",
      "LOG: Epoch [655/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3969\n",
      "LOG: Epoch [655/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3658\n",
      "    Batch [2/2], Val Loss: 0.0597\n",
      "Epoch [655/2000], Avg Train Loss: 0.3969, Avg Val Loss: 0.2128\n",
      "\n",
      "Validation loss improved from 0.2128 to 0.2128. Saving model...\n",
      "LOG: Epoch [656/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3957\n",
      "LOG: Epoch [656/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3658\n",
      "    Batch [2/2], Val Loss: 0.0597\n",
      "Epoch [656/2000], Avg Train Loss: 0.3957, Avg Val Loss: 0.2127\n",
      "\n",
      "Validation loss improved from 0.2128 to 0.2127. Saving model...\n",
      "LOG: Epoch [657/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3990\n",
      "LOG: Epoch [657/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3657\n",
      "    Batch [2/2], Val Loss: 0.0596\n",
      "Epoch [657/2000], Avg Train Loss: 0.3990, Avg Val Loss: 0.2127\n",
      "\n",
      "Validation loss improved from 0.2127 to 0.2127. Saving model...\n",
      "LOG: Epoch [658/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [658/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3657\n",
      "    Batch [2/2], Val Loss: 0.0596\n",
      "Epoch [658/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2126\n",
      "\n",
      "Validation loss improved from 0.2127 to 0.2126. Saving model...\n",
      "LOG: Epoch [659/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3967\n",
      "LOG: Epoch [659/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3656\n",
      "    Batch [2/2], Val Loss: 0.0595\n",
      "Epoch [659/2000], Avg Train Loss: 0.3967, Avg Val Loss: 0.2126\n",
      "\n",
      "Validation loss improved from 0.2126 to 0.2126. Saving model...\n",
      "LOG: Epoch [660/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3986\n",
      "LOG: Epoch [660/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3655\n",
      "    Batch [2/2], Val Loss: 0.0595\n",
      "Epoch [660/2000], Avg Train Loss: 0.3986, Avg Val Loss: 0.2125\n",
      "\n",
      "Validation loss improved from 0.2126 to 0.2125. Saving model...\n",
      "LOG: Epoch [661/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [661/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3655\n",
      "    Batch [2/2], Val Loss: 0.0595\n",
      "Epoch [661/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2125\n",
      "\n",
      "Validation loss improved from 0.2125 to 0.2125. Saving model...\n",
      "LOG: Epoch [662/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3942\n",
      "LOG: Epoch [662/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3655\n",
      "    Batch [2/2], Val Loss: 0.0595\n",
      "Epoch [662/2000], Avg Train Loss: 0.3942, Avg Val Loss: 0.2125\n",
      "\n",
      "Validation loss improved from 0.2125 to 0.2125. Saving model...\n",
      "LOG: Epoch [663/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4007\n",
      "LOG: Epoch [663/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3655\n",
      "    Batch [2/2], Val Loss: 0.0595\n",
      "Epoch [663/2000], Avg Train Loss: 0.4007, Avg Val Loss: 0.2125\n",
      "\n",
      "Validation loss improved from 0.2125 to 0.2125. Saving model...\n",
      "LOG: Epoch [664/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [664/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3655\n",
      "    Batch [2/2], Val Loss: 0.0595\n",
      "Epoch [664/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2125\n",
      "\n",
      "Validation loss improved from 0.2125 to 0.2125. Saving model...\n",
      "LOG: Epoch [665/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3987\n",
      "LOG: Epoch [665/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3655\n",
      "    Batch [2/2], Val Loss: 0.0595\n",
      "Epoch [665/2000], Avg Train Loss: 0.3987, Avg Val Loss: 0.2125\n",
      "\n",
      "Validation loss improved from 0.2125 to 0.2125. Saving model...\n",
      "LOG: Epoch [666/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3993\n",
      "LOG: Epoch [666/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3654\n",
      "    Batch [2/2], Val Loss: 0.0595\n",
      "Epoch [666/2000], Avg Train Loss: 0.3993, Avg Val Loss: 0.2124\n",
      "\n",
      "Validation loss improved from 0.2125 to 0.2124. Saving model...\n",
      "LOG: Epoch [667/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [667/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3653\n",
      "    Batch [2/2], Val Loss: 0.0594\n",
      "Epoch [667/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2124\n",
      "\n",
      "Validation loss improved from 0.2124 to 0.2124. Saving model...\n",
      "LOG: Epoch [668/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3971\n",
      "LOG: Epoch [668/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3652\n",
      "    Batch [2/2], Val Loss: 0.0594\n",
      "Epoch [668/2000], Avg Train Loss: 0.3971, Avg Val Loss: 0.2123\n",
      "\n",
      "Validation loss improved from 0.2124 to 0.2123. Saving model...\n",
      "LOG: Epoch [669/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4005\n",
      "LOG: Epoch [669/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3652\n",
      "    Batch [2/2], Val Loss: 0.0593\n",
      "Epoch [669/2000], Avg Train Loss: 0.4005, Avg Val Loss: 0.2123\n",
      "\n",
      "Validation loss improved from 0.2123 to 0.2123. Saving model...\n",
      "LOG: Epoch [670/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3969\n",
      "LOG: Epoch [670/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3651\n",
      "    Batch [2/2], Val Loss: 0.0593\n",
      "Epoch [670/2000], Avg Train Loss: 0.3969, Avg Val Loss: 0.2122\n",
      "\n",
      "Validation loss improved from 0.2123 to 0.2122. Saving model...\n",
      "LOG: Epoch [671/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3956\n",
      "LOG: Epoch [671/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3650\n",
      "    Batch [2/2], Val Loss: 0.0593\n",
      "Epoch [671/2000], Avg Train Loss: 0.3956, Avg Val Loss: 0.2122\n",
      "\n",
      "Validation loss improved from 0.2122 to 0.2122. Saving model...\n",
      "LOG: Epoch [672/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [672/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3649\n",
      "    Batch [2/2], Val Loss: 0.0593\n",
      "Epoch [672/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2121\n",
      "\n",
      "Validation loss improved from 0.2122 to 0.2121. Saving model...\n",
      "LOG: Epoch [673/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3983\n",
      "LOG: Epoch [673/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3649\n",
      "    Batch [2/2], Val Loss: 0.0592\n",
      "Epoch [673/2000], Avg Train Loss: 0.3983, Avg Val Loss: 0.2120\n",
      "\n",
      "Validation loss improved from 0.2121 to 0.2120. Saving model...\n",
      "LOG: Epoch [674/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3982\n",
      "LOG: Epoch [674/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3648\n",
      "    Batch [2/2], Val Loss: 0.0592\n",
      "Epoch [674/2000], Avg Train Loss: 0.3982, Avg Val Loss: 0.2120\n",
      "\n",
      "Validation loss improved from 0.2120 to 0.2120. Saving model...\n",
      "LOG: Epoch [675/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3974\n",
      "LOG: Epoch [675/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3648\n",
      "    Batch [2/2], Val Loss: 0.0591\n",
      "Epoch [675/2000], Avg Train Loss: 0.3974, Avg Val Loss: 0.2119\n",
      "\n",
      "Validation loss improved from 0.2120 to 0.2119. Saving model...\n",
      "LOG: Epoch [676/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3966\n",
      "LOG: Epoch [676/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3647\n",
      "    Batch [2/2], Val Loss: 0.0591\n",
      "Epoch [676/2000], Avg Train Loss: 0.3966, Avg Val Loss: 0.2119\n",
      "\n",
      "Validation loss improved from 0.2119 to 0.2119. Saving model...\n",
      "LOG: Epoch [677/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3971\n",
      "LOG: Epoch [677/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3646\n",
      "    Batch [2/2], Val Loss: 0.0591\n",
      "Epoch [677/2000], Avg Train Loss: 0.3971, Avg Val Loss: 0.2119\n",
      "\n",
      "Validation loss improved from 0.2119 to 0.2119. Saving model...\n",
      "LOG: Epoch [678/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3944\n",
      "LOG: Epoch [678/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3646\n",
      "    Batch [2/2], Val Loss: 0.0591\n",
      "Epoch [678/2000], Avg Train Loss: 0.3944, Avg Val Loss: 0.2118\n",
      "\n",
      "Validation loss improved from 0.2119 to 0.2118. Saving model...\n",
      "LOG: Epoch [679/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [679/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3645\n",
      "    Batch [2/2], Val Loss: 0.0590\n",
      "Epoch [679/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2118\n",
      "\n",
      "Validation loss improved from 0.2118 to 0.2118. Saving model...\n",
      "LOG: Epoch [680/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [680/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3644\n",
      "    Batch [2/2], Val Loss: 0.0590\n",
      "Epoch [680/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2117\n",
      "\n",
      "Validation loss improved from 0.2118 to 0.2117. Saving model...\n",
      "LOG: Epoch [681/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3950\n",
      "LOG: Epoch [681/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3642\n",
      "    Batch [2/2], Val Loss: 0.0590\n",
      "Epoch [681/2000], Avg Train Loss: 0.3950, Avg Val Loss: 0.2116\n",
      "\n",
      "Validation loss improved from 0.2117 to 0.2116. Saving model...\n",
      "LOG: Epoch [682/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [682/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3641\n",
      "    Batch [2/2], Val Loss: 0.0590\n",
      "Epoch [682/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2115\n",
      "\n",
      "Validation loss improved from 0.2116 to 0.2115. Saving model...\n",
      "LOG: Epoch [683/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3956\n",
      "LOG: Epoch [683/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3640\n",
      "    Batch [2/2], Val Loss: 0.0590\n",
      "Epoch [683/2000], Avg Train Loss: 0.3956, Avg Val Loss: 0.2115\n",
      "\n",
      "Validation loss improved from 0.2115 to 0.2115. Saving model...\n",
      "LOG: Epoch [684/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3946\n",
      "LOG: Epoch [684/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3639\n",
      "    Batch [2/2], Val Loss: 0.0590\n",
      "Epoch [684/2000], Avg Train Loss: 0.3946, Avg Val Loss: 0.2114\n",
      "\n",
      "Validation loss improved from 0.2115 to 0.2114. Saving model...\n",
      "LOG: Epoch [685/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [685/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3638\n",
      "    Batch [2/2], Val Loss: 0.0589\n",
      "Epoch [685/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2114\n",
      "\n",
      "Validation loss improved from 0.2114 to 0.2114. Saving model...\n",
      "LOG: Epoch [686/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3959\n",
      "LOG: Epoch [686/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3637\n",
      "    Batch [2/2], Val Loss: 0.0589\n",
      "Epoch [686/2000], Avg Train Loss: 0.3959, Avg Val Loss: 0.2113\n",
      "\n",
      "Validation loss improved from 0.2114 to 0.2113. Saving model...\n",
      "LOG: Epoch [687/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [687/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3636\n",
      "    Batch [2/2], Val Loss: 0.0589\n",
      "Epoch [687/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2112\n",
      "\n",
      "Validation loss improved from 0.2113 to 0.2112. Saving model...\n",
      "LOG: Epoch [688/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3880\n",
      "LOG: Epoch [688/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3634\n",
      "    Batch [2/2], Val Loss: 0.0588\n",
      "Epoch [688/2000], Avg Train Loss: 0.3880, Avg Val Loss: 0.2111\n",
      "\n",
      "Validation loss improved from 0.2112 to 0.2111. Saving model...\n",
      "LOG: Epoch [689/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [689/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3633\n",
      "    Batch [2/2], Val Loss: 0.0588\n",
      "Epoch [689/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2111\n",
      "\n",
      "Validation loss improved from 0.2111 to 0.2111. Saving model...\n",
      "LOG: Epoch [690/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3985\n",
      "LOG: Epoch [690/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3633\n",
      "    Batch [2/2], Val Loss: 0.0588\n",
      "Epoch [690/2000], Avg Train Loss: 0.3985, Avg Val Loss: 0.2110\n",
      "\n",
      "Validation loss improved from 0.2111 to 0.2110. Saving model...\n",
      "LOG: Epoch [691/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [691/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3632\n",
      "    Batch [2/2], Val Loss: 0.0587\n",
      "Epoch [691/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2110\n",
      "\n",
      "Validation loss improved from 0.2110 to 0.2110. Saving model...\n",
      "LOG: Epoch [692/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3954\n",
      "LOG: Epoch [692/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.0587\n",
      "Epoch [692/2000], Avg Train Loss: 0.3954, Avg Val Loss: 0.2109\n",
      "\n",
      "Validation loss improved from 0.2110 to 0.2109. Saving model...\n",
      "LOG: Epoch [693/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3955\n",
      "LOG: Epoch [693/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.0587\n",
      "Epoch [693/2000], Avg Train Loss: 0.3955, Avg Val Loss: 0.2109\n",
      "\n",
      "Validation loss improved from 0.2109 to 0.2109. Saving model...\n",
      "LOG: Epoch [694/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [694/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.0586\n",
      "Epoch [694/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2109\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [695/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3974\n",
      "LOG: Epoch [695/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3632\n",
      "    Batch [2/2], Val Loss: 0.0586\n",
      "Epoch [695/2000], Avg Train Loss: 0.3974, Avg Val Loss: 0.2109\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [696/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3965\n",
      "LOG: Epoch [696/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3632\n",
      "    Batch [2/2], Val Loss: 0.0586\n",
      "Epoch [696/2000], Avg Train Loss: 0.3965, Avg Val Loss: 0.2109\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [697/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3953\n",
      "LOG: Epoch [697/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3632\n",
      "    Batch [2/2], Val Loss: 0.0585\n",
      "Epoch [697/2000], Avg Train Loss: 0.3953, Avg Val Loss: 0.2109\n",
      "\n",
      "Validation loss improved from 0.2109 to 0.2109. Saving model...\n",
      "LOG: Epoch [698/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3947\n",
      "LOG: Epoch [698/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3632\n",
      "    Batch [2/2], Val Loss: 0.0585\n",
      "Epoch [698/2000], Avg Train Loss: 0.3947, Avg Val Loss: 0.2109\n",
      "\n",
      "Validation loss improved from 0.2109 to 0.2109. Saving model...\n",
      "LOG: Epoch [699/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3934\n",
      "LOG: Epoch [699/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3632\n",
      "    Batch [2/2], Val Loss: 0.0585\n",
      "Epoch [699/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2108\n",
      "\n",
      "Validation loss improved from 0.2109 to 0.2108. Saving model...\n",
      "LOG: Epoch [700/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [700/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.0585\n",
      "Epoch [700/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2108\n",
      "\n",
      "Validation loss improved from 0.2108 to 0.2108. Saving model...\n",
      "LOG: Epoch [701/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3950\n",
      "LOG: Epoch [701/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.0585\n",
      "Epoch [701/2000], Avg Train Loss: 0.3950, Avg Val Loss: 0.2108\n",
      "\n",
      "Validation loss improved from 0.2108 to 0.2108. Saving model...\n",
      "LOG: Epoch [702/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3969\n",
      "LOG: Epoch [702/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.0585\n",
      "Epoch [702/2000], Avg Train Loss: 0.3969, Avg Val Loss: 0.2108\n",
      "\n",
      "Validation loss improved from 0.2108 to 0.2108. Saving model...\n",
      "LOG: Epoch [703/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [703/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.0585\n",
      "Epoch [703/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2108\n",
      "\n",
      "Validation loss improved from 0.2108 to 0.2108. Saving model...\n",
      "LOG: Epoch [704/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3998\n",
      "LOG: Epoch [704/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.0584\n",
      "Epoch [704/2000], Avg Train Loss: 0.3998, Avg Val Loss: 0.2107\n",
      "\n",
      "Validation loss improved from 0.2108 to 0.2107. Saving model...\n",
      "LOG: Epoch [705/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3962\n",
      "LOG: Epoch [705/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.0584\n",
      "Epoch [705/2000], Avg Train Loss: 0.3962, Avg Val Loss: 0.2107\n",
      "\n",
      "Validation loss improved from 0.2107 to 0.2107. Saving model...\n",
      "LOG: Epoch [706/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3948\n",
      "LOG: Epoch [706/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3629\n",
      "    Batch [2/2], Val Loss: 0.0584\n",
      "Epoch [706/2000], Avg Train Loss: 0.3948, Avg Val Loss: 0.2107\n",
      "\n",
      "Validation loss improved from 0.2107 to 0.2107. Saving model...\n",
      "LOG: Epoch [707/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [707/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3628\n",
      "    Batch [2/2], Val Loss: 0.0584\n",
      "Epoch [707/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2106\n",
      "\n",
      "Validation loss improved from 0.2107 to 0.2106. Saving model...\n",
      "LOG: Epoch [708/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3981\n",
      "LOG: Epoch [708/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3628\n",
      "    Batch [2/2], Val Loss: 0.0584\n",
      "Epoch [708/2000], Avg Train Loss: 0.3981, Avg Val Loss: 0.2106\n",
      "\n",
      "Validation loss improved from 0.2106 to 0.2106. Saving model...\n",
      "LOG: Epoch [709/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [709/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3627\n",
      "    Batch [2/2], Val Loss: 0.0584\n",
      "Epoch [709/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2105\n",
      "\n",
      "Validation loss improved from 0.2106 to 0.2105. Saving model...\n",
      "LOG: Epoch [710/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3949\n",
      "LOG: Epoch [710/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3627\n",
      "    Batch [2/2], Val Loss: 0.0584\n",
      "Epoch [710/2000], Avg Train Loss: 0.3949, Avg Val Loss: 0.2105\n",
      "\n",
      "Validation loss improved from 0.2105 to 0.2105. Saving model...\n",
      "LOG: Epoch [711/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3952\n",
      "LOG: Epoch [711/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3626\n",
      "    Batch [2/2], Val Loss: 0.0583\n",
      "Epoch [711/2000], Avg Train Loss: 0.3952, Avg Val Loss: 0.2105\n",
      "\n",
      "Validation loss improved from 0.2105 to 0.2105. Saving model...\n",
      "LOG: Epoch [712/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [712/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3625\n",
      "    Batch [2/2], Val Loss: 0.0583\n",
      "Epoch [712/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2104\n",
      "\n",
      "Validation loss improved from 0.2105 to 0.2104. Saving model...\n",
      "LOG: Epoch [713/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [713/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0583\n",
      "Epoch [713/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2103\n",
      "\n",
      "Validation loss improved from 0.2104 to 0.2103. Saving model...\n",
      "LOG: Epoch [714/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3878\n",
      "LOG: Epoch [714/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0582\n",
      "Epoch [714/2000], Avg Train Loss: 0.3878, Avg Val Loss: 0.2103\n",
      "\n",
      "Validation loss improved from 0.2103 to 0.2103. Saving model...\n",
      "LOG: Epoch [715/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3942\n",
      "LOG: Epoch [715/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3622\n",
      "    Batch [2/2], Val Loss: 0.0582\n",
      "Epoch [715/2000], Avg Train Loss: 0.3942, Avg Val Loss: 0.2102\n",
      "\n",
      "Validation loss improved from 0.2103 to 0.2102. Saving model...\n",
      "LOG: Epoch [716/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [716/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3622\n",
      "    Batch [2/2], Val Loss: 0.0582\n",
      "Epoch [716/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2102\n",
      "\n",
      "Validation loss improved from 0.2102 to 0.2102. Saving model...\n",
      "LOG: Epoch [717/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3956\n",
      "LOG: Epoch [717/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3622\n",
      "    Batch [2/2], Val Loss: 0.0582\n",
      "Epoch [717/2000], Avg Train Loss: 0.3956, Avg Val Loss: 0.2102\n",
      "\n",
      "Validation loss improved from 0.2102 to 0.2102. Saving model...\n",
      "LOG: Epoch [718/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3959\n",
      "LOG: Epoch [718/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0581\n",
      "Epoch [718/2000], Avg Train Loss: 0.3959, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [719/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3966\n",
      "LOG: Epoch [719/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0581\n",
      "Epoch [719/2000], Avg Train Loss: 0.3966, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [720/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3965\n",
      "LOG: Epoch [720/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0581\n",
      "Epoch [720/2000], Avg Train Loss: 0.3965, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [721/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [721/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0581\n",
      "Epoch [721/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [722/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [722/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0581\n",
      "Epoch [722/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [723/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3887\n",
      "LOG: Epoch [723/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0580\n",
      "Epoch [723/2000], Avg Train Loss: 0.3887, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [724/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [724/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0580\n",
      "Epoch [724/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [725/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [725/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0580\n",
      "Epoch [725/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [726/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3876\n",
      "LOG: Epoch [726/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3625\n",
      "    Batch [2/2], Val Loss: 0.0580\n",
      "Epoch [726/2000], Avg Train Loss: 0.3876, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [727/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [727/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3625\n",
      "    Batch [2/2], Val Loss: 0.0580\n",
      "Epoch [727/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [728/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3982\n",
      "LOG: Epoch [728/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0580\n",
      "Epoch [728/2000], Avg Train Loss: 0.3982, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [729/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3946\n",
      "LOG: Epoch [729/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0581\n",
      "Epoch [729/2000], Avg Train Loss: 0.3946, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [730/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3947\n",
      "LOG: Epoch [730/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0581\n",
      "Epoch [730/2000], Avg Train Loss: 0.3947, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [731/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [731/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0581\n",
      "Epoch [731/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [732/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3972\n",
      "LOG: Epoch [732/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0581\n",
      "Epoch [732/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [733/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [733/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0581\n",
      "Epoch [733/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [734/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3880\n",
      "LOG: Epoch [734/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0581\n",
      "Epoch [734/2000], Avg Train Loss: 0.3880, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [735/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3992\n",
      "LOG: Epoch [735/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0581\n",
      "Epoch [735/2000], Avg Train Loss: 0.3992, Avg Val Loss: 0.2103\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [736/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [736/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0581\n",
      "Epoch [736/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2103\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [737/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [737/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0581\n",
      "Epoch [737/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [738/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [738/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3625\n",
      "    Batch [2/2], Val Loss: 0.0580\n",
      "Epoch [738/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [739/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [739/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0580\n",
      "Epoch [739/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [740/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3942\n",
      "LOG: Epoch [740/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0580\n",
      "Epoch [740/2000], Avg Train Loss: 0.3942, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [741/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3968\n",
      "LOG: Epoch [741/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0579\n",
      "Epoch [741/2000], Avg Train Loss: 0.3968, Avg Val Loss: 0.2102\n",
      "\n",
      "Validation loss improved from 0.2102 to 0.2102. Saving model...\n",
      "LOG: Epoch [742/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [742/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0579\n",
      "Epoch [742/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2102\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [743/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [743/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0579\n",
      "Epoch [743/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2102\n",
      "\n",
      "Validation loss improved from 0.2102 to 0.2102. Saving model...\n",
      "LOG: Epoch [744/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [744/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0578\n",
      "Epoch [744/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2101\n",
      "\n",
      "Validation loss improved from 0.2102 to 0.2101. Saving model...\n",
      "LOG: Epoch [745/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [745/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3622\n",
      "    Batch [2/2], Val Loss: 0.0577\n",
      "Epoch [745/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2100\n",
      "\n",
      "Validation loss improved from 0.2101 to 0.2100. Saving model...\n",
      "LOG: Epoch [746/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3955\n",
      "LOG: Epoch [746/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3621\n",
      "    Batch [2/2], Val Loss: 0.0577\n",
      "Epoch [746/2000], Avg Train Loss: 0.3955, Avg Val Loss: 0.2099\n",
      "\n",
      "Validation loss improved from 0.2100 to 0.2099. Saving model...\n",
      "LOG: Epoch [747/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [747/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3620\n",
      "    Batch [2/2], Val Loss: 0.0576\n",
      "Epoch [747/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2098\n",
      "\n",
      "Validation loss improved from 0.2099 to 0.2098. Saving model...\n",
      "LOG: Epoch [748/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [748/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3619\n",
      "    Batch [2/2], Val Loss: 0.0576\n",
      "Epoch [748/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2098\n",
      "\n",
      "Validation loss improved from 0.2098 to 0.2098. Saving model...\n",
      "LOG: Epoch [749/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3965\n",
      "LOG: Epoch [749/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3618\n",
      "    Batch [2/2], Val Loss: 0.0576\n",
      "Epoch [749/2000], Avg Train Loss: 0.3965, Avg Val Loss: 0.2097\n",
      "\n",
      "Validation loss improved from 0.2098 to 0.2097. Saving model...\n",
      "LOG: Epoch [750/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3957\n",
      "LOG: Epoch [750/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3618\n",
      "    Batch [2/2], Val Loss: 0.0575\n",
      "Epoch [750/2000], Avg Train Loss: 0.3957, Avg Val Loss: 0.2097\n",
      "\n",
      "Validation loss improved from 0.2097 to 0.2097. Saving model...\n",
      "LOG: Epoch [751/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [751/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3617\n",
      "    Batch [2/2], Val Loss: 0.0575\n",
      "Epoch [751/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2096\n",
      "\n",
      "Validation loss improved from 0.2097 to 0.2096. Saving model...\n",
      "LOG: Epoch [752/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [752/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3617\n",
      "    Batch [2/2], Val Loss: 0.0575\n",
      "Epoch [752/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2096\n",
      "\n",
      "Validation loss improved from 0.2096 to 0.2096. Saving model...\n",
      "LOG: Epoch [753/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [753/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3617\n",
      "    Batch [2/2], Val Loss: 0.0574\n",
      "Epoch [753/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2095\n",
      "\n",
      "Validation loss improved from 0.2096 to 0.2095. Saving model...\n",
      "LOG: Epoch [754/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3924\n",
      "LOG: Epoch [754/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3616\n",
      "    Batch [2/2], Val Loss: 0.0574\n",
      "Epoch [754/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2095\n",
      "\n",
      "Validation loss improved from 0.2095 to 0.2095. Saving model...\n",
      "LOG: Epoch [755/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3894\n",
      "LOG: Epoch [755/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3616\n",
      "    Batch [2/2], Val Loss: 0.0574\n",
      "Epoch [755/2000], Avg Train Loss: 0.3894, Avg Val Loss: 0.2095\n",
      "\n",
      "Validation loss improved from 0.2095 to 0.2095. Saving model...\n",
      "LOG: Epoch [756/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [756/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3616\n",
      "    Batch [2/2], Val Loss: 0.0574\n",
      "Epoch [756/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2095\n",
      "\n",
      "Validation loss improved from 0.2095 to 0.2095. Saving model...\n",
      "LOG: Epoch [757/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [757/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3615\n",
      "    Batch [2/2], Val Loss: 0.0574\n",
      "Epoch [757/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2095\n",
      "\n",
      "Validation loss improved from 0.2095 to 0.2095. Saving model...\n",
      "LOG: Epoch [758/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3972\n",
      "LOG: Epoch [758/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3615\n",
      "    Batch [2/2], Val Loss: 0.0574\n",
      "Epoch [758/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2094\n",
      "\n",
      "Validation loss improved from 0.2095 to 0.2094. Saving model...\n",
      "LOG: Epoch [759/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [759/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3615\n",
      "    Batch [2/2], Val Loss: 0.0574\n",
      "Epoch [759/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2094\n",
      "\n",
      "Validation loss improved from 0.2094 to 0.2094. Saving model...\n",
      "LOG: Epoch [760/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3936\n",
      "LOG: Epoch [760/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3615\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [760/2000], Avg Train Loss: 0.3936, Avg Val Loss: 0.2094\n",
      "\n",
      "Validation loss improved from 0.2094 to 0.2094. Saving model...\n",
      "LOG: Epoch [761/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3943\n",
      "LOG: Epoch [761/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [761/2000], Avg Train Loss: 0.3943, Avg Val Loss: 0.2094\n",
      "\n",
      "Validation loss improved from 0.2094 to 0.2094. Saving model...\n",
      "LOG: Epoch [762/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [762/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [762/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2094\n",
      "\n",
      "Validation loss improved from 0.2094 to 0.2094. Saving model...\n",
      "LOG: Epoch [763/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [763/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [763/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2094\n",
      "\n",
      "Validation loss improved from 0.2094 to 0.2094. Saving model...\n",
      "LOG: Epoch [764/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [764/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [764/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2094\n",
      "\n",
      "Validation loss improved from 0.2094 to 0.2094. Saving model...\n",
      "LOG: Epoch [765/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [765/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [765/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2094 to 0.2093. Saving model...\n",
      "LOG: Epoch [766/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [766/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [766/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [767/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3943\n",
      "LOG: Epoch [767/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [767/2000], Avg Train Loss: 0.3943, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [768/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [768/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [768/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [769/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3924\n",
      "LOG: Epoch [769/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [769/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [770/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3888\n",
      "LOG: Epoch [770/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [770/2000], Avg Train Loss: 0.3888, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [771/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [771/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [771/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [772/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3888\n",
      "LOG: Epoch [772/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [772/2000], Avg Train Loss: 0.3888, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [773/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [773/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [773/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [774/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3954\n",
      "LOG: Epoch [774/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [774/2000], Avg Train Loss: 0.3954, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [775/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [775/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [775/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [776/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [776/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [776/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [777/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3944\n",
      "LOG: Epoch [777/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [777/2000], Avg Train Loss: 0.3944, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [778/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3918\n",
      "LOG: Epoch [778/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [778/2000], Avg Train Loss: 0.3918, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [779/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [779/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [779/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [780/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3985\n",
      "LOG: Epoch [780/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [780/2000], Avg Train Loss: 0.3985, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [781/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3944\n",
      "LOG: Epoch [781/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [781/2000], Avg Train Loss: 0.3944, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [782/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [782/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [782/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [783/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [783/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [783/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [784/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3886\n",
      "LOG: Epoch [784/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [784/2000], Avg Train Loss: 0.3886, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [785/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [785/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [785/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2093\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2093. Saving model...\n",
      "LOG: Epoch [786/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [786/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.0573\n",
      "Epoch [786/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2093 to 0.2092. Saving model...\n",
      "LOG: Epoch [787/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3952\n",
      "LOG: Epoch [787/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [787/2000], Avg Train Loss: 0.3952, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [788/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [788/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [788/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [789/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3985\n",
      "LOG: Epoch [789/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [789/2000], Avg Train Loss: 0.3985, Avg Val Loss: 0.2092\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [790/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3889\n",
      "LOG: Epoch [790/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [790/2000], Avg Train Loss: 0.3889, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [791/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3940\n",
      "LOG: Epoch [791/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [791/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2092\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [792/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [792/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [792/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2092\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [793/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [793/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [793/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2093\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [794/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [794/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [794/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2093\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [795/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [795/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [795/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2093\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [796/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [796/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [796/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2093\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [797/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3940\n",
      "LOG: Epoch [797/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [797/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2093\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [798/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [798/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [798/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2093\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [799/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [799/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [799/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2093\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [800/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3940\n",
      "LOG: Epoch [800/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [800/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2093\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [801/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3944\n",
      "LOG: Epoch [801/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [801/2000], Avg Train Loss: 0.3944, Avg Val Loss: 0.2093\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [802/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3924\n",
      "LOG: Epoch [802/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [802/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2093\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [803/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [803/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [803/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2092\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [804/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3889\n",
      "LOG: Epoch [804/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [804/2000], Avg Train Loss: 0.3889, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [805/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [805/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [805/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [806/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [806/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0572\n",
      "Epoch [806/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [807/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [807/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [807/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [808/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3980\n",
      "LOG: Epoch [808/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [808/2000], Avg Train Loss: 0.3980, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [809/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3924\n",
      "LOG: Epoch [809/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [809/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [810/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [810/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [810/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [811/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [811/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [811/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [812/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [812/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [812/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [813/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3948\n",
      "LOG: Epoch [813/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [813/2000], Avg Train Loss: 0.3948, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [814/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3949\n",
      "LOG: Epoch [814/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [814/2000], Avg Train Loss: 0.3949, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [815/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3920\n",
      "LOG: Epoch [815/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [815/2000], Avg Train Loss: 0.3920, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [816/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [816/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [816/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [817/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3865\n",
      "LOG: Epoch [817/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [817/2000], Avg Train Loss: 0.3865, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [818/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [818/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [818/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [819/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [819/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [819/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [820/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [820/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [820/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2092\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2092. Saving model...\n",
      "LOG: Epoch [821/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [821/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [821/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2092 to 0.2091. Saving model...\n",
      "LOG: Epoch [822/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [822/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [822/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [823/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3946\n",
      "LOG: Epoch [823/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [823/2000], Avg Train Loss: 0.3946, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [824/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3878\n",
      "LOG: Epoch [824/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [824/2000], Avg Train Loss: 0.3878, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [825/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [825/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [825/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [826/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3960\n",
      "LOG: Epoch [826/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [826/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [827/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [827/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [827/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [828/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [828/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [828/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [829/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [829/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [829/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [830/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3883\n",
      "LOG: Epoch [830/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [830/2000], Avg Train Loss: 0.3883, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [831/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [831/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [831/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [832/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3950\n",
      "LOG: Epoch [832/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [832/2000], Avg Train Loss: 0.3950, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [833/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [833/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [833/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [834/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [834/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [834/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [835/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3898\n",
      "LOG: Epoch [835/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [835/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [836/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [836/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [836/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [837/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3883\n",
      "LOG: Epoch [837/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [837/2000], Avg Train Loss: 0.3883, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [838/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3887\n",
      "LOG: Epoch [838/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [838/2000], Avg Train Loss: 0.3887, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [839/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3960\n",
      "LOG: Epoch [839/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [839/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [840/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [840/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [840/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [841/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [841/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [841/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [842/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [842/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [842/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [843/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3952\n",
      "LOG: Epoch [843/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [843/2000], Avg Train Loss: 0.3952, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [844/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3940\n",
      "LOG: Epoch [844/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [844/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [845/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3946\n",
      "LOG: Epoch [845/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [845/2000], Avg Train Loss: 0.3946, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [846/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [846/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [846/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [847/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [847/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [847/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [848/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [848/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [848/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [849/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [849/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [849/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [850/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3946\n",
      "LOG: Epoch [850/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [850/2000], Avg Train Loss: 0.3946, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [851/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [851/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [851/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [852/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3957\n",
      "LOG: Epoch [852/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [852/2000], Avg Train Loss: 0.3957, Avg Val Loss: 0.2091\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2091. Saving model...\n",
      "LOG: Epoch [853/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [853/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [853/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2091 to 0.2090. Saving model...\n",
      "LOG: Epoch [854/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [854/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [854/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2091\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [855/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [855/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [855/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2090\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [856/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3877\n",
      "LOG: Epoch [856/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [856/2000], Avg Train Loss: 0.3877, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [857/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [857/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [857/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [858/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [858/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [858/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [859/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3924\n",
      "LOG: Epoch [859/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [859/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [860/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [860/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [860/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [861/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [861/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [861/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [862/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3883\n",
      "LOG: Epoch [862/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [862/2000], Avg Train Loss: 0.3883, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [863/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3897\n",
      "LOG: Epoch [863/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [863/2000], Avg Train Loss: 0.3897, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [864/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [864/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [864/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [865/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [865/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [865/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [866/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3967\n",
      "LOG: Epoch [866/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [866/2000], Avg Train Loss: 0.3967, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [867/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [867/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [867/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [868/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [868/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [868/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [869/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [869/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [869/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [870/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [870/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [870/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [871/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [871/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [871/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [872/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3936\n",
      "LOG: Epoch [872/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [872/2000], Avg Train Loss: 0.3936, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [873/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [873/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [873/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [874/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3878\n",
      "LOG: Epoch [874/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [874/2000], Avg Train Loss: 0.3878, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [875/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [875/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [875/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [876/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [876/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [876/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [877/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [877/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [877/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [878/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [878/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [878/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [879/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [879/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [879/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [880/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3964\n",
      "LOG: Epoch [880/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0571\n",
      "Epoch [880/2000], Avg Train Loss: 0.3964, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [881/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [881/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [881/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [882/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [882/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [882/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [883/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [883/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [883/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [884/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [884/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [884/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [885/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [885/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [885/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2090\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2090. Saving model...\n",
      "LOG: Epoch [886/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3916\n",
      "LOG: Epoch [886/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [886/2000], Avg Train Loss: 0.3916, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2090 to 0.2089. Saving model...\n",
      "LOG: Epoch [887/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3958\n",
      "LOG: Epoch [887/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [887/2000], Avg Train Loss: 0.3958, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [888/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [888/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [888/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [889/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [889/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [889/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [890/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [890/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [890/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [891/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3947\n",
      "LOG: Epoch [891/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [891/2000], Avg Train Loss: 0.3947, Avg Val Loss: 0.2089\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [892/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [892/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [892/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [893/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [893/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [893/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [894/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [894/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [894/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2089\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [895/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3960\n",
      "LOG: Epoch [895/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [895/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2089\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [896/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3874\n",
      "LOG: Epoch [896/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [896/2000], Avg Train Loss: 0.3874, Avg Val Loss: 0.2089\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [897/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [897/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [897/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [898/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3918\n",
      "LOG: Epoch [898/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [898/2000], Avg Train Loss: 0.3918, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [899/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3883\n",
      "LOG: Epoch [899/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [899/2000], Avg Train Loss: 0.3883, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [900/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3881\n",
      "LOG: Epoch [900/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [900/2000], Avg Train Loss: 0.3881, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [901/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [901/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [901/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [902/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [902/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [902/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [903/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3940\n",
      "LOG: Epoch [903/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [903/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [904/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [904/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [904/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [905/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3916\n",
      "LOG: Epoch [905/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [905/2000], Avg Train Loss: 0.3916, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [906/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3940\n",
      "LOG: Epoch [906/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [906/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [907/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [907/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [907/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2089\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [908/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3947\n",
      "LOG: Epoch [908/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [908/2000], Avg Train Loss: 0.3947, Avg Val Loss: 0.2089\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [909/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3876\n",
      "LOG: Epoch [909/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [909/2000], Avg Train Loss: 0.3876, Avg Val Loss: 0.2089\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [910/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [910/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [910/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2089\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [911/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [911/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [911/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [912/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3897\n",
      "LOG: Epoch [912/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [912/2000], Avg Train Loss: 0.3897, Avg Val Loss: 0.2089\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [913/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [913/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [913/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [914/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [914/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [914/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [915/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [915/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [915/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [916/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [916/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [916/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [917/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [917/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [917/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [918/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [918/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [918/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [919/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [919/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [919/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [920/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3890\n",
      "LOG: Epoch [920/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [920/2000], Avg Train Loss: 0.3890, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [921/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [921/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [921/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [922/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [922/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [922/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [923/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [923/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [923/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [924/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3871\n",
      "LOG: Epoch [924/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [924/2000], Avg Train Loss: 0.3871, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [925/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3871\n",
      "LOG: Epoch [925/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [925/2000], Avg Train Loss: 0.3871, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [926/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [926/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [926/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [927/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [927/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [927/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [928/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3953\n",
      "LOG: Epoch [928/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [928/2000], Avg Train Loss: 0.3953, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [929/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3964\n",
      "LOG: Epoch [929/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [929/2000], Avg Train Loss: 0.3964, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [930/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3955\n",
      "LOG: Epoch [930/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [930/2000], Avg Train Loss: 0.3955, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [931/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3944\n",
      "LOG: Epoch [931/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.0570\n",
      "Epoch [931/2000], Avg Train Loss: 0.3944, Avg Val Loss: 0.2089\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2089. Saving model...\n",
      "LOG: Epoch [932/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3934\n",
      "LOG: Epoch [932/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [932/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2088\n",
      "\n",
      "Validation loss improved from 0.2089 to 0.2088. Saving model...\n",
      "LOG: Epoch [933/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3852\n",
      "LOG: Epoch [933/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [933/2000], Avg Train Loss: 0.3852, Avg Val Loss: 0.2088\n",
      "\n",
      "Validation loss improved from 0.2088 to 0.2088. Saving model...\n",
      "LOG: Epoch [934/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [934/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [934/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2088\n",
      "\n",
      "Validation loss improved from 0.2088 to 0.2088. Saving model...\n",
      "LOG: Epoch [935/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [935/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [935/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2088\n",
      "\n",
      "Validation loss improved from 0.2088 to 0.2088. Saving model...\n",
      "LOG: Epoch [936/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [936/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [936/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2088\n",
      "\n",
      "Validation loss improved from 0.2088 to 0.2088. Saving model...\n",
      "LOG: Epoch [937/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3950\n",
      "LOG: Epoch [937/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [937/2000], Avg Train Loss: 0.3950, Avg Val Loss: 0.2088\n",
      "\n",
      "Validation loss improved from 0.2088 to 0.2088. Saving model...\n",
      "LOG: Epoch [938/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3981\n",
      "LOG: Epoch [938/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [938/2000], Avg Train Loss: 0.3981, Avg Val Loss: 0.2088\n",
      "\n",
      "Validation loss improved from 0.2088 to 0.2088. Saving model...\n",
      "LOG: Epoch [939/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3957\n",
      "LOG: Epoch [939/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [939/2000], Avg Train Loss: 0.3957, Avg Val Loss: 0.2088\n",
      "\n",
      "Validation loss improved from 0.2088 to 0.2088. Saving model...\n",
      "LOG: Epoch [940/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3944\n",
      "LOG: Epoch [940/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [940/2000], Avg Train Loss: 0.3944, Avg Val Loss: 0.2088\n",
      "\n",
      "Validation loss improved from 0.2088 to 0.2088. Saving model...\n",
      "LOG: Epoch [941/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3924\n",
      "LOG: Epoch [941/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [941/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2088\n",
      "\n",
      "Validation loss improved from 0.2088 to 0.2088. Saving model...\n",
      "LOG: Epoch [942/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [942/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [942/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2088\n",
      "\n",
      "Validation loss improved from 0.2088 to 0.2088. Saving model...\n",
      "LOG: Epoch [943/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [943/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [943/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2088\n",
      "\n",
      "Validation loss improved from 0.2088 to 0.2088. Saving model...\n",
      "LOG: Epoch [944/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [944/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [944/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2088 to 0.2087. Saving model...\n",
      "LOG: Epoch [945/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [945/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [945/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [946/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [946/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [946/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [947/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3871\n",
      "LOG: Epoch [947/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [947/2000], Avg Train Loss: 0.3871, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [948/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [948/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [948/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [949/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [949/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [949/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [950/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3875\n",
      "LOG: Epoch [950/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [950/2000], Avg Train Loss: 0.3875, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [951/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [951/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [951/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [952/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [952/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [952/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [953/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3950\n",
      "LOG: Epoch [953/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [953/2000], Avg Train Loss: 0.3950, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [954/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [954/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [954/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [955/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [955/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [955/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [956/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [956/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [956/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [957/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [957/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [957/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [958/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [958/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [958/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [959/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [959/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [959/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [960/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3948\n",
      "LOG: Epoch [960/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [960/2000], Avg Train Loss: 0.3948, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [961/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [961/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [961/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [962/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3971\n",
      "LOG: Epoch [962/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [962/2000], Avg Train Loss: 0.3971, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [963/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3889\n",
      "LOG: Epoch [963/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [963/2000], Avg Train Loss: 0.3889, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [964/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3879\n",
      "LOG: Epoch [964/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [964/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [965/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [965/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [965/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [966/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [966/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [966/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [967/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [967/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [967/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [968/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3897\n",
      "LOG: Epoch [968/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [968/2000], Avg Train Loss: 0.3897, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [969/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [969/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [969/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [970/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3948\n",
      "LOG: Epoch [970/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [970/2000], Avg Train Loss: 0.3948, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [971/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [971/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [971/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [972/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3888\n",
      "LOG: Epoch [972/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [972/2000], Avg Train Loss: 0.3888, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [973/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [973/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [973/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [974/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3942\n",
      "LOG: Epoch [974/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [974/2000], Avg Train Loss: 0.3942, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [975/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [975/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [975/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [976/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3962\n",
      "LOG: Epoch [976/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [976/2000], Avg Train Loss: 0.3962, Avg Val Loss: 0.2087\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [977/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3920\n",
      "LOG: Epoch [977/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [977/2000], Avg Train Loss: 0.3920, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [978/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [978/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [978/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [979/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [979/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0569\n",
      "Epoch [979/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [980/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3970\n",
      "LOG: Epoch [980/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [980/2000], Avg Train Loss: 0.3970, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [981/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [981/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [981/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [982/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [982/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [982/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [983/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3898\n",
      "LOG: Epoch [983/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [983/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [984/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3946\n",
      "LOG: Epoch [984/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [984/2000], Avg Train Loss: 0.3946, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [985/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [985/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [985/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [986/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [986/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [986/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [987/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [987/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [987/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [988/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [988/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [988/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [989/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3854\n",
      "LOG: Epoch [989/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [989/2000], Avg Train Loss: 0.3854, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [990/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [990/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [990/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [991/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [991/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [991/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [992/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [992/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [992/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [993/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [993/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [993/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [994/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [994/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [994/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [995/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [995/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [995/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [996/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3934\n",
      "LOG: Epoch [996/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [996/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [997/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [997/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [997/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [998/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3868\n",
      "LOG: Epoch [998/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [998/2000], Avg Train Loss: 0.3868, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [999/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [999/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [999/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [1000/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [1000/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1000/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [1001/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [1001/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1001/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [1002/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1002/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1002/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [1003/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1003/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1003/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [1004/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1004/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1004/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [1005/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3920\n",
      "LOG: Epoch [1005/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1005/2000], Avg Train Loss: 0.3920, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [1006/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3965\n",
      "LOG: Epoch [1006/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1006/2000], Avg Train Loss: 0.3965, Avg Val Loss: 0.2087\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2087. Saving model...\n",
      "LOG: Epoch [1007/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [1007/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1007/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2087 to 0.2086. Saving model...\n",
      "LOG: Epoch [1008/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [1008/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1008/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1009/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1009/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1009/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1010/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3916\n",
      "LOG: Epoch [1010/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1010/2000], Avg Train Loss: 0.3916, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1011/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1011/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1011/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1012/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [1012/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1012/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1013/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1013/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1013/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1014/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [1014/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1014/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1015/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1015/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1015/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1016/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3886\n",
      "LOG: Epoch [1016/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1016/2000], Avg Train Loss: 0.3886, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1017/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1017/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1017/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1018/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1018/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1018/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1019/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1019/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1019/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1020/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [1020/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1020/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1021/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3956\n",
      "LOG: Epoch [1021/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1021/2000], Avg Train Loss: 0.3956, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1022/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3876\n",
      "LOG: Epoch [1022/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1022/2000], Avg Train Loss: 0.3876, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1023/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [1023/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1023/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1024/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3936\n",
      "LOG: Epoch [1024/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1024/2000], Avg Train Loss: 0.3936, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1025/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1025/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1025/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1026/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3875\n",
      "LOG: Epoch [1026/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1026/2000], Avg Train Loss: 0.3875, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1027/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3920\n",
      "LOG: Epoch [1027/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1027/2000], Avg Train Loss: 0.3920, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1028/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [1028/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1028/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1029/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3920\n",
      "LOG: Epoch [1029/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1029/2000], Avg Train Loss: 0.3920, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1030/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3890\n",
      "LOG: Epoch [1030/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1030/2000], Avg Train Loss: 0.3890, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1031/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [1031/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1031/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1032/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1032/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1032/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1033/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1033/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1033/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1034/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1034/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1034/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1035/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [1035/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1035/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1036/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [1036/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1036/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1037/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1037/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1037/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1038/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [1038/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1038/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1039/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3963\n",
      "LOG: Epoch [1039/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1039/2000], Avg Train Loss: 0.3963, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1040/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1040/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1040/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1041/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3942\n",
      "LOG: Epoch [1041/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1041/2000], Avg Train Loss: 0.3942, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1042/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3943\n",
      "LOG: Epoch [1042/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1042/2000], Avg Train Loss: 0.3943, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1043/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [1043/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1043/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1044/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3920\n",
      "LOG: Epoch [1044/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1044/2000], Avg Train Loss: 0.3920, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1045/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [1045/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1045/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1046/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3968\n",
      "LOG: Epoch [1046/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1046/2000], Avg Train Loss: 0.3968, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1047/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3867\n",
      "LOG: Epoch [1047/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1047/2000], Avg Train Loss: 0.3867, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1048/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3877\n",
      "LOG: Epoch [1048/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1048/2000], Avg Train Loss: 0.3877, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1049/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3886\n",
      "LOG: Epoch [1049/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1049/2000], Avg Train Loss: 0.3886, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1050/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [1050/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1050/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1051/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1051/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1051/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1052/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1052/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1052/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1053/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3889\n",
      "LOG: Epoch [1053/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1053/2000], Avg Train Loss: 0.3889, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1054/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [1054/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1054/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1055/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3981\n",
      "LOG: Epoch [1055/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1055/2000], Avg Train Loss: 0.3981, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1056/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [1056/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1056/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1057/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [1057/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1057/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1058/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3978\n",
      "LOG: Epoch [1058/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1058/2000], Avg Train Loss: 0.3978, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1059/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1059/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1059/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1060/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [1060/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1060/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1061/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1061/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1061/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1062/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3940\n",
      "LOG: Epoch [1062/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1062/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1063/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1063/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1063/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1064/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3946\n",
      "LOG: Epoch [1064/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1064/2000], Avg Train Loss: 0.3946, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1065/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3963\n",
      "LOG: Epoch [1065/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1065/2000], Avg Train Loss: 0.3963, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1066/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [1066/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1066/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1067/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [1067/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1067/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1068/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [1068/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1068/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1069/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1069/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1069/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1070/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [1070/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1070/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1071/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [1071/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1071/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1072/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [1072/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1072/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1073/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1073/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1073/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1074/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [1074/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1074/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1075/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [1075/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1075/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1076/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3878\n",
      "LOG: Epoch [1076/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1076/2000], Avg Train Loss: 0.3878, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1077/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3942\n",
      "LOG: Epoch [1077/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1077/2000], Avg Train Loss: 0.3942, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1078/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [1078/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1078/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1079/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1079/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1079/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1080/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1080/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1080/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1081/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3869\n",
      "LOG: Epoch [1081/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1081/2000], Avg Train Loss: 0.3869, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1082/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3940\n",
      "LOG: Epoch [1082/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1082/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1083/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1083/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1083/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1084/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3936\n",
      "LOG: Epoch [1084/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1084/2000], Avg Train Loss: 0.3936, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1085/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [1085/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1085/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1086/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [1086/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1086/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1087/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [1087/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1087/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1088/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [1088/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1088/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1089/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1089/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1089/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1090/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1090/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1090/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1091/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1091/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1091/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1092/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3884\n",
      "LOG: Epoch [1092/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1092/2000], Avg Train Loss: 0.3884, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1093/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1093/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1093/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1094/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [1094/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1094/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1095/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3954\n",
      "LOG: Epoch [1095/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1095/2000], Avg Train Loss: 0.3954, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1096/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [1096/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1096/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1097/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3956\n",
      "LOG: Epoch [1097/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1097/2000], Avg Train Loss: 0.3956, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1098/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1098/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1098/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1099/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3954\n",
      "LOG: Epoch [1099/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1099/2000], Avg Train Loss: 0.3954, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1100/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [1100/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1100/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1101/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [1101/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1101/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1102/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3882\n",
      "LOG: Epoch [1102/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1102/2000], Avg Train Loss: 0.3882, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1103/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [1103/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1103/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1104/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3948\n",
      "LOG: Epoch [1104/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1104/2000], Avg Train Loss: 0.3948, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1105/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3875\n",
      "LOG: Epoch [1105/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1105/2000], Avg Train Loss: 0.3875, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1106/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1106/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1106/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1107/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [1107/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1107/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1108/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [1108/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1108/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1109/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1109/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1109/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1110/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3965\n",
      "LOG: Epoch [1110/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1110/2000], Avg Train Loss: 0.3965, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1111/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [1111/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1111/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1112/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1112/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1112/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1113/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1113/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1113/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1114/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3979\n",
      "LOG: Epoch [1114/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1114/2000], Avg Train Loss: 0.3979, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1115/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3955\n",
      "LOG: Epoch [1115/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1115/2000], Avg Train Loss: 0.3955, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1116/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [1116/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1116/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1117/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [1117/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1117/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1118/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [1118/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1118/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1119/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1119/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1119/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [1120/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1120/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1121/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3949\n",
      "LOG: Epoch [1121/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1121/2000], Avg Train Loss: 0.3949, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1122/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1122/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1122/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1123/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3958\n",
      "LOG: Epoch [1123/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1123/2000], Avg Train Loss: 0.3958, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1124/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [1124/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1124/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1125/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3942\n",
      "LOG: Epoch [1125/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1125/2000], Avg Train Loss: 0.3942, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1126/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1126/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1127/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3882\n",
      "LOG: Epoch [1127/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1127/2000], Avg Train Loss: 0.3882, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1128/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1128/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1128/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1129/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1129/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1129/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1130/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3918\n",
      "LOG: Epoch [1130/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1130/2000], Avg Train Loss: 0.3918, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1131/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3975\n",
      "LOG: Epoch [1131/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1131/2000], Avg Train Loss: 0.3975, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1132/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [1132/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1132/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1133/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1133/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1133/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1134/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3881\n",
      "LOG: Epoch [1134/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1134/2000], Avg Train Loss: 0.3881, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1135/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1135/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1135/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1136/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1136/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1136/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1137/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1137/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1137/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1138/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3940\n",
      "LOG: Epoch [1138/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1138/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1139/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3872\n",
      "LOG: Epoch [1139/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1139/2000], Avg Train Loss: 0.3872, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1140/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1140/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1140/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1141/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [1141/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1141/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1142/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1142/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1142/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1143/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [1143/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1143/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1144/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [1144/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1144/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1145/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [1145/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1145/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1146/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1146/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1146/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1147/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3898\n",
      "LOG: Epoch [1147/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1147/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1148/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3877\n",
      "LOG: Epoch [1148/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1148/2000], Avg Train Loss: 0.3877, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1149/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [1149/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1149/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1150/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1150/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1150/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1151/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [1151/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1151/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1152/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [1152/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1152/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1153/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [1153/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1153/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1154/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1154/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1154/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1155/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1155/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1155/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1156/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1156/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1156/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1157/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1157/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1157/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1158/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1158/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1158/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1159/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [1159/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1159/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1160/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1160/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1160/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1161/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3879\n",
      "LOG: Epoch [1161/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1161/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3869\n",
      "LOG: Epoch [1162/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1162/2000], Avg Train Loss: 0.3869, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1163/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3947\n",
      "LOG: Epoch [1163/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1163/2000], Avg Train Loss: 0.3947, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1164/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [1164/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1164/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1165/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1165/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1165/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1166/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1166/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1166/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1167/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1167/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1167/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1168/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1168/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1168/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1169/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1169/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1169/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1170/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [1170/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1170/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1171/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1171/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1171/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1172/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3878\n",
      "LOG: Epoch [1172/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1172/2000], Avg Train Loss: 0.3878, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1173/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3963\n",
      "LOG: Epoch [1173/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1173/2000], Avg Train Loss: 0.3963, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1174/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1174/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1174/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1175/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1175/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1175/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1176/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [1176/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1176/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1177/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1177/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1177/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1178/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3889\n",
      "LOG: Epoch [1178/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1178/2000], Avg Train Loss: 0.3889, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1179/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3916\n",
      "LOG: Epoch [1179/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1179/2000], Avg Train Loss: 0.3916, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1180/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3872\n",
      "LOG: Epoch [1180/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1180/2000], Avg Train Loss: 0.3872, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1181/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [1181/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1181/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1182/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3920\n",
      "LOG: Epoch [1182/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1182/2000], Avg Train Loss: 0.3920, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1183/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1183/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1183/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1184/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3879\n",
      "LOG: Epoch [1184/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1184/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1185/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1185/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1185/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1186/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3881\n",
      "LOG: Epoch [1186/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1186/2000], Avg Train Loss: 0.3881, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1187/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [1187/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1187/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1188/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [1188/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1188/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1189/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1189/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1189/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1190/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3916\n",
      "LOG: Epoch [1190/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1190/2000], Avg Train Loss: 0.3916, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1191/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3946\n",
      "LOG: Epoch [1191/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1191/2000], Avg Train Loss: 0.3946, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1192/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [1192/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1192/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3924\n",
      "LOG: Epoch [1193/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1193/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1194/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3916\n",
      "LOG: Epoch [1194/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1194/2000], Avg Train Loss: 0.3916, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1195/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3965\n",
      "LOG: Epoch [1195/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1195/2000], Avg Train Loss: 0.3965, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1196/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [1196/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1196/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1197/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3942\n",
      "LOG: Epoch [1197/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1197/2000], Avg Train Loss: 0.3942, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1198/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3878\n",
      "LOG: Epoch [1198/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1198/2000], Avg Train Loss: 0.3878, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1199/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3881\n",
      "LOG: Epoch [1199/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1199/2000], Avg Train Loss: 0.3881, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1200/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1200/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1200/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1201/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3879\n",
      "LOG: Epoch [1201/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1201/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1202/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1202/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1202/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1203/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1203/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1203/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1204/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [1204/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1204/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1205/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [1205/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1205/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1206/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1206/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1206/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1207/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3936\n",
      "LOG: Epoch [1207/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1207/2000], Avg Train Loss: 0.3936, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1208/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1208/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1208/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1209/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [1209/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1209/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1210/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [1210/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1210/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1211/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1211/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1211/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1212/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [1212/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1212/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1213/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [1213/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1213/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1214/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3862\n",
      "LOG: Epoch [1214/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1214/2000], Avg Train Loss: 0.3862, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1215/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3881\n",
      "LOG: Epoch [1215/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1215/2000], Avg Train Loss: 0.3881, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1216/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1216/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1216/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1217/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1217/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1217/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1218/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3946\n",
      "LOG: Epoch [1218/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1218/2000], Avg Train Loss: 0.3946, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1219/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [1219/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1219/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1220/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3886\n",
      "LOG: Epoch [1220/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1220/2000], Avg Train Loss: 0.3886, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1221/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1221/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1221/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1222/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3960\n",
      "LOG: Epoch [1222/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1222/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1223/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [1223/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1223/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1224/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [1224/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1224/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1225/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3875\n",
      "LOG: Epoch [1225/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1225/2000], Avg Train Loss: 0.3875, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1226/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1226/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1226/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1227/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [1227/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1227/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1228/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1228/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1228/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1229/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [1229/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1229/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1230/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3872\n",
      "LOG: Epoch [1230/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1230/2000], Avg Train Loss: 0.3872, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1231/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3942\n",
      "LOG: Epoch [1231/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1231/2000], Avg Train Loss: 0.3942, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1232/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1232/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1232/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1233/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1233/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1233/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1234/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3963\n",
      "LOG: Epoch [1234/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1234/2000], Avg Train Loss: 0.3963, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [1235/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1235/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1236/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1236/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1236/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1237/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [1237/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1237/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1238/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3864\n",
      "LOG: Epoch [1238/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1238/2000], Avg Train Loss: 0.3864, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1239/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [1239/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1239/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1240/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3883\n",
      "LOG: Epoch [1240/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1240/2000], Avg Train Loss: 0.3883, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1241/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3944\n",
      "LOG: Epoch [1241/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1241/2000], Avg Train Loss: 0.3944, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1242/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [1242/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1242/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1243/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1243/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1243/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1244/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1244/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1244/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1245/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1245/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1245/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1246/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3918\n",
      "LOG: Epoch [1246/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1246/2000], Avg Train Loss: 0.3918, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1247/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3889\n",
      "LOG: Epoch [1247/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1247/2000], Avg Train Loss: 0.3889, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1248/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1248/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1248/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1249/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [1249/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1249/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1250/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1250/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1250/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1251/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1251/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1251/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1252/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1252/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1252/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1253/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3934\n",
      "LOG: Epoch [1253/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1253/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1254/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [1254/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1254/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1255/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [1255/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1255/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1256/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3897\n",
      "LOG: Epoch [1256/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1256/2000], Avg Train Loss: 0.3897, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1257/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3883\n",
      "LOG: Epoch [1257/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1257/2000], Avg Train Loss: 0.3883, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1258/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3952\n",
      "LOG: Epoch [1258/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1258/2000], Avg Train Loss: 0.3952, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1259/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [1259/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1259/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1260/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3887\n",
      "LOG: Epoch [1260/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1260/2000], Avg Train Loss: 0.3887, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1261/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1261/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1261/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1262/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [1262/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1262/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1263/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1263/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1263/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1264/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1264/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1264/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1265/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3947\n",
      "LOG: Epoch [1265/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1265/2000], Avg Train Loss: 0.3947, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1266/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [1266/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1266/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [1267/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1267/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1268/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3967\n",
      "LOG: Epoch [1268/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1268/2000], Avg Train Loss: 0.3967, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1269/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [1269/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1269/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1270/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1270/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1270/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1271/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3853\n",
      "LOG: Epoch [1271/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1271/2000], Avg Train Loss: 0.3853, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1272/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [1272/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1272/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1273/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1273/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1273/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1274/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [1274/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1274/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1275/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1275/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1275/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1276/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1276/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1276/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1277/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1277/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1277/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1278/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3934\n",
      "LOG: Epoch [1278/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1278/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1279/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1279/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1279/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1280/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3874\n",
      "LOG: Epoch [1280/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1280/2000], Avg Train Loss: 0.3874, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1281/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1281/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1281/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1282/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1282/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1282/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1283/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [1283/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1283/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1284/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [1284/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1284/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1285/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3958\n",
      "LOG: Epoch [1285/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1285/2000], Avg Train Loss: 0.3958, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1286/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1286/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1286/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1287/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1287/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1287/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1288/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1288/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1288/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1289/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3877\n",
      "LOG: Epoch [1289/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1289/2000], Avg Train Loss: 0.3877, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1290/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3881\n",
      "LOG: Epoch [1290/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1290/2000], Avg Train Loss: 0.3881, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1291/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3957\n",
      "LOG: Epoch [1291/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1291/2000], Avg Train Loss: 0.3957, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1292/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1292/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1292/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1293/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [1293/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1293/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1294/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3950\n",
      "LOG: Epoch [1294/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1294/2000], Avg Train Loss: 0.3950, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1295/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3897\n",
      "LOG: Epoch [1295/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1295/2000], Avg Train Loss: 0.3897, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1296/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1296/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1296/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1297/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [1297/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1297/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1298/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1298/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1298/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1299/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [1299/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1299/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1300/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1300/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1300/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1301/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3894\n",
      "LOG: Epoch [1301/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1301/2000], Avg Train Loss: 0.3894, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1302/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3881\n",
      "LOG: Epoch [1302/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1302/2000], Avg Train Loss: 0.3881, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1303/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [1303/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1303/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1304/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3949\n",
      "LOG: Epoch [1304/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1304/2000], Avg Train Loss: 0.3949, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1305/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3953\n",
      "LOG: Epoch [1305/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1305/2000], Avg Train Loss: 0.3953, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1306/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [1306/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1306/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1307/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3879\n",
      "LOG: Epoch [1307/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1307/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1308/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3884\n",
      "LOG: Epoch [1308/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1308/2000], Avg Train Loss: 0.3884, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1309/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [1309/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1309/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1310/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1310/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1310/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1311/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3880\n",
      "LOG: Epoch [1311/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1311/2000], Avg Train Loss: 0.3880, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1312/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [1312/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1312/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1313/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [1313/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1313/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1314/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1314/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1314/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1315/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1315/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1315/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1316/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [1316/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1316/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1317/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3881\n",
      "LOG: Epoch [1317/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1317/2000], Avg Train Loss: 0.3881, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1318/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [1318/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1318/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1319/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [1319/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1319/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1320/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1320/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1320/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1321/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3898\n",
      "LOG: Epoch [1321/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1321/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1322/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1322/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1322/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1323/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3882\n",
      "LOG: Epoch [1323/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1323/2000], Avg Train Loss: 0.3882, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1324/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3949\n",
      "LOG: Epoch [1324/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1324/2000], Avg Train Loss: 0.3949, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1325/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [1325/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1325/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1326/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [1326/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1326/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1327/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1327/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1327/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1328/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3883\n",
      "LOG: Epoch [1328/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1328/2000], Avg Train Loss: 0.3883, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1329/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1329/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1329/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1330/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3858\n",
      "LOG: Epoch [1330/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1330/2000], Avg Train Loss: 0.3858, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1331/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [1331/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1331/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1332/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3898\n",
      "LOG: Epoch [1332/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1332/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1333/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [1333/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1333/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1334/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3874\n",
      "LOG: Epoch [1334/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1334/2000], Avg Train Loss: 0.3874, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1335/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1335/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1335/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1336/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1336/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1336/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1337/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3898\n",
      "LOG: Epoch [1337/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1337/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1338/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [1338/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1338/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1339/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [1339/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1339/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1340/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3879\n",
      "LOG: Epoch [1340/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1340/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1341/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3869\n",
      "LOG: Epoch [1341/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1341/2000], Avg Train Loss: 0.3869, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1342/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3888\n",
      "LOG: Epoch [1342/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1342/2000], Avg Train Loss: 0.3888, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1343/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3940\n",
      "LOG: Epoch [1343/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1343/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1344/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3948\n",
      "LOG: Epoch [1344/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1344/2000], Avg Train Loss: 0.3948, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1345/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [1345/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1345/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1346/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3949\n",
      "LOG: Epoch [1346/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1346/2000], Avg Train Loss: 0.3949, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1347/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [1347/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1347/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1348/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3954\n",
      "LOG: Epoch [1348/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1348/2000], Avg Train Loss: 0.3954, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1349/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [1349/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1349/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1350/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1350/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1350/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1351/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1351/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1351/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1352/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3889\n",
      "LOG: Epoch [1352/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1352/2000], Avg Train Loss: 0.3889, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1353/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [1353/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1353/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1354/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [1354/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1354/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1355/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3957\n",
      "LOG: Epoch [1355/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1355/2000], Avg Train Loss: 0.3957, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1356/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [1356/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1356/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1357/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3890\n",
      "LOG: Epoch [1357/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1357/2000], Avg Train Loss: 0.3890, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1358/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [1358/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1358/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1359/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1359/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1359/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1360/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1360/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1360/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1361/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3887\n",
      "LOG: Epoch [1361/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1361/2000], Avg Train Loss: 0.3887, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1362/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [1362/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1362/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1363/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3872\n",
      "LOG: Epoch [1363/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1363/2000], Avg Train Loss: 0.3872, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1364/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [1364/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1364/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1365/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3942\n",
      "LOG: Epoch [1365/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1365/2000], Avg Train Loss: 0.3942, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1366/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1366/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1366/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1367/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3870\n",
      "LOG: Epoch [1367/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1367/2000], Avg Train Loss: 0.3870, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1368/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1368/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1368/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1369/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3887\n",
      "LOG: Epoch [1369/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1369/2000], Avg Train Loss: 0.3887, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1370/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [1370/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1370/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1371/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [1371/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1371/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1372/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3876\n",
      "LOG: Epoch [1372/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1372/2000], Avg Train Loss: 0.3876, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1373/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [1373/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1373/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1374/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3947\n",
      "LOG: Epoch [1374/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1374/2000], Avg Train Loss: 0.3947, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1375/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3949\n",
      "LOG: Epoch [1375/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1375/2000], Avg Train Loss: 0.3949, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1376/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1376/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1376/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1377/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3924\n",
      "LOG: Epoch [1377/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1377/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1378/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [1378/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1378/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1379/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3898\n",
      "LOG: Epoch [1379/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1379/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1380/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [1380/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1380/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1381/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1381/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1381/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1382/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3960\n",
      "LOG: Epoch [1382/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1382/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1383/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3918\n",
      "LOG: Epoch [1383/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1383/2000], Avg Train Loss: 0.3918, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1384/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [1384/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1384/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1385/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3957\n",
      "LOG: Epoch [1385/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1385/2000], Avg Train Loss: 0.3957, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1386/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3878\n",
      "LOG: Epoch [1386/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1386/2000], Avg Train Loss: 0.3878, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1387/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1387/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1387/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1388/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1388/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1388/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1389/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1389/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1389/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1390/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3988\n",
      "LOG: Epoch [1390/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1390/2000], Avg Train Loss: 0.3988, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1391/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [1391/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1391/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1392/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3878\n",
      "LOG: Epoch [1392/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1392/2000], Avg Train Loss: 0.3878, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1393/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [1393/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1393/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1394/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3918\n",
      "LOG: Epoch [1394/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1394/2000], Avg Train Loss: 0.3918, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1395/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3886\n",
      "LOG: Epoch [1395/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1395/2000], Avg Train Loss: 0.3886, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1396/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [1396/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1396/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1397/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1397/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1397/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1398/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3871\n",
      "LOG: Epoch [1398/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1398/2000], Avg Train Loss: 0.3871, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1399/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1399/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1399/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1400/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3948\n",
      "LOG: Epoch [1400/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1400/2000], Avg Train Loss: 0.3948, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1401/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1401/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1401/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1402/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1402/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1402/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1403/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3878\n",
      "LOG: Epoch [1403/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1403/2000], Avg Train Loss: 0.3878, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1404/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [1404/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1404/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1405/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [1405/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1405/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1406/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3960\n",
      "LOG: Epoch [1406/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1406/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1407/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3967\n",
      "LOG: Epoch [1407/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1407/2000], Avg Train Loss: 0.3967, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1408/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1408/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1408/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1409/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1409/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1409/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1410/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [1410/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1410/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1411/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [1411/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1411/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1412/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3884\n",
      "LOG: Epoch [1412/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1412/2000], Avg Train Loss: 0.3884, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1413/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3967\n",
      "LOG: Epoch [1413/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1413/2000], Avg Train Loss: 0.3967, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1414/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [1414/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1414/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1415/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3968\n",
      "LOG: Epoch [1415/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1415/2000], Avg Train Loss: 0.3968, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1416/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [1416/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1416/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1417/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1417/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1417/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1418/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [1418/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1418/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1419/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3883\n",
      "LOG: Epoch [1419/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1419/2000], Avg Train Loss: 0.3883, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1420/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [1420/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1420/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1421/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1421/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1421/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1422/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3934\n",
      "LOG: Epoch [1422/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1422/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1423/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3916\n",
      "LOG: Epoch [1423/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1423/2000], Avg Train Loss: 0.3916, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1424/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3964\n",
      "LOG: Epoch [1424/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1424/2000], Avg Train Loss: 0.3964, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1425/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3954\n",
      "LOG: Epoch [1425/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1425/2000], Avg Train Loss: 0.3954, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1426/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1426/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1426/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1427/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3944\n",
      "LOG: Epoch [1427/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1427/2000], Avg Train Loss: 0.3944, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1428/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [1428/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1428/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1429/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [1429/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1429/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1430/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3936\n",
      "LOG: Epoch [1430/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1430/2000], Avg Train Loss: 0.3936, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1431/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [1431/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1431/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1432/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [1432/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1432/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1433/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1433/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1433/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1434/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1434/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1434/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1435/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3936\n",
      "LOG: Epoch [1435/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1435/2000], Avg Train Loss: 0.3936, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3877\n",
      "LOG: Epoch [1436/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1436/2000], Avg Train Loss: 0.3877, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1437/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1437/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1437/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1438/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [1438/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1438/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1439/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3873\n",
      "LOG: Epoch [1439/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1439/2000], Avg Train Loss: 0.3873, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1440/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3897\n",
      "LOG: Epoch [1440/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1440/2000], Avg Train Loss: 0.3897, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1441/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [1441/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1441/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1442/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1442/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1442/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1443/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1443/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1443/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1444/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3889\n",
      "LOG: Epoch [1444/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1444/2000], Avg Train Loss: 0.3889, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1445/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3920\n",
      "LOG: Epoch [1445/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1445/2000], Avg Train Loss: 0.3920, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1446/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [1446/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1446/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1447/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3940\n",
      "LOG: Epoch [1447/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1447/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1448/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [1448/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1448/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1449/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [1449/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1449/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1450/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1450/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1450/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [1451/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1451/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1452/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1452/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1452/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1453/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [1453/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1453/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1454/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1454/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1454/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1455/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [1455/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1455/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1456/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1456/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1456/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1457/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1457/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1457/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1458/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3894\n",
      "LOG: Epoch [1458/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1458/2000], Avg Train Loss: 0.3894, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1459/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3934\n",
      "LOG: Epoch [1459/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1459/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1460/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [1460/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1460/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1461/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3950\n",
      "LOG: Epoch [1461/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1461/2000], Avg Train Loss: 0.3950, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1462/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1462/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1462/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1463/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1463/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1463/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1464/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1464/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1464/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1465/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1465/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1465/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1466/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [1466/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1466/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1467/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1467/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1467/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1468/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [1468/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1468/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1469/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1469/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1469/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1470/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [1470/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1470/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1471/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3898\n",
      "LOG: Epoch [1471/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1471/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1472/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [1472/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1472/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1473/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1473/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1473/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1474/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [1474/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1474/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1475/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [1475/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1475/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1476/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [1476/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1476/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1477/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [1477/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1477/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1478/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3894\n",
      "LOG: Epoch [1478/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1478/2000], Avg Train Loss: 0.3894, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1479/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [1479/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1479/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1480/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1480/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1480/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1481/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3882\n",
      "LOG: Epoch [1481/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1481/2000], Avg Train Loss: 0.3882, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1482/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1482/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1482/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1483/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3876\n",
      "LOG: Epoch [1483/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1483/2000], Avg Train Loss: 0.3876, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1484/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1484/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1484/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1485/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1485/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1485/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1486/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3918\n",
      "LOG: Epoch [1486/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1486/2000], Avg Train Loss: 0.3918, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1487/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1487/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1487/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1488/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3884\n",
      "LOG: Epoch [1488/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1488/2000], Avg Train Loss: 0.3884, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1489/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [1489/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1489/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1490/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3918\n",
      "LOG: Epoch [1490/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1490/2000], Avg Train Loss: 0.3918, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1491/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [1491/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1491/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1492/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [1492/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1492/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1493/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [1493/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1493/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1494/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [1494/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1494/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1495/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1495/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1495/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1496/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [1496/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1496/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1497/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3850\n",
      "LOG: Epoch [1497/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1497/2000], Avg Train Loss: 0.3850, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1498/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [1498/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1498/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1499/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1499/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1499/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1500/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3950\n",
      "LOG: Epoch [1500/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1500/2000], Avg Train Loss: 0.3950, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1501/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [1501/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1501/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1502/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3948\n",
      "LOG: Epoch [1502/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1502/2000], Avg Train Loss: 0.3948, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1503/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [1503/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1503/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1504/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1504/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1504/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1505/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [1505/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1505/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1506/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [1506/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1506/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1507/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3956\n",
      "LOG: Epoch [1507/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1507/2000], Avg Train Loss: 0.3956, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1508/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3886\n",
      "LOG: Epoch [1508/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1508/2000], Avg Train Loss: 0.3886, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1509/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [1509/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1509/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1510/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1510/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1510/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1511/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3949\n",
      "LOG: Epoch [1511/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1511/2000], Avg Train Loss: 0.3949, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1512/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [1512/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1512/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1513/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [1513/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1513/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1514/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1514/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1514/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1515/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1515/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1515/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1516/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1516/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1516/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1517/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1517/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1517/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1518/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3874\n",
      "LOG: Epoch [1518/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1518/2000], Avg Train Loss: 0.3874, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1519/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [1519/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1519/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1520/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1520/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1520/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1521/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3955\n",
      "LOG: Epoch [1521/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1521/2000], Avg Train Loss: 0.3955, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1522/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [1522/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1522/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1523/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1523/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1523/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1524/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [1524/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1524/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1525/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3837\n",
      "LOG: Epoch [1525/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1525/2000], Avg Train Loss: 0.3837, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1526/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1526/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1526/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1527/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [1527/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1527/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1528/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3920\n",
      "LOG: Epoch [1528/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1528/2000], Avg Train Loss: 0.3920, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1529/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3946\n",
      "LOG: Epoch [1529/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1529/2000], Avg Train Loss: 0.3946, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1530/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [1530/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1530/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1531/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1531/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1531/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1532/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3940\n",
      "LOG: Epoch [1532/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1532/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1533/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1533/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1533/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1534/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1534/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1534/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1535/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3934\n",
      "LOG: Epoch [1535/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1535/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1536/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [1536/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1536/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1537/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [1537/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1537/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1538/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [1538/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1538/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1539/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3886\n",
      "LOG: Epoch [1539/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1539/2000], Avg Train Loss: 0.3886, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1540/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3963\n",
      "LOG: Epoch [1540/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1540/2000], Avg Train Loss: 0.3963, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1541/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [1541/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1541/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1542/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3943\n",
      "LOG: Epoch [1542/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1542/2000], Avg Train Loss: 0.3943, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1543/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [1543/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1543/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1544/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3940\n",
      "LOG: Epoch [1544/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1544/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1545/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1545/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1545/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1546/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [1546/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1546/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1547/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [1547/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1547/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1548/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3942\n",
      "LOG: Epoch [1548/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1548/2000], Avg Train Loss: 0.3942, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1549/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [1549/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1549/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1550/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3887\n",
      "LOG: Epoch [1550/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1550/2000], Avg Train Loss: 0.3887, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1551/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1551/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1551/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1552/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [1552/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1552/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1553/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3918\n",
      "LOG: Epoch [1553/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1553/2000], Avg Train Loss: 0.3918, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1554/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3963\n",
      "LOG: Epoch [1554/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1554/2000], Avg Train Loss: 0.3963, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1555/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3918\n",
      "LOG: Epoch [1555/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1555/2000], Avg Train Loss: 0.3918, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1556/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [1556/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1556/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1557/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [1557/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1557/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1558/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [1558/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1558/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1559/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [1559/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1559/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1560/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1560/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1560/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1561/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [1561/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1561/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1562/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [1562/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1562/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1563/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1563/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1563/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1564/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3950\n",
      "LOG: Epoch [1564/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1564/2000], Avg Train Loss: 0.3950, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1565/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [1565/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1565/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1566/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1566/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1566/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1567/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3894\n",
      "LOG: Epoch [1567/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1567/2000], Avg Train Loss: 0.3894, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1568/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [1568/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1568/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1569/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1569/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1569/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1570/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [1570/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1570/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1571/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3861\n",
      "LOG: Epoch [1571/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1571/2000], Avg Train Loss: 0.3861, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1572/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [1572/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1572/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1573/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3962\n",
      "LOG: Epoch [1573/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1573/2000], Avg Train Loss: 0.3962, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1574/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1574/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1574/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1575/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1575/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1575/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1576/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3924\n",
      "LOG: Epoch [1576/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1576/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1577/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3949\n",
      "LOG: Epoch [1577/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1577/2000], Avg Train Loss: 0.3949, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1578/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1578/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1579/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [1579/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1579/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1580/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [1580/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1580/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1581/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1581/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1581/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1582/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1582/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1582/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1583/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3882\n",
      "LOG: Epoch [1583/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1583/2000], Avg Train Loss: 0.3882, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1584/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [1584/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1584/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1585/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1585/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1585/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1586/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [1586/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1586/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1587/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [1587/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1587/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1588/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3975\n",
      "LOG: Epoch [1588/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1588/2000], Avg Train Loss: 0.3975, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1589/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [1589/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1589/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1590/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [1590/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1590/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1591/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3882\n",
      "LOG: Epoch [1591/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1591/2000], Avg Train Loss: 0.3882, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1592/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [1592/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1592/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1593/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [1593/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1593/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1594/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [1594/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1594/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1595/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1595/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1595/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1596/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [1596/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1596/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1597/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1597/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1597/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1598/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3942\n",
      "LOG: Epoch [1598/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1598/2000], Avg Train Loss: 0.3942, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1599/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3884\n",
      "LOG: Epoch [1599/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1599/2000], Avg Train Loss: 0.3884, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1600/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [1600/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1600/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1601/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [1601/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1601/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1602/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [1602/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1602/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1603/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [1603/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1603/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1604/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3875\n",
      "LOG: Epoch [1604/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1604/2000], Avg Train Loss: 0.3875, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1605/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [1605/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1605/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1606/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1606/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1606/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1607/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3881\n",
      "LOG: Epoch [1607/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1607/2000], Avg Train Loss: 0.3881, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1608/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1608/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1608/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1609/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3944\n",
      "LOG: Epoch [1609/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1609/2000], Avg Train Loss: 0.3944, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1610/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1610/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1610/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1611/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3880\n",
      "LOG: Epoch [1611/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1611/2000], Avg Train Loss: 0.3880, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1612/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3878\n",
      "LOG: Epoch [1612/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1612/2000], Avg Train Loss: 0.3878, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1613/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1613/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1613/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [1614/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1614/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1615/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [1615/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1615/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3894\n",
      "LOG: Epoch [1616/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1616/2000], Avg Train Loss: 0.3894, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1617/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [1617/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1617/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1618/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3956\n",
      "LOG: Epoch [1618/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1618/2000], Avg Train Loss: 0.3956, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1619/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3943\n",
      "LOG: Epoch [1619/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1619/2000], Avg Train Loss: 0.3943, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1620/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3960\n",
      "LOG: Epoch [1620/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1620/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1621/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [1621/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1621/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1622/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3957\n",
      "LOG: Epoch [1622/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1622/2000], Avg Train Loss: 0.3957, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1623/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [1623/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1623/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1624/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1624/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1624/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1625/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3894\n",
      "LOG: Epoch [1625/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1625/2000], Avg Train Loss: 0.3894, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1626/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [1626/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1626/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1627/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [1627/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1627/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1628/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1628/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1628/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1629/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3960\n",
      "LOG: Epoch [1629/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1629/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1630/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3889\n",
      "LOG: Epoch [1630/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1630/2000], Avg Train Loss: 0.3889, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1631/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3936\n",
      "LOG: Epoch [1631/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1631/2000], Avg Train Loss: 0.3936, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1632/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [1632/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1632/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1633/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [1633/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1633/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1634/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [1634/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1634/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1635/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3924\n",
      "LOG: Epoch [1635/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1635/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1636/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3897\n",
      "LOG: Epoch [1636/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1636/2000], Avg Train Loss: 0.3897, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1637/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1637/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1637/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1638/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1638/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1638/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1639/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3934\n",
      "LOG: Epoch [1639/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1639/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1640/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1640/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1640/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1641/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3871\n",
      "LOG: Epoch [1641/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1641/2000], Avg Train Loss: 0.3871, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1642/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [1642/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1642/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1643/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1643/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1643/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1644/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1644/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1644/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1645/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1645/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1645/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1646/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [1646/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1646/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1647/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1647/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1647/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1648/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1648/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1648/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1649/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1649/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1649/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1650/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [1650/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1650/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1651/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [1651/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1651/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1652/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1652/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1652/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1653/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3943\n",
      "LOG: Epoch [1653/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1653/2000], Avg Train Loss: 0.3943, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1654/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1654/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1654/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1655/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3918\n",
      "LOG: Epoch [1655/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1655/2000], Avg Train Loss: 0.3918, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1656/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3946\n",
      "LOG: Epoch [1656/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1656/2000], Avg Train Loss: 0.3946, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1657/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [1657/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1657/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1658/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [1658/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1658/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1659/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3877\n",
      "LOG: Epoch [1659/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1659/2000], Avg Train Loss: 0.3877, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1660/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1660/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1660/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1661/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [1661/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1661/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1662/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [1662/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1662/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1663/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3879\n",
      "LOG: Epoch [1663/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1663/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1664/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [1664/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1664/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1665/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1665/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1665/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1666/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [1666/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1666/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1667/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3924\n",
      "LOG: Epoch [1667/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1667/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1668/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [1668/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1668/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1669/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [1669/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1669/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1670/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [1670/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1670/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1671/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3878\n",
      "LOG: Epoch [1671/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1671/2000], Avg Train Loss: 0.3878, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1672/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [1672/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1672/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1673/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3949\n",
      "LOG: Epoch [1673/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1673/2000], Avg Train Loss: 0.3949, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1674/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1674/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1674/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1675/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1675/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1675/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1676/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3936\n",
      "LOG: Epoch [1676/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1676/2000], Avg Train Loss: 0.3936, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1677/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3872\n",
      "LOG: Epoch [1677/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1677/2000], Avg Train Loss: 0.3872, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1678/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1678/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1678/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1679/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3887\n",
      "LOG: Epoch [1679/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1679/2000], Avg Train Loss: 0.3887, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1680/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3959\n",
      "LOG: Epoch [1680/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1680/2000], Avg Train Loss: 0.3959, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1681/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1681/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1681/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1682/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1682/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1682/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1683/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [1683/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1683/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1684/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1684/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1684/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1685/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1685/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1685/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1686/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3886\n",
      "LOG: Epoch [1686/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1686/2000], Avg Train Loss: 0.3886, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1687/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1687/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1687/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1688/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1688/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1688/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1689/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3872\n",
      "LOG: Epoch [1689/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1689/2000], Avg Train Loss: 0.3872, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1690/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [1690/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1690/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1691/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3934\n",
      "LOG: Epoch [1691/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1691/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1692/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3948\n",
      "LOG: Epoch [1692/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1692/2000], Avg Train Loss: 0.3948, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1693/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3924\n",
      "LOG: Epoch [1693/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1693/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1694/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3898\n",
      "LOG: Epoch [1694/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1694/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1695/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1695/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1695/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1696/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3916\n",
      "LOG: Epoch [1696/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1696/2000], Avg Train Loss: 0.3916, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1697/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [1697/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1697/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1698/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [1698/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1698/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1699/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1699/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1699/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1700/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3877\n",
      "LOG: Epoch [1700/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1700/2000], Avg Train Loss: 0.3877, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1701/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3884\n",
      "LOG: Epoch [1701/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1701/2000], Avg Train Loss: 0.3884, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1702/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1702/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1702/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1703/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [1703/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1703/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1704/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3884\n",
      "LOG: Epoch [1704/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1704/2000], Avg Train Loss: 0.3884, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1705/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [1705/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1705/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1706/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3887\n",
      "LOG: Epoch [1706/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1706/2000], Avg Train Loss: 0.3887, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1707/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3886\n",
      "LOG: Epoch [1707/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1707/2000], Avg Train Loss: 0.3886, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1708/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3888\n",
      "LOG: Epoch [1708/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1708/2000], Avg Train Loss: 0.3888, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1709/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [1709/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1709/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1710/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3916\n",
      "LOG: Epoch [1710/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1710/2000], Avg Train Loss: 0.3916, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1711/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1711/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1711/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1712/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [1712/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1712/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1713/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3918\n",
      "LOG: Epoch [1713/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1713/2000], Avg Train Loss: 0.3918, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1714/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1714/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1714/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1715/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1715/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1715/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1716/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [1716/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1716/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1717/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [1717/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1717/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1718/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3897\n",
      "LOG: Epoch [1718/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1718/2000], Avg Train Loss: 0.3897, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1719/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [1719/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1719/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1720/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3920\n",
      "LOG: Epoch [1720/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1720/2000], Avg Train Loss: 0.3920, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1721/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1721/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1721/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1722/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3955\n",
      "LOG: Epoch [1722/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1722/2000], Avg Train Loss: 0.3955, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1723/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1723/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1723/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1724/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3877\n",
      "LOG: Epoch [1724/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1724/2000], Avg Train Loss: 0.3877, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1725/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [1725/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1725/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1726/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3942\n",
      "LOG: Epoch [1726/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1726/2000], Avg Train Loss: 0.3942, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1727/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [1727/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1727/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1728/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [1728/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1728/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1729/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [1729/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1729/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1730/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [1730/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1730/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1731/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [1731/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1731/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1732/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3936\n",
      "LOG: Epoch [1732/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1732/2000], Avg Train Loss: 0.3936, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1733/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3894\n",
      "LOG: Epoch [1733/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1733/2000], Avg Train Loss: 0.3894, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1734/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1734/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1734/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1735/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [1735/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1735/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1736/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3886\n",
      "LOG: Epoch [1736/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1736/2000], Avg Train Loss: 0.3886, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1737/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3873\n",
      "LOG: Epoch [1737/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1737/2000], Avg Train Loss: 0.3873, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1738/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1738/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1738/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1739/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1739/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1739/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1740/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1740/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1740/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1741/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3948\n",
      "LOG: Epoch [1741/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1741/2000], Avg Train Loss: 0.3948, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1742/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [1742/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1742/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1743/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1743/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1743/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1744/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3924\n",
      "LOG: Epoch [1744/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1744/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1745/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1745/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1745/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1746/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1746/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1746/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1747/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [1747/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1747/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1748/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3959\n",
      "LOG: Epoch [1748/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1748/2000], Avg Train Loss: 0.3959, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1749/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [1749/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1749/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1750/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [1750/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1750/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1751/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3920\n",
      "LOG: Epoch [1751/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1751/2000], Avg Train Loss: 0.3920, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1752/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1752/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1752/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1753/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [1753/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1753/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1754/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3888\n",
      "LOG: Epoch [1754/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1754/2000], Avg Train Loss: 0.3888, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1755/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3890\n",
      "LOG: Epoch [1755/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1755/2000], Avg Train Loss: 0.3890, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1756/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [1756/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1756/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1757/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1757/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1757/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1758/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1758/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1758/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1759/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1759/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1759/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1760/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3894\n",
      "LOG: Epoch [1760/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1760/2000], Avg Train Loss: 0.3894, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1761/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1761/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1761/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1762/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3873\n",
      "LOG: Epoch [1762/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1762/2000], Avg Train Loss: 0.3873, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1763/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1763/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1763/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1764/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3942\n",
      "LOG: Epoch [1764/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1764/2000], Avg Train Loss: 0.3942, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1765/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1765/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1765/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1766/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3956\n",
      "LOG: Epoch [1766/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1766/2000], Avg Train Loss: 0.3956, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1767/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1767/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1767/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1768/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [1768/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1768/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1769/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [1769/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1769/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1770/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1770/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1770/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1771/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3916\n",
      "LOG: Epoch [1771/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1771/2000], Avg Train Loss: 0.3916, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1772/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3943\n",
      "LOG: Epoch [1772/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1772/2000], Avg Train Loss: 0.3943, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1773/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [1773/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1773/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1774/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3924\n",
      "LOG: Epoch [1774/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1774/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1775/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3864\n",
      "LOG: Epoch [1775/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1775/2000], Avg Train Loss: 0.3864, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1776/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [1776/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1776/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1777/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3924\n",
      "LOG: Epoch [1777/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1777/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1778/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3956\n",
      "LOG: Epoch [1778/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1778/2000], Avg Train Loss: 0.3956, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1779/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1779/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1779/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1780/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3934\n",
      "LOG: Epoch [1780/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1780/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1781/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [1781/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1781/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1782/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3949\n",
      "LOG: Epoch [1782/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1782/2000], Avg Train Loss: 0.3949, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1783/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3878\n",
      "LOG: Epoch [1783/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1783/2000], Avg Train Loss: 0.3878, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1784/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1784/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1784/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1785/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [1785/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1785/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1786/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3875\n",
      "LOG: Epoch [1786/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1786/2000], Avg Train Loss: 0.3875, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1787/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [1787/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1787/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1788/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1788/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1788/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1789/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [1789/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1789/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1790/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1790/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1790/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1791/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1791/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1791/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1792/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1792/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1792/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1793/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1793/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1793/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1794/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1794/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1794/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1795/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [1795/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1795/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1796/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1796/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1796/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1797/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3966\n",
      "LOG: Epoch [1797/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1797/2000], Avg Train Loss: 0.3966, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1798/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1798/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1798/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1799/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [1799/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1799/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1800/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [1800/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1800/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1801/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [1801/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1801/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1802/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1802/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1802/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1803/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3879\n",
      "LOG: Epoch [1803/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1803/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1804/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [1804/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1804/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1805/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1805/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1805/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1806/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3877\n",
      "LOG: Epoch [1806/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1806/2000], Avg Train Loss: 0.3877, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1807/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [1807/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1807/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1808/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [1808/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1808/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1809/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3968\n",
      "LOG: Epoch [1809/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1809/2000], Avg Train Loss: 0.3968, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1810/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [1810/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1810/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1811/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3897\n",
      "LOG: Epoch [1811/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1811/2000], Avg Train Loss: 0.3897, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1812/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1812/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1812/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1813/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1813/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1813/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1814/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3952\n",
      "LOG: Epoch [1814/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1814/2000], Avg Train Loss: 0.3952, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1815/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1815/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1815/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1816/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1816/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1816/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1817/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3877\n",
      "LOG: Epoch [1817/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1817/2000], Avg Train Loss: 0.3877, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1818/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [1818/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1818/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1819/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3920\n",
      "LOG: Epoch [1819/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1819/2000], Avg Train Loss: 0.3920, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1820/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [1820/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1820/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1821/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3887\n",
      "LOG: Epoch [1821/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1821/2000], Avg Train Loss: 0.3887, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1822/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3961\n",
      "LOG: Epoch [1822/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1822/2000], Avg Train Loss: 0.3961, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1823/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1823/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1823/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1824/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1824/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1824/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1825/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1825/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1825/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1826/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1826/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1826/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1827/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3877\n",
      "LOG: Epoch [1827/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1827/2000], Avg Train Loss: 0.3877, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1828/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3955\n",
      "LOG: Epoch [1828/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1828/2000], Avg Train Loss: 0.3955, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1829/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [1829/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1829/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1830/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1830/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1830/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1831/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3955\n",
      "LOG: Epoch [1831/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1831/2000], Avg Train Loss: 0.3955, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1832/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [1832/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1832/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1833/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [1833/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1833/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1834/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [1834/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1834/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1835/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3907\n",
      "LOG: Epoch [1835/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1835/2000], Avg Train Loss: 0.3907, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1836/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [1836/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1836/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1837/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [1837/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1837/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1838/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [1838/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1838/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1839/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3899\n",
      "LOG: Epoch [1839/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1839/2000], Avg Train Loss: 0.3899, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1840/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [1840/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1840/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1841/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [1841/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1841/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1842/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [1842/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1842/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1843/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3950\n",
      "LOG: Epoch [1843/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1843/2000], Avg Train Loss: 0.3950, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1844/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3952\n",
      "LOG: Epoch [1844/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1844/2000], Avg Train Loss: 0.3952, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1845/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [1845/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1845/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1846/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3965\n",
      "LOG: Epoch [1846/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1846/2000], Avg Train Loss: 0.3965, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1847/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [1847/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1847/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1848/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [1848/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1848/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1849/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [1849/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1849/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1850/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1850/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1850/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1851/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1851/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1851/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1852/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3916\n",
      "LOG: Epoch [1852/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1852/2000], Avg Train Loss: 0.3916, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1853/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3897\n",
      "LOG: Epoch [1853/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1853/2000], Avg Train Loss: 0.3897, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1854/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3890\n",
      "LOG: Epoch [1854/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1854/2000], Avg Train Loss: 0.3890, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1855/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [1855/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1855/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1856/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3947\n",
      "LOG: Epoch [1856/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1856/2000], Avg Train Loss: 0.3947, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1857/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3927\n",
      "LOG: Epoch [1857/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1857/2000], Avg Train Loss: 0.3927, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1858/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1858/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1858/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1859/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [1859/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1859/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1860/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [1860/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1860/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1861/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1861/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1861/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1862/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1862/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1862/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1863/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1863/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1863/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1864/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3894\n",
      "LOG: Epoch [1864/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1864/2000], Avg Train Loss: 0.3894, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1865/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [1865/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1865/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1866/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [1866/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1866/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1867/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3880\n",
      "LOG: Epoch [1867/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1867/2000], Avg Train Loss: 0.3880, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1868/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [1868/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1868/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1869/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [1869/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1869/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1870/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3966\n",
      "LOG: Epoch [1870/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1870/2000], Avg Train Loss: 0.3966, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1871/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3942\n",
      "LOG: Epoch [1871/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1871/2000], Avg Train Loss: 0.3942, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1872/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1872/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1872/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1873/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [1873/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1873/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1874/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3891\n",
      "LOG: Epoch [1874/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1874/2000], Avg Train Loss: 0.3891, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1875/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [1875/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1875/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1876/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [1876/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1876/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1877/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [1877/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1877/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1878/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3946\n",
      "LOG: Epoch [1878/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1878/2000], Avg Train Loss: 0.3946, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1879/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1879/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1879/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1880/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [1880/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1880/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1881/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1881/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1881/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1882/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [1882/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1882/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1883/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1883/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1883/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1884/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [1884/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1884/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1885/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3897\n",
      "LOG: Epoch [1885/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1885/2000], Avg Train Loss: 0.3897, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1886/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3919\n",
      "LOG: Epoch [1886/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1886/2000], Avg Train Loss: 0.3919, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1887/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [1887/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1887/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1888/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3901\n",
      "LOG: Epoch [1888/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1888/2000], Avg Train Loss: 0.3901, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1889/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3871\n",
      "LOG: Epoch [1889/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1889/2000], Avg Train Loss: 0.3871, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1890/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3940\n",
      "LOG: Epoch [1890/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1890/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1891/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [1891/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1891/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1892/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3890\n",
      "LOG: Epoch [1892/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1892/2000], Avg Train Loss: 0.3890, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1893/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3878\n",
      "LOG: Epoch [1893/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1893/2000], Avg Train Loss: 0.3878, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1894/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3888\n",
      "LOG: Epoch [1894/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1894/2000], Avg Train Loss: 0.3888, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1895/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3949\n",
      "LOG: Epoch [1895/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1895/2000], Avg Train Loss: 0.3949, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1896/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [1896/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1896/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1897/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1897/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1897/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1898/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3898\n",
      "LOG: Epoch [1898/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1898/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1899/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1899/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1899/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1900/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [1900/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1900/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1901/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3868\n",
      "LOG: Epoch [1901/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1901/2000], Avg Train Loss: 0.3868, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1902/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [1902/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1902/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1903/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3902\n",
      "LOG: Epoch [1903/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1903/2000], Avg Train Loss: 0.3902, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1904/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [1904/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1904/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1905/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3894\n",
      "LOG: Epoch [1905/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1905/2000], Avg Train Loss: 0.3894, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1906/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3842\n",
      "LOG: Epoch [1906/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1906/2000], Avg Train Loss: 0.3842, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1907/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3943\n",
      "LOG: Epoch [1907/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1907/2000], Avg Train Loss: 0.3943, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1908/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1908/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1908/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1909/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3875\n",
      "LOG: Epoch [1909/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1909/2000], Avg Train Loss: 0.3875, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1910/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [1910/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1910/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1911/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3890\n",
      "LOG: Epoch [1911/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1911/2000], Avg Train Loss: 0.3890, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1912/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [1912/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1912/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1913/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1913/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1913/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1914/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [1914/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1914/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1915/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3959\n",
      "LOG: Epoch [1915/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1915/2000], Avg Train Loss: 0.3959, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1916/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [1916/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1916/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1917/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1917/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1917/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1918/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3905\n",
      "LOG: Epoch [1918/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1918/2000], Avg Train Loss: 0.3905, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1919/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3890\n",
      "LOG: Epoch [1919/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1919/2000], Avg Train Loss: 0.3890, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1920/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1920/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1920/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1921/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3881\n",
      "LOG: Epoch [1921/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1921/2000], Avg Train Loss: 0.3881, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1922/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1922/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1922/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1923/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [1923/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1923/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1924/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1924/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1924/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1925/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1925/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1925/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1926/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [1926/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1926/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1927/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1927/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1927/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1928/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [1928/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1928/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1929/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3932\n",
      "LOG: Epoch [1929/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1929/2000], Avg Train Loss: 0.3932, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1930/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [1930/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1930/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1931/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3869\n",
      "LOG: Epoch [1931/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1931/2000], Avg Train Loss: 0.3869, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1932/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3879\n",
      "LOG: Epoch [1932/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1932/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1933/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3969\n",
      "LOG: Epoch [1933/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1933/2000], Avg Train Loss: 0.3969, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1934/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3879\n",
      "LOG: Epoch [1934/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1934/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1935/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3926\n",
      "LOG: Epoch [1935/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1935/2000], Avg Train Loss: 0.3926, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1936/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1936/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1936/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1937/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3960\n",
      "LOG: Epoch [1937/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1937/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1938/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1938/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1938/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1939/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1939/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1939/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1940/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [1940/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1940/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1941/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3895\n",
      "LOG: Epoch [1941/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1941/2000], Avg Train Loss: 0.3895, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1942/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1942/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1942/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1943/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3969\n",
      "LOG: Epoch [1943/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1943/2000], Avg Train Loss: 0.3969, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1944/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3912\n",
      "LOG: Epoch [1944/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1944/2000], Avg Train Loss: 0.3912, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1945/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3894\n",
      "LOG: Epoch [1945/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1945/2000], Avg Train Loss: 0.3894, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1946/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3875\n",
      "LOG: Epoch [1946/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1946/2000], Avg Train Loss: 0.3875, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1947/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3892\n",
      "LOG: Epoch [1947/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1947/2000], Avg Train Loss: 0.3892, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1948/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [1948/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1948/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1949/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1949/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1949/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1950/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3897\n",
      "LOG: Epoch [1950/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1950/2000], Avg Train Loss: 0.3897, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1951/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3917\n",
      "LOG: Epoch [1951/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1951/2000], Avg Train Loss: 0.3917, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1952/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [1952/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1952/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1953/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1953/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1953/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1954/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3898\n",
      "LOG: Epoch [1954/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1954/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1955/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3936\n",
      "LOG: Epoch [1955/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1955/2000], Avg Train Loss: 0.3936, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1956/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1956/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1956/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1957/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3893\n",
      "LOG: Epoch [1957/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1957/2000], Avg Train Loss: 0.3893, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1958/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3944\n",
      "LOG: Epoch [1958/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1958/2000], Avg Train Loss: 0.3944, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1959/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [1959/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1959/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1960/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [1960/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1960/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1961/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3881\n",
      "LOG: Epoch [1961/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1961/2000], Avg Train Loss: 0.3881, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1962/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3908\n",
      "LOG: Epoch [1962/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1962/2000], Avg Train Loss: 0.3908, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1963/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3952\n",
      "LOG: Epoch [1963/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1963/2000], Avg Train Loss: 0.3952, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1964/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3900\n",
      "LOG: Epoch [1964/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1964/2000], Avg Train Loss: 0.3900, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1965/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3916\n",
      "LOG: Epoch [1965/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1965/2000], Avg Train Loss: 0.3916, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1966/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3937\n",
      "LOG: Epoch [1966/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1966/2000], Avg Train Loss: 0.3937, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1967/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3903\n",
      "LOG: Epoch [1967/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1967/2000], Avg Train Loss: 0.3903, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1968/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [1968/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1968/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1969/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3946\n",
      "LOG: Epoch [1969/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1969/2000], Avg Train Loss: 0.3946, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1970/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3909\n",
      "LOG: Epoch [1970/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1970/2000], Avg Train Loss: 0.3909, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1971/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [1971/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1971/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1972/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3897\n",
      "LOG: Epoch [1972/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1972/2000], Avg Train Loss: 0.3897, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1973/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3904\n",
      "LOG: Epoch [1973/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1973/2000], Avg Train Loss: 0.3904, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1974/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3938\n",
      "LOG: Epoch [1974/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1974/2000], Avg Train Loss: 0.3938, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1975/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3910\n",
      "LOG: Epoch [1975/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1975/2000], Avg Train Loss: 0.3910, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1976/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [1976/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1976/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1977/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1977/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1977/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1978/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [1978/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1978/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1979/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3957\n",
      "LOG: Epoch [1979/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1979/2000], Avg Train Loss: 0.3957, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1980/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3896\n",
      "LOG: Epoch [1980/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1980/2000], Avg Train Loss: 0.3896, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1981/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [1981/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1981/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1982/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3920\n",
      "LOG: Epoch [1982/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1982/2000], Avg Train Loss: 0.3920, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1983/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [1983/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1983/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1984/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3898\n",
      "LOG: Epoch [1984/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1984/2000], Avg Train Loss: 0.3898, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1985/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3925\n",
      "LOG: Epoch [1985/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1985/2000], Avg Train Loss: 0.3925, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1986/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1986/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1986/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1987/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3928\n",
      "LOG: Epoch [1987/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1987/2000], Avg Train Loss: 0.3928, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1988/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3933\n",
      "LOG: Epoch [1988/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1988/2000], Avg Train Loss: 0.3933, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1989/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3934\n",
      "LOG: Epoch [1989/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1989/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1990/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3916\n",
      "LOG: Epoch [1990/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1990/2000], Avg Train Loss: 0.3916, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1991/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3921\n",
      "LOG: Epoch [1991/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1991/2000], Avg Train Loss: 0.3921, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1992/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [1992/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1992/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1993/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3948\n",
      "LOG: Epoch [1993/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1993/2000], Avg Train Loss: 0.3948, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1994/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [1994/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1994/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1995/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [1995/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1995/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2086\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1996/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3934\n",
      "LOG: Epoch [1996/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1996/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1997/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3923\n",
      "LOG: Epoch [1997/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1997/2000], Avg Train Loss: 0.3923, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1998/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1998/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1998/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [1999/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [1999/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [1999/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n",
      "LOG: Epoch [2000/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3911\n",
      "LOG: Epoch [2000/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0568\n",
      "Epoch [2000/2000], Avg Train Loss: 0.3911, Avg Val Loss: 0.2086\n",
      "\n",
      "Validation loss improved from 0.2086 to 0.2086. Saving model...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_model = SupConNet().to(device)\n",
    "sclsdl_criterion = SilhouetteDistanceLoss()\n",
    "sclsdl_optimizer = optim.AdamW(sclsdl_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "sclsdl_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    sclsdl_optimizer, \n",
    "    mode='min',\n",
    "    patience=25,\n",
    "    factor=0.1\n",
    ")\n",
    "\n",
    "sclsdl_num_epochs = 2000\n",
    "\n",
    "sclsdl_patience = 100\n",
    "sclsdl_best_val_loss = float('inf')\n",
    "sclsdl_epochs_without_improvement = 0\n",
    "\n",
    "sclsdl_train_loss_history = []\n",
    "sclsdl_val_loss_history = []\n",
    "\n",
    "for sclsdl_epoch in range(sclsdl_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_model.train()\n",
    "    sclsdl_running_train_loss = 0.0\n",
    "    \n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Training\")\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_train_loader):\n",
    "\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_train_projections = sclsdl_model(vectors)\n",
    "\n",
    "        sclsdl_loss = sclsdl_criterion(sclsdl_train_projections, labels)\n",
    "\n",
    "        # Backprop and optimize\n",
    "        sclsdl_optimizer.zero_grad()\n",
    "        sclsdl_loss.backward()\n",
    "        sclsdl_optimizer.step()\n",
    "\n",
    "        sclsdl_running_train_loss += sclsdl_loss.item()\n",
    "        print(f\"    Batch [{batch_idx+1}/{len(sclsdl_train_loader)}], Train Loss: {sclsdl_loss.item():.4f}\")\n",
    "\n",
    "    sclsdl_train_epoch_loss = sclsdl_running_train_loss / len(sclsdl_train_loader)\n",
    "    sclsdl_train_loss_history.append(sclsdl_train_epoch_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_model.eval()\n",
    "    sclsdl_running_val_loss = 0.0\n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Validation\")\n",
    "    with torch.no_grad():\n",
    "        for val_batch_idx, (vectors, labels) in enumerate(sclsdl_val_loader):\n",
    "\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            sclsdl_val_projections = sclsdl_model(vectors)\n",
    "            sclsdl_val_batch_loss = sclsdl_criterion(sclsdl_val_projections, labels).item()\n",
    "            sclsdl_running_val_loss += sclsdl_val_batch_loss\n",
    "            print(f\"    Batch [{val_batch_idx+1}/{len(sclsdl_val_loader)}], Val Loss: {sclsdl_val_batch_loss:.4f}\")\n",
    "\n",
    "    sclsdl_val_epoch_loss = sclsdl_running_val_loss / len(sclsdl_val_loader)\n",
    "    sclsdl_val_loss_history.append(sclsdl_val_epoch_loss)\n",
    "    \n",
    "    sclsdl_scheduler.step(sclsdl_val_epoch_loss)\n",
    "\n",
    "    print(f\"Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {sclsdl_train_epoch_loss:.4f}, \"\n",
    "          f\"Avg Val Loss: {sclsdl_val_epoch_loss:.4f}\\n\")\n",
    "    \n",
    "    #early stopping logic\n",
    "    if sclsdl_val_epoch_loss < sclsdl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_best_val_loss:.4f} to {sclsdl_val_epoch_loss:.4f}. Saving model...\")\n",
    "        sclsdl_best_val_loss = sclsdl_val_epoch_loss\n",
    "        sclsdl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        sclsdl_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! Patience: {sclsdl_epochs_without_improvement}/{sclsdl_patience}\")\n",
    "\n",
    "    #stop training if val loss not improving\n",
    "    if sclsdl_epochs_without_improvement >= sclsdl_patience:\n",
    "        print(f\"!! Early stopping triggered at epoch {sclsdl_epoch + 1}!!\\nNo improvement for {sclsdl_patience} epochs\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Silhouette Distance Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:36:24.733238Z",
     "iopub.status.busy": "2025-05-08T19:36:24.732237Z",
     "iopub.status.idle": "2025-05-08T19:36:24.991248Z",
     "shell.execute_reply": "2025-05-08T19:36:24.991248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/46], Loss: 0.3048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [20/46], Loss: 0.2230\n",
      "Test Batch [30/46], Loss: 0.3094\n",
      "Test Batch [40/46], Loss: 0.2626\n",
      "\n",
      "Test Loss: 0.2856\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "sclsdl_model.eval()\n",
    "sclsdl_total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = sclsdl_model(vectors)\n",
    "        loss = sclsdl_criterion(projections, labels)\n",
    "        sclsdl_total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(sclsdl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "sclsdl_avg_test_loss = sclsdl_total_test_loss / len(sclsdl_test_loader)\n",
    "print(f\"\\nTest Loss: {sclsdl_avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=sclsdl_avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the representations learnt by SCL w/ SDL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:36:24.993258Z",
     "iopub.status.busy": "2025-05-08T19:36:24.993258Z",
     "iopub.status.idle": "2025-05-08T19:36:25.362111Z",
     "shell.execute_reply": "2025-05-08T19:36:25.362111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL_SDL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'sclsdl_representations\\train'.\n",
      "\n",
      "Extracting SCL_SDL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'sclsdl_representations\\val'.\n",
      "\n",
      "Extracting SCL_SDL representations for the test dataset...\n",
      "  Processed batch 10/46 for test dataset.\n",
      "  Processed batch 20/46 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 30/46 for test dataset.\n",
      "  Processed batch 40/46 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'sclsdl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "sclsdl_rep_dir = \"sclsdl_representations\"\n",
    "os.makedirs(sclsdl_rep_dir, exist_ok=True)\n",
    "\n",
    "sclsdl_loaders = {\n",
    "    'train': sclsdl_train_loader,\n",
    "    'val': sclsdl_val_loader,\n",
    "    'test': sclsdl_test_loader\n",
    "}\n",
    "\n",
    "sclsdl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_split_name, sclsdl_loader in sclsdl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL_SDL representations for the {sclsdl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        sclsdl_split_dir = os.path.join(sclsdl_rep_dir, sclsdl_split_name)\n",
    "        os.makedirs(sclsdl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for sclsdl_batch_idx, (sclsdl_vectors, sclsdl_labels) in enumerate(sclsdl_loader):\n",
    "            sclsdl_vectors = sclsdl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            sclsdl_projections = sclsdl_model(sclsdl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            sclsdl_projections_np = sclsdl_projections.cpu().numpy()\n",
    "            sclsdl_labels_np = sclsdl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_encoded_batch_{sclsdl_batch_idx}.npy\"), sclsdl_projections_np)\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_labels_batch_{sclsdl_batch_idx}.npy\"), sclsdl_labels_np)\n",
    "            \n",
    "            if (sclsdl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {sclsdl_batch_idx + 1}/{len(sclsdl_loader)} for {sclsdl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {sclsdl_split_name} dataset. Representations saved in '{sclsdl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by SCL w/ SDL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:36:25.365117Z",
     "iopub.status.busy": "2025-05-08T19:36:25.364118Z",
     "iopub.status.idle": "2025-05-08T19:36:25.368183Z",
     "shell.execute_reply": "2025-05-08T19:36:25.368183Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_sclsdl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    sclsdl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    sclsdl_all_reps = []\n",
    "    sclsdl_all_labels = []\n",
    "\n",
    "    for sclsdl_rep_file in sclsdl_rep_files:\n",
    "        #deriving label filenames\n",
    "        sclsdl_label_file = sclsdl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        sclsdl_reps = np.load(sclsdl_rep_file)\n",
    "        sclsdl_labels = np.load(sclsdl_label_file)\n",
    "\n",
    "        sclsdl_all_reps.append(sclsdl_reps)\n",
    "        sclsdl_all_labels.append(sclsdl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    sclsdl_all_reps = np.concatenate(sclsdl_all_reps, axis = 0)\n",
    "    sclsdl_all_labels = np.concatenate(sclsdl_all_labels, axis = 0)\n",
    "\n",
    "    return sclsdl_all_reps, sclsdl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:36:25.370709Z",
     "iopub.status.busy": "2025-05-08T19:36:25.369705Z",
     "iopub.status.idle": "2025-05-08T19:36:25.934710Z",
     "shell.execute_reply": "2025-05-08T19:36:25.934710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (280, 128)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 128)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_lrm_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_lrm_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_lrm_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_lrm_train_reps, sclsdl_lrm_train_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_train_dir)\n",
    "sclsdl_lrm_val_reps, sclsdl_lrm_val_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_val_dir)\n",
    "sclsdl_lrm_test_reps, sclsdl_lrm_test_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:36:25.937834Z",
     "iopub.status.busy": "2025-05-08T19:36:25.936834Z",
     "iopub.status.idle": "2025-05-08T19:36:25.982252Z",
     "shell.execute_reply": "2025-05-08T19:36:25.982252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 94.29%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       0.83      1.00      0.91         5\n",
      "           4       1.00      0.80      0.89         5\n",
      "           5       0.60      0.60      0.60         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       0.80      0.80      0.80         5\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.94        70\n",
      "   macro avg       0.95      0.94      0.94        70\n",
      "weighted avg       0.95      0.94      0.94        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 85.85%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       245\n",
      "           1       0.88      0.89      0.89        76\n",
      "           2       0.90      0.95      0.93       226\n",
      "           3       0.87      0.99      0.93       190\n",
      "           4       0.80      0.72      0.75       244\n",
      "           5       0.63      0.69      0.66       244\n",
      "           6       1.00      0.91      0.95       234\n",
      "           7       0.81      0.85      0.83       178\n",
      "           8       0.81      0.66      0.73       289\n",
      "           9       0.78      0.93      0.85       223\n",
      "          10       0.96      0.86      0.91       280\n",
      "          11       0.93      0.99      0.96       156\n",
      "          12       0.84      0.84      0.84       243\n",
      "          13       1.00      0.94      0.97        70\n",
      "\n",
      "    accuracy                           0.86      2898\n",
      "   macro avg       0.87      0.87      0.87      2898\n",
      "weighted avg       0.86      0.86      0.86      2898\n",
      "\n",
      "Saved SCL_SDL+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression Model on the SCLSDL representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "sclsdl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "sclsdl_logistic_clf.fit(sclsdl_lrm_train_reps, sclsdl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "sclsdl_lrm_val_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_val_reps)\n",
    "sclsdl_lrm_val_accuracy = accuracy_score(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {sclsdl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions))\n",
    "\n",
    "# Evaluate on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "sclsdl_lrm_test_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_test_reps)\n",
    "sclsdl_lrm_test_accuracy = accuracy_score(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {sclsdl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_predictions.npy'), sclsdl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_true_labels.npy'), sclsdl_lrm_test_labels)\n",
    "print(f\"Saved SCL_SDL+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the representations learnt by SCL w/ SDL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:36:25.985259Z",
     "iopub.status.busy": "2025-05-08T19:36:25.985259Z",
     "iopub.status.idle": "2025-05-08T19:36:26.002109Z",
     "shell.execute_reply": "2025-05-08T19:36:26.002109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (280, 128)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 128)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_mlp_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_mlp_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_mlp_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_mlp_train_reps, sclsdl_mlp_train_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_train_dir)\n",
    "sclsdl_mlp_val_reps, sclsdl_mlp_val_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_val_dir)\n",
    "sclsdl_mlp_test_reps, sclsdl_mlp_test_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:36:26.004123Z",
     "iopub.status.busy": "2025-05-08T19:36:26.004123Z",
     "iopub.status.idle": "2025-05-08T19:36:26.009637Z",
     "shell.execute_reply": "2025-05-08T19:36:26.009637Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "sclsdl_mlp_train_embeddings_torch = torch.tensor(sclsdl_mlp_train_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_train_labels_torch = torch.tensor(sclsdl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_val_embeddings_torch = torch.tensor(sclsdl_mlp_val_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_val_labels_torch = torch.tensor(sclsdl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_test_embeddings_torch = torch.tensor(sclsdl_mlp_test_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_test_labels_torch = torch.tensor(sclsdl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "sclsdl_mlp_train_dataset = TensorDataset(sclsdl_mlp_train_embeddings_torch, sclsdl_mlp_train_labels_torch)\n",
    "sclsdl_mlp_val_dataset = TensorDataset(sclsdl_mlp_val_embeddings_torch, sclsdl_mlp_val_labels_torch)\n",
    "sclsdl_mlp_test_dataset = TensorDataset(sclsdl_mlp_test_embeddings_torch, sclsdl_mlp_test_labels_torch)\n",
    "\n",
    "sclsdl_mlp_batch_size = 64\n",
    "sclsdl_mlp_train_loader = DataLoader(sclsdl_mlp_train_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=True)\n",
    "sclsdl_mlp_val_loader = DataLoader(sclsdl_mlp_val_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n",
    "sclsdl_mlp_test_loader = DataLoader(sclsdl_mlp_test_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:36:26.012648Z",
     "iopub.status.busy": "2025-05-08T19:36:26.012648Z",
     "iopub.status.idle": "2025-05-08T19:36:32.132217Z",
     "shell.execute_reply": "2025-05-08T19:36:32.132217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.7094  |  Val Loss: 2.6919\n",
      "Validation loss improved from inf to 2.6919.\n",
      "[Epoch 2/1000] Train Loss: 2.6819  |  Val Loss: 2.6667\n",
      "Validation loss improved from 2.6919 to 2.6667.\n",
      "[Epoch 3/1000] Train Loss: 2.6570  |  Val Loss: 2.6441\n",
      "Validation loss improved from 2.6667 to 2.6441.\n",
      "[Epoch 4/1000] Train Loss: 2.6347  |  Val Loss: 2.6218\n",
      "Validation loss improved from 2.6441 to 2.6218.\n",
      "[Epoch 5/1000] Train Loss: 2.6120  |  Val Loss: 2.6008\n",
      "Validation loss improved from 2.6218 to 2.6008.\n",
      "[Epoch 6/1000] Train Loss: 2.5912  |  Val Loss: 2.5796\n",
      "Validation loss improved from 2.6008 to 2.5796.\n",
      "[Epoch 7/1000] Train Loss: 2.5709  |  Val Loss: 2.5587\n",
      "Validation loss improved from 2.5796 to 2.5587.\n",
      "[Epoch 8/1000] Train Loss: 2.5504  |  Val Loss: 2.5380\n",
      "Validation loss improved from 2.5587 to 2.5380.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/1000] Train Loss: 2.5308  |  Val Loss: 2.5179\n",
      "Validation loss improved from 2.5380 to 2.5179.\n",
      "[Epoch 10/1000] Train Loss: 2.5119  |  Val Loss: 2.4982\n",
      "Validation loss improved from 2.5179 to 2.4982.\n",
      "[Epoch 11/1000] Train Loss: 2.4932  |  Val Loss: 2.4788\n",
      "Validation loss improved from 2.4982 to 2.4788.\n",
      "[Epoch 12/1000] Train Loss: 2.4741  |  Val Loss: 2.4596\n",
      "Validation loss improved from 2.4788 to 2.4596.\n",
      "[Epoch 13/1000] Train Loss: 2.4555  |  Val Loss: 2.4405\n",
      "Validation loss improved from 2.4596 to 2.4405.\n",
      "[Epoch 14/1000] Train Loss: 2.4370  |  Val Loss: 2.4212\n",
      "Validation loss improved from 2.4405 to 2.4212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/1000] Train Loss: 2.4175  |  Val Loss: 2.4023\n",
      "Validation loss improved from 2.4212 to 2.4023.\n",
      "[Epoch 16/1000] Train Loss: 2.3986  |  Val Loss: 2.3836\n",
      "Validation loss improved from 2.4023 to 2.3836.\n",
      "[Epoch 17/1000] Train Loss: 2.3798  |  Val Loss: 2.3642\n",
      "Validation loss improved from 2.3836 to 2.3642.\n",
      "[Epoch 18/1000] Train Loss: 2.3600  |  Val Loss: 2.3443\n",
      "Validation loss improved from 2.3642 to 2.3443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/1000] Train Loss: 2.3404  |  Val Loss: 2.3240\n",
      "Validation loss improved from 2.3443 to 2.3240.\n",
      "[Epoch 20/1000] Train Loss: 2.3199  |  Val Loss: 2.3033\n",
      "Validation loss improved from 2.3240 to 2.3033.\n",
      "[Epoch 21/1000] Train Loss: 2.2997  |  Val Loss: 2.2825\n",
      "Validation loss improved from 2.3033 to 2.2825.\n",
      "[Epoch 22/1000] Train Loss: 2.2789  |  Val Loss: 2.2620\n",
      "Validation loss improved from 2.2825 to 2.2620.\n",
      "[Epoch 23/1000] Train Loss: 2.2590  |  Val Loss: 2.2416\n",
      "Validation loss improved from 2.2620 to 2.2416.\n",
      "[Epoch 24/1000] Train Loss: 2.2383  |  Val Loss: 2.2214\n",
      "Validation loss improved from 2.2416 to 2.2214.\n",
      "[Epoch 25/1000] Train Loss: 2.2170  |  Val Loss: 2.2012\n",
      "Validation loss improved from 2.2214 to 2.2012.\n",
      "[Epoch 26/1000] Train Loss: 2.1968  |  Val Loss: 2.1806\n",
      "Validation loss improved from 2.2012 to 2.1806.\n",
      "[Epoch 27/1000] Train Loss: 2.1759  |  Val Loss: 2.1604\n",
      "Validation loss improved from 2.1806 to 2.1604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/1000] Train Loss: 2.1548  |  Val Loss: 2.1403\n",
      "Validation loss improved from 2.1604 to 2.1403.\n",
      "[Epoch 29/1000] Train Loss: 2.1345  |  Val Loss: 2.1201\n",
      "Validation loss improved from 2.1403 to 2.1201.\n",
      "[Epoch 30/1000] Train Loss: 2.1141  |  Val Loss: 2.0998\n",
      "Validation loss improved from 2.1201 to 2.0998.\n",
      "[Epoch 31/1000] Train Loss: 2.0928  |  Val Loss: 2.0798\n",
      "Validation loss improved from 2.0998 to 2.0798.\n",
      "[Epoch 32/1000] Train Loss: 2.0722  |  Val Loss: 2.0603\n",
      "Validation loss improved from 2.0798 to 2.0603.\n",
      "[Epoch 33/1000] Train Loss: 2.0518  |  Val Loss: 2.0409\n",
      "Validation loss improved from 2.0603 to 2.0409.\n",
      "[Epoch 34/1000] Train Loss: 2.0317  |  Val Loss: 2.0215\n",
      "Validation loss improved from 2.0409 to 2.0215.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35/1000] Train Loss: 2.0114  |  Val Loss: 2.0028\n",
      "Validation loss improved from 2.0215 to 2.0028.\n",
      "[Epoch 36/1000] Train Loss: 1.9916  |  Val Loss: 1.9845\n",
      "Validation loss improved from 2.0028 to 1.9845.\n",
      "[Epoch 37/1000] Train Loss: 1.9721  |  Val Loss: 1.9662\n",
      "Validation loss improved from 1.9845 to 1.9662.\n",
      "[Epoch 38/1000] Train Loss: 1.9528  |  Val Loss: 1.9480\n",
      "Validation loss improved from 1.9662 to 1.9480.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39/1000] Train Loss: 1.9336  |  Val Loss: 1.9303\n",
      "Validation loss improved from 1.9480 to 1.9303.\n",
      "[Epoch 40/1000] Train Loss: 1.9152  |  Val Loss: 1.9123\n",
      "Validation loss improved from 1.9303 to 1.9123.\n",
      "[Epoch 41/1000] Train Loss: 1.8967  |  Val Loss: 1.8946\n",
      "Validation loss improved from 1.9123 to 1.8946.\n",
      "[Epoch 42/1000] Train Loss: 1.8780  |  Val Loss: 1.8773\n",
      "Validation loss improved from 1.8946 to 1.8773.\n",
      "[Epoch 43/1000] Train Loss: 1.8602  |  Val Loss: 1.8602\n",
      "Validation loss improved from 1.8773 to 1.8602.\n",
      "[Epoch 44/1000] Train Loss: 1.8424  |  Val Loss: 1.8431\n",
      "Validation loss improved from 1.8602 to 1.8431.\n",
      "[Epoch 45/1000] Train Loss: 1.8250  |  Val Loss: 1.8265\n",
      "Validation loss improved from 1.8431 to 1.8265.\n",
      "[Epoch 46/1000] Train Loss: 1.8073  |  Val Loss: 1.8099\n",
      "Validation loss improved from 1.8265 to 1.8099.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 47/1000] Train Loss: 1.7896  |  Val Loss: 1.7934\n",
      "Validation loss improved from 1.8099 to 1.7934.\n",
      "[Epoch 48/1000] Train Loss: 1.7724  |  Val Loss: 1.7770\n",
      "Validation loss improved from 1.7934 to 1.7770.\n",
      "[Epoch 49/1000] Train Loss: 1.7553  |  Val Loss: 1.7607\n",
      "Validation loss improved from 1.7770 to 1.7607.\n",
      "[Epoch 50/1000] Train Loss: 1.7379  |  Val Loss: 1.7447\n",
      "Validation loss improved from 1.7607 to 1.7447.\n",
      "[Epoch 51/1000] Train Loss: 1.7208  |  Val Loss: 1.7289\n",
      "Validation loss improved from 1.7447 to 1.7289.\n",
      "[Epoch 52/1000] Train Loss: 1.7039  |  Val Loss: 1.7129\n",
      "Validation loss improved from 1.7289 to 1.7129.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 53/1000] Train Loss: 1.6873  |  Val Loss: 1.6967\n",
      "Validation loss improved from 1.7129 to 1.6967.\n",
      "[Epoch 54/1000] Train Loss: 1.6701  |  Val Loss: 1.6811\n",
      "Validation loss improved from 1.6967 to 1.6811.\n",
      "[Epoch 55/1000] Train Loss: 1.6535  |  Val Loss: 1.6655\n",
      "Validation loss improved from 1.6811 to 1.6655.\n",
      "[Epoch 56/1000] Train Loss: 1.6369  |  Val Loss: 1.6499\n",
      "Validation loss improved from 1.6655 to 1.6499.\n",
      "[Epoch 57/1000] Train Loss: 1.6204  |  Val Loss: 1.6343\n",
      "Validation loss improved from 1.6499 to 1.6343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 58/1000] Train Loss: 1.6034  |  Val Loss: 1.6186\n",
      "Validation loss improved from 1.6343 to 1.6186.\n",
      "[Epoch 59/1000] Train Loss: 1.5870  |  Val Loss: 1.6030\n",
      "Validation loss improved from 1.6186 to 1.6030.\n",
      "[Epoch 60/1000] Train Loss: 1.5704  |  Val Loss: 1.5874\n",
      "Validation loss improved from 1.6030 to 1.5874.\n",
      "[Epoch 61/1000] Train Loss: 1.5546  |  Val Loss: 1.5717\n",
      "Validation loss improved from 1.5874 to 1.5717.\n",
      "[Epoch 62/1000] Train Loss: 1.5379  |  Val Loss: 1.5563\n",
      "Validation loss improved from 1.5717 to 1.5563.\n",
      "[Epoch 63/1000] Train Loss: 1.5211  |  Val Loss: 1.5414\n",
      "Validation loss improved from 1.5563 to 1.5414.\n",
      "[Epoch 64/1000] Train Loss: 1.5047  |  Val Loss: 1.5263\n",
      "Validation loss improved from 1.5414 to 1.5263.\n",
      "[Epoch 65/1000] Train Loss: 1.4881  |  Val Loss: 1.5109\n",
      "Validation loss improved from 1.5263 to 1.5109.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 66/1000] Train Loss: 1.4716  |  Val Loss: 1.4954\n",
      "Validation loss improved from 1.5109 to 1.4954.\n",
      "[Epoch 67/1000] Train Loss: 1.4547  |  Val Loss: 1.4797\n",
      "Validation loss improved from 1.4954 to 1.4797.\n",
      "[Epoch 68/1000] Train Loss: 1.4378  |  Val Loss: 1.4635\n",
      "Validation loss improved from 1.4797 to 1.4635.\n",
      "[Epoch 69/1000] Train Loss: 1.4206  |  Val Loss: 1.4471\n",
      "Validation loss improved from 1.4635 to 1.4471.\n",
      "[Epoch 70/1000] Train Loss: 1.4033  |  Val Loss: 1.4303\n",
      "Validation loss improved from 1.4471 to 1.4303.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 71/1000] Train Loss: 1.3858  |  Val Loss: 1.4134\n",
      "Validation loss improved from 1.4303 to 1.4134.\n",
      "[Epoch 72/1000] Train Loss: 1.3684  |  Val Loss: 1.3961\n",
      "Validation loss improved from 1.4134 to 1.3961.\n",
      "[Epoch 73/1000] Train Loss: 1.3506  |  Val Loss: 1.3791\n",
      "Validation loss improved from 1.3961 to 1.3791.\n",
      "[Epoch 74/1000] Train Loss: 1.3332  |  Val Loss: 1.3619\n",
      "Validation loss improved from 1.3791 to 1.3619.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 75/1000] Train Loss: 1.3155  |  Val Loss: 1.3445\n",
      "Validation loss improved from 1.3619 to 1.3445.\n",
      "[Epoch 76/1000] Train Loss: 1.2982  |  Val Loss: 1.3274\n",
      "Validation loss improved from 1.3445 to 1.3274.\n",
      "[Epoch 77/1000] Train Loss: 1.2804  |  Val Loss: 1.3100\n",
      "Validation loss improved from 1.3274 to 1.3100.\n",
      "[Epoch 78/1000] Train Loss: 1.2633  |  Val Loss: 1.2926\n",
      "Validation loss improved from 1.3100 to 1.2926.\n",
      "[Epoch 79/1000] Train Loss: 1.2456  |  Val Loss: 1.2751\n",
      "Validation loss improved from 1.2926 to 1.2751.\n",
      "[Epoch 80/1000] Train Loss: 1.2280  |  Val Loss: 1.2578\n",
      "Validation loss improved from 1.2751 to 1.2578.\n",
      "[Epoch 81/1000] Train Loss: 1.2104  |  Val Loss: 1.2408\n",
      "Validation loss improved from 1.2578 to 1.2408.\n",
      "[Epoch 82/1000] Train Loss: 1.1931  |  Val Loss: 1.2239\n",
      "Validation loss improved from 1.2408 to 1.2239.\n",
      "[Epoch 83/1000] Train Loss: 1.1754  |  Val Loss: 1.2068\n",
      "Validation loss improved from 1.2239 to 1.2068.\n",
      "[Epoch 84/1000] Train Loss: 1.1581  |  Val Loss: 1.1899\n",
      "Validation loss improved from 1.2068 to 1.1899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 85/1000] Train Loss: 1.1413  |  Val Loss: 1.1727\n",
      "Validation loss improved from 1.1899 to 1.1727.\n",
      "[Epoch 86/1000] Train Loss: 1.1240  |  Val Loss: 1.1563\n",
      "Validation loss improved from 1.1727 to 1.1563.\n",
      "[Epoch 87/1000] Train Loss: 1.1068  |  Val Loss: 1.1397\n",
      "Validation loss improved from 1.1563 to 1.1397.\n",
      "[Epoch 88/1000] Train Loss: 1.0904  |  Val Loss: 1.1225\n",
      "Validation loss improved from 1.1397 to 1.1225.\n",
      "[Epoch 89/1000] Train Loss: 1.0732  |  Val Loss: 1.1058\n",
      "Validation loss improved from 1.1225 to 1.1058.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 90/1000] Train Loss: 1.0569  |  Val Loss: 1.0891\n",
      "Validation loss improved from 1.1058 to 1.0891.\n",
      "[Epoch 91/1000] Train Loss: 1.0403  |  Val Loss: 1.0725\n",
      "Validation loss improved from 1.0891 to 1.0725.\n",
      "[Epoch 92/1000] Train Loss: 1.0241  |  Val Loss: 1.0563\n",
      "Validation loss improved from 1.0725 to 1.0563.\n",
      "[Epoch 93/1000] Train Loss: 1.0080  |  Val Loss: 1.0400\n",
      "Validation loss improved from 1.0563 to 1.0400.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 94/1000] Train Loss: 0.9923  |  Val Loss: 1.0241\n",
      "Validation loss improved from 1.0400 to 1.0241.\n",
      "[Epoch 95/1000] Train Loss: 0.9768  |  Val Loss: 1.0081\n",
      "Validation loss improved from 1.0241 to 1.0081.\n",
      "[Epoch 96/1000] Train Loss: 0.9617  |  Val Loss: 0.9927\n",
      "Validation loss improved from 1.0081 to 0.9927.\n",
      "[Epoch 97/1000] Train Loss: 0.9454  |  Val Loss: 0.9780\n",
      "Validation loss improved from 0.9927 to 0.9780.\n",
      "[Epoch 98/1000] Train Loss: 0.9311  |  Val Loss: 0.9632\n",
      "Validation loss improved from 0.9780 to 0.9632.\n",
      "[Epoch 99/1000] Train Loss: 0.9160  |  Val Loss: 0.9486\n",
      "Validation loss improved from 0.9632 to 0.9486.\n",
      "[Epoch 100/1000] Train Loss: 0.9017  |  Val Loss: 0.9341\n",
      "Validation loss improved from 0.9486 to 0.9341.\n",
      "[Epoch 101/1000] Train Loss: 0.8868  |  Val Loss: 0.9203\n",
      "Validation loss improved from 0.9341 to 0.9203.\n",
      "[Epoch 102/1000] Train Loss: 0.8729  |  Val Loss: 0.9067\n",
      "Validation loss improved from 0.9203 to 0.9067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 103/1000] Train Loss: 0.8589  |  Val Loss: 0.8928\n",
      "Validation loss improved from 0.9067 to 0.8928.\n",
      "[Epoch 104/1000] Train Loss: 0.8450  |  Val Loss: 0.8788\n",
      "Validation loss improved from 0.8928 to 0.8788.\n",
      "[Epoch 105/1000] Train Loss: 0.8316  |  Val Loss: 0.8653\n",
      "Validation loss improved from 0.8788 to 0.8653.\n",
      "[Epoch 106/1000] Train Loss: 0.8182  |  Val Loss: 0.8524\n",
      "Validation loss improved from 0.8653 to 0.8524.\n",
      "[Epoch 107/1000] Train Loss: 0.8051  |  Val Loss: 0.8397\n",
      "Validation loss improved from 0.8524 to 0.8397.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 108/1000] Train Loss: 0.7923  |  Val Loss: 0.8272\n",
      "Validation loss improved from 0.8397 to 0.8272.\n",
      "[Epoch 109/1000] Train Loss: 0.7798  |  Val Loss: 0.8149\n",
      "Validation loss improved from 0.8272 to 0.8149.\n",
      "[Epoch 110/1000] Train Loss: 0.7674  |  Val Loss: 0.8031\n",
      "Validation loss improved from 0.8149 to 0.8031.\n",
      "[Epoch 111/1000] Train Loss: 0.7553  |  Val Loss: 0.7914\n",
      "Validation loss improved from 0.8031 to 0.7914.\n",
      "[Epoch 112/1000] Train Loss: 0.7435  |  Val Loss: 0.7799\n",
      "Validation loss improved from 0.7914 to 0.7799.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 113/1000] Train Loss: 0.7316  |  Val Loss: 0.7691\n",
      "Validation loss improved from 0.7799 to 0.7691.\n",
      "[Epoch 114/1000] Train Loss: 0.7201  |  Val Loss: 0.7584\n",
      "Validation loss improved from 0.7691 to 0.7584.\n",
      "[Epoch 115/1000] Train Loss: 0.7088  |  Val Loss: 0.7479\n",
      "Validation loss improved from 0.7584 to 0.7479.\n",
      "[Epoch 116/1000] Train Loss: 0.6977  |  Val Loss: 0.7372\n",
      "Validation loss improved from 0.7479 to 0.7372.\n",
      "[Epoch 117/1000] Train Loss: 0.6867  |  Val Loss: 0.7267\n",
      "Validation loss improved from 0.7372 to 0.7267.\n",
      "[Epoch 118/1000] Train Loss: 0.6764  |  Val Loss: 0.7163\n",
      "Validation loss improved from 0.7267 to 0.7163.\n",
      "[Epoch 119/1000] Train Loss: 0.6659  |  Val Loss: 0.7058\n",
      "Validation loss improved from 0.7163 to 0.7058.\n",
      "[Epoch 120/1000] Train Loss: 0.6553  |  Val Loss: 0.6957\n",
      "Validation loss improved from 0.7058 to 0.6957.\n",
      "[Epoch 121/1000] Train Loss: 0.6452  |  Val Loss: 0.6854\n",
      "Validation loss improved from 0.6957 to 0.6854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 122/1000] Train Loss: 0.6352  |  Val Loss: 0.6755\n",
      "Validation loss improved from 0.6854 to 0.6755.\n",
      "[Epoch 123/1000] Train Loss: 0.6253  |  Val Loss: 0.6660\n",
      "Validation loss improved from 0.6755 to 0.6660.\n",
      "[Epoch 124/1000] Train Loss: 0.6159  |  Val Loss: 0.6567\n",
      "Validation loss improved from 0.6660 to 0.6567.\n",
      "[Epoch 125/1000] Train Loss: 0.6061  |  Val Loss: 0.6478\n",
      "Validation loss improved from 0.6567 to 0.6478.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 126/1000] Train Loss: 0.5970  |  Val Loss: 0.6391\n",
      "Validation loss improved from 0.6478 to 0.6391.\n",
      "[Epoch 127/1000] Train Loss: 0.5881  |  Val Loss: 0.6301\n",
      "Validation loss improved from 0.6391 to 0.6301.\n",
      "[Epoch 128/1000] Train Loss: 0.5794  |  Val Loss: 0.6214\n",
      "Validation loss improved from 0.6301 to 0.6214.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 129/1000] Train Loss: 0.5706  |  Val Loss: 0.6130\n",
      "Validation loss improved from 0.6214 to 0.6130.\n",
      "[Epoch 130/1000] Train Loss: 0.5622  |  Val Loss: 0.6047\n",
      "Validation loss improved from 0.6130 to 0.6047.\n",
      "[Epoch 131/1000] Train Loss: 0.5539  |  Val Loss: 0.5971\n",
      "Validation loss improved from 0.6047 to 0.5971.\n",
      "[Epoch 132/1000] Train Loss: 0.5457  |  Val Loss: 0.5899\n",
      "Validation loss improved from 0.5971 to 0.5899.\n",
      "[Epoch 133/1000] Train Loss: 0.5378  |  Val Loss: 0.5826\n",
      "Validation loss improved from 0.5899 to 0.5826.\n",
      "[Epoch 134/1000] Train Loss: 0.5299  |  Val Loss: 0.5751\n",
      "Validation loss improved from 0.5826 to 0.5751.\n",
      "[Epoch 135/1000] Train Loss: 0.5221  |  Val Loss: 0.5674\n",
      "Validation loss improved from 0.5751 to 0.5674.\n",
      "[Epoch 136/1000] Train Loss: 0.5146  |  Val Loss: 0.5600\n",
      "Validation loss improved from 0.5674 to 0.5600.\n",
      "[Epoch 137/1000] Train Loss: 0.5069  |  Val Loss: 0.5533\n",
      "Validation loss improved from 0.5600 to 0.5533.\n",
      "[Epoch 138/1000] Train Loss: 0.4995  |  Val Loss: 0.5461\n",
      "Validation loss improved from 0.5533 to 0.5461.\n",
      "[Epoch 139/1000] Train Loss: 0.4918  |  Val Loss: 0.5390\n",
      "Validation loss improved from 0.5461 to 0.5390.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 140/1000] Train Loss: 0.4846  |  Val Loss: 0.5317\n",
      "Validation loss improved from 0.5390 to 0.5317.\n",
      "[Epoch 141/1000] Train Loss: 0.4776  |  Val Loss: 0.5248\n",
      "Validation loss improved from 0.5317 to 0.5248.\n",
      "[Epoch 142/1000] Train Loss: 0.4704  |  Val Loss: 0.5181\n",
      "Validation loss improved from 0.5248 to 0.5181.\n",
      "[Epoch 143/1000] Train Loss: 0.4634  |  Val Loss: 0.5118\n",
      "Validation loss improved from 0.5181 to 0.5118.\n",
      "[Epoch 144/1000] Train Loss: 0.4567  |  Val Loss: 0.5059\n",
      "Validation loss improved from 0.5118 to 0.5059.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 145/1000] Train Loss: 0.4501  |  Val Loss: 0.4999\n",
      "Validation loss improved from 0.5059 to 0.4999.\n",
      "[Epoch 146/1000] Train Loss: 0.4435  |  Val Loss: 0.4938\n",
      "Validation loss improved from 0.4999 to 0.4938.\n",
      "[Epoch 147/1000] Train Loss: 0.4371  |  Val Loss: 0.4873\n",
      "Validation loss improved from 0.4938 to 0.4873.\n",
      "[Epoch 148/1000] Train Loss: 0.4307  |  Val Loss: 0.4813\n",
      "Validation loss improved from 0.4873 to 0.4813.\n",
      "[Epoch 149/1000] Train Loss: 0.4244  |  Val Loss: 0.4751\n",
      "Validation loss improved from 0.4813 to 0.4751.\n",
      "[Epoch 150/1000] Train Loss: 0.4183  |  Val Loss: 0.4691\n",
      "Validation loss improved from 0.4751 to 0.4691.\n",
      "[Epoch 151/1000] Train Loss: 0.4125  |  Val Loss: 0.4632\n",
      "Validation loss improved from 0.4691 to 0.4632.\n",
      "[Epoch 152/1000] Train Loss: 0.4065  |  Val Loss: 0.4579\n",
      "Validation loss improved from 0.4632 to 0.4579.\n",
      "[Epoch 153/1000] Train Loss: 0.4006  |  Val Loss: 0.4520\n",
      "Validation loss improved from 0.4579 to 0.4520.\n",
      "[Epoch 154/1000] Train Loss: 0.3953  |  Val Loss: 0.4463\n",
      "Validation loss improved from 0.4520 to 0.4463.\n",
      "[Epoch 155/1000] Train Loss: 0.3900  |  Val Loss: 0.4411\n",
      "Validation loss improved from 0.4463 to 0.4411.\n",
      "[Epoch 156/1000] Train Loss: 0.3846  |  Val Loss: 0.4362\n",
      "Validation loss improved from 0.4411 to 0.4362.\n",
      "[Epoch 157/1000] Train Loss: 0.3792  |  Val Loss: 0.4319\n",
      "Validation loss improved from 0.4362 to 0.4319.\n",
      "[Epoch 158/1000] Train Loss: 0.3740  |  Val Loss: 0.4275\n",
      "Validation loss improved from 0.4319 to 0.4275.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 159/1000] Train Loss: 0.3692  |  Val Loss: 0.4238\n",
      "Validation loss improved from 0.4275 to 0.4238.\n",
      "[Epoch 160/1000] Train Loss: 0.3643  |  Val Loss: 0.4199\n",
      "Validation loss improved from 0.4238 to 0.4199.\n",
      "[Epoch 161/1000] Train Loss: 0.3595  |  Val Loss: 0.4159\n",
      "Validation loss improved from 0.4199 to 0.4159.\n",
      "[Epoch 162/1000] Train Loss: 0.3549  |  Val Loss: 0.4115\n",
      "Validation loss improved from 0.4159 to 0.4115.\n",
      "[Epoch 163/1000] Train Loss: 0.3502  |  Val Loss: 0.4075\n",
      "Validation loss improved from 0.4115 to 0.4075.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 164/1000] Train Loss: 0.3458  |  Val Loss: 0.4033\n",
      "Validation loss improved from 0.4075 to 0.4033.\n",
      "[Epoch 165/1000] Train Loss: 0.3413  |  Val Loss: 0.3996\n",
      "Validation loss improved from 0.4033 to 0.3996.\n",
      "[Epoch 166/1000] Train Loss: 0.3370  |  Val Loss: 0.3953\n",
      "Validation loss improved from 0.3996 to 0.3953.\n",
      "[Epoch 167/1000] Train Loss: 0.3329  |  Val Loss: 0.3913\n",
      "Validation loss improved from 0.3953 to 0.3913.\n",
      "[Epoch 168/1000] Train Loss: 0.3289  |  Val Loss: 0.3877\n",
      "Validation loss improved from 0.3913 to 0.3877.\n",
      "[Epoch 169/1000] Train Loss: 0.3247  |  Val Loss: 0.3834\n",
      "Validation loss improved from 0.3877 to 0.3834.\n",
      "[Epoch 170/1000] Train Loss: 0.3209  |  Val Loss: 0.3799\n",
      "Validation loss improved from 0.3834 to 0.3799.\n",
      "[Epoch 171/1000] Train Loss: 0.3169  |  Val Loss: 0.3768\n",
      "Validation loss improved from 0.3799 to 0.3768.\n",
      "[Epoch 172/1000] Train Loss: 0.3130  |  Val Loss: 0.3737\n",
      "Validation loss improved from 0.3768 to 0.3737.\n",
      "[Epoch 173/1000] Train Loss: 0.3095  |  Val Loss: 0.3709\n",
      "Validation loss improved from 0.3737 to 0.3709.\n",
      "[Epoch 174/1000] Train Loss: 0.3058  |  Val Loss: 0.3676\n",
      "Validation loss improved from 0.3709 to 0.3676.\n",
      "[Epoch 175/1000] Train Loss: 0.3022  |  Val Loss: 0.3645\n",
      "Validation loss improved from 0.3676 to 0.3645.\n",
      "[Epoch 176/1000] Train Loss: 0.2990  |  Val Loss: 0.3619\n",
      "Validation loss improved from 0.3645 to 0.3619.\n",
      "[Epoch 177/1000] Train Loss: 0.2955  |  Val Loss: 0.3589\n",
      "Validation loss improved from 0.3619 to 0.3589.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 178/1000] Train Loss: 0.2921  |  Val Loss: 0.3563\n",
      "Validation loss improved from 0.3589 to 0.3563.\n",
      "[Epoch 179/1000] Train Loss: 0.2886  |  Val Loss: 0.3534\n",
      "Validation loss improved from 0.3563 to 0.3534.\n",
      "[Epoch 180/1000] Train Loss: 0.2857  |  Val Loss: 0.3504\n",
      "Validation loss improved from 0.3534 to 0.3504.\n",
      "[Epoch 181/1000] Train Loss: 0.2826  |  Val Loss: 0.3477\n",
      "Validation loss improved from 0.3504 to 0.3477.\n",
      "[Epoch 182/1000] Train Loss: 0.2792  |  Val Loss: 0.3453\n",
      "Validation loss improved from 0.3477 to 0.3453.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 183/1000] Train Loss: 0.2767  |  Val Loss: 0.3427\n",
      "Validation loss improved from 0.3453 to 0.3427.\n",
      "[Epoch 184/1000] Train Loss: 0.2734  |  Val Loss: 0.3405\n",
      "Validation loss improved from 0.3427 to 0.3405.\n",
      "[Epoch 185/1000] Train Loss: 0.2705  |  Val Loss: 0.3380\n",
      "Validation loss improved from 0.3405 to 0.3380.\n",
      "[Epoch 186/1000] Train Loss: 0.2675  |  Val Loss: 0.3359\n",
      "Validation loss improved from 0.3380 to 0.3359.\n",
      "[Epoch 187/1000] Train Loss: 0.2651  |  Val Loss: 0.3336\n",
      "Validation loss improved from 0.3359 to 0.3336.\n",
      "[Epoch 188/1000] Train Loss: 0.2622  |  Val Loss: 0.3312\n",
      "Validation loss improved from 0.3336 to 0.3312.\n",
      "[Epoch 189/1000] Train Loss: 0.2594  |  Val Loss: 0.3288\n",
      "Validation loss improved from 0.3312 to 0.3288.\n",
      "[Epoch 190/1000] Train Loss: 0.2567  |  Val Loss: 0.3267\n",
      "Validation loss improved from 0.3288 to 0.3267.\n",
      "[Epoch 191/1000] Train Loss: 0.2541  |  Val Loss: 0.3243\n",
      "Validation loss improved from 0.3267 to 0.3243.\n",
      "[Epoch 192/1000] Train Loss: 0.2517  |  Val Loss: 0.3224\n",
      "Validation loss improved from 0.3243 to 0.3224.\n",
      "[Epoch 193/1000] Train Loss: 0.2492  |  Val Loss: 0.3205\n",
      "Validation loss improved from 0.3224 to 0.3205.\n",
      "[Epoch 194/1000] Train Loss: 0.2467  |  Val Loss: 0.3180\n",
      "Validation loss improved from 0.3205 to 0.3180.\n",
      "[Epoch 195/1000] Train Loss: 0.2446  |  Val Loss: 0.3161\n",
      "Validation loss improved from 0.3180 to 0.3161.\n",
      "[Epoch 196/1000] Train Loss: 0.2419  |  Val Loss: 0.3146\n",
      "Validation loss improved from 0.3161 to 0.3146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 197/1000] Train Loss: 0.2401  |  Val Loss: 0.3131\n",
      "Validation loss improved from 0.3146 to 0.3131.\n",
      "[Epoch 198/1000] Train Loss: 0.2374  |  Val Loss: 0.3112\n",
      "Validation loss improved from 0.3131 to 0.3112.\n",
      "[Epoch 199/1000] Train Loss: 0.2353  |  Val Loss: 0.3096\n",
      "Validation loss improved from 0.3112 to 0.3096.\n",
      "[Epoch 200/1000] Train Loss: 0.2330  |  Val Loss: 0.3078\n",
      "Validation loss improved from 0.3096 to 0.3078.\n",
      "[Epoch 201/1000] Train Loss: 0.2309  |  Val Loss: 0.3066\n",
      "Validation loss improved from 0.3078 to 0.3066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 202/1000] Train Loss: 0.2289  |  Val Loss: 0.3050\n",
      "Validation loss improved from 0.3066 to 0.3050.\n",
      "[Epoch 203/1000] Train Loss: 0.2267  |  Val Loss: 0.3039\n",
      "Validation loss improved from 0.3050 to 0.3039.\n",
      "[Epoch 204/1000] Train Loss: 0.2247  |  Val Loss: 0.3025\n",
      "Validation loss improved from 0.3039 to 0.3025.\n",
      "[Epoch 205/1000] Train Loss: 0.2227  |  Val Loss: 0.3007\n",
      "Validation loss improved from 0.3025 to 0.3007.\n",
      "[Epoch 206/1000] Train Loss: 0.2207  |  Val Loss: 0.2996\n",
      "Validation loss improved from 0.3007 to 0.2996.\n",
      "[Epoch 207/1000] Train Loss: 0.2189  |  Val Loss: 0.2983\n",
      "Validation loss improved from 0.2996 to 0.2983.\n",
      "[Epoch 208/1000] Train Loss: 0.2169  |  Val Loss: 0.2962\n",
      "Validation loss improved from 0.2983 to 0.2962.\n",
      "[Epoch 209/1000] Train Loss: 0.2151  |  Val Loss: 0.2945\n",
      "Validation loss improved from 0.2962 to 0.2945.\n",
      "[Epoch 210/1000] Train Loss: 0.2132  |  Val Loss: 0.2925\n",
      "Validation loss improved from 0.2945 to 0.2925.\n",
      "[Epoch 211/1000] Train Loss: 0.2112  |  Val Loss: 0.2910\n",
      "Validation loss improved from 0.2925 to 0.2910.\n",
      "[Epoch 212/1000] Train Loss: 0.2094  |  Val Loss: 0.2897\n",
      "Validation loss improved from 0.2910 to 0.2897.\n",
      "[Epoch 213/1000] Train Loss: 0.2077  |  Val Loss: 0.2882\n",
      "Validation loss improved from 0.2897 to 0.2882.\n",
      "[Epoch 214/1000] Train Loss: 0.2060  |  Val Loss: 0.2867\n",
      "Validation loss improved from 0.2882 to 0.2867.\n",
      "[Epoch 215/1000] Train Loss: 0.2042  |  Val Loss: 0.2854\n",
      "Validation loss improved from 0.2867 to 0.2854.\n",
      "[Epoch 216/1000] Train Loss: 0.2025  |  Val Loss: 0.2837\n",
      "Validation loss improved from 0.2854 to 0.2837.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 217/1000] Train Loss: 0.2011  |  Val Loss: 0.2826\n",
      "Validation loss improved from 0.2837 to 0.2826.\n",
      "[Epoch 218/1000] Train Loss: 0.1993  |  Val Loss: 0.2816\n",
      "Validation loss improved from 0.2826 to 0.2816.\n",
      "[Epoch 219/1000] Train Loss: 0.1977  |  Val Loss: 0.2808\n",
      "Validation loss improved from 0.2816 to 0.2808.\n",
      "[Epoch 220/1000] Train Loss: 0.1960  |  Val Loss: 0.2797\n",
      "Validation loss improved from 0.2808 to 0.2797.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 221/1000] Train Loss: 0.1943  |  Val Loss: 0.2788\n",
      "Validation loss improved from 0.2797 to 0.2788.\n",
      "[Epoch 222/1000] Train Loss: 0.1926  |  Val Loss: 0.2780\n",
      "Validation loss improved from 0.2788 to 0.2780.\n",
      "[Epoch 223/1000] Train Loss: 0.1912  |  Val Loss: 0.2768\n",
      "Validation loss improved from 0.2780 to 0.2768.\n",
      "[Epoch 224/1000] Train Loss: 0.1896  |  Val Loss: 0.2755\n",
      "Validation loss improved from 0.2768 to 0.2755.\n",
      "[Epoch 225/1000] Train Loss: 0.1878  |  Val Loss: 0.2742\n",
      "Validation loss improved from 0.2755 to 0.2742.\n",
      "[Epoch 226/1000] Train Loss: 0.1863  |  Val Loss: 0.2733\n",
      "Validation loss improved from 0.2742 to 0.2733.\n",
      "[Epoch 227/1000] Train Loss: 0.1849  |  Val Loss: 0.2720\n",
      "Validation loss improved from 0.2733 to 0.2720.\n",
      "[Epoch 228/1000] Train Loss: 0.1833  |  Val Loss: 0.2716\n",
      "Validation loss improved from 0.2720 to 0.2716.\n",
      "[Epoch 229/1000] Train Loss: 0.1819  |  Val Loss: 0.2708\n",
      "Validation loss improved from 0.2716 to 0.2708.\n",
      "[Epoch 230/1000] Train Loss: 0.1805  |  Val Loss: 0.2698\n",
      "Validation loss improved from 0.2708 to 0.2698.\n",
      "[Epoch 231/1000] Train Loss: 0.1793  |  Val Loss: 0.2694\n",
      "Validation loss improved from 0.2698 to 0.2694.\n",
      "[Epoch 232/1000] Train Loss: 0.1780  |  Val Loss: 0.2680\n",
      "Validation loss improved from 0.2694 to 0.2680.\n",
      "[Epoch 233/1000] Train Loss: 0.1765  |  Val Loss: 0.2671\n",
      "Validation loss improved from 0.2680 to 0.2671.\n",
      "[Epoch 234/1000] Train Loss: 0.1749  |  Val Loss: 0.2665\n",
      "Validation loss improved from 0.2671 to 0.2665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 235/1000] Train Loss: 0.1737  |  Val Loss: 0.2652\n",
      "Validation loss improved from 0.2665 to 0.2652.\n",
      "[Epoch 236/1000] Train Loss: 0.1723  |  Val Loss: 0.2642\n",
      "Validation loss improved from 0.2652 to 0.2642.\n",
      "[Epoch 237/1000] Train Loss: 0.1712  |  Val Loss: 0.2632\n",
      "Validation loss improved from 0.2642 to 0.2632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 238/1000] Train Loss: 0.1696  |  Val Loss: 0.2623\n",
      "Validation loss improved from 0.2632 to 0.2623.\n",
      "[Epoch 239/1000] Train Loss: 0.1686  |  Val Loss: 0.2617\n",
      "Validation loss improved from 0.2623 to 0.2617.\n",
      "[Epoch 240/1000] Train Loss: 0.1675  |  Val Loss: 0.2609\n",
      "Validation loss improved from 0.2617 to 0.2609.\n",
      "[Epoch 241/1000] Train Loss: 0.1663  |  Val Loss: 0.2602\n",
      "Validation loss improved from 0.2609 to 0.2602.\n",
      "[Epoch 242/1000] Train Loss: 0.1651  |  Val Loss: 0.2597\n",
      "Validation loss improved from 0.2602 to 0.2597.\n",
      "[Epoch 243/1000] Train Loss: 0.1639  |  Val Loss: 0.2586\n",
      "Validation loss improved from 0.2597 to 0.2586.\n",
      "[Epoch 244/1000] Train Loss: 0.1627  |  Val Loss: 0.2575\n",
      "Validation loss improved from 0.2586 to 0.2575.\n",
      "[Epoch 245/1000] Train Loss: 0.1616  |  Val Loss: 0.2566\n",
      "Validation loss improved from 0.2575 to 0.2566.\n",
      "[Epoch 246/1000] Train Loss: 0.1603  |  Val Loss: 0.2566\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 247/1000] Train Loss: 0.1593  |  Val Loss: 0.2562\n",
      "Validation loss improved from 0.2566 to 0.2562.\n",
      "[Epoch 248/1000] Train Loss: 0.1580  |  Val Loss: 0.2558\n",
      "Validation loss improved from 0.2562 to 0.2558.\n",
      "[Epoch 249/1000] Train Loss: 0.1568  |  Val Loss: 0.2555\n",
      "Validation loss improved from 0.2558 to 0.2555.\n",
      "[Epoch 250/1000] Train Loss: 0.1558  |  Val Loss: 0.2548\n",
      "Validation loss improved from 0.2555 to 0.2548.\n",
      "[Epoch 251/1000] Train Loss: 0.1544  |  Val Loss: 0.2537\n",
      "Validation loss improved from 0.2548 to 0.2537.\n",
      "[Epoch 252/1000] Train Loss: 0.1534  |  Val Loss: 0.2529\n",
      "Validation loss improved from 0.2537 to 0.2529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 253/1000] Train Loss: 0.1523  |  Val Loss: 0.2522\n",
      "Validation loss improved from 0.2529 to 0.2522.\n",
      "[Epoch 254/1000] Train Loss: 0.1513  |  Val Loss: 0.2518\n",
      "Validation loss improved from 0.2522 to 0.2518.\n",
      "[Epoch 255/1000] Train Loss: 0.1503  |  Val Loss: 0.2509\n",
      "Validation loss improved from 0.2518 to 0.2509.\n",
      "[Epoch 256/1000] Train Loss: 0.1493  |  Val Loss: 0.2497\n",
      "Validation loss improved from 0.2509 to 0.2497.\n",
      "[Epoch 257/1000] Train Loss: 0.1481  |  Val Loss: 0.2494\n",
      "Validation loss improved from 0.2497 to 0.2494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 258/1000] Train Loss: 0.1472  |  Val Loss: 0.2489\n",
      "Validation loss improved from 0.2494 to 0.2489.\n",
      "[Epoch 259/1000] Train Loss: 0.1461  |  Val Loss: 0.2486\n",
      "Validation loss improved from 0.2489 to 0.2486.\n",
      "[Epoch 260/1000] Train Loss: 0.1451  |  Val Loss: 0.2478\n",
      "Validation loss improved from 0.2486 to 0.2478.\n",
      "[Epoch 261/1000] Train Loss: 0.1442  |  Val Loss: 0.2474\n",
      "Validation loss improved from 0.2478 to 0.2474.\n",
      "[Epoch 262/1000] Train Loss: 0.1431  |  Val Loss: 0.2473\n",
      "Validation loss improved from 0.2474 to 0.2473.\n",
      "[Epoch 263/1000] Train Loss: 0.1424  |  Val Loss: 0.2474\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 264/1000] Train Loss: 0.1413  |  Val Loss: 0.2474\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 265/1000] Train Loss: 0.1404  |  Val Loss: 0.2466\n",
      "Validation loss improved from 0.2473 to 0.2466.\n",
      "[Epoch 266/1000] Train Loss: 0.1394  |  Val Loss: 0.2461\n",
      "Validation loss improved from 0.2466 to 0.2461.\n",
      "[Epoch 267/1000] Train Loss: 0.1387  |  Val Loss: 0.2451\n",
      "Validation loss improved from 0.2461 to 0.2451.\n",
      "[Epoch 268/1000] Train Loss: 0.1376  |  Val Loss: 0.2444\n",
      "Validation loss improved from 0.2451 to 0.2444.\n",
      "[Epoch 269/1000] Train Loss: 0.1367  |  Val Loss: 0.2435\n",
      "Validation loss improved from 0.2444 to 0.2435.\n",
      "[Epoch 270/1000] Train Loss: 0.1359  |  Val Loss: 0.2426\n",
      "Validation loss improved from 0.2435 to 0.2426.\n",
      "[Epoch 271/1000] Train Loss: 0.1349  |  Val Loss: 0.2414\n",
      "Validation loss improved from 0.2426 to 0.2414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 272/1000] Train Loss: 0.1341  |  Val Loss: 0.2407\n",
      "Validation loss improved from 0.2414 to 0.2407.\n",
      "[Epoch 273/1000] Train Loss: 0.1332  |  Val Loss: 0.2404\n",
      "Validation loss improved from 0.2407 to 0.2404.\n",
      "[Epoch 274/1000] Train Loss: 0.1324  |  Val Loss: 0.2397\n",
      "Validation loss improved from 0.2404 to 0.2397.\n",
      "[Epoch 275/1000] Train Loss: 0.1315  |  Val Loss: 0.2390\n",
      "Validation loss improved from 0.2397 to 0.2390.\n",
      "[Epoch 276/1000] Train Loss: 0.1311  |  Val Loss: 0.2386\n",
      "Validation loss improved from 0.2390 to 0.2386.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 277/1000] Train Loss: 0.1298  |  Val Loss: 0.2380\n",
      "Validation loss improved from 0.2386 to 0.2380.\n",
      "[Epoch 278/1000] Train Loss: 0.1290  |  Val Loss: 0.2378\n",
      "Validation loss improved from 0.2380 to 0.2378.\n",
      "[Epoch 279/1000] Train Loss: 0.1282  |  Val Loss: 0.2375\n",
      "Validation loss improved from 0.2378 to 0.2375.\n",
      "[Epoch 280/1000] Train Loss: 0.1276  |  Val Loss: 0.2373\n",
      "Validation loss improved from 0.2375 to 0.2373.\n",
      "[Epoch 281/1000] Train Loss: 0.1267  |  Val Loss: 0.2365\n",
      "Validation loss improved from 0.2373 to 0.2365.\n",
      "[Epoch 282/1000] Train Loss: 0.1260  |  Val Loss: 0.2358\n",
      "Validation loss improved from 0.2365 to 0.2358.\n",
      "[Epoch 283/1000] Train Loss: 0.1251  |  Val Loss: 0.2353\n",
      "Validation loss improved from 0.2358 to 0.2353.\n",
      "[Epoch 284/1000] Train Loss: 0.1245  |  Val Loss: 0.2351\n",
      "Validation loss improved from 0.2353 to 0.2351.\n",
      "[Epoch 285/1000] Train Loss: 0.1236  |  Val Loss: 0.2350\n",
      "Validation loss improved from 0.2351 to 0.2350.\n",
      "[Epoch 286/1000] Train Loss: 0.1230  |  Val Loss: 0.2350\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 287/1000] Train Loss: 0.1219  |  Val Loss: 0.2351\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 288/1000] Train Loss: 0.1213  |  Val Loss: 0.2350\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 289/1000] Train Loss: 0.1206  |  Val Loss: 0.2347\n",
      "Validation loss improved from 0.2350 to 0.2347.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 290/1000] Train Loss: 0.1196  |  Val Loss: 0.2345\n",
      "Validation loss improved from 0.2347 to 0.2345.\n",
      "[Epoch 291/1000] Train Loss: 0.1190  |  Val Loss: 0.2338\n",
      "Validation loss improved from 0.2345 to 0.2338.\n",
      "[Epoch 292/1000] Train Loss: 0.1182  |  Val Loss: 0.2334\n",
      "Validation loss improved from 0.2338 to 0.2334.\n",
      "[Epoch 293/1000] Train Loss: 0.1175  |  Val Loss: 0.2329\n",
      "Validation loss improved from 0.2334 to 0.2329.\n",
      "[Epoch 294/1000] Train Loss: 0.1168  |  Val Loss: 0.2329\n",
      "Validation loss improved from 0.2329 to 0.2329.\n",
      "[Epoch 295/1000] Train Loss: 0.1161  |  Val Loss: 0.2324\n",
      "Validation loss improved from 0.2329 to 0.2324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 296/1000] Train Loss: 0.1153  |  Val Loss: 0.2317\n",
      "Validation loss improved from 0.2324 to 0.2317.\n",
      "[Epoch 297/1000] Train Loss: 0.1147  |  Val Loss: 0.2317\n",
      "Validation loss improved from 0.2317 to 0.2317.\n",
      "[Epoch 298/1000] Train Loss: 0.1139  |  Val Loss: 0.2308\n",
      "Validation loss improved from 0.2317 to 0.2308.\n",
      "[Epoch 299/1000] Train Loss: 0.1131  |  Val Loss: 0.2306\n",
      "Validation loss improved from 0.2308 to 0.2306.\n",
      "[Epoch 300/1000] Train Loss: 0.1125  |  Val Loss: 0.2303\n",
      "Validation loss improved from 0.2306 to 0.2303.\n",
      "[Epoch 301/1000] Train Loss: 0.1118  |  Val Loss: 0.2290\n",
      "Validation loss improved from 0.2303 to 0.2290.\n",
      "[Epoch 302/1000] Train Loss: 0.1114  |  Val Loss: 0.2277\n",
      "Validation loss improved from 0.2290 to 0.2277.\n",
      "[Epoch 303/1000] Train Loss: 0.1109  |  Val Loss: 0.2267\n",
      "Validation loss improved from 0.2277 to 0.2267.\n",
      "[Epoch 304/1000] Train Loss: 0.1102  |  Val Loss: 0.2264\n",
      "Validation loss improved from 0.2267 to 0.2264.\n",
      "[Epoch 305/1000] Train Loss: 0.1094  |  Val Loss: 0.2258\n",
      "Validation loss improved from 0.2264 to 0.2258.\n",
      "[Epoch 306/1000] Train Loss: 0.1089  |  Val Loss: 0.2258\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 307/1000] Train Loss: 0.1083  |  Val Loss: 0.2259\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 308/1000] Train Loss: 0.1076  |  Val Loss: 0.2261\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 309/1000] Train Loss: 0.1068  |  Val Loss: 0.2262\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 310/1000] Train Loss: 0.1064  |  Val Loss: 0.2268\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 311/1000] Train Loss: 0.1055  |  Val Loss: 0.2270\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 312/1000] Train Loss: 0.1050  |  Val Loss: 0.2275\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 313/1000] Train Loss: 0.1044  |  Val Loss: 0.2278\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 314/1000] Train Loss: 0.1039  |  Val Loss: 0.2271\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 315/1000] Train Loss: 0.1033  |  Val Loss: 0.2265\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 316/1000] Train Loss: 0.1028  |  Val Loss: 0.2263\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 317/1000] Train Loss: 0.1021  |  Val Loss: 0.2264\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 318/1000] Train Loss: 0.1016  |  Val Loss: 0.2259\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 319/1000] Train Loss: 0.1009  |  Val Loss: 0.2256\n",
      "Validation loss improved from 0.2258 to 0.2256.\n",
      "[Epoch 320/1000] Train Loss: 0.1004  |  Val Loss: 0.2254\n",
      "Validation loss improved from 0.2256 to 0.2254.\n",
      "[Epoch 321/1000] Train Loss: 0.0999  |  Val Loss: 0.2246\n",
      "Validation loss improved from 0.2254 to 0.2246.\n",
      "[Epoch 322/1000] Train Loss: 0.0993  |  Val Loss: 0.2242\n",
      "Validation loss improved from 0.2246 to 0.2242.\n",
      "[Epoch 323/1000] Train Loss: 0.0989  |  Val Loss: 0.2243\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 324/1000] Train Loss: 0.0983  |  Val Loss: 0.2242\n",
      "Validation loss improved from 0.2242 to 0.2242.\n",
      "[Epoch 325/1000] Train Loss: 0.0977  |  Val Loss: 0.2252\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 326/1000] Train Loss: 0.0971  |  Val Loss: 0.2252\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 327/1000] Train Loss: 0.0966  |  Val Loss: 0.2258\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 328/1000] Train Loss: 0.0961  |  Val Loss: 0.2257\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 329/1000] Train Loss: 0.0957  |  Val Loss: 0.2254\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 330/1000] Train Loss: 0.0952  |  Val Loss: 0.2246\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 331/1000] Train Loss: 0.0945  |  Val Loss: 0.2248\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 332/1000] Train Loss: 0.0940  |  Val Loss: 0.2250\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 333/1000] Train Loss: 0.0936  |  Val Loss: 0.2252\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 334/1000] Train Loss: 0.0930  |  Val Loss: 0.2252\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 335/1000] Train Loss: 0.0925  |  Val Loss: 0.2244\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 336/1000] Train Loss: 0.0919  |  Val Loss: 0.2238\n",
      "Validation loss improved from 0.2242 to 0.2238.\n",
      "[Epoch 337/1000] Train Loss: 0.0916  |  Val Loss: 0.2230\n",
      "Validation loss improved from 0.2238 to 0.2230.\n",
      "[Epoch 338/1000] Train Loss: 0.0909  |  Val Loss: 0.2230\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 339/1000] Train Loss: 0.0906  |  Val Loss: 0.2233\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 340/1000] Train Loss: 0.0902  |  Val Loss: 0.2232\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 341/1000] Train Loss: 0.0896  |  Val Loss: 0.2227\n",
      "Validation loss improved from 0.2230 to 0.2227.\n",
      "[Epoch 342/1000] Train Loss: 0.0890  |  Val Loss: 0.2225\n",
      "Validation loss improved from 0.2227 to 0.2225.\n",
      "[Epoch 343/1000] Train Loss: 0.0886  |  Val Loss: 0.2219\n",
      "Validation loss improved from 0.2225 to 0.2219.\n",
      "[Epoch 344/1000] Train Loss: 0.0882  |  Val Loss: 0.2209\n",
      "Validation loss improved from 0.2219 to 0.2209.\n",
      "[Epoch 345/1000] Train Loss: 0.0877  |  Val Loss: 0.2201\n",
      "Validation loss improved from 0.2209 to 0.2201.\n",
      "[Epoch 346/1000] Train Loss: 0.0872  |  Val Loss: 0.2198\n",
      "Validation loss improved from 0.2201 to 0.2198.\n",
      "[Epoch 347/1000] Train Loss: 0.0868  |  Val Loss: 0.2195\n",
      "Validation loss improved from 0.2198 to 0.2195.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 348/1000] Train Loss: 0.0864  |  Val Loss: 0.2193\n",
      "Validation loss improved from 0.2195 to 0.2193.\n",
      "[Epoch 349/1000] Train Loss: 0.0857  |  Val Loss: 0.2194\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 350/1000] Train Loss: 0.0853  |  Val Loss: 0.2199\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 351/1000] Train Loss: 0.0849  |  Val Loss: 0.2203\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 352/1000] Train Loss: 0.0845  |  Val Loss: 0.2212\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 353/1000] Train Loss: 0.0841  |  Val Loss: 0.2215\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 354/1000] Train Loss: 0.0836  |  Val Loss: 0.2214\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 355/1000] Train Loss: 0.0832  |  Val Loss: 0.2207\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 356/1000] Train Loss: 0.0828  |  Val Loss: 0.2200\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 357/1000] Train Loss: 0.0823  |  Val Loss: 0.2201\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 358/1000] Train Loss: 0.0819  |  Val Loss: 0.2203\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 359/1000] Train Loss: 0.0815  |  Val Loss: 0.2205\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 360/1000] Train Loss: 0.0811  |  Val Loss: 0.2202\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 361/1000] Train Loss: 0.0805  |  Val Loss: 0.2198\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 362/1000] Train Loss: 0.0801  |  Val Loss: 0.2190\n",
      "Validation loss improved from 0.2193 to 0.2190.\n",
      "[Epoch 363/1000] Train Loss: 0.0796  |  Val Loss: 0.2185\n",
      "Validation loss improved from 0.2190 to 0.2185.\n",
      "[Epoch 364/1000] Train Loss: 0.0795  |  Val Loss: 0.2176\n",
      "Validation loss improved from 0.2185 to 0.2176.\n",
      "[Epoch 365/1000] Train Loss: 0.0791  |  Val Loss: 0.2177\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 366/1000] Train Loss: 0.0785  |  Val Loss: 0.2176\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 367/1000] Train Loss: 0.0784  |  Val Loss: 0.2177\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 368/1000] Train Loss: 0.0778  |  Val Loss: 0.2183\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 369/1000] Train Loss: 0.0773  |  Val Loss: 0.2185\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 370/1000] Train Loss: 0.0770  |  Val Loss: 0.2190\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 371/1000] Train Loss: 0.0766  |  Val Loss: 0.2187\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 372/1000] Train Loss: 0.0762  |  Val Loss: 0.2184\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 373/1000] Train Loss: 0.0758  |  Val Loss: 0.2181\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 374/1000] Train Loss: 0.0754  |  Val Loss: 0.2181\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 375/1000] Train Loss: 0.0752  |  Val Loss: 0.2172\n",
      "Validation loss improved from 0.2176 to 0.2172.\n",
      "[Epoch 376/1000] Train Loss: 0.0746  |  Val Loss: 0.2165\n",
      "Validation loss improved from 0.2172 to 0.2165.\n",
      "[Epoch 377/1000] Train Loss: 0.0743  |  Val Loss: 0.2167\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 378/1000] Train Loss: 0.0741  |  Val Loss: 0.2162\n",
      "Validation loss improved from 0.2165 to 0.2162.\n",
      "[Epoch 379/1000] Train Loss: 0.0736  |  Val Loss: 0.2162\n",
      "Validation loss improved from 0.2162 to 0.2162.\n",
      "[Epoch 380/1000] Train Loss: 0.0733  |  Val Loss: 0.2161\n",
      "Validation loss improved from 0.2162 to 0.2161.\n",
      "[Epoch 381/1000] Train Loss: 0.0729  |  Val Loss: 0.2160\n",
      "Validation loss improved from 0.2161 to 0.2160.\n",
      "[Epoch 382/1000] Train Loss: 0.0725  |  Val Loss: 0.2158\n",
      "Validation loss improved from 0.2160 to 0.2158.\n",
      "[Epoch 383/1000] Train Loss: 0.0722  |  Val Loss: 0.2157\n",
      "Validation loss improved from 0.2158 to 0.2157.\n",
      "[Epoch 384/1000] Train Loss: 0.0718  |  Val Loss: 0.2152\n",
      "Validation loss improved from 0.2157 to 0.2152.\n",
      "[Epoch 385/1000] Train Loss: 0.0715  |  Val Loss: 0.2150\n",
      "Validation loss improved from 0.2152 to 0.2150.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 386/1000] Train Loss: 0.0711  |  Val Loss: 0.2151\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 387/1000] Train Loss: 0.0707  |  Val Loss: 0.2152\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 388/1000] Train Loss: 0.0704  |  Val Loss: 0.2149\n",
      "Validation loss improved from 0.2150 to 0.2149.\n",
      "[Epoch 389/1000] Train Loss: 0.0701  |  Val Loss: 0.2151\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 390/1000] Train Loss: 0.0698  |  Val Loss: 0.2157\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 391/1000] Train Loss: 0.0694  |  Val Loss: 0.2163\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 392/1000] Train Loss: 0.0690  |  Val Loss: 0.2164\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 393/1000] Train Loss: 0.0687  |  Val Loss: 0.2168\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 394/1000] Train Loss: 0.0684  |  Val Loss: 0.2168\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 395/1000] Train Loss: 0.0681  |  Val Loss: 0.2172\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 396/1000] Train Loss: 0.0677  |  Val Loss: 0.2172\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 397/1000] Train Loss: 0.0676  |  Val Loss: 0.2162\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 398/1000] Train Loss: 0.0672  |  Val Loss: 0.2170\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 399/1000] Train Loss: 0.0667  |  Val Loss: 0.2169\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 400/1000] Train Loss: 0.0664  |  Val Loss: 0.2166\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 401/1000] Train Loss: 0.0662  |  Val Loss: 0.2162\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 402/1000] Train Loss: 0.0658  |  Val Loss: 0.2167\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 403/1000] Train Loss: 0.0656  |  Val Loss: 0.2174\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 404/1000] Train Loss: 0.0653  |  Val Loss: 0.2178\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 405/1000] Train Loss: 0.0649  |  Val Loss: 0.2175\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 406/1000] Train Loss: 0.0647  |  Val Loss: 0.2171\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 407/1000] Train Loss: 0.0643  |  Val Loss: 0.2165\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 408/1000] Train Loss: 0.0640  |  Val Loss: 0.2160\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 409/1000] Train Loss: 0.0638  |  Val Loss: 0.2157\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 410/1000] Train Loss: 0.0635  |  Val Loss: 0.2146\n",
      "Validation loss improved from 0.2149 to 0.2146.\n",
      "[Epoch 411/1000] Train Loss: 0.0632  |  Val Loss: 0.2148\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 412/1000] Train Loss: 0.0629  |  Val Loss: 0.2148\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 413/1000] Train Loss: 0.0627  |  Val Loss: 0.2149\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 414/1000] Train Loss: 0.0623  |  Val Loss: 0.2146\n",
      "Validation loss improved from 0.2146 to 0.2146.\n",
      "[Epoch 415/1000] Train Loss: 0.0621  |  Val Loss: 0.2145\n",
      "Validation loss improved from 0.2146 to 0.2145.\n",
      "[Epoch 416/1000] Train Loss: 0.0619  |  Val Loss: 0.2138\n",
      "Validation loss improved from 0.2145 to 0.2138.\n",
      "[Epoch 417/1000] Train Loss: 0.0615  |  Val Loss: 0.2134\n",
      "Validation loss improved from 0.2138 to 0.2134.\n",
      "[Epoch 418/1000] Train Loss: 0.0612  |  Val Loss: 0.2135\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 419/1000] Train Loss: 0.0609  |  Val Loss: 0.2130\n",
      "Validation loss improved from 0.2134 to 0.2130.\n",
      "[Epoch 420/1000] Train Loss: 0.0606  |  Val Loss: 0.2129\n",
      "Validation loss improved from 0.2130 to 0.2129.\n",
      "[Epoch 421/1000] Train Loss: 0.0602  |  Val Loss: 0.2123\n",
      "Validation loss improved from 0.2129 to 0.2123.\n",
      "[Epoch 422/1000] Train Loss: 0.0602  |  Val Loss: 0.2122\n",
      "Validation loss improved from 0.2123 to 0.2122.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 423/1000] Train Loss: 0.0599  |  Val Loss: 0.2121\n",
      "Validation loss improved from 0.2122 to 0.2121.\n",
      "[Epoch 424/1000] Train Loss: 0.0597  |  Val Loss: 0.2124\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 425/1000] Train Loss: 0.0594  |  Val Loss: 0.2126\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 426/1000] Train Loss: 0.0590  |  Val Loss: 0.2131\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 427/1000] Train Loss: 0.0586  |  Val Loss: 0.2139\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 428/1000] Train Loss: 0.0584  |  Val Loss: 0.2145\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 429/1000] Train Loss: 0.0583  |  Val Loss: 0.2138\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 430/1000] Train Loss: 0.0579  |  Val Loss: 0.2134\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 431/1000] Train Loss: 0.0577  |  Val Loss: 0.2139\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 432/1000] Train Loss: 0.0573  |  Val Loss: 0.2136\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 433/1000] Train Loss: 0.0570  |  Val Loss: 0.2128\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 434/1000] Train Loss: 0.0568  |  Val Loss: 0.2123\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 435/1000] Train Loss: 0.0566  |  Val Loss: 0.2131\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 436/1000] Train Loss: 0.0563  |  Val Loss: 0.2132\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 437/1000] Train Loss: 0.0560  |  Val Loss: 0.2132\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 438/1000] Train Loss: 0.0558  |  Val Loss: 0.2135\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 439/1000] Train Loss: 0.0555  |  Val Loss: 0.2141\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 440/1000] Train Loss: 0.0553  |  Val Loss: 0.2149\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 441/1000] Train Loss: 0.0550  |  Val Loss: 0.2150\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 442/1000] Train Loss: 0.0549  |  Val Loss: 0.2154\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 443/1000] Train Loss: 0.0545  |  Val Loss: 0.2149\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 444/1000] Train Loss: 0.0544  |  Val Loss: 0.2145\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 445/1000] Train Loss: 0.0540  |  Val Loss: 0.2149\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 446/1000] Train Loss: 0.0539  |  Val Loss: 0.2147\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 447/1000] Train Loss: 0.0536  |  Val Loss: 0.2149\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 448/1000] Train Loss: 0.0534  |  Val Loss: 0.2149\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 449/1000] Train Loss: 0.0533  |  Val Loss: 0.2152\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 450/1000] Train Loss: 0.0529  |  Val Loss: 0.2162\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 451/1000] Train Loss: 0.0528  |  Val Loss: 0.2163\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 452/1000] Train Loss: 0.0524  |  Val Loss: 0.2156\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 453/1000] Train Loss: 0.0521  |  Val Loss: 0.2158\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 454/1000] Train Loss: 0.0519  |  Val Loss: 0.2154\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 455/1000] Train Loss: 0.0517  |  Val Loss: 0.2149\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 456/1000] Train Loss: 0.0514  |  Val Loss: 0.2146\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 457/1000] Train Loss: 0.0512  |  Val Loss: 0.2145\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 458/1000] Train Loss: 0.0510  |  Val Loss: 0.2146\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 459/1000] Train Loss: 0.0508  |  Val Loss: 0.2143\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 460/1000] Train Loss: 0.0506  |  Val Loss: 0.2138\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 461/1000] Train Loss: 0.0504  |  Val Loss: 0.2136\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 462/1000] Train Loss: 0.0503  |  Val Loss: 0.2143\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 463/1000] Train Loss: 0.0499  |  Val Loss: 0.2154\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 464/1000] Train Loss: 0.0497  |  Val Loss: 0.2152\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 465/1000] Train Loss: 0.0497  |  Val Loss: 0.2159\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 466/1000] Train Loss: 0.0494  |  Val Loss: 0.2153\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 467/1000] Train Loss: 0.0490  |  Val Loss: 0.2152\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 468/1000] Train Loss: 0.0488  |  Val Loss: 0.2156\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 469/1000] Train Loss: 0.0486  |  Val Loss: 0.2158\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 470/1000] Train Loss: 0.0485  |  Val Loss: 0.2153\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 471/1000] Train Loss: 0.0482  |  Val Loss: 0.2147\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 472/1000] Train Loss: 0.0480  |  Val Loss: 0.2145\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 473/1000] Train Loss: 0.0477  |  Val Loss: 0.2146\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 474/1000] Train Loss: 0.0475  |  Val Loss: 0.2146\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 475/1000] Train Loss: 0.0474  |  Val Loss: 0.2145\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 476/1000] Train Loss: 0.0471  |  Val Loss: 0.2149\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 477/1000] Train Loss: 0.0470  |  Val Loss: 0.2158\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 478/1000] Train Loss: 0.0469  |  Val Loss: 0.2160\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 479/1000] Train Loss: 0.0466  |  Val Loss: 0.2158\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 480/1000] Train Loss: 0.0464  |  Val Loss: 0.2158\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 481/1000] Train Loss: 0.0461  |  Val Loss: 0.2150\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 482/1000] Train Loss: 0.0460  |  Val Loss: 0.2141\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 483/1000] Train Loss: 0.0457  |  Val Loss: 0.2141\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 484/1000] Train Loss: 0.0455  |  Val Loss: 0.2143\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 485/1000] Train Loss: 0.0453  |  Val Loss: 0.2143\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 486/1000] Train Loss: 0.0451  |  Val Loss: 0.2138\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 487/1000] Train Loss: 0.0448  |  Val Loss: 0.2136\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 488/1000] Train Loss: 0.0446  |  Val Loss: 0.2139\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 489/1000] Train Loss: 0.0445  |  Val Loss: 0.2142\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 490/1000] Train Loss: 0.0443  |  Val Loss: 0.2139\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 491/1000] Train Loss: 0.0441  |  Val Loss: 0.2137\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 492/1000] Train Loss: 0.0439  |  Val Loss: 0.2130\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 493/1000] Train Loss: 0.0438  |  Val Loss: 0.2130\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 494/1000] Train Loss: 0.0436  |  Val Loss: 0.2130\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 495/1000] Train Loss: 0.0433  |  Val Loss: 0.2137\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 496/1000] Train Loss: 0.0432  |  Val Loss: 0.2138\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 497/1000] Train Loss: 0.0430  |  Val Loss: 0.2138\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 498/1000] Train Loss: 0.0429  |  Val Loss: 0.2139\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 499/1000] Train Loss: 0.0426  |  Val Loss: 0.2139\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 500/1000] Train Loss: 0.0424  |  Val Loss: 0.2137\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 501/1000] Train Loss: 0.0422  |  Val Loss: 0.2135\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 502/1000] Train Loss: 0.0421  |  Val Loss: 0.2133\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 503/1000] Train Loss: 0.0420  |  Val Loss: 0.2124\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 504/1000] Train Loss: 0.0419  |  Val Loss: 0.2126\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 505/1000] Train Loss: 0.0415  |  Val Loss: 0.2129\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 506/1000] Train Loss: 0.0413  |  Val Loss: 0.2131\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 507/1000] Train Loss: 0.0412  |  Val Loss: 0.2132\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 508/1000] Train Loss: 0.0410  |  Val Loss: 0.2136\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 509/1000] Train Loss: 0.0408  |  Val Loss: 0.2138\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 510/1000] Train Loss: 0.0407  |  Val Loss: 0.2137\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 511/1000] Train Loss: 0.0405  |  Val Loss: 0.2140\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 512/1000] Train Loss: 0.0403  |  Val Loss: 0.2143\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 513/1000] Train Loss: 0.0401  |  Val Loss: 0.2140\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 514/1000] Train Loss: 0.0399  |  Val Loss: 0.2141\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 515/1000] Train Loss: 0.0397  |  Val Loss: 0.2135\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 516/1000] Train Loss: 0.0395  |  Val Loss: 0.2132\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 517/1000] Train Loss: 0.0394  |  Val Loss: 0.2133\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 518/1000] Train Loss: 0.0394  |  Val Loss: 0.2143\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 519/1000] Train Loss: 0.0391  |  Val Loss: 0.2154\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 520/1000] Train Loss: 0.0388  |  Val Loss: 0.2169\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 521/1000] Train Loss: 0.0387  |  Val Loss: 0.2175\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 522/1000] Train Loss: 0.0385  |  Val Loss: 0.2178\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 523/1000] Train Loss: 0.0384  |  Val Loss: 0.2175\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 523 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_input_dim = sclsdl_mlp_train_reps.shape[1]\n",
    "sclsdl_mlp_num_classes = len(torch.unique(sclsdl_mlp_train_labels_torch))\n",
    "sclsdl_mlp_model = MLPClassifier(sclsdl_mlp_input_dim, sclsdl_mlp_num_classes).to(device)\n",
    "\n",
    "sclsdl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "sclsdl_mlp_optimizer = optim.Adam(sclsdl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "sclsdl_mlp_num_epochs = 1000\n",
    "sclsdl_mlp_patience = 100\n",
    "\n",
    "sclsdl_mlp_train_losses = []\n",
    "sclsdl_mlp_val_losses = []\n",
    "\n",
    "sclsdl_mlp_best_val_loss = float('inf')\n",
    "sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for sclsdl_mlp_epoch in range(sclsdl_mlp_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_mlp_model.train()\n",
    "    sclsdl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for sclsdl_mlp_embeddings_batch, sclsdl_mlp_labels_batch in sclsdl_mlp_train_loader:\n",
    "        sclsdl_mlp_embeddings_batch = sclsdl_mlp_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_labels_batch = sclsdl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        sclsdl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        sclsdl_mlp_outputs = sclsdl_mlp_model(sclsdl_mlp_embeddings_batch)\n",
    "        sclsdl_mlp_loss = sclsdl_mlp_criterion(sclsdl_mlp_outputs, sclsdl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        sclsdl_mlp_loss.backward()\n",
    "        sclsdl_mlp_optimizer.step()\n",
    "        \n",
    "        sclsdl_mlp_train_running_loss += sclsdl_mlp_loss.item() * sclsdl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    sclsdl_mlp_epoch_train_loss = sclsdl_mlp_train_running_loss / len(sclsdl_mlp_train_loader.dataset)\n",
    "    sclsdl_mlp_train_losses.append(sclsdl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_mlp_model.eval()\n",
    "    sclsdl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sclsdl_mlp_val_embeddings_batch, sclsdl_mlp_val_labels_batch in sclsdl_mlp_val_loader:\n",
    "            sclsdl_mlp_val_embeddings_batch = sclsdl_mlp_val_embeddings_batch.to(device)\n",
    "            sclsdl_mlp_val_labels_batch = sclsdl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            sclsdl_mlp_val_outputs = sclsdl_mlp_model(sclsdl_mlp_val_embeddings_batch)\n",
    "            sclsdl_mlp_val_loss = sclsdl_mlp_criterion(sclsdl_mlp_val_outputs, sclsdl_mlp_val_labels_batch)\n",
    "\n",
    "            sclsdl_mlp_val_running_loss += sclsdl_mlp_val_loss.item() * sclsdl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    sclsdl_mlp_epoch_val_loss = sclsdl_mlp_val_running_loss / len(sclsdl_mlp_val_loader.dataset)\n",
    "    sclsdl_mlp_val_losses.append(sclsdl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {sclsdl_mlp_epoch+1}/{sclsdl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {sclsdl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {sclsdl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if sclsdl_mlp_epoch_val_loss < sclsdl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_mlp_best_val_loss:.4f} to {sclsdl_mlp_epoch_val_loss:.4f}.\")\n",
    "        sclsdl_mlp_best_val_loss = sclsdl_mlp_epoch_val_loss\n",
    "        sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "\n",
    "    else:\n",
    "        sclsdl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {sclsdl_mlp_epochs_without_improvement}/{sclsdl_mlp_patience}\")\n",
    "        \n",
    "        if sclsdl_mlp_epochs_without_improvement >= sclsdl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {sclsdl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {sclsdl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(sclsdl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(sclsdl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:36:32.135240Z",
     "iopub.status.busy": "2025-05-08T19:36:32.135240Z",
     "iopub.status.idle": "2025-05-08T19:36:32.285934Z",
     "shell.execute_reply": "2025-05-08T19:36:32.285934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SCL_SDL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.4609 | Test Accuracy: 85.99%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_model.eval()\n",
    "\n",
    "sclsdl_mlp_test_running_loss = 0.0\n",
    "sclsdl_mlp_test_correct = 0\n",
    "sclsdl_mlp_all_predictions = []\n",
    "sclsdl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_mlp_test_embeddings_batch, sclsdl_mlp_test_labels_batch in sclsdl_mlp_test_loader:\n",
    "        sclsdl_mlp_test_embeddings_batch = sclsdl_mlp_test_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_test_labels_batch = sclsdl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_mlp_test_outputs = sclsdl_mlp_model(sclsdl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        sclsdl_mlp_test_loss_batch = sclsdl_mlp_criterion(sclsdl_mlp_test_outputs, sclsdl_mlp_test_labels_batch)\n",
    "        sclsdl_mlp_test_running_loss += sclsdl_mlp_test_loss_batch.item() * sclsdl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, sclsdl_mlp_test_predicted = torch.max(sclsdl_mlp_test_outputs, dim=1)\n",
    "        sclsdl_mlp_test_correct += (sclsdl_mlp_test_predicted == sclsdl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        sclsdl_mlp_all_predictions.extend(sclsdl_mlp_test_predicted.cpu().numpy())\n",
    "        sclsdl_mlp_all_true_labels.extend(sclsdl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_predictions.npy'), np.array(sclsdl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_true_labels.npy'), np.array(sclsdl_mlp_all_true_labels))\n",
    "print(f\"Saved SCL_SDL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "sclsdl_mlp_epoch_test_loss = sclsdl_mlp_test_running_loss / len(sclsdl_mlp_test_loader.dataset)\n",
    "sclsdl_mlp_test_accuracy = sclsdl_mlp_test_correct / len(sclsdl_mlp_test_loader.dataset)\n",
    "\n",
    "sclsdl_mlp_test_accuracy_pct = sclsdl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {sclsdl_mlp_epoch_test_loss:.4f} | Test Accuracy: {sclsdl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "sclsdl_mlp_num_epochs_run = len(sclsdl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         [sclsdl_mlp_epoch_test_loss]*sclsdl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Results and Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:36:32.287939Z",
     "iopub.status.busy": "2025-05-08T19:36:32.287939Z",
     "iopub.status.idle": "2025-05-08T19:36:32.293314Z",
     "shell.execute_reply": "2025-05-08T19:36:32.293314Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_conf_matrix(model_name, class_names = None, cm_save_dir='confusion_matrices'):\n",
    "    os.makedirs(cm_save_dir, exist_ok = True)\n",
    "\n",
    "    #loading predictions and true labels\n",
    "    predictions_path = os.path.join(predictions_dir, f'{model_name}_predictions.npy')\n",
    "    true_labels_path = os.path.join(predictions_dir, f'{model_name}_true_labels.npy')\n",
    "\n",
    "    if not os.path.exists(predictions_path) or not os.path.exists(true_labels_path):\n",
    "        print(f\"Error: Files not found for model {model_name}\")\n",
    "        return\n",
    "    \n",
    "    cm_predictions = np.load(predictions_path)\n",
    "    cm_true_labels = np.load(true_labels_path)\n",
    "\n",
    "    conf_matrix = confusion_matrix(cm_true_labels, cm_predictions)\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    conf_matrix_normalised = conf_matrix.astype('float') / conf_matrix.sum(axis = 1)[:, np.newaxis]\n",
    "    sns.heatmap(conf_matrix_normalised, annot=conf_matrix, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "    plt.title(f\"{model_name.upper()} Confusion Matrix\", fontsize=16)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    cm_save_path = os.path.join(cm_save_dir, f'{model_name}_confusion_matrix.png')\n",
    "    plt.savefig(cm_save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved confusion matrix to: {cm_save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "    print(f\"Classification Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:36:32.296319Z",
     "iopub.status.busy": "2025-05-08T19:36:32.295322Z",
     "iopub.status.idle": "2025-05-08T19:36:37.562168Z",
     "shell.execute_reply": "2025-05-08T19:36:37.562168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving confusion matrices to: confusion_matrices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\e2e_cnn_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 97.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 77.64%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 58.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 84.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 84.44%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAMWCAYAAABIgshOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADM3ElEQVR4nOzdd1hT1+MG8DdsREUExT0RFVFUxAG4R9XWLXXUUfese4BYtVqLe9RV96571Fq17q11+3WPOnCATFE2hPv7wx+pkRkIuffo++lzn6e58825IZ6cnHOikiRJAhERERERKY6R3AGIiIiIiCh1rKwTERERESkUK+tERERERArFyjoRERERkUKxsk5EREREpFCsrBMRERERKRQr60RERERECsXKOhERERGRQrGyTkRERESkUKysExF9JkJDQ9GvXz8ULVoUxsbGUKlUmDJlisGu/+zZM6hUKpQqVcpg1/ySrVu3DiqVCt9//73cUYgoB7GyTp8Nf39/jBo1Cs7OzrCysoKlpSVKlCgBd3d3jB07Fn///Xe6x9+6dQvDhw9HlSpVYGNjAzMzM9jb26Np06aYP38+QkNDtfY/efIkVCoVVCqVTjnv3r2LAQMGwNHREZaWlrCyskLp0qXRoEED/Pjjjzh//nyKY0qVKqW5lkqlgpGREfLmzYvixYujadOmmDhxIu7evZvudRs0aJBjlbcpU6ZApVKhQYMGmdr/47L79DlVr14dkyZNwtu3b9M8/uPjFi1alO61Ro4cqdk3O5VIXV8fcmjTpg1WrVqFqKgo1KhRAx4eHihRooTcsRQl+QNF8vLnn3+mu3+7du00+2b29Z2RGzduYMqUKdi7d69ezkdEnzmJ6DNw7NgxKU+ePBIAydjYWCpVqpRUs2ZNycHBQVKpVBIAydbWNtVjExMTpR9++EEyMjKSAEgmJiZShQoVJDc3N6lEiRISAAmAZG1tLR05ckRz3IkTJzTbMmvTpk2SmZmZBEAyNTWVypYtK7m5uUklS5bUnMvV1TXFccnby5UrJ3l4eEgeHh6Sq6ur1nEApA4dOkghISGpXrt+/foSAGny5MmZzptZkydPlgBI9evXz9T+H5dd8vNxd3eXSpQooblfpUqVkl69epXq8R8/Zzc3tzSvk5iYKBUqVEizb8mSJXV+bll9fRjazZs3JQBS0aJFpbdv38qS4eXLl1L58uWlRo0ayXL9zHj69KnW68fLyyvNfcPCwjR/r7q8vjOydu1aCYDUs2fPbJ1n9+7dUvny5SVvb2+95CIiZWLLOgnv3bt36NSpE96/f4+vv/4a//77L54+fYp//vkHjx49QlhYGNatW4datWqlenzXrl2xaNEiWFlZYeHChQgNDcW9e/dw6dIlPH/+HE+fPoW3tzcSEhJw+/btLOd89uwZ+vTpg/j4ePTu3RsvX77E48ePcenSJTx79gwBAQFYvHgxnJyc0jzHhAkTcPbsWZw9exZXrlzBs2fPEBwcjAULFsDOzg67du2Cp6cnIiIispzT0JKfz7lz5/D8+XNcvHgRhQsXxrNnzzB27Nh0jy1fvjwuX76MBw8epLr9yJEjCAwMRPny5bOcz1Cvj+y6f/8+AMDDwwPW1tayZChatCju37+PY8eOyXJ9XRgbG6Ns2bL4888/0/x72bZtG+Lj47P1+slJ7dq1w/379+Hn5yd3FCLKQaysk/AOHDiAkJAQ5M2bF9u3b0fJkiW1tufLlw89e/bEX3/9leLYVatWYfv27bC0tMSJEycwbNgw5M2bV2ufUqVKwc/PD5cvX4aDg0OWc27duhVxcXEoX748Vq5ciYIFC2ptL1SoEIYMGYINGzbodF47OzsMHz4cV65cQeHChXH//n2MGDEiyznlVrNmTUybNg0AsG/fPqjV6jT37datGwBg06ZNqW5PXt+9e/csZTHk6yO7YmJiAACWlpayZRBNt27dEBsbi507d6a6fdOmTVCpVPjuu+8MnIyI6D+srJPwnjx5AgBwdHRErly5Mn2cWq3G9OnTAQCTJk2Cq6truvs7OTnhm2++yXbOypUrw8hI/396JUuWxNKlSwF8qGS8ePFC79cwFDc3NwBAZGQkQkJC0tyvQ4cOsLS0xKZNmyBJkta2qKgo7N27FyVKlEC9evV0zqCv18f58+fRvn172Nvbw8zMDMWKFUOPHj1w7969VM+TPLbg5MmTuH//Pry8vGBnZwdLS0u4urpi+/btWvsn9/9PHmS4fv16rT7ZyTIaX5E8LuLZs2da60NDQzFmzBhUqFABFhYWsLKyQqlSpdC8eXPN6y1ZRgNMQ0NDMW7cOJQvXx6WlpawsbFBgwYNsHnz5hT3D9AeQBkXF4cpU6bAwcEBFhYWKF68OEaNGoWoqKg0n1NGkj/sbdy4McW2p0+f4ty5c/Dw8EDp0qXTPMfFixcxbtw41KhRAwULFoS5uTmKFy+O7t27486dOyn2L1WqFHr16gUg5b36uE/8x6+DGzduoGPHjrC3t4eRkRHWrVuXonySxcXFoXLlylCpVJoPvR+TJAkNGzaESqVC//79M1NMRCQzVtZJeMktnY8ePUp3UOKn/vnnHzx79gwmJiYG+UcrOeeNGzeQkJCQI9do3bo1ihQpgsTERBw+fDhHrmEI0dHRmv9P7wNYnjx50KZNGzx79gznzp3T2rZ7925ERUXhu+++03kQMKCf18eyZcvg6emJPXv2AABcXFwQFRWFjRs3onr16ql+25Ps6tWrcHNzw99//41SpUohT548uHbtGjp16qT1TYK1tTU8PDxQrlw5AEDBggXh4eGhWbIjIiICtWrVwty5c/H06VOULVsWFSpUQExMDA4fPowJEyZk+lyPHz9GtWrVMHv2bDx79gxOTk7Inz8/Tp06hW7duuH7779PtcIOAAkJCWjWrBmmTp0KCwsLlCpVCq9fv8b8+fPRrl27LD8/BwcH1K5dG6dPn4a/v7/Wtsx+K9OtWzfNc7K3t0fFihXx/v17bNq0CW5ubjh58qTW/m5ubmneq8qVK6c4/+nTp1G7dm38/fffKF68eLofHADA3NwcGzduhJmZGaZOnYrLly9rbZ87dy5OnjyJsmXLYt68eemei4gUQt4u80TZ9+DBA83gP1dXV2nnzp2ZGmA3e/ZsCYBUtWrVLF1X1wGmR44c0ezfuHFj6cCBA1JUVFSmjk0eSLp27doM9+3QoYMEQBowYIDWeqUOME3NpEmTJABSmTJlUt2efOyLFy+kv/76SwIg9e/fX2ufpk2bSgCkO3fuSGfOnNF5gGl2Xx/Xr1+XTExMJADSrFmzJLVaLUmSJMXGxkqDBw/WDEp9/fq11nHJ98nU1FQaOnSoFBMTI0mSJCUlJUnjx4+XAEhFihSREhMTtY7LaNBiRq/V5NfY06dPNevmzJkjAZCaNWsmhYaGau3//Plzaf78+VrrkgdvflrOSUlJUo0aNTSvkcDAQM22gwcPSlZWVhIAaenSpak+J1NTU8nJyUl68OCBZtuFCxekvHnzSgCkgwcPpvm8PpWc0djYWJIkSVqyZIkEQPrll1+09nN0dJTMzc2lsLAwaePGjWm+vtevXy/9+++/WusSEhKkVatWSSYmJlKZMmU09/7T55XeANPk14GxsbHUv39/rfeK6OjoDM/j5+cnAZAcHR01x966dUsyNzeXjI2NpfPnz6d5bSJSFrask/AcHR01X/devXoVHTt2hI2NDSpUqIBevXph27ZtiIuLS3Hcq1evACDDlip9adKkiaaF9tixY2jZsiWsra3h4uKCgQMHYv/+/en2z86s4sWLAwCCgoKyfS5DkiQJL1++xLx58zBz5kwAgI+PT4bHNWvWDAULFsT27ds19zkgIADHjx9H9erV0x2wm57svj7mzJmDxMREtGnTBmPHjtV0fTI3N8fixYtRqVIlREREYNmyZake7+TkhIULF8LCwgIANN0aChUqhNevX+N///tflnLp4tGjRwCAIUOGIH/+/FrbSpQokemxEceOHcOVK1dgbm6OrVu3wt7eXrOtefPmmDx5MgBg5syZqbauJyYmYv369XB0dNSsq127Nvr27QsAOHjwoE7P62OdOnWCqampVleYf/75Bw8fPsTXX38NGxubdI/v0aMHypQpo7XOxMQEffr0QefOnfHkyRNcvHgxy/mcnZ2xbNkyrW+YMjMuYdy4cfD09MTDhw8xZswYxMfHo1u3boiLi4OPjw/q1KmT5UxEZFisrNNnYcKECTh+/DhatmwJMzMzSJKEBw8eYN26dejcuTMcHR1TfB39/v17AICVlZXBci5fvhy7du1C/fr1YWxsjMTERPzvf//D8uXL0apVK7i4uODWrVvZukby80l+fkr38TzrxYsXx+jRo5E3b14sWrRIUxlLj4mJCTp37oy3b99qupX8/vvvUKvVWR5YCmT/9ZHcDemHH35IsU2lUmHYsGFa+32qd+/eKcY2mJqawsXFBcB/YyByUvIHvz179iAxMTHL50l+jl5eXihUqFCK7QMHDoS5uTmeP3+e6sw+VatWRY0aNVKsTx7bkJ2ysLW1RYsWLXDv3j1cu3YNgO4Dk+/fv4/Jkyejffv2aNCgATw9PeHp6YlTp04BAG7evJnlfN26dcvSGBcjIyNs2LABefLkwbJly/D111/j5s2bcHV1xaRJk7Kch4gMj5V1+mw0bNgQf/31F96+fYvTp09j9uzZmoFU/v7+aNmypWZ6O+BDf2cA2RqglhXt27fHyZMnERYWhiNHjmDatGmoWbMmAODOnTto0qQJgoODs3z+yMhIAEgxa4lSJffXdXNz07RiWltbo27dupk+x6cDBTdu3AhjY2N06dIly7my8/p4+/at5h6m1bJfqVIlAMDDhw9T3V62bNlU1yfPIpR8n3NSr169YG1tjXXr1qFYsWL4/vvvsXr1ap0rx8nPMa2yyJMnj+aDQWrlkdNl8fHrJzExEdu2bUP+/PnRsmXLDI/18/NDpUqVMHXqVOzZswenTp3CuXPncO7cOc0g77CwsCxnq1ixYpaPLV26NBYsWAAAOHr0qGYwtqmpaZbPSUSGx8o6fXYsLS1Rt25djBkzBsePH8fp06dhZWWFmJgYzJ07V7Nf0aJFAXyY9UEOefPmRZMmTTBx4kT8888/2LFjB4yMjBAUFIQVK1Zk+bzJA+U+nRpSqZLnWb906RICAwMxefJkPH78GM2bN093JpiPubm5oUKFCjhw4ABOnz6NmzdvomnTplrdLXSVndfHx5XHtO5Dcra0vgFJq0U/uZU1te4i+lakSBFcuHABHTp0QEREBNavX4++ffuibNmyqFOnDi5cuJCp8ySXR3qvyfTKI6fLolWrVrC2tsaWLVuwf/9+BAcH49tvv4WZmVm6x50+fRoTJkyASqWCn58f7ty5g8jISCQlJUGSJPj6+gJAtgaUZ/ebv3r16sHExAQAUKdOHVSoUCFb5yMiw2NlnT57np6eGDx4MADg0qVLmvXu7u4AgNu3b2er5UtfOnbsiA4dOgDQzqmLpKQkTQUqubVeJGZmZpgyZQratGmDwMBAeHt7Z/rYbt26IT4+XtN1ITtdYIDsvT5y586t+f+0xg68efMGwH8t+IaSVsU2rW8QKlasiJ07d+Lt27c4ceIEpkyZggoVKuDixYto1qxZiqkeU5NcHumNo5CrPADAwsICXl5eePPmDYYPHw4gc6+fzZs3AwDGjh0Lb29vODk5wcrKSjP7kNzTp6rVavTo0QOJiYkwMjLC8ePHNZmJSBysrNMXIXkAWHx8vGZdrVq1UKpUKSQmJmarJVufUsupi7179yIwMBCmpqZo1qyZPqMZlJ+fn2Y+6cePH2fqmG7dumm6POXOnRtt27bNVobsvD7y5cuHAgUKAADu3r2b6j7Jc3B/PGgyJyW30KbWxSoiIiLDbzHMzc3RoEEDTJ48Gbdv34aHhwciIyOxZcuWDK+d/BzTKov3799rKraGKo9PJXeF8ff3R5kyZTQf1tKT/EElrX3T6quelalEs+KXX37BhQsXUKlSJWzbtg0AMHToUNk/RBCRblhZJ+GFhIRk+DX4+fPnAUAzvzHw4efGk2cbmTZtmmZwWVru3buH/fv3ZzlnZmZnSS1nZj1//hxDhw4F8GGGiuRuHCKqWLEiWrduDbVarZkZJiMlS5bEgAED0LhxY4wZM0anH8hKTXZfH1999RUAYNGiRSn2lSRJsz55v5yW/EHw03m3gQ+/1KoLY2NjzeDO169fZ7h/8nPcsWMHAgMDU2xfvnw54uLiULJkSZQvX16nLPpSr149tG/fHo0bN8bYsWMzdUzyrCzJ3wp87PDhw2lW1pOPS/7V2Zxw9epVTJs2Daampti0aRM6duyIfv364e3bt+nOaU9EysPKOglv06ZNqFq1KlauXInQ0FCtbW/fvsWkSZM0szsk/3Jgsv79+6NDhw6Ijo5Gw4YNsWjRohR9Zl+8eIGJEyeiRo0amW7lTc0vv/yCunXrYsuWLSmuERAQgIEDB+LMmTNQqVTo2bNnps8bEhKCX3/9FTVq1EBAQACcnJw+ix87GT9+PABgw4YNePnyZaaOWbZsGY4ePaqZCjC7svP6GD16NExMTPDHH39g7ty5SEpKAvDhW5Phw4fj9u3bsLa2xqBBg/SSNSMtWrQAAEycOFGrcnno0CFMnTpV06/5Y76+vli9enWKHxu7ffu25pdUq1evnuG1GzVqBDc3N8TFxaFLly5aH1wPHz6Mn376CQDg7e1tsFbnT6lUKuzatQtHjx7FwIEDM3WMp6cnAGDGjBlaYxsuX76M3r17a6bd/NTHH5w+/gEwfYmJiUH37t2RkJCAn376CVWrVgUAzJs3D2XLlsXx48excOFCvV+XiHKIXBO8E+nLggULND/4AkAqXbq0VLNmTalcuXKSmZmZZv2YMWNSPT4hIUEaPHiwpFKpND/AUrFiRalmzZpSqVKlNMfnz59fOnbsmOa4j3/Yx9bWNs2lQYMGkiRJ0ogRIzT7GxkZSeXKlZNq1qwplS5dWvPjOcbGxtLChQtTZEz+wZpy5cpJHh4ekoeHh1SjRg2tfAAkLy+vFD9ekyz5R1YsLS3TzXvgwAGd70HyjyKZmJike25fX98UZZeeunXrSgCk4cOHa61PPvbFixeZypeVH0VKltXXhyRJ0tKlSzXH2dvbS25ublK+fPkkAJK5ubm0f//+FNdLvk8nTpxINU/Pnj1T/YGsjH5oJygoSCpUqJDm2lWrVtXk9/b2TvVHkdq0aaN5vTo4OEg1a9aUHBwcNM+5YcOGUkJCgmb/tH4USZIk6dGjR1KxYsU0169evbrWubp37y4lJSXp9JySX0eZ/TGujzMm/yhSZqT1o0gRERFSmTJlJACSmZmZVLlyZal8+fISAMnJyUkaNWpUqj9EplarpXLlymneO+rUqSPVr19f63We0etAktIunx9++EECILm7u6f48axz585JxsbGkoWFhXT37t1MlwERyYct6yS8wYMH4/jx4xg7dizc3d2hVqtx48YNvHr1CiVLlkSPHj1w5swZzJ49O9XjTUxMsGTJEty4cQNDhw6Fo6MjXr9+jevXryM6OhqNGzfGwoUL8e+//6JRo0apniM0NDTNJTw8HMCHlvW//voLQ4cOhaurK6KionD9+nUEBwfD0dERAwcOxLVr1zTzb6fm0aNHmmnh7t+/j8TERDRp0gS+vr64e/cutm/fnuLHaz4VExOTbt7UfkAqsxITE9M9t65T7CW3rq9cuTJb01lmR3ZeH4MGDcKZM2fQtm1bJCUl4caNG8iVKxe6deuGa9eu4euvvzbY8yhQoADOnTsHLy8v5MqVCw8ePICNjQ3Wrl0LPz+/VI+ZOHEivL294ebmhsjISNy4cQMxMTGoX78+NmzYgMOHD6faIp8aBwcHXL9+HWPGjEGJEiVw584dBAUFoV69eti4cSPWr18vW6t6VuXNmxdnz55Fjx49kDdvXjx48ADx8fEYNWoULly4kOZgWSMjI/z111/o2LEjjI2NcenSJZw6dQo3btzIdqajR49i8eLFsLKywoYNG2BsbKy13d3dHePHj0dsbCy6deuWrZlqiMgwVJLEjmtERERERErElnUiIiIiIoViZZ2IiIiISKEy19mQiL4YXl5eCAgIyNS+LVu2xIQJE3I4ERER0ZeLlXUi0nL58mU8f/48U/s6ODjkcBoiIqIvGweYEhEREREpFPusExEREREpFCvrREREREQK9dn2WbesNlTuCJkSfnmx3BHIgETpdCbYb9MQEVE6LBRW21NSHS3muvLrYWxZJyIiIiJSKFbWiYiIiIgUSmFfjBARERHRZ03FtmJdsLSIiIiIiBSKlXUiIiIiIoViNxgiIiIiMhxOOaYTtqwTERERESkUK+tERERERArFbjBEREREZDicDUYnLC0iIiIiIoViyzoRERERGQ4HmOqELetERERERArFyjoRERERkUKxGwwRERERGQ4HmOqEpUVEREREpFCsrBMRERERKRS7wRARERGR4XA2GJ2wZZ2IiIiISKG+6Mr6mN7NcHbTWASdnYPnx/ywfV4/lCtZMM39F/l2Rsz1xRjatUGa++xdPAgx1xejVYMqOZA4fdu2bEaLZo3gVq0yOnu1x7WrVwyeISMiZASUn/PqlcsYNmQgmjb0RFXn8jh+7KjckdKk9LIExMgIiJFThIyAGDlFyAiIkVOEjIA4ObNNZaScRQBipMwhdas74Ldtp1G/xxx8M2gxjI2NsX/ZUOSyMEuxb6sGVeBWuRReB71N83w/fNcQkpSDgdNx6OABzJrhh379B2Hbzr2oXt0Vgwf0Q8Dr1/IESoUIGQExcsbERMOxfHl4T5gkd5R0iVCWImQExMgpQkZAjJwiZATEyClCRkCcnGR4X3Rlvc3Qpdj05z+49yQQtx6+woApm1CicH5UcyqutV+RAtaY7+2FXhPWISFRneq5KjsWxbBujTBwyiZDRE9h4/q1aNehA9p39EKZsmUxzscXhQoXwvZtW2TJkxoRMgJi5PSsWx9Dh41E46bN5I6SLhHKUoSMgBg5RcgIiJFThIyAGDlFyAiIk5MM74uurH8qb24LAEB4RLRmnUqlwuqfe2D++mO49yQw1eMsLUyx3u97jJy5HW9C3xsk68cS4uNx7+4d1HH31Fpfx90DN29cN3ie1IiQERAnpwhEKEsRMgJi5BQhIyBGThEyAmLkFCEjIE5OvVGplLMIgJX1j8wc3QHnrj3G3X8DNOtG92qKRHUSlmw5meZxs0Z3wMWbT7H/5C0DpEwp/G041Go1bG1ttdbb2tohJCRYlkyfEiEjIE5OEYhQliJkBMTIKUJGQIycImQExMgpQkZAnJwkD8VX1l+8eIHevXunu09cXBzevXuntUhJqXdXSct8729RuVwR9PRZp1lXrWJxDOnSAP0np9215ev6ldGgpiPGzt6p0/VyguqTT4iSJKVYJzcRMgLi5BSBCGUpQkZAjJwiZATEyClCRkCMnCJkBMTJSYal+Mp6WFgY1q9fn+4+fn5+sLa21loS31zN9DXmjffCN/Ur46t+v+LVRwNIPaqVRcH8ufHwwFS8v7wQ7y8vRMkitpgxqj3u//UTAKCBmyPKFLND4OnZmn0AYMucvvh75XDdn3AW2OSzgbGxMUJCQrTWh4WFwtbWziAZMiJCRkCcnCIQoSxFyAiIkVOEjIAYOUXICIiRU4SMgDg59UbuGWA4G4xu9u3bl+5y4sSJDM/h4+ODiIgIrcXE3jVT158/3gttGrmg+YBf8fx1qNa23/+6DLdv/VCr8wzN8jroLeZvOIpWg5cAAOasPZxiHwAYN3dXui3y+mRqZoaKTpVw8fw5rfUXz5+HS9VqBsmQEREyAuLkFIEIZSlCRkCMnCJkBMTIKUJGQIycImQExMlJ8pD9F0zbtm0LlUoFKZ05DzP6Csjc3Bzm5ubaxxgZZ3jtBT7folOLGvAauQKRUbGwt80DAIiIjEVsXALCIqIQFhGldUxCohpvQt7h0fMgAMCb0PepDip9ERCeovKfk7r37AVf73FwcnaGi0s17NqxDQEBAfDq1NlgGTIiQkZAjJzR0VHw9/fXPH716iXu378Ha2trFC5cRMZk2kQoSxEyAmLkFCEjIEZOETICYuQUISMgTk4yPNkr64ULF8aSJUvQtm3bVLffuHEDrq6ZayXX1YBv6wEAjqwaobW+36SN2PTnPzlyzZzSvEVLRLwNx4plSxEcHASHco5Y8tsKFClSVO5oGiJkBMTIeef2bfTr3UPzeO4sPwBAqzbtMG36DLlipSBCWYqQERAjpwgZATFyipARECOnCBkBcXLqBfvh60QlpdekbQCtW7dG1apVMXXq1FS337x5E9WqVUNSUpJO57WsNlQf8XJc+OXFckcgA5L3ry3z+D5KRPT5sJC9aVabpYev3BE0Ys5NlztChmS/fWPHjkVUVFSa2x0cHDLVb52IiIiIBCDIwE6lkL2yXrdu3XS3W1lZoX79+gZKQ0RERESkHPxoQ0RERESkULK3rBMRERHRF4QDo3TClnUiIiIiIoViZZ2IiIiISKHYDYaIiIiIDIezweiEpUVEREREpFCsrBMRERERKRS7wRARERGR4bAbjE5YWkRERERECsWWdSIiIiIyHCPOs64LtqwTERERESkUK+tERERERArFbjBEREREZDgcYKoTlhYRERERkUKxsk5EREREpFDsBkNEREREhqPibDC6YMs6EREREZFCsbJORERERKRQn203mPDLi+WOkCk2bZWfM3zvULkjfDZi4tVyR/hs5DI3ljsCERFlBWeD0QlLi4iIiIhIoT7blnUiIiIiUiAOMNUJW9aJiIiIiBSKlXUiIiIiIoViNxgiIiIiMhwOMNUJS4uIiIiISKFYWSciIiIiUih2gyEiIiIiw+FsMDphyzoRERERkUKxZZ2IiIiIDIcDTHXC0iIiIiIiUihW1omIiIiIFIrdYIiIiIjIcDjAVCdsWSciIiIiUihW1omIiIiIFIrdYIiIiIjIcDgbjE5YWkRERERECsXKOhERERGRQrGyngnbtmxGi2aN4FatMjp7tce1q1fkjoQitlZYM7opXv7eF6E7B+Dir51QrWwBzXYrC1PMH1gPj9d9j7BdA3F9WVf0a+EsY+IPlFiWqRElJwCsX7MCdao7Yf5sP7mjpEvJOUW53yLkFCEjIEZOETICYuQUISMgTs5sU6mUswiAlfUMHDp4ALNm+KFf/0HYtnMvqld3xeAB/RDw+rVsmfJZmeP4rA5ISExC2yn7UG3w7/BefQ5vo+I0+8zq54mm1Uug19wjqDpoMxbtvYl5A+vhm1qlZcutxLJMjSg5AeDunVv4Y/cOOJQrL3eUdCk5pyj3W4ScImQExMgpQkZAjJwiZATEyUmGx8p6BjauX4t2HTqgfUcvlClbFuN8fFGocCFs37ZFtkyjO1bHy5BIDFh4DFceBsE/6D1O3nyJp4HvNPvUqlAIm47fx5lbr+Af9B5r/r6D/z0NQfVyBWXLrcSyTI0oOaOjozDFdxy8f/wJefLmlTtOmpSeU5T7LUJOETICYuQUISMgRk4RMgLi5NQLlZFyFgGIkVImCfHxuHf3Duq4e2qtr+PugZs3rsuUCvi6VmlcexSEzd7N8XxTb1xY2Am9vnLS2uf83QB8U7M0ithaAQDqVS6KckXy4eg1fzkiK7YsPyVKTgCYM+NnuHvWR81a7nJHSZeSc4pyv0XIKUJGQIycImQExMgpQkZAnJwkD07dmI7wt+FQq9WwtbXVWm9ra4eQkGCZUgGlC+VFv5bO+HXvDczafgU1HO0xt389xCWo8fvxBwCA0ctPY+kPjfDv+l5ISFQjSQIG/Xoc5+8GyJJZqWX5KVFyHvn7AB7cv4s1G7fLHSVdSs8pyv0WIacIGQExcoqQERAjpwgZAXFykjwUUVmPiYnB1atXkT9/fjg5abcQx8bGYvv27ejRo0eax8fFxSEuLk5rnWRsDnNzc73kU30yAEGSpBTrDMlIpcK1x0GYvOEiAODmkxA4lciP/i0rayrrQ1q5oGZ5e3SYuh/+Qe/h6VwECwfVR2BYFE7cfClbdqWVZVqUnPNNYADmz/bDwqUr9fYazwmi5ASUfb8/JkJOETICYuQUISMgRk4RMgLi5Mw2QbqfKIXspfXw4UNUrFgR9erVQ+XKldGgQQMEBPzX+hsREYFevXqlew4/Pz9YW1trLbNnZn/GCZt8NjA2NkZISIjW+rCwUNja2mX7/FkVGB6Fe/5hWuvuvwhH8QK5AQAWZsb4qUdtjF91FgcuPcPtZ6H4bf8t7DzzCCPaV5MjsmLL8lMi5Lx/7w7Cw0LR6zsveLpVhqdbZVy/ehk7tm6Cp1tlqNVquSMCECOnCPcbECOnCBkBMXKKkBEQI6cIGQFxcpI8ZK+sjx8/HpUrV0ZQUBAePHiAvHnzwsPDA/7+me9b7ePjg4iICK1l7HifbGczNTNDRadKuHj+nNb6i+fPw6WqPJVeALhwNxCOxWy01pUrmg/+Qe8BAKbGRjAzNUaSJGnto06SYCTTJ3SlluWnRMhZo2YdbNr+B9Zv2a1ZKjo546sW32D9lt0wNjaWOyIAMXKKcL8BMXKKkBEQI6cIGQExcoqQERAnJ8lD9m4w58+fx9GjR2FnZwc7Ozvs27cPQ4YMQd26dXHixAlYWVlleA5z85RdXmIT9ZOve89e8PUeBydnZ7i4VMOuHdsQEBAAr06d9XOBLFj0xw2cmN0BY71csevsY7g52qN380oYuvgEAOB9TAJO33qFX3p7ICZeDf+gd6jrXBTfNaqA8avOypZbiWWZGqXntLKyQlmHclrrLCwtkdc6X4r1chIlp9LvdzIRcoqQERAjpwgZATFyipARECenXnyOXXtykOyV9ZiYGJiYaMdYsmQJjIyMUL9+ffz+++8yJfugeYuWiHgbjhXLliI4OAgO5Ryx5LcVKFKkqGyZrj4KQqfpBzG1Zx1M6OKGZ2/eYezKM9h68qFmnx4z/8bUnnWwbkxT2OS2gH/Qe0zZeBErD96WLbcSyzI1ouQk/RDlfouQU4SMgBg5RcgIiJFThIyAODnJ8FSS9ElfCQOrWbMmfvjhB3Tv3j3FtqFDh2Lz5s149+6dzv1b9dWyntNs2i6WO0KGwvcOlTvCZyM6Tv5+2p+LXObyd6MhIhKBhexNs9osWy+TO4JGzL5BckfIkOx91tu1a4ctW1Kf8H/x4sXo0qULZP48QURERET6IvcPIQn2o0iyt6znFLas6w9b1vWHLev6w5Z1IqLMUVzLepvlckfQiPljgNwRMqSw20dEREREnzUOMNWJGO3/RERERERfIFbWiYiIiIgUit1giIiIiMhwBBnYqRQsLSIiIiIihWJlnYiIiIhIodgNhoiIiIgMh7PB6IQt60RERERECsWWdSIiIiIyGBVb1nXClnUiIiIiIoViZZ2IiIiISKHYDYaIiIiIDIbdYHTDlnUiIiIiIoViZZ2IiIiISKHYDYaIiIiIDIe9YHTClnUiIiIiIoViZZ2IiIiISKHYDYaIiIiIDIazweiGlXWZhe8dKneEDNk0+FHuCJkSenyq3BEylMvcWO4ImSJJcicgQxLlficmJckdIUOmxvzCmoj0i5V1IiIiIjIYtqzrhk0AREREREQKxco6EREREZFCsRsMERERERkMu8Hohi3rREREREQKxco6EREREZFCsRsMERERERkMu8Hohi3rREREREQKxco6EREREZFCsRsMERERERkOe8HohC3rREREREQKxZZ1IiIiIjIYDjDVDVvWiYiIiIgUipV1IiIiIiKFYjcYIiIiIjIYdoPRDVvWiYiIiIgUipV1IiIiIiKFYjcYIiIiIjIYdoPRDVvWM2Hbls1o0awR3KpVRmev9rh29YrckVIlZ84x3erh7MoBCDo8Ec//HI/tv3RFueJ2Wvu0qeeEfXN74MV+b8ScnYYqDoVSnOfvRb0Rc3aa1rJhyreGehrYvm0Lvm3fGp61XeFZ2xU9vuuEs2dOG+z6ulD66/LqlcsYNmQgmjb0RFXn8jh+7KjckdKk9LJMpvScotzzoDdv8KPPODSuWxseNauhq1c73Lt7R+5YKSj9ficTIacIGQFxcpJhsbKegUMHD2DWDD/06z8I23buRfXqrhg8oB8CXr+WO5oWuXPWrVYKv+2+hPoDVuCbkethbGyE/fN7IpeFqWafXJamuHDLHz/+diTdc63edxmlWs/ULENn/5HT8TXs7e3xw4jR2Lx1JzZv3YmatWpj5LAh+PfxI4NlyAy573dmxMREw7F8eXhPmCR3lHSJUJaAGDlFuOfv3kWgT8+uMDExwcKlK7Bjz36MGD0OefLkkTuaFhHuNyBGThEyAuLkJMNTSZIkyR0iJ8Qm6uc833X2QkUnJ0yc9JNmXdtWLdCwURMMHzlaPxfRg5zMadPgR52PscuXCy/2+6DJkFU4d/O51rYShfLhwc7RqPX9EvzvcaDWtr8X9cb/HgVg7K8Hdb5m6PGpOh+TGfU9amHE6LFo175jts9lZKSfr/5y+nWp73eFqs7lMW/hEjRq3ERv59TXt6j8G9f//QZy5p4nJiVl+xyLFszFzevXsWr9Jj0kSsnUWD9tYHxd6o8IGYGczWmhsE7Ptj22yB1BI3RDF7kjZIgt6+lIiI/Hvbt3UMfdU2t9HXcP3LxxXaZUKSkxZ14rCwBA+LsYnY/t1NQFL/Z74+rGH+A35CvktjTTd7xMUavVOHTwL8TERKOKS1VZMqRGifdbVKKUpSg5RXD65AlUrFQJ40ePQNP6Huj6bXvs2bld7lhaRLnfIuQUISMgTk6Sh8I+aylL+NtwqNVq2Nraaq23tbVDSEiwTKlSUmLOmT+0wLmbz3D3aZBOx209fBPPAsLxJjQSlcrYY+qApqjsUAjfjFyfQ0lTevTwAXp264L4+DhY5sqFuQsWo2xZB4NdPyNKvN+iEqUsRckpglcvX2DX9q34rvv36NW3P+7cvoU5M3+BqZkZvmndVu54AMS53yLkFCEjIE5OveH4Up0oorJ+7949XLx4EXXq1EGFChVw//59LFy4EHFxcejWrRsaNWqU7vFxcXGIi4vTWicZm8Pc3Fwv+T4dtSxJkiJHMisl5/xR36ByWXs0HrxK52PX/nlV8/93nwbh8ctQnF89CFUdC+PGwwB9xkxTqdKlsXXnHrx//w7HjhzGpIneWLV2o6Iq7IBy7vfnQJSyFCWnkiUlSXCqVAlDho8EAFSo6IQn/z7Gru1bFVNZTybK/RYhpwgZAXFykmHJ3g3m0KFDqFq1KsaMGYNq1arh0KFDqFevHh4/fgx/f3989dVXOH78eLrn8PPzg7W1tdYye6ZftrPZ5LOBsbExQkJCtNaHhYXC1tYujaMMT0k55434Gt94VMBXw9bgVfC7bJ/v+oPXiE9IhEMx24x31hNTUzOUKFESlSpVxrARo+HoWAFbNm0w2PUzoqT7LTpRylKUnCKwK2CH0mXKaq0rXboMAgMN0xiQGaLcbxFyipARECcnyUP2yvrUqVMxduxYhIaGYu3atejatSv69euHI0eO4OjRoxg3bhxmzJiR7jl8fHwQERGhtYwd75PtbKZmZqjoVAkXz5/TWn/x/Hm4VK2W7fPri1Jyzh/5NdrUd0Lz4WvwPOCtXs7pVLogzExNEBD6Xi/nyxoJ8fHxMl5fm1Lu9+dAlLIUJacIXKpWx/Nnz7TWPX/+DIULF5EnUCpEud8i5BQhIyBOTn1RqVSKWUQgezeYO3fuYMOGD62W3377Lbp3744OHTpotnfp0gWrV69O9xzm5im7vOhrNpjuPXvB13scnJyd4eJSDbt2bENAQAC8OnXWzwX0RO6cC0Z/g05NqsDL53dERsfDPn9uAEBEZCxi4z/cDJs8lihub43Cdh+mSHMs8aG14E1YJN6ERaJ0ERt0buaCvy88REhENCqWKoAZQ1vg+oPXuHDL3yDPY9HCefDwrIdChQohKioKfx86gCuXL2HJspUGuX5myX2/MyM6Ogr+/v/dt1evXuL+/XuwtrZWVMVIhLIExMgpwj3v2r0nevfoijUrl6PpV81x59Yt7Nm5A76Tf8r4YAMS4X4DYuQUISMgTk4yPNkr6x8zMjKChYUF8uXLp1mXJ08eREREyJapeYuWiHgbjhXLliI4OAgO5Ryx5LcVKFKkqGyZUiN3zgHtagEAjizuo7W+3/Td2HTww0j2rz0rYKVve822jVM7AQB+XnMc09ecQEKiGg1dy2CIVx3ktjTDy6AIHLrwENPXnEBSkmFmGA0NDcXECeMQEhyM3HnyoFy58liybCVqu3sY5PqZJff9zow7t2+jX+8emsdzZ33omtaqTTtMm57+t2WGJEJZAmLkFOGeV3KujDnzf8XihfOxavlSFClaDKPHeaPF163kjqZFhPsNiJFThIyAODnJ8GSfZ93FxQUzZ85E8+bNAQC3b99GhQoVYGLy4XPE2bNn0aNHDzx58kSn8+qrZZ2yNs+6HHJqnnV90tc86zlNhF9fEOTbSyGIcL8B/cyzntP0Nc86kT4pbZ71Ar22yR1BI3htJ7kjZEj22zdo0CCo1WrNY2dnZ63tBw8ezHA2GCIiIiKiz5HslfWBAwemu3369OkGSkJEREREOU2UgZ1Kwe/riIiIiIgUipV1IiIiIqJMWrp0KUqXLg0LCwu4urrizJkz6e6/efNmuLi4IFeuXChcuDB69eqF0NDQTF+PlXUiIiIiMhyVghYdbdu2DSNGjICvry+uX7+OunXrokWLFlrT1n4seaKUPn364M6dO9ixYwcuX76Mvn37ZvqarKwTEREREWXCvHnz0KdPH/Tt2xcVK1bEggULULx4cSxbtizV/S9evIhSpUph2LBhKF26NDw9PTFgwABcuXIl09dkZZ2IiIiIKAPx8fG4evUqmjVrprW+WbNmOH/+fKrHuLu74+XLlzhw4AAkScKbN2+wc+dOfP3115m+ruyzwRARERHRl0NJs8HExcUhLi5Oa525uTnMzc1T7BsSEgK1Wg17e3ut9fb29ggMDEz1/O7u7ti8eTM6deqE2NhYJCYmonXr1li0aFGmM7JlnYiIiIi+SH5+frC2ttZa/Pz80j3m0w8bkiSl+QHk7t27GDZsGCZNmoSrV6/i0KFDePr0aYZTl3+MLetERERE9EXy8fHBqFGjtNal1qoOAHZ2djA2Nk7Rih4UFJSitT2Zn58fPDw8MHbsWABAlSpVYGVlhbp16+Lnn39G4cKFM8zIlnUiIiIiMhiVSqWYxdzcHHnz5tVa0qqsm5mZwdXVFUeOHNFaf+TIEbi7u6d6THR0NIyMtKvbxsbGAD60yGcGK+tERERERJkwatQorFq1CmvWrMG9e/cwcuRI+Pv7a7q1+Pj4oEePHpr9W7Vqhd27d2PZsmV48uQJzp07h2HDhqFmzZooUqRIpq7JbjBEREREZDBKGmCqq06dOiE0NBRTp05FQEAAnJ2dceDAAZQsWRIAEBAQoDXn+vfff4/3799j8eLFGD16NPLly4dGjRph5syZmb6mSspsG7xgYhPlTvD5sGnwo9wRMiX0+FS5I2TIyEiMNygR3hUEfq9XHBHuNwAkJiXJHSFDpsb8wpqUx0JhTbOF+++SO4JGwIoOckfIEN9ViIiIiIgUSmGftYiIiIjocyZyNxg5sGWdiIiIiEihWFknIiIiIlIodoMhIiIiIsNhLxidsGWdiIiIiEih2LJOGQo7MU3uCJmSv+ZQuSNkKPzyYrkjZArH/nxZRLnfnBaRiL5ErKwTERERkcFwNhjdsJmCiIiIiEih2LJORERERAbDlnXdsGWdiIiIiEihWFknIiIiIlIodoMhIiIiIoNhNxjdsGWdiIiIiEihWFknIiIiIlIodoMhIiIiIsNhLxidsGWdiIiIiEihWFknIiIiIlIodoMhIiIiIoPhbDC6Ycs6EREREZFCsWWdiIiIiAyGLeu6Ycs6EREREZFCsbJORERERKRQ7AZDRERERAbDbjC6Ycs6EREREZFCsbKeCdu2bEaLZo3gVq0yOnu1x7WrV+SOlCql57x65TKGDRmIpg09UdW5PI4fO2rwDB7Vy2LnggF4cng6Yq4vRqsGVbS2W1maYf54Lzw+NA1hF+bh+q6J6OflqbVP6WJ22Da3H/yP++HNmdnYNLM3CubPY8inAUD59zuZCDlFyAiIkVOEjIAYOUXICIiRU4SMgDg5ybBYWc/AoYMHMGuGH/r1H4RtO/eienVXDB7QDwGvX8sdTYsIOWNiouFYvjy8J0ySLYOVpTluPXyFkTO2p7p91pgOaOruhF6+G1C1/c9YtPkE5o3zwjcNKgMAclmYYf/SIZAkCS36L0KjXvNhZmqMXQsHGPRrPRHuNyBGThEyAmLkFCEjIEZOETICYuQUISMgTk59UKlUillEwMp6BjauX4t2HTqgfUcvlClbFuN8fFGocCFs37ZF7mhaRMjpWbc+hg4bicZNm8mW4fC5u/hp6X78cfxmqttrVSmNTfv/wZmrj+AfEIY1u8/hfw9fobpTCQBAnaplULKILfpN3oQ7j1/jzuPX6D95E2o4l0KDmo4Gex4i3G9AjJwiZATEyClCRkCMnCJkBMTIKUJGQJycZHiKrKxLkiR3BABAQnw87t29gzru2t0g6rh74OaN6zKlSkmUnCI4f+MJvqlfGUUKWAMA6tUoh3IlC+Lo+XsAAHMzE0iShLj4RM0xsfGJUKuT4F61rEEyinK/RcgpQkZAjJwiZATEyClCRkCMnCJkBMTJqTcqBS0CUGRl3dzcHPfu3ZM7BsLfhkOtVsPW1lZrva2tHUJCgmVKlZIoOUUweuYO3HsSiH8PT8e7Swuxb8lgDPfbhvM3ngAALt16hqiYeEwf3gaWFqbIZWEGvxFtYWxshEJ2eQ2SUZT7LUJOETICYuQUISMgRk4RMgJi5BQhIyBOTpKHrFM3jho1KtX1arUaM2bM0Lxo582bl+554uLiEBcXp7VOMjaHubm5XnJ+2qdJkiRF9nMSJaeSDenSADUrl0KH4b/BPyAMntUdsNCnEwJD3uHEPw8QEh6J78atxq8TOmFwl/pISpKw/dBVXLvrD3VSkkGzinK/RcgpQkZAjJwiZATEyClCRkCMnCJkBMTJSYYla2V9wYIFcHFxQb58+bTWS5KEe/fuwcrKKlMvUj8/P/z0009a63x/nIyJk6ZkK59NPhsYGxsjJCREa31YWChsbe2ydW59EiWn0lmYm+KnH1qh06iVOHT2DgDg9qPXqFK+GEZ0b4wT/zwAABy7eB+VWv8E23xWSExMQkRkDJ4e+QXPX4UaJKco91uEnCJkBMTIKUJGQIycImQExMgpQkZAnJz6wg8gupG1G8z06dMRERGBH3/8ESdOnNAsxsbGWLduHU6cOIHjx49neB4fHx9ERERoLWPH+2Q7n6mZGSo6VcLF8+e01l88fx4uVatl+/z6IkpOpTM1MYaZqQmSPhkzoVYnwcgo5RtL6NsoRETGoL6bIwrmz439p24ZJqcg91uEnCJkBMTIKUJGQIycImQExMgpQkZAnJwkD1lb1n18fNCkSRN069YNrVq1gp+fH0xNTXU+j7l5yi4vsYlp7Kyj7j17wdd7HJycneHiUg27dmxDQEAAvDp11s8F9ESEnNHRUfD399c8fvXqJe7fvwdra2sULlzEIBmsLM1QtngBzeNSRW1RxbEowt9F40VgOE5feYRfRrRFTGwC/APCUNfVAd99UxPj5+3WHNO9dW08eBqI4PBI1KpSGnPGdsSizSfw6HmQQZ4DIMb9BsTIKUJGQIycImQExMgpQkZAjJwiZATEyUmGJ2tlHQDc3Nxw9epVDBkyBDVq1MCmTZsU9fVI8xYtEfE2HCuWLUVwcBAcyjliyW8rUKRIUbmjaREh553bt9Gvdw/N47mz/AAArdq0w7TpMwySobpTSRxeNVzzeNaYDgCAjfsuov/kTejhvQZTf2iDdb/0hE3eXPAPCMOUJfuxcsdZzTGOpQpi6g+tkd86F56/DsOs1X/j100ZfwOkTyLcb0CMnCJkBMTIKUJGQIycImQExMgpQkZAnJz6oKR6nghUklLmSQSwdetWjBgxAsHBwbh16xacnJyyfC59tawToJxXSPry1xwqd4QMhV9eLHcEIiL6wljI3jSrrezog3JH0Ph3bgu5I2RIUbevc+fO8PT0xNWrV1GyZEm54xARERERyUpRlXUAKFasGIoVKyZ3DCIiIiLKAewFoxtF/igSEREREREpsGWdiIiIiD5fHGCqG7asExEREREpFCvrREREREQKxW4wRERERGQw7AWjG7asExEREREpFCvrREREREQKxW4wRERERGQwnA1GN2xZJyIiIiJSKFbWiYiIiIgUit1giIiIiMhg2AtGN2xZJyIiIiJSKLasExEREZHBGBmxaV0XbFknIiIiIlIoVtaJiIiIiBSK3WCIiIiIyGA4wFQ3bFknIiIiIlIoVtaJiIiIiBSK3WBkpk6S5I6QISNBvq8KuvCr3BEyVH3SYbkjZMq+EXXljpChojaWckfIFEkS4G+cMzN8URLVyn9NAkB8YpLcETKUy9xY7ghCUglSr1AKtqwTERERESkUK+tERERERArFbjBEREREZDDsBaMbtqwTERERESkUW9aJiIiIyGA4wFQ3bFknIiIiIlIoVtaJiIiIiBSK3WCIiIiIyGDYDUY3bFknIiIiIlIoVtaJiIiIiBSK3WCIiIiIyGDYC0Y3bFknIiIiIlIotqwTERERkcFwgKlu2LJORERERKRQrKwTERERESkUu8EQERERkcGwF4xu2LJORERERKRQrKwTERERESkUu8FkwrYtm7Fu7WqEBAejrEM5jPOegOquNeSOlaY1q5Zj8cL56NKtB8aOnyB3HI2rVy5j/drVuHf3NoKDgzFv4RI0atxE7lhaWrVojIDXr1Os9+rUBeMnTDJIBtdSNuhdtxQqFc2Dgnkt8MPG6zh2L1iz/e4vzVI9bs7Bh1hz5hkAYF3fGqhZJr/W9gP/C8CYrbdyLPdfe7bjwN4deBP4ofxKli6LLt/3R43angCAedN/xLFDf2odU96pMuYt35hjmTJDhNfl9m1bsHPbFrx+/QoAUKasA/oPHALPuvVkTpaSKO+XIuRUesblSxdhxW9LtNbZ2trh8ImzMiUCrl+9gs0b1uDBvTsICQnGjLm/on7D//6eV/22GEcOH0RQYCBMTU1RvqITBg4ZjkqVXWTL/DGl33N94WwwumFlPQOHDh7ArBl+8P1xMqpWq46d27di8IB+2LPvLxQuUkTueCncuX0Lu3duRznH8nJHSSEmJhqO5cujTdv2GD3yB7njpGrD5h1QJ6k1j/99/AhDBvRB46bNDZYhl5kxHgS+x55rr/Drd1VTbK/3y0mtx3Ud7TCtfSUcvv1Ga/32Sy+x+OhjzePYhKSciKthV9Ae3w8chiJFSwAAjh7ah2k+I/Drmq0oWdoBAOBaywMjfH7SHGNqapqjmTJDhNelvb09fhgxGiVKfCjbP/ftxchhQ7B1x26UdSgnc7r/iPJ+KUJOETICQNmy5bB05RrNY2MjYxnTALGx0SjnWB7ftG4Hn7HDU2wvXrIURo/3RdGixREXF4utmzdg+JB+2PHHIdjY5E/ljIYjyj0nw2NlPQMb169Fuw4d0L6jFwBgnI8vzp8/i+3btmD4yNEyp9MWHR0FX+8x+HHyNKxasUzuOCl41q0Pz7r15Y6RLpv82m/W69esRLHiJeBaw81gGc48DMGZhyFpbg+JjNd63MipIC49DcPL8Bit9bEJ6hT75qRaHtr3tmf/H3Bg7w7cv3NLU1k3NTVFfls7g2XKDBFel/UbNNJ6PHTYSOzYthX/+99NRVXWRXm/FCGnCBkBwNjEGHZ2BeSOoVHHox7qeKT9jdNXLb7Rejx81Hj8uXcXHj98ALdadXI6XrpEuedkeOyzno6E+Hjcu3sHddw9tdbXcffAzRvXZUqVthnTp8KzbgPUquMud5TPQkJCPA789Sdat22v2K/sbHOboV55O+y68irFtm+qFsY53wbYN9wdY1s4IpeZ4Vq81Go1Th09hNjYGFSsVEWz/taNK+jaqiH6dWmNX2f+hLfhYQbL9LlQq9U4dPAvxMREo4pLVbnjaIjyfilCThEyJvN//hxfNa6LVs0bw2fcKLx8+ULuSJmWkBCPvbu3I3fuPCjnWEHeLALdc31QqZSziIAt6+kIfxsOtVoNW1tbrfW2tnYICQlO4yh5/H3wL9y/excbt+6UO8pn4+TxY4h8/x6tWreTO0qa2lQrgug4NY7cCdJav/9GAF6FxyA4Mh7l7HNjZLNyKF8oD/quvZqjeZ79+wijB/VAfHw8LC0tMXH6PJQoXRYAUKO2JzwbNkXBQkXwJuAVNq5aggnD+2Hhqi0wNTPL0Vyfg0cPH6Bnty6Ij4+DZa5cmLtgMcqWdZA7loYo75ci5BQhIwA4V3bB1OkzUKJkKYSFhWL1imXo3b0Ltu/5E/ny2cgdL01nT5/EJJ/RiI2Nha1dASxctgr5bOTNK8o9J3korrIeHh6O9evX49GjRyhcuDB69uyJ4sWLp3tMXFwc4uLitNZJxuYwNzfXS6ZPW1UlSVJUS2tgYABmz/gFS1es1ttzJuCPPbvg7lEXBQoWlDtKmtrXKIr9NwMQn6jdH33nRy3tj99E4nlIFHYOrYOKRfLg3uv3OZanaIlSWLRmG6Ii3+PcyWOYN30SZi5ahRKly6Je4680+5Uq44By5Z3Qy6sFLl04A4/6jXMs0+eiVOnS2LpzD96/f4djRw5j0kRvrFq7UVEVdkD575fJRMip9IwenwxwrlKlKtp83Qz79+1Ftx69ZEqVMVe3mli/ZTci3r7FH3t2YOL4UVi1YSvy57fN+OAcpvR7ri+f43PKSbJ3gylSpAhCQ0MBAE+fPoWTkxNmzpyJR48eYfny5ahcuTLu37+f7jn8/PxgbW2ttcye6ZftbDb5bGBsbIyQEO3+w2FhobBVUL/be3fuICwsFN916gC3qpXgVrUSrl65jK2bN8KtaiWo1eqMT0JaAl6/wqV/LqBN+45yR0mTa6l8KFPACjsvv8xw37uv3yMhMQklbXPlaCZTU1MUKVYC5SpUwvcDh6G0gyP+2Pl7qvvmtyuAgoUK4/VL/xzN9LkwNTVDiRIlUalSZQwbMRqOjhWwZdMGuWNpiPJ+KUJOETKmxjJXLjiUc4T/8+dyR0mXpWUuFC9REs5VXOA7+WcYGxvjz727ZM0k6j0nw5C9sh4YGKipTE6YMAEVKlTAv//+i8OHD+Px48eoW7cufvzxx3TP4ePjg4iICK1l7HifbGczNTNDRadKuHj+nNb6i+fPw6VqtWyfX19q1q6N7bv3YcuOPZrFqZIzWnzdClt27IGxsbyj80W07489sMmfX9EDD9u7FsXtlxF4EBiZ4b4O9rlhamKE4PeGG3AKAJAkJMSnfs13EW8RHPRGcQNOxSEhPo2ylYMo75ci5BQhY2ri4+Px9Mm/sCugnAGnmSGl8z5lKKLeczIMRXWD+eeff7Bq1SrkyvWh9c/c3BwTJ05Ex47pt26am6fs8hKbqJ9M3Xv2gq/3ODg5O8PFpRp27diGgIAAeHXqrJ8L6IGVVW44lHPUWmdpaQnrfPlSrJdTdHQU/P3/a0V99eol7t+/B2traxQurJxpqZKSkvDnH7vxTau2MDEx/J9ILjNjlPioBbxofktUKJwHEdEJCIiIBQBYmRvjq8qFMPvAgxTHF89viW+qFsbpByEIj4qHQ8HcGNvSEXdfvcP15+E5lnv98l/hWtsTBQraIyY6GqeOHcKtG1cwdc4SxERHY/Pa3+BRvzHy29rhTeBrrF+xCHmt86FOvUYZnzwHifC6XLRwHjw866FQoUKIiorC34cO4MrlS1iybKXc0bSI8H4JiJFThIzz58xEvQYNUahQEU2f9aioSLRq3Va2TNHRUXj54r+/59evXuHhg3vIm9ca1vnyYd2q5ahbvxFs7ezwLiICu3ZsQXDQGzRq+lU6ZzUMEe65vrAXjG4UUVlP7rsUFxcHe3t7rW329vYIDpZvcEXzFi0R8TYcK5YtRXBwEBzKOWLJbytQpEhR2TKJ6s7t2+jXu4fm8dxZH7oqtWrTDtOmz5ArVgqXLl5AYEAAWrdtL8v1KxXNi/X9/psq0vvrD7MU7Ln6Cr677gAAWlYpBBWAv24Gpjg+QZ2E2mXzo7t7CeQyM0FgRCxOPQjG0mP/IknKudzh4WGY+7MvwkJDYGWVG6XKOmLqnCWo5lYHcXGxeP7vIxw/9CeiIt/DxrYAqlSrAe8ps5Arl1XOhcoEEV6XoaGhmDhhHEKCg5E7Tx6UK1ceS5atRG13D7mjaRHl/VKEnCJkDAp6gwnjR+Nt+FvY5LdB5couWLdpGwrLmPH+3TsY0v97zeNf580EALRs1RbjJkzG82dPcWD/cES8DYe1dT5UrOSMZas3okxZ+adAFeGekzxUkiTl4D/fGTMyMoKzszNMTEzw6NEjbNiwAe3a/Tf7xunTp9G1a1e8fJlxv9yP6atlPaepc7L2pCdGgnwETlTn7I/+6EOtqUfljpAp+0bUlTtChoraWModIVNkfovNFCMjMf7GST8S1cp/TQJIMXBeiXKZi9HN1EIRTbP/qfnJj/vJ6dKEBnJHyJDst2/y5Mlaj5O7wCT7888/Ubeu8isORERERJQxzgajG8VV1j81e/ZsAyUhIiIiIlIW2WeDISIiIiKi1Mnesk5EREREXw72gtENW9aJiIiIiBSKLetEREREZDAcYKobtqwTERERESkUK+tERERERArFbjBEREREZDDsBaMbtqwTERERESkUK+tERERERArFbjBEREREZDCcDUY3bFknIiIiIlIotqwTERERkcGwYV03bFknIiIiIlIoVtaJiIiIiBSK3WCIiIiIyGA4wFQ3bFknIiIiIlIoVtaJiIiIiBSK3WCIiIiIyGDYDUY3rKzLTITXqwgZAQAC5Dw+vqHcETKl+fzTckfI0MWJjeWOkCki/KP0ODBS7giZ4lAot9wRPgsmxsp/TQKAkRG//CcC2A2GiIiIiEix2LJORERERAYjwBeOisKWdSIiIiIihWLLOhEREREZjAhjeZSELetERERERArFyjoRERERkUKxGwwRERERGQx7weiGLetERERERArFyjoRERERkUKxGwwRERERGQxng9ENW9aJiIiIiBSKlXUiIiIiIoViNxgiIiIiMhj2gtENW9aJiIiIiBSKLetEREREZDBGbFrXCVvWiYiIiIgUipV1IiIiIiKFYjcYIiIiIjIY9oLRDVvWM2Hbls1o0awR3KpVRmev9rh29YrckbSsXrkc33XqCI+a1dGonjtGDhuCZ0+fyB0rVUovSwAIevMGP/qMQ+O6teFRsxq6erXDvbt3ZMuzad1K9O/ZCc0b1ESbr+rBd8ww+D9/qrWPJElYu2IJ2rdsiKZ1XTF84Pd4+u/jHM1VvWQ+LOxSBYdHe+LGlMZoWMEuxT6l7XJhQZcqOONdH+d86mND3xooZG2u2V7MxhLzOlXG8bF1cdanPmZ5OSO/lVmO5k6NCK9LQNk5d/++Bh0au2LNkjmadYtmTkaHxq5ai/fQnjKm/I+SyzKZCBkBZecU6d9HQNllSfJhZT0Dhw4ewKwZfujXfxC27dyL6tVdMXhAPwS8fi13NI1rVy6jU5eu2PD7NixbsQbqxEQM6t8XMdHRckfTIkJZvnsXgT49u8LExAQLl67Ajj37MWL0OOTJk0e2TDevXUE7ry5Ytvp3zF20Amp1Isb80B8xMf/d3y0b1mD7lg0YMXYClq/bivy2dhj9Qz9ER0XlWC5LU2M8fBOJGQcepLq9mI0l1vaugWch0ei77iq+/e0frDz1FHGJSQAAC1MjLOteFRKA/uuv4fvVV2BqbIRfu1YxaKuLCK9LQNk5H9+/gyN/7UHJMuVSbKvm5o5VO/7WLL6//CpDQm1KLstkImQElJ9TlH8fAeWXJclHJUmSJHeInBCbqJ/zfNfZCxWdnDBx0k+adW1btUDDRk0wfOTobJ8/KQeKPywsDI3ruWPVuo1wreGW7fPpa9R2Tpdlgjop2+dYtGAubl6/jlXrN2X7XKmJilVn+xxvw8PQ5qt6+PW3dXCpXgOSJKF9y4bw6twdXXv2AQDEx8ejXfP6GDB0JFq3/1bnazSff1qn/W9MaYyRW2/ixP0QzboZHZ2RqE7CxD13Uz2mTtn8WPxdVdSbeQpRcR/KJY+FCc5418eADdfwz5PwdK95cWJjnTKmJadfl/qSkzkfB0Zm+diYmGiMHfAd+g33xq7Nq1GqrCN6DxkD4EPLelTke3hPm5etfMkcCuXWy3lEuOciZARyNueX9O8jkLNlaaGwTs9fLf1H7ggafw+uJXeEDLFlPR0J8fG4d/cO6rh7aq2v4+6Bmzeuy5QqY5GR7wEA1tbWMif5jyhlefrkCVSsVAnjR49A0/oe6Ppte+zZuV3uWFoiIz9UrPL8//0NeP0SYaEhqFHbXbOPmZkZXKrXwO3/3ZAjIlQqoG45WzwPjcbSblVxfGxdbOxbQ6urjKmxESRIiE/870NWfGIS1EkSqpXIZ5CcorwulZxz1cIZcK3tCRfX1P/Bu3PzKnp1aIKhPdph2dxpiAgPM3BCbUouy2QiZATEyfkxJf77CIhZlmQ4rKynI/xtONRqNWxtbbXW29raISQkWKZU6ZMkCXNnzUC16q5wKOcodxwNUcry1csX2LV9K0qUKIlFv61EB69OmDPzF+zft1fuaAA+3N8lC2ahskt1lCn7octBWOiH1uz8+bXL1ia/rWaboeW3MoOVuQl6e5bC+cehGLTxOo7fD8bcTlXgWjIfAODWywjExCdhRFMHWJgawcLUCCObOcDYSAW73ObpX0BPRHldKjXn2eN/48nj+/iu79BUt1ev6YERE37GT3N+Q8+BI/H4wV1MHjMQCfHxBk76H6WW5cdEyAiIkzOZUv99BMQrSzIs2Svr169fx9On/w2W27RpEzw8PFC8eHF4enpi69atGZ4jLi4O796901ri4uL0llH1yddckiSlWKcUM6ZPw6OHD+A3a67cUVKl9LJMSpJQoaIThgwfiQoVndDBqxPadvDCru0Zvw4NYcHs6Xjy+CEm/TwrxTYlla3R/1/25INgbLr4Ag8CI7H27HOcfhiCjjWKAgDCoxMwbsct1HO0w/kJDXDWpz5ym5vg7ut3OfL1d3qUVHbpUVLOkKBArFkyB8N9foaZWeofrjwaNoNr7booUdoBbu71MNHvVwS8fI6r/5w1cNqUlFSWaREhIyBOTqX/+wiIU5bZZaRSzpIVS5cuRenSpWFhYQFXV1ecOXMm3f3j4uLg6+uLkiVLwtzcHGXLlsWaNWsyX15Zi6k/ffr0wbNnzwAAq1atQv/+/VGjRg34+vrCzc0N/fr1y/AJ+fn5wdraWmuZPdMv29ls8tnA2NgYISHarZNhYaGwtU0584XcZvwyDadOHMfKNRtgX6iQ3HG0iFKWdgXsULpMWa11pUuXQWBggEyJ/rNg9i84d/oEFixdg4L2/93f/P9ffqGftKK/DQ+DzSet7YYSHp2ABHUS/g3WHuD6NDgKha0tNI8v/BuGVr9eQKPZZ9Bw1hlM3HMXBfOa41V4jEFyivK6VGLOfx/eQ8TbMIwd2A1eTWvCq2lN3Ll5FQf2bIVX05pQq1OOz7CxLQA7+8IIeOkvQ+L/z6DAsvyUCBkBcXICyv73ERCrLL9027Ztw4gRI+Dr64vr16+jbt26aNGiBfz9035f+/bbb3Hs2DGsXr0aDx48wJYtW1ChQoVMX1P2yvqDBw9QtuyHytHSpUuxYMECLFy4EAMHDsT8+fOxfPlyzJ2b/qdgHx8fREREaC1jx/tkO5upmRkqOlXCxfPntNZfPH8eLlWrZfv8+iJJEmZMn4rjR49g+Zp1KFqsmNyRUhClLF2qVsfz///wmOz582coXLiIPIHw4f4umD0dZ04exYKla1C4qPb9LVykGPLb2uHKPxc06xISEnDz2hU4V6lq4LQfJKol3H39DqVsc2mtL2mbCwERsSn2fxudgPexiXArbYP8VmY4+cAw3XdEeV0qMWeV6jUxf9U2zF3xu2YpW94JdRu3wNwVv8PY2DjFMe8j3iI06A1sZKx8KLEsPyVCRkCMnCL8+wiIUZb6pFKpFLPoat68eejTpw/69u2LihUrYsGCBShevDiWLVuW6v6HDh3CqVOncODAATRp0gSlSpVCzZo14e7unur+qZF9fLClpSWCg4NRokQJvHr1CrVqaQ9SqlWrllY3mdSYm5vD3Fz7a1h9zQbTvWcv+HqPg5OzM1xcqmHXjm0ICAiAV6fO+rmAHvj9PBUHD+zH/F+XwMrKStO/LXfuPLCwsMjgaMMRoSy7du+J3j26Ys3K5Wj6VXPcuXULe3bugO/knzI+OIfMn/Uzjv19ANPn/ArLXFYI/f+Wl9y5c8PcwgIqlQpenbtj87qVKFa8BIqVKIlNa1fC3MICTb76OsdyWZoZo0R+S83jovksUb5QbkTEJCAwIg7rzvljlpczrj1/i8vPwuHuYIt65e3Qd901zTFtqhbGk5AohEcloEpxa4xr7ohNF/zxPNRw06qJ8LoElJfTMpcVSpR20FpnYWGJPHmtUaK0A2JiorF9/XLUrtsYNrZ2CAp8jd9XL0Ee63yo5dlQlszJlFaWqREhI6D8nKL8+wgovyw/V3FxcSm6TqdWrwQ+zLR29epVeHt7a61v1qwZzp8/n+r59+3bhxo1amDWrFnYuHEjrKys0Lp1a0ybNg2WlpapHvMp2SvrLVq0wLJly7Bq1SrUr18fO3fuhIuLi2b79u3b4eDgkM4ZclbzFi0R8TYcK5YtRXBwEBzKOWLJbytQpEhR2TJ9ase2LQCAfr16aK3/6edf0LptezkipUqEsqzkXBlz5v+KxQvnY9XypShStBhGj/NGi69byZbpj13bAADDB/bSWu896We0+KYtAKBLj96Ii4vF/Fk/I/L9O1SsVAVzFq1ALiurHMtVqUgerPreVfN4TPMPA7b23XiNSXvv4cT9YPy8/z76eJbCuBaOeB4ajTHbbuGGf4TmmJJ2ufBDk7KwtjTF67exWHXmKTZdeJFjmVMjwusSECdnMiMjIzx/+hgnj/yF6Mj3yJffDs5Va2DUj36wzJVzr8vMEKEsRcgIKD+nKP8+Asovy8+Vn58ffvpJu0Fu8uTJmDJlSop9Q0JCoFarYW9vr7Xe3t4egYGBqZ7/yZMnOHv2LCwsLLBnzx6EhIRg8ODBCAsLy3S/ddnnWX/9+jU8PDxQokQJ1KhRA8uWLYOrqysqVqyIBw8e4OLFi9izZw9atmyp03n11bKe0ww9kC4r9DmPbE7SxzzrOU0f86wbgq7zrMtBX/OsU/bmWTckfc2zTmLgv4/6o7R51r9efknuCBq7v3fJdMv669evUbRoUZw/fx516tTRrJ8+fTo2btyI+/fvpzimWbNmOHPmDAIDAzVThu7evRsdO3ZEVFRUplrXZe+zXqRIEVy/fh116tTBoUOHIEkSLl26hMOHD6NYsWI4d+6czhV1IiIiIqKMmJubI2/evFpLahV1ALCzs4OxsXGKVvSgoKAUre3JChcujKJFi2rN7V+xYkVIkoSXL19mKqPslXUAyJcvH2bMmIE7d+4gJiYGcXFxePbsGTZv3owaNWrIHY+IiIiIvnBmZmZwdXXFkSNHtNYfOXIkzQGjHh4eeP36teYHDQHg4cOHMDIyQrFMDnhWRGWdiIiIiL4MKgX9p6tRo0Zh1apVWLNmDe7du4eRI0fC398fAwcOBPBhhsIePf4bI9G1a1fY2tqiV69euHv3Lk6fPo2xY8eid+/e4gwwJSIiIiISQadOnRAaGoqpU6ciICAAzs7OOHDgAEqWLAkACAgI0JpzPXfu3Dhy5Ah++OEH1KhRA7a2tvj222/x888/Z/qasg8wzSkcYKo/ogyg4QBT/eEA0y8LB5iSEvHfR/1R2gDT1isuyx1BY19/N7kjZIjdYIiIiIiIFIqVdSIiIiIihVLYFyNERERE9DlTCdJ9SCnYsk5EREREpFCsrBMRERERKRS7wRARERGRwbAXjG7Ysk5EREREpFCsrBMRERERKRS7wRARERGRwYjyY1JKwZZ1IiIiIiKFYss6ERERERkMG9Z1w5Z1IiIiIiKFYmWdiIiIiEih2A2GiIiIiAxGxX4wOmHLOhERERGRQrFlXW6S3AEy9i42Qe4ImZLX0lTuCBnKm0uM1oSLExvLHSFDNq3myx0hU8L/HCl3hAw5FMotdwSiFDi9H9EHrKwTERERkcHwc5hu2A2GiIiIiEihWFknIiIiIlIodoMhIiIiIoPheATdsGWdiIiIiEih2LJORERERAbDdnXdsGWdiIiIiEihWFknIiIiIlKoTHWD8ff31+mkJUqUyFIYIiIiIvq8qTjAVCeZqqyXKlVKp4JVq9VZDkRERERERB9kqrK+Zs0afgoiIiIiIjKwTFXWv//++xyOQURERERfAiO2/+okWwNMY2Ji8OrVKyQmJuorDxERERER/b8sVdZPnDiBOnXqIE+ePChZsiT+97//AQCGDBmC3bt36zUgEREREdGXSufK+vHjx9GsWTPExsZizJgxSEpK0myzs7PDunXr9JmPiIiIiD4jKpVKMYsIdK6sT5o0CS1btsT169fx888/a21zcXHBjRs39JWNiIiIiOiLlqkBph+7fv06duzYASDlPJkFChRAUFCQfpIRERER0WdHkAZtxdC5Zd3ExAQJCQmpbgsKCkKePHmyHYqIiIiIiLJQWXdzc8PGjRtT3bZz507UqVMn26GUZtuWzWjRrBHcqlVGZ6/2uHb1ityRtGzftgXftm8Nz9qu8Kztih7fdcLZM6fljoUb165g/MghaNu8IerWcMbpk8e0ttet4Zzq8vuGNTIl/o+S7/nqlcvxXaeO8KhZHY3quWPksCF49vSJ3LHSJGdZjvnWDWcXdkHQriF4vmUAtv/YCuWK2mjt08bdAft+bocXWwci5uBIVClTQGu7TW5zzBvUADdX9kTonqF4uL4P5g5sgLy5zAz2PJIp+XWZTISMgBg5RcgIiJFThIyAODnJsHSurHt7e2PPnj1o164d9u3bB5VKhX/++QdDhw7Fzp07MW7cuJzIKZtDBw9g1gw/9Os/CNt27kX16q4YPKAfAl6/ljuahr29PX4YMRqbt+7E5q07UbNWbYwcNgT/Pn4ka67YmBg4lCuPkeMmpLp976GTWov3pGlQqVRo0KipgZNqU/o9v3blMjp16YoNv2/DshVroE5MxKD+fRETHS13tBTkLsu6lYvhtz9vov7Irfhmwi4YGxth//T2yGX+Xw/AXBamuHD3NX5cezbVcxS2zY3C+XPDZ9UZ1Bi8Ef3mHUZT11L4bWQzgzyHZHKXZWaIkBEQI6cIGQExcoqQERAnpz7IPahUtAGmKkmSJF0P2rRpE0aMGIGwsDDNunz58mHRokX47rvv9Bowq2L1NPX7d529UNHJCRMn/aRZ17ZVCzRs1ATDR47O9vmTknQu/kyp71ELI0aPRbv2HbN9rsi47Bdm3RrOmD5nIeo1aJzmPj6jhyE6OgoLl63O0jXyWppmNZ6WnLznSbr/uWUoLCwMjeu5Y9W6jXCt4aaXcxrp6Q0sJ8vSptV8nY+xs7bEi60D0WTsdpy7/UprW4mCefFgfR/UGrIJ/3sSnO552nuWw5pxzWHbdjHUGfwNh/85Uuecqcnp9yJ9ECEjIEZOETICYuQUISOQszktdB6hmLN6/P4/uSNobOhaRe4IGcrSPOvdunXDixcvcPjwYWzatAmHDh3CixcvFFNR15eE+Hjcu3sHddw9tdbXcffAzRvXZUqVPrVajUMH/0JMTDSquFSVO06mhYWG4MLZ0/imTXtZc4h4zyMj3wMArK2tZU6iTYllmdx1Jfx9bPbOY2WOd9HxGVbU9UWJZfkpETICYuQUISMgRk4RMgLi5CR5ZPmzlqWlJZo0aZLtAD/88AO+/fZb1K1bN9vn0rfwt+FQq9WwtbXVWm9ra4eQkPRb3gzt0cMH6NmtC+Lj42CZKxfmLliMsmUd5I6VaQf370Muq1yo1zD7r6nsEOmeA4AkSZg7awaqVXeFQzlHueNoUWJZzuxfH+duv8Ld56FZPkf+PBbw6VILqw/c0mOy9CmxLD8lQkZAjJwiZATEyClCRkCcnPpiJEbvE8XIUmX93bt3WLJkCU6cOIHQ0FDY2tqiYcOGGDRoEPLly6fTuZYsWYKlS5eibNmy6NOnD3r27IlChQrpdI64uDjExcVprZOMzWFubq7TedLyaZ8mSZIU18+pVOnS2LpzD96/f4djRw5j0kRvrFq7UZgK+4F9e9C0+Td6u2fZJcI9B4AZ06fh0cMHWLvhd7mjpEkpZTl/cENULm2HxmO2Z/kceXKZYc/UtrjnH4rpmy/qMV3mKKUs0yNCRkCMnCJkBMTIKUJGQJycZFg6d4N5+vQpqlSpAl9fXzx69AhmZmZ49OgRfH194eLigidPdJ+V4vDhw2jZsiXmzJmDEiVKoE2bNti/f7/Wr6Omx8/PD9bW1lrL7Jl+Ouf4lE0+GxgbGyMkJERrfVhYKGxt7bJ9fn0yNTVDiRIlUalSZQwbMRqOjhWwZdMGuWNlys3rV+H//ClatZW3Cwwg1j2f8cs0nDpxHCvXbIC9jh9wDUFJZTlvUAN8U7ssvhq/E69CIrN0jtyWptg3rR0iYxLQadqfSFRn7v1JH5RUlmkRISMgRk4RMgJi5BQhIyBOTn2Re1CpaANMda6sDx8+HLGxsTh37hyePn2KCxcu4OnTpzh79izi4uIwYsQInUNUrlwZCxYswOvXr7Fp0ybExcWhbdu2KF68OHx9ffH48eN0j/fx8UFERITWMna8j845PmVqZoaKTpVw8fw5rfUXz5+HS9Vq2T5/zpIQHx8vd4hM2f/HbpSv6AQHxwpyRxHinkuShBnTp+L40SNYvmYdihYrJnekVCmlLOcPaog27uXQ3Hsnnr95l6Vz5Mllhv3T2yM+UY2OP/2BuAS1nlOmTyllmR4RMgJi5BQhIyBGThEyAuLkJHno3A3m+PHjWLhwYYr51N3d3fHzzz9nqbKezNTUFN9++y2+/fZb+Pv7Y82aNVi3bh1mzJgBtTrtfxzNzVN2edHXbDDde/aCr/c4ODk7w8WlGnbt2IaAgAB4deqsnwvowaKF8+DhWQ+FChVCVFQU/j50AFcuX8KSZStlzRUdHY1XL/w1jwNevcKjB/eR19oa9oUKAwCiIiNx8uhhDBkxRq6YKSj9nvv9PBUHD+zH/F+XwMrKStOfMXfuPLCwsJA5nTa5y3LBkEbo1KA8vKbuQ2RMPOxtcgEAIqLiEBv/4T3FJrc5ihfMi8K2VgAAx2If5mF/Ex6FN+HRyG1piv3T28PS3AS9Zh9C3lxmmoGqwRExOTaj06fkLsvMECEjIEZOETICYuQUISMgTk4yPJ0r6+bm5ihevHiq20qUKKG3PsclSpTAlClTMHnyZBw9elQv58yK5i1aIuJtOFYsW4rg4CA4lHPEkt9WoEiRorJl+lRoaCgmThiHkOBg5M6TB+XKlceSZStR291D1lwP7t7GsIG9NY8Xz58FAGj+TRv4TpkOADh2+CAkSUKT5i1lyZgapd/zHdu2AAD69eqhtf6nn39BawV0JfqY3GU54BsXAMCRWd9qre83929sOnoXAPB17bJYOforzbaNPl8DAH7edAHTN19ENQd71Kzw4cPl3TW9tc5Tvudq+AdlrbVeV3KXZWaIkBEQI6cIGQExcoqQERAnpz6I0flEOXSeZ713794wNjbGypUpW2379euH+Ph4rF+/PtPnK126NK5cuZJiBHR26atlPacZqlUuO/Qxz7oh6Gue9ZyUE/Os5wR9zbOek7Iyz7oc9DXPOhFRViltnvXeWw03m1ZG1nSuLHeEDGXq9l27dk3z/127dkWfPn3g5eWFrl27olChQggMDMTmzZtx5coVrF6t2w/aPH36VLfERERERERfiExV1mvUqKE1YlaSJLx48QK7d+/WWgcAzZo1S7d/ORERERF9uUT49lZJMlVZX7t2bU7nICIiIiKiT2Sqst6zZ8+czkFERERERJ9Q2JADIiIiIvqcsReMbrJUWQ8LC8Pvv/+Oe/fuISYmRmubSqXSeZApERERERGlpHNl3d/fH25uboiOjkZ0dDTs7OwQFhYGtVoNGxsbWFtb50ROIiIiIvoMqNi0rhMjXQ/w9vZGpUqV8ObNG0iShIMHDyIqKgqLFi2ChYUF/vrrr5zISURERET0xdG5sn7hwgUMGjRI87PmkiTBzMwMQ4YMQZ8+fTB27Fi9hyQiIiIi+hLpXFl/8+YNChcuDCMjIxgbG+Pdu/9+art+/fo4e/asXgMSERER0edDpVLOIgKdK+v29vYICwsDAJQqVQpXrlzRbHv27BlMTDjBDBERERGRPuhcs65duzauX7+O1q1bo3379pg6dSri4uJgZmaG2bNno1GjRjmRk4iIiIjoi6NzZX3MmDF49uwZAGDSpEm4d+8eJk+eDEmSUK9ePSxYsEDPEYmIiIjoc2EkSv8ThdC5su7q6gpXV1cAgJWVFfbt24d3795BpVIhT548eg9IRERERPSl0rnPemry5s2LPHny4PTp0+wGQ0RERESkJ3odDRocHIxTp07p85RERERE9BlhLxjd6KVlnYiIiIiI9I/zLBIRERGRwajYtK4TtqwTERERESkUK+tERERERAqVqW4wVapUydTJ3r17l60wXyIjI+V/FZTX0lTuCJ8Nzi2rP+F/jpQ7QqbYdV0nd4QMhfz+vdwRMiUwIlbuCBmytTKTO0KGTE3YTkfy4itQN5mqrOfPnz9T/YtsbW1RunTpbIciIiIiIqJMVtZPnjyZwzGIiIiIiOhTnA2GiIiIiAyGs8Hoht2GiIiIiIgUii3rRERERGQwAsytoShsWSciIiIiUihW1omIiIiIFIrdYIiIiIjIYNgNRjdZrqzfv38fp06dQkhICPr06YNChQrh9evXsLGxgaWlpT4zEhERERF9kXSurKvVavTv3x/r1q2DJElQqVRo0aIFChUqhAEDBqBatWqYOnVqTmQlIiIiIvqi6Nxnffr06fj9998xe/Zs3L59G5Ikaba1aNEChw4d0mtAIiIiIvp8qFQqxSwi0Lllfd26dfjxxx8xatQoqNVqrW2lS5fG06dP9RaOiIiIiOhLpnPL+qtXr1CnTp1Ut1lYWOD9+/fZDkVERERERFmorBcsWBBPnjxJdduDBw9QrFixbIciIiIios+TkUo5iwh0rqy3bNkS06dPx6tXrzTrVCoVIiIi8Ouvv6JVq1Z6DUhERERE9KXSubI+depUJCYmwsnJCR06dIBKpcKECRPg7OyM2NhY/PjjjzmRk4iIiIg+AyqVchYR6FxZt7e3x+XLl9GlSxdcvXoVxsbGuHnzJlq0aIHz588jf/78OZGTiIiIiOiLk6UfRbK3t8dvv/2m7yxERERERPQRnVvWv0TbtmxGi2aN4FatMjp7tce1q1fkjpQqEXKKkBEQI6cIGQExcsqd0aOiPbaPb4xHv32LyO3f4xu3Elrbfxvsicjt32stx3/+WrPdxsoMc3rVwrUF7RC0sRvuLe2I2b1qIq+lqUGfByB/WX5s64bV+KF3V7RtUgfftmyAKeNH4MXzZ1r7nD15FBNGDIRXi/r4yt0F/z68L0/Yjyxfthg1XCpqLV81qit3rDQp6Z6nRYSMgDg5s8tIpVLMIgKdK+u9e/dOd+nTp09O5JTNoYMHMGuGH/r1H4RtO/eienVXDB7QDwGvX8sdTYsIOUXICIiRU4SMgBg5lZAxl7kJbj8Lw+g1F9Pc5/D1lyjTb5tm6eB3RLOtcP5cKJzfEr4bL6PWmD8wcMlZNHEpiqWDPAwRX0MJZfmx/12/glYdOmHBio3wW7gcanUiJowYiNiYaM0+sTExcKpSFb0HDZclY1rKlHXAoWOnNcvWnX/IHSlVSrvnqREhIyBOTjI8lfTxT5BmQqlSpVL84lNoaCgiIyORL18+5MuXL82pHQ0pNlE/5/musxcqOjlh4qSfNOvatmqBho2aYPjI0fq5iB6IkFOEjIAYOUXICIiRM6cz2nVdp9P+kdu/R+fZx7H/sr9m3W+DPWFtZYYus49n+jztapfEqh/qoWD3TVAnpf82H/L79zplTEtOl2VgRGy2jn8bHoZOXzfEnCVrULmaq/a5A16hZ4eWWLpuG8o6VsjyNWytzLKVEfjQsn7qxDH8vn1Pts+VGlMT/X2pzr9x/cnJnBZZ6vScc7wPPJQ7gsaMlo5yR8iQzn+xz549w9OnT7WWd+/e4ejRoyhYsCD++EOZn/6zIiE+Hvfu3kEdd0+t9XXcPXDzxnWZUqUkQk4RMgJi5BQhIyBGThEyJqvrVAhPV3bC9QXtsGiAOwrktUh3/7y5zPA+JiHDirq+iFCWUVGRAIA8efPKnCRj/s+fo3mTemjdogl8xo3Cy5cv5I6Uggj3XISMgDg59cVIQYsI9JazUaNGGDp0KIYP1/2rxEWLFqFnz57Yvn07AGDjxo1wcnJChQoVMGHCBCQm6qmZXEfhb8OhVqtha2urtd7W1g4hIcGyZEqNCDlFyAiIkVOEjIAYOUXICABHrr9En19P4+upf2PCxstwLWuHvyZ9BbM0Wkjz5zbH+A4uWHPkgcEyKr0sJUnCil/noJJLNZQqW07uOOlyrlwFP02fgcXLVsF38lSEhoagT4+uePs2XO5oWpR+zwExMgLi5CR56PWLEScnJ3h7e+t0zLRp0zB79mw0a9YMw4cPx9OnTzF79myMHDkSRkZGmD9/PkxNTfHTTz+leY64uDjExcVprZOMzWFubp6l5/GpT7v9SJKUYp0SiJBThIyAGDlFyAiIkVPpGXddeKb5/7sv3uLav6G4t7Qjmlcvhn2X/LX2zWNpip3eTXD/5Vv8svOGYYNCuWW5ZK4fnj5+hLm/rZM7SoY8POtp/t+hnCOqVKmKtt98hf37/kC3Ht/LFywNSr3nHxMhIyBOTjIsvVbWT506BTs7O52OWbduHdatW4f27dvj5s2bcHV1xfr16/Hdd98BACpUqIBx48alW1n38/NLsd33x8mYOGmKzs/hYzb5bGBsbIyQkBCt9WFhobC11e155iQRcoqQERAjpwgZATFyipAxNW/exsA/OAplC2t358htYYI9E5oiKjYBXeacQKLaMF1gAGWX5ZJ5frhw9iTmLl2DAgXtZc2SFZa5cqFsuXJ44f9M7ihalHzPk4mQERAnp77w84dusvQLpp8uvr6+aNWqFaZPn44uXbrodL6AgADUqFEDAODi4gIjIyNUrVpVs7169ep4ncFIaB8fH0RERGgtY8f76PrUUjA1M0NFp0q4eP6c1vqL58/DpWq1bJ9fX0TIKUJGQIycImQExMgpQsbU5M9tjmK2VggMj9Gsy2Npij8mNkNCYhK+nXUMcQlqg2ZSYllKkoTFc3/BuZPHMGvRShQqUkyWHNkVHx+PZ0+ewM6ugNxRtCjxnn9KhIyAODlJHjq3rE+ZMiXFOnNzc5QqVQpTp07F2LFjdTpfoUKFcPfuXZQoUQKPHj2CWq3G3bt3UalSJQDAnTt3ULBgwXTPYW6essuLvmaD6d6zF3y9x8HJ2RkuLtWwa8c2BAQEwKtTZ/1cQE9EyClCRkCMnCJkBMTIqYSMVuYmKFPov1bykgVzo3LJ/AiPjEN4ZBwmfFsVf1x8jsC3MShZIDcmd6mO0Pex+PPScwAfWtT/8G2GXObG6LvoBPJYmiGP5YdzhbyLRZJuk35lmRLK8mOL5/yCE0cOYsrMBbDMZYWw0A+tlla5c8Pc/MMA3XfvIhAcGIDQ/+8XnNx6bWNrh/wytWgumDsLdes3QKFCRRAeForVK39DVFQkvmndVpY86VHaPU+NCBkBcXLqgyjzmyuFzpX1pKQkvQbo2rUrevTogTZt2uDYsWMYP348xowZg9DQUKhUKkyfPh0dO3bU6zV10bxFS0S8DceKZUsRHBwEh3KOWPLbChQpUlS2TKkRIacIGQExcoqQERAjpxIyVi9rh4NTmmsez+xZEwCw6eRjjFh5AZWK26BrvbKwtjJDYHgMTt8JRM8FJxH5/60S1crYoabjh1bXW4s6aJ3bachO+AdHGuR5KKEsP7Z/z4dJC8YO0f79j9G+U9Hs6zYAgItnTmLu9EmabX6TxgMAuvUeiO59Bxkm6CfevAmEr/cYvA1/CxsbGzhXccHajVtRWEF/N8mUds9TI0JGQJycZHg6zbMeExODPn36YPDgwfD09Mz4gExQq9WYMWMGLl68CE9PT4wfPx5bt27FuHHjEB0djVatWmHx4sWwsrLS6bz6alknIsoOXedZl4O+5lnPadmdZ90Q9DHPek7T5zzrJAalzbP+46FHckfQmNZc2bNDAVn4USQrKyscPHgQ9erVy3hnGbGyTkRKwMq6/rCyrh+srH95lFZZn/S3cirrU79SfmVd57/YqlWr4vbt2zmRhYiIiIiIPqJzZX3GjBmYNWsWTp06lRN5iIiIiIjo/2Xqi5HTp0+jevXqyJ07NwYPHozIyEg0atQINjY2KFy4sNaE/SqVCjdv3syxwEREREQkLiNOBqOTTFXWGzZsiAsXLqBmzZqwtbXV+YePiIiIiIhId5mqrH88BvXkyZM5lYWIiIiIiD6isPHBRERERPQ5448i6SbTA0xVLFgiIiIiIoPKdMt6w4YNYWSUcd1epVIhIiIiW6GIiIiI6PPE9l/dZLqy3qBBAxQoUCAnsxARERER0UcyXVmfNGkSatasmZNZiIiIiIjoIxxgSkREREQGw3nWdaPzL5gSEREREZFhsLJORERERKRQmeoGk5SUlNM5iIiIiOgLoAL7weiCLetERERERArFAaZEREREZDAcYKobtqwTERERESkUK+tERERERArFbjBEREREZDDsBqMbVtYpQ0lJktwRMiUuUfmzFpkI8g716E2k3BEy5FQ0r9wRMiXk9+/ljpChhnNPyx0hU06Mrid3BDKguATlv6ebm7KDAuU8vsqIiIiIiBSKLetEREREZDAqlRjfMisFW9aJiIiIiBSKlXUiIiIiIoViNxgiIiIiMhhB5lpQDLasExEREREpFFvWiYiIiMhgOL5UN2xZJyIiIiJSKFbWiYiIiIgUit1giIiIiMhgjNgPRidsWSciIiIiUihW1omIiIiIFIrdYIiIiIjIYDjPum7Ysk5ERERElElLly5F6dKlYWFhAVdXV5w5cyZTx507dw4mJiaoWrWqTtdjZZ2IiIiIKBO2bduGESNGwNfXF9evX0fdunXRokUL+Pv7p3tcREQEevTogcaNG+t8TVbWiYiIiMhgVCrlLLqaN28e+vTpg759+6JixYpYsGABihcvjmXLlqV73IABA9C1a1fUqVNH52uysk5ERERElIH4+HhcvXoVzZo101rfrFkznD9/Ps3j1q5di3///ReTJ0/O0nU5wJSIiIiIDMYIyhlhGhcXh7i4OK115ubmMDc3T7FvSEgI1Go17O3ttdbb29sjMDAw1fM/evQI3t7eOHPmDExMslbtZst6JmzbshktmjWCW7XK6OzVHteuXpE7UqpEyQkAq1ctR7XKFTB75i+y5rh+9QpGDx+Mb5rWR+1qTjh14qjW9pW/LUandl+jQR1XNK1XG0MH9MbtWzdlSvtBYmIili5egNYtmsCjZlW0adkUK39bgqSkJFlzhYUEYfGMH9GvQxP0bOUJ74Fd8eThPc32S2ePw8/nB/Tr2ARdmrnh2b8PZEyrTZS/HTlzVi1mjdkdKmHf4Fq4ML4e6pWz1dpuk8sUE1s6Yt/gWjgxygPzvZxRzMZCa582LoWwpEsVHB3hjgvj6yG3ubHB8ie7euUyfhg8EE0aeMKlUnkcP3Y044Nkwtel7q5dvYxRwwahZdN6qFm1Ik4e176/J44dxg+D+qJpgzqoWbUiHt6/l8aZ5KGksvxS+Pn5wdraWmvx8/NL9xjVJ/1nJElKsQ4A1Go1unbtip9++gmOjo5ZzsjKegYOHTyAWTP80K//IGzbuRfVq7ti8IB+CHj9Wu5oWkTJCQB3bt/C7p3bUc6xvNxREBMTjXKO5THae2Kq20uULIXR432xecdeLF+7EYWLFMXwwf0QHhZm4KT/Wb92FXbt2IZxPhOxY89f+GHkGGxcvwbbtmySLVPk+3eYPLIvTExMMH76QsxZuR3dBoyAVe48mn3iYmPhWKkKuvQZKlvO1IjytyN3TgszIzwKisLco49T3T6zfSUUyWeJ8bvvoOe6awh8F4dfO1WBhel//8xYmBrj4pNwrL/wwiCZUxMTE43y5cvD23eSbBkyQ+77nVlKyxkbE4NyjuUxNo339JiYGLhUrYYhw0YZOFnGlFaWXwofHx9ERERoLT4+Pqnua2dnB2Nj4xSt6EFBQSla2wHg/fv3uHLlCoYOHQoTExOYmJhg6tSpuHnzJkxMTHD8+PFMZWRlPQMb169Fuw4d0L6jF8qULYtxPr4oVLgQtm/bInc0LaLkjI6OwgTvMfhx8jTkzZtX7jhw96yHgUOGo2Hjpqlu/6rFN6hZ2x1FixVHmbLlMGL0eERFRuLxI/lahW/dvIH6DRrBs14DFClaFE2afoVadTxw985t2TL9uX09bAvYY+CYyXCoUAkFChWBc7WasC9STLNP3SYt0aFbP1SuVlO2nKkR5W9H7pwXn4RjxZlnOPUwNMW24jaWqFw0L2YffoR7gZHwD4vB7MOPkMvMGE0rFtTst+3KK2z85wVuv35nkMyp8axbH0OHj0STps0y3llGct/vzFJaTnfPehg0dAQaNk79/rb8pg36DhiCmrXcDZwsY0ory5wk96DSjxdzc3PkzZtXa0mtCwwAmJmZwdXVFUeOHNFaf+TIEbi7p3xN5c2bF7du3cKNGzc0y8CBA1G+fHncuHEDtWrVylR5yV5ZDwgIwKRJk9CoUSNUrFgRzs7OaNWqFVavXg21Wi1rtoT4eNy7ewd13D211tdx98DNG9dlSpWSKDkBwG/6VNSt2wC16yjvjTIjCQnx2Lt7O3LnzoNyjhVky1G1misuX7qI58+eAgAePriPm9evwaNufdkyXb1wBmXKVcSCad4Y4NUM3oO+w7EDe2TLk1mi/O0oPaeZ8Yevf+MT/+uKlSQBCeokuBST/0O5aJR+v5OJklMELEtxjBo1CqtWrcKaNWtw7949jBw5Ev7+/hg4cCCADy31PXr0AAAYGRnB2dlZaylYsCAsLCzg7OwMKyurTF1T1gGmV65cQZMmTVC6dGlYWlri4cOH+O677xAfH48xY8Zg9erV+Pvvv5EnT56MT5YDwt+GQ61Ww9ZWu2+mra0dQkKCZcmUGlFyHjr4F+7fvYtNW3fKHUUnZ0+fxI/eoxEbGws7uwL49bdVyGdjI1uenr37IjLyPTq2/RpGxsZIUqsx+IcRaN7ia9kyBQW8wtH9u9CyQ1e06dIL/96/g/VL58LU1Az1msqXKyOi/O0oPeezsBgERMRiUP3SmHnoEWIS1OjiVgx2uc1hm9tM7njCUfr9TiZKThGwLMXRqVMnhIaGYurUqQgICICzszMOHDiAkiVLAvjQCJ3RnOu6krWyPmLECIwcOVIzlc2mTZuwePFiXLx4EeHh4WjUqBEmTpyIhQsXpnue1EbySsapj+TNiswOJJCbknMGBgZg9oxfsHTFar3dF0NxdauJDVt3I+LtW/yxewd8x43C6o1bkT+/bcYH54DDhw7g4F9/4me/2SjrUA4P7t/DvNl+KFCgIL5p3VaWTElSEso4VkTn3kMAAKUdyuPl8yc4un+XoivryZT8t/MxpeZUJ0nw2XMXE1o44vAIdyQmSbjyLBzn/5VvbMfnQKn3+1Oi5BTBl1KWRoI/pcGDB2Pw4MGpblu3bl26x06ZMgVTpkzR6XqydoO5du0aunfvrnnctWtXXLt2DW/evIGNjQ1mzZqFnTszboVNbSTv7Jnpj+TNDJt8NjA2NkZISIjW+rCwUNja2mX7/PoiQs57d+4gLCwU33XqgBpVK6FG1Uq4euUytmzeiBpVK8ne5Sk9lpa5ULxESThXcYHvlJ9hbGyMP/fski3Pr/PnoGfvvviqxddwKOeIr1u1QZduPbF29QrZMtnkt0OxEmW01hUtUQohQalPZaUUIvztAGLkfPAmEj3XXUOT+efQavFFjNxxG9aWJgiIiJU7mnBEuN+AODlFwLKk9MhaWS9YsCACAgI0j9+8eYPExETNwMNy5cohLBOzbqQ2knfs+NRH8urC1MwMFZ0q4eL5c1rrL54/D5eq1bJ9fn0RIWfN2rWxY/c+bN2xR7M4VXJGy69bYeuOPTA2NvwUblknIT4hXrarx8bGwMhI+0/X2NgYkoxTNzpWcsHrl8+11gW89IedfSGZEmWOCH87gDg5ASAqXo23MQkoZmOBCoXy4PSjlANSKX2i3G9RcoqAZUnpkbUbTNu2bTFw4EDMnj0b5ubmmDZtGurXrw9LS0sAwIMHD1C0aNEMz5Pa5PWxifrJ2L1nL/h6j4OTszNcXKph145tCAgIgFenzvq5gJ4oPaeVVW44lNOeY9TS0hLW+fKlWG9I0dFRePniv75lr1+9wsMH95A3rzWs8+XDulXLUbd+I9ja2SEiIgK7tm9B0Js3aNz0K9ky163fEGtWLkehQoVRpmw5PLh/F5s3rkPrNu1ly9SyfRdMHtEHe7esRe16TfDvgzs4fmAP+o6YoNkn8l0EQoIDER76oeUo4MWHyn0+G1vkyy9fy5HS/3aSyZ3T0tQIxWwsNY+LWFugXEErvItJxJv3cWhU3g7h0Ql48y4OZQtYYWSTsjj9KASXnoVrjslvZQpbKzPNecoWsEJ0vBpv3sXhnb7etDMQHRWl1Z/01cuXuH/vHqytrVG4SBGDZMgMue93ZiktZ3R0FF76f/ye/hIP799DXmtrFCpcBBERb/EmIADBwUEAgOfPPwzUz29nBzu7ArJkTqa0ssxJRp9h156cpJIkSZLr4pGRkejTpw92794NtVqNOnXqYNOmTShdujQA4PDhw4iIiICXl5fO59bn+/62LZuxbs1qBAcHwaGcI8aO94FrDTf9XUBPcipnUlLOvET69uqO8hUqYuz4CRnvnAlxibq3LF+9cglD+n2fYn3LVm0x3ncyJk0Yi7u3/oe3b8NhbZ0PFSs5o1e/gXCqVDlLGU300FEvKioKvy1ZiBPHjyI8LAx2BQriqxYt0W/AYJia6mcw36M3kTofc+3iGWxdswSBr16gQKEiaNmhKxq3bKfZfurwn/htztQUx3Xo1g8de/TX+XpORfU3y8iX/jfecO7pDPepVtwaS7u6pFj/161A/HzgIbxci+C7msWR38oUIZHxOHTnDdac80fiR+8ffTxKoq9nyRTnmPbXAxy4/SbDDCdG18twn4xcvvQP+vbqkWJ96zbtMO2XGdk+vz596a/LuIQsvKdfvoRB/XqmWP91q7aYPM0P+//Yg6mTU/6b03fAEPQfpPtvQJib6reDQk6VpYXCfq9+xcXnGe9kIP1rp3xPUhpZK+vJYmNjkZiYiNy5c+vvnIZppPki5FRlXd+yUlk3NH1U1g0hK5V1Q9NnZf1Ll5nKuhLoo7JO4shKZd3Q9F1ZzylKq6yv/Ec5lfV+tZRfWVfE7bOwsMh4JyIiIiKiL4wYHwmJiIiIiL5AimhZJyIiIqIvAweY6oYt60RERERECsXKOhERERGRQrEbDBEREREZDHvB6IYt60RERERECsWWdSIiIiIyGLYU64blRURERESkUKysExEREREpFLvBEBEREZHBqDjCVCdsWSciIiIiUihW1omIiIiIFIrdYIiIiIjIYNgJRjdsWSciIiIiUihW1omIiIiIFIrdYIiIiIjIYIw4G4xO2LJORERERKRQbFknIiIiIoNhu7pu2LJORERERKRQbFmnDBkZifEZ2NLMWO4Inw2nonnljvDZkCS5E2TsxOh6ckfIFJtm0+WOkKGwv33ljpAhUboLJyYlyR0hQ+Zs8yQDYGWdiIiIiAxGlA+MSsGPhERERERECsXKOhERERGRQrEbDBEREREZjIr9YHTClnUiIiIiIoViZZ2IiIiISKHYDYaIiIiIDIYtxbpheRERERERKRRb1omIiIjIYDjAVDdsWSciIiIiUihW1omIiIiIFIrdYIiIiIjIYNgJRjdsWSciIiIiUihW1omIiIiIFIrdYIiIiIjIYDgbjG7Ysk5EREREpFCsrBMRERERKRS7wRARERGRwbClWDcsr0zYtmUzWjRrBLdqldHZqz2uXb0id6RUiZBThIyAGDlFyAiIkVPpGa9euYxhQwaiaUNPVHUuj+PHjsodKU1yluWYLu44u7QXgvaPwfNdI7B9akeUK54/xX6+PeviyfZhCDs4Dn/P64aKpey0ttvbWGG1T2s83TkcIX+NxfnlfdCuXgVDPQ0AvOdZdf3qFYwdPhitmzWAe/VKOHXimNb2Vb8tQef236CRew18Vb8Ohg3sgzu3/idT2pSUVJakHIqorEdFRWHlypXo1asXWrRogZYtW6JXr15YtWoVoqKiZM126OABzJrhh379B2Hbzr2oXt0Vgwf0Q8Dr17Lm+pQIOUXICIiRU4SMgBg5RcgYExMNx/Ll4T1hktxR0iV3WdZ1KYHf/riK+kPX4Zuxv8PY2Aj7Z3VFLgtTzT6jO9fBsI61MHLR3/ActBZvwiLx16yuyG1pptlntU9rOBa3hdfEHajRdyX+OHMfG39sBxcHe4M8D4D3PKtiY2Pg4Fgeo8b7prq9RMmSGD3eFxu378GyNRtRuEhRjBjSD+HhYQZOmpLSyjInqVQqxSwiUEmSJMkZ4O7du2jatCmio6NRv3592NvbQ5IkBAUF4dSpU7CyssLhw4fh5OSk03ljE/WT77vOXqjo5ISJk37SrGvbqgUaNmqC4SNH6+cieiBCThEyAmLkFCEjIEbOnM6o73fYqs7lMW/hEjRq3ERv59TXv1c5XZY2zabrtL+ddS682DMSTUZswLn/vQAAPNkxHEt2XcLcrRcAAGamxni+awQmrjiO1fuvAwCC/xqLYQsOYsuR25pzvdwzEr4rjmP9wZvpXjPs79Qridmh73uuz/pJTt7zqLjs/UPuXr0S/Ob+ivoNG6d9jchINK1XC78uW40atWrrfA0rc/31Js7JsrRQWKfnPf8LlDuCRrsqheSOkCHZW9aHDBmCevXq4c2bN9i7dy+WL1+OFStWYO/evXjz5g3q1auHIUOGyJItIT4e9+7eQR13T631ddw9cPPGdVkypUaEnCJkBMTIKUJGQIycImQUhRLLMq+VOQAg/F0sAKBU4XwobJsbR6880ewTn6DGmZv+qF2pmGbd+Vsv0LGBE2zyWEClArwaOsHczASnbz437BNQOCXec10kJMTjj907kDt3Hjg4lpc3i+BlSTlL9s9a//zzD65cuQIzM7MU28zMzDBhwgTUrFlThmRA+NtwqNVq2Nraaq23tbVDSEiwLJlSI0JOETICYuQUISMgRk4RMopCiWU5c3ATnPufP+4++3D9QvmtAABB4drdK4PCo1DCPq/mcfdpe7Dxx3Z4/cdoJCSqER2bgE6TduLp67cGyy4CJd7zzDh3+iQm+YxBbGwsbO0KYMGylchnYyNrJlHLMqvE6HyiHLK3rNvY2ODRo0dpbn/8+DFsMvgjiouLw7t377SWuLg4vWX8tE+TJEmK7OckQk4RMgJi5BQhIyBGThEyikIpZTl/2FeoXKYgev68N8W2T7smqVTa66b0rg+bPBZoMXozPAauwa87L2Hz5PaoVLpAzoYWlFLueWZVd6uJ9Vt2Yfnazajt7okfx49GWFio3LEAiFeWZBiyV9b79euHnj17Ys6cObh58yYCAwPx5s0b3Lx5E3PmzEHv3r0xYMCAdM/h5+cHa2trrWX2TL9sZ7PJZwNjY2OEhIRorQ8LC4WtrV0aRxmeCDlFyAiIkVOEjIAYOUXIKAolleW8H5rhG3dHfDVqE16FvNesDwz70KJu//8t7MkK5LPStLaXLpIPg9q5YcDs/Th5/RluPQnCLxvO4NqDAAxoU8NwT0IASrrnurC0zIViJUrCuYoLJkyeBmNjY+zfu1vWTKKWJRmG7JX1KVOmwMfHB/PmzUO1atVQtGhRFClSBNWqVcO8efPg7e2NSZPSHw3v4+ODiIgIrWXseJ9sZzM1M0NFp0q4eP6c1vqL58/DpWq1bJ9fX0TIKUJGQIycImQExMgpQkZRKKUs5w/7Cm3qVkDz0ZvwPDBCa9uzgLcICI1EY9fSmnWmJkao61ICF++8BADkMv8wc0xSknbzuzopCUZGbOH8mFLueXZJkoT4+HhZM3wuZZlZKpVyFhHI3mcdAMaPH4/x48fj6dOnCAz8MEK4UKFCKF26dAZHfmBubg5zc3OtdfqaDaZ7z17w9R4HJ2dnuLhUw64d2xAQEACvTp31cwE9ESGnCBkBMXKKkBEQI6cIGaOjo+Dv7695/OrVS9y/fw/W1tYoXLiIjMm0yV2WC4Y3R6fGleA1cQcio+Nhb/OhBT0iKg6x8R/+UViy6xLGfueBx6/C8fhlGMZ9546Y2ARsO3YHAPDAPxSPX4Zh8aiW8PntGELfRaO1R3k0di2D9r7bDPI8AN7zrIqOjsLLF/+VW8Crl3j44B7y5rWGdb58WL9qBTzrN4StXQG8i3iL3Tu2IjjoDRo1/UqWvB9TWlmSciiisp6sdOnSKSroL168wOTJk7FmzRpZMjVv0RIRb8OxYtlSBAcHwaGcI5b8tgJFihSVJU9aRMgpQkZAjJwiZATEyClCxju3b6Nf7x6ax3Nnfejm16pNO0ybPkOuWCnIXZYD2rgCAI4s6K61vt/MP7Hp7w8/fDN36wVYmJtgwfDmsMljgcv3XuGbcVsQGfOhZTVRnYS2Plvxc79G2PmzF3JbmuHf1+HoO3Mf/v7nX4M8D4D3PKvu372Dof17aR7/Om8WAKBlqzYYO2Eynj97igP7/0DE23BYW+dDhUrOWLp6A8qUdZAl78eUVpY5yYhDTHUi+zzrGbl58yaqV68OtVqt03H6alknIsoOZb/DfiDKV8G6zrMuh5yYZ13fRLnf2Z1n3RD0Oc96TlLaPOt/3nojdwSNVpUN92NnWSX77du3b1+62588eZLudiIiIiKiz5XslfW2bdtCpVIhvQZ+TltERERE9HlgtU43ss8GU7hwYezatQtJSUmpLteuXZM7IhERERGRLGSvrLu6uqZbIc+o1Z2IiIiI6HMlezeYsWPHIioqKs3tDg4OOHHihAETEREREVFOUXE2GJ3IXlmvW7duututrKxQv359A6UhIiIiIlIO2bvBEBERERFR6mRvWSciIiKiLwdng9ENW9aJiIiIiBSKLetEREREZDBGHGCqE7asExHR/7V333FV1Y8fx99XxgUREEEZmqigiCMVXKDkTENFUXNkKmlaluUqHGnhxlna0DJX7r3yq7kizXCjZoorBw4QkaGCMi7n90c/b13vZSXez/nY+9njPh557rn3vjj3Ah8+fO6BiIhUioN1IiIiIiKV4jIYIiIiIjIbvsG0aDizTkRERESkUhysExERERGpFJfBEBEREZHZcBlM0XBmnYiIiIhIpThYJyIiIiJSKS6DISIiIiKz0fCPIhUJZ9aJiIiIiFSKM+tERM9RakaW6IQCOdlZi04olNvbR4tOKJBLryWiEwqUtKqf6IRCsdNyiPKiKsGJ9SLhzDoRERERkUpxsE5EREREpFL8HRMRERERmQ3fYFo0nFknIiIiIlIpDtaJiIiIiFSKy2CIiIiIyGw0XAVTJJxZJyIiIiJSKc6sExEREZHZ8A2mRcOZdSIiIiIileJgnYiIiIhIpbgMhoiIiIjMpgRXwRQJZ9aJiIiIiFSKg3UiIiIiIpXiMhgiIiIiMhueDaZoOLNORERERKRSHKwTEREREakUl8EQERERkdlouAqmSDizTkRERESkUhysF8La1SsR3KYlGtSrjZ7duiDmxHHRSSbJ0ClDIyBHpwyNgBydampcuXQh3g3rieDmjRDathnGfjwEcdev5rn/7MgJaN6wNtavXm7Gyryp6VgCwMkTx/HR0PfR4dVmaFyvBvZH7c1z32mTI9C4Xg2sWbnsufV8HFobByI7IGFZb1xb2BNrwluiqodDnvt/+U4g0tf3w+B2NQy2W1uWwKz+jXB90RtIXN4b60a1gkeZks+t25RF33+HXj26IrBhPbR4JQDDhryPa1evmLWhsNT2usyLLJ3PSqOiiwxUP1i/c+cOJk6cKOzxf9q5AzOmRWLgO+9h7YYt8PPzx/vvDkT87dvCmkyRoVOGRkCOThkaATk61dZ4KuY4Qrv1xLxFKzHrqwXQ6XQI//BdPHqUYbTvr7/sw7k/zsClbDkBpcbUdiwB4NGjDFSt5oOPRo/Ld7/9UXtx9szvKPucj2XTmm5YsOs8WnyyHSGTdsHSogS2jWuLklrjVakdGlREg6ouuJ2cbnTdjH6N0LGhJ96a8wte/XQHStlYYeOY1ihhxr82c+L4UfR4400sW7UO3y5YAl2ODu+98zYeZRi/VkVS4+vSFFk6yfxUP1hPSEjAhAkThD3+8h+WoHPXrujyejdU8fLCyDFj4ebuhnVrVwtrMkWGThkaATk6ZWgE5OhUW+PML79FcIdQVPbyhnc1H4z+bBLuJMTjYuw5g/3uJt7B3FlTMW7iNFhYquPtR2o7lgAQ2PQVDBo8FC1avZrnPomJdzBr2hRMmDrjuR/L0Cl7sOKXy4i9mYoz11MwaN6vqFi2FOpVcTbYz71MSXz+dmP0n3sA2Tm5Btc5lLRCWMuqGLPsGKLOxOP0tWT0/3I/alZ0Qsva7s+1/5/mfbcInUK7wNu7KnyqV8eEyZGIj7+Nc+fOmq2hMNT4ujRFlk4yP+GD9d9//z3fy4ULF4S1ZWdlIfbcWQQENjXYHhDYBKdPnRRUZUyGThkaATk6ZWgE5OiUofHhw4cAAHtHR/223NxcTI34BD1790NlL29RaQZkOJam5ObmYsK40egd1h9VvKqa/fEdSloDAFIeZuq3aTTAog9fwZxtfyD2ZqrRbepVcYG1pQX2nb6l35aQ8gjn4lLRyEfcb1kePnwAAHD8x2tVNFlel7J0FpcSGo1qLjIQPh1Tt25daDQaKIpidN2T7RpBBzMlNQU6nQ7OzoYzHs7OLkhKuiukyRQZOmVoBOTolKERkKNT7Y2KomDenJmoXcfPYCC5etliWFhaoGuPNwXWGVL7sczL8iULYWFhge5v9Bby+NPCGuK32AScu5Gq3/ZRp9rI0eVi3o5zJm/jWtoWmdk6pKZnGWxPTHsE19LmXbf+hKIomD0jEvX8/OFdtZqQBlNkeV3K0kliCB+sOzs7Y/r06WjVqpXJ68+ePYuQkJB87yMzMxOZmZkG2xQLLbRabbE0Pv3DgsgfIPIjQ6cMjYAcnTI0AnJ0qrVx7swp+PPyRXy14Af9tguxZ7FhzQp8v3ydKhqfptZjacr5c2exdvVy/LBqo5DGz99ujFoVndD60x36bXWrOOP99jUQOHJbke9Po4HJiS9ziJwyERcvXsTSZauEPH5BZHldytJJ5iV8sO7v74/bt2/D09PT5PWpqakFfvGJjIw0Wtc+9tMIjPts/DO1OZV2goWFBZKSkgy2Jyffg7OzyzPdd3GSoVOGRkCOThkaATk61dw4d+ZU/HbgF3z53VKUc3XTb//9VAxSU5LRvWMb/bZcnQ7z587ChjUrsHbrLhG5qj6WeTl18gRSkpMR2u7vySKdTocvP5+BNSuXYcuOvM8c86xm9W+E9vUrok3EDtxO/vsNmU2qu6Ksgy0uzO+u32ZpUQKRYQ0wuH0N1Bi8AXdSH0FrZYHSdtYGs+tlHWxx+ELic2vOy7Spk7A/6mcs/mEFXN3cCr6BGcnyupSls7jwx4+iEb5m/d1330WlSpXyvL5ixYpYsmRJvvcxZswYpKWlGVzCR4155jYra2v41qiJw9G/GWw/HB2NOnXrPfP9FxcZOmVoBOTolKERkKNTjY2KomDOzCn49Zd9+GLeIriXr2BwfZvgECxatRELV6zXX1zKlkOP3m9h5pffCmkG1HksCxLcviNWrNuCZWs26S9ly5bDm337Y+6875/b485+uzE6NfJEuwk/4XriQ4PrVh/4E40+3oKA8K36y+3kdMzZ9gc6TdkNADh5JQlZOTq0fNlDfzu30raoUbE0jphxsK4oCiKnTMS+vbuxYPEPKF/hJbM9dmHJ8rqUpZPEED6z3rlz53yvd3JyQlhYWL77aLXGS14e5zxzGgCgT1g/jB09EjVq1UKdOvWwcf1axMfHo1uPnsXzAMVEhk4ZGgE5OmVoBOToVFvjnBlTsHfXDkyZNRe2Je1w7/9n2kqVKgWtjQ0cS5eGY+nSBrexsLREGWcXVPSsLKD4b2o7lgCQkZGOmzfi9P++fesWLl6IhYODI9zcPUweS2cXF3hWej7H8osBjdG9aRX0mLEPDx9nw7W0LQAgLSMLj7N0SH6YieSHhss6s3NycSflES7dvg8AuJ+RjR9+voTIvg2R/CATKQ8zMbVvA5yNS8HPZ+KfS7cpUydPwM4d2zHny3mws7PTr60uVcoeNjY2ZusoiBpfl6bI0knmJ3ywXpAbN24gIiICixcvFvL4rwW3Q1pqChbMn4e7dxPhXbUavvl2ATw8ygvpyYsMnTI0AnJ0ytAIyNGptsatG9cCAIYN6m+wfdRnkxDcIVRAUeGp7VgCQOy5sxg88C39v+fOng4AaBcSis8mTjV7zzttfQEAuya0M9j+7je/YsUvlwt9P6OWHkWOLhfLRjSHrbUlfjlzG+98cxC5ueZbs77+/08pOKBfH4PtEyZHolNoF7N1FESNr0tTZOksFlwHUyQaRdS7UQrp9OnT8PPzg06nK9LtimtmnYjoWaQ8dcYONXKysxadUCiPsor2fUCECmHP76+fFpekVf1EJxQK31dZfGxUNjV7+M9U0Ql6jb1Ki04okPCnb9u2/N/xfuWKOv90MREREREVnYZT60UifLAeGhqa53nWn+Bpi4iIiIjov0j42WDc3d2xceNG5ObmmrzExMSITiQiIiIiEkL4YN3f3z/fAXlBs+5EREREJA+NRj0XGQhfBhMeHo709PQ8r/f29kZUVJQZi4iIiIiI1EH4YD0oKCjf6+3s7NCsWTMz1RARERERqYfwwToRERER/XdIsvpENYSvWSciIiIiItM4WCciIiIiUikugyEiIiIi8+E6mCLhzDoRERERkUpxZp2IiIiIzEbDqfUi4cw6EREREZFKcbBORERERKRSXAZDRERERGaj4SqYIuHMOhERERGRSnGwTkRERESkUlwGQ0RERERmw1UwRcOZdSIiIiIileLMOhERERGZD6fWi0SjKIoiOuJ5eJwjuoCIiEh9nBp8IDqhUJKPfi06oUCynNXERmVTszHX74tO0PPzdBCdUCAugyEiIiIiUimV/axFRERERC8yDdfBFAln1omIiIiIVIqDdSIiIiIileJgnYiIiIjMRqNRz+XfmDdvHipXrgwbGxv4+/vj119/zXPfTZs24dVXX0XZsmXh4OCAgIAA7Nq1q0iPx8E6EREREVEhrF27FsOGDcPYsWNx8uRJBAUFITg4GHFxcSb3P3DgAF599VXs2LEDJ06cQIsWLRASEoKTJ08W+jF56kYiIqL/EJ66sfjw1I3/zqm4B6IT9OpWtC/S/o0aNYKfnx/mz5+v3+br64vQ0FBERkYW6j5q1qyJHj164LPPPivU/ip7+oiIiIjoRaamn3EyMzORmZlpsE2r1UKr1Rrtm5WVhRMnTmD06NEG29u0aYPo6OhCPV5ubi4ePHiAMmXKFLqRy2CIiIiI6D8pMjISjo6OBpe8ZsiTkpKg0+ng6upqsN3V1RUJCQmFerzZs2cjPT0d3bt3L3QjZ9aJiIiIyHxUNLU+ZswYjBgxwmCbqVn1f9I8tf5JURSjbaasXr0a48ePx9atW1GuXLlCN3KwTkRERET/SXkteTHFxcUFFhYWRrPoiYmJRrPtT1u7di3efvttrF+/Hq1bty5SI5fBEBEREREVwNraGv7+/tizZ4/B9j179iAwMDDP261evRpvvfUWVq1ahfbt2xf5cTmzTkRERERmo1HTOpgiGjFiBPr06YP69esjICAACxYsQFxcHAYNGgTgr2U1t27dwrJlywD8NVDv27cv5s6di8aNG+tn5W1tbeHo6Fiox+RgnYiIiIioEHr06IF79+5h4sSJiI+PR61atbBjxw54enoCAOLj4w3Ouf7dd98hJycHgwcPxuDBg/Xbw8LCsHTp0kI9Js+zTkRE9B/C86wXH55n/d/5/cZD0Ql6L79USnRCgVT29BERERHRi0yWH3LUgm8wJSIiIiJSKQ7WiYiIiIhUioP1Qli7eiWC27REg3q10bNbF8ScOC46ySQZOmVoBOTolKERkKNThkZAjk4ZGgE5OkU2NvHzwoY57+LK7il4dPJrhDR/2eD6BRN649HJrw0u+3/4yGCfXd8PNdpn2bR+ZvsYnjhx/BiGDB6EV1s0Rd1aPvh5316zNxSWDK/L4qBR0UUGqhms37x5Ew8fGr/hIDs7GwcOHBBQ9Jefdu7AjGmRGPjOe1i7YQv8/Pzx/rsDEX/7trAmU2TolKERkKNThkZAjk4ZGgE5OmVoBOToFN1oZ6vFmYu3MHzaujz32fXbWVRqPUZ/Cf1wvtE+izb+ZrDPB5NXP89skx49ykA1Hx+M/uQzsz92UYh+zkm9hA/W4+Pj0bBhQ3h6eqJ06dIICwszGLQnJyejRYsWwvqW/7AEnbt2RZfXu6GKlxdGjhkLN3c3rFtr/i84+ZGhU4ZGQI5OGRoBOTplaATk6JShEZCjU3Tj7t/OYcK87dj68+k898nKysGdew/0l5T7GUb7PHqcZbDP/YePn2e2SU2DmuGDIcPR6tU2Zn/sohD9nJuV6Ol0yabWhQ/WR48eDQsLCxw5cgQ//fQTzp07h+bNmyMlJUW/j6izS2ZnZSH23FkEBDY12B4Q2ASnT50U0mSKDJ0yNAJydMrQCMjRKUMjIEenDI2AHJ0yNAJAUP2quL4vEr9v+QzffPoGyjoZnwKvR7v6uPHzNJzYMBaRwzujVMnC/Vn3/xpZnnMSQ/ipG/fu3YvNmzejfv36AICgoCD06NEDLVu2xL59+wAAGkHn+ElJTYFOp4Ozs7PBdmdnFyQl3RXSZIoMnTI0AnJ0ytAIyNEpQyMgR6cMjYAcnTI07v7tHDbtOYm4+GRUKu+Mz97vgJ0LhiCw1wxkZf/1h07W7DiGa7fv4U7SfdT09sDED0NQu1p5dHhP/edPNzcZnnMSR/hgPS0tDU5OTvp/a7VabNiwAd26dUOLFi2wYsWKAu8jMzMTmZmZBtsUCy202uL5Cf7pHxYURRH2A0R+ZOiUoRGQo1OGRkCOThkaATk6ZWgE5OhUc+OG3TH6/z/3ZzxizsXhwo6JCA6qqV86s2RztME+l+MSEb1qFOpWr4BT52+avVkGan7Oi5NGlvUnKiF8GUyVKlXw+++/G2yztLTE+vXrUaVKFXTo0KHA+4iMjISjo6PBZeb0yGducyrtBAsLCyQlJRlsT06+B2dnl2e+/+IiQ6cMjYAcnTI0AnJ0ytAIyNEpQyMgR6cMjU9LSLqPuPhkeFcsm+c+J2NvICs7B94Vy5mxTA4yPudkPsIH68HBwViwYIHR9icD9rp16xa4Zn3MmDFIS0szuISPGvPMbVbW1vCtUROHo38z2H44Ohp16tZ75vsvLjJ0ytAIyNEpQyMgR6cMjYAcnTI0AnJ0ytD4tDKOdqjg6oT4pPt57lPDyx3WVpaIT0ozY5kcZHzOyXyEL4OZMmUKMjKM30EO/DVg37RpE27ezP/XZVqt8ZKXxznF09cnrB/Gjh6JGrVqoU6deti4fi3i4+PRrUfP4nmAYiJDpwyNgBydMjQCcnTK0AjI0SlDIyBHp+hGO1treL309yx5pfLOeLlaeaTcz0ByWjrGDWqPLftOIf5uGjw9nDHxwxDcS32Ibf+/BKZyBRf0bFcfuw6eQ1LKQ/h6uWHa8C44GXsDh05dMcvH8ERGRjri4uL0/7516ybOn4+Fo6Mj3N09zNqSH9HPuTm9gCt7nivhg3VLS0s4ODjkef3t27cxYcIELF682IxVf3stuB3SUlOwYP483L2bCO+q1fDNtwvg4VFeSE9eZOiUoRGQo1OGRkCOThkaATk6ZWgE5OgU3ehXwxO7Fw7V/3vGx10BAMu3HcaQqWtR09sDvTo0RGl7WyQk3cf+YxfRZ9RiPMz46/1j2dk5aNHQB4PfaIFSJa1xMyEVPx38A1O+24ncXPOe4e3sH39gYP+++n/PnvHXMtmQTp0xaco0s7bkR/RzTuqlUUSdF7GQTp8+DT8/P+h0uiLdrrhm1omIiF4kTg0+EJ1QKMlH1X/WGFlmiG2ET80aOnc7XXSCXg0PO9EJBRL+9G3bti3f669cMe+vy4iIiIjo+ZHkZxzVED5YDw0NhUajyfdNpC/iaYuIiIiIiAoi/Gww7u7u2LhxI3Jzc01eYmJiCr4TIiIiIpKDRkUXCQgfrPv7++c7IC9o1p2IiIiI6EUlfBlMeHg40tPzfqOBt7c3oqKizFhERERERKQOwgfrQUFB+V5vZ2eHZs2amamGiIiIiJ4njSzrT1RC+DIYIiIiIiIyjYN1IiIiIiKVEr4MhoiIiIj+O3hG7qLhzDoRERERkUpxZp2IiIiIzIYT60XDmXUiIiIiIpXiYJ2IiIiISKW4DIaIiIiIzIfrYIqEM+tERERERCrFwToRERERkUpxGQwRERERmY2G62CKhDPrREREREQqxcE6EREREZFKcRkMEREREZmNhqtgikSjKIoiOuJ5eJwjuoDIWLYuV3RCoVhZ8JduxSU7R/3PuZWlHM93Wka26IQClbLhHFhx8XhrheiEAt1Z1kd0QqGo7WV5OfGR6AQ973K2ohMKpLKnj4iIiIheZJxYLxo5plOIiIiIiP6DOFgnIiIiIlIpLoMhIiIiIvPhOpgi4cw6EREREZFKcbBORERERKRSXAZDRERERGaj4TqYIuHMOhERERGRSnGwTkRERESkUlwGQ0RERERmo+EqmCLhzDoRERERkUpxZp2IiIiIzIYT60XDmXUiIiIiIpXiYJ2IiIiISKW4DIaIiIiIzIfrYIqEM+tERERERCrFwToRERERkUpxGQwRERERmY2G62CKhDPrhbB29UoEt2mJBvVqo2e3Log5cVx0kkkydMrQCKi/M/HOHXw6ZiRaBTVGk4b10KtbZ8SeOys6yyS1H0tA/Y0hwa1Qv46v0WX61Imi04yo7VieijmO0cMHo3NwC7zSoBZ+/WWfwfUZGRn4YsYUdG3fCq2b+qN3txBs2bBGUK1pixd+B7/a1TFz+lTRKXkS0TiiYy1ETQrGzUU9cXl+N6wc0Rze7g5G+43u+jLOf9MVCUvfwPZxr6J6ecc873PDyJZIW9UH7eu/9DzT86S2zx9SB1UM1u/du4eoqCgkJycDAJKSkjB9+nRMnDgRsbGxQtt+2rkDM6ZFYuA772Hthi3w8/PH++8ORPzt20K7niZDpwyNgPo7799Pw9thvWBpaYm58xZg/ebtGPbRSNjb24tOM6L2YwnI0bhs5Xr8tO+A/vLNd4sAAK1efU1wmSE1HsvHjx7Bq5oPhoV/YvL6rz+fjqOHDmLcxEgsX7cN3d/oi7mzIvHr/p/NXGra2T/OYNOGdahazUd0Sp5ENTbxLYfv91xA6892IjRyLyxLaLB5dCuU1P69aGBYSE0MDvZF+NKjaDFuJxLTHmPLJ61RysZ4YcH7wb5QzPkBPEWNnz/Pi0ajnosMhA/Wjx49Ci8vL7Rq1Qre3t44ceIEGjZsiEWLFmH58uXw9/dHTEyMsL7lPyxB565d0eX1bqji5YWRY8bCzd0N69auFtZkigydMjQC6u/8YfFCuLq6I2LSVNSq/TI8ypdHw8YBqPBSRdFpRtR+LAE5Gp3KlIGLS1n95eCBX1DhpYrwr99AdJoBNR7Lxk2CMPC9IWjW8lWT1589cxqvte+Eev4N4e5RHh27dINXVR9cUMFvqjIy0jF29Mf4NGISHByMZ4zVQGRj1+k/Y9WBKzh/Kw1/xKXg/e+iUbFsKdStXEa/z3uvVcfsrX/gx2M3EHszFYPm/wZba0t0C6xscF+1KjphcDtfDP4u2qwfwz+p8fOH1EH4YH3s2LHo1q0b0tLS8MknnyA0NBStWrXCxYsXcenSJfTq1QuTJk0S0padlYXYc2cRENjUYHtAYBOcPnVSSJMpMnTK0AjI0Xnglyj41qyJUR8Nw6vNmqBX9y7YvGGd6CwjMhxLGRqflp2dhR3/+xEdQ7tAo6JpIRmPJQDUrlsPvx2Iwt3EO1AUBTHHj+JG3DU0DGgiOg3TpkxE06DmaBQQKDolT2pqdCxpDQBIeZgFAKhUrhTcnEri59//npnOysnFb7F30LBaWf02W2sLLPqgKcKXHkVi2mPzRv8/WT9/yDyED9ZPnDiBESNGwN7eHkOHDsXt27cxcOBA/fWDBw/GsWPHhLSlpKZAp9PB2dnZYLuzswuSku4KaTJFhk4ZGgE5Om/dvIGN69agYkVPfPXt9+jarQdmTZ+K7du2iE4zIMOxlKHxab/8vA8PHzxASMfOolMMyHgsAWDox5/As4oXurZvhZYB9RA+5F2MGDUOL9f1E9q1a+f/cP7cOXw4bITQjvyorXFKb39En7+D2JupAIByjrYAYDQAv3v/MVxL2+r/HdmnPo5euosdJ26arfVpsn7+/FsaFV1kIPxsMFlZWbC1/euTxsrKCiVLloSLi4v+emdnZ9y7dy/f+8jMzERmZqbBNsVCC61WWyyNT89eKYqiqhmtJ2TolKERUHdnbq6CGjVrYvDQ4QCA6r41cOXPy9i4bg06dAwVG2eCmo/lEzI0PrF180YENglC2XLlRKeYJNOxBIANa1bg3JnfETn7a7i5u+PUyRP4fPpkODuXRf1GAUKaEhLiMXPaVMxbsKjYvo8VN7U1znqrIWpWdMJrE3YZXff0OnQN/npdAkCwXwW8UtMNQWP+9/wjC0G2zx8yD+GD9ZdeeglXrlxBpUqVAABr1qyBu7u7/vr4+HiDwbspkZGRmDBhgsG2sZ9GYNxn45+pzam0EywsLJCUlGSwPTn5Hpyd828yJxk6ZWgE5Oh0KeuCylW8DLZVrlwFP+/dLajINBmOpQyN/xR/+xaOHjmEGZ9/KTrFiGzHEgAyHz/G9/PmYsrMuQho2gwA4FXVB5cvnseaFUuFDdZjz55FcvI9vNmjq36bTqdDzInjWLd6JQ6f+B0WFhZC2p5QU+OMsAYI9q+AdhN343Zyhn57YtojAICrow3upD7Sb3dxsNHPtr9S0w2Vy9kjbmEPg/tcPuwVRJ9PRIfJe8zwEcj5+UPmI3wZTM+ePZGYmKj/d/v27fUz7QCwbds2NGzYMN/7GDNmDNLS0gwu4aPGPHOblbU1fGvUxOHo3wy2H46ORp269Z75/ouLDJ0yNAJydNap64fr164ZbLt+/Rrc3T3EBOVBhmMpQ+M/bdu6GU5lyqBpUDPRKUZkO5YAkJOTg5ycHGg0ht8KS5SwQK6SK6gKaNi4MdZt2obV6zfrLzVq1kJw+xCsXr9Z+EBdTY0z32qAkAYVETJlD67ffWhw3bXEh0hIyUCL2n9PAFpZlEATX1ccvfjX0pIvtv2BwNHb0XTM//QXABiz/AQGf3fILB8DIOfnz7MQfQYY2c4GI3xmPSIiIt/rx44dW+AnvVZrvOTlcc4zpwEA+oT1w9jRI1GjVi3UqVMPG9evRXx8PLr16Fk8D1BMZOiUoRFQf2evPmHo37cXFn//HV5t+xrOnjmDzRvWY2zEhIJvbGZqP5aAHI0AkJubix+3bkKHkFBYWgr/0m2SGo9lRkYGbt2I0/87/vYtXLpwHg6OjnB1c0ddv/qY/+VsaG20cHXzwOmY49i1Yxs+GBYurNnOrhS8q1Yz2GZrawvH0qWNtouihsbZ/Rri9cDK6DU7Cg8fZaOcow0A4H5GNh5n6wAA8386jxGdauPPhAf4M+EBPupUC4+ycrA++iqAv9azm3pT6c176UaD/+dNjZ8/pA7q/Ir/D/fu3UNERAQWL14s5PFfC26HtNQULJg/D3fvJsK7ajV88+0CeHiUF9KTFxk6ZWgE1N9Zs1ZtzPriS3w99wss/G4ePMpXwEcjRyO4fYjoNCNqP5aAHI0AcPTwISTEx6NjaBfRKXlS47G8EPsHhg7qr//311/MAAC81r4TPhk/BRFTZmHBN3Mw6dPRuH8/DW5uHhj43hB06tojr7sklRjw6l/ndd/xWVuD7e99+xtWHbgCAJjz41nYWFtgdr+GKG2nxfE/k9A5ch8eFteMXjFS4+cPqYNGefIuC5U6ffo0/Pz8oNPpinQ7FX4eEiFbJ+5X60VhZSF8hdwLIztH/c+5laUcz3daRrbohAKZ+mM79O94vLVCdEKB7izrIzqhUNT2sryZkiU6Qa+Ck7XohAIJf/q2bduW7/VXrlwxUwkRERERkboIH6yHhoZCo9Egvwl+nraIiIiI6MXAYV3RCP/dp7u7OzZu3Ijc3FyTl5iYGNGJRERERERCCB+s+/v75zsgL2jWnYiIiIjoRSV8GUx4eDjS09PzvN7b2xtRUVFmLCIiIiKi54WrYIpG+GA9KCgo3+vt7OzQrJn6/gAIEREREdHzJnwZDBERERERmSZ8Zp2IiIiI/jt4Npii4cw6EREREZFKcbBORERERKRSXAZDRERERGaj4flgioQz60REREREKsWZdSIiIiIyH06sFwln1omIiIiIVIqDdSIiIiIileIyGCIiIiIyG66CKRrOrBMRERERqRQH60REREREKsVlMERERERkNhqugykSzqwTEREREamURlEURXTE8/A4R3QBkbH0TDlemHZa/tKNiKggTi3HCy4onEcHxotOMJD4IFt0gl45eyvRCQXid2QiIiIiMhsNzwdTJFwGQ0RERESkUpxZJyIiIiLz4cR6kXBmnYiIiIhIpThYJyIiIiJSKS6DISIiIiKz4SqYouHMOhERERGRSnGwTkRERESkUlwGQ0RERERmo+E6mCLhzDoRERERkUpxZp2IiIiIzIZ/wbRoOLNORERERKRSHKwTEREREakUl8EQERERkdnwDaZFw5l1IiIiIiKV4mCdiIiIiEilOFgnIiIiIlIpDtaJiIiIiFSKg/VCWLt6JYLbtESDerXRs1sXxJw4LjrJJBk6ZWgE5OkEgGWLv0egX03MmRkpOsUkGY6lDI2AHJ0yNAJydMrQCMjRqbZGDxd7LB7XBTd/HIl7u8fi8KJBqFfN3WAfH08XrI98Awk7RiPxpzHYP38AXirnKKiYRFLtYL1KlSq4dOmS6Az8tHMHZkyLxMB33sPaDVvg5+eP998diPjbt0WnGZChU4ZGQJ5OADh39gy2bloP76rVRKeYJMOxlKERkKNThkZAjk4ZGgE5OtXWWLqUDX7+5m1k5+gQOnIl6vX9BqO/2YXUh4/1+1T2cMK+r/vj4vUktB26FA37fYvIH/bjcVaOkObiptGo5yIDjaIoisiAL7/80uT2ESNGYOTIkXBzcwMADBkypEj3+7iYXs9v9uwG3xo1MO6zCfptoSHBaNGyNYYO/6h4HqQYyNApQyPwfDvTM4vvC21GRjr69eqGj8d8iqULv0PVaj4YFj6mWO7bTls8Z3WV4TmXoRGQo1OGRkCOThkaATk6n2ejU8vxRb7NpHdbI6DWS2j94ZI891kW8Tqyc3R4e8rmf932T48OjC+W+ykuqY90ohP0SttaiE4okPDzrA8bNgzly5eHpaVhSm5uLpYtWwYrKytoNJoiD9aLQ3ZWFmLPnUX/Ae8YbA8IbILTp06avScvMnTK0AjI0wkAs6dNRmDTV9CgUQCWLvxOdI4RGY6lDI2AHJ0yNAJydMrQCMjRqcbG9k18sPfoZayc0A1N61bC7bv3sWDLMSzZHgMA0Gg0eC2gKj5f9Ru2zeqNOlXdcT0+BTNXHMSPB88LaS5uGkgypa0SwpfBDBw4EC4uLtixYweuXr2qv1hYWGD37t24evUqrly5IqQtJTUFOp0Ozs7OBtudnV2QlHRXSJMpMnTK0AjI07ln1w5cOB+LQR8OF52SJxmOpQyNgBydMjQCcnTK0AjI0anGxsruThjYqQEu30xGx4+XY+G245g9NBi92tYBAJRzsoN9SS0+frMp9hy5jJCPlmPbr+exZnIPNK3jKaSZxBI+s/7dd99hy5YtaNu2LUaOHIkPPvigyPeRmZmJzMxMg22KhRZarbZYGjVPLWpSFMVomxrI0ClDI6DuzjsJ8ZgzcxrmzFtQbK/x50nNx/IJGRoBOTplaATk6JShEZCjU02NJUpoEHPhNiK+3wcAOH0pATUqlcM7nepj1a7TKPH/XdsPXsBX6w8DAH6/nIBGtV7CwE71cfD0dSHdJI7wmXUACA0NxaFDh7B582YEBwcjISGhSLePjIyEo6OjwWXm9Gc/M4ZTaSdYWFggKSnJYHty8j04O7s88/0XFxk6ZWgE5Og8H3sOKcn30P/N7ghq8DKCGryMkyeOYf2alQhq8DJ0OnWsBZThWMrQCMjRKUMjIEenDI2AHJ1qbEy49wCx1wxn9c9fv4uXXP8600tSWgayc3SIvW64z4V/7CM70W8qle0NpqoYrANA+fLlsXfvXrzyyiuoV68eivK+1zFjxiAtLc3gEj7q2d9oZ2VtDd8aNXE4+jeD7Yejo1Gnbr1nvv/iIkOnDI2AHJ31GzbG8nVbsHT1Rv2leo2aaBPcAUtXb4SFhTreLCPDsZShEZCjU4ZGQI5OGRoBOTrV2HjozA1Ue8lwWU7Vl5wRdycNAJCdo8OJ87eN96ngjLiENLN1knoIXwbzTxqNBmPGjEGbNm1w8OBBuLu7F3wjAFqt8ZKX4jobTJ+wfhg7eiRq1KqFOnXqYeP6tYiPj0e3Hj2L5wGKiQydMjQC6u+0s7ODl3dVg222tiXh6OhotF00tR9LQI5GQI5OGRoBOTplaATk6FRb41frDyFq3tsI7x2EjVFn0cC3PPqH+OODWT/q9/li9W9YPr4bDp6+jv0nr6FNI2+0C/RB26FLhTSTWKoarD/h7+8Pf39/AMCNGzcQERGBxYsXC2l5Lbgd0lJTsGD+PNy9mwjvqtXwzbcL4OFRXkhPXmTolKERkKdTBjIcSxkaATk6ZWgE5OiUoRGQo1NtjSfO30aPsWsx8d1W+CSsGa4lpCD8q5+wZs8Z/T7bfj2PD2dvR3jvppg9NBgX4+7hjc/WIvpMnJDm4ibJ6hPVEH6e9YKcPn0afn5+RV6HW1wz60TFqTjPs/48Fdd51omIXmROLccLLigctZ1n/cHjXNEJevY2qlkRnifh35G3bduW7/WiTttIRERERCSa8MF6aGgoNBpNvm8oVdspoIiIiIjoX+KwrkiEz/27u7tj48aNyM3NNXmJiYkRnUhEREREJITwwbq/v3++A/KCZt2JiIiISB4aFf0nA+HLYMLDw5Genp7n9d7e3oiKijJjERERERGROggfrAcFBeV7vZ2dHZo1a2amGiIiIiIi9RA+WCciIiKi/w6eN6RohK9ZJyIiIiIi0zhYJyIiIiJSKS6DISIiIiKz4SqYouHMOhERERGRSnGwTkRERESkUlwGQ0RERETmw3UwRcKZdSIiIiIileLMOhERERGZjYZT60XCmXUiIiIiokKaN28eKleuDBsbG/j7++PXX3/Nd//9+/fD398fNjY2qFKlCr799tsiPR4H60REREREhbB27VoMGzYMY8eOxcmTJxEUFITg4GDExcWZ3P/q1ato164dgoKCcPLkSXzyyScYMmQINm7cWOjH1CiKohTXB6Amj3NEFxAZS8+U44Vpp+UKOSKigji1HC+4oHAeHRgvOsGAmsZoNkX8dteoUSP4+flh/vz5+m2+vr4IDQ1FZGSk0f6jRo3Ctm3bEBsbq982aNAgnD59GocOHSrUY3JmnYiIiIioAFlZWThx4gTatGljsL1NmzaIjo42eZtDhw4Z7d+2bVscP34c2dnZhXpcTp8RERER0X9SZmYmMjMzDbZptVpotVqjfZOSkqDT6eDq6mqw3dXVFQkJCSbvPyEhweT+OTk5SEpKgru7e8GRChXK48ePlYiICOXx48eiU/IkQ6OiyNEpQ6OiyNEpQ6OiyNEpQ6OiyNEpQ6OiyNEpQ6OiyNEpQ+OLJiIiQgFgcImIiDC5761btxQASnR0tMH2yZMnKz4+PiZvU7VqVWXq1KkG2w4ePKgAUOLj4wvV+MKuWS9u9+/fh6OjI9LS0uDg4CA6xyQZGgE5OmVoBOTolKERkKNThkZAjk4ZGgE5OmVoBOTolKHxRVOUmfWsrCyULFkS69evR+fOnfXbhw4dilOnTmH//v1Gt3nllVdQr149zJ07V79t8+bN6N69OzIyMmBlZVVgI9esExEREdF/klarhYODg8HF1EAdAKytreHv7489e/YYbN+zZw8CAwNN3iYgIMBo/927d6N+/fqFGqgDHKwTERERERXKiBEjsHDhQixevBixsbEYPnw44uLiMGjQIADAmDFj0LdvX/3+gwYNwvXr1zFixAjExsZi8eLFWLRoET7++ONCPybfYEpEREREVAg9evTAvXv3MHHiRMTHx6NWrVrYsWMHPD09AQDx8fEG51yvXLkyduzYgeHDh+Obb76Bh4cHvvzyS3Tt2rXQj8nBeiFptVpERETk+asRNZChEZCjU4ZGQI5OGRoBOTplaATk6JShEZCjU4ZGQI5OGRoJeP/99/H++++bvG7p0qVG25o1a4aYmJh//Xh8gykRERERkUpxzToRERERkUpxsE5EREREpFIcrBMRERERqRQH6wU4cOAAQkJC4OHhAY1Ggy1btohOMhIZGYkGDRrA3t4e5cqVQ2hoKC5cuCA6y8j8+fPx8ssv689jGhAQgJ07d4rOyldkZCQ0Gg2GDRsmOsXA+PHjodFoDC5ubm6is4zcunULvXv3hrOzM0qWLIm6devixIkTorMMVKpUyehYajQaDB48WHSaXk5ODsaNG4fKlSvD1tYWVapUwcSJE5Gbmys6zcCDBw8wbNgweHp6wtbWFoGBgTh27JjQpoK+hiuKgvHjx8PDwwO2trZo3rw5zp49q6rGTZs2oW3btnBxcYFGo8GpU6fM2leYzuzsbIwaNQq1a9eGnZ0dPDw80LdvX9y+fVs1jcBfXzurV68OOzs7ODk5oXXr1jhy5IhZGwvT+U/vvvsuNBoN5syZY7Y+UhcO1guQnp6OOnXq4Ouvvxadkqf9+/dj8ODBOHz4MPbs2YOcnBy0adMG6enpotMMVKhQAdOmTcPx48dx/PhxtGzZEp06dTL7N8bCOnbsGBYsWICXX35ZdIpJNWvWRHx8vP5y5swZ0UkGUlJS0KRJE1hZWWHnzp04d+4cZs+ejdKlS4tOM3Ds2DGD4/jkj1d069ZNcNnfpk+fjm+//RZff/01YmNjMWPGDMycORNfffWV6DQDAwYMwJ49e7B8+XKcOXMGbdq0QevWrXHr1i1hTQV9DZ8xYwY+//xzfP311zh27Bjc3Nzw6quv4sGDB6ppTE9PR5MmTTBt2jSzNeXVkVdnRkYGYmJi8OmnnyImJgabNm3CxYsX0bFjR9U0AkC1atXw9ddf48yZMzh48CAqVaqENm3a4O7du6rqfGLLli04cuQIPDw8zFRGqqRQoQFQNm/eLDqjQImJiQoAZf/+/aJTCuTk5KQsXLhQdIaRBw8eKFWrVlX27NmjNGvWTBk6dKjoJAMRERFKnTp1RGfka9SoUUrTpk1FZxTZ0KFDFS8vLyU3N1d0il779u2V/v37G2zr0qWL0rt3b0FFxjIyMhQLCwtl+/btBtvr1KmjjB07VlCVoae/hufm5ipubm7KtGnT9NseP36sODo6Kt9++62Awvy/z1y9elUBoJw8edKsTaYU5vvh0aNHFQDK9evXzRP1lMI0pqWlKQCUvXv3mifKhLw6b968qZQvX175448/FE9PT+WLL74wexupA2fWX0BpaWkAgDJlygguyZtOp8OaNWuQnp6OgIAA0TlGBg8ejPbt26N169aiU/J06dIleHh4oHLlyujZsyeuXLkiOsnAtm3bUL9+fXTr1g3lypVDvXr18P3334vOyldWVhZWrFiB/v37Q6PRiM7Ra9q0Kfbt24eLFy8CAE6fPo2DBw+iXbt2gsv+lpOTA51OBxsbG4Pttra2OHjwoKCq/F29ehUJCQlo06aNfptWq0WzZs0QHR0tsOzFkJaWBo1Go7rfpj2RlZWFBQsWwNHREXXq1BGdYyA3Nxd9+vRBeHg4atasKTqHBOMfRXrBKIqCESNGoGnTpqhVq5boHCNnzpxBQEAAHj9+jFKlSmHz5s2oUaOG6CwDa9asQUxMjPC1tvlp1KgRli1bhmrVquHOnTuYPHkyAgMDcfbsWTg7O4vOAwBcuXIF8+fPx4gRI/DJJ5/g6NGjGDJkCLRarcGfYlaTLVu2IDU1FW+99ZboFAOjRo1CWloaqlevDgsLC+h0OkyZMgVvvPGG6DQ9e3t7BAQEYNKkSfD19YWrqytWr16NI0eOoGrVqqLzTEpISAAAuLq6Gmx3dXXF9evXRSS9MB4/fozRo0ejV69ecHBwEJ1jYPv27ejZsycyMjLg7u6OPXv2wMXFRXSWgenTp8PS0hJDhgwRnUIqwMH6C+aDDz7A77//rtqZLB8fH5w6dQqpqanYuHEjwsLCsH//ftUM2G/cuIGhQ4di9+7dRjOEahIcHKz//9q1ayMgIABeXl744YcfMGLECIFlf8vNzUX9+vUxdepUAEC9evVw9uxZzJ8/X7WD9UWLFiE4OFh160PXrl2LFStWYNWqVahZsyZOnTqFYcOGwcPDA2FhYaLz9JYvX47+/fujfPnysLCwgJ+fH3r16vVMf7nPHJ7+LYqiKKr6zYpssrOz0bNnT+Tm5mLevHmic4y0aNECp06dQlJSEr7//nt0794dR44cQbly5USnAQBOnDiBuXPnIiYmhq9DAsA3mL5QPvzwQ2zbtg1RUVGoUKGC6ByTrK2t4e3tjfr16yMyMhJ16tTB3LlzRWfpnThxAomJifD394elpSUsLS2xf/9+fPnll7C0tIROpxOdaJKdnR1q166NS5cuiU7Rc3d3N/ohzNfXF3FxcYKK8nf9+nXs3bsXAwYMEJ1iJDw8HKNHj0bPnj1Ru3Zt9OnTB8OHD0dkZKToNANeXl7Yv38/Hj58iBs3buDo0aPIzs5G5cqVRaeZ9OQMSk9m2J9ITEw0mm2nwsnOzkb37t1x9epV7NmzR3Wz6sBfXy+9vb3RuHFjLFq0CJaWlli0aJHoLL1ff/0ViYmJqFixov770PXr1/HRRx+hUqVKovNIAA7WXwCKouCDDz7Apk2b8PPPP6v2G6MpiqIgMzNTdIZeq1atcObMGZw6dUp/qV+/Pt58802cOnUKFhYWohNNyszMRGxsLNzd3UWn6DVp0sToFKIXL16Ep6enoKL8LVmyBOXKlUP79u1FpxjJyMhAiRKGX64tLCxUd+rGJ+zs7ODu7o6UlBTs2rULnTp1Ep1kUuXKleHm5qY/AxDw1zrm/fv3IzAwUGCZnJ4M1C9duoS9e/eqZkleQdT2fahPnz74/fffDb4PeXh4IDw8HLt27RKdRwJwGUwBHj58iMuXL+v/ffXqVZw6dQplypRBxYoVBZb9bfDgwVi1ahW2bt0Ke3t7/SyRo6MjbG1tBdf97ZNPPkFwcDBeeuklPHjwAGvWrMEvv/yCn376SXSanr29vdFafzs7Ozg7O6vqPQAff/wxQkJCULFiRSQmJmLy5Mm4f/++qpZEDB8+HIGBgZg6dSq6d++Oo0ePYsGCBViwYIHoNCO5ublYsmQJwsLCYGmpvi+LISEhmDJlCipWrIiaNWvi5MmT+Pzzz9G/f3/RaQZ27doFRVHg4+ODy5cvIzw8HD4+PujXr5+wpoK+hg8bNgxTp05F1apVUbVqVUydOhUlS5ZEr169VNOYnJyMuLg4/TnLn/wQ7ObmZta/r5Bfp4eHB15//XXExMRg+/bt0Ol0+u9FZcqUgbW1tfBGZ2dnTJkyBR07doS7uzvu3buHefPm4ebNm2Y/VWtBz/nTP+hYWVnBzc0NPj4+Zu0klRB5KhoZREVFKQCMLmFhYaLT9Ez1AVCWLFkiOs1A//79FU9PT8Xa2lopW7as0qpVK2X37t2iswqkxlM39ujRQ3F3d1esrKwUDw8PpUuXLsrZs2dFZxn58ccflVq1ailarVapXr26smDBAtFJJu3atUsBoFy4cEF0ikn3799Xhg4dqlSsWFGxsbFRqlSpoowdO1bJzMwUnWZg7dq1SpUqVRRra2vFzc1NGTx4sJKamiq0qaCv4bm5uUpERITi5uamaLVa5ZVXXlHOnDmjqsYlS5aYvD4iIkI1nU9OK2nqEhUVpYrGR48eKZ07d1Y8PDwUa2trxd3dXenYsaNy9OhRs/UVptMUnrrxv02jKIpS/D8CEBERERHRs+KadSIiIiIileJgnYiIiIhIpThYJyIiIiJSKQ7WiYiIiIhUioN1IiIiIiKV4mCdiIiIiEilOFgnIiIiIlIpDtaJiIiIiFSKg3Uieq6WLl0KjUajv1haWqJChQro168fbt26ZZaGSpUq4a233tL/+5dffoFGo8Evv/xSpPuJjo7G+PHjkZqaWqx9APDWW2+hUqVKBe7XvHlz1KpVq1ge88lzc/z48WK5v3/e57Vr14rtPomI/ss4WCcis1iyZAkOHTqEPXv2YODAgVi9ejWCgoKQnp5u9hY/Pz8cOnQIfn5+RbpddHQ0JkyY8FwG60RERKZYig4gov+GWrVqoX79+gCAFi1aQKfTYdKkSdiyZQvefPNNk7fJyMhAyZIli73FwcEBjRs3Lvb7JSIiKm6cWSciIZ4Mlq9fvw7gr2UgpUqVwpkzZ9CmTRvY29ujVatWAICsrCxMnjwZ1atXh1arRdmyZdGvXz/cvXvX4D6zs7MxcuRIuLm5oWTJkmjatCmOHj1q9Nh5LYM5cuQIQkJC4OzsDBsbG3h5eWHYsGEAgPHjxyM8PBwAULlyZf2ynn/ex9q1axEQEAA7OzuUKlUKbdu2xcmTJ40ef+nSpfDx8YFWq4Wvry+WLVv2r45hXo4fP46ePXuiUqVKsLW1RaVKlfDGG2/oj/XTUlJS0K9fP5QpUwZ2dnYICQnBlStXjPbbu3cvWrVqBQcHB5QsWRJNmjTBvn37irWdiIgMcbBOREJcvnwZAFC2bFn9tqysLHTs2BEtW7bE1q1bMWHCBOTm5qJTp06YNm0aevXqhf/973+YNm0a9uzZg+bNm+PRo0f62w8cOBCzZs1C3759sXXrVnTt2hVdunRBSkpKgT27du1CUFAQ4uLi8Pnnn2Pnzp0YN24c7ty5AwAYMGAAPvzwQwDApk2bcOjQIYOlNFOnTsUbb7yBGjVqYN26dVi+fDkePHiAoKAgnDt3Tv84S5cuRb9+/eDr64uNGzdi3LhxmDRpEn7++ednP6j/79q1a/Dx8cGcOXOwa9cuTJ8+HfHx8WjQoAGSkpKM9n/77bdRokQJrFq1CnPmzMHRo0fRvHlzg+U+K1asQJs2beDg4IAffvgB69atQ5kyZdC2bVsO2ImInieFiOg5WrJkiQJAOXz4sJKdna08ePBA2b59u1K2bFnF3t5eSUhIUBRFUcLCwhQAyuLFiw1uv3r1agWAsnHjRoPtx44dUwAo8+bNUxRFUWJjYxUAyvDhww32W7lypQJACQsL02+LiopSAChRUVH6bV5eXoqXl5fy6NGjPD+WmTNnKgCUq1evGmyPi4tTLC0tlQ8//NBg+4MHDxQ3Nzele/fuiqIoik6nUzw8PBQ/Pz8lNzdXv9+1a9cUKysrxdPTM8/HfqJZs2ZKzZo1C9zvn3JycpSHDx8qdnZ2yty5c/Xbnzw3nTt3Ntj/t99+UwAokydPVhRFUdLT05UyZcooISEhBvvpdDqlTp06SsOGDY3u8+ljRERE/w5n1onILBo3bgwrKyvY29ujQ4cOcHNzw86dO+Hq6mqwX9euXQ3+vX37dpQuXRohISHIycnRX+rWrQs3Nzf9MpSoqCgAMFr/3r17d1ha5v/2nIsXL+LPP//E22+/DRsbmyJ/bLt27UJOTg769u1r0GhjY4NmzZrpGy9cuIDbt2+jV69e0Gg0+tt7enoiMDCwyI+bl4cPH2LUqFHw9vaGpaUlLC0tUapUKaSnpyM2NtZo/6ePWWBgIDw9PfXHNDo6GsnJyQgLCzP4+HJzc/Haa6/h2LFjQt4oTET0X8A3mBKRWSxbtgy+vr6wtLSEq6sr3N3djfYpWbIkHBwcDLbduXMHqampsLa2Nnm/T5Z13Lt3DwDg5uZmcL2lpSWcnZ3zbXuy9r1ChQqF+2Ce8mSpTIMGDUxeX6JEiXwbn2wrrtMd9urVC/v27cOnn36KBg0awMHBARqNBu3atTNYNvTPxza17Unvk4/v9ddfz/Mxk5OTYWdnVyz9RET0Nw7WicgsfH199WeDycs/Z5ufcHFxgbOzM3766SeTt7G3twcA/YA8ISEB5cuX11+fk5OjH3Tm5cm6+Zs3b+a7X15cXFwAABs2bICnp2ee+/2z8Wmmtv0baWlp2L59OyIiIjB69Gj99szMTCQnJ5u8TV493t7eAP7++L766qs8z6Lz9G9IiIioeHCwTkSq1qFDB6xZswY6nQ6NGjXKc7/mzZsDAFauXAl/f3/99nXr1iEnJyffx6hWrRq8vLywePFijBgxAlqt1uR+T7Y/PTvdtm1bWFpa4s8//zRaxvNPPj4+cHd3x+rVqzFixAj9DyfXr19HdHQ0PDw88u0sDI1GA0VRjD6GhQsXQqfTmbzNypUrDbqjo6Nx/fp1DBgwAADQpEkTlC5dGufOncMHH3zwzI1ERFR4HKwTkar17NkTK1euRLt27TB06FA0bNgQVlZWuHnzJqKiotCpUyd07twZvr6+6N27N+bMmQMrKyu0bt0af/zxB2bNmmW0tMaUb775BiEhIWjcuDGGDx+OihUrIi4uDrt27cLKlSsBALVr1wYAzJ07F2FhYbCysoKPjw8qVaqEiRMnYuzYsbhy5Qpee+01ODk54c6dOzh69Cjs7OwwYcIElChRApMmTcKAAQPQuXNnDBw4EKmpqRg/frzJpSh5uX//PjZs2GC0vWzZsmjWrBleeeUVzJw5Ey4uLqhUqRL279+PRYsWoXTp0ibv7/jx4xgwYAC6deuGGzduYOzYsShfvjzef/99AECpUqXw1VdfISwsDMnJyXj99ddRrlw53L17F6dPn8bdu3cxf/78QvcTEVERiH6HKxG92J6cHeTYsWP57hcWFqbY2dmZvC47O1uZNWuWUqdOHcXGxkYpVaqUUr16deXdd99VLl26pN8vMzNT+eijj5Ry5copNjY2SuPGjZVDhw4pnp6eBZ4NRlEU5dChQ0pwcLDi6OioaLVaxcvLy+jsMmPGjFE8PDyUEiVKGN3Hli1blBYtWigODg6KVqtVPD09lddff13Zu3evwX0sXLhQqVq1qmJtba1Uq1ZNWbx4sRIWFlbos8EAMHlp1qyZoiiKcvPmTaVr166Kk5OTYm9vr7z22mvKH3/8YXQcnjw3u3fvVvr06aOULl1asbW1Vdq1a2dwXJ/Yv3+/0r59e6VMmTKKlZWVUr58eaV9+/bK+vXrje6TZ4MhIioeGkVRFEE/JxARERERUT546kYiIiIiIpXiYJ2IiIiISKU4WCciIiIiUikO1omIiIiIVIqDdSIiIiIileJgnYiIiIhIpThYJyIiIiJSKQ7WiYiIiIhUioN1IiIiIiKV4mCdiIiIiEilOFgnIiIiIlIpDtaJiIiIiFTq/wB9TZ0GXXKfSAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 85.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAMWCAYAAABIgshOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADURUlEQVR4nOzdd3hMWQMG8HfSIyIiIXoLQYQgwRK9LlbvVlm9rt6C1Yney+rRN8qyu9rqndWtEj0ECamCJFLv94cvs0bqyMzce3h/z3OfR25959w748yZc89VSZIkgYiIiIiIFMdI7gBERERERJQyVtaJiIiIiBSKlXUiIiIiIoViZZ2IiIiISKFYWSciIiIiUihW1omIiIiIFIqVdSIiIiIihWJlnYiIiIhIoVhZJyIiIiJSKFbWiYi+AqGhoejduzfy5csHY2NjqFQqTJ482WDHf/r0KVQqFQoXLmywY37LvL29oVKp8NNPP8kdhYj0jJV1+qr4+/tj+PDhcHFxgZWVFSwtLVGwYEFUrVoVo0aNwt9//53m9rdu3cKQIUNQtmxZ2NrawszMDA4ODqhfvz4WLlyI0NBQjfVPnjwJlUoFlUqlVc67d++ib9++cHJygqWlJaysrFCkSBHUqlULv/zyC86fP59sm8KFC6uPpVKpYGRkhGzZsqFAgQKoX78+JkyYgLt376Z53Fq1aumtEjd58mR1NgcHB8THx6e6bmhoKMzMzNTre3t7ayxPqohktOKXVFH8fLK2toarqyvGjRuHkJCQL35t2l4XcmjevDnWrl2LyMhIuLu7w8PDAwULFpQ7lqJ8fp389ddfaa7fsmVL9bq1atXSSYYbN25g8uTJ2Lt3r072R0TfAInoK3Hs2DHJ2tpaAiAZGxtLhQsXlipVqiQVK1ZMUqlUEgDJzs4uxW3j4+Oln3/+WTIyMpIASCYmJlLJkiWlihUrSgULFpQASAAkGxsb6ciRI+rtTpw4oV6WUVu2bJHMzMwkAJKpqank6OgoVaxYUSpUqJB6X25ubsm2S1pevHhxycPDQ/Lw8JDc3Nw0tgMgtW7dWgoJCUnx2DVr1pQASJMmTcpw3oyaNGmSRo79+/enuu6yZcs01t2wYYPG8g0bNkgApEKFCmXo2H5+fup9ubu7q8uncOHC6nOfL18+6cmTJ1q9pi+9Lgzt5s2b6tf45s0bWTK8ePFCKlGihFSnTh1Zjp8Rn14nAKS2bdumum5YWJj6fQpAqlmzpk4yJF3b3bp1y9R+fv/9d6lEiRLS2LFjdZKLiJSLLev0VXj79i3at2+Pd+/eoUmTJnj8+DH8/Pzwzz//4OHDhwgLC4O3tzcqV66c4vadOnXC0qVLYWVlhcWLFyM0NBS+vr64dOkSnj17Bj8/P4wdOxZxcXG4ffv2F+d8+vQpevbsidjYWPTo0QMvXrzAo0ePcOnSJTx9+hSBgYFYtmwZnJ2dU93HuHHjcPbsWZw9exZXrlzB06dPERwcjEWLFsHe3h67d+9GtWrVEBER8cU5M6NEiRIAgM2bN6e6zubNm6FSqVC8eHGdH3/nzp3q8vHz88OVK1dQqFAhvHz5Ev3799dqX4a6LjLr3r17AAAPDw/Y2NjIkiFfvny4d+8ejh07JsvxtWFsbAxHR0f89ddfqb5PfHx8EBsbq76elaZly5a4d+8evLy85I5CRHrGyjp9FQ4cOICQkBBky5YNO3bsQKFChTSWZ8+eHd26dcP+/fuTbbt27Vrs2LEDlpaWOHHiBAYPHoxs2bJprFO4cGF4eXnh8uXLKFas2Bfn/O233xATE4MSJUpgzZo1yJUrl8by3LlzY+DAgdi0aZNW+7W3t8eQIUNw5coV5MmTB/fu3cPQoUO/OGdmeHh4oHDhwvjjjz/w7t27ZMsfPXqEf/75BzVr1jRIN40KFSpg4cKFAIDDhw9nuMuKIa+LzIqOjgYAWFpaypZBNJ07d8aHDx+wa9euFJdv2bIFKpUKP/74o4GTERFpYmWdvgpPnjwBADg5OSFLliwZ3i4hIQEzZswAAEycOBFubm5pru/s7Iwffvgh0znLlCkDIyPdv/0KFSqEFStWAPhY2Xj+/LnOj5GepApOdHQ0du/enWx5Uot7586dDZapRo0aAABJkvD48eN019fVdXH+/Hm0atUKDg4OMDMzQ/78+dG1a1f4+vqmuJ+kewpOnjyJe/fuoW3btrC3t4elpSXc3NywY8cOjfWT7plIuslw48aNGn2yk6R3X0XS/RBPnz7VmB8aGoqRI0eiZMmSsLCwgJWVFQoXLozvv/9efZ0lSe8G09DQUIwePRolSpSApaUlbG1tUatWLWzduhWSJCVb/9MbKGNiYjB58mQUK1YMFhYWKFCgAIYPH47IyMhUX1N6kq6/lH4B8vPzw7lz5+Dh4YEiRYqkuo+LFy9i9OjRcHd3R65cuWBubo4CBQqgS5cuuHPnTrL1CxcujO7duwNIfq4+7RP/6XVw48YNtGnTBg4ODjAyMlLf35HSDaYxMTEoU6YMVCoVpk2bluz4kiShdu3aUKlU6NOnT0aKiYgUgJV1+ioktXg+fPgQb968yfB2//zzD54+fQoTExOD/OeVlPPGjRuIi4vTyzGaNWuGvHnzIj4+HocPH9bLMdLTpUsXAB+/MHxu69atsLCwQJs2bQyWJ6XKYFp0cV2sXLkS1apVw549ewAArq6uiIyMxObNm1GhQoUUf+VJcvXqVVSsWBF///03ChcuDGtra1y7dg3t27fXKFMbGxt4eHiouxPlypULHh4e6ikzIiIiULlyZcyfPx9+fn5wdHREyZIlER0djcOHD2PcuHEZ3tejR49Qvnx5zJ07F0+fPoWzszNy5MiBU6dOoXPnzvjpp59SPUdxcXFo0KABpk6dCgsLCxQuXBgBAQFYuHAhWrZs+cWvr1ixYvjuu+9w+vRp+Pv7ayxLKuOk6zg1nTt3Vr8mBwcHlCpVCu/evcOWLVtQsWJFnDx5UmP9ihUrpnquypQpk2z/p0+fxnfffYe///4bBQoUSPOLAwCYm5tj8+bNMDMzw9SpU3H58mWN5fPnz8fJkyfh6OiIBQsWpLkvIlIQWXvME+nI/fv31TcBurm5Sbt27crQjXZz586VAEjlypX7ouNqe4PpkSNH1OvXrVtXOnDggBQZGZmhbZNuJP38ZsyUtG7dWgIg9e3bV2O+IW4w7dmzpyRJklSxYkXJyMhIevHihXqdc+fOSQCkdu3aSZIkSXXr1tX5DaZ+fn7Jlv/+++8SAEmlUknBwcHp7i+z18X169clExMTCYA0Z84cKSEhQZIkSfrw4YM0YMAA9U2pAQEBGtslnR9TU1Np0KBBUnR0tCRJkpSYmCiNGTNGAiDlzZtXio+P19guvZsW07tGk66tT8tu3rx5EgCpQYMGUmhoqMb6z549kxYuXKgxL+kcfH7OEhMTJXd3d/VNmq9evVIvO3jwoGRlZSUBkFasWJHiazI1NZWcnZ2l+/fvq5dduHBBypYtmwRAOnjwYKqv63NJGY2NjSVJkqTly5dLAKSZM2dqrOfk5CSZm5tLYWFh0ubNm1O9wXTjxo3S48ePNebFxcVJa9eulUxMTKSiRYuqz/3nryutG0yTrgNjY2OpT58+Gp8RUVFR6e7Hy8tLAiA5OTmpt71165Zkbm4uGRsbS+fPn0/12ESkPGxZp6+Ck5OT+mffq1evok2bNrC1tUXJkiXRvXt3+Pj4ICYmJtl2L1++BIB0W6x0pV69euqW2mPHjqFx48awsbGBq6sr+vXrh3379iEhISHTxylQoAAAICgoKNP7+lKdO3dGYmIitm7dqp4nRxeY69evY9iwYQCAOnXqwN7ePt1tMntdzJs3D/Hx8WjevDlGjRql7vJkbm6OZcuWoXTp0oiIiMDKlStT3N7Z2RmLFy+GhYUFAKi7NeTOnRsBAQH4999/vyiXNh4+fAgAGDhwIHLkyKGxrGDBghm+J+LYsWO4cuUKzM3N8dtvv8HBwUG97Pvvv8ekSZMAALNnz06xdT0+Ph4bN26Ek5OTet53332HXr16AQAOHjyo1ev6VPv27WFqaqrRFeaff/7BgwcP0KRJE9ja2qa5fdeuXVG0aFGNeSYmJujZsyc6dOiAJ0+e4OLFi1+cz8XFBStXrtTo2peR+xJGjx6NatWq4cGDBxg5ciRiY2PRuXNnxMTEwNPTE1WqVPniTERkeKys01dj3LhxOH78OBo3bgwzMzNIkoT79+/D29sbHTp0gJOTU7KfpZNugLSysjJYzlWrVmH37t2oWbMmjI2NER8fj3///RerVq1C06ZN4erqilu3bmXqGEmvJ6UbPA2lY8eOMDExUXcpiI2NxY4dO2Bvb4/vv/9eb8dt27YtqlWrhmrVqqFo0aJwc3PDs2fP4ODgkGrl+HOZvS6Suh/9/PPPyZapVCoMHjxYY73P9ejRI9k9DaampnB1dQXw370P+pT0hW/Pnj1pjpmfnqTX2LZtW+TOnTvZ8n79+sHc3BzPnj3D/fv3ky0vV64c3N3dk82vWLEigMyVhZ2dHRo1agRfX19cu3YNQMa7wCS5d+8eJk2ahFatWqFWrVrqa+/UqVMAgJs3b35xvs6dO3/RvS1GRkbYtGkTrK2tsXLlSjRp0gQ3b96Em5sbJk6c+MV5iEgerKzTV6V27drYv38/3rx5g9OnT2Pu3LnqG6r8/f3RuHFj9TB3AGBtbQ0AmbpR7Uu0atUKJ0+eRFhYGI4cOYJp06ahUqVKAIA7d+6gXr16CA4O/uL9v3//HgCSjV5iSDlz5kSDBg1w69Yt3Lx5EwcOHEBYWJi6NVNfrly5gnPnzuHcuXN49eoVSpUqhZEjR+LmzZsZHioyM9fFmzdv1OcutSE4S5cuDQB48OBBissdHR1TnJ80elDS+dWn7t27w8bGBt7e3sifPz9++uknrFu3TuvKcdJrTK0srK2t1V8MUioPfZfFpzeaxsfHw8fHBzly5EDjxo3T3dbLywulS5fG1KlTsWfPHpw6dUp97SXd3B0WFvbF2UqVKvXF2xYpUgSLFi0CABw9ehSWlpbYsmWLXt97RKQfrKzTV8nS0hLVq1fHyJEjcfz4cZw+fRpWVlaIjo7G/Pnz1evly5cPwMfRH+SQLVs21KtXDxMmTMA///yDnTt3wsjICEFBQVi9evUX7zfphrnPh4Y0tE9vNNW2xfJL+fn5QZIkSJKEqKgo3LlzB3PnztXofpGezFwXn1YeUyv/pCyp/fKRWot+UitrSt1FdC1v3ry4cOECWrdujYiICGzcuBG9evWCo6MjqlSpggsXLmRoP0nlkda1mFZ56LssmjZtChsbG2zfvh379u1DcHAw2rVrBzMzszS3O336NMaNGweVSgUvLy/cuXMH79+/R2JiIiRJwvjx4wEgUzeSZ/YXvxo1asDExAQAUKVKFZQsWTJT+yMiebCyTt+EatWqYcCAAQCAS5cuqedXrVoVAHD79u1MtYDpSps2bdC6dWsAmjm1kZiYqK5IJbXWy6V58+bIli0bNm/ejH379qF48eKpPphKSTJzXWTNmlX979TuGXj9+jWA/1rwDSW1im1qvyCUKlUKu3btwps3b3DixAlMnjwZJUuWxMWLF9GgQYNkQz2mJKk80rp/Qq7yAAALCwu0bdsWr1+/xpAhQwBk7Atl0r0Yo0aNwtixY+Hs7AwrKyv1EJlyDJv6qYSEBHTt2hXx8fEwMjLC8ePHNe4fISJxsLJO34ykG8FiY2PV8ypXrozChQsjPj4+Uy3ZupRSTm3s3bsXr169gqmpKRo0aKDLaFqztLREq1at8Pr1a8TExBj0xtLMyMx1kT17duTMmRMAcPfu3RTXSRqD+9ObJvUpqYU2pa5VERERCAkJSXN7c3Nz1KpVC5MmTcLt27fh4eGB9+/fY/v27ekeO+k1plYW7969U1dsDVUen0u6Lv39/VG0aFH1l7W0JH1RSW3d1PqqpzXevS7NnDkTFy5cQOnSpeHj4wMAGDRokOxfIohIe6ys01chJCQk3Z/Dz58/DwAa/ZaNjY3h6ekJAJg2bZr6JrPU+Pr6Yt++fV+cMyOjs6SUM6OePXuGQYMGAfg4UkVSdw459enTB3Xr1kXdunX13gVGVzJ7XTRs2BAAsHTp0mTrSpKknp+0nr4lfQH8fNxt4OOTWrVhbGysvrkzICAg3fWTXuPOnTvx6tWrZMtXrVqFmJgYFCpUCCVKlNAqi67UqFEDrVq1Qt26dTFq1KgMbZM0KkvSrwKfOnz4cKqV9aTtkp46qw9Xr17FtGnTYGpqii1btqBNmzbo3bs33rx5k+aY9kSkTKys01dhy5YtKFeuHNasWZPscfJv3rzBxIkT1X2mk54gmKRPnz5o3bo1oqKiULt2bSxdujRZ39nnz59jwoQJcHd3x6NHj74458yZM1G9enVs37492TECAwPRr18/nDlzBiqVCt26dcvwfkNCQrBkyRK4u7sjMDAQzs7OinnoSZUqVXD06FEcPXrUYENk6kJmrosRI0bAxMQEf/zxB+bPn4/ExEQAH38tGTJkCG7fvg0bGxv079/fIK+lUaNGAIAJEyZoVC4PHTqEqVOnqvs1f2r8+PFYt25dsoeM3b59W/0k1QoVKqR77Dp16qBixYqIiYlBx44dNb6wHj58GFOmTAEAjB071mCtzp9TqVTYvXs3jh49in79+mVom2rVqgEAZs2apXFvw+XLl9GjRw/1sJuf+/SLU1RUVCaTJxcdHY0uXbogLi4OU6ZMQbly5QAACxYsgKOjI44fP47Fixfr/LhEpEcyje9OpFOLFi1SP/gFgFSkSBGpUqVKUvHixSUzMzP1/JEjR6a4fVxcnDRgwABJpVKpH8RSqlQpqVKlSlLhwoXV2+fIkUM6duyYertPH4pkZ2eX6lSrVi1JkiRp6NCh6vWNjIyk4sWLS5UqVZKKFCmifoiOsbGxtHjx4mQZkx5cU7x4ccnDw0Py8PCQ3N3dNfIBkNq2bZvsITZJkh62YmlpmWbeAwcOaH0OPn8oUkak91AkIyOjNHN26dJFkqT0H4r0pb70upAkSVqxYoV6OwcHB6lixYpS9uzZJQCSubm5tG/fvmTHSzo/J06cSDFPt27d0iyv1B60ExQUJOXOnVt97HLlyqnzjx07NsWHIjVv3lx9DooVKyZVqlRJKlasmPo1165dW4qLi1Ovn9pDkSRJkh4+fCjlz59fffwKFSpo7KtLly5SYmKiVq8p6b2X0sOKUvP5Q5EyIrWHIkVEREhFixaVAEhmZmZSmTJlpBIlSkgAJGdnZ2n48OEpPoAsISFBKl68uPozo0qVKlLNmjWlIUOGqNdJ7zqQpNTL5+eff5YASFWrVk328Kxz585JxsbGkoWFhXT37t0MlwERyYst6/RVGDBgAI4fP45Ro0ahatWqSEhIwI0bN/Dy5UsUKlQIXbt2xZkzZzB37twUtzcxMcHy5ctx48YNDBo0CE5OTggICMD169cRFRWFunXrYvHixXj8+DHq1KmT4j5CQ0NTncLDwwF8bFnfv38/Bg0aBDc3N0RGRuL69esIDg6Gk5MT+vXrh2vXrqnH4U7Jw4cP1cPD3bt3D/Hx8ahXrx7Gjx+Pu3fvYseOHckeYvO56OjoNPOm9AApOSQmJqaZ8+3bt3o9fmaui/79++PMmTNo0aIFEhMTcePGDWTJkgWdO3fGtWvX0KRJE71m/1TOnDlx7tw5tG3bFlmyZMH9+/dha2uLDRs2wMvLK8VtJkyYgLFjx6JixYp4//49bty4gejoaNSsWRObNm3C4cOHU2yRT0mxYsVw/fp1jBw5EgULFsSdO3cQFBSEGjVqYPPmzdi4caNsrepfKlu2bDh79iy6du2KbNmy4f79+4iNjcXw4cNx4cKFVG+WNTIywv79+9GmTRsYGxvj0qVLOHXqFG7cuJHpTEePHsWyZctgZWWFTZs2wdjYWGN51apVMWbMGHz48AGdO3fO1Eg1RGQ4Kkli5zUiIiIiIiViyzoRERERkUKxsk5EREREpFAZ63BIRN+Utm3bIjAwMEPrNm7cGOPGjdNzIiIiom8TK+tElMzly5fx7NmzDK1brFgxPachIiKS3+nTpzF37lxcvXoVgYGB2LNnD1q0aJHmNqdOncLw4cNx584d5M2bF6NHj87wELFJ2A2GiJJ5+vQpJEnK0OTt7S13XCIiIr2LjIyEq6srli1blqH1/fz80LhxY1SvXh3Xr1/HuHHjMHjwYOzevVur43I0GCIiIiIiLahUqnRb1seMGYM///wTvr6+6nn9+vXDzZs3ceHChQwfiy3rRERERPRNiomJwdu3bzUmXT1r5MKFC2jQoIHGvIYNG+LKlStaPefgq+2zblkh9YfKKEn4pSVyRyCib5wov68K9twkIsWwUFhtz7L8ILkjqI1pbo8pU6ZozJs0aRImT56c6X2/evUKDg4OGvMcHBwQHx+PkJAQ5MmTJ0P7UdjpIyIiIiIyDE9PTwwfPlxjnrm5uc72//nTmZN6n2vz1GZW1omIiIjom2Rubq7TyvmncufOjVevXmnMCwoKgomJCezs7DK8H1bWiYiIiMhwVN/GLZNVqlTBX3/9pTHv8OHDcHd3h6mpaYb3822UFhERERFRJrx//x43btzAjRs3AHwcmvHGjRvw9/cH8LFLTdeuXdXr9+vXD8+ePcPw4cPh6+uL9evXY926dRg5cqRWx2XLOhERERFROq5cuYLatWur/07q696tWzd4e3sjMDBQXXEHgCJFiuDAgQMYNmwYli9fjrx582LJkiVo3bq1Vsf9asdZ52gwREQZI8r/AhwNhujLKG40GLchckdQi766WO4I6WI3GCIiIiIihWJlnYiIiIhIoRT2wwgRERERfdW+kdFgdIWlRURERESkUGxZJyIiIiLD4d3iWmHLOhERERGRQrGyTkRERESkUOwGQ0RERESGwxtMtcLSIiIiIiJSKFbWiYiIiIgUit1giIiIiMhwOBqMVtiyTkRERESkUN90ZX1k9/o4u3kEgs7MwbOjM7Bjfi8UL5Qr1fWXjm+P6GtLMKhTrVTX2bu0H6KvLUHTWmX0kDhtPtu3olGDOqhYvgw6tG2Fa1evGDxDekTICIiRU4SMgBg5RcgIKD/n1SuXMXhgP9SvXQ3lXErg+LGjckdKldLLEhAjIyBGThEyAuLkzDSVkXImAYiRUk+quxXDrzvOoGa3Bfih/3IYmxhh34oByGJhlmzdprXKoKJLIQQEvUl1fz//WAuSJOkxceoOHTyAObO80LtPf/js2osKFdwwoG9vBAYEyJInJSJkBMTIKUJGQIycImQExMgZHR0FpxIlMHbcRLmjpEmEshQhIyBGThEyAuLkJMP7pivrzQetxJa/LsH3ySvcehiAvpO2oWCeHCjvXEBjvbw5bbBwTFt0H78JcfEJKe6rTPG8GPxjbfSbss0Q0ZPZvHEDWrZujVZt2qKooyNGe45H7jy5scNnuyx5UiJCRkCMnCJkBMTIKUJGQIyc1arXxKDBw1C3fgO5o6RJhLIUISMgRk4RMgLi5CTD+6Yr65/LZm0BAAiPiFLPU6lUWDe9CxZuOgbfJ69S3M7SwhQbvX7CsNm78Dr0nUGyfiouNha+d++gStVqGvOrVPXAzRvXDZ4nJSJkBMTIKUJGQIycImQExMkpAhHKUoSMgBg5RcgIiJNTZ1Qq5UwCYGX9E7OHt8S5649x93Gget6In+ohPj4Ry7efSnW7OSNa4eJNP+w7dcsQMZMJfxOOhIQE2NnZacy3s7NHSEiwLJk+J0JGQIycImQExMgpQkZAnJwiEKEsRcgIiJFThIyAODlJHoqvrD9//hw9evRIc52YmBi8fftWY5ISU+6ukpqFY9uiTPG86Oa5UT2vfKkCGNixJvpM2pLqdk1quKBWxeIYNW+3VsfTB9Vn3xAlSUo2T24iZATEyClCRkCMnCJkBMTJKQIRylKEjIAYOUXICIiTkwxL8ZX1sLAwbNy4Mc11vLy8YGNjozHFv874HdQLRrfGDzVc0LDPUrz85AZSj/KOyJUjKx4cmIJ3lxbi3aWFKJTXDrOGtcC9fZMAALUqOaFofnu8OjVbvQ4AbJ/bE3+v/ln7F/wFbLPbwtjYGCEhIRrzw8JCYWdnb5AM6REhIyBGThEyAmLkFCEjIE5OEYhQliJkBMTIKUJGQJycOiP3CDAcDUY7f/75Z5rTiRMn0t2Hp6cnIiIiNCYTB/cMHX/hmDZoXscV3/ddhmcBYRrLtu2/hIrtZ6NyxznqKSDoDRZuOoamA1cCAOZtOJJsHQAYPf939Jm8VcvS+DKmZmYo5VwaF8+f05h/8fx5uJYrb5AM6REhIyBGThEyAmLkFCEjIE5OEYhQliJkBMTIKUJGQJycJA/Zn2DaokULqFSqNIc8TO8nIHNzc5ibm2tuY2Sc7rEXjW2L9o3c0HbYWryP+gAHO2sAQMT7D/gQE4ewiCiEfXKzKQDExSfgdeg7PHwWBAB4HfouxZtKn78KT1b516cu3bpj/NjRcHZxgatreeze6YPAwEC0bd/BYBnSI0JGQIycImQExMgpQkZAjJxRUZHw9/dX//3y5Qvcu+cLGxsb5MmTV8ZkmkQoSxEyAmLkFCEjIE5OMjzZK+t58uTB8uXL0aJFixSX37hxA25ubno5dt921QEAR9YO1pjfe9IWbPnrkl6OqS/fN2qMiDfhWL1yBYKDg1CsuBOW/7oaefPmkzuamggZATFyipARECOnCBkBMXLeuX0bvXt0Vf89f44XAKBp85aYNmOWXLGSEaEsRcgIiJFThIyAODl1gv3wtaKS5HqKz/81a9YM5cqVw9SpU1NcfvPmTZQvXx6JiYla7deywuD0V1KA8EtL5I5ARN84ef8XyDj+/070ZSxkb5rVZOkxXu4IatHnZsgdIV2yn75Ro0YhMjIy1eXFihXLUL91IiIiIhKAIDd2KoXslfXq1aunudzKygo1a9Y0UBoiIiIiIuXgVxsiIiIiIoWSvWWdiIiIiL4hvAFFK2xZJyIiIiJSKFbWiYiIiIgUit1giIiIiMhwOBqMVlhaREREREQKxco6EREREZFCsRsMERERERkOu8FohaVFRERERKRQbFknIiIiIsMx4jjr2mDLOhERERGRQrGyTkRERESkUOwGQ0RERESGwxtMtcLSIiIiIiJSKFbWiYiIiIgUit1giIiIiMhwVBwNRhtsWSciIiIiUihW1omIiIiIFOqr7QYTfmmJ3BEyxLbxXLkjpCv8wCi5I3w1EhMluSNkSGRsgtwR0mVt8dV+fBkcf5EmIoPiaDBaYWkRERERESkUm6aIiIiIyHD4c55W2LJORERERKRQrKwTERERESkUu8EQERERkeHwBlOtsLSIiIiIiBSKlXUiIiIiIoViNxgiIiIiMhyOBqMVtqwTERERESkUW9aJiIiIyHB4g6lWWFpERERERArFyjoRERERkUKxGwwRERERGQ5vMNUKW9aJiIiIiBSKlXUiIiIiIoViNxgiIiIiMhyOBqMVlhYRERERkUKxsk5EREREpFCsrGeAz/ataNSgDiqWL4MObVvh2tUrsua5t6kPog+PSjYtHFRPvc74LlXxZHt/hP01FH/PbY9ShexkTPwfpZVlapSe8+qVyxgyqB/q16mO8mVK4sSxo3JHSmbdquWo5lZaY2rWoIbcsVKk9POdRIScImQExMgpQkZAjJwiZATEyZlpKpVyJgGwsp6OQwcPYM4sL/Tu0x8+u/aiQgU3DOjbG4EBAbJlqvbzZhRuv0I9NR6zAwDw++n7AIAR7SphcCt3DFt2FNV+3oLX4ZHYP6sdslqaypYZUGZZpkSEnNHR0XByKomx436RO0qaijgWwx9/n1RPG332yh0pGRHONyBGThEyAmLkFCEjIEZOETIC4uQkw2NlPR2bN25Ay9at0apNWxR1dMRoz/HInSc3dvhsly1TSEQ0XodHqqfGlYvi8ctwnPn3OQBgYEs3zNl+EX+ce4i7T0PQa+5BWJqboH0dZ9kyA8osy5SIkLNa9RoYOHgo6tZrIHeUNBkbG8POPqd6srXNIXekZEQ434AYOUXICIiRU4SMgBg5RcgIiJNTJ1RGypkEIEZKmcTFxsL37h1UqVpNY36Vqh64eeO6TKk0mZoYoUNdZ2z8+xYAoHBuG+Sxy4qjV5+q14mNS8CZf5/jO+e8MqUUoywBcXKK4oW/P5o3rIW2TRtgkudIvHzxXO5IGkQ53yLkFCEjIEZOETICYuQUISMgTk6SB4duTEP4m3AkJCTAzk6zv7ednT1CQoJlSqWpWdXiyJ7VAlsO3wYA5M5hBQAICo/UWC/oTRQK5spm8HxJRChLQJycInB2KYsJU2eiQMHCCAsLxcZ1q9C/x4/YvONP2GTPLnc8AOKcbxFyipARECOnCBkBMXKKkBEQJyfJQxGV9ejoaFy9ehU5cuSAs7NmV40PHz5gx44d6Nq1a6rbx8TEICYmRmOeZGwOc3NzneRTfXYDgiRJyebJpdv3ZfD35ScIDNOsnEufracCIH0+UwZKLstPiZJTyap4VFf/2xGAS1lXtG/+PQ7u24sOnX+SLVdKRDnfIuQUISMgRk4RMgJi5BQhIyBOzkwTpPuJUsheWg8ePECpUqVQo0YNlClTBrVq1UJgYKB6eUREBLp3757mPry8vGBjY6MxzZ3tlelsttltYWxsjJCQEI35YWGhsLOzz/T+M6tgrmyoU74QvA/eUs979f9Ku4Otlca6ObNnQdAbzQq9ISm9LJOIklNElpZZULSYE174+8sdRU2U8y1CThEyAmLkFCEjIEZOETIC4uQkecheWR8zZgzKlCmDoKAg3L9/H9myZYOHhwf8tfgP3dPTExERERrTqDGemc5mamaGUs6lcfH8OY35F8+fh2u58pnef2Z1aeiCoDdROPjPY/W8p68iEBj6HnUrFFbPMzUxQvWyBXDxrnx3lCu9LJOIklNEsbGxeOb3BHb2yvmPR5TzLUJOETICYuQUISMgRk4RMgLi5CR5yN4N5vz58zh69Cjs7e1hb2+PP//8EwMHDkT16tVx4sQJWFlZpbsPc/PkXV4+xOsmX5du3TF+7Gg4u7jA1bU8du/0QWBgINq276CbA3whlQro2sAFW4/cQUKiZv+W5XuuYlTHyngUEI5HL8MxukNlRMfEw+f4XZnSfqTUsvycCDmjoiLx/JMvtC9fvsD9e77IZmODPHnku5H4U8sWzoVHjVpwyJ0H4WFh2LjuV0RGvkejpi3kjqZBhPMNiJFThIyAGDlFyAiIkVOEjIA4OXXia+zao0eyV9ajo6NhYqIZY/ny5TAyMkLNmjWxbds2mZJ99H2jxoh4E47VK1cgODgIxYo7Yfmvq5E3bz5Zc9WpUBgFHWzUo8B8av6OS7AwN8GiQfVga22By/cC8YPnTryPjpMh6X+UWpafEyHn3Tu30btHN/Xf8+fOAgA0bdYCU2fMkiuWhuCg15g8bhQi3oQju20OlC5TFqu8tyG3Qr5MJBHhfANi5BQhIyBGThEyAmLkFCEjIE5OMjyVJMl722GlSpXw888/o0uXLsmWDRo0CFu3bsXbt2+RkJCg1X511bKub7aN58odIV3hB0bJHeGrkZiogLt8MyAyVrv3mxysLWRvayAiEoLSPi4tm62UO4Ja9J/95Y6QLtn7rLds2RLbt6c84P+yZcvQsWNHyPx9goiIiIh0Re4HIQn2UCTZW9b1hS3rusOWdd1hy7rusGWdiChjlPZxadl8ldwR1KL/6Ct3hHQp7PQRERER0VeNN5hqRYz2fyIiIiKibxAr60RERERECsVuMERERERkOILc2KkULC0iIiIiIoViZZ2IiIiISKHYDYaIiIiIDIejwWiFLetERERERArFlnUiIiIiMhgVW9a1wpZ1IiIiIiKFYmWdiIiIiEih2A2GiIiIiAyG3WC0w5Z1IiIiIiKFYmWdiIiIiEih2A2GiIiIiAyHvWC0wpZ1IiIiIiKFYmWdiIiIiEih2A2GiIiIiAyGo8Foh5V1mYUfGCV3hHTZ1p8md4QMCT40Qe4I6TIxFuMDKqs5Pxq+JZIkd4KMiU9IlDtCukxN+IM1EekW/0cmIiIiIoNhy7p22ARARERERKRQrKwTERERESkUu8EQERERkcGwG4x22LJORERERKRQrKwTERERESkUu8EQERERkcGwG4x22LJORERERKRQrKwTERERESkUu8EQERERkeGwF4xW2LJORERERKRQbFknIiIiIoPhDabaYcs6EREREZFCsbJORERERKRQ7AZDRERERAbDbjDaYcs6EREREZFCsbJORERERKRQ7AZDRERERAbDbjDaYct6Bvhs34pGDeqgYvky6NC2Fa5dvSJ3pBTJmXNkJw+cXdkTQftH49nvw7FjWjsUL2CnsU7z6iXx55xOeL53BKJP/IKyjg4ay22tLbDg54a4uXEAQg+OxYPfBmP+zw2RzcrcYK9j1YqlcCtbUmNqULuawY6vDaVfl1evXMbggf1Qv3Y1lHMpgePHjsodKVVKL8skSs8pwjlv2qgu3F1LJZtmz5wqd7RklH6+k4iQU4SMgDg5ybBYWU/HoYMHMGeWF3r36Q+fXXtRoYIbBvTtjcCAALmjaZA7Z3XXgvh172XUHLgBP4zaCmNjFfbN6YQsFqbqdbJYmOLC7ef4ZfWxFPeRx84aeeyt4fnrEbj3XIXes/9E/YqO+HVUU4O8hiSOjsXx9/Ez6sln958GPX5GyH2+MyI6OgpOJUpg7LiJckdJkwhlCYiRU4RzvmnrThw6dlo9LV+1DgBQt/73MifTJML5BsTIKUJGQJycZHgqSZIkuUPow4d43eznxw5tUcrZGRMmTlHPa9G0EWrXqYchw0bo5iA6oM+ctvWnab2NvU0WPN87AvWGbMS5f/01lhV0sMH93wajcq/V+Pfx6zT306pmKawf1wJ2jWYhITHtSzX40AStc35u1YqlOHniGLbv3JvpfaXExFg3P/3p+7rU9adCOZcSWLB4OerUraezferqV1S+x3V/vgH9nPP4hESd7SvJ/Dkzceb0Kez565BOfpo3NdFNGxivS90RISOg35wWCuv0bNd1u9wR1EI3dZQ7QrrYsp6GuNhY+N69gypVNbtBVKnqgZs3rsuUKjkl5kzquhL+NjrT+3kbFZNuRV2X/J89Q8O61dH0+7rwHD0cL148N9ixM0KJ51tUopSlKDlFExcXiwP7/0KzFq0U1YdWlPMtQk4RMgLi5CR5KOy7lrKEvwlHQkIC7Ow0+17b2dkjJCRYplTJKTHn7AENcO5ff9x9+uXHz5HNEp5dqmPdX9d0mCxtLmVcMXXGLBQsVBhhYaFYt3olenTpiB17/kL27LYGy5EWJZ5vUYlSlqLkFM3J48fw/t07NG3WUu4oGkQ53yLkFCEjIE5OnVHOd2MhKKKy7uvri4sXL6JKlSooWbIk7t27h8WLFyMmJgadO3dGnTp10tw+JiYGMTExGvMkY3OYm+vmxsTPW1wkSVJUK0wSpeRcOOR7lHHMhbo/e3/xPqyzmGGPVwf4PgvBjI2ndRcuHR7Va2j8XbZsOTRv0gD7/tyLzl27GyxHRijlfH8NRClLUXKK4o89u1HVozpy5sold5QUiXK+RcgpQkZAnJxkWLJ3gzl06BDKlSuHkSNHonz58jh06BBq1KiBR48ewd/fHw0bNsTx48fT3IeXlxdsbGw0prmzvTKdzTa7LYyNjRESEqIxPywsFHZ29pnev64oKeeCnxvih6pOaDhsM16GvPuifWS1NMOfszvhfXQs2v+yQy/9VDPKMksWFCvuBP9nz2TL8DklnW/RiVKWouQUSWDAS1z65wKat2ojd5RkRDnfIuQUISMgTk6Sh+yV9alTp2LUqFEIDQ3Fhg0b0KlTJ/Tu3RtHjhzB0aNHMXr0aMyaNSvNfXh6eiIiIkJjGjXGM9PZTM3MUMq5NC6eP6cx/+L583AtVz7T+9cVpeRcOPh7NK9eEt8P34Jnr9580T6ss5hh39wfERufgDbjfRATl6DbkFqKjY2F35PHsM+ZU9Ycn1LK+f4aiFKWouQUyZ9/7IFtjhyoVr2m3FGSEeV8i5BThIyAODl1RaVSKWYSgezdYO7cuYNNmzYBANq1a4cuXbqgdevW6uUdO3bEunXr0tyHuXnyLi+6Gg2mS7fuGD92NJxdXODqWh67d/ogMDAQbdt30M0BdETunIuGNkL7ui5oO8EH76Ni4GBrBQCIiIzBh9iPJ8PW2gIFctkgj701AMCp4Me+ea/D3uN1eCSyWn6sqFuam6L7zL3IlsUc2bJ8PK/BEVFINMBNpgvnzUaNWrWRO3dedZ/1yMj3aNqshd6PrQ25z3dGREVFwt//v5GAXr58gXv3fGFjY4M8efLKmEyTCGUJiJFTlHOemJiIv/74HT80bQETE9n/G0yRCOcbECOnCBkBcXKS4SnqU8rIyAgWFhbInj27ep61tTUiIiJky/R9o8aIeBOO1StXIDg4CMWKO2H5r6uRN28+2TKlRO6cfZu7AwCOLOqmMb/3rD+w5e9/AQBNqjphzdjm6mWbJ378Ujbd+xRmbDyN8k55UMk5PwDg7tZBGvsp0WEJ/F/r/zoICnqNcWNG4E34G9jmsEWZMq7w3uKDPDzfWrtz+zZ69+iq/nv+nI9d05o2b4lpM9L+tcyQRChLQIycopzzSxcv4FVgIJq1aCV3lFSJcL4BMXKKkBEQJycZnuzjrLu6umL27Nn4/vuPD6S4ffs2SpYsqW7tOHv2LLp27YonT55otV9dtazTl42zLgddjLOub7oaZ13fRHj6giC/XgpBhPMN6GecdV3T1TjrRLqktHHWc3b3kTuCWvCG9nJHSJfsp69///5ISPivX7KLi4vG8oMHD6Y7GgwRERER0ddI9sp6v3790lw+Y8YMAyUhIiIiIn0T5cZOpeDvdURERERECsXKOhERERGRQsneDYaIiIiIviHsBaMVtqwTERERESkUK+tERERERBm0YsUKFClSBBYWFnBzc8OZM2fSXH/r1q1wdXVFlixZkCdPHnTv3h2hoaEZPh4r60RERERkMCqVSjGTtnx8fDB06FCMHz8e169fR/Xq1dGoUSONpzd/Kul5QT179sSdO3ewc+dOXL58Gb169crwMVlZJyIiIiLKgAULFqBnz57o1asXSpUqhUWLFqFAgQJYuXJliutfvHgRhQsXxuDBg1GkSBFUq1YNffv2xZUrVzJ8TFbWiYiIiOibFBMTg7dv32pMMTExKa4bGxuLq1evokGDBhrzGzRogPPnz6e4TdWqVfHixQscOHAAkiTh9evX2LVrF5o0aZLhjKysExEREZHByN315dPJy8sLNjY2GpOXl1eKuUNCQpCQkAAHBweN+Q4ODnj16lWK21StWhVbt25F+/btYWZmhty5cyN79uxYunRphsuLlXUiIiIi+iZ5enoiIiJCY/L09Exzm8/7ukuSlGr/97t372Lw4MGYOHEirl69ikOHDsHPzw/9+vXLcEaOs05EREREBvMlN3bqi7m5OczNzTO0rr29PYyNjZO1ogcFBSVrbU/i5eUFDw8PjBo1CgBQtmxZWFlZoXr16pg+fTry5MmT7nHZsk5ERERElA4zMzO4ubnhyJEjGvOPHDmCqlWrprhNVFQUjIw0q9vGxsYAPrbIZwQr60REREREGTB8+HCsXbsW69evh6+vL4YNGwZ/f391txZPT0907dpVvX7Tpk3x+++/Y+XKlXjy5AnOnTuHwYMHo1KlSsibN2+GjsluMERERERkMErqBqOt9u3bIzQ0FFOnTkVgYCBcXFxw4MABFCpUCAAQGBioMeb6Tz/9hHfv3mHZsmUYMWIEsmfPjjp16mD27NkZPqZKymgbvGA+xMud4OthW3+a3BEyJPjQBLkjpMvEWIwPKBE+FQT+rFccEc43AMQnJModIV2mJvzBmpTHQmFNs3n7/i53BLWAVa3kjpAufqoQERERESmUwr5rEREREdFXjb+MaoUt60RERERECsWWdUpX2OFf5I6QITm+GyJ3hHSF/7NY7ggZIkJ/cFH6WYtQliJkBNgfnIi+TaysExEREZHBiDwajBzYTEFEREREpFBsWSciIiIig2HLunbYsk5EREREpFCsrBMRERERKRS7wRARERGRwbAbjHbYsk5EREREpFCsrBMRERERKRS7wRARERGR4bAXjFbYsk5EREREpFCsrBMRERERKRS7wRARERGRwXA0GO2wZZ2IiIiISKHYsk5EREREBsOWde2wZZ2IiIiISKFYWSciIiIiUih2gyEiIiIig2E3GO2wZZ2IiIiISKFYWc8An+1b0ahBHVQsXwYd2rbCtatX5I6UIqXnvHrlMgYP7If6tauhnEsJHD921OAZPMo7YtfC3nhyaCqiry5G01plNJZbWZph4ejWeHRgCsLOzcX1XZ7o3cZDYx0HO2usm9oZfn9PQ8jZOTi/dSRa1nU15MsAoPzznUTpOZVwXWaU0ssSECMjIEZOETICYuQUISMgTk4yLFbW03Ho4AHMmeWF3n36w2fXXlSo4IYBfXsjMCBA7mgaRMgZHR0FpxIlMHbcRNkyWFma4daDlxg2e1eKy+eMaIn6VUuh+y+bUa6NF5ZuPYkFo1rjh5ou6nXWTe0Cp0K50Hb4Gri3n40/jv+LzV4/wbVEPkO9DCHONyBGTiVclxkhQlmKkBEQI6cIGQExcoqQERAnpy6oVCrFTCJgZT0dmzduQMvWrdGqTVsUdXTEaM/xyJ0nN3b4bJc7mgYRclarXhODBg9D3foNZMtw+Lwvpqw8gD9O/Jvi8splimDLvks4c/UR/APDsH7PBfz7MAAVnAv+t07ZwljhcxpX7vjj6ctQzF53GG/eRaNcyQKGehlCnG9AjJxKuC4zQoSyFCEjIEZOETICYuQUISMgTk4yPEVW1iVJkjsCACAuNha+d++gStVqGvOrVPXAzRvXZUqVnCg5RXD+xhP8UKMM8ua0AQDUcC+G4gVz4uiFexrrtGlQAbbZskClUqFtg/IwNzPB6asPDZJRlPMtSk4RiFCWImQExMgpQkZAjJwiZATEyakzKgVNAlDkaDDm5ua4efMmSpUqJWuO8DfhSEhIgJ2dncZ8Ozt7hIQEy5QqOVFyimDE3N1Y8UsHPD40FXHxCUhMlNB/2nacv/FEvU4XT29s9voJASe8EBefgKgPsWg/ch38XoQaJKMo51uUnCIQoSxFyAiIkVOEjIAYOUXICIiTk+Qha2V9+PDhKc5PSEjArFmz1BftggUL0txPTEwMYmJiNOZJxuYwNzfXSc7P+zRJkqTIfk6i5FSygR1roJJLIbQeuhr+geGoVsERi8e2xauQtzhx6QEAYHL/JrDNZolG/ZYj9M17NK1VFltn/4R6vZbgzqNAg2UV5XyLklMEIpSlCBkBMXKKkBEQI6cIGQFxcpJhyVpZX7RoEVxdXZE9e3aN+ZIkwdfXF1ZWVhm6SL28vDBlyhSNeeN/mYQJEydnKp9tdlsYGxsjJCREY35YWCjs7OwztW9dEiWn0lmYm2LKwB/QfuQ6HDp7FwBw+1EAypbIh6Fd6uDEpQcokt8O/TvUQIW2XvB98goAcOthADzKF0XfttUx2GuH3nOKcr5FySkCEcpShIyAGDlFyAiIkVOEjIA4OXWFX0C0I2uf9RkzZiAiIgK//PILTpw4oZ6MjY3h7e2NEydO4Pjx4+nux9PTExERERrTqDGemc5namaGUs6lcfH8OY35F8+fh2u58pnev66IklPpTE2MYGZqgsREzXsmEhISYWT08YMli4UZACRfJ/G/dfSeU5DzLUpOEYhQliJkBMTIKUJGQIycImQExMlJ8pC1Zd3T0xP16tVD586d0bRpU3h5ecHU1FTr/ZibJ+/y8iFeNxm7dOuO8WNHw9nFBa6u5bF7pw8CAwPRtn0H3RxAR0TIGRUVCX9/f/XfL1++wL17vrCxsUGePHkNksHK0gyOBXKq/y6c1w5lnfIh/G0Unr8Kx+krDzFzSHNEx8TBPzAM1d2K4ccmFTFm4V4AwP2nr/HIPxjLxreD56I/EBoRiWa1yqJu5RJoNXSNQV4DIMb5BsTIqYTrMiNEKEsRMgJi5BQhIyBGThEyAuLkJMOT/QbTihUr4urVqxg4cCDc3d2xZcsWRf088n2jxoh4E47VK1cgODgIxYo7Yfmvq5E3r+HG1M4IEXLeuX0bvXt0Vf89f44XAKBp85aYNmOWQTJUcC6Iw6t/Vv89Z0RLAMDmv/5Bn8nb0HXcRkwd1BTe07vANlsW+L8Kx+QV+7Fm18fWjvj4RLQYvArTf26KXQv7IGsWMzx+HoJek7bi73N3DfIaADHONyBGTiVclxkhQlmKkBEQI6cIGQExcoqQERAnpy4oqZ4nApWklHESAfz2228YOnQogoODcevWLTg7O3/xvnTVsk6Acq6QtOX4bojcEdIV/s9iuSN8NUS5Lvl/EhHJzUL2pllNjiMOyh1B7fH8RnJHSJeiTl+HDh1QrVo1XL16FYUKFZI7DhERERGRrBRVWQeA/PnzI3/+/HLHICIiIiI94C+O2lHkE0yJiIiIiEiBLetERERE9PXiDabaYcs6EREREZFCsbJORERERKRQ7AZDRERERAbDXjDaYcs6EREREZFCsbJORERERKRQ7AZDRERERAbD0WC0w5Z1IiIiIiKFYmWdiIiIiEih2A2GiIiIiAyGvWC0w5Z1IiIiIiKFYss6ERERERmMkRGb1rXBlnUiIiIiIoViZZ2IiIiISKHYDYaIiIiIDIY3mGqHLetERERERArFyjoRERERkUKxG4zM4hIS5Y6QLlNjMb7TBZ5dIHeEdFWYeFjuCBlyeFQtuSOkyy6rmdwRMiQ+QZI7QrpMjPmb9LfkTVSc3BEyJJul8qsoRuzP8UVULDetiFELIyIiIiL6BrGyTkRERESkUMr/jYmIiIiIvhrsBaMdtqwTERERESkUW9aJiIiIyGB4g6l22LJORERERKRQrKwTERERESkUu8EQERERkcGwG4x22LJORERERKRQrKwTERERESkUu8EQERERkcGwF4x22LJORERERKRQbFknIiIiIoPhDabaYcs6EREREZFCsbJORERERKRQ7AZDRERERAbDXjDaYcs6EREREZFCsbJORERERKRQ7AaTAT7bt8J7wzqEBAfDsVhxjB47DhXc3OWOpSHo9WssXTQf58+exoeYGBQqVBi/TJmOUs6l5Y6mQWllef3qFWzZuB73fO8gJDgYcxYsQc069dTLJUnC2l+XY+/vO/Hu7VuUdimLUZ4TULRYcb1lcitsix7VC6N0PmvkymaBnzdfxzHfYPXyuzMbpLjdvIMPsP7MU/XfrgVsMKRBcZQtYIP4hETcC3yHvt7XEBOfqPPM2zauxdmTR+H/zA/m5hZwLuOKPgOHoUChIimuv2DWFOzfuwsDho5G6w5ddJ5HG1evXMbGDevge/c2goODsWDxctSpWy/9DQ1o1YqlWP3rco15dnb2OHzirEyJUqe093hqRMippIxbNqzB6RP/vcddypZD30HDULDwf+9xSZLgvWYF/tqzC+/evYVz6TIYOnoCijgWkyUzAKxbswrHjx7BU78nMLewgGu58hgybAQKFykqW6a0KOmc6xNHg9EOW9bTcejgAcyZ5YXeffrDZ9deVKjghgF9eyMwIEDuaGpv30agZ7dOMDExweIVq7Fzzz4MHTEa1tbWckfToMSyjI6OQnGnEhg5dkKKyzd7r8O2LRsxcuwEbNi6Azns7fFz/16IjIzUW6YsZsa4/+odpv91L8XlNWae1JjG77qNxEQJh2+/Vq/jWsAGq7tXwPmHIeiw4iLar/gH2y4+R6Ik6SXzv9evoFnrDli2divmLFmNhIQEjB7SF9HRUcnWPXvqGO7duQW7nLn0kkVb0dFRcCpRAmPHTZQ7SpocHYvj7+Nn1JPP7j/ljpSMEt/jKREhp9Iy3rx2BS3bdsTK9dswf9lqJCTEY+TPfTTe49s3rceObZswdNQ4rPL+DTns7DFiUG9E6fHzMj3XrlxG+46dsGmbD1auXo+E+Hj079ML0VHJP5vkprRzTsqhkiQ9/e8tsw/xutnPjx3aopSzMyZMnKKe16JpI9SuUw9Dho3I9P7jEjLfyrl00XzcvH4dazduyfS+UmJqrJvvdPouyw9xCZnavnI5Z42WdUmS0KR+TXT4sSu6du8FAIiNjUWjOtUxcOhwtGrTXutjVJ12TKv1785skKxl/XNLO5eDlbkxeqy7qp63vV8lnH8UiqVHH2udEQAOj6r1RdsleRMehtaNamLhyg0oW/6/VqHgoNcY1LMTZi9ehXHDB6J1h85f3LJul9UsUxlTUs6lhM5b1hMSM/8Ru2rFUpw8cQzbd+7NfKAUmBjrppVL3+9xXREhpz4zvomKy2w8vAkPQ/MGNbBklTdcK7hDkiS0alQbbTt2QaduPQF8/Lxs2bAm+v48DM1atdP6GNksdf/jf1hYGOrWqIq13pvh5l4x0/sz0mELsT7PuYXC+lG4TTshdwS1q7/UljtCutiynoa42Fj43r2DKlWracyvUtUDN29clylVcqdPnkCp0qUxZsRQ1K/pgU7tWmHPrh1yx9IgSll+KuDlC4SGhKBylarqeWZmZijv7o5bN27IF+wTdlnNUKOEPXZfeamel8PKDK4FsyMsMhZb+1bC6XE1sbG3OyoUym6wXJHv3wMArLPZqOclJiZi1pRxaNe5OwoXle9ncVH5P3uGhnWro+n3deE5ejhevHgudyQNorzHRcgpQsb3n73HA1++QFhoCNy/0/y8dK3gjtv/3pAjYorev38HALCxsUlnTcMS4ZzrkkqlnEkErKynIfxNOBISEmBnZ6cx387OHiEhqbd0GtrLF8+xe8dvKFiwEJb+ugat27bHvNkzse/PvXJHUxOlLD8VGhICAMiRw15jfo4c9ggNDZEjUjLNy+dFVEwCjtwJUs/Ln8MSADCwriN2XX6Bvhuu4e7Ld1jf0x2F7LLoPZMkSVi5eC5cXCugiON/fft/27wexsbGaNXuR71n+Nq4lHHF1BmzsGzlWkyYPA2hIcHo0aUj3rwJlzuamijvcRFyKj2jJElYvnAOypSroL5/Jyw06fNSM7NtDjv1MrlJkoT5c2ahfAU3FCvuJHccDUo/5yQvhf0wAoSHh2Pjxo14+PAh8uTJg27duqFAgQJpbhMTE4OYmBiNeZKxOczNzXWS6fMbISRJUtTNEYmJEpxLl8bAIcMAACVLOePJ40fYveM3/NCshbzhPqP0skxJsnwKytzKPR/23QxE7Cc3jRr9P9qOSy+w59rHvo6+gffxnWMOtHLLi4WHH+k105J5M/Dk0QMsXr1RPe/BvTv43WcLft24QzFlJxKP6jU0/i5bthyaN2mAfX/uReeu3WVKlTJR3uMi5FRqxkVzPr7Hl67ZlGxZipkhf2YAmDVjGh4+uI8Nm7bJHSVVSj3nuvY1viZ9kr1lPW/evAgNDQUA+Pn5wdnZGbNnz8bDhw+xatUqlClTBvfupXyjXRIvLy/Y2NhoTHNne2U6m212WxgbGyMkRLNVICwsFHZ29qlsZXj2Oe1RpKijxrwiRYri1atAmRIlJ0pZfsrO/mOu0FDNVo2w8NBkrUdycCucHUVzWmHX5Rca84PfxQIAHgdp3tT1JDgSebJb6jXT0nkzceHMScxfsQ45c+VWz7914xrehIehY4sGqO9RDvU9yuH1qwD8umQeOrVoqNdMXyPLLFlQrLgT/J89kzuKmijvcRFyKjnjorkzce70CSxauR65HP57j+ewS/q81Mz8JjwMtnbyf17OmjkNp04cx5r1m+CQO3f6GxiYks85yU/2yvqrV6+QkPDxxsBx48ahZMmSePz4MQ4fPoxHjx6hevXq+OWXX9Lch6enJyIiIjSmUWM8M53N1MwMpZxL4+L5cxrzL54/D9dy5TO9f11xLVcBz54+1Zj37NlT5MmTV55AKRClLD+VN19+2Nnb49KFC+p5cXGxuH7lCsqUKydfsP9r5ZYPt19E4P6r9xrzX4ZH43XEBxS21+zyUtg+CwLeROsliyRJWDJvBs6cOoZ5y9YhT978GsvrNWqKNVt2Y/WmnerJLmcutPvxJ8xe/KteMn3NYmNj4ffkMexz5pQ7ipoo73ERcioxoyRJWDRnBs6cOIpFK9cjTz7N93iefPmRw84eV/759PMyDjevXYFL2XIGTvsfSZIwa8ZUHD96BKvWeyNf/vzpbyQDJZ5zUg5FdYP5559/sHbtWmTJ8rGSYW5ujgkTJqBNmzZpbmdunrzLi65Gg+nSrTvGjx0NZxcXuLqWx+6dPggMDETb9h10cwAd6NSlG3p07YT1a1ahfsPvcefWLezZtRPjJ01Jf2MDUmJZRkVF4oW/v/rvgJcv8eCeL7LZ2CB3nrzo8GNXeK9bjQKFCqFAwULwXrsaFpYWaNjoB71lymJmjIKf9C3Pl8MSJfNYIyIqDoERHwAAVubGaFgmN+YeuJ/iPtafeYpB9Rxx/9V73At4i+YV8qJITisM3XZTL5mXzJ2BY4cPYNqcxchiZaXuo2pllRXmFhawsckOG5vsGtuYGJsgh519qmOxG0pUVCT8P7kGXr58gXv3fGFjY6OYL7wL581GjVq1kTt3XoSFhWLd6pWIjHyPpgrr5qbE93hKRMiptIwLZ0/Hsb8PYMa8JbDMYqW+pydr1o/vcZVKhbYdu2DrhjXIX6Ag8hcohC3ea2BuYYF6DZvIkhkAvKZPxcED+7BwyXJYWVmp+39nzWoNCwsL2XKlRGnnXJ/YC0Y7iqisJ/VdiomJgYODg8YyBwcHBAfLd3PF940aI+JNOFavXIHg4CAUK+6E5b+uRt68+WTL9LnSLmUwb+ESLFu8EGtXrUDefPkxYvRYNGrSVO5oGpRYlr537mBA75/Ufy+aPxsA0KRpC0ycNhNdfuqJmA8fMGfm1I8PRSpTFktWroWVlZXeMpXOlw0be/83pNjYJiUBAHuuvsT43XcAAI3L5oYKwP6br1Lcx+bz/jA3McKYxiVgk8UU9wPfodf6q3gepp+W9T9/9wEADB/QQ2P+qAnT8P0PLfRyTF25c/s2evfoqv57/pyPXeiaNm+JaTNmyRVLQ1DQa4wbMwJvwt/ANoctypRxhfcWH+RR0OcQoMz3eEpEyKm0jH/s/vgeH9JP8x6JsROno1HTFgCAjl17ICbmAxbOno73796iVOmymLd0NbLo8fMyPTt9tgMAenfvqjF/yvSZaNailRyRUqW0c07KIfs460ZGRnBxcYGJiQkePnyITZs2oWXLlurlp0+fRqdOnfDixYs09pKcrlrW9U0X46zrm67GWde3zI6zbgjajrMul8yOs24I+hhnXR90Mc66vulqnHUSgy7GWTcEfYyzrmu6HGddn5Q2znqlmSfljqB2aVwtuSOkS/bTN2nSJI2/k7rAJPnrr79QvXp1Q0YiIiIiIj3haDDaUVxl/XNz5841UBIiIiIiImURo38DEREREdE3SPaWdSIiIiL6drAXjHbYsk5EREREpFBsWSciIiIig+ENptphyzoRERERkUKxsk5EREREpFDsBkNEREREBsNeMNphyzoRERERkUKxsk5EREREpFDsBkNEREREBsPRYLTDlnUiIiIiIoViyzoRERERGQwb1rXDlnUiIiIiIoViZZ2IiIiISKHYDYaIiIiIDIY3mGqHLetERERERArFyjoRERERkUKxGwwRERERGQy7wWiHlXWZmRjxxw1dMTNWflkeGV1L7ggZUm3KEbkjpMt3bhO5I2SIibHy/1MKCP8gd4QMyWtrIXeEr0L2LKZyR8iQREmSOwKRIii/dkNERERE9I1iyzoRERERGQx7wWiHLetERERERArFlnUiIiIiMhjeYKodtqwTERERESkUK+tERERERArFbjBEREREZDDsBaMdtqwTERERESkUK+tERERERArFbjBEREREZDAcDUY7bFknIiIiIlIoVtaJiIiIiBSK3WCIiIiIyGDYC0Y7bFknIiIiIlIotqwTERERkcEYsWldK2xZJyIiIiJSKFbWiYiIiIgUit1giIiIiMhg2AtGO6ysZ4DP9q3w3rAOIcHBcCxWHKPHjkMFN3e5Y2m4euUyNm5YB9+7txEcHIwFi5ejTt16csdKRullucNnO3b5bEdAwEsAQFHHYujTbyCqVa8hW6Zt3mtx5uRR+D/zg7m5BUqXcUXvQcNQsFAR9Trea1bgxJGDCH79GiamJnAq6Yye/QajlEtZveWqVDQH+tQpCpf8NnCwsUCfdVdw5PZr9fIsZsYY80NJ1C/jANssZngRHg3v037Yet5fvc6Mti7wcLKHQzYLRMbG45pfOGbtu4cnQZF6y50SpV+XSZSUc9+eHdi/dwdeBwYAAAoVcUSnn/qiYpVqiI+Pw8bVy3Dl4lkEBryAlZU1yrtXRvf+Q2Bnn0uWvJ9TUlmmRoSMgLJzrluzCsePHsFTvycwt7CAa7nyGDJsBAoXKSp3tBQpuSxJPuwGk45DBw9gziwv9O7THz679qJCBTcM6NsbgQEBckfTEB0dBacSJTB23ES5o6RKhLJ0cHDAz0NHYOtvu7D1t12oVPk7DBs8EI8fPZQt083rV9C8TQcsW7cVc5esRkJCAkYP7ovo6Cj1OgUKFsLgkeOwdttuLF69Cbnz5MPowX3xJjxMb7kszYzh+/ItJu2+k+LyX1o4o0bJnBi25QbqzTqF9aeeYHKr0qjv4qBe5/aLCIze/i/qzTqFbqsuQaVSYVO/yjAyYKuLCNcloLyc9jlzoXu/IViydhuWrN0G1wqVMNVzCJ49eYSYDx/w+ME9dOzWB8vW+2DCjAV48fwZpowZIkvWzymtLFMiQkZA+TmvXbmM9h07YdM2H6xcvR4J8fHo36cXoqOi0t/YwJReliQflSRJktwh9OFDvG7282OHtijl7IwJE6eo57Vo2gi169TDkGEjMr1/fZR+OZcSOm1Z19XPVfouy8RE/VzKNT0qY+iIUWjZqk2m9xUeFZfpfbwJD0Or72ti4a8b4Fo+5RaXyPfv0bRuFcxbtgYVKn6n9TGqTTmi1fp+C5ska1k/NLoG9l8PwNIjj9Tz/hxeDSd9g7Dg4IMU91MyjzUOjq6BmtNPwD807f9Mfec20SpjavR9XeqKPnMGhH/IbDwAQNtG1dFr4DA0/KFVsmX3fW9jaO8fsXHXIeTKneeL9p/X1iKzEQGIcc5FyAjoN2eiHv6DDAsLQ90aVbHWezPc3Ctmen+6HNVEn2VpobB+FA1X/CN3BLW/B1SWO0K62LKehrjYWPjevYMqVatpzK9S1QM3b1yXKZWYRCzLhIQEHDq4H9HRUSjrWk7uOGqR798DALJls0lxeVxcHPbt3QWrrNZwLF7CkNE0XPELQ10XBzjYmAMAvitmhyI5rXD6XnCK61uaGaNN5fzwD41C4Jtog2QU5bpUes6EhAScPHoQHz5Eo2Rp1xTXiXr/HiqVClbW1gZOp0npZQmIkREQJ+en3r9/BwCwsUn581MuIpYlGY7CvmspS/ibcCQkJMDOzk5jvp2dPUJCUq5wUMpEKsuHD+6jW+eOiI2NgWWWLJi/aBkcHYvJHQsAIEkSViyeizKuFVDEsbjGsgtnT2HahFGI+fABOexzYu7S1bDJbitTUmDK73fg1b4sLk6uh7iERCRKEjx9buGKX7jGep09CmFs05KwMjfBo9fv0WXlP4hLMMwPfqJcl0rN6ff4IYb364LY2FhYWmbBLzMXolARx2TrxcbEYMOvi1GrfiNYWWWVIel/lFqWnxIhIyBOziSSJGH+nFkoX8ENxYo7yR1Hg2hlSYYle2X9+vXryJ49O4oU+Xiz3JYtW7By5Ur4+/ujUKFCGDRoEDp06JDmPmJiYhATE6MxTzI2h7m5uU4yqj77mUuSpGTzKGNEKMvCRYrgt1178O7dWxw7chgTJ4zF2g2bFVFhXzJ3Bp48eoAlqzYmW1bOrSLWbN6FiDfh2P/HbkwdNxLL12+FbQ67FPakfz9VL4LyhbKj19rLeBkWjUqOOTC1tQuC3n7AuQeh6vX+uPoSZ+8HI1c2C/SuXRTLulVAmyXnERufaLCsIlyXgPJy5i9YGMs37MD79+9w7uRRzJ/xC+YsXadRYY+Pj8OsyWOQKCVi4IjxsmX9nNLKMiUiZATEyTlrxjQ8fHAfGzZtkztKqkQpy8wy5H1JXwPZu8H07NkTT58+BQCsXbsWffr0gbu7O8aPH4+KFSuid+/eWL9+fZr78PLygo2NjcY0d7ZXprPZZreFsbExQkJCNOaHhYXCzs4+0/v/lohUlqamZihYsBBKly6DwUNHwMmpJLZv2SR3LCyZNxPnz5zEghXrkNMhd7LllpZZkK9AQTiXccWoCVNhbGyMg3/uMXxQAOamRhjZpASm/+GLY3eCcC/wHTadfYb9NwLQu5bmKAzvPsTjaUgULj0JwwDvq3DMZYWGZZK/Pn0Q5bpUak5TU1PkzV8QTiVLo3u/ISjq6IQ/dm5VL4+Pj8PMX0bhVcBLzFy4SvZWdUC5ZfkpETIC4uQEgFkzp+HUieNYs34THHIb5vNFGyKVJRme7JX1+/fvw9HxYyvMihUrsGjRIixevBj9+vXDwoULsWrVKsyfPz/NfXh6eiIiIkJjGjXGM9PZTM3MUMq5NC6eP6cx/+L583AtVz7T+/+WiF2WEmJjY+U7uiRh8dwZOHPyGOYvX4c8efNnbDtIiI2TJ7epkRHMTIyS3fSbkCjBKJ0mFZVKBTMTw3w0iXJdipJTgoS4uI83USdV1ANe+GPmolXIZpNd3nD/J0JZipARECOnJEmYNWMqjh89glXrvZEvf8Y+Pw1NhLLUJZVKpZjpS6xYsQJFihSBhYUF3NzccObMmTTXj4mJwfjx41GoUCGYm5vD0dEx3YboT8neDcbS0hLBwcEoWLAgXr58icqVNe/KrVy5Mvz8/NLch7l58i4vuhoNpku37hg/djScXVzg6loeu3f6IDAwEG3bp901x9CioiLh7//f+NUvX77AvXu+sLGxQZ48eWVM9h8RynLp4gXwqFYDuXPnRmRkJP4+dABXLl/C8pVrZMu0eO4MHPv7AKbPXYwsVlYIC/3Y8mJllRXmFhaIjo7C1g1rULV6LeSwz4m3EW/w524fBAe9Rs26DfSWK4uZMQrZW6n/LmCXBaXyZkNEVCwC3nzAxUeh8GxWCh/iEvAyPBqVHe3Qyj0/pv9x9//rW+KHcnlx5n4wwt7HwsHGAv3qOuJDXAJO+gbpLffnRLguAeXl9F61BO7fVUPOXA6IiorCqaOHcOv6FUybvwIJ8fGYMWEkHj3wxZTZS5GYmKi+bq2z2cDU1FSWzEmUVpYpESEjoPycXtOn4uCBfVi4ZDmsrKzU/b+zZrWGhYVuRhfSFaWXJX3k4+ODoUOHYsWKFfDw8MCqVavQqFEj3L17FwULFkxxm3bt2uH169dYt24dihUrhqCgIMTHZ7yiKvvQjV26dIG5uTnWrl2Ldu3aoUSJEpg2bZp6uZeXF7Zv345///1Xq/3qqrIO/P8hBevXITg4CMWKO2HUGE+dDPkE6G7oxsuX/kHvHl2TzW/avCWmzZiVqX3rsrucPstSF0M3Tp44Hpf+uYCQ4GBktbZG8eIl0L1HL3xX1UMHCb9s6MY6lcukOH/0L9Pw/Q8tEBsTg+kTx8D3zi28fROObDbZUaJUaXTu0RclnV2+KGdGhm6s7JgDvw2qkmz+rkvPMWr7v7C3NsfoJiVQvUROZM9iipfh0dh+wR/rTn388p0rmzlmtS+LMgVskM3SFCHvYnDpSRiW/v0QT4LTfyiSroZuBPR7XeqSvnJ+ydCNC70m4cbVSwgLDYaVVVYUcXRC287dUaFiFbwOfImf2jZOcbvZS9aibIUvy6yroRsBMc65CBkB/eXUxdCN5V1Kpjh/yvSZaNYi+RCj2tLl0I2A/spSaUM3Nv71ktwR1A70q6TV+pUrV0aFChWwcuVK9bxSpUqhRYsW8PJK3gX70KFD6NChA548eYIcOXJ8UUbZK+sBAQHw8PBAwYIF4e7ujpUrV8LNzQ2lSpXC/fv3cfHiRezZsweNG6f8wZ8aXVbW9UmEUe5FubdFX+Os65Iuxlk3BG3HWZeDLivr3zpdjbOub7qsrJPy6WOcdV3TdWVdX5RWWW+ySjmV9d9/ck02SElKPTYAIDY2FlmyZMHOnTvRsmVL9fwhQ4bgxo0bOHXqVLJtBgwYgAcPHsDd3R2bN2+GlZUVmjVrhmnTpsHS0jJDGWXvs543b15cv34dVapUwaFDhyBJEi5duoTDhw8jf/78OHfunNYVdSIiIiKi9KQ0SElKLeQAEBISgoSEBDg4OGjMd3BwwKtXr1Lc5smTJzh79ixu376NPXv2YNGiRdi1axcGDhyY4YyK+K6VPXt2zJo1C7NmZa67BhERERFRRnl6emL48OEa89Ib+lubITYTExOhUqmwdetW9cO4FixYgDZt2mD58uUZal1XRGWdiIiIiL4NKiin+1BqXV5SYm9vD2Nj42St6EFBQcla25PkyZMH+fLl03hqbqlSpSBJEl68eIHixYunuN2nZO8GQ0RERESkdGZmZnBzc8ORI5r3dR05cgRVq1ZNcRsPDw8EBATg/fv36nkPHjyAkZER8mdwKFFW1omIiIjIYIxUypm0NXz4cKxduxbr16+Hr68vhg0bBn9/f/Tr1w/Ax241Xbv+Nzpfp06dYGdnh+7du+Pu3bs4ffo0Ro0ahR49emT4BlN2gyEiIiIiyoD27dsjNDQUU6dORWBgIFxcXHDgwAEUKlQIABAYGKjx3JusWbPiyJEj+Pnnn+Hu7g47Ozu0a9cO06dPz/AxZR+6UV84dKPuCDIyFYdu1CEO3fht4dCNpEQculF3lDZ0Y7PVl+WOoPZnH+U9u+BzCjt9RERERPQ1S23kFEoZ+6wTERERESkUK+tERERERArFbjBEREREZDDsBaMdtqwTERERESkUK+tERERERArFbjBEREREZDCiDHmpFGxZJyIiIiJSKLasExEREZHBsGFdO2xZJyIiIiJSKFbWiYiIiIgUit1giIiIiMhgVOwHoxW2rBMRERERKRRb1mUmQZI7QrqiYxLljpAhWcyN5Y6QrhxWZnJHyBDfuU3kjpAu24Yz5Y6QIeF/j5M7Qrry2lrIHSFDJOV/XPLGOR3i8H5EH7GyTkREREQGw+9h2mE3GCIiIiIihWJlnYiIiIhIodgNhoiIiIgMhvcjaIct60RERERECsWWdSIiIiIyGLara4ct60RERERECsXKOhERERGRQmWoG4y/v79WOy1YsOAXhSEiIiKir5uKN5hqJUOV9cKFC2tVsAkJCV8ciIiIiIiIPspQZX39+vX8FkREREREZGAZqqz/9NNPeo5BRERERN8CI7b/aiVTN5hGR0fj5cuXiI+P11UeIiIiIiL6vy+qrJ84cQJVqlSBtbU1ChUqhH///RcAMHDgQPz+++86DUhERERE9K3SurJ+/PhxNGjQAB8+fMDIkSORmJioXmZvbw9vb29d5iMiIiKir4hKpVLMJAKtK+sTJ05E48aNcf36dUyfPl1jmaurK27cuKGrbERERERE37QM3WD6qevXr2Pnzp0Ako+TmTNnTgQFBekmGRERERF9dQRp0FYMrVvWTUxMEBcXl+KyoKAgWFtbZzoUERERERF9QWW9YsWK2Lx5c4rLdu3ahSpVqmQ6lNL4bN+KRg3qoGL5MujQthWuXb0idyQN69aswo/t28CjUgXUqVEVwwYPxFO/J3LHwvWrVzByyAA0bVATVSo449SJo+pl8XFxWL54Pn5s1xy1q7qhaYOamPLLWAQHK+OXGaWf86tXLmPwwH6oX7sayrmUwPFjR9PfSCZyluXIjlVwdvlPCPprBJ7tGoIdU1ujeP4cGus0r1YCf87qgOe/D0X0sXEo65gr2X4cbK2wbmxT+O0cjJB9I3H+1x5oWaOkoV6GmtKvS0D5Gfne0T0RcoqQERAnJxmW1pX1sWPHYs+ePWjZsiX+/PNPqFQq/PPPPxg0aBB27dqF0aNH6yOnbA4dPIA5s7zQu09/+OzaiwoV3DCgb28EBgTIHU3t2pXLaN+xEzZt88HK1euREB+P/n16IToqStZcHz5EobhTCYwYMyGFZR9w/95ddO/VD97bdsFr3hI8f/YUo4cOlCGpJhHOeXR0FJxKlMDYcRPljpImucuyetmC+PXPq6g5aCN+GL0dxsZG2DenI7JYmKrXyWJhigt3XuCXtSdS3c86z2ZwKmCHthN2wr33Wvxx5j42T2gB12IOhngZAOQvy4wQISPfO7olQk4RMgLi5NQFuW8qFe0GU5UkSZK2G23ZsgVDhw5FWFiYel727NmxdOlS/PjjjzoN+KU+6Gjo9x87tEUpZ2dMmDhFPa9F00aoXacehgwbken9J2pf/OkKCwtD3RpVsdZ7M9zcK2Z6fx9iE9NfKR1VKjhj1vwlqFm7Xqrr3L1zCz27tMee/UeRO09erY+Rxdw4MxHV9HnO9XC6Uc6lBBYsXo46dVMvW23p6vNLn2Vp23Cm1tvY22TB89+Hot7QzTh367nGsoIONri/bSAq91mLfx9r/sITvG8kBi86hO1Hb6vnvdgzFONXn8DGgzfTPGb43+O0zpkSfX8W6YK+M+r6/fOtvnd0SYScImQE9JvTQus7FPWr67Z/5Y6gtqlTWbkjpOuLxlnv3Lkznj9/jsOHD2PLli04dOgQnj9/rpiKuq7ExcbC9+4dVKlaTWN+laoeuHnjukyp0vf+/TsAgI2NjcxJtPP+/TuoVCpYW2eTLYOo51yJlFiW2azMAQDh7z5otd35W8/RpnYp2FpbQKUC2tZ2hrmpCU7feKaPmMkosSw/J0JGUYhSliLkFCEjIE5OkscXf9eytLREvXqZb434+eef0a5dO1SvXj3T+9K18DfhSEhIgJ2dncZ8Ozt7hIQEy5QqbZIkYf6cWShfwQ3FijvJHSfDYmJisHLJQjT4vgmssmaVLYeI51yplFiWs/vXxblbz3H3qXbH7zJ9LzZPaIGAvcMRF5+AqA9xaD9pF/wC3+gn6GeUWJafEyGjKEQpSxFyipARECenrhiJ0ftEMb6osv727VssX74cJ06cQGhoKOzs7FC7dm30798f2bNn12pfy5cvx4oVK+Do6IiePXuiW7duyJ07t1b7iImJQUxMjMY8ydgc5ubmWu0nNZ/3aZIkSbH9nGbNmIaHD+5jw6ZtckfJsPi4OEz0HIFEKRGjPJXRj1Skc650SinLhYMbokzRXKg7JOUb5NMyuXtN2FpboNHIbQiNiEJTDydsndgK9YZuxh0/w/1HqpSyTIsIGUUhSlmKkFOEjIA4OcmwtO4G4+fnh7Jly2L8+PF4+PAhzMzM8PDhQ4wfPx6urq548kT7UUgOHz6Mxo0bY968eShYsCCaN2+Offv2aTwdNS1eXl6wsbHRmObO9tI6x+dss9vC2NgYISEhGvPDwkJhZ2ef6f3r2qyZ03DqxHGsWb8JDlp+4ZFLfFwcxo8djoCXL7FkxTpZW9UB8c65kimpLBcMaoAfqhRHwxFb8TLknVbbFsmTHf1buqPv3P04ef0pbj0JwszNZ3HtfiD6NnfTU2JNSirL1IiQURSilKUIOUXICIiTU1fkvqlUtBtMta6sDxkyBB8+fMC5c+fg5+eHCxcuwM/PD2fPnkVMTAyGDh2qdYgyZcpg0aJFCAgIwJYtWxATE4MWLVqgQIECGD9+PB49epTm9p6enoiIiNCYRo3x1DrH50zNzFDKuTQunj+nMf/i+fNwLVc+0/vXFUmSMGvGVBw/egSr1nsjX/78ckfKkKSK+gv/Z1jy6zrYaPmrjD6Ics5FoJSyXPhzAzSvXgLfj9yKZ68itN4+aeSYz28GT0iUYGSgD3qllGVaRMgoClHKUoScImQExMlJ8tC6G8zx48exePHiZOOpV61aFdOnT/+iynoSU1NTtGvXDu3atYO/vz/Wr18Pb29vzJo1CwkJCaluZ26evMuLrkaD6dKtO8aPHQ1nFxe4upbH7p0+CAwMRNv2HXRzAB3wmj4VBw/sw8Ily2FlZaXu35Y1qzUsLCxkyxUVFYkXz/3Vfwe8fIkH932RLZsN7HPmwrjRQ3H/ni/mLV6BxIQEhP4/dzYbG5iamskVW4hzHhUVCX///8r25csXuHfPFzY2NsjzBSPp6IvcZblocEO0r1sabX/ZhfdRsXCwtQIARETG4EPsxw8JW2sLFMiVDXnsPj7QzanAxz6jr8Mi8To8Evf9Q/HoRRiWDWsEz1+PIfRtNJpVc0JdtyJoNX6HQV4HIH9ZZoQIGfne0S0RcoqQERAnJxme1kM32tnZYfv27WjQoEGyZYcPH0bHjh0RGhqa4f0ZGRnh1atXyJUr+YNIgI+txkePHkX9+vW1iamzyjrw8SEF3uvXITg4CMWKO2HUGE+dDIkI6GboxvIuKT+cZcr0mWjWolWm9/+lQzdeu3IJA/v8lGx+46Yt0KvvQLT6IeVzuny1Nyq4V9L6eLoauhHQ3znX1dBzly/9g949uiab37R5S0ybMSvT+9dlg7G+yjIjQzdGH0t52MTec/7Clr9vAQA6NyyDNaObJltn+sYzmLHpDADAMZ8tpveqjSplCiCrhSkeB4Rj0Y5/NIZyTI2uhm4E9PtZpCv6zKiL9w/fO7onQk4RMgL6y6m0oRt7/HZL7ghq6zuUkTtCurSurPfo0QPGxsZYs2ZNsmW9e/dGbGwsNm7cmOH9FSlSBFeuXEl2B3Rm6bKyrk/6GGdd13Qxzroh6LKyri8CnG4Auq1w6MuXjLMuB11W1r91Irx/RHjv0LeHlfXUiVBZz9Dpu3btmvrfnTp1Qs+ePdG2bVt06tQJuXPnxqtXr7B161ZcuXIF69at0yqAn5+fdomJiIiIiL4RGaqsu7u7a9wxK0kSnj9/jt9//11jHgA0aNAgzf7lRERERPTtMtTN+V+LDFXWN2zYoO8cRERERET0mQxV1rt166bvHERERERE9BmF3XJARERERF8z9oLRzhdV1sPCwrBt2zb4+voiOjpaY5lKpdL6JlMiIiIiIkpO68q6v78/KlasiKioKERFRcHe3h5hYWFISEiAra0tbGxs9JGTiIiIiL4CKjata8VI2w3Gjh2L0qVL4/Xr15AkCQcPHkRkZCSWLl0KCwsL7N+/Xx85iYiIiIi+OVpX1i9cuID+/furH2MvSRLMzMwwcOBA9OzZE6NGjdJ5SCIiIiKib5HWlfXXr18jT548MDIygrGxMd6+fateVrNmTZw9e1anAYmIiIjo66FSKWcSgdaVdQcHB4SFhQEAChcujCtXrqiXPX36FCYmHGCGiIiIiEgXtK5Zf/fdd7h+/TqaNWuGVq1aYerUqYiJiYGZmRnmzp2LOnXq6CMnEREREdE3R+vK+siRI/H06VMAwMSJE+Hr64tJkyZBkiTUqFEDixYt0nFEIiIiIvpaGInS/0QhtK6su7m5wc3NDQBgZWWFP//8E2/fvoVKpYK1tbXOAxIRERERfau07rOekmzZssHa2hqnT59mNxgiIiIiIh3R6d2gwcHBOHXqlC53SURERERfEfaC0Y5OWtaJiIiIiEj3OM4iERERERmMik3rWmHLOhERERGRQrGyTkRERESkUBnqBlO2bNkM7ezt27eZCvMtEmGs0SzmxnJH+GoIcLqFEf73OLkjZIhtk3lyR0hX+P6RckfIkERJkjtCuqI+JMgdIV3WluwBS/JiS7F2MvSOzZEjR4b6F9nZ2aFIkSKZDkVERERERBmsrJ88eVLPMYiIiIiI6HP8LYyIiIiIDIajwWiH3YaIiIiIiBSKLetEREREZDBGbFjXClvWiYiIiIgUipV1IiIiIiKFYjcYIiIiIjIYdoPRzhdX1u/du4dTp04hJCQEPXv2RO7cuREQEABbW1tYWlrqMiMRERER0TdJ68p6QkIC+vTpA29vb0iSBJVKhUaNGiF37tzo27cvypcvj6lTp+ojKxERERHRN0XrPuszZszAtm3bMHfuXNy+fRvSJ49/btSoEQ4dOqTTgERERET09VCpVIqZRKB1y7q3tzd++eUXDB8+HAkJCRrLihQpAj8/P52FIyIiIiL6lmndsv7y5UtUqVIlxWUWFhZ49+5dpkMREREREdEXVNZz5cqFJ0+epLjs/v37yJ8/f6ZDEREREdHXyUilnEkEWlfWGzdujBkzZuDly5fqeSqVChEREViyZAmaNm2q04BERERERN8qrSvrU6dORXx8PJydndG6dWuoVCqMGzcOLi4u+PDhA3755Rd95CQiIiKir4BKpZxJBFpX1h0cHHD58mV07NgRV69ehbGxMW7evIlGjRrh/PnzyJEjhz5yEhERERF9c77ooUgODg749ddfdZ2FiIiIiIg+oXXL+rfIZ/tWNGpQBxXLl0GHtq1w7eoVuSOlSIScImQExMgpQkZAjJxyZ/RwyY9dU1riybZ+iP57JJpWKZZsnRIFcmDn5BZ49fvPCNozGKcWdUKBnNbq5UsH18edDb0Q9ucQ+PsMwI7JLeBUwPC/dMpdlunZ6bMd7Vo1Q/Xv3FD9Ozd0+7E9zp05LWumG9euYPSwAWj+fS1Ucy+N0yePqZfFx8dhxZL56Nq+BepVc0fz72th2kRPhAQHyZhYk9LPOSBGRkCcnJllpFIpZhKB1pX1Hj16pDn17NlTHzllc+jgAcyZ5YXeffrDZ9deVKjghgF9eyMwIEDuaBpEyClCRkCMnCJkBMTIqYSMVhamuPUkCMOWH0txeZE8Nji2oCMePA9Dw1E+qNR/I7y2XcSH2P+edXH94Wv0mX8I5XpvQLPxu6ACsG9mGxgZcLgDJZRlenI5OGDw0BHY8tsubPltFypW/g7DBg/E40cPZcsUHR2NYsVLYPjo8cmWffjwAQ/u+aJbr35Yv2UnZsxdjOf+TzFm+CAZkiYnwjkXISMgTk4yPJX06SNIM6Bw4cLJnvgUGhqK9+/fI3v27MiePXuqQzsa0od43eznxw5tUcrZGRMmTlHPa9G0EWrXqYchw0bo5iA6IEJOETICYuQUISMgRk59Z7RtMk+r9aP/Hol2k/firwuP1PM2ef6AuPgE9Jx7MMP7cSlij8u//gTnn9bALzAizXXD94/UKmNq9F2WCYla/XeVYbU8KmPoiFFo0apNpvcVFZOQ/kppqOZeGjPnLUGNWnVTXcf3zi307tYBu/YdQe7cebU+hrXlF/WATRHf47qjz5wWujvlOjH2wAO5I6jNauwkd4R0ad2y/vTpU/j5+WlMb9++xdGjR5ErVy788ccf+sgpi7jYWPjevYMqVatpzK9S1QM3b1yXKVVyIuQUISMgRk4RMgJi5BQho0oFfF+pKB6+DMefM1rjmc8AnF78Y4pdZZJkMTdF1wYu8At8gxfBhnlQnQhl+bmEhAT8fXA/oqOjUNa1nNxxMuz9+/dQqVSwzppN1hwinHMRMgLi5NQVIwVNItBZzjp16mDQoEEYMmSI1tsuXboU3bp1w44dOwAAmzdvhrOzM0qWLIlx48YhPl5HzeRaCn8TjoSEBNjZ2WnMt7OzR0hIsCyZUiJCThEyAmLkFCEjIEZOETLmyp4F1lnMMLJ9ZRy58hRNPXfiz3MP8dvE5qhWRvMhdH1+KIfgvYMR+ucQ1HcvgiaeOxEXn2iQnCKUZZKHD+7Do1IFfOdWFjOmTcb8RctQ1DH1Lz9KEhMTg1+XLUT975vAKmtWWbOIcM5FyAiIk5PkodMfRpydnTF27Fittpk2bRrmzp2LBg0aYMiQIfDz88PcuXMxbNgwGBkZYeHChTA1NcWUKVNS3UdMTAxiYmI05knG5jA3N/+i1/G5z7v9SJKUbJ4SiJBThIyAGDlFyAiIkVPJGZNugNp34RGW7rkKAPj3STAqO+dF7yauOHvrhXrd347fxbFrT5E7R1YMbeOOLeObos6w7YiJy1zXDG0ouSyTFC5SBNt37cH7d29x7MhhTJwwFms3bFZ8hT0+Pg6Tx42ElJiIEWOU80wTEc65CBkBcXKSYen0F4BTp07B3t5eq228vb3h7e2NXbt24dChQxg/fjwWL16M8ePHw9PTE6tWrcK2bdvS3IeXlxdsbGw0prmzvTLzUgAAttltYWxsjJCQEI35YWGhsLPT7nXqkwg5RcgIiJFThIyAGDlFyBjyNhpx8QnwfRaqMf/+8zAUyKXZDeJtVCweB7zBudsv0Gn6nyhRwA7NPYobJKcIZZnE1NQMBQsWgnPpMvh56Ag4OZXEti2b5I6Vpvj4OPwydgQCAl5g4fK1sreqA2KccxEyAuLk1BW5H4T01T8UaerUqcmm8ePHo2nTppgxYwY6duyo1f4CAwPh7u4OAHB1dYWRkRHKlSunXl6hQgUEpHMntKenJyIiIjSmUWM8tX1pyZiamaGUc2lcPH9OY/7F8+fhWq58pvevKyLkFCEjIEZOETICYuQUIWNcfCKuPngFp/y2GvOL57OFf9DbNLdVATAzNdZjuv+IUJapkSAhLjZW7hipSqqov/B/hkUr1sEme3a5IwEQ45yLkBEQJyfJQ+tuMJMnT042z9zcHIULF8bUqVMxatQorfaXO3du3L17FwULFsTDhw+RkJCAu3fvonTp0gCAO3fuIFeuXGnuw9w8eZcXXY0G06Vbd4wfOxrOLi5wdS2P3Tt9EBgYiLbtO+jmADoiQk4RMgJi5BQhIyBGTiVktLIwhWPe7Oq/C+e2QdmiORH+7gOeB7/Dwp2XsXlcU5y9/QKnbj5HA/ciaPydIxqO8lGv36ZmCRy7+gwhEVHIa58VI9pVQnRsPP6+5Gew16GEskzP0sUL4FGtBnLnzo3IyEj8fegArl6+hGUr18iWKSoqEi+f+6v/Dnz5Ag/v+8Laxgb29rkwYfQwPLjvi9kLlyMxIQGh/+/DnM3GBqamZnLFBiDGORchIyBOTl0QZXxzpdC6sp6YqNublTp16oSuXbuiefPmOHbsGMaMGYORI0ciNDQUKpUKM2bMQJs2mR9O60t936gxIt6EY/XKFQgODkKx4k5Y/utq5M2bT7ZMKREhpwgZATFyipARECOnEjJWcMqNw3Pbq/+e0682AGDz4dvoM/8Q/jz/CD8vOYJRHSpjfv86ePAiHB2n/YHzd14CAGJi4+Hhkh+DWrrBNqsFgt5E4uytF6g9bBuCI6IM9jqUUJbpCQsNxS/jRiMkOBhZra1RvHgJLFu5Bt9V9ZAt0727dzC4X3f130sXzgEANPqhOXr0GYizp08AALp3aq2x3ZJfN6CCeyXDBU2BCOdchIyAODnJ8LQaZz06Oho9e/bEgAEDUK1atfQ3yICEhATMmjULFy9eRLVq1TBmzBj89ttvGD16NKKiotC0aVMsW7YMVlZWWu1XVy3rRESZoe0463LQ1Tjr+qavcdZ1KbPjrBuCLsdZJzEobZz1Xw7J9xCyz0373jD39WSG1g9FsrKywsGDB1GjRg19ZdIJVtaJSAlYWdcdVtZ1g5X1b4/SKusT/1ZOZX1qQ+VX1rW+wbRcuXK4ffu2PrIQEREREdEntK6sz5o1C3PmzMGpU6f0kYeIiIiIiP4vQz+MnD59GhUqVEDWrFkxYMAAvH//HnXq1IGtrS3y5MmjMWC/SqXCzZs39RaYiIiIiMRlxMFgtJKhynrt2rVx4cIFVKpUCXZ2dlo/+IiIiIiIiLSXocr6p/egnjx5Ul9ZiIiIiIjoEwq7P5iIiIiIvmZ8KJJ2MnyDqYoFS0RERERkUBluWa9duzaMjNKv26tUKkRERGQqFBERERF9ndj+q50MV9Zr1aqFnDlz6jMLERERERF9IsOV9YkTJ6JSpUr6zEJERERERJ/gDaZEREREZDAcZ107Wj/BlIiIiIiIDIOVdSIiIiIihcpQN5jExER95yAiIiKib4AK7AejDbasExEREREpFG8wJSIiIiKD4Q2m2mHLOhERERGRQrGyTkRERESkUOwGQ0REREQGw24w2mFlndIVnyDJHSFDEiXl5zQxFuMT6uyjELkjpKtG8ZxyR8iQ8P0j5Y6QrpZr/pE7Qobs6V1Z7gjpsrbkf6u6Ehev/JHoTE3YQYH0j1cZEREREZFCsQmAiIiIiAxGpRLjV2alYMs6EREREZFCsbJORERERKRQ7AZDRERERAbD0WC0w5Z1IiIiIiKFYss6ERERERkM7y/VDlvWiYiIiIgUipV1IiIiIiKFYjcYIiIiIjIYI/aD0Qpb1omIiIiIFIqVdSIiIiIihWI3GCIiIiIyGI6zrh22rBMRERERKRQr60REREREGbRixQoUKVIEFhYWcHNzw5kzZzK03blz52BiYoJy5cppdTxW1omIiIjIYFQq5Uza8vHxwdChQzF+/Hhcv34d1atXR6NGjeDv75/mdhEREejatSvq1q2r9TFZWSciIiIiyoAFCxagZ8+e6NWrF0qVKoVFixahQIECWLlyZZrb9e3bF506dUKVKlW0PiYr60RERERkMEZQKWbSRmxsLK5evYoGDRpozG/QoAHOnz+f6nYbNmzA48ePMWnSpC8qL44GkwE+27fCe8M6hAQHw7FYcYweOw4V3NzljpWMCDmDXr/GkkXzcP7saXyIiUGhQoUxccp0lHJ2kSXPtauXsdl7Pe753kFIcDDmLlyKWnXqqZdLkoQ1vy7Hnt078O7tW5QuUxajPX+BY7HisuRNsuO37djlsx0BAS8BAEWLFUOffgNRrXoNWfIkJMTj4G/rcfnUEbx7E4pstnaoXKcxGrbtBiOj5G0Cv62Yg3OH/0SrHoNRu1k7GRJrEuG9A8ib0yWPNdqUy4NiOa1gZ2WGqQcf4MLTcPXyg/0rp7jd2gv+2H0jUP13SYes6FY5P0rmyor4RAlPQqLwy/57iE2Q9P4aAODqlcvwXr8OvndvIzg4GAuXLEeduvXS39DARMkJKPv9Ex8fj9W/LsOh/fsQGhoCe/uc+KFZC/Ts0z/Fzya5Kbksv1YxMTGIiYnRmGdubg5zc/Nk64aEhCAhIQEODg4a8x0cHPDq1asU9//w4UOMHTsWZ86cgYnJl1W7lXelKsyhgwcwZ5YXevfpD59de1GhghsG9O2NwIAAuaNpECHn27cR6NGtI0xMTLBkxRrs2rMPw0aMQVbrbLJlio6OhlOJEhg1dkKKyzdtWIttm70xauwEeG/dATs7ewzq1xORkZEGTqrJIbcDfh42Alt9dmGrzy5UqvQdhv08EI8fPZQlz9Hft+LsoT/Qts8wjF+6Fc27DcCxPdtwev+uZOvevHgaTx/chU0OexmSJifCeweQP6eFqRGehEZhxZmnKS7v5H1NY1pw/DESJQnnHoep1ynpkBXTm5TAtecRGLL7Dobsvo2/br+GZJh6OgAgOjoKJUqUwNjxEw130C8gSk65r8v0bNywFrt3+mC05wTs3LMfPw8bic0b18Nn+xa5oyWj9LL8Wnl5ecHGxkZj8vLySnMb1Wed3SVJSjYPABISEtCpUydMmTIFTk5OX5yRlfV0bN64AS1bt0arNm1R1NERoz3HI3ee3Njhs13uaBpEyOm9fi0cHPJg8jQvuJQpi7z58qPSd1VQoEBB2TJ5VKuB/oOGok69BsmWSZKE7Vs3oXuvvqhTrwGKFXfC5Omz8OHDB/x9YJ8Maf9Ts1YdVK9RE4UKF0GhwkUwaMgwZMmSBf/evClLHr/7d1CmUjW4uFeFnUMelK9aGyXLVYL/o/sa670JDcauNQvRbfhEGBsr44c9Ed47gPw5r/hHYNOlFzjvF57i8vDoOI3puyK2+PflW7x691+LVV+PQvjj1mvsvB4I//BoBETE4OyTMMQlGq62Xq16TQwaMgz16id/zyuJKDnlvi7Tc+vmDdSsVQfVatRC3nz5UK9+Q1Su4oG7d27LHS0ZpZelLsl9U+mnk6enJyIiIjQmT0/PFHPb29vD2Ng4WSt6UFBQstZ2AHj37h2uXLmCQYMGwcTEBCYmJpg6dSpu3rwJExMTHD9+PEPlJXtlPTAwEBMnTkSdOnVQqlQpuLi4oGnTpli3bh0SEhJkzRYXGwvfu3dQpWo1jflVqnrg5o3rMqVKTpScp08eh3NpF4weMQT1alZFp3Yt8fuuHXLHStXLly8QGhKC76p4qOeZmZmhgltF/HtTOeWakJCAQwf2Izo6CmW1HA5KV4qWKoMH/15F0MuPd8O/8HuIJ77/wtntO/U6iYmJ2LRoGuq26Ig8BYvKkvNzorx3RMmZJLulCSoVzI6/7wWr59lYmqCkQ1ZERMdhfktnbOtWAXOal0Lp3FllTEqZIcJ1Wa68Gy5fuohnT/0AAA/u38PN69fgUb2mzMk0iVCWXytzc3Nky5ZNY0qpCwzwsQ7g5uaGI0eOaMw/cuQIqlatmmz9bNmy4datW7hx44Z66tevH0qUKIEbN26gcuWUuw9+TtamrStXrqBevXooUqQILC0t8eDBA/z444+IjY3FyJEjsW7dOvz999+wtraWJV/4m3AkJCTAzs5OY76dnT1CQoJT2crwRMn58sVz7NqxHT92+Qk9evXFndv/Yt7sGTAzM8MPzVrIHS+Z0JAQAEAOO83uGjns7PBKAT9LPnxwH91+7IjY2BhYZsmC+YuXwdGxmCxZ6rfqjA9RkZg+6EeojIwgJSbihx/7wL1GffU6R3/fCmMjY9T8oa0sGVMiyntHlJxJ6pXIiei4RJx78l8XmDzZLAAAP1bMh7Xn/fEkNAp1nezh1awU+vn8i4CImNR2RwolwnXZrUcvvH//Dm1aNIGRsTESExIw4Oeh+L5RE7mjaRChLOmj4cOHo0uXLnB3d0eVKlWwevVq+Pv7o1+/fgA+ttS/fPkSmzZtgpGREVxcNO/Jy5UrFywsLJLNT4uslfWhQ4di2LBh6rtjt2zZgmXLluHixYsIDw9HnTp1MGHCBCxevDjN/aR0c4BknPLNAV8io32T5Kb0nImJEpxLl8agIcMBACVLOePx40fYtWO7IivrST4vQkmSvmxwVh0rXKQIftu9B+/evsWxI4cxcfxYrPXeLEuF/drZY7h88jC6DZ+EPAWK4IXfQ+xevwQ2OexRuU4j+D+6h5P7dmLMgvWKuiaTKP29k0SUnA1K5sSJhyGI++Sm0aSUB+4G4cj9j1+EH4f4o1x+GzQomQve/zyXISnpgpKvy8OHDuDg/r8w3WsuHIsVx/17vlgw1ws5c+ZS5P87Si5LXTIS+CW1b98eoaGhmDp1KgIDA+Hi4oIDBw6gUKFCAD72GElvzHVtydoN5tq1a+jSpYv6706dOuHatWt4/fo1bG1tMWfOHOzalfwGtc+ldHPA3Nlp3xyQEbbZbWFsbIyQ/7ewJgkLC4WdnTJujgPEyWmfMyeKFNWsSBYp4ohXrwJT2UJedvYfyy70s3INDwtL1vohB1NTMxQsWAilXcpg8LARcCpREtu3bJIly17vFajf+ke4Va+HvIUdUan296jdtB0O794MAHh891+8jwjHxF6tMaRVTQxpVRNhwa+wx3sZJvVuI0tmQJz3jig5AaB0HmsUsLXEIV/N1sCwqDgAgH9YtMZ8//Bo5MpqZrB8pDsiXJdLFs5Dtx690LBRExQr7oQmTZujY+du2LButdzRNIhQlvSfAQMG4OnTp4iJicHVq1dRo8Z/I7F5e3vj5MmTqW47efJk3LhxQ6vjyVpZz5UrFwID/6uovX79GvHx8ciW7ePoIMWLF0dYWFhqm6uldHPAqDEp3xygDVMzM5RyLo2L589pzL94/jxcy5XP9P51RZScruXKq/sNJvF/9hR58uSVKVHa8uXLDzt7e/xz8b+xU+PiYnHt6mWUdVVOuapJEmJjY2U5dGzsB6hUmh8nRkbGkKREAEClWg0xdtFGjFm4QT3Z5LBH3RYdMWDyAjkiAxDnvSNKTgBoWDInHgS9h19olMb81+9iEPI+FvmzW2rMz29jgdfv2QVGRCJclx8+RCcbotHY2BhSYqJMiVImQlmSfGTtBtOiRQv069cPc+fOhbm5OaZNm4aaNWvC0vLjh/n9+/eRL1++dPeT0niYH+J1k7FLt+4YP3Y0nF1c4OpaHrt3+iAwMBBt23fQzQF0RIScP3b5Cd27dsT6Nb+ifsNGuH3rX/y+awfGT5oqW6aoqEg8/+TnqoCXL3D/ni9sbGyQO09edPyxKzasW40CBQuhQMFC8F63GhYWFmjY+AfZMgPA0kUL4FG9BnLnzo3IyEj8ffAArly+hOW/rpElj4u7Bw7v2gTbnA7/7wbzACf+9MF3dRsDAKyy2cAqm43GNsbGJsiW3Q4O+eQbDQgQ470DyJ/TwsQIeW0s1H87ZDNHUbsseBcTj+D3H78kZjE1RnXHHFhzPuWfgHffDERn93zwC43C45BI1CuRE/ltLTHjsOGGHI2KjNT4ifrlixe45/vxPZ8nr3IaDkTJKfd1mZ7qNWtj/ZpVyJ07D4o6Fsf9e3exdbM3mjVvJXe0ZJRelrpk9BV27dEnWSvr06dPR2BgIJo2bYqEhARUqVIFW7b8N/apSqVKd6xLffu+UWNEvAnH6pUrEBwchGLFnbD819XImzf9LxGGJELO0i5lMG/hUixbvABrVq1A3nz5MWK0Jxo3aSpbJt87d9CvVzf13wvnzQYANGnWApOneaFr916IiYnB7JlT1Q9FWrpyLaysrOSKDAAIDQ3FBM/RCAkORlZraxR3KoHlv67Bd1U90t9YD9r2GYb9W9dgx6r5eB8RDhtbe3g0bIbv23WXJY82RHjvAPLnLJ7LCnOaO6v/7uvxsX/mkXvBWHDiCQCgZrEcAICTj0JT3Mfef1/B1FiFPh4FYW1ugiehURj/ly8C3xquZf3Ondvo1b2r+u95cz7+H9OseUtMmznLYDnSI0pOua/L9IwaOwG/Ll+MWTOnIjwsDPY5c6FVm3bo3XeA3NGSUXpZknxUkmTIx1Gk7MOHD4iPj0fWrLobwktXLesExBvoyYKZlSj/pZwuE2MxWhPOPgpJfyWZ1SieU+4IX42Wa/6RO0KG7OmdsWHO6OsQF6+sriopMTWRfQTsDLFQxmMt1Nb880zuCGq9KxeSO0K6FHH6LCws0l+JiIiIiOgbI8ZXQiIiIiKib5AiWtaJiIiI6NvAG0y1w5Z1IiIiIiKFYmWdiIiIiEih2A2GiIiIiAyGvWC0w5Z1IiIiIiKFYss6ERERERkMW4q1w/IiIiIiIlIoVtaJiIiIiBSK3WCIiIiIyGBUvMNUK2xZJyIiIiJSKFbWiYiIiIgUit1giIiIiMhg2AlGO2xZJyIiIiJSKFbWiYiIiIgUit1giIiIiMhgjDgajFbYsk5EREREpFBsWSciIiIig2G7unbYsk5EREREpFBsWad0mRiL8h1YlJzKV6N4TrkjfDUSJUnuCOna07uy3BEyxPaHBXJHSFfQH0PljpAuU2Mx2uniEpT/3jFlLYoMgJcZERERERkM7y/Vjhhfr4mIiIiIvkGsrBMRERERKRS7wRARERGRwajYD0YrbFknIiIiIlIoVtaJiIiIiBSK3WCIiIiIyGDYUqwdlhcRERERkUKxZZ2IiIiIDIY3mGqHLetERERERArFyjoRERERkUKxGwwRERERGQw7wWiHLetERERERArFyjoRERERkUKxGwwRERERGQxHg9EOW9aJiIiIiBSKlXUiIiIiIoViNxgiIiIiMhi2FGuH5ZUBPtu3olGDOqhYvgw6tG2Fa1evyB0pRSLkFCEjIEZOETICYuRUesZ1a1bhx/Zt4FGpAurUqIphgwfiqd8TuWOlSM6yHNm+Is4u6YSg3wfh2W/9sGNiMxTPb5tsvfGdq+DJ1j4I+2Mw/p7TFqUK2WksXzq4Hu6s74GwPwbD/7d+2DGpGZxS2I8+Bb1+jV88R6Nu9e/gUak8OrVtCd+7dwyaIaOU9P65fvUKRg4ZgKYNaqJKBWecOnFUvSw+Lg7LF8/Hj+2ao3ZVNzRtUBNTfhmL4OAg2fJ+TkllScqhiMp6ZGQk1qxZg+7du6NRo0Zo3LgxunfvjrVr1yIyMlLWbIcOHsCcWV7o3ac/fHbtRYUKbhjQtzcCAwJkzfU5EXKKkBEQI6cIGQExcoqQ8dqVy2jfsRM2bfPBytXrkRAfj/59eiE6KkruaBrkLsvqZQrg179uoOaw7fjBcxeMjY2wb0ZrZDH/70fkEW0rYnDLChi24jiqDd6K12GR2D+zNbJamqrXuf7wNfos+Bvl+nij2YTfoVKpsG9maxgZGeamuLdvI9CzWyeYmJhg8YrV2LlnH4aOGA1ra2uDHF8bcp/zz334EIXiTiUwYsyEFJZ9wP17d9G9Vz94b9sFr3lL8PzZU4weOlCGpMkprSz1SaVSKWYSgUqSJEnOAHfv3kX9+vURFRWFmjVrwsHBAZIkISgoCKdOnYKVlRUOHz4MZ2dnrfb7IV43+X7s0BalnJ0xYeIU9bwWTRuhdp16GDJshG4OogMi5BQhIyBGThEyAmLk1HfGRD18xIaFhaFujapY670Zbu4VM70/Ix39h6XvsrT9YYFW69vbWOK5T3/UG+mDc7dfAgCebOuD5XuuY/7OywAAM1NjPNveFxPWn8G6A7dS3I9LEXtcXtkVzt3XwS8wIs1jBv0xVKuMKVm6aD5uXr+OtRu3ZHpfKTE11l07nT7PeVRMQqa2r1LBGbPmL0HN2vVSXefunVvo2aU99uw/itx58mp9jCzmxpmJqEGfZWmhsE7Pe/59JXcEtZZlc8sdIV2yt6wPHDgQNWrUwOvXr7F3716sWrUKq1evxt69e/H69WvUqFEDAwfK8603LjYWvnfvoErVahrzq1T1wM0b12XJlBIRcoqQERAjpwgZATFyipAxJe/fvwMA2NjYyJzkP0osy2xZzAEA4e8+AAAK57ZBnhxZcfTaU/U6sXEJOHPrBb4rlXJFLYu5CbrWLw2/wDd4EfxO75kB4PTJEyhVujTGjBiK+jU90KldK+zZtcMgx9aGEs+5tt6/fweVSgVr62yy5vgaypL0R/bvWv/88w+uXLkCMzOzZMvMzMwwbtw4VKpUSYZkQPibcCQkJMDOTrM/o52dPUJCgmXJlBIRcoqQERAjpwgZATFyipDxc5IkYf6cWShfwQ3FijvJHUdNiWU5u29NnLv9AnefhQIActtmAQAEhWt2HwoKj0JBB83KWp8fXDGjZ3VktTTDPf9QNBm3G3HxiQbJ/fLFc+ze8Rt+7PITuvfqgzu3b2He7JkwNTPDD81aGCRDRijxnGsjJiYGK5csRIPvm8Aqa1ZZs4heltoSo/OJcsheWbe1tcXDhw9T7eby6NEj2NqmfWNPTEwMYmJiNOZJxuYwNzfXScbP+zRJkqTIfk4i5BQhIyBGThEyAmLkFCFjklkzpuHhg/vYsGmb3FFSpJSyXDiwDsoUsUfdET7Jln3eMUmlUuHz3kq/HffFsWvPkDuHFYa2cceWcT+gzvDfEBOXua4ZGZGYKMG5dGkMHDIMAFCylDOePH6E3Tt+U1RlPYlSzrk24uPiMNFzBBKlRIzynCh3HDURy5L0T/ZuML1790a3bt0wb9483Lx5E69evcLr169x8+ZNzJs3Dz169EDfvn3T3IeXlxdsbGw0prmzvTKdzTa7LYyNjRESEqIxPywsFHZ29pnev66IkFOEjIAYOUXICIiRU4SMn5o1cxpOnTiONes3wSG3svpZKqksF/SvjR++c0TD0f9r777jqiofOI5/r4wLIhuVoYICbkXAhYq4FQ3FbZaSpg2tHOUgLdw4WpqpmaJlamiYmT93EWVoDtRMcZQKoiAyVZB9fn+YN69cVsI959Hvu9d5veLcc+/9cFgPj889bMeNlHua/Un/zKjX/meG/aGaVqZITte+mMGd7Dz8fTMDv/15AyMX/IBGdW0woKNb1ccDsKtph/oNXLX21a/fAElJiXp5/vJS0se8Igry8zFr5lTcvHEDK1atl31WHRD3XJJ+yD5YnzNnDoKDg/HRRx/B09MTTk5OcHR0hKenJz766CPMnDkT779f+m+9wcHByMzM1NqmzQh+4jYjY2M0adoMR6N/09p/NDoaHq08n/jxK4sInSI0AmJ0itAIiNEpQiPwYHZt8cJ5+OnQQXwethFOderInVSMUs7lxxO6YUBHd/SZsR1xt+5o3XYtKROJaffQ3dNZs8/IsBp8W9TB0djSr7ihwoMXo+qDRysvxF27prUvLu4aHP7DCyCrklI+5hXxcKCeEB+HFWvWw9LKSu4kAGKeyyehUilnE4Hsy2AAYMaMGZgxYwauXr2KpKQHrxC2t7dH/fr1y3V/tbr4kpfKuhrMqKAxmDVzOpo2bw4PD09EbA9HYmIihg4fUTlPUElE6BShERCjU4RGQIxOERpDF8zD3j278fGKz2BmZqZZw1qjhjlMTExkrvuX3Ofyk4ndMLxrYwyduwv37udpZtAzs/KQk/fgh8Jn353CtBFt8dfNDPx1Ix3TR7TD/dwChEdeAPDgRahD/Brix5NxSMm8D0e7Gnh7aBvczyvA/mNX9fJ+jBwVhLGjRyLsi8/Rs3cfnDt7Ft99ux2zQuaWfWc9k/tj/rjs7CwkXI/XvH3zxg1cuhgLCwtL2NWshXenT8bFC7H4YPkqFBUWIvWfryULS0sYGRV/7Zw+Ke1cknLIfunGsly/fh0hISEICwur0P0qa7AOPPgjBRvD1uP27WS4uTfEtBnBlXK5tMomQqcIjYAYnSI0AmJ0VmVjZVy60bN5Y5375y5YhP6Bg5748Svr0o1A1Z7Lsi7deH/fVJ37x3+4D18fPK95e9aLPni5bwtY1zDB8QtJmPzZj5oXoTrYmGHV5F7wdK8F6xomSM7IxuGzCVi05SguJ6SX2VgZl24EgF+jIrFy+ce4Hh8HR6c6eGFUEAYOGVYpj12Zl24Equ5j/l8u3Rhz4hgmvvJSsf19AwIx7tWJGPRcT533+2ztRni1rvjFLCrz0o1A1Z1LpV268Yezt+RO0AhoUVvuhDIpfrB+5swZeHl5obCwYl+0lTlYJyL6r6riOuuVrTIH61WpotdZl0NlDdarUmUP1qvKk15nXR8qe7BeVThYL5kIg3XZP3y7du0q9fYrV5T5J7WJiIiIiKqa7IP1wMDAfy6bVfLsEy9bRERERPR04LCuYmT/tzAHBwdERESgqKhI5xYTEyN3IhERERGRLGQfrHt7e5c6IC9r1p2IiIiI6Gkl+zKYadOmISsrq8Tb3dzcEBkZqcciIiIiIqoqKnAdTEXIPlj39fUt9XYzMzP4+fnpqYaIiIiISDlkXwZDRERERES6yT6zTkRERETPDl4NpmI4s05EREREpFCcWSciIiIivanGF5hWCGfWiYiIiIgUioN1IiIiIiKF4jIYIiIiItIbvsC0YjizTkRERESkUBysExEREREpFJfBEBEREZHecBlMxXBmnYiIiIhIoThYJyIiIiJSKC6DISIiIiK9UfGPIlUIZ9aJiIiIiBSKM+tERFUo+U6u3Allsrc0kTuhXJJ3TpY7oUx1xmyWO6FMSV+OkjuhXKqrDeROoCpSjRPrFcKZdSIiIiIiheJgnYiIiIhIobgMhoiIiIj0hi8wrRjOrBMRERERKRQH60RERERECsVlMERERESkNyqugqkQzqwTERERESkUZ9aJiIiISG/4AtOK4cw6EREREZFCcbBORERERKRQXAZDRERERHpTjatgKoQz60RERERECsXBOhERERGRQnEZDBERERHpDa8GUzGcWSciIiIiUigO1omIiIiIFIrLYIiIiIhIb1RcBVMhnFknIiIiIlIoDtbLIXzrZvj36oY2ni0wYuggxJw8IXeSTiJ0itAIiNEpQiMgRqeSGn/YsQ2vjRqCgT06YGCPDpg8fhSOHzmsuX3TutV4ecQA9O/WDoN7d8KMt17BhXN/yNb7OCWdS10KCgqwauUn6O/fAx3btsKAvj3xxZrPUFRUpJfnn9q/OSLn+yNh/Qj8tXooNk/tAjcHC61jZg5uieMf9MfNsOcR98UwfP9uD3i72hV7rDbudvhhVs9/jhuO3bN7wsTIQC/vBwCs/+JzjBw+GB3aeqJrZx9MfmsCrl29orfnrwilf16ePHEcb054DT26dIJHs0b46cdDcidVKZWCNhEofrB+69YtzJs3T7bn37d3D5YuDsX4V15H+Lc74eXljQmvjkfizZuyNekiQqcIjYAYnSI0AmJ0Kq2xZq1aGPv6JHwatgWfhm2Bh3dbzJkxCdeu/AUAcKrnjIlvB+PzTRH4cPVG2Ds4Injy68hIT5Ol91FKO5e6fLlhHSK2h2N68Gxs/+5/eHPKO9j0ZRjCt36tl+fv2KQWvjh4ET3e34vA0EMwrKbCdzO7o7r631WpfyXewbSNx9Bh5g/oPWc/4m/fw3fB3WFrrtYc08bdDhEzuuOnP26i23t70PW9PfjiwEUUSZJe3g8AOHniGIY//wK+2rINa9ZuQGFBIV5/5WXcz87WW0N5iPB5ef9+Nho1aoSZs96XO4UUSCVJevzK/g/OnDkDLy8vFBYWVuh+OQWV8/wvjBiKJk2bYvb7czX7AgP80bVbD0ya8nblPEklEKFThEZAjE4RGgExOqu6MSkz54kfY3BvX4x/Ywr6BAwqdltW1j0M6tkRi1eshWfrdv/p8e0tTZ40EUDVn8v8gief/Z78xmuwsbXF+3MXavZNm/oWTExMMH/R0id+/DpjN1foeFtzNa58Pgz+8/Yj+kKyzmPMTY2QsH4E+i88iKhzSQCAQ3P7IPLPRCzcfqbCjUlfjqrwfcojLS0N3Tr7YP3Gr+Hdus0TP15lrWsW4fvQozyaNcLHKz5Dt+49Ku0xTRT2CsXfLqfLnaDR0d1a7oQyyT6z/scff5S6Xbx4Uba2/Lw8xJ4/B58OnbT2+3ToiDOnT8lUVZwInSI0AmJ0itAIiNGp9MbCwkL8fHAvcnPuo0lzj2K35+fnY8/3ETCrYY4Gbg1lKHykReHn8qFWnt44fuwo4q5dBQBcungBZ07FoKOvnyw9ltWNAQDp9/J03m5kUA0vdXNHRlYezsY/GODYWZigjXtN3M7MwYE5vXF59RD8771eaN+opt66dbl37y4AwNLSUtaOR4nyefmsqaZSKWYTgey/a7Vq1QoqlQq6Jvgf7lfJdDLTM9JRWFgIW1tbrf22tnZISbktS5MuInSK0AiI0SlCIyBGp1Ibr/59GZNfGYW8vDyYmlbH+6Efw7m+q+b2o79FIfT9GcjNyYGNrR1CP1kDSyt5Z4eUei4fFzR2HO7du4shgf1QzcAARYWFmPDmZPTx7ydLz8IXvRF94RZiEzK09vf2dELYm76obmyIpIz7GBh6CGl3cwEALrVqAACCB3tg9paTOHstDSN8XbHr3Z5oP+MHXEm6q+93A5Ik4cOlofD08oabu7y/OD5KlM9LotLIPli3tbXFkiVL0L17d523nzt3DgEBAaU+Rm5uLnJzc7X2SQZqqNXqEu5RMY//siDnLxClEaFThEZAjE4RGgExOpXWWKeeC1Z9uQ1Zd+/i8M+H8MGC97Dss/WaAXsrrzZY9eU23MnIwN5dEVj43jSs+OJrWNnYlvHIVU9p5/JxB/btwd7//YAFocvg6uaOixdi8dGyUNSsWQvP9Q/Ua8sHL7VFs3rW6DN3f7Hbfj1/C77B/4ONuRovdXXHxrc6o9v7e5FyJ0czG7jhp0vYHPU3AOCPuBPwa26PUX5umBuu/xnj0IXzcOnSJWz8aoven7s8lP55SVQa2ZfBeHt74+bNm3B2dta5OTk56Zx1f1RoaCgsLS21tmVLQp+4zdrKGgYGBkhJSdHan5aWClvb4q/Ml4sInSI0AmJ0itAIiNGp1EYjIyM41amHhk2aYezrk1DfrSF2bvt3LbSJaXU41amHJs1bYuq7c2FgYIh9u3fK1gso91w+bsXHHyBo7Dj09u8HN/eG6BcwAM+/GIQN69fqtWNpUBv4e9dBwIKDuJlW/AWZ2bkFuHLrLk78lYI3vjiCgqIijO7iBgC4lXEfAHAhIVPrPpduZKKOnVnVxz9m8aL5iIr8CevCvkRte3u9P39pRPm8fNbIfQUYXg2mgl599VW4uLiUeHu9evWwYcOGUh8jODgYmZmZWtu0GcFP3GZkbIwmTZvhaPRvWvuPRkfDo5XnEz9+ZRGhU4RGQIxOERoBMTpFaAQASBLy8/NLuVlCfp7uNc/6Isq5zMm5j2rVtH/0GRgYQNLTpRsBYNlLbRDQph4CFh5E3O175bqPCoCx0YPuuNv3cDMtG+6O2pd8dHOwwPWU8j1eZZAkCaEL5+HHQwewNuxLONWpq7fnLi9RPi+JSiP7MpiBAweWeru1tTWCgoJKPUatLr7kpbKuBjMqaAxmzZyOps2bw8PDExHbw5GYmIihw0dUzhNUEhE6RWgExOgUoREQo1NpjWFrVqBN+06oWbs27mdn4+eD+/DHqRNY8NEq5NzPxpYv18GnUxfY2Nrhzp1M7N4RjpTbt+DbracsvY9S2rnUxdevK8K++Bz29g5o4OqOixfOY/Omjeg/oPiVdqrCh2PaYkiH+hj5YSTu3c9HrX+uxHMnOx85+YWorjbEO4HNsedkAm5l3IdNDTXG9WwIRxsz7Dwap3mcFbvPIXiIB/6MS8fZuHQ837kB3B0tMPqTKL28HwCwaMFc7N2zG5+sWAUzMzPNGvAaNcxhYlI5VxiqDCJ8XmZnZSE+Pl7z9o2EBFyIjYWlpSUcHB1lLCMlkH2wXpbr168jJCQEYWFhsjx/H/++yMxIx9rVq3D7djLc3BviszVr4ejoJEtPSUToFKEREKNThEZAjE6lNWakpWLZvFlIS72N6mY1UN+tIRZ8tArebX2Ql5uLhLirmL9nF+5kZsDc0goNGzfDh6s2wKWBmyy9j1LaudRl2szZWPPZcixeNA/paWmwq1kLg4YMw/hXJ+jl+cf1bAQA2PN+b639r6/5DVt+uYLCoiI0dLDE85NdYWuuRtq9XMT8nQr/eftx4ca/y15W77sAEyMDLBrVGtZmavwZn4bA0EO4mqy/mfXt4VsfvE9jtC8FOXdBKAYE6ueXn/IQ4fPy3Lk/MW7MaM3bHyx9sJS3/4CBmL9osVxZVUeU9ScKweusExFVocq4znpVq6zrrFe1yrjOelWr6HXW5VBV11mvbHz9Z+VR2nXWj/6dIXeCRntXK7kTyiT7h2/Xrl2l3n7lijL/dDERERERVZyKU+sVIvtgPTAwsMTrrD/EyysRERER0bNI9qvBODg4ICIiAkVFRTq3mJgYuROJiIiIiGQh+2Dd29u71AF5WbPuRERERCQOlUo5mwhkXwYzbdo0ZGVllXi7m5sbIiMj9VhERERERKQMsg/WfX19S73dzMwMfn5+eqohIiIiIlIO2QfrRERERPTsEGT1iWLIvmadiIiIiIh042CdiIiIiEihuAyGiIiIiPSH62AqhDPrREREREQKxZl1IiIiItIbFafWK4Qz60RERERECsXBOhERERGRQnEZDBERERHpjYqrYCqEM+tERERERArFwToRERERkUJxGQwRERER6Q1XwVQMZ9aJiIiIiBSKM+tEREREpD+cWq8QlSRJktwRVSGnQO4CIiIi5bFu84bcCeWSfnyl3AlPDROFTc3GxN2RO0HDy9lC7oQycRkMEREREZFCKex3LSIiIiJ6mqm4DqZCOLNORERERKRQHKwTERERESkUB+tEREREpDcqlXK2/2LVqlWoX78+TExM4O3tjV9//bXEY3fs2IGePXuiZs2asLCwgI+PD/bv31+h5+NgnYiIiIioHMLDwzF58mTMmjULp06dgq+vL/z9/REfH6/z+F9++QU9e/bEnj17cPLkSXTt2hUBAQE4depUuZ+Tl24kIiJ6hvDSjc8epV268XT8XbkTNFrVM6/Q8e3atYOXlxdWr16t2dekSRMEBgYiNDS0XI/RrFkzDB8+HO+//365jufMOhERERHpjUpBW0Xk5eXh5MmT6NWrl9b+Xr16ITo6ulyPUVRUhLt378LGxqbcz6uw37WIiIiIiPQjNzcXubm5WvvUajXUanWxY1NSUlBYWIjatWtr7a9duzaSkpLK9XwffvghsrKyMGzYsHI3cmadiIiIiPRH7un0R7bQ0FBYWlpqbWUtZ1E99spUSZKK7dNl69atmDNnDsLDw1GrVq0yj3+IM+tERERE9EwKDg7G1KlTtfbpmlUHADs7OxgYGBSbRU9OTi422/648PBwvPzyy9i+fTt69OhRoUbOrBMRERHRM0mtVsPCwkJrK2mwbmxsDG9vbxw8eFBr/8GDB9GhQ4cSn2Pr1q146aWXsGXLFvTr16/CjZxZJyIiIiK9UVX4pZ3KMXXqVIwaNQqtW7eGj48P1q5di/j4eLz22msAHszU37hxA1999RWABwP10aNHY/ny5Wjfvr1mVt7U1BSWlpblek4O1omIiIiIymH48OFITU3FvHnzkJiYiObNm2PPnj1wdnYGACQmJmpdc/3zzz9HQUEBJk6ciIkTJ2r2BwUFYePGjeV6Tl5nnYiI6BnC66w/e5R2nfU/rt+TO0GjZd0acieUSWEfPiIiIiJ6mpXjwin0CL7AlIiIiIhIoThYJyIiIiJSKA7WyyF862b49+qGNp4tMGLoIMScPCF3kk4idIrQCIjRKUIjIEanCI2AGJ0iNAJidMrZ2NHLFd9+8iquHFiI+6dWIqBLS63b1859EfdPrdTaor58u9jjtGtZH3s/fxMp0R8i8Zel2P/FJJiojfT1bmiI8PEGxOl8Ugr4W0iaTQSKGawnJCTg3r3iLzjIz8/HL7/8IkPRA/v27sHSxaEY/8rrCP92J7y8vDHh1fFIvHlTtiZdROgUoREQo1OERkCMThEaATE6RWgExOiUu9HMVI2zl25gyuJtJR6z/7dzcOkRrNkC31ytdXu7lvXx/coJ+PHoBfi+uAydXlyGNeFRKCrS73Ut5D6X5SVKJ+mf7IP1xMREtG3bFs7OzrCyskJQUJDWoD0tLQ1du3aVrW/TlxswcPBgDBoyFA1cXTE9eBbsHeyxLXyrbE26iNApQiMgRqcIjYAYnSI0AmJ0itAIiNEpd+OB385j7qrd+P6nMyUek5dXgFupdzVb+p1srduXvj0Iq775GR9sOIjYK0n4O/42vjt0Gnn5+r1cm9znsrxE6awUck+nCza1LvtgfebMmTAwMMDvv/+Offv24fz58+jSpQvS09M1x8h1dcn8vDzEnj8Hnw6dtPb7dOiIM6dPydKkiwidIjQCYnSK0AiI0SlCIyBGpwiNgBidIjQCgG9rd8T9GIo/dr6Pz957HjWt/70EXk3rGmjbsj5up91D5MapuHZoEQ6sm4QOrRrotVGUcylKJ8lD9sH6oUOHsHz5crRu3Ro9evTA4cOHUadOHXTr1g1paWkAAJVM1/hJz0hHYWEhbG1ttfbb2tohJeW2LE26iNApQiMgRqcIjYAYnSI0AmJ0itAIiNEpQuOB385jzLtfwv+VFZj50Q54N3PG3rVvwdjowRWh69exAwDMerUvwnZEY8DEVTgdex17Pn8TrvVq6q1ThHMJiNNJ8pB9sJ6ZmQlra2vN22q1Gt9++y1cXFzQtWtXJCcnl/kYubm5uHPnjtaWm5tbaY2P/7IgSZJsv0CURoROERoBMTpFaATE6BShERCjU4RGQIxOJTd+eyAG+w6fw/m/E7Hnlz8R+MYquDvXgr9vMwBAtWoPOtdHHMamXUdx5mICpn+4A5euJSNogI/ee5V8Lh8lSueTUinoPxHIPlhv0KAB/vjjD619hoaG2L59Oxo0aIDnnnuuzMcIDQ2FpaWl1rZsSegTt1lbWcPAwAApKSla+9PSUmFra/fEj19ZROgUoREQo1OERkCMThEaATE6RWgExOgUofFxSSl3EJ+YBrd/Zs0Tb98BAMReSdI67uLVJNS1ty52/6oiyrkUpZPkIftg3d/fH2vXri22/+GAvVWrVmWuWQ8ODkZmZqbWNm1G8BO3GRkbo0nTZjga/ZvW/qPR0fBo5fnEj19ZROgUoREQo1OERkCMThEaATE6RWgExOgUofFxNpZmqFPbGokpDwbpcTdTcTM5Aw1damkd5+ZcC/GJaXrrEuVcitJJ8jCUO2DhwoXIzs7WeZuhoSF27NiBhISEUh9DrVZDrVZr7cuppBebjwoag1kzp6Np8+bw8PBExPZwJCYmYujwEZXzBJVEhE4RGgExOkVoBMToFKEREKNThEZAjE65G81MjeFa99+15S5OtmjZ0Anpd7KRlpmF2a/1w84fTyPxdiacHW0x780ApGbcw65Hrh7z8ZeHMPu1fjh76QbOXEzAiwHt0MilNkZOW6+X9+Ehuc9leYnSWRmewpU9VUr2wbqhoSEsLCxKvP3mzZuYO3cuwsLC9Fj1rz7+fZGZkY61q1fh9u1kuLk3xGdr1sLR0UmWnpKI0ClCIyBGpwiNgBidIjQCYnSK0AiI0Sl3o1dTZxxYN0nz9tJ3BgMANu06ircWhaOZmyNGPtcWVuamSEq5g6jjlzBqRhjuZf/7erGVW36GidoIS98eDGvL6jh76Qaee30lriakFHu+qiT3uSwvUTpJ/1SSXNdFLKczZ87Ay8sLhYWFFbpfZc2sExERPU2s27whd0K5pB9fKXfCU8NE9qlZbedvZsmdoNHU0UzuhDLJ/uHbtWtXqbdfuXJFTyVEREREVNW4CqZiZB+sBwYGQqVSlfoi0qfxskVERERERGWR/WowDg4OiIiIQFFRkc4tJiZG7kQiIiIiqiwqBW0CkH2w7u3tXeqAvKxZdyIiIiKip5Xsy2CmTZuGrKySX2jg5uaGyMhIPRYRERERESmD7IN1X1/fUm83MzODn5+fnmqIiIiIqCqpRFl/ohCyL4MhIiIiIiLdOFgnIiIiIlIo2ZfBEBEREdGzg1fkrhjOrBMRERERKRRn1omIiIhIbzixXjGcWSciIiIiUigO1omIiIiIFIrLYIiIiIhIf7gOpkI4s05EREREpFAcrBMRERERKRSXwRARERGR3qi4DqZCOLNORERERKRQHKwTERERESkUl8EQERERkd6ouAqmQlSSJElyR1SFnAK5C4iKKywS48vNoBq/k1aW3PwiuRPKpDYS4x9Zs3ML5U4ok7Gh8s9lQZHyPycBoMEr4XInlOnmhpFyJ5SLicKmZv9Kvi93goZbLVO5E8qksA8fERERET3NOB1UMcqfAiAiIiIiekZxsE5EREREpFBcBkNERERE+sN1MBXCmXUiIiIiIoXiYJ2IiIiISKG4DIaIiIiI9EbFdTAVwpl1IiIiIiKF4mCdiIiIiEihuAyGiIiIiPRGxVUwFcKZdSIiIiIiheLMOhERERHpDSfWK4Yz60RERERECsXBOhERERGRQnEZDBERERHpD9fBVAhn1omIiIiIFIqDdSIiIiIiheIyGCIiIiLSGxXXwVQIZ9bLIXzrZvj36oY2ni0wYuggxJw8IXeSTiJ0itAIiNMJAGHrPodXi8ZYtmSR3Ck6iXAuRWjMysrCR0sXob9/N/i2a4WXRz+P83+elTurGKWdy1MnT+CdSRMQ0MsPPl5NERV5SOv2dWtWYvigfujawRu9/NrjzdfG4tzZMzLVPvD5qk/h3bKx1taraydZm4AH5/LttyagX08/tGvVFFE/aZ9LSZLwxeqV6NfTD53beeL1l4Nw5a/LVdYzOaApDs3tjbi1Q3Hxs0HYNNkXbvbmxY6bMbAFzq0IxI31w7Dr3e5o7GSpuc3KzBiLR3nj96XPIWHdMPzx8QCEjvKGualRlXWXRmlfP6QMihisp6amIjIyEmlpaQCAlJQULFmyBPPmzUNsbKysbfv27sHSxaEY/8rrCP92J7y8vDHh1fFIvHlT1q7HidApQiMgTicAnPvzLHZ8uw3uDRvJnaKTCOdShEYAWDh3Nn4/Go05C5Zgy/bv0c6nIya+NhbJt27JnaahxHOZk5MN94aN8PaM2Tpvr+vsgrdnzMLX23ZiTdgmODg6YdLE8UhPT9NzqTZXV3fs/+lXzRYesUvWHgC4f//BuXxnpu5zuWnjemz5+ku8M3M2NmzeBhs7O7z5+jhkZWVVSU/HxrWw/tAl9J57AIOW/ATDatUQMaMbqqsNNMe81a8JJvg3xoyvTqBHyH4kZ+YgYkZX1DB5sLDAwdoUDtameH/rKXR6dw8mfnEU3Vs44NNx7aqkuTRK/PqpKiqVcjYRyD5YP3bsGFxdXdG9e3e4ubnh5MmTaNu2LdavX49NmzbB29sbMTExsvVt+nIDBg4ejEFDhqKBqyumB8+CvYM9toVvla1JFxE6RWgExOnMzs7CrJnv4L2Q+bCwsJA7RycRzqUIjTk5OYj88SDenPwOvLzboG49Z7zy+htwdKyDiO3K6VTiufTp2BmvTpyELt176ry9t/9zaNuuA5zq1EUDV3dMmjoDWffu4a9LF/Vcqs3A0AB2djU1m7WNjaw9ANChU2e89sYkdNVxLiVJwjebv8KYca+ia/eecHVzR8j8UOTcz8H+vburpGfosp+x9deruHAjE+fiM/DGF0dR184MHi7/nqvX+jTGh9//id0nEhCbkIkJnx9BdWNDDPZxAQDEJmQiaMVh7D91A9eS7+HX87ew8Nsz6O3pBINq+h3JKfHrh5RB9sH6rFmzMHToUGRmZuLdd99FYGAgunfvjkuXLuHy5csYOXIk5s+fL0tbfl4eYs+fg08H7X9+9OnQEWdOn5KlSRcROkVoBMTpBIDFC+ehk28XtPPpIHeKTiKcSxEaAaCwsBCFhYUwVqu19qtN1DhzSr7JjEeJci5Lk5+fh507tqFGDXO4N2wsa0t8XBx6d/dFQJ/uCJ4+FQkJ12XtKcvNGwlITUnR+n5kbGwMz9atcfb0ab00WPyzdCUjKw8A4FzTDPZWpoj8M0lzTF5BEX67kIy27nalPI4x7t7PR2GRVLXBj3gavn6o6sg+WD958iSmTp0Kc3NzTJo0CTdv3sT48eM1t0+cOBHHjx+XpS09Ix2FhYWwtbXV2m9ra4eUlNuyNOkiQqcIjYA4nfv3/g8Xzp/Hm5Onyp1SIhHOpQiNAGBmZoYWLVshbO1q3E5ORmFhIfb+bxfOnf1DMZ2inEtdDv/yM7p19IZfe098s/krLF+9DlbW1rL1NG/hgXkLF2Pl6nWYPWc+UlNuY+yo55GRkS5bU1lSU1IAADY22oNgGxs7pKam6KVhwQteOHIxGbEJmQCA2lamAIDbmTlax92+k4PalqY6H8O6hjHeCWyOjZF/VW3sY0T++vkvVAraRCD71WDy8vJgavrgi8bIyAjVq1eHnd2/X+y2trZITU0t9TFyc3ORm5urtU8yUEP92CzUf6V6bFGTJEnF9imBCJ0iNALK7kxKSsSyxYuwau36Svscr0pKPpcPidA4d+ESzJ8zC/16+cHAwACNGjdFb//ncPHCebnTtIhwLh/n3aYtvty6A5kZGfj+u+2YPWMq1n31DWxsbMu+cxXo6NtZ6+2WLVthQL9e2L1rJ14cPUaWpvIq9rHW08d/aVBrNKtrhb7zDxa7TZK0Z8hVACQUnzU3NzFE+NtdcPFGJpZ+J8+Lt0X8+qGqJ/vMet26dXHlyhXN29988w0cHBw0bycmJmoN3nUJDQ2FpaWl1rZsSegTt1lbWcPAwAApKdqzAmlpqbC1Lb1Jn0ToFKEREKMz9tw5pKWl4oXhg9GmVTO0adUMJ08cxzebN6FNq2YoLCyUOxGAGOdShMaH6tSth8/Xb0LUkZP4Yd9P2Lh5GwoK8uHo6CR3GgCxzuXjTE2ro249ZzRv6YFZIQtgYGCAH3ZGyJ2lYVq9OtzcGyI+Lk7ulBLZ/vNzOjVVexY4LT21yn/pWTzKG/6eTugf+iNupt/X7L+V8eD/a1lpz6LbWZgg+bHZ9homhtg+vSvu5RRg1PJfUFCovyUwgNhfP1T1ZB+sjxgxAsnJyZq3+/Xrp5lpB4Bdu3ahbdu2pT5GcHAwMjMztbZpM4KfuM3I2BhNmjbD0ejftPYfjY6GRyvPJ378yiJCpwiNgBidbdu3x7Ydu7B1+3earWmz5vDvF4Ct27+DgYFB2Q+iByKcSxEaH2dqWh12NWvhzp1MHI3+DZ27dJc7CYCY57IkkiQhPy9P7gyNvLw8XL3yN+xq1pQ7pUSOTnVga2eHY0eOaPbl5+fh1IkTaNGqVZU975LRrfFc67oYEPoT4m9rX3Um7nYWkjLuo0tze80+I4Nq6Ni4Fo5d/ndQbG5iiIjp3ZBXUIQXPo5Cbn5RlfWW5Gn6+ikPua8AI9rVYGRfBhMSElLq7bNmzSpz8KFWF1/yklPwxGkAgFFBYzBr5nQ0bd4cHh6eiNgejsTERAwdPqJynqCSiNApQiOg/E4zsxpwc2+otc/U1BSWVlbF9stN6ecSEKMRAI5EHwYkCfVc6iMhPg4rPv4Azi71ETBgoNxpGko8l9nZWUi4Hq95++aNG7h0MRYWFpawtLLCxnWfw9evG2zt7HAnMxMR27fidvItdOvZW7bmjz9Ygs5dusLe3hFpaalYv3Y1srLuIaB/oGxNwD/nMv6xc3khFhaWlrB3cMSIF0Zj4/q1qOvsjLr1nLFx3VqYmJqgt/9zVdKzLKg1hvi44IVPfsG9nHzUsjQBANzJzkdO/oN/YVyz7wKmBjTDlaS7uHLrLqYENEN2XgEijlwD8GBGPWJGN5gaG+DVNdEwNzXSXGM95U4uiiT9zbAr8euHlEH2wXpZUlNTERISgrCwMFmev49/X2RmpGPt6lW4fTsZbu4N8dmatYr5p+eHROgUoREQp1MEIpxLERoB4N7du1j16cdIvpUEC0tLdOveC6+/MRmGRvL88RZdlHguL5w/h4mvvKR5e8VHSwAAfQMCMf3dEMRdu4o9uychMyMdlpZWaNKsOVav34QGru4yFQPJybfw7oy3kZGeAWsba7Ro4YGNX4fDQebPydhz5zBh/Euatz/58MG57BcQiPfnL8Kol15Gbk4Oli6ah7t37qBZi5ZYsXodzMzMqqTn5R4PJid2z+qhtX/i2iPY+utVAMCK/8XC1NgQy15qA6vqxjh5JQVDlkbi3j8zeh4uNmjt9mCZScyH/bUex2PK97ieUjXXiNdFiV8/pAwq6fFXXijMmTNn4OXlVeF1uJU1s05UmfR5KbAnoe/rCz/N5Pgn9YpSG8m+IrJcsnOV8XqM0hgbKv9cFhQp/3MSABq8Ei53Qplubhgpd0K5mChsajYhXTnLzOpYG8udUCbZP3y7dpX+V9keffEpEREREdGzRPbBemBgIFQqVbFLKz2Kly0iIiIiejpwWFcxsv97nYODAyIiIlBUVKRzi4lRxl/nIyIiIiLSN9kH697e3qUOyMuadSciIiIielrJvgxm2rRpyMoq+dXWbm5uiIyM1GMREREREVUVroKpGNkH676+vqXebmZmBj8/Pz3VEBEREREph+zLYIiIiIiISDfZZ9aJiIiI6NnBq8FUDGfWiYiIiIgUioN1IiIiIiKF4jIYIiIiItIbFa8HUyGcWSciIiIiUijOrBMRERGR/nBivUI4s05EREREpFAcrBMRERERKRSXwRARERGR3nAVTMVwZp2IiIiISKE4WCciIiIiUigugyEiIiIivVFxHUyFcGadiIiIiEihVJIkSXJHVIWcArkLiIq7cz9f7oRysTA1kjuBiEjxrPssljuhXO4fmil3gpbku8r5WVjLXPk/77gMhoiIiIj0RsXrwVQIl8EQERERESkUZ9aJiIiISH84sV4hnFknIiIiIlIoDtaJiIiIiBSKy2CIiIiISG+4CqZiOLNORERERKRQHKwTERERESkUl8EQERERkd6ouA6mQjizTkRERESkUJxZJyIiIiK94V8wrRjOrBMRERERKRQH60RERERECsVlMERERESkN3yBacVwZp2IiIiISKE4WCciIiIiUigO1omIiIiIFIqDdSIiIiIiheJgvRzCt26Gf69uaOPZAiOGDkLMyRNyJ+kkQqcIjYDyO8M+/wy+rZtrbQN6+8mdpZPSzyUgRiMgRqcIjYAYnSI0AmJ0Kq3R0bYGwmY+h4Qdk5C6+20cXTMGnu61NbevndYP9w/N1NqiPh0lYzHJSbGD9QYNGuDy5ctyZ2Df3j1YujgU4195HeHf7oSXlzcmvDoeiTdvyp2mRYROERoBcTrrN3DDzn0/a7aN33wnd1IxIpxLERoBMTpFaATE6BShERCjU2mNVjXU+Gn5KOQXFCEweBs8X16HmZ//hIx7uVrH7T/2N1yGfqrZAt/dLktvVVCplLOJQCVJkiRnwIoVK3Tunzp1KqZPnw57e3sAwFtvvVWhx80peOI0AMALI4aiSdOmmP3+XM2+wAB/dO3WA5OmvF05T1IJROgUoRGo2s479/OfNA/Ag5n1X6N+woYtEZXyeI+zMDWqlMcR4WMuQiMgRqcIjYAYnSI0AmJ0VmWjdZ/FFb7P/HF+8GlWBz2mbC7xmLXT+sGqhhrDQnY8SZ7G/UMzK+VxKkvG/UK5EzSsTA3kTiiT7NdZnzx5MpycnGBoqJ1SVFSEr776CkZGRlCpVBUerFeG/Lw8xJ4/h7HjXtHa79OhI86cPqX3npKI0ClCIyBOJwAkxMcjsE9XGBsbo0mzFnh14iQ41qkrd5aGCOdShEZAjE4RGgExOkVoBMToVGJjPx93HDpxFZvfC0SnlnVxM/Ue1u6KwYY9Z7SO8/Woh7jtbyIzKxe//hGPOWG/4HZGtizNlU0FQaa0FUL2wfr48eNx7NgxbNmyBU2aNNHsNzIywoEDB9C0aVPZ2tIz0lFYWAhbW1ut/ba2dkhJuS1TVXEidIrQCIjT2bR5S8yauwh1nZ2RnpqKL9d/jtdffhFfhX8PSysrufMAiHEuRWgExOgUoREQo1OERkCMTiU21newwvgAT6z49hiWbj2C1o0c8OHEHsjNL8SWg38CAA4c/xs7frmA+FuZcLG3wvsv+WLvsufRYcJG5OUrZ1aa9EP2wfrnn3+OnTt3onfv3pg+fTreeOONCj9Gbm4ucnO113pJBmqo1epKaVQ9tqhJkqRi+5RAhE4RGgHld7bv6PvvG25As5YeGBHoj727v8eIF4PkC9NB6ecSEKMREKNThEZAjE4RGgExOpXUWE2lQsylRISE/QIAOPPXLTR1scMrAZ6awfq3P1/QHH/+WgpiLiXi4uYJ8G/niu8PX5Klm+SjiBeYBgYG4siRI/juu+/g7++PpKSkCt0/NDQUlpaWWtuyJaFP3GVtZQ0DAwOkpKRo7U9LS4Wtrd0TP35lEaFThEZAnM7HmZpWRwNXdyRcj5M7RUOEcylCIyBGpwiNgBidIjQCYnQqsTEp7R5i41K19l2IT0XdWhal3CcL8bcy4eZkXdV5eiH3i0pFe4GpIgbrAODk5IRDhw6hc+fO8PT0REVe9xocHIzMzEytbdqM4CduMjI2RpOmzXA0+jet/Uejo+HRyvOJH7+yiNApQiMgTufj8vLyEHftKmztasqdoiHCuRShERCjU4RGQIxOERoBMTqV2HjkXAIa1rXR2udexwbxtzJLvI+NhQnq1LJAYlpWVeeRAsm+DOZRKpUKwcHB6NWrFw4fPgwHB4dy3U+tLr7kpbKuBjMqaAxmzZyOps2bw8PDExHbw5GYmIihw0dUzhNUEhE6RWgExOj87JNl6ODbBbXtHZCenoav1n+OrKx78H9ugNxpWkQ4lyI0AmJ0itAIiNEpQiMgRqfSGj+NOI7I5aMw7XkfRETFok1jR4zt64E3Pt4HADAzMcLs0Z2w89eLSEzLgrO9JeaN7YzUzGzs4hKYZ5KiBusPeXt7w9vbGwBw/fp1hISEICwsTJaWPv59kZmRjrWrV+H27WS4uTfEZ2vWwtHRSZaekojQKUIjIEZn8q1bmDtrOjIz0mFlbYNmzVtizYYtsHdwlDtNiwjnUoRGQIxOERoBMTpFaATE6FRa48mLSRgesgPzxvnh3VEdcS0xA9NW/4hvfjoPACgsktCsQU2M7NkcVjVMkJR2D1Gn4zFqwfe4dz9PlubKJsjqE8WQ/TrrZTlz5gy8vLxQWFixVz9X1sw6UWWqrOusV7XKus46EdHT7L9cZ10OSrvO+t2cIrkTNMxNFLMivESyz6zv2rWr1NuvXLmipxIiIiIiImWRfbAeGBgIlUpV6gtKlXYJKCIiIiL6jzisqxDZ5/4dHBwQERGBoqIinVtMTIzciUREREREspB9sO7t7V3qgLysWXciIiIiEodKQf+JQPZlMNOmTUNWVsnXDXVzc0NkZKQei4iIiIiIlEH2wbqvr2+pt5uZmcHPz09PNUREREREyiH7YJ2IiIiInh28bkjFyL5mnYiIiIiIdONgnYiIiIhIobgMhoiIiIj0hqtgKoYz60RERERECsXBOhERERGRQnEZDBERERHpD9fBVAhn1omIiIiIFIoz60RERESkNypOrVcIZ9aJiIiIiMpp1apVqF+/PkxMTODt7Y1ff/211OOjoqLg7e0NExMTNGjQAGvWrKnQ83GwTkRERERUDuHh4Zg8eTJmzZqFU6dOwdfXF/7+/oiPj9d5/NWrV9G3b1/4+vri1KlTePfdd/HWW28hIiKi3M+pkiRJqqx3QElyCuQuICruzv18uRPKxcLUSO4EIiLFs+6zWO6Ecrl/aKbcCVqUNEYzqeCC8Hbt2sHLywurV6/W7GvSpAkCAwMRGhpa7PgZM2Zg165diI2N1ex77bXXcObMGRw5cqRcz8mZdSIiIiKiMuTl5eHkyZPo1auX1v5evXohOjpa532OHDlS7PjevXvjxIkTyM8v3wQeX2BKRERERM+k3Nxc5Obmau1Tq9VQq9XFjk1JSUFhYSFq166ttb927dpISkrS+fhJSUk6jy8oKEBKSgocHBzKjpSoXHJycqSQkBApJydH7pQSidAoSWJ0itAoSWJ0itAoSWJ0itAoSWJ0itAoSWJ0itAoSWJ0itD4tAkJCZEAaG0hISE6j71x44YEQIqOjtbav2DBAqlRo0Y67+Pu7i4tWrRIa9/hw4clAFJiYmK5Gp/aNeuV7c6dO7C0tERmZiYsLCzkztFJhEZAjE4RGgExOkVoBMToFKEREKNThEZAjE4RGgExOkVofNpUZGY9Ly8P1atXx/bt2zFw4EDN/kmTJuH06dOIiooqdp/OnTvD09MTy5cv1+z77rvvMGzYMGRnZ8PIqOzXiHHNOhERERE9k9RqNSwsLLQ2XQN1ADA2Noa3tzcOHjyotf/gwYPo0KGDzvv4+PgUO/7AgQNo3bp1uQbqAAfrRERERETlMnXqVKxbtw5hYWGIjY3FlClTEB8fj9deew0AEBwcjNGjR2uOf+211xAXF4epU6ciNjYWYWFhWL9+Pd55551yPydfYEpEREREVA7Dhw9Hamoq5s2bh8TERDRv3hx79uyBs7MzACAxMVHrmuv169fHnj17MGXKFHz22WdwdHTEihUrMHjw4HI/Jwfr5aRWqxESElLiP40ogQiNgBidIjQCYnSK0AiI0SlCIyBGpwiNgBidIjQCYnSK0EjAhAkTMGHCBJ23bdy4sdg+Pz8/xMTE/Ofn4wtMiYiIiIgUimvWiYiIiIgUioN1IiIiIiKF4mCdiIiIiEihOFgvwy+//IKAgAA4OjpCpVJh586dcicVExoaijZt2sDc3By1atVCYGAgLl68KHdWMatXr0bLli011zH18fHB3r175c4qVWhoKFQqFSZPnix3ipY5c+ZApVJpbfb29nJnFXPjxg28+OKLsLW1RfXq1dGqVSucPHlS7iwtLi4uxc6lSqXCxIkT5U7TKCgowOzZs1G/fn2YmpqiQYMGmDdvHoqKiuRO03L37l1MnjwZzs7OMDU1RYcOHXD8+HFZm8r6Hi5JEubMmQNHR0eYmpqiS5cuOHfunKIad+zYgd69e8POzg4qlQqnT5/Wa195OvPz8zFjxgy0aNECZmZmcHR0xOjRo3Hz5k3FNAIPvnc2btwYZmZmsLa2Ro8ePfD777/rtbE8nY969dVXoVKp8Mknn+itj5SFg/UyZGVlwcPDAytXrpQ7pURRUVGYOHEijh49ioMHD6KgoAC9evVCVlaW3Gla6tSpg8WLF+PEiRM4ceIEunXrhgEDBuj9B2N5HT9+HGvXrkXLli3lTtGpWbNmSExM1Gxnz56VO0lLeno6OnbsCCMjI+zduxfnz5/Hhx9+CCsrK7nTtBw/flzrPD784xVDhw6VuexfS5YswZo1a7By5UrExsZi6dKlWLZsGT799FO507SMGzcOBw8exKZNm3D27Fn06tULPXr0wI0bN2RrKut7+NKlS/HRRx9h5cqVOH78OOzt7dGzZ0/cvXtXMY1ZWVno2LEjFi9erLemkjpK6szOzkZMTAzee+89xMTEYMeOHbh06RL69++vmEYAaNiwIVauXImzZ8/i8OHDcHFxQa9evXD79m1FdT60c+dO/P7773B0dNRTGSmSROUGQPruu+/kzihTcnKyBECKioqSO6VM1tbW0rp16+TOKObu3buSu7u7dPDgQcnPz0+aNGmS3ElaQkJCJA8PD7kzSjVjxgypU6dOcmdU2KRJkyRXV1epqKhI7hSNfv36SWPHjtXaN2jQIOnFF1+Uqai47OxsycDAQNq9e7fWfg8PD2nWrFkyVWl7/Ht4UVGRZG9vLy1evFizLycnR7K0tJTWrFkjQ2HpP2euXr0qAZBOnTql1yZdyvPz8NixYxIAKS4uTj9RjylPY2ZmpgRAOnTokH6idCipMyEhQXJycpL+/PNPydnZWfr444/13kbKwJn1p1BmZiYAwMbGRuaSkhUWFuKbb75BVlYWfHx85M4pZuLEiejXrx969Oghd0qJLl++DEdHR9SvXx8jRozAlStX5E7SsmvXLrRu3RpDhw5FrVq14OnpiS+++ELurFLl5eXh66+/xtixY6FSqeTO0ejUqRN+/PFHXLp0CQBw5swZHD58GH379pW57F8FBQUoLCyEiYmJ1n5TU1McPnxYpqrSXb16FUlJSejVq5dmn1qthp+fH6Kjo2UsezpkZmZCpVIp7l/THsrLy8PatWthaWkJDw8PuXO0FBUVYdSoUZg2bRqaNWsmdw7JjH8U6SkjSRKmTp2KTp06oXnz5nLnFHP27Fn4+PggJycHNWrUwHfffYemTZvKnaXlm2++QUxMjOxrbUvTrl07fPXVV2jYsCFu3bqFBQsWoEOHDjh37hxsbW3lzgMAXLlyBatXr8bUqVPx7rvv4tixY3jrrbegVqu1/hSzkuzcuRMZGRl46aWX5E7RMmPGDGRmZqJx48YwMDBAYWEhFi5ciOeff17uNA1zc3P4+Phg/vz5aNKkCWrXro2tW7fi999/h7u7u9x5OiUlJQEAateurbW/du3aiIuLkyPpqZGTk4OZM2di5MiRsLCwkDtHy+7duzFixAhkZ2fDwcEBBw8ehJ2dndxZWpYsWQJDQ0O89dZbcqeQAnCw/pR544038Mcffyh2JqtRo0Y4ffo0MjIyEBERgaCgIERFRSlmwH79+nVMmjQJBw4cKDZDqCT+/v6a/2/RogV8fHzg6uqKL7/8ElOnTpWx7F9FRUVo3bo1Fi1aBADw9PTEuXPnsHr1asUO1tevXw9/f3/FrQ8NDw/H119/jS1btqBZs2Y4ffo0Jk+eDEdHRwQFBcmdp7Fp0yaMHTsWTk5OMDAwgJeXF0aOHPlEf7lPHx7/VxRJkhT1Lyuiyc/Px4gRI1BUVIRVq1bJnVNM165dcfr0aaSkpOCLL77AsGHD8Pvvv6NWrVpypwEATp48ieXLlyMmJoafhwSALzB9qrz55pvYtWsXIiMjUadOHblzdDI2Noabmxtat26N0NBQeHh4YPny5XJnaZw8eRLJycnw9vaGoaEhDA0NERUVhRUrVsDQ0BCFhYVyJ+pkZmaGFi1a4PLly3KnaDg4OBT7JaxJkyaIj4+Xqah0cXFxOHToEMaNGyd3SjHTpk3DzJkzMWLECLRo0QKjRo3ClClTEBoaKneaFldXV0RFReHevXu4fv06jh07hvz8fNSvX1/uNJ0eXkHp4Qz7Q8nJycVm26l88vPzMWzYMFy9ehUHDx5U3Kw68OD7pZubG9q3b4/169fD0NAQ69evlztL49dff0VycjLq1aun+TkUFxeHt99+Gy4uLnLnkQw4WH8KSJKEN954Azt27MBPP/2k2B+MukiShNzcXLkzNLp3746zZ8/i9OnTmq1169Z44YUXcPr0aRgYGMidqFNubi5iY2Ph4OAgd4pGx44di11C9NKlS3B2dpapqHQbNmxArVq10K9fP7lTisnOzka1atrfrg0MDBR36caHzMzM4ODggPT0dOzfvx8DBgyQO0mn+vXrw97eXnMFIODBOuaoqCh06NBBxjIxPRyoX758GYcOHVLMkryyKO3n0KhRo/DHH39o/RxydHTEtGnTsH//frnzSAZcBlOGe/fu4a+//tK8ffXqVZw+fRo2NjaoV6+ejGX/mjhxIrZs2YLvv/8e5ubmmlkiS0tLmJqaylz3r3fffRf+/v6oW7cu7t69i2+++QY///wz9u3bJ3eahrm5ebG1/mZmZrC1tVXUawDeeecdBAQEoF69ekhOTsaCBQtw584dRS2JmDJlCjp06IBFixZh2LBhOHbsGNauXYu1a9fKnVZMUVERNmzYgKCgIBgaKu/bYkBAABYuXIh69eqhWbNmOHXqFD766COMHTtW7jQt+/fvhyRJaNSoEf766y9MmzYNjRo1wpgxY2RrKut7+OTJk7Fo0SK4u7vD3d0dixYtQvXq1TFy5EjFNKalpSE+Pl5zzfKHvwTb29vr9e8rlNbp6OiIIUOGICYmBrt370ZhYaHmZ5GNjQ2MjY1lb7S1tcXChQvRv39/ODg4IDU1FatWrUJCQoLeL9Va1sf88V90jIyMYG9vj0aNGum1kxRCzkvRiCAyMlICUGwLCgqSO01DVx8AacOGDXKnaRk7dqzk7OwsGRsbSzVr1pS6d+8uHThwQO6sMinx0o3Dhw+XHBwcJCMjI8nR0VEaNGiQdO7cObmzivnhhx+k5s2bS2q1WmrcuLG0du1auZN02r9/vwRAunjxotwpOt25c0eaNGmSVK9ePcnExERq0KCBNGvWLCk3N1fuNC3h4eFSgwYNJGNjY8ne3l6aOHGilJGRIWtTWd/Di4qKpJCQEMne3l5Sq9VS586dpbNnzyqqccOGDTpvDwkJUUznw8tK6toiIyMV0Xj//n1p4MCBkqOjo2RsbCw5ODhI/fv3l44dO6a3vvJ06sJLNz7bVJIkSZX/KwARERERET0prlknIiIiIlIoDtaJiIiIiBSKg3UiIiIiIoXiYJ2IiIiISKE4WCciIiIiUigO1omIiIiIFIqDdSIiIiIiheJgnYiIiIhIoThYJ6IqtXHjRqhUKs1maGiIOnXqYMyYMbhx44ZeGlxcXPDSSy9p3v7555+hUqnw888/V+hxoqOjMWfOHGRkZFRqHwC89NJLcHFxKfO4Ll26oHnz5pXynA8/NidOnKiUx3v0Ma9du1Zpj0lE9CzjYJ2I9GLDhg04cuQIDh48iPHjx2Pr1q3w9fVFVlaW3lu8vLxw5MgReHl5Veh+0dHRmDt3bpUM1omIiHQxlDuAiJ4NzZs3R+vWrQEAXbt2RWFhIebPn4+dO3fihRde0Hmf7OxsVK9evdJbLCws0L59+0p/XCIiosrGmXUiksXDwXJcXByAB8tAatSogbNnz6JXr14wNzdH9+7dAQB5eXlYsGABGjduDLVajZo1a2LMmDG4ffu21mPm5+dj+vTpsLe3R/Xq1dGpUyccO3as2HOXtAzm999/R0BAAGxtbWFiYgJXV1dMnjwZADBnzhxMmzYNAFC/fn3Nsp5HHyM8PBw+Pj4wMzNDjRo10Lt3b5w6darY82/cuBGNGjWCWq1GkyZN8NVXX/2nc1iSEydOYMSIEXBxcYGpqSlcXFzw/PPPa87149LT0zFmzBjY2NjAzMwMAQEBuHLlSrHjDh06hO7du8PCwgLVq1dHx44d8eOPP1ZqOxERaeNgnYhk8ddffwEAatasqdmXl5eH/v37o1u3bvj+++8xd+5cFBUVYcCAAVi8eDFGjhyJ//3vf1i8eDEOHjyILl264P79+5r7jx8/Hh988AFGjx6N77//HoMHD8agQYOQnp5eZs/+/fvh6+uL+Ph4fPTRR9i7dy9mz56NW7duAQDGjRuHN998EwCwY8cOHDlyRGspzaJFi/D888+jadOm2LZtGzZt2oS7d+/C19cX58+f1zzPxo0bMWbMGDRp0gQRERGYPXs25s+fj59++unJT+o/rl27hkaNGuGTTz7B/v37sWTJEiQmJqJNmzZISUkpdvzLL7+MatWqYcuWLfjkk09w7NgxdOnSRWu5z9dff41evXrBwsICX375JbZt2wYbGxv07t2bA3YioqokERFVoQ0bNkgApKNHj0r5+fnS3bt3pd27d0s1a9aUzM3NpaSkJEmSJCkoKEgCIIWFhWndf+vWrRIAKSIiQmv/8ePHJQDSqlWrJEmSpNjYWAmANGXKFK3jNm/eLAGQgoKCNPsiIyMlAFJkZKRmn6urq+Tq6irdv3+/xPdl2bJlEgDp6tWrWvvj4+MlQ0ND6c0339Taf/fuXcne3l4aNmyYJEmSVFhYKDk6OkpeXl5SUVGR5rhr165JRkZGkrOzc4nP/ZCfn5/UrFmzMo97VEFBgXTv3j3JzMxMWr58uWb/w4/NwIEDtY7/7bffJADSggULJEmSpKysLMnGxkYKCAjQOq6wsFDy8PCQ2rZtW+wxHz9HRET033BmnYj0on379jAyMoK5uTmee+452NvbY+/evahdu7bWcYMHD9Z6e/fu3bCyskJAQAAKCgo0W6tWrWBvb69ZhhIZGQkAxda/Dxs2DIaGpb8859KlS/j777/x8ssvw8TEpMLv2/79+1FQUIDRo0drNZqYmMDPz0/TePHiRdy8eRMjR46ESqXS3N/Z2RkdOnSo8POW5N69e5gxYwbc3NxgaGgIQ0ND1KhRA1lZWYiNjS12/OPnrEOHDnB2dtac0+joaKSlpSEoKEjr/SsqKkKfPn1w/PhxWV4oTET0LOALTIlIL7766is0adIEhoaGqF27NhwcHIodU716dVhYWGjtu3XrFjIyMmBsbKzzcR8u60hNTQUA2Nvba91uaGgIW1vbUtsern2vU6dO+d6ZxzxcKtOmTRudt1erVq3Uxof7KutyhyNHjsSPP/6I9957D23atIGFhQVUKhX69u2rtWzo0efWte9h78P3b8iQISU+Z1paGszMzCqln4iI/sXBOhHpRZMmTTRXgynJo7PND9nZ2cHW1hb79u3TeR9zc3MA0AzIk5KS4OTkpLm9oKBAM+gsycN18wkJCaUeVxI7OzsAwLfffgtnZ+cSj3u08XG69v0XmZmZ2L17N0JCQjBz5kzN/tzcXKSlpem8T0k9bm5uAP59/z799NMSr6Lz+L+QEBFR5eBgnYgU7bnnnsM333yDwsJCtGvXrsTjunTpAgDYvHkzvL29Nfu3bduGgoKCUp+jYcOGcHV1RVhYGKZOnQq1Wq3zuIf7H5+d7t27NwwNDfH3338XW8bzqEaNGsHBwQFbt27F1KlTNb+cxMXFITo6Go6OjqV2lodKpYIkScXeh3Xr1qGwsFDnfTZv3qzVHR0djbi4OIwbNw4A0LFjR1hZWeH8+fN44403nriRiIjKj4N1IlK0ESNGYPPmzejbty8mTZqEtm3bwsjICAkJCYiMjMSAAQMwcOBANGnSBC+++CI++eQTGBkZoUePHvjzzz/xwQcfFFtao8tnn32GgIAAtG/fHlOmTEG9evUQHx+P/fv3Y/PmzQCAFi1aAACWL1+OoKAgGBkZoVGjRnBxccG8efMwa9YsXLlyBX369IG1tTVu3bqFY8eOwczMDHPnzkW1atUwf/58jBs3DgMHDsT48eORkZGBOXPm6FyKUpI7d+7g22+/Lba/Zs2a8PPzQ+fOnbFs2TLY2dnBxcUFUVFRWL9+PaysrHQ+3okTJzBu3DgMHToU169fx6xZs+Dk5IQJEyYAAGrUqIFPP/0UQUFBSEtLw5AhQ1CrVi3cvn0bZ86cwe3bt7F69epy9xMRUQXI/QpXInq6Pbw6yPHjx0s9LigoSDIzM9N5W35+vvTBBx9IHh4ekomJiVSjRg2pcePG0quvvipdvnxZc1xubq709ttvS7Vq1ZJMTEyk9u3bS0eOHJGcnZ3LvBqMJEnSkSNHJH9/f8nS0lJSq9WSq6trsavLBAcHS46OjlK1atWKPcbOnTulrl27ShYWFpJarZacnZ2lIUOGSIcOHdJ6jHXr1knu7u6SsbGx1LBhQyksLEwKCgoq99VgAOjc/Pz8JEmSpISEBGnw4MGStbW1ZG5uLvXp00f6888/i52Hhx+bAwcOSKNGjZKsrKwkU1NTqW/fvlrn9aGoqCipX79+ko2NjWRkZCQ5OTlJ/fr1k7Zv317sMXk1GCKiyqGSJEmS6fcEIiIiIiIqBS/dSERERESkUBysExEREREpFAfrREREREQKxcE6EREREZFCcbBORERERKRQHKwTERERESkUB+tERERERArFwToRERERkUJxsE5EREREpFAcrBMRERERKRQH60RERERECsXBOhERERGRQv0fuNPPCGexGKEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 85.99%\n"
     ]
    }
   ],
   "source": [
    "class_names = [str(i+1) for i in range(len(np.unique(y_labels)))]\n",
    "confusion_matrices_dir = 'confusion_matrices'\n",
    "os.makedirs(confusion_matrices_dir, exist_ok=True)\n",
    "print(f\"Saving confusion matrices to: {confusion_matrices_dir}\")\n",
    "plot_conf_matrix('e2e_cnn', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_mlp', class_names, confusion_matrices_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:36:37.564174Z",
     "iopub.status.busy": "2025-05-08T19:36:37.564174Z",
     "iopub.status.idle": "2025-05-08T19:36:37.572044Z",
     "shell.execute_reply": "2025-05-08T19:36:37.572044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          97.27\n",
      "1    LRM (CAE)          77.64\n",
      "2    MLP (CAE)          58.35\n",
      "3     TSCL LRM          84.30\n",
      "4     TSCL MLP          84.44\n",
      "5  SCL_SDL LRM          85.85\n",
      "6  SCL_SDL MLP          85.99\n",
      "\n",
      "In Desc. Order (Test Accu)\n",
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          97.27\n",
      "6  SCL_SDL MLP          85.99\n",
      "5  SCL_SDL LRM          85.85\n",
      "4     TSCL MLP          84.44\n",
      "3     TSCL LRM          84.30\n",
      "1    LRM (CAE)          77.64\n",
      "2    MLP (CAE)          58.35\n"
     ]
    }
   ],
   "source": [
    "final_results_df = pd.DataFrame({\n",
    "    \"Model\": [\"E2E CNN\", \"LRM (CAE)\", \"MLP (CAE)\", \"TSCL LRM\", \"TSCL MLP\", \"SCL_SDL LRM\", \"SCL_SDL MLP\"],\n",
    "    \"Test_Accuracy\": [test_accuracy, lrm_test_accuracy * 100, cae_mlp_test_accuracy_pct, \n",
    "                      tscl_lrm_test_accuracy * 100, tscl_mlp_test_accuracy_pct, \n",
    "                      sclsdl_lrm_test_accuracy * 100, sclsdl_mlp_test_accuracy_pct]\n",
    "})\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "print(final_results_df)\n",
    "print(f\"\\nIn Desc. Order (Test Accu)\\n{final_results_df.sort_values('Test_Accuracy', ascending=False)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
