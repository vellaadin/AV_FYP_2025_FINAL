{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependancy Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:37.568495Z",
     "iopub.status.busy": "2025-05-08T19:07:37.567990Z",
     "iopub.status.idle": "2025-05-08T19:07:37.572856Z",
     "shell.execute_reply": "2025-05-08T19:07:37.572856Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:37.575862Z",
     "iopub.status.busy": "2025-05-08T19:07:37.575862Z",
     "iopub.status.idle": "2025-05-08T19:07:39.648423Z",
     "shell.execute_reply": "2025-05-08T19:07:39.648423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-metric-learning in c:\\users\\vella\\anaconda3\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.5.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (2.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (4.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vella\\anaconda3\\lib\\site-packages (from tqdm->pytorch-metric-learning) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:39.650429Z",
     "iopub.status.busy": "2025-05-08T19:07:39.650429Z",
     "iopub.status.idle": "2025-05-08T19:07:43.087653Z",
     "shell.execute_reply": "2025-05-08T19:07:43.087653Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nbformat\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "from torch.amp import autocast, GradScaler\n",
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:43.090674Z",
     "iopub.status.busy": "2025-05-08T19:07:43.089663Z",
     "iopub.status.idle": "2025-05-08T19:07:43.107057Z",
     "shell.execute_reply": "2025-05-08T19:07:43.107057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:43.109287Z",
     "iopub.status.busy": "2025-05-08T19:07:43.109287Z",
     "iopub.status.idle": "2025-05-08T19:07:44.056957Z",
     "shell.execute_reply": "2025-05-08T19:07:44.056957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: (1476, 256)\n",
      "Hypercube shape: (1476, 256, 145)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dir = r\"C:\\Users\\vella\\Documents\\GitHub\\FYP2425_LOCAL\\FYP_DATASET\"\n",
    "\n",
    "gt_files = 'Botswana_gt.mat'\n",
    "data_files = 'Botswana.mat'\n",
    "label_files = 'Botswana_gt'\n",
    "hypercube_files = 'Botswana'\n",
    "\n",
    "def extract_Features():\n",
    "    gt_file = os.path.join(dataset_dir, gt_files)\n",
    "    data_file = os.path.join(dataset_dir, data_files)\n",
    "\n",
    "    gt = sio.loadmat(gt_file)\n",
    "    labels = gt[label_files]\n",
    "\n",
    "    data = sio.loadmat(data_file)\n",
    "    hypercube = data[hypercube_files]\n",
    "    #scaling the data in place and setting to float32 to reduce memory usage\n",
    "    max_value = np.max(hypercube)\n",
    "    hypercube = (hypercube / max_value).astype(np.float32)\n",
    "\n",
    "\n",
    "    #shapes of loaded data\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Hypercube shape: {hypercube.shape}\")\n",
    "\n",
    "    #visualisation of label map and a given band of hyperspectral data\n",
    "    plt.figure()\n",
    "    plt.imshow(labels)\n",
    "    plt.title('Labels')\n",
    "\n",
    "    band = 101\n",
    "    plt.figure()\n",
    "    plt.imshow(hypercube[:,:,band])\n",
    "    plt.title(f'Hyperspectral Band {band}')\n",
    "    plt.show()\n",
    "\n",
    "    return hypercube, labels\n",
    "\n",
    "hypercube, labels = extract_Features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:44.060041Z",
     "iopub.status.busy": "2025-05-08T19:07:44.060041Z",
     "iopub.status.idle": "2025-05-08T19:07:44.067048Z",
     "shell.execute_reply": "2025-05-08T19:07:44.067048Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_windows(data, labels, window_size):\n",
    "    extract_windows_save_dir = 'extracted_windows_labels'\n",
    "    if not os.path.exists(extract_windows_save_dir):\n",
    "        os.makedirs(extract_windows_save_dir)\n",
    "        print(f\"Created directory: {extract_windows_save_dir}\")\n",
    "\n",
    "    margin = window_size // 2\n",
    "    padded_data = np.pad(data, ((margin, margin), (margin, margin), (0, 0)), mode='constant')\n",
    "    padded_labels = np.pad(labels, ((margin, margin), (margin, margin)), mode='constant')\n",
    "\n",
    "    X_windows = []  #extracted windows\n",
    "    y_labels = []   #corresponding labels\n",
    "\n",
    "    print(\"Starting window extraction...\")\n",
    "    for i in range(margin, padded_data.shape[0] - margin):\n",
    "        for j in range(margin, padded_data.shape[1] - margin):\n",
    "            window = padded_data[i-margin:i+margin+1, j-margin:j+margin+1, :]\n",
    "            label = padded_labels[i, j]\n",
    "\n",
    "            if label != 0:\n",
    "                #print('ignoring label 0 (background)')\n",
    "                X_windows.append(window)\n",
    "                y_labels.append(label)\n",
    "\n",
    "    #convertying to numpy arrays\n",
    "    X_windows = np.array(X_windows)\n",
    "    y_labels = np.array(y_labels)\n",
    "\n",
    "    #saving extracted windows and labels\n",
    "    windows_file = os.path.join(extract_windows_save_dir, 'extracted_windows.npy')\n",
    "    labels_file = os.path.join(extract_windows_save_dir, 'extracted_labels.npy')\n",
    "\n",
    "    np.save(windows_file, X_windows)\n",
    "    np.save(labels_file, y_labels)\n",
    "\n",
    "    print(f\"Saved extracted windows to: {windows_file}\")\n",
    "    print(f\"Saved corresponding labels to: {labels_file}\")\n",
    "    print(f\"\\nTotal windows extracted: {len(X_windows)}\")\n",
    "    print(f\"Extracted windows shape: {X_windows.shape}\")\n",
    "    print(f\"Corresponding labels shape: {y_labels.shape}\")\n",
    "\n",
    "    return X_windows, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:44.070063Z",
     "iopub.status.busy": "2025-05-08T19:07:44.069063Z",
     "iopub.status.idle": "2025-05-08T19:07:44.933818Z",
     "shell.execute_reply": "2025-05-08T19:07:44.933818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: extracted_windows_labels\n",
      "Starting window extraction...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved extracted windows to: extracted_windows_labels\\extracted_windows.npy\n",
      "Saved corresponding labels to: extracted_windows_labels\\extracted_labels.npy\n",
      "\n",
      "Total windows extracted: 3248\n",
      "Extracted windows shape: (3248, 5, 5, 145)\n",
      "Corresponding labels shape: (3248,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "\n",
    "X_windows, y_labels = extract_windows(hypercube, labels, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:44.936822Z",
     "iopub.status.busy": "2025-05-08T19:07:44.935822Z",
     "iopub.status.idle": "2025-05-08T19:07:44.944017Z",
     "shell.execute_reply": "2025-05-08T19:07:44.944017Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_samples(X_windows, y_labels, samples_per_class):\n",
    "    \n",
    "    indices_save_dir = 'indices'\n",
    "    if not os.path.exists(indices_save_dir):\n",
    "        os.makedirs(indices_save_dir)\n",
    "        print(f\"Created directory: {indices_save_dir}\")\n",
    "    \n",
    "    #get unique classes\n",
    "    classes = np.unique(y_labels)\n",
    "    print(f\"Unique classes found as: {classes}\")\n",
    "\n",
    "    #init lists\n",
    "    X_sampled = [] #to store training samples\n",
    "    y_sampled = [] #to store training labels\n",
    "\n",
    "    X_val = [] # to store validation samples\n",
    "    y_val = [] # to store validation labels\n",
    "\n",
    "    selected_indices_total = [] #to store indices of selected training and validation samples\n",
    "    validation_selected = [] #temp storage for validation indices\n",
    "    validation_total = [] #to store all validation indices\n",
    "\n",
    "    print(\"\\n == STARTING SAMPLING PROCESS ==\")\n",
    "    for cls in classes:\n",
    "        if cls == 0:\n",
    "            print(f\"!! SKIPPING CLASS 0 !!\")\n",
    "            continue\n",
    "\n",
    "        #getting the indices for the current class:\n",
    "        class_indices = np.where(y_labels == cls)[0]\n",
    "        print(f\"Class: {cls}: Found {len(class_indices)} samples\")\n",
    "\n",
    "        # shuffle class-specific indices to ensure randomness\n",
    "        np.random.shuffle(class_indices)\n",
    "        print(f\"Shuffled class indices for class '{cls}'\")\n",
    "\n",
    "        #select 'samples_per_class' samples for training\n",
    "        selected_indices = class_indices[:samples_per_class]\n",
    "        #selecting 5 samples for validation\n",
    "        validation_selected = class_indices[samples_per_class:samples_per_class+5]\n",
    "\n",
    "        print(f\"Selected {len(selected_indices)} training samples and {len(validation_selected)} validation samples for class '{cls}'\\n\")\n",
    "\n",
    "        #store selected indices for training and validation\n",
    "        selected_indices_total.extend(selected_indices)\n",
    "        validation_total.extend(validation_selected)\n",
    "\n",
    "        # appending the selected samples and their labels to the lists\n",
    "        X_sampled.append(X_windows[selected_indices])\n",
    "        y_sampled.append(y_labels[selected_indices])\n",
    "\n",
    "        X_val.append(X_windows[validation_selected])\n",
    "        y_val.append(y_labels[validation_selected])\n",
    "\n",
    "    #concat the sampled arrays for training\n",
    "    X_train = np.vstack(X_sampled)\n",
    "    y_train = np.hstack(y_sampled)\n",
    "\n",
    "    # shift labels to start from 0\n",
    "    y_train = y_train - 1\n",
    "\n",
    "    print(f\"\\n -- Training set created with: \\n\\t{X_train.shape[0]} samples\\n\\tshape {X_train.shape} --\")\n",
    "\n",
    "    #concat the sampled arrays for validation\n",
    "    X_val = np.vstack(X_val)\n",
    "    y_val = np.hstack(y_val)\n",
    "    y_val = y_val - 1\n",
    "\n",
    "    print(f\"\\n -- Validation set created with: \\n\\t{X_val.shape[0]} samples\\n\\tshape {X_val.shape} --\")\n",
    "\n",
    "    #create the test set from the remaining data (i.e. that which is not selected for training or validation)\n",
    "    selected_indices_total.extend(validation_total)\n",
    "\n",
    "    #getting indices not in the training or val sets\n",
    "    test_indices = np.setdiff1d(np.arange(X_windows.shape[0]), selected_indices_total)\n",
    "    X_test = X_windows[test_indices]\n",
    "    y_test = y_labels[test_indices]\n",
    "    y_test = y_test - 1\n",
    "\n",
    "    print(f\"\\n -- Test set created with: \\n\\t{X_test.shape[0]} samples\\n\\tshape {X_test.shape} --\\n\")\n",
    "\n",
    "    # Save the datasets to the 'datasets' folder\n",
    "    np.save(os.path.join(indices_save_dir, 'X_train.npy'), X_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_train.npy'), y_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_val.npy'), X_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_val.npy'), y_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_test.npy'), X_test)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_test.npy'), y_test)\n",
    "\n",
    "    print(f\"\\nAll datasets saved to the '{indices_save_dir}' folder.\")\n",
    "\n",
    "    #return the training, val, test sets + selected indices\n",
    "    return X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:44.946267Z",
     "iopub.status.busy": "2025-05-08T19:07:44.946267Z",
     "iopub.status.idle": "2025-05-08T19:07:45.157843Z",
     "shell.execute_reply": "2025-05-08T19:07:45.157843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: indices\n",
      "Unique classes found as: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      " == STARTING SAMPLING PROCESS ==\n",
      "Class: 1: Found 270 samples\n",
      "Shuffled class indices for class '1'\n",
      "Selected 20 training samples and 5 validation samples for class '1'\n",
      "\n",
      "Class: 2: Found 101 samples\n",
      "Shuffled class indices for class '2'\n",
      "Selected 20 training samples and 5 validation samples for class '2'\n",
      "\n",
      "Class: 3: Found 251 samples\n",
      "Shuffled class indices for class '3'\n",
      "Selected 20 training samples and 5 validation samples for class '3'\n",
      "\n",
      "Class: 4: Found 215 samples\n",
      "Shuffled class indices for class '4'\n",
      "Selected 20 training samples and 5 validation samples for class '4'\n",
      "\n",
      "Class: 5: Found 269 samples\n",
      "Shuffled class indices for class '5'\n",
      "Selected 20 training samples and 5 validation samples for class '5'\n",
      "\n",
      "Class: 6: Found 269 samples\n",
      "Shuffled class indices for class '6'\n",
      "Selected 20 training samples and 5 validation samples for class '6'\n",
      "\n",
      "Class: 7: Found 259 samples\n",
      "Shuffled class indices for class '7'\n",
      "Selected 20 training samples and 5 validation samples for class '7'\n",
      "\n",
      "Class: 8: Found 203 samples\n",
      "Shuffled class indices for class '8'\n",
      "Selected 20 training samples and 5 validation samples for class '8'\n",
      "\n",
      "Class: 9: Found 314 samples\n",
      "Shuffled class indices for class '9'\n",
      "Selected 20 training samples and 5 validation samples for class '9'\n",
      "\n",
      "Class: 10: Found 248 samples\n",
      "Shuffled class indices for class '10'\n",
      "Selected 20 training samples and 5 validation samples for class '10'\n",
      "\n",
      "Class: 11: Found 305 samples\n",
      "Shuffled class indices for class '11'\n",
      "Selected 20 training samples and 5 validation samples for class '11'\n",
      "\n",
      "Class: 12: Found 181 samples\n",
      "Shuffled class indices for class '12'\n",
      "Selected 20 training samples and 5 validation samples for class '12'\n",
      "\n",
      "Class: 13: Found 268 samples\n",
      "Shuffled class indices for class '13'\n",
      "Selected 20 training samples and 5 validation samples for class '13'\n",
      "\n",
      "Class: 14: Found 95 samples\n",
      "Shuffled class indices for class '14'\n",
      "Selected 20 training samples and 5 validation samples for class '14'\n",
      "\n",
      "\n",
      " -- Training set created with: \n",
      "\t280 samples\n",
      "\tshape (280, 5, 5, 145) --\n",
      "\n",
      " -- Validation set created with: \n",
      "\t70 samples\n",
      "\tshape (70, 5, 5, 145) --\n",
      "\n",
      " -- Test set created with: \n",
      "\t2898 samples\n",
      "\tshape (2898, 5, 5, 145) --\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All datasets saved to the 'indices' folder.\n",
      "(280, 5, 5, 145)\n",
      "(70, 5, 5, 145)\n",
      "(2898, 5, 5, 145)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total = get_samples(X_windows, y_labels, 20)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:45.162365Z",
     "iopub.status.busy": "2025-05-08T19:07:45.161365Z",
     "iopub.status.idle": "2025-05-08T19:07:45.166615Z",
     "shell.execute_reply": "2025-05-08T19:07:45.165599Z"
    }
   },
   "outputs": [],
   "source": [
    "class HyperspectralDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (numpy.ndarray): Hyperspectral data of shape (num_samples, height, width, num_bands).\n",
    "            y (numpy.ndarray): Labels of shape (num_samples,).\n",
    "        \"\"\"\n",
    "        #converting to pytorch tensor\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:45.169120Z",
     "iopub.status.busy": "2025-05-08T19:07:45.169120Z",
     "iopub.status.idle": "2025-05-08T19:07:45.230814Z",
     "shell.execute_reply": "2025-05-08T19:07:45.229809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 2 applied\n",
      "DataLoaders created successfully!\n",
      "Training batch size: 280\n",
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20}\n"
     ]
    }
   ],
   "source": [
    "#loading the saved datasets\n",
    "X_train = np.load('indices/X_train.npy')\n",
    "y_train = np.load('indices/y_train.npy')\n",
    "X_val = np.load('indices/X_val.npy')\n",
    "y_val = np.load('indices/y_val.npy')\n",
    "X_test = np.load('indices/X_test.npy')\n",
    "y_test = np.load('indices/y_test.npy')\n",
    "\n",
    "\n",
    "#creating pytorch datasets\n",
    "train_dataset = HyperspectralDataset(X_train, y_train)\n",
    "val_dataset = HyperspectralDataset(X_val, y_val)\n",
    "test_dataset = HyperspectralDataset(X_test, y_test)\n",
    "\n",
    "m = 20\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "#theoretical batch size calc\n",
    "required_batch_size = m * num_classes  # 10 * 9 = 90\n",
    "\n",
    "#ensuring batch size doesn't exceed training set size\n",
    "if required_batch_size > len(train_dataset):\n",
    "    #case 1: not enough samples - reduce m proportionally\n",
    "    print(\"Case 1 applied\")\n",
    "    max_possible_m = len(train_dataset) // num_classes\n",
    "    m = max(1, max_possible_m)\n",
    "    batch_size_train = m * num_classes\n",
    "else:\n",
    "    #case 2: use full batch size\n",
    "    print(\"Case 2 applied\")\n",
    "    batch_size_train = required_batch_size\n",
    "\n",
    "sampler = MPerClassSampler(labels = y_train, m=m, batch_size = batch_size_train, length_before_new_iter = len(train_dataset))\n",
    "\n",
    "#dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size_train, sampler=sampler)\n",
    "\n",
    "batch_size = 256\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")\n",
    "\n",
    "#class dist in first batch\n",
    "for X_batch, y_batch in train_loader:\n",
    "    unique, counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(f\"Training batch size: {batch_size_train}\")\n",
    "    print(\"Class distribution in batch:\", dict(zip(unique, counts)))\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating directory for saving model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:45.232815Z",
     "iopub.status.busy": "2025-05-08T19:07:45.232815Z",
     "iopub.status.idle": "2025-05-08T19:07:45.238921Z",
     "shell.execute_reply": "2025-05-08T19:07:45.238410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dir: model_predictions\n"
     ]
    }
   ],
   "source": [
    "predictions_dir = 'model_predictions'\n",
    "os.makedirs(predictions_dir, exist_ok=True)\n",
    "print(f\"Created dir: {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset splits and Dataloaders for unsupervised tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:45.240926Z",
     "iopub.status.busy": "2025-05-08T19:07:45.240926Z",
     "iopub.status.idle": "2025-05-08T19:07:45.257261Z",
     "shell.execute_reply": "2025-05-08T19:07:45.257261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2598, 5, 5, 145)\n",
      "Validation data shape: (650, 5, 5, 145)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = train_test_split(X_windows, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:45.260071Z",
     "iopub.status.busy": "2025-05-08T19:07:45.260071Z",
     "iopub.status.idle": "2025-05-08T19:07:45.263561Z",
     "shell.execute_reply": "2025-05-08T19:07:45.263561Z"
    }
   },
   "outputs": [],
   "source": [
    "class UnsupervisedDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)  #converting to pytorch tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:45.266617Z",
     "iopub.status.busy": "2025-05-08T19:07:45.266617Z",
     "iopub.status.idle": "2025-05-08T19:07:45.275600Z",
     "shell.execute_reply": "2025-05-08T19:07:45.275097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "#creating datasets for unsupervised task\n",
    "unsup_train_dataset = UnsupervisedDataset(X_train)\n",
    "unsup_val_dataset = UnsupervisedDataset(X_val)\n",
    "\n",
    "#dataloaders for unsupervised task\n",
    "batch_size = 64\n",
    "train_loader_cae = DataLoader(unsup_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader_cae = DataLoader(unsup_val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:45.277603Z",
     "iopub.status.busy": "2025-05-08T19:07:45.277603Z",
     "iopub.status.idle": "2025-05-08T19:07:45.281238Z",
     "shell.execute_reply": "2025-05-08T19:07:45.281238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    }
   ],
   "source": [
    "window_num_channels = X_windows.shape[3]\n",
    "print(window_num_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:45.283243Z",
     "iopub.status.busy": "2025-05-08T19:07:45.283243Z",
     "iopub.status.idle": "2025-05-08T19:07:45.289758Z",
     "shell.execute_reply": "2025-05-08T19:07:45.289758Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncode(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.1):\n",
    "        super(ConvAutoEncode, self).__init__()\n",
    "\n",
    "        #encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            #Block 1\n",
    "            nn.Conv2d(window_num_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            #Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            #Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(64, window_num_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:07:45.293765Z",
     "iopub.status.busy": "2025-05-08T19:07:45.292763Z",
     "iopub.status.idle": "2025-05-08T19:08:07.289834Z",
     "shell.execute_reply": "2025-05-08T19:08:07.289834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1/41], Loss: 0.2200, PSNR: -8.3967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Training Loss: 0.2125, PSNR: -8.7242\n",
      "\t[Val]   Batch [1/11] Loss: 0.2035, PSNR: -6.1228\n",
      "\t[Val]   Batch [10/11] Loss: 0.2036, PSNR: -8.3616\n",
      "Epoch [1/50] Validation Loss: 0.2035, PSNR: -8.0536\n",
      "\n",
      "LOG: Epoch [2/50]\n",
      "\t Training Batch [1/41], Loss: 0.1985, PSNR: -9.3268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Training Loss: 0.1901, PSNR: -8.3894\n",
      "\t[Val]   Batch [1/11] Loss: 0.1775, PSNR: -5.5286\n",
      "\t[Val]   Batch [10/11] Loss: 0.1777, PSNR: -7.7692\n",
      "Epoch [2/50] Validation Loss: 0.1773, PSNR: -7.4562\n",
      "\n",
      "LOG: Epoch [3/50]\n",
      "\t Training Batch [1/41], Loss: 0.1768, PSNR: -8.9325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Training Loss: 0.1689, PSNR: -7.7130\n",
      "\t[Val]   Batch [1/11] Loss: 0.1518, PSNR: -4.8489\n",
      "\t[Val]   Batch [10/11] Loss: 0.1519, PSNR: -7.0882\n",
      "Epoch [3/50] Validation Loss: 0.1517, PSNR: -6.7779\n",
      "\n",
      "LOG: Epoch [4/50]\n",
      "\t Training Batch [1/41], Loss: 0.1555, PSNR: -7.3762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] Training Loss: 0.1484, PSNR: -7.2266\n",
      "\t[Val]   Batch [1/11] Loss: 0.1319, PSNR: -4.2403\n",
      "\t[Val]   Batch [10/11] Loss: 0.1320, PSNR: -6.4803\n",
      "Epoch [4/50] Validation Loss: 0.1318, PSNR: -6.1685\n",
      "\n",
      "LOG: Epoch [5/50]\n",
      "\t Training Batch [1/41], Loss: 0.1356, PSNR: -7.3018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] Training Loss: 0.1291, PSNR: -6.5635\n",
      "\t[Val]   Batch [1/11] Loss: 0.1141, PSNR: -3.6086\n",
      "\t[Val]   Batch [10/11] Loss: 0.1141, PSNR: -5.8448\n",
      "Epoch [5/50] Validation Loss: 0.1139, PSNR: -5.5345\n",
      "\n",
      "LOG: Epoch [6/50]\n",
      "\t Training Batch [1/41], Loss: 0.1165, PSNR: -5.9366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] Training Loss: 0.1116, PSNR: -6.0879\n",
      "\t[Val]   Batch [1/11] Loss: 0.0972, PSNR: -2.9123\n",
      "\t[Val]   Batch [10/11] Loss: 0.0971, PSNR: -5.1458\n",
      "Epoch [6/50] Validation Loss: 0.0971, PSNR: -4.8381\n",
      "\n",
      "LOG: Epoch [7/50]\n",
      "\t Training Batch [1/41], Loss: 0.1001, PSNR: -4.3583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] Training Loss: 0.0962, PSNR: -5.3479\n",
      "\t[Val]   Batch [1/11] Loss: 0.0860, PSNR: -2.3841\n",
      "\t[Val]   Batch [10/11] Loss: 0.0860, PSNR: -4.6198\n",
      "Epoch [7/50] Validation Loss: 0.0860, PSNR: -4.3117\n",
      "\n",
      "LOG: Epoch [8/50]\n",
      "\t Training Batch [1/41], Loss: 0.0880, PSNR: -4.0674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] Training Loss: 0.0830, PSNR: -4.8694\n",
      "\t[Val]   Batch [1/11] Loss: 0.0734, PSNR: -1.6927\n",
      "\t[Val]   Batch [10/11] Loss: 0.0734, PSNR: -3.9294\n",
      "Epoch [8/50] Validation Loss: 0.0733, PSNR: -3.6195\n",
      "\n",
      "LOG: Epoch [9/50]\n",
      "\t Training Batch [1/41], Loss: 0.0752, PSNR: -3.7347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] Training Loss: 0.0717, PSNR: -3.8670\n",
      "\t[Val]   Batch [1/11] Loss: 0.0651, PSNR: -1.1751\n",
      "\t[Val]   Batch [10/11] Loss: 0.0651, PSNR: -3.4115\n",
      "Epoch [9/50] Validation Loss: 0.0651, PSNR: -3.1034\n",
      "\n",
      "LOG: Epoch [10/50]\n",
      "\t Training Batch [1/41], Loss: 0.0642, PSNR: -2.6959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] Training Loss: 0.0622, PSNR: -3.4974\n",
      "\t[Val]   Batch [1/11] Loss: 0.0561, PSNR: -0.5229\n",
      "\t[Val]   Batch [10/11] Loss: 0.0561, PSNR: -2.7589\n",
      "Epoch [10/50] Validation Loss: 0.0560, PSNR: -2.4513\n",
      "\n",
      "LOG: Epoch [11/50]\n",
      "\t Training Batch [1/41], Loss: 0.0579, PSNR: -4.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] Training Loss: 0.0543, PSNR: -2.9185\n",
      "\t[Val]   Batch [1/11] Loss: 0.0504, PSNR: -0.0596\n",
      "\t[Val]   Batch [10/11] Loss: 0.0504, PSNR: -2.2962\n",
      "Epoch [11/50] Validation Loss: 0.0504, PSNR: -1.9889\n",
      "\n",
      "LOG: Epoch [12/50]\n",
      "\t Training Batch [1/41], Loss: 0.0497, PSNR: -4.3586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] Training Loss: 0.0478, PSNR: -2.5103\n",
      "\t[Val]   Batch [1/11] Loss: 0.0440, PSNR: 0.5263\n",
      "\t[Val]   Batch [10/11] Loss: 0.0440, PSNR: -1.7099\n",
      "Epoch [12/50] Validation Loss: 0.0440, PSNR: -1.4029\n",
      "\n",
      "LOG: Epoch [13/50]\n",
      "\t Training Batch [1/41], Loss: 0.0435, PSNR: -2.2240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50] Training Loss: 0.0422, PSNR: -1.8391\n",
      "\t[Val]   Batch [1/11] Loss: 0.0394, PSNR: 1.0035\n",
      "\t[Val]   Batch [10/11] Loss: 0.0394, PSNR: -1.2330\n",
      "Epoch [13/50] Validation Loss: 0.0394, PSNR: -0.9266\n",
      "\n",
      "LOG: Epoch [14/50]\n",
      "\t Training Batch [1/41], Loss: 0.0392, PSNR: -1.3880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50] Training Loss: 0.0376, PSNR: -1.2232\n",
      "\t[Val]   Batch [1/11] Loss: 0.0355, PSNR: 1.4647\n",
      "\t[Val]   Batch [10/11] Loss: 0.0355, PSNR: -0.7727\n",
      "Epoch [14/50] Validation Loss: 0.0355, PSNR: -0.4654\n",
      "\n",
      "LOG: Epoch [15/50]\n",
      "\t Training Batch [1/41], Loss: 0.0354, PSNR: -3.0973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50] Training Loss: 0.0337, PSNR: -0.9024\n",
      "\t[Val]   Batch [1/11] Loss: 0.0321, PSNR: 1.8926\n",
      "\t[Val]   Batch [10/11] Loss: 0.0322, PSNR: -0.3468\n",
      "Epoch [15/50] Validation Loss: 0.0321, PSNR: -0.0380\n",
      "\n",
      "LOG: Epoch [16/50]\n",
      "\t Training Batch [1/41], Loss: 0.0316, PSNR: -1.9604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] Training Loss: 0.0304, PSNR: -0.4202\n",
      "\t[Val]   Batch [1/11] Loss: 0.0290, PSNR: 2.3463\n",
      "\t[Val]   Batch [10/11] Loss: 0.0290, PSNR: 0.1058\n",
      "Epoch [16/50] Validation Loss: 0.0289, PSNR: 0.4155\n",
      "\n",
      "LOG: Epoch [17/50]\n",
      "\t Training Batch [1/41], Loss: 0.0286, PSNR: -1.8288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50] Training Loss: 0.0275, PSNR: 0.0015\n",
      "\t[Val]   Batch [1/11] Loss: 0.0261, PSNR: 2.7965\n",
      "\t[Val]   Batch [10/11] Loss: 0.0261, PSNR: 0.5551\n",
      "Epoch [17/50] Validation Loss: 0.0261, PSNR: 0.8656\n",
      "\n",
      "LOG: Epoch [18/50]\n",
      "\t Training Batch [1/41], Loss: 0.0256, PSNR: -1.0521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50] Training Loss: 0.0250, PSNR: 0.6353\n",
      "\t[Val]   Batch [1/11] Loss: 0.0241, PSNR: 3.1505\n",
      "\t[Val]   Batch [10/11] Loss: 0.0241, PSNR: 0.9103\n",
      "Epoch [18/50] Validation Loss: 0.0241, PSNR: 1.2192\n",
      "\n",
      "LOG: Epoch [19/50]\n",
      "\t Training Batch [1/41], Loss: 0.0240, PSNR: 0.3616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50] Training Loss: 0.0229, PSNR: 0.9510\n",
      "\t[Val]   Batch [1/11] Loss: 0.0220, PSNR: 3.5367\n",
      "\t[Val]   Batch [10/11] Loss: 0.0220, PSNR: 1.2965\n",
      "Epoch [19/50] Validation Loss: 0.0220, PSNR: 1.6055\n",
      "\n",
      "LOG: Epoch [20/50]\n",
      "\t Training Batch [1/41], Loss: 0.0219, PSNR: 3.5672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50] Training Loss: 0.0210, PSNR: 1.3996\n",
      "\t[Val]   Batch [1/11] Loss: 0.0203, PSNR: 3.8901\n",
      "\t[Val]   Batch [10/11] Loss: 0.0203, PSNR: 1.6502\n",
      "Epoch [20/50] Validation Loss: 0.0203, PSNR: 1.9594\n",
      "\n",
      "LOG: Epoch [21/50]\n",
      "\t Training Batch [1/41], Loss: 0.0196, PSNR: 0.6203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50] Training Loss: 0.0193, PSNR: 1.6942\n",
      "\t[Val]   Batch [1/11] Loss: 0.0187, PSNR: 4.2549\n",
      "\t[Val]   Batch [10/11] Loss: 0.0187, PSNR: 2.0161\n",
      "Epoch [21/50] Validation Loss: 0.0187, PSNR: 2.3246\n",
      "\n",
      "LOG: Epoch [22/50]\n",
      "\t Training Batch [1/41], Loss: 0.0185, PSNR: 2.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50] Training Loss: 0.0179, PSNR: 1.8437\n",
      "\t[Val]   Batch [1/11] Loss: 0.0173, PSNR: 4.5827\n",
      "\t[Val]   Batch [10/11] Loss: 0.0173, PSNR: 2.3450\n",
      "Epoch [22/50] Validation Loss: 0.0173, PSNR: 2.6534\n",
      "\n",
      "LOG: Epoch [23/50]\n",
      "\t Training Batch [1/41], Loss: 0.0167, PSNR: 4.7295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50] Training Loss: 0.0165, PSNR: 2.2356\n",
      "\t[Val]   Batch [1/11] Loss: 0.0162, PSNR: 4.8772\n",
      "\t[Val]   Batch [10/11] Loss: 0.0162, PSNR: 2.6395\n",
      "Epoch [23/50] Validation Loss: 0.0162, PSNR: 2.9490\n",
      "\n",
      "LOG: Epoch [24/50]\n",
      "\t Training Batch [1/41], Loss: 0.0154, PSNR: 3.7598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50] Training Loss: 0.0154, PSNR: 2.6309\n",
      "\t[Val]   Batch [1/11] Loss: 0.0151, PSNR: 5.1815\n",
      "\t[Val]   Batch [10/11] Loss: 0.0151, PSNR: 2.9437\n",
      "Epoch [24/50] Validation Loss: 0.0151, PSNR: 3.2539\n",
      "\n",
      "LOG: Epoch [25/50]\n",
      "\t Training Batch [1/41], Loss: 0.0151, PSNR: 1.7507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50] Training Loss: 0.0144, PSNR: 2.8064\n",
      "\t[Val]   Batch [1/11] Loss: 0.0140, PSNR: 5.5088\n",
      "\t[Val]   Batch [10/11] Loss: 0.0140, PSNR: 3.2704\n",
      "Epoch [25/50] Validation Loss: 0.0140, PSNR: 3.5806\n",
      "\n",
      "LOG: Epoch [26/50]\n",
      "\t Training Batch [1/41], Loss: 0.0140, PSNR: 5.5026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50] Training Loss: 0.0134, PSNR: 2.9720\n",
      "\t[Val]   Batch [1/11] Loss: 0.0130, PSNR: 5.8132\n",
      "\t[Val]   Batch [10/11] Loss: 0.0130, PSNR: 3.5744\n",
      "Epoch [26/50] Validation Loss: 0.0130, PSNR: 3.8849\n",
      "\n",
      "LOG: Epoch [27/50]\n",
      "\t Training Batch [1/41], Loss: 0.0128, PSNR: 5.8862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50] Training Loss: 0.0126, PSNR: 3.5211\n",
      "\t[Val]   Batch [1/11] Loss: 0.0123, PSNR: 6.0499\n",
      "\t[Val]   Batch [10/11] Loss: 0.0123, PSNR: 3.8115\n",
      "Epoch [27/50] Validation Loss: 0.0123, PSNR: 4.1211\n",
      "\n",
      "LOG: Epoch [28/50]\n",
      "\t Training Batch [1/41], Loss: 0.0117, PSNR: 2.8465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50] Training Loss: 0.0118, PSNR: 3.7865\n",
      "\t[Val]   Batch [1/11] Loss: 0.0116, PSNR: 6.3357\n",
      "\t[Val]   Batch [10/11] Loss: 0.0116, PSNR: 4.0979\n",
      "Epoch [28/50] Validation Loss: 0.0115, PSNR: 4.4074\n",
      "\n",
      "LOG: Epoch [29/50]\n",
      "\t Training Batch [1/41], Loss: 0.0109, PSNR: 4.1575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50] Training Loss: 0.0111, PSNR: 4.1739\n",
      "\t[Val]   Batch [1/11] Loss: 0.0108, PSNR: 6.6225\n",
      "\t[Val]   Batch [10/11] Loss: 0.0108, PSNR: 4.3843\n",
      "Epoch [29/50] Validation Loss: 0.0108, PSNR: 4.6949\n",
      "\n",
      "LOG: Epoch [30/50]\n",
      "\t Training Batch [1/41], Loss: 0.0105, PSNR: 3.9629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50] Training Loss: 0.0104, PSNR: 4.0912\n",
      "\t[Val]   Batch [1/11] Loss: 0.0103, PSNR: 6.8357\n",
      "\t[Val]   Batch [10/11] Loss: 0.0103, PSNR: 4.5972\n",
      "Epoch [30/50] Validation Loss: 0.0103, PSNR: 4.9079\n",
      "\n",
      "LOG: Epoch [31/50]\n",
      "\t Training Batch [1/41], Loss: 0.0098, PSNR: 7.0504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50] Training Loss: 0.0098, PSNR: 4.4101\n",
      "\t[Val]   Batch [1/11] Loss: 0.0097, PSNR: 7.1030\n",
      "\t[Val]   Batch [10/11] Loss: 0.0097, PSNR: 4.8647\n",
      "Epoch [31/50] Validation Loss: 0.0097, PSNR: 5.1756\n",
      "\n",
      "LOG: Epoch [32/50]\n",
      "\t Training Batch [1/41], Loss: 0.0095, PSNR: 4.2674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50] Training Loss: 0.0093, PSNR: 4.8374\n",
      "\t[Val]   Batch [1/11] Loss: 0.0092, PSNR: 7.3415\n",
      "\t[Val]   Batch [10/11] Loss: 0.0092, PSNR: 5.1031\n",
      "Epoch [32/50] Validation Loss: 0.0092, PSNR: 5.4141\n",
      "\n",
      "LOG: Epoch [33/50]\n",
      "\t Training Batch [1/41], Loss: 0.0092, PSNR: 5.4132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50] Training Loss: 0.0088, PSNR: 5.0922\n",
      "\t[Val]   Batch [1/11] Loss: 0.0087, PSNR: 7.5493\n",
      "\t[Val]   Batch [10/11] Loss: 0.0087, PSNR: 5.3121\n",
      "Epoch [33/50] Validation Loss: 0.0087, PSNR: 5.6217\n",
      "\n",
      "LOG: Epoch [34/50]\n",
      "\t Training Batch [1/41], Loss: 0.0085, PSNR: 5.2623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50] Training Loss: 0.0084, PSNR: 5.3142\n",
      "\t[Val]   Batch [1/11] Loss: 0.0082, PSNR: 7.8267\n",
      "\t[Val]   Batch [10/11] Loss: 0.0082, PSNR: 5.5899\n",
      "Epoch [34/50] Validation Loss: 0.0082, PSNR: 5.8999\n",
      "\n",
      "LOG: Epoch [35/50]\n",
      "\t Training Batch [1/41], Loss: 0.0079, PSNR: 5.1754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50] Training Loss: 0.0079, PSNR: 5.6556\n",
      "\t[Val]   Batch [1/11] Loss: 0.0078, PSNR: 8.0382\n",
      "\t[Val]   Batch [10/11] Loss: 0.0078, PSNR: 5.8014\n",
      "Epoch [35/50] Validation Loss: 0.0078, PSNR: 6.1116\n",
      "\n",
      "LOG: Epoch [36/50]\n",
      "\t Training Batch [1/41], Loss: 0.0075, PSNR: 6.2734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50] Training Loss: 0.0075, PSNR: 5.7741\n",
      "\t[Val]   Batch [1/11] Loss: 0.0075, PSNR: 8.2342\n",
      "\t[Val]   Batch [10/11] Loss: 0.0075, PSNR: 5.9984\n",
      "Epoch [36/50] Validation Loss: 0.0075, PSNR: 6.3079\n",
      "\n",
      "LOG: Epoch [37/50]\n",
      "\t Training Batch [1/41], Loss: 0.0070, PSNR: 6.9178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50] Training Loss: 0.0072, PSNR: 6.0318\n",
      "\t[Val]   Batch [1/11] Loss: 0.0071, PSNR: 8.4687\n",
      "\t[Val]   Batch [10/11] Loss: 0.0071, PSNR: 6.2331\n",
      "Epoch [37/50] Validation Loss: 0.0071, PSNR: 6.5424\n",
      "\n",
      "LOG: Epoch [38/50]\n",
      "\t Training Batch [1/41], Loss: 0.0072, PSNR: 4.4565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50] Training Loss: 0.0068, PSNR: 5.9624\n",
      "\t[Val]   Batch [1/11] Loss: 0.0068, PSNR: 8.6654\n",
      "\t[Val]   Batch [10/11] Loss: 0.0068, PSNR: 6.4308\n",
      "Epoch [38/50] Validation Loss: 0.0067, PSNR: 6.7396\n",
      "\n",
      "LOG: Epoch [39/50]\n",
      "\t Training Batch [1/41], Loss: 0.0066, PSNR: 4.3213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50] Training Loss: 0.0065, PSNR: 6.2922\n",
      "\t[Val]   Batch [1/11] Loss: 0.0064, PSNR: 8.8968\n",
      "\t[Val]   Batch [10/11] Loss: 0.0064, PSNR: 6.6612\n",
      "Epoch [39/50] Validation Loss: 0.0064, PSNR: 6.9715\n",
      "\n",
      "LOG: Epoch [40/50]\n",
      "\t Training Batch [1/41], Loss: 0.0063, PSNR: 6.5696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50] Training Loss: 0.0062, PSNR: 6.6156\n",
      "\t[Val]   Batch [1/11] Loss: 0.0061, PSNR: 9.0744\n",
      "\t[Val]   Batch [10/11] Loss: 0.0061, PSNR: 6.8391\n",
      "Epoch [40/50] Validation Loss: 0.0061, PSNR: 7.1499\n",
      "\n",
      "LOG: Epoch [41/50]\n",
      "\t Training Batch [1/41], Loss: 0.0059, PSNR: 7.9410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50] Training Loss: 0.0059, PSNR: 6.6528\n",
      "\t[Val]   Batch [1/11] Loss: 0.0059, PSNR: 9.2288\n",
      "\t[Val]   Batch [10/11] Loss: 0.0059, PSNR: 6.9939\n",
      "Epoch [41/50] Validation Loss: 0.0059, PSNR: 7.3049\n",
      "\n",
      "LOG: Epoch [42/50]\n",
      "\t Training Batch [1/41], Loss: 0.0060, PSNR: 5.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50] Training Loss: 0.0057, PSNR: 6.9854\n",
      "\t[Val]   Batch [1/11] Loss: 0.0056, PSNR: 9.4529\n",
      "\t[Val]   Batch [10/11] Loss: 0.0056, PSNR: 7.2186\n",
      "Epoch [42/50] Validation Loss: 0.0056, PSNR: 7.5295\n",
      "\n",
      "LOG: Epoch [43/50]\n",
      "\t Training Batch [1/41], Loss: 0.0054, PSNR: 8.0394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50] Training Loss: 0.0054, PSNR: 7.2006\n",
      "\t[Val]   Batch [1/11] Loss: 0.0054, PSNR: 9.6637\n",
      "\t[Val]   Batch [10/11] Loss: 0.0054, PSNR: 7.4302\n",
      "Epoch [43/50] Validation Loss: 0.0054, PSNR: 7.7405\n",
      "\n",
      "LOG: Epoch [44/50]\n",
      "\t Training Batch [1/41], Loss: 0.0054, PSNR: 6.6993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50] Training Loss: 0.0052, PSNR: 7.1868\n",
      "\t[Val]   Batch [1/11] Loss: 0.0052, PSNR: 9.8244\n",
      "\t[Val]   Batch [10/11] Loss: 0.0052, PSNR: 7.5915\n",
      "Epoch [44/50] Validation Loss: 0.0052, PSNR: 7.9007\n",
      "\n",
      "LOG: Epoch [45/50]\n",
      "\t Training Batch [1/41], Loss: 0.0051, PSNR: 8.3082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50] Training Loss: 0.0050, PSNR: 7.7135\n",
      "\t[Val]   Batch [1/11] Loss: 0.0050, PSNR: 10.0126\n",
      "\t[Val]   Batch [10/11] Loss: 0.0050, PSNR: 7.7800\n",
      "Epoch [45/50] Validation Loss: 0.0049, PSNR: 8.0885\n",
      "\n",
      "LOG: Epoch [46/50]\n",
      "\t Training Batch [1/41], Loss: 0.0049, PSNR: 6.6600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50] Training Loss: 0.0048, PSNR: 7.7618\n",
      "\t[Val]   Batch [1/11] Loss: 0.0047, PSNR: 10.2057\n",
      "\t[Val]   Batch [10/11] Loss: 0.0047, PSNR: 7.9724\n",
      "Epoch [46/50] Validation Loss: 0.0047, PSNR: 8.2817\n",
      "\n",
      "LOG: Epoch [47/50]\n",
      "\t Training Batch [1/41], Loss: 0.0045, PSNR: 6.2364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50] Training Loss: 0.0046, PSNR: 7.7874\n",
      "\t[Val]   Batch [1/11] Loss: 0.0046, PSNR: 10.3668\n",
      "\t[Val]   Batch [10/11] Loss: 0.0046, PSNR: 8.1332\n",
      "Epoch [47/50] Validation Loss: 0.0046, PSNR: 8.4429\n",
      "\n",
      "LOG: Epoch [48/50]\n",
      "\t Training Batch [1/41], Loss: 0.0045, PSNR: 7.0380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50] Training Loss: 0.0044, PSNR: 8.0443\n",
      "\t[Val]   Batch [1/11] Loss: 0.0044, PSNR: 10.5645\n",
      "\t[Val]   Batch [10/11] Loss: 0.0044, PSNR: 8.3306\n",
      "Epoch [48/50] Validation Loss: 0.0044, PSNR: 8.6407\n",
      "\n",
      "LOG: Epoch [49/50]\n",
      "\t Training Batch [1/41], Loss: 0.0045, PSNR: 7.0423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50] Training Loss: 0.0042, PSNR: 8.1066\n",
      "\t[Val]   Batch [1/11] Loss: 0.0042, PSNR: 10.7283\n",
      "\t[Val]   Batch [10/11] Loss: 0.0042, PSNR: 8.4948\n",
      "Epoch [49/50] Validation Loss: 0.0042, PSNR: 8.8045\n",
      "\n",
      "LOG: Epoch [50/50]\n",
      "\t Training Batch [1/41], Loss: 0.0042, PSNR: 6.2325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50] Training Loss: 0.0041, PSNR: 8.2114\n",
      "\t[Val]   Batch [1/11] Loss: 0.0041, PSNR: 10.8850\n",
      "\t[Val]   Batch [10/11] Loss: 0.0041, PSNR: 8.6522\n",
      "Epoch [50/50] Validation Loss: 0.0040, PSNR: 8.9618\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_cae = ConvAutoEncode()\n",
    "criterion_cae = nn.MSELoss()\n",
    "optimizer_cae = optim.Adam(model_cae.parameters(), lr=0.0001)\n",
    "\n",
    "#parameters for CAE\n",
    "num_epochs_cae = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_cae = model_cae.to(device)\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 3  # number of epochs to wait for improvement\n",
    "tolerance = 1e-4\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "#grad accumulation parameters\n",
    "accumulation_steps = 8 \n",
    "\n",
    "# for loss and metrics tracking\n",
    "autoencoder_epoch_losses_cae = []\n",
    "validation_epoch_losses_cae = []\n",
    "train_psnr = []\n",
    "val_psnr = []\n",
    "\n",
    "psnr = PeakSignalNoiseRatio().to(device)\n",
    "\n",
    "# mixed precision training\n",
    "scaler = GradScaler()  # Gradient scaler for mixed precision\n",
    "\n",
    "for epoch in range(num_epochs_cae):\n",
    "    # training\n",
    "    model_cae.train()\n",
    "    running_loss = 0.0\n",
    "    running_psnr = 0.0\n",
    "\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs_cae}]\")\n",
    "\n",
    "    optimizer_cae.zero_grad()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader_cae):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "        # mixed precision forward pass\n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            _, decoded = model_cae(data)\n",
    "            loss = criterion_cae(decoded, data) / accumulation_steps\n",
    "\n",
    "            with torch.no_grad():\n",
    "                nan_in_out = torch.isnan(decoded).any().item()\n",
    "                inf_in_out = torch.isinf(decoded).any().item()\n",
    "\n",
    "        #backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        loss_value = loss.item() * accumulation_steps\n",
    "        running_loss += loss_value\n",
    "\n",
    "        psnr_value = psnr(decoded, data).item()\n",
    "        running_psnr += psnr_value\n",
    "\n",
    "\n",
    "        # performing optimizer step and reset gradients after `accumulation_steps` batches\n",
    "        if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader_cae):\n",
    "            scaler.step(optimizer_cae)\n",
    "            scaler.update()\n",
    "            optimizer_cae.zero_grad()\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 200 == 0:\n",
    "            print(\n",
    "    f\"\\t Training Batch [{batch_idx + 1}/{len(train_loader_cae)}], \"\n",
    "    f\"Loss: {loss_value:.4f}, PSNR: {psnr_value:.4f}\"\n",
    ")\n",
    "\n",
    "\n",
    "        #delete intermediate variables and clear GPU cache\n",
    "        del data, decoded, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    #compute average metrics for the epoch\n",
    "    avg_train_loss = running_loss / len(train_loader_cae)\n",
    "    avg_train_psnr = running_psnr / len(train_loader_cae)\n",
    "\n",
    "    autoencoder_epoch_losses_cae.append(avg_train_loss)\n",
    "    train_psnr.append(avg_train_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Training Loss: {avg_train_loss:.4f}, PSNR: {avg_train_psnr:.4f}\")\n",
    "\n",
    "    #clear GPU cache after training\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    #validation\n",
    "    model_cae.eval()\n",
    "    validation_loss = 0.0\n",
    "    val_psnr_epoch = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(val_loader_cae):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # Mixed precision forward pass for validation\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                _, decoded = model_cae(data)\n",
    "                loss = criterion_cae(decoded, data)\n",
    "\n",
    "            validation_loss += loss.item()\n",
    "            val_psnr_epoch += psnr(decoded, data).item()\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                loss_val = loss.item()\n",
    "                psnr_val = psnr(decoded, data).item()\n",
    "                print(\n",
    "                    f\"\\t[Val]   Batch [{batch_idx + 1}/{len(val_loader_cae)}] \"\n",
    "                    f\"Loss: {loss_val:.4f}, PSNR: {psnr_val:.4f}\"\n",
    "                )\n",
    "\n",
    "            del data, decoded, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # average validation metrics for the epoch\n",
    "    avg_val_loss = validation_loss / len(val_loader_cae)\n",
    "    avg_val_psnr = val_psnr_epoch / len(val_loader_cae)\n",
    "\n",
    "    validation_epoch_losses_cae.append(avg_val_loss)\n",
    "    val_psnr.append(avg_val_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Validation Loss: {avg_val_loss:.4f}, PSNR: {avg_val_psnr:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss < best_val_loss - tolerance:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0  # Reset counter\n",
    "        #best model checkpoint\n",
    "        #torch.save(model_cae.state_dict(), 'best_model_cae.pth')\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "#plot for training and validation loss trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(autoencoder_epoch_losses_cae) + 1), autoencoder_epoch_losses_cae, marker='o', label=\"Training Loss\")\n",
    "plt.plot(range(1, len(validation_epoch_losses_cae) + 1), validation_epoch_losses_cae, marker='x', label=\"Validation Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#plot for PSNR trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_psnr) + 1), train_psnr, marker='o', label=\"Training PSNR\")\n",
    "plt.plot(range(1, len(val_psnr) + 1), val_psnr, marker='x', label=\"Validation PSNR\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('PSNR Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the encoder section of CAE as feature extractor to generate compact representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:07.292839Z",
     "iopub.status.busy": "2025-05-08T19:08:07.292839Z",
     "iopub.status.idle": "2025-05-08T19:08:07.449967Z",
     "shell.execute_reply": "2025-05-08T19:08:07.449967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting representations for the train dataset...\n",
      "    Processed batch 1/1 for train dataset.\n",
      "Completed encoding for the train dataset.\n",
      "\n",
      "Extracting representations for the val dataset...\n",
      "    Processed batch 1/1 for val dataset.\n",
      "Completed encoding for the val dataset.\n",
      "\n",
      "Extracting representations for the test dataset...\n",
      "    Processed batch 1/12 for test dataset.\n",
      "Completed encoding for the test dataset.\n",
      "Feature extraction completed for all subsets.\n"
     ]
    }
   ],
   "source": [
    "#dir to save encoded representations\n",
    "encoded_dir = 'encoded_representations'\n",
    "os.makedirs(encoded_dir, exist_ok=True)\n",
    "\n",
    "loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "model_cae.eval()\n",
    "\n",
    "# Feature extraction\n",
    "with torch.no_grad():\n",
    "    for subset_name, loader in loaders.items():\n",
    "        print(f\"\\nExtracting representations for the {subset_name} dataset...\")\n",
    "\n",
    "        # dir for the given subset's encoded features\n",
    "        subset_encoded_dir = os.path.join(encoded_dir, subset_name)\n",
    "        os.makedirs(subset_encoded_dir, exist_ok=True)\n",
    "\n",
    "        for batch_idx, (data, labels) in enumerate(loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # passing data through the encoder to obtain representations\n",
    "            encoded_features, _ = model_cae(data)  # latent representation\n",
    "\n",
    "            # moving to CPU and convert to NumPy\n",
    "            encoded_features = encoded_features.cpu().numpy()  \n",
    "            labels = labels.cpu().numpy() \n",
    "\n",
    "            #saving the encoded features and labels\n",
    "            np.save(os.path.join(subset_encoded_dir, f'encoded_batch_{batch_idx}.npy'), encoded_features)\n",
    "            np.save(os.path.join(subset_encoded_dir, f'labels_batch_{batch_idx}.npy'), labels)\n",
    "\n",
    "            if batch_idx % 1 == 0 and subset_name != 'test':\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "            elif subset_name == 'test' and batch_idx % 100 == 0:  # Log less frequently for the test set\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed encoding for the {subset_name} dataset.\")\n",
    "\n",
    "print(\"Feature extraction completed for all subsets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-To-End CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:07.451975Z",
     "iopub.status.busy": "2025-05-08T19:08:07.451975Z",
     "iopub.status.idle": "2025-05-08T19:08:07.457405Z",
     "shell.execute_reply": "2025-05-08T19:08:07.457405Z"
    }
   },
   "outputs": [],
   "source": [
    "class hyperspectralCNN(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(hyperspectralCNN, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #fully connected layers for classification\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),  #3D to 1D vector for input to FC layers\n",
    "            nn.Linear(16 * 2 * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:07.460468Z",
     "iopub.status.busy": "2025-05-08T19:08:07.459466Z",
     "iopub.status.idle": "2025-05-08T19:08:16.349462Z",
     "shell.execute_reply": "2025-05-08T19:08:16.349462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] completed, Average Training Loss: 2.6533\n",
      "    Validation Batch [1/1], Loss: 2.6426\n",
      "Validation Loss: 2.6426, Validation Accuracy: 7.14%\n",
      "Validation loss improved from inf to 2.6426. Saving model...\n",
      "\n",
      "LOG: Epoch [2/1000] - Training\n",
      "Epoch [2/1000] completed, Average Training Loss: 2.6086\n",
      "    Validation Batch [1/1], Loss: 2.6426\n",
      "Validation Loss: 2.6426, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [3/1000] - Training\n",
      "Epoch [3/1000] completed, Average Training Loss: 2.5855\n",
      "    Validation Batch [1/1], Loss: 2.6426\n",
      "Validation Loss: 2.6426, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [4/1000] - Training\n",
      "Epoch [4/1000] completed, Average Training Loss: 2.5563\n",
      "    Validation Batch [1/1], Loss: 2.6426\n",
      "Validation Loss: 2.6426, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6426 to 2.6426. Saving model...\n",
      "\n",
      "LOG: Epoch [5/1000] - Training\n",
      "Epoch [5/1000] completed, Average Training Loss: 2.5465\n",
      "    Validation Batch [1/1], Loss: 2.6426\n",
      "Validation Loss: 2.6426, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6426 to 2.6426. Saving model...\n",
      "\n",
      "LOG: Epoch [6/1000] - Training\n",
      "Epoch [6/1000] completed, Average Training Loss: 2.5356\n",
      "    Validation Batch [1/1], Loss: 2.6426\n",
      "Validation Loss: 2.6426, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6426 to 2.6426. Saving model...\n",
      "\n",
      "LOG: Epoch [7/1000] - Training\n",
      "Epoch [7/1000] completed, Average Training Loss: 2.5068\n",
      "    Validation Batch [1/1], Loss: 2.6426\n",
      "Validation Loss: 2.6426, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6426 to 2.6426. Saving model...\n",
      "\n",
      "LOG: Epoch [8/1000] - Training\n",
      "Epoch [8/1000] completed, Average Training Loss: 2.4941\n",
      "    Validation Batch [1/1], Loss: 2.6426\n",
      "Validation Loss: 2.6426, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6426 to 2.6426. Saving model...\n",
      "\n",
      "LOG: Epoch [9/1000] - Training\n",
      "Epoch [9/1000] completed, Average Training Loss: 2.4742\n",
      "    Validation Batch [1/1], Loss: 2.6425\n",
      "Validation Loss: 2.6425, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6426 to 2.6425. Saving model...\n",
      "\n",
      "LOG: Epoch [10/1000] - Training\n",
      "Epoch [10/1000] completed, Average Training Loss: 2.4650\n",
      "    Validation Batch [1/1], Loss: 2.6425\n",
      "Validation Loss: 2.6425, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6425 to 2.6425. Saving model...\n",
      "\n",
      "LOG: Epoch [11/1000] - Training\n",
      "Epoch [11/1000] completed, Average Training Loss: 2.4399\n",
      "    Validation Batch [1/1], Loss: 2.6424\n",
      "Validation Loss: 2.6424, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6425 to 2.6424. Saving model...\n",
      "\n",
      "LOG: Epoch [12/1000] - Training\n",
      "Epoch [12/1000] completed, Average Training Loss: 2.4343\n",
      "    Validation Batch [1/1], Loss: 2.6423\n",
      "Validation Loss: 2.6423, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6424 to 2.6423. Saving model...\n",
      "\n",
      "LOG: Epoch [13/1000] - Training\n",
      "Epoch [13/1000] completed, Average Training Loss: 2.4374\n",
      "    Validation Batch [1/1], Loss: 2.6423\n",
      "Validation Loss: 2.6423, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6423 to 2.6423. Saving model...\n",
      "\n",
      "LOG: Epoch [14/1000] - Training\n",
      "Epoch [14/1000] completed, Average Training Loss: 2.4013\n",
      "    Validation Batch [1/1], Loss: 2.6422\n",
      "Validation Loss: 2.6422, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6423 to 2.6422. Saving model...\n",
      "\n",
      "LOG: Epoch [15/1000] - Training\n",
      "Epoch [15/1000] completed, Average Training Loss: 2.4010\n",
      "    Validation Batch [1/1], Loss: 2.6420\n",
      "Validation Loss: 2.6420, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6422 to 2.6420. Saving model...\n",
      "\n",
      "LOG: Epoch [16/1000] - Training\n",
      "Epoch [16/1000] completed, Average Training Loss: 2.3800\n",
      "    Validation Batch [1/1], Loss: 2.6419\n",
      "Validation Loss: 2.6419, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6420 to 2.6419. Saving model...\n",
      "\n",
      "LOG: Epoch [17/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/1000] completed, Average Training Loss: 2.3673\n",
      "    Validation Batch [1/1], Loss: 2.6418\n",
      "Validation Loss: 2.6418, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6419 to 2.6418. Saving model...\n",
      "\n",
      "LOG: Epoch [18/1000] - Training\n",
      "Epoch [18/1000] completed, Average Training Loss: 2.3545\n",
      "    Validation Batch [1/1], Loss: 2.6417\n",
      "Validation Loss: 2.6417, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6418 to 2.6417. Saving model...\n",
      "\n",
      "LOG: Epoch [19/1000] - Training\n",
      "Epoch [19/1000] completed, Average Training Loss: 2.3571\n",
      "    Validation Batch [1/1], Loss: 2.6417\n",
      "Validation Loss: 2.6417, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6417 to 2.6417. Saving model...\n",
      "\n",
      "LOG: Epoch [20/1000] - Training\n",
      "Epoch [20/1000] completed, Average Training Loss: 2.3499\n",
      "    Validation Batch [1/1], Loss: 2.6415\n",
      "Validation Loss: 2.6415, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6417 to 2.6415. Saving model...\n",
      "\n",
      "LOG: Epoch [21/1000] - Training\n",
      "Epoch [21/1000] completed, Average Training Loss: 2.3237\n",
      "    Validation Batch [1/1], Loss: 2.6413\n",
      "Validation Loss: 2.6413, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6415 to 2.6413. Saving model...\n",
      "\n",
      "LOG: Epoch [22/1000] - Training\n",
      "Epoch [22/1000] completed, Average Training Loss: 2.3228\n",
      "    Validation Batch [1/1], Loss: 2.6412\n",
      "Validation Loss: 2.6412, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6413 to 2.6412. Saving model...\n",
      "\n",
      "LOG: Epoch [23/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/1000] completed, Average Training Loss: 2.3157\n",
      "    Validation Batch [1/1], Loss: 2.6411\n",
      "Validation Loss: 2.6411, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6412 to 2.6411. Saving model...\n",
      "\n",
      "LOG: Epoch [24/1000] - Training\n",
      "Epoch [24/1000] completed, Average Training Loss: 2.2872\n",
      "    Validation Batch [1/1], Loss: 2.6410\n",
      "Validation Loss: 2.6410, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6411 to 2.6410. Saving model...\n",
      "\n",
      "LOG: Epoch [25/1000] - Training\n",
      "Epoch [25/1000] completed, Average Training Loss: 2.2926\n",
      "    Validation Batch [1/1], Loss: 2.6409\n",
      "Validation Loss: 2.6409, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6410 to 2.6409. Saving model...\n",
      "\n",
      "LOG: Epoch [26/1000] - Training\n",
      "Epoch [26/1000] completed, Average Training Loss: 2.2567\n",
      "    Validation Batch [1/1], Loss: 2.6408\n",
      "Validation Loss: 2.6408, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6409 to 2.6408. Saving model...\n",
      "\n",
      "LOG: Epoch [27/1000] - Training\n",
      "Epoch [27/1000] completed, Average Training Loss: 2.2581\n",
      "    Validation Batch [1/1], Loss: 2.6406\n",
      "Validation Loss: 2.6406, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6408 to 2.6406. Saving model...\n",
      "\n",
      "LOG: Epoch [28/1000] - Training\n",
      "Epoch [28/1000] completed, Average Training Loss: 2.2616\n",
      "    Validation Batch [1/1], Loss: 2.6406\n",
      "Validation Loss: 2.6406, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6406 to 2.6406. Saving model...\n",
      "\n",
      "LOG: Epoch [29/1000] - Training\n",
      "Epoch [29/1000] completed, Average Training Loss: 2.2363\n",
      "    Validation Batch [1/1], Loss: 2.6404\n",
      "Validation Loss: 2.6404, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6406 to 2.6404. Saving model...\n",
      "\n",
      "LOG: Epoch [30/1000] - Training\n",
      "Epoch [30/1000] completed, Average Training Loss: 2.2372\n",
      "    Validation Batch [1/1], Loss: 2.6401\n",
      "Validation Loss: 2.6401, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6404 to 2.6401. Saving model...\n",
      "\n",
      "LOG: Epoch [31/1000] - Training\n",
      "Epoch [31/1000] completed, Average Training Loss: 2.2340\n",
      "    Validation Batch [1/1], Loss: 2.6396\n",
      "Validation Loss: 2.6396, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6401 to 2.6396. Saving model...\n",
      "\n",
      "LOG: Epoch [32/1000] - Training\n",
      "Epoch [32/1000] completed, Average Training Loss: 2.2040\n",
      "    Validation Batch [1/1], Loss: 2.6391\n",
      "Validation Loss: 2.6391, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6396 to 2.6391. Saving model...\n",
      "\n",
      "LOG: Epoch [33/1000] - Training\n",
      "Epoch [33/1000] completed, Average Training Loss: 2.2098\n",
      "    Validation Batch [1/1], Loss: 2.6385\n",
      "Validation Loss: 2.6385, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6391 to 2.6385. Saving model...\n",
      "\n",
      "LOG: Epoch [34/1000] - Training\n",
      "Epoch [34/1000] completed, Average Training Loss: 2.2077\n",
      "    Validation Batch [1/1], Loss: 2.6379\n",
      "Validation Loss: 2.6379, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6385 to 2.6379. Saving model...\n",
      "\n",
      "LOG: Epoch [35/1000] - Training\n",
      "Epoch [35/1000] completed, Average Training Loss: 2.1985\n",
      "    Validation Batch [1/1], Loss: 2.6372\n",
      "Validation Loss: 2.6372, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6379 to 2.6372. Saving model...\n",
      "\n",
      "LOG: Epoch [36/1000] - Training\n",
      "Epoch [36/1000] completed, Average Training Loss: 2.1865\n",
      "    Validation Batch [1/1], Loss: 2.6363\n",
      "Validation Loss: 2.6363, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6372 to 2.6363. Saving model...\n",
      "\n",
      "LOG: Epoch [37/1000] - Training\n",
      "Epoch [37/1000] completed, Average Training Loss: 2.1717\n",
      "    Validation Batch [1/1], Loss: 2.6355\n",
      "Validation Loss: 2.6355, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6363 to 2.6355. Saving model...\n",
      "\n",
      "LOG: Epoch [38/1000] - Training\n",
      "Epoch [38/1000] completed, Average Training Loss: 2.1650\n",
      "    Validation Batch [1/1], Loss: 2.6346\n",
      "Validation Loss: 2.6346, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6355 to 2.6346. Saving model...\n",
      "\n",
      "LOG: Epoch [39/1000] - Training\n",
      "Epoch [39/1000] completed, Average Training Loss: 2.1502\n",
      "    Validation Batch [1/1], Loss: 2.6335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.6335, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6346 to 2.6335. Saving model...\n",
      "\n",
      "LOG: Epoch [40/1000] - Training\n",
      "Epoch [40/1000] completed, Average Training Loss: 2.1461\n",
      "    Validation Batch [1/1], Loss: 2.6324\n",
      "Validation Loss: 2.6324, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6335 to 2.6324. Saving model...\n",
      "\n",
      "LOG: Epoch [41/1000] - Training\n",
      "Epoch [41/1000] completed, Average Training Loss: 2.1255\n",
      "    Validation Batch [1/1], Loss: 2.6312\n",
      "Validation Loss: 2.6312, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6324 to 2.6312. Saving model...\n",
      "\n",
      "LOG: Epoch [42/1000] - Training\n",
      "Epoch [42/1000] completed, Average Training Loss: 2.1240\n",
      "    Validation Batch [1/1], Loss: 2.6301\n",
      "Validation Loss: 2.6301, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6312 to 2.6301. Saving model...\n",
      "\n",
      "LOG: Epoch [43/1000] - Training\n",
      "Epoch [43/1000] completed, Average Training Loss: 2.0989\n",
      "    Validation Batch [1/1], Loss: 2.6290\n",
      "Validation Loss: 2.6290, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6301 to 2.6290. Saving model...\n",
      "\n",
      "LOG: Epoch [44/1000] - Training\n",
      "Epoch [44/1000] completed, Average Training Loss: 2.0825\n",
      "    Validation Batch [1/1], Loss: 2.6274\n",
      "Validation Loss: 2.6274, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6290 to 2.6274. Saving model...\n",
      "\n",
      "LOG: Epoch [45/1000] - Training\n",
      "Epoch [45/1000] completed, Average Training Loss: 2.0937\n",
      "    Validation Batch [1/1], Loss: 2.6255\n",
      "Validation Loss: 2.6255, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6274 to 2.6255. Saving model...\n",
      "\n",
      "LOG: Epoch [46/1000] - Training\n",
      "Epoch [46/1000] completed, Average Training Loss: 2.0741\n",
      "    Validation Batch [1/1], Loss: 2.6236\n",
      "Validation Loss: 2.6236, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6255 to 2.6236. Saving model...\n",
      "\n",
      "LOG: Epoch [47/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/1000] completed, Average Training Loss: 2.0639\n",
      "    Validation Batch [1/1], Loss: 2.6218\n",
      "Validation Loss: 2.6218, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6236 to 2.6218. Saving model...\n",
      "\n",
      "LOG: Epoch [48/1000] - Training\n",
      "Epoch [48/1000] completed, Average Training Loss: 2.0354\n",
      "    Validation Batch [1/1], Loss: 2.6191\n",
      "Validation Loss: 2.6191, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6218 to 2.6191. Saving model...\n",
      "\n",
      "LOG: Epoch [49/1000] - Training\n",
      "Epoch [49/1000] completed, Average Training Loss: 2.0360\n",
      "    Validation Batch [1/1], Loss: 2.6153\n",
      "Validation Loss: 2.6153, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6191 to 2.6153. Saving model...\n",
      "\n",
      "LOG: Epoch [50/1000] - Training\n",
      "Epoch [50/1000] completed, Average Training Loss: 2.0463\n",
      "    Validation Batch [1/1], Loss: 2.6112\n",
      "Validation Loss: 2.6112, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6153 to 2.6112. Saving model...\n",
      "\n",
      "LOG: Epoch [51/1000] - Training\n",
      "Epoch [51/1000] completed, Average Training Loss: 2.0260\n",
      "    Validation Batch [1/1], Loss: 2.6067\n",
      "Validation Loss: 2.6067, Validation Accuracy: 8.57%\n",
      "Validation loss improved from 2.6112 to 2.6067. Saving model...\n",
      "\n",
      "LOG: Epoch [52/1000] - Training\n",
      "Epoch [52/1000] completed, Average Training Loss: 2.0127\n",
      "    Validation Batch [1/1], Loss: 2.6019\n",
      "Validation Loss: 2.6019, Validation Accuracy: 8.57%\n",
      "Validation loss improved from 2.6067 to 2.6019. Saving model...\n",
      "\n",
      "LOG: Epoch [53/1000] - Training\n",
      "Epoch [53/1000] completed, Average Training Loss: 1.9812\n",
      "    Validation Batch [1/1], Loss: 2.5973\n",
      "Validation Loss: 2.5973, Validation Accuracy: 10.00%\n",
      "Validation loss improved from 2.6019 to 2.5973. Saving model...\n",
      "\n",
      "LOG: Epoch [54/1000] - Training\n",
      "Epoch [54/1000] completed, Average Training Loss: 1.9941\n",
      "    Validation Batch [1/1], Loss: 2.5918\n",
      "Validation Loss: 2.5918, Validation Accuracy: 11.43%\n",
      "Validation loss improved from 2.5973 to 2.5918. Saving model...\n",
      "\n",
      "LOG: Epoch [55/1000] - Training\n",
      "Epoch [55/1000] completed, Average Training Loss: 1.9884\n",
      "    Validation Batch [1/1], Loss: 2.5846\n",
      "Validation Loss: 2.5846, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.5918 to 2.5846. Saving model...\n",
      "\n",
      "LOG: Epoch [56/1000] - Training\n",
      "Epoch [56/1000] completed, Average Training Loss: 1.9793\n",
      "    Validation Batch [1/1], Loss: 2.5766\n",
      "Validation Loss: 2.5766, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.5846 to 2.5766. Saving model...\n",
      "\n",
      "LOG: Epoch [57/1000] - Training\n",
      "Epoch [57/1000] completed, Average Training Loss: 1.9634\n",
      "    Validation Batch [1/1], Loss: 2.5663\n",
      "Validation Loss: 2.5663, Validation Accuracy: 14.29%\n",
      "Validation loss improved from 2.5766 to 2.5663. Saving model...\n",
      "\n",
      "LOG: Epoch [58/1000] - Training\n",
      "Epoch [58/1000] completed, Average Training Loss: 1.9505\n",
      "    Validation Batch [1/1], Loss: 2.5561\n",
      "Validation Loss: 2.5561, Validation Accuracy: 17.14%\n",
      "Validation loss improved from 2.5663 to 2.5561. Saving model...\n",
      "\n",
      "LOG: Epoch [59/1000] - Training\n",
      "Epoch [59/1000] completed, Average Training Loss: 1.9328\n",
      "    Validation Batch [1/1], Loss: 2.5475\n",
      "Validation Loss: 2.5475, Validation Accuracy: 17.14%\n",
      "Validation loss improved from 2.5561 to 2.5475. Saving model...\n",
      "\n",
      "LOG: Epoch [60/1000] - Training\n",
      "Epoch [60/1000] completed, Average Training Loss: 1.9435\n",
      "    Validation Batch [1/1], Loss: 2.5369\n",
      "Validation Loss: 2.5369, Validation Accuracy: 17.14%\n",
      "Validation loss improved from 2.5475 to 2.5369. Saving model...\n",
      "\n",
      "LOG: Epoch [61/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/1000] completed, Average Training Loss: 1.9278\n",
      "    Validation Batch [1/1], Loss: 2.5240\n",
      "Validation Loss: 2.5240, Validation Accuracy: 18.57%\n",
      "Validation loss improved from 2.5369 to 2.5240. Saving model...\n",
      "\n",
      "LOG: Epoch [62/1000] - Training\n",
      "Epoch [62/1000] completed, Average Training Loss: 1.9108\n",
      "    Validation Batch [1/1], Loss: 2.5070\n",
      "Validation Loss: 2.5070, Validation Accuracy: 18.57%\n",
      "Validation loss improved from 2.5240 to 2.5070. Saving model...\n",
      "\n",
      "LOG: Epoch [63/1000] - Training\n",
      "Epoch [63/1000] completed, Average Training Loss: 1.9097\n",
      "    Validation Batch [1/1], Loss: 2.4911\n",
      "Validation Loss: 2.4911, Validation Accuracy: 18.57%\n",
      "Validation loss improved from 2.5070 to 2.4911. Saving model...\n",
      "\n",
      "LOG: Epoch [64/1000] - Training\n",
      "Epoch [64/1000] completed, Average Training Loss: 1.8920\n",
      "    Validation Batch [1/1], Loss: 2.4773\n",
      "Validation Loss: 2.4773, Validation Accuracy: 22.86%\n",
      "Validation loss improved from 2.4911 to 2.4773. Saving model...\n",
      "\n",
      "LOG: Epoch [65/1000] - Training\n",
      "Epoch [65/1000] completed, Average Training Loss: 1.8793\n",
      "    Validation Batch [1/1], Loss: 2.4616\n",
      "Validation Loss: 2.4616, Validation Accuracy: 25.71%\n",
      "Validation loss improved from 2.4773 to 2.4616. Saving model...\n",
      "\n",
      "LOG: Epoch [66/1000] - Training\n",
      "Epoch [66/1000] completed, Average Training Loss: 1.8610\n",
      "    Validation Batch [1/1], Loss: 2.4427\n",
      "Validation Loss: 2.4427, Validation Accuracy: 32.86%\n",
      "Validation loss improved from 2.4616 to 2.4427. Saving model...\n",
      "\n",
      "LOG: Epoch [67/1000] - Training\n",
      "Epoch [67/1000] completed, Average Training Loss: 1.8625\n",
      "    Validation Batch [1/1], Loss: 2.4215\n",
      "Validation Loss: 2.4215, Validation Accuracy: 40.00%\n",
      "Validation loss improved from 2.4427 to 2.4215. Saving model...\n",
      "\n",
      "LOG: Epoch [68/1000] - Training\n",
      "Epoch [68/1000] completed, Average Training Loss: 1.8508\n",
      "    Validation Batch [1/1], Loss: 2.3978\n",
      "Validation Loss: 2.3978, Validation Accuracy: 41.43%\n",
      "Validation loss improved from 2.4215 to 2.3978. Saving model...\n",
      "\n",
      "LOG: Epoch [69/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/1000] completed, Average Training Loss: 1.8429\n",
      "    Validation Batch [1/1], Loss: 2.3761\n",
      "Validation Loss: 2.3761, Validation Accuracy: 42.86%\n",
      "Validation loss improved from 2.3978 to 2.3761. Saving model...\n",
      "\n",
      "LOG: Epoch [70/1000] - Training\n",
      "Epoch [70/1000] completed, Average Training Loss: 1.8182\n",
      "    Validation Batch [1/1], Loss: 2.3566\n",
      "Validation Loss: 2.3566, Validation Accuracy: 40.00%\n",
      "Validation loss improved from 2.3761 to 2.3566. Saving model...\n",
      "\n",
      "LOG: Epoch [71/1000] - Training\n",
      "Epoch [71/1000] completed, Average Training Loss: 1.8190\n",
      "    Validation Batch [1/1], Loss: 2.3356\n",
      "Validation Loss: 2.3356, Validation Accuracy: 44.29%\n",
      "Validation loss improved from 2.3566 to 2.3356. Saving model...\n",
      "\n",
      "LOG: Epoch [72/1000] - Training\n",
      "Epoch [72/1000] completed, Average Training Loss: 1.8079\n",
      "    Validation Batch [1/1], Loss: 2.3113\n",
      "Validation Loss: 2.3113, Validation Accuracy: 48.57%\n",
      "Validation loss improved from 2.3356 to 2.3113. Saving model...\n",
      "\n",
      "LOG: Epoch [73/1000] - Training\n",
      "Epoch [73/1000] completed, Average Training Loss: 1.8059\n",
      "    Validation Batch [1/1], Loss: 2.2813\n",
      "Validation Loss: 2.2813, Validation Accuracy: 50.00%\n",
      "Validation loss improved from 2.3113 to 2.2813. Saving model...\n",
      "\n",
      "LOG: Epoch [74/1000] - Training\n",
      "Epoch [74/1000] completed, Average Training Loss: 1.8049\n",
      "    Validation Batch [1/1], Loss: 2.2593\n",
      "Validation Loss: 2.2593, Validation Accuracy: 48.57%\n",
      "Validation loss improved from 2.2813 to 2.2593. Saving model...\n",
      "\n",
      "LOG: Epoch [75/1000] - Training\n",
      "Epoch [75/1000] completed, Average Training Loss: 1.7720\n",
      "    Validation Batch [1/1], Loss: 2.2418\n",
      "Validation Loss: 2.2418, Validation Accuracy: 57.14%\n",
      "Validation loss improved from 2.2593 to 2.2418. Saving model...\n",
      "\n",
      "LOG: Epoch [76/1000] - Training\n",
      "Epoch [76/1000] completed, Average Training Loss: 1.7933\n",
      "    Validation Batch [1/1], Loss: 2.2086\n",
      "Validation Loss: 2.2086, Validation Accuracy: 57.14%\n",
      "Validation loss improved from 2.2418 to 2.2086. Saving model...\n",
      "\n",
      "LOG: Epoch [77/1000] - Training\n",
      "Epoch [77/1000] completed, Average Training Loss: 1.7731\n",
      "    Validation Batch [1/1], Loss: 2.1754\n",
      "Validation Loss: 2.1754, Validation Accuracy: 57.14%\n",
      "Validation loss improved from 2.2086 to 2.1754. Saving model...\n",
      "\n",
      "LOG: Epoch [78/1000] - Training\n",
      "Epoch [78/1000] completed, Average Training Loss: 1.7658\n",
      "    Validation Batch [1/1], Loss: 2.1444\n",
      "Validation Loss: 2.1444, Validation Accuracy: 57.14%\n",
      "Validation loss improved from 2.1754 to 2.1444. Saving model...\n",
      "\n",
      "LOG: Epoch [79/1000] - Training\n",
      "Epoch [79/1000] completed, Average Training Loss: 1.7275\n",
      "    Validation Batch [1/1], Loss: 2.1167\n",
      "Validation Loss: 2.1167, Validation Accuracy: 57.14%\n",
      "Validation loss improved from 2.1444 to 2.1167. Saving model...\n",
      "\n",
      "LOG: Epoch [80/1000] - Training\n",
      "Epoch [80/1000] completed, Average Training Loss: 1.7161\n",
      "    Validation Batch [1/1], Loss: 2.0799\n",
      "Validation Loss: 2.0799, Validation Accuracy: 57.14%\n",
      "Validation loss improved from 2.1167 to 2.0799. Saving model...\n",
      "\n",
      "LOG: Epoch [81/1000] - Training\n",
      "Epoch [81/1000] completed, Average Training Loss: 1.7116\n",
      "    Validation Batch [1/1], Loss: 2.0536\n",
      "Validation Loss: 2.0536, Validation Accuracy: 55.71%\n",
      "Validation loss improved from 2.0799 to 2.0536. Saving model...\n",
      "\n",
      "LOG: Epoch [82/1000] - Training\n",
      "Epoch [82/1000] completed, Average Training Loss: 1.7028\n",
      "    Validation Batch [1/1], Loss: 2.0264\n",
      "Validation Loss: 2.0264, Validation Accuracy: 58.57%\n",
      "Validation loss improved from 2.0536 to 2.0264. Saving model...\n",
      "\n",
      "LOG: Epoch [83/1000] - Training\n",
      "Epoch [83/1000] completed, Average Training Loss: 1.6951\n",
      "    Validation Batch [1/1], Loss: 2.0076\n",
      "Validation Loss: 2.0076, Validation Accuracy: 60.00%\n",
      "Validation loss improved from 2.0264 to 2.0076. Saving model...\n",
      "\n",
      "LOG: Epoch [84/1000] - Training\n",
      "Epoch [84/1000] completed, Average Training Loss: 1.6726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 1.9783\n",
      "Validation Loss: 1.9783, Validation Accuracy: 58.57%\n",
      "Validation loss improved from 2.0076 to 1.9783. Saving model...\n",
      "\n",
      "LOG: Epoch [85/1000] - Training\n",
      "Epoch [85/1000] completed, Average Training Loss: 1.6967\n",
      "    Validation Batch [1/1], Loss: 1.9490\n",
      "Validation Loss: 1.9490, Validation Accuracy: 58.57%\n",
      "Validation loss improved from 1.9783 to 1.9490. Saving model...\n",
      "\n",
      "LOG: Epoch [86/1000] - Training\n",
      "Epoch [86/1000] completed, Average Training Loss: 1.6718\n",
      "    Validation Batch [1/1], Loss: 1.9161\n",
      "Validation Loss: 1.9161, Validation Accuracy: 60.00%\n",
      "Validation loss improved from 1.9490 to 1.9161. Saving model...\n",
      "\n",
      "LOG: Epoch [87/1000] - Training\n",
      "Epoch [87/1000] completed, Average Training Loss: 1.6799\n",
      "    Validation Batch [1/1], Loss: 1.8844\n",
      "Validation Loss: 1.8844, Validation Accuracy: 60.00%\n",
      "Validation loss improved from 1.9161 to 1.8844. Saving model...\n",
      "\n",
      "LOG: Epoch [88/1000] - Training\n",
      "Epoch [88/1000] completed, Average Training Loss: 1.6409\n",
      "    Validation Batch [1/1], Loss: 1.8583\n",
      "Validation Loss: 1.8583, Validation Accuracy: 60.00%\n",
      "Validation loss improved from 1.8844 to 1.8583. Saving model...\n",
      "\n",
      "LOG: Epoch [89/1000] - Training\n",
      "Epoch [89/1000] completed, Average Training Loss: 1.6475\n",
      "    Validation Batch [1/1], Loss: 1.8391\n",
      "Validation Loss: 1.8391, Validation Accuracy: 60.00%\n",
      "Validation loss improved from 1.8583 to 1.8391. Saving model...\n",
      "\n",
      "LOG: Epoch [90/1000] - Training\n",
      "Epoch [90/1000] completed, Average Training Loss: 1.6482\n",
      "    Validation Batch [1/1], Loss: 1.8185\n",
      "Validation Loss: 1.8185, Validation Accuracy: 61.43%\n",
      "Validation loss improved from 1.8391 to 1.8185. Saving model...\n",
      "\n",
      "LOG: Epoch [91/1000] - Training\n",
      "Epoch [91/1000] completed, Average Training Loss: 1.6286\n",
      "    Validation Batch [1/1], Loss: 1.7964\n",
      "Validation Loss: 1.7964, Validation Accuracy: 60.00%\n",
      "Validation loss improved from 1.8185 to 1.7964. Saving model...\n",
      "\n",
      "LOG: Epoch [92/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/1000] completed, Average Training Loss: 1.6168\n",
      "    Validation Batch [1/1], Loss: 1.7705\n",
      "Validation Loss: 1.7705, Validation Accuracy: 60.00%\n",
      "Validation loss improved from 1.7964 to 1.7705. Saving model...\n",
      "\n",
      "LOG: Epoch [93/1000] - Training\n",
      "Epoch [93/1000] completed, Average Training Loss: 1.6265\n",
      "    Validation Batch [1/1], Loss: 1.7553\n",
      "Validation Loss: 1.7553, Validation Accuracy: 62.86%\n",
      "Validation loss improved from 1.7705 to 1.7553. Saving model...\n",
      "\n",
      "LOG: Epoch [94/1000] - Training\n",
      "Epoch [94/1000] completed, Average Training Loss: 1.5953\n",
      "    Validation Batch [1/1], Loss: 1.7309\n",
      "Validation Loss: 1.7309, Validation Accuracy: 64.29%\n",
      "Validation loss improved from 1.7553 to 1.7309. Saving model...\n",
      "\n",
      "LOG: Epoch [95/1000] - Training\n",
      "Epoch [95/1000] completed, Average Training Loss: 1.6045\n",
      "    Validation Batch [1/1], Loss: 1.7131\n",
      "Validation Loss: 1.7131, Validation Accuracy: 61.43%\n",
      "Validation loss improved from 1.7309 to 1.7131. Saving model...\n",
      "\n",
      "LOG: Epoch [96/1000] - Training\n",
      "Epoch [96/1000] completed, Average Training Loss: 1.5778\n",
      "    Validation Batch [1/1], Loss: 1.7031\n",
      "Validation Loss: 1.7031, Validation Accuracy: 64.29%\n",
      "Validation loss improved from 1.7131 to 1.7031. Saving model...\n",
      "\n",
      "LOG: Epoch [97/1000] - Training\n",
      "Epoch [97/1000] completed, Average Training Loss: 1.5583\n",
      "    Validation Batch [1/1], Loss: 1.6997\n",
      "Validation Loss: 1.6997, Validation Accuracy: 67.14%\n",
      "Validation loss improved from 1.7031 to 1.6997. Saving model...\n",
      "\n",
      "LOG: Epoch [98/1000] - Training\n",
      "Epoch [98/1000] completed, Average Training Loss: 1.5500\n",
      "    Validation Batch [1/1], Loss: 1.6627\n",
      "Validation Loss: 1.6627, Validation Accuracy: 67.14%\n",
      "Validation loss improved from 1.6997 to 1.6627. Saving model...\n",
      "\n",
      "LOG: Epoch [99/1000] - Training\n",
      "Epoch [99/1000] completed, Average Training Loss: 1.5403\n",
      "    Validation Batch [1/1], Loss: 1.6427\n",
      "Validation Loss: 1.6427, Validation Accuracy: 65.71%\n",
      "Validation loss improved from 1.6627 to 1.6427. Saving model...\n",
      "\n",
      "LOG: Epoch [100/1000] - Training\n",
      "Epoch [100/1000] completed, Average Training Loss: 1.5432\n",
      "    Validation Batch [1/1], Loss: 1.6416\n",
      "Validation Loss: 1.6416, Validation Accuracy: 67.14%\n",
      "Validation loss improved from 1.6427 to 1.6416. Saving model...\n",
      "\n",
      "LOG: Epoch [101/1000] - Training\n",
      "Epoch [101/1000] completed, Average Training Loss: 1.5373\n",
      "    Validation Batch [1/1], Loss: 1.6307\n",
      "Validation Loss: 1.6307, Validation Accuracy: 67.14%\n",
      "Validation loss improved from 1.6416 to 1.6307. Saving model...\n",
      "\n",
      "LOG: Epoch [102/1000] - Training\n",
      "Epoch [102/1000] completed, Average Training Loss: 1.5214\n",
      "    Validation Batch [1/1], Loss: 1.6227\n",
      "Validation Loss: 1.6227, Validation Accuracy: 68.57%\n",
      "Validation loss improved from 1.6307 to 1.6227. Saving model...\n",
      "\n",
      "LOG: Epoch [103/1000] - Training\n",
      "Epoch [103/1000] completed, Average Training Loss: 1.5214\n",
      "    Validation Batch [1/1], Loss: 1.6008\n",
      "Validation Loss: 1.6008, Validation Accuracy: 67.14%\n",
      "Validation loss improved from 1.6227 to 1.6008. Saving model...\n",
      "\n",
      "LOG: Epoch [104/1000] - Training\n",
      "Epoch [104/1000] completed, Average Training Loss: 1.4896\n",
      "    Validation Batch [1/1], Loss: 1.5705\n",
      "Validation Loss: 1.5705, Validation Accuracy: 67.14%\n",
      "Validation loss improved from 1.6008 to 1.5705. Saving model...\n",
      "\n",
      "LOG: Epoch [105/1000] - Training\n",
      "Epoch [105/1000] completed, Average Training Loss: 1.4800\n",
      "    Validation Batch [1/1], Loss: 1.5539\n",
      "Validation Loss: 1.5539, Validation Accuracy: 70.00%\n",
      "Validation loss improved from 1.5705 to 1.5539. Saving model...\n",
      "\n",
      "LOG: Epoch [106/1000] - Training\n",
      "Epoch [106/1000] completed, Average Training Loss: 1.4790\n",
      "    Validation Batch [1/1], Loss: 1.5594\n",
      "Validation Loss: 1.5594, Validation Accuracy: 71.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [107/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107/1000] completed, Average Training Loss: 1.4761\n",
      "    Validation Batch [1/1], Loss: 1.5622\n",
      "Validation Loss: 1.5622, Validation Accuracy: 74.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [108/1000] - Training\n",
      "Epoch [108/1000] completed, Average Training Loss: 1.4537\n",
      "    Validation Batch [1/1], Loss: 1.5166\n",
      "Validation Loss: 1.5166, Validation Accuracy: 71.43%\n",
      "Validation loss improved from 1.5539 to 1.5166. Saving model...\n",
      "\n",
      "LOG: Epoch [109/1000] - Training\n",
      "Epoch [109/1000] completed, Average Training Loss: 1.4449\n",
      "    Validation Batch [1/1], Loss: 1.5008\n",
      "Validation Loss: 1.5008, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.5166 to 1.5008. Saving model...\n",
      "\n",
      "LOG: Epoch [110/1000] - Training\n",
      "Epoch [110/1000] completed, Average Training Loss: 1.4549\n",
      "    Validation Batch [1/1], Loss: 1.4986\n",
      "Validation Loss: 1.4986, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.5008 to 1.4986. Saving model...\n",
      "\n",
      "LOG: Epoch [111/1000] - Training\n",
      "Epoch [111/1000] completed, Average Training Loss: 1.4264\n",
      "    Validation Batch [1/1], Loss: 1.4829\n",
      "Validation Loss: 1.4829, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.4986 to 1.4829. Saving model...\n",
      "\n",
      "LOG: Epoch [112/1000] - Training\n",
      "Epoch [112/1000] completed, Average Training Loss: 1.4208\n",
      "    Validation Batch [1/1], Loss: 1.4632\n",
      "Validation Loss: 1.4632, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.4829 to 1.4632. Saving model...\n",
      "\n",
      "LOG: Epoch [113/1000] - Training\n",
      "Epoch [113/1000] completed, Average Training Loss: 1.4409\n",
      "    Validation Batch [1/1], Loss: 1.4589\n",
      "Validation Loss: 1.4589, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.4632 to 1.4589. Saving model...\n",
      "\n",
      "LOG: Epoch [114/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [114/1000] completed, Average Training Loss: 1.3903\n",
      "    Validation Batch [1/1], Loss: 1.4483\n",
      "Validation Loss: 1.4483, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.4589 to 1.4483. Saving model...\n",
      "\n",
      "LOG: Epoch [115/1000] - Training\n",
      "Epoch [115/1000] completed, Average Training Loss: 1.3993\n",
      "    Validation Batch [1/1], Loss: 1.4357\n",
      "Validation Loss: 1.4357, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.4483 to 1.4357. Saving model...\n",
      "\n",
      "LOG: Epoch [116/1000] - Training\n",
      "Epoch [116/1000] completed, Average Training Loss: 1.3872\n",
      "    Validation Batch [1/1], Loss: 1.4200\n",
      "Validation Loss: 1.4200, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.4357 to 1.4200. Saving model...\n",
      "\n",
      "LOG: Epoch [117/1000] - Training\n",
      "Epoch [117/1000] completed, Average Training Loss: 1.3358\n",
      "    Validation Batch [1/1], Loss: 1.4202\n",
      "Validation Loss: 1.4202, Validation Accuracy: 72.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [118/1000] - Training\n",
      "Epoch [118/1000] completed, Average Training Loss: 1.3734\n",
      "    Validation Batch [1/1], Loss: 1.4090\n",
      "Validation Loss: 1.4090, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.4200 to 1.4090. Saving model...\n",
      "\n",
      "LOG: Epoch [119/1000] - Training\n",
      "Epoch [119/1000] completed, Average Training Loss: 1.3658\n",
      "    Validation Batch [1/1], Loss: 1.3946\n",
      "Validation Loss: 1.3946, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.4090 to 1.3946. Saving model...\n",
      "\n",
      "LOG: Epoch [120/1000] - Training\n",
      "Epoch [120/1000] completed, Average Training Loss: 1.3662\n",
      "    Validation Batch [1/1], Loss: 1.3969\n",
      "Validation Loss: 1.3969, Validation Accuracy: 71.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [121/1000] - Training\n",
      "Epoch [121/1000] completed, Average Training Loss: 1.3246\n",
      "    Validation Batch [1/1], Loss: 1.3788\n",
      "Validation Loss: 1.3788, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.3946 to 1.3788. Saving model...\n",
      "\n",
      "LOG: Epoch [122/1000] - Training\n",
      "Epoch [122/1000] completed, Average Training Loss: 1.3291\n",
      "    Validation Batch [1/1], Loss: 1.3625\n",
      "Validation Loss: 1.3625, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.3788 to 1.3625. Saving model...\n",
      "\n",
      "LOG: Epoch [123/1000] - Training\n",
      "Epoch [123/1000] completed, Average Training Loss: 1.3333\n",
      "    Validation Batch [1/1], Loss: 1.3476\n",
      "Validation Loss: 1.3476, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.3625 to 1.3476. Saving model...\n",
      "\n",
      "LOG: Epoch [124/1000] - Training\n",
      "Epoch [124/1000] completed, Average Training Loss: 1.3035\n",
      "    Validation Batch [1/1], Loss: 1.3394\n",
      "Validation Loss: 1.3394, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.3476 to 1.3394. Saving model...\n",
      "\n",
      "LOG: Epoch [125/1000] - Training\n",
      "Epoch [125/1000] completed, Average Training Loss: 1.2800\n",
      "    Validation Batch [1/1], Loss: 1.3243\n",
      "Validation Loss: 1.3243, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.3394 to 1.3243. Saving model...\n",
      "\n",
      "LOG: Epoch [126/1000] - Training\n",
      "Epoch [126/1000] completed, Average Training Loss: 1.3229\n",
      "    Validation Batch [1/1], Loss: 1.3242\n",
      "Validation Loss: 1.3242, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.3243 to 1.3242. Saving model...\n",
      "\n",
      "LOG: Epoch [127/1000] - Training\n",
      "Epoch [127/1000] completed, Average Training Loss: 1.3010\n",
      "    Validation Batch [1/1], Loss: 1.3226\n",
      "Validation Loss: 1.3226, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.3242 to 1.3226. Saving model...\n",
      "\n",
      "LOG: Epoch [128/1000] - Training\n",
      "Epoch [128/1000] completed, Average Training Loss: 1.2872\n",
      "    Validation Batch [1/1], Loss: 1.3205\n",
      "Validation Loss: 1.3205, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.3226 to 1.3205. Saving model...\n",
      "\n",
      "LOG: Epoch [129/1000] - Training\n",
      "Epoch [129/1000] completed, Average Training Loss: 1.2877\n",
      "    Validation Batch [1/1], Loss: 1.3063\n",
      "Validation Loss: 1.3063, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.3205 to 1.3063. Saving model...\n",
      "\n",
      "LOG: Epoch [130/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [130/1000] completed, Average Training Loss: 1.2763\n",
      "    Validation Batch [1/1], Loss: 1.2888\n",
      "Validation Loss: 1.2888, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.3063 to 1.2888. Saving model...\n",
      "\n",
      "LOG: Epoch [131/1000] - Training\n",
      "Epoch [131/1000] completed, Average Training Loss: 1.2458\n",
      "    Validation Batch [1/1], Loss: 1.2677\n",
      "Validation Loss: 1.2677, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.2888 to 1.2677. Saving model...\n",
      "\n",
      "LOG: Epoch [132/1000] - Training\n",
      "Epoch [132/1000] completed, Average Training Loss: 1.2359\n",
      "    Validation Batch [1/1], Loss: 1.2652\n",
      "Validation Loss: 1.2652, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.2677 to 1.2652. Saving model...\n",
      "\n",
      "LOG: Epoch [133/1000] - Training\n",
      "Epoch [133/1000] completed, Average Training Loss: 1.2041\n",
      "    Validation Batch [1/1], Loss: 1.2657\n",
      "Validation Loss: 1.2657, Validation Accuracy: 75.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [134/1000] - Training\n",
      "Epoch [134/1000] completed, Average Training Loss: 1.2600\n",
      "    Validation Batch [1/1], Loss: 1.2493\n",
      "Validation Loss: 1.2493, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.2652 to 1.2493. Saving model...\n",
      "\n",
      "LOG: Epoch [135/1000] - Training\n",
      "Epoch [135/1000] completed, Average Training Loss: 1.2131\n",
      "    Validation Batch [1/1], Loss: 1.2426\n",
      "Validation Loss: 1.2426, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.2493 to 1.2426. Saving model...\n",
      "\n",
      "LOG: Epoch [136/1000] - Training\n",
      "Epoch [136/1000] completed, Average Training Loss: 1.1910\n",
      "    Validation Batch [1/1], Loss: 1.2223\n",
      "Validation Loss: 1.2223, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.2426 to 1.2223. Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [137/1000] - Training\n",
      "Epoch [137/1000] completed, Average Training Loss: 1.2012\n",
      "    Validation Batch [1/1], Loss: 1.2245\n",
      "Validation Loss: 1.2245, Validation Accuracy: 77.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [138/1000] - Training\n",
      "Epoch [138/1000] completed, Average Training Loss: 1.1722\n",
      "    Validation Batch [1/1], Loss: 1.2060\n",
      "Validation Loss: 1.2060, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.2223 to 1.2060. Saving model...\n",
      "\n",
      "LOG: Epoch [139/1000] - Training\n",
      "Epoch [139/1000] completed, Average Training Loss: 1.1758\n",
      "    Validation Batch [1/1], Loss: 1.2007\n",
      "Validation Loss: 1.2007, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.2060 to 1.2007. Saving model...\n",
      "\n",
      "LOG: Epoch [140/1000] - Training\n",
      "Epoch [140/1000] completed, Average Training Loss: 1.1947\n",
      "    Validation Batch [1/1], Loss: 1.2055\n",
      "Validation Loss: 1.2055, Validation Accuracy: 77.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [141/1000] - Training\n",
      "Epoch [141/1000] completed, Average Training Loss: 1.1503\n",
      "    Validation Batch [1/1], Loss: 1.2039\n",
      "Validation Loss: 1.2039, Validation Accuracy: 75.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [142/1000] - Training\n",
      "Epoch [142/1000] completed, Average Training Loss: 1.1636\n",
      "    Validation Batch [1/1], Loss: 1.1974\n",
      "Validation Loss: 1.1974, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.2007 to 1.1974. Saving model...\n",
      "\n",
      "LOG: Epoch [143/1000] - Training\n",
      "Epoch [143/1000] completed, Average Training Loss: 1.1309\n",
      "    Validation Batch [1/1], Loss: 1.1942\n",
      "Validation Loss: 1.1942, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.1974 to 1.1942. Saving model...\n",
      "\n",
      "LOG: Epoch [144/1000] - Training\n",
      "Epoch [144/1000] completed, Average Training Loss: 1.1406\n",
      "    Validation Batch [1/1], Loss: 1.1565\n",
      "Validation Loss: 1.1565, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.1942 to 1.1565. Saving model...\n",
      "\n",
      "LOG: Epoch [145/1000] - Training\n",
      "Epoch [145/1000] completed, Average Training Loss: 1.1208\n",
      "    Validation Batch [1/1], Loss: 1.1371\n",
      "Validation Loss: 1.1371, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.1565 to 1.1371. Saving model...\n",
      "\n",
      "LOG: Epoch [146/1000] - Training\n",
      "Epoch [146/1000] completed, Average Training Loss: 1.0970\n",
      "    Validation Batch [1/1], Loss: 1.1458\n",
      "Validation Loss: 1.1458, Validation Accuracy: 77.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [147/1000] - Training\n",
      "Epoch [147/1000] completed, Average Training Loss: 1.1234\n",
      "    Validation Batch [1/1], Loss: 1.1367\n",
      "Validation Loss: 1.1367, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.1371 to 1.1367. Saving model...\n",
      "\n",
      "LOG: Epoch [148/1000] - Training\n",
      "Epoch [148/1000] completed, Average Training Loss: 1.1250\n",
      "    Validation Batch [1/1], Loss: 1.1326\n",
      "Validation Loss: 1.1326, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.1367 to 1.1326. Saving model...\n",
      "\n",
      "LOG: Epoch [149/1000] - Training\n",
      "Epoch [149/1000] completed, Average Training Loss: 1.0998\n",
      "    Validation Batch [1/1], Loss: 1.1336\n",
      "Validation Loss: 1.1336, Validation Accuracy: 77.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [150/1000] - Training\n",
      "Epoch [150/1000] completed, Average Training Loss: 1.0742\n",
      "    Validation Batch [1/1], Loss: 1.1132\n",
      "Validation Loss: 1.1132, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.1326 to 1.1132. Saving model...\n",
      "\n",
      "LOG: Epoch [151/1000] - Training\n",
      "Epoch [151/1000] completed, Average Training Loss: 1.0850\n",
      "    Validation Batch [1/1], Loss: 1.0925\n",
      "Validation Loss: 1.0925, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 1.1132 to 1.0925. Saving model...\n",
      "\n",
      "LOG: Epoch [152/1000] - Training\n",
      "Epoch [152/1000] completed, Average Training Loss: 1.0846\n",
      "    Validation Batch [1/1], Loss: 1.1000\n",
      "Validation Loss: 1.1000, Validation Accuracy: 78.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [153/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [153/1000] completed, Average Training Loss: 1.0481\n",
      "    Validation Batch [1/1], Loss: 1.1013\n",
      "Validation Loss: 1.1013, Validation Accuracy: 78.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [154/1000] - Training\n",
      "Epoch [154/1000] completed, Average Training Loss: 1.0404\n",
      "    Validation Batch [1/1], Loss: 1.0877\n",
      "Validation Loss: 1.0877, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.0925 to 1.0877. Saving model...\n",
      "\n",
      "LOG: Epoch [155/1000] - Training\n",
      "Epoch [155/1000] completed, Average Training Loss: 1.0432\n",
      "    Validation Batch [1/1], Loss: 1.0817\n",
      "Validation Loss: 1.0817, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.0877 to 1.0817. Saving model...\n",
      "\n",
      "LOG: Epoch [156/1000] - Training\n",
      "Epoch [156/1000] completed, Average Training Loss: 1.0366\n",
      "    Validation Batch [1/1], Loss: 1.1010\n",
      "Validation Loss: 1.1010, Validation Accuracy: 77.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [157/1000] - Training\n",
      "Epoch [157/1000] completed, Average Training Loss: 1.0293\n",
      "    Validation Batch [1/1], Loss: 1.0506\n",
      "Validation Loss: 1.0506, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.0817 to 1.0506. Saving model...\n",
      "\n",
      "LOG: Epoch [158/1000] - Training\n",
      "Epoch [158/1000] completed, Average Training Loss: 1.0202\n",
      "    Validation Batch [1/1], Loss: 1.0474\n",
      "Validation Loss: 1.0474, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.0506 to 1.0474. Saving model...\n",
      "\n",
      "LOG: Epoch [159/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [159/1000] completed, Average Training Loss: 1.0002\n",
      "    Validation Batch [1/1], Loss: 1.0572\n",
      "Validation Loss: 1.0572, Validation Accuracy: 78.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [160/1000] - Training\n",
      "Epoch [160/1000] completed, Average Training Loss: 0.9884\n",
      "    Validation Batch [1/1], Loss: 1.0507\n",
      "Validation Loss: 1.0507, Validation Accuracy: 78.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [161/1000] - Training\n",
      "Epoch [161/1000] completed, Average Training Loss: 1.0084\n",
      "    Validation Batch [1/1], Loss: 1.0290\n",
      "Validation Loss: 1.0290, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.0474 to 1.0290. Saving model...\n",
      "\n",
      "LOG: Epoch [162/1000] - Training\n",
      "Epoch [162/1000] completed, Average Training Loss: 0.9932\n",
      "    Validation Batch [1/1], Loss: 1.0224\n",
      "Validation Loss: 1.0224, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.0290 to 1.0224. Saving model...\n",
      "\n",
      "LOG: Epoch [163/1000] - Training\n",
      "Epoch [163/1000] completed, Average Training Loss: 0.9957\n",
      "    Validation Batch [1/1], Loss: 1.0230\n",
      "Validation Loss: 1.0230, Validation Accuracy: 78.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [164/1000] - Training\n",
      "Epoch [164/1000] completed, Average Training Loss: 1.0135\n",
      "    Validation Batch [1/1], Loss: 1.0308\n",
      "Validation Loss: 1.0308, Validation Accuracy: 78.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [165/1000] - Training\n",
      "Epoch [165/1000] completed, Average Training Loss: 0.9789\n",
      "    Validation Batch [1/1], Loss: 1.0153\n",
      "Validation Loss: 1.0153, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.0224 to 1.0153. Saving model...\n",
      "\n",
      "LOG: Epoch [166/1000] - Training\n",
      "Epoch [166/1000] completed, Average Training Loss: 0.9485\n",
      "    Validation Batch [1/1], Loss: 1.0235\n",
      "Validation Loss: 1.0235, Validation Accuracy: 82.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [167/1000] - Training\n",
      "Epoch [167/1000] completed, Average Training Loss: 0.9579\n",
      "    Validation Batch [1/1], Loss: 1.0122\n",
      "Validation Loss: 1.0122, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.0153 to 1.0122. Saving model...\n",
      "\n",
      "LOG: Epoch [168/1000] - Training\n",
      "Epoch [168/1000] completed, Average Training Loss: 0.9154\n",
      "    Validation Batch [1/1], Loss: 0.9821\n",
      "Validation Loss: 0.9821, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.0122 to 0.9821. Saving model...\n",
      "\n",
      "LOG: Epoch [169/1000] - Training\n",
      "Epoch [169/1000] completed, Average Training Loss: 0.9504\n",
      "    Validation Batch [1/1], Loss: 0.9747\n",
      "Validation Loss: 0.9747, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 0.9821 to 0.9747. Saving model...\n",
      "\n",
      "LOG: Epoch [170/1000] - Training\n",
      "Epoch [170/1000] completed, Average Training Loss: 0.8807\n",
      "    Validation Batch [1/1], Loss: 0.9706\n",
      "Validation Loss: 0.9706, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 0.9747 to 0.9706. Saving model...\n",
      "\n",
      "LOG: Epoch [171/1000] - Training\n",
      "Epoch [171/1000] completed, Average Training Loss: 0.9161\n",
      "    Validation Batch [1/1], Loss: 0.9827\n",
      "Validation Loss: 0.9827, Validation Accuracy: 77.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [172/1000] - Training\n",
      "Epoch [172/1000] completed, Average Training Loss: 0.9268\n",
      "    Validation Batch [1/1], Loss: 0.9703\n",
      "Validation Loss: 0.9703, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 0.9706 to 0.9703. Saving model...\n",
      "\n",
      "LOG: Epoch [173/1000] - Training\n",
      "Epoch [173/1000] completed, Average Training Loss: 0.9259\n",
      "    Validation Batch [1/1], Loss: 0.9625\n",
      "Validation Loss: 0.9625, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 0.9703 to 0.9625. Saving model...\n",
      "\n",
      "LOG: Epoch [174/1000] - Training\n",
      "Epoch [174/1000] completed, Average Training Loss: 0.9064\n",
      "    Validation Batch [1/1], Loss: 0.9454\n",
      "Validation Loss: 0.9454, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 0.9625 to 0.9454. Saving model...\n",
      "\n",
      "LOG: Epoch [175/1000] - Training\n",
      "Epoch [175/1000] completed, Average Training Loss: 0.8953\n",
      "    Validation Batch [1/1], Loss: 0.9392\n",
      "Validation Loss: 0.9392, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 0.9454 to 0.9392. Saving model...\n",
      "\n",
      "LOG: Epoch [176/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [176/1000] completed, Average Training Loss: 0.9162\n",
      "    Validation Batch [1/1], Loss: 0.9360\n",
      "Validation Loss: 0.9360, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 0.9392 to 0.9360. Saving model...\n",
      "\n",
      "LOG: Epoch [177/1000] - Training\n",
      "Epoch [177/1000] completed, Average Training Loss: 0.8724\n",
      "    Validation Batch [1/1], Loss: 0.9417\n",
      "Validation Loss: 0.9417, Validation Accuracy: 84.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [178/1000] - Training\n",
      "Epoch [178/1000] completed, Average Training Loss: 0.8733\n",
      "    Validation Batch [1/1], Loss: 0.9675\n",
      "Validation Loss: 0.9675, Validation Accuracy: 77.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [179/1000] - Training\n",
      "Epoch [179/1000] completed, Average Training Loss: 0.8921\n",
      "    Validation Batch [1/1], Loss: 0.9129\n",
      "Validation Loss: 0.9129, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 0.9360 to 0.9129. Saving model...\n",
      "\n",
      "LOG: Epoch [180/1000] - Training\n",
      "Epoch [180/1000] completed, Average Training Loss: 0.8746\n",
      "    Validation Batch [1/1], Loss: 0.9266\n",
      "Validation Loss: 0.9266, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [181/1000] - Training\n",
      "Epoch [181/1000] completed, Average Training Loss: 0.8419\n",
      "    Validation Batch [1/1], Loss: 0.8993\n",
      "Validation Loss: 0.8993, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 0.9129 to 0.8993. Saving model...\n",
      "\n",
      "LOG: Epoch [182/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [182/1000] completed, Average Training Loss: 0.8480\n",
      "    Validation Batch [1/1], Loss: 0.8936\n",
      "Validation Loss: 0.8936, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 0.8993 to 0.8936. Saving model...\n",
      "\n",
      "LOG: Epoch [183/1000] - Training\n",
      "Epoch [183/1000] completed, Average Training Loss: 0.8335\n",
      "    Validation Batch [1/1], Loss: 0.8939\n",
      "Validation Loss: 0.8939, Validation Accuracy: 84.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [184/1000] - Training\n",
      "Epoch [184/1000] completed, Average Training Loss: 0.8402\n",
      "    Validation Batch [1/1], Loss: 0.8793\n",
      "Validation Loss: 0.8793, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 0.8936 to 0.8793. Saving model...\n",
      "\n",
      "LOG: Epoch [185/1000] - Training\n",
      "Epoch [185/1000] completed, Average Training Loss: 0.8255\n",
      "    Validation Batch [1/1], Loss: 0.8692\n",
      "Validation Loss: 0.8692, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 0.8793 to 0.8692. Saving model...\n",
      "\n",
      "LOG: Epoch [186/1000] - Training\n",
      "Epoch [186/1000] completed, Average Training Loss: 0.8275\n",
      "    Validation Batch [1/1], Loss: 0.8828\n",
      "Validation Loss: 0.8828, Validation Accuracy: 82.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [187/1000] - Training\n",
      "Epoch [187/1000] completed, Average Training Loss: 0.8357\n",
      "    Validation Batch [1/1], Loss: 0.8634\n",
      "Validation Loss: 0.8634, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 0.8692 to 0.8634. Saving model...\n",
      "\n",
      "LOG: Epoch [188/1000] - Training\n",
      "Epoch [188/1000] completed, Average Training Loss: 0.8161\n",
      "    Validation Batch [1/1], Loss: 0.8556\n",
      "Validation Loss: 0.8556, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 0.8634 to 0.8556. Saving model...\n",
      "\n",
      "LOG: Epoch [189/1000] - Training\n",
      "Epoch [189/1000] completed, Average Training Loss: 0.8066\n",
      "    Validation Batch [1/1], Loss: 0.8527\n",
      "Validation Loss: 0.8527, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 0.8556 to 0.8527. Saving model...\n",
      "\n",
      "LOG: Epoch [190/1000] - Training\n",
      "Epoch [190/1000] completed, Average Training Loss: 0.8005\n",
      "    Validation Batch [1/1], Loss: 0.8473\n",
      "Validation Loss: 0.8473, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 0.8527 to 0.8473. Saving model...\n",
      "\n",
      "LOG: Epoch [191/1000] - Training\n",
      "Epoch [191/1000] completed, Average Training Loss: 0.7615\n",
      "    Validation Batch [1/1], Loss: 0.8278\n",
      "Validation Loss: 0.8278, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 0.8473 to 0.8278. Saving model...\n",
      "\n",
      "LOG: Epoch [192/1000] - Training\n",
      "Epoch [192/1000] completed, Average Training Loss: 0.7919\n",
      "    Validation Batch [1/1], Loss: 0.8273\n",
      "Validation Loss: 0.8273, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 0.8278 to 0.8273. Saving model...\n",
      "\n",
      "LOG: Epoch [193/1000] - Training\n",
      "Epoch [193/1000] completed, Average Training Loss: 0.7722\n",
      "    Validation Batch [1/1], Loss: 0.8364\n",
      "Validation Loss: 0.8364, Validation Accuracy: 84.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [194/1000] - Training\n",
      "Epoch [194/1000] completed, Average Training Loss: 0.7697\n",
      "    Validation Batch [1/1], Loss: 0.8220\n",
      "Validation Loss: 0.8220, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 0.8273 to 0.8220. Saving model...\n",
      "\n",
      "LOG: Epoch [195/1000] - Training\n",
      "Epoch [195/1000] completed, Average Training Loss: 0.7714\n",
      "    Validation Batch [1/1], Loss: 0.8127\n",
      "Validation Loss: 0.8127, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 0.8220 to 0.8127. Saving model...\n",
      "\n",
      "LOG: Epoch [196/1000] - Training\n",
      "Epoch [196/1000] completed, Average Training Loss: 0.7638\n",
      "    Validation Batch [1/1], Loss: 0.7990\n",
      "Validation Loss: 0.7990, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 0.8127 to 0.7990. Saving model...\n",
      "\n",
      "LOG: Epoch [197/1000] - Training\n",
      "Epoch [197/1000] completed, Average Training Loss: 0.7439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.7810\n",
      "Validation Loss: 0.7810, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 0.7990 to 0.7810. Saving model...\n",
      "\n",
      "LOG: Epoch [198/1000] - Training\n",
      "Epoch [198/1000] completed, Average Training Loss: 0.7660\n",
      "    Validation Batch [1/1], Loss: 0.7899\n",
      "Validation Loss: 0.7899, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [199/1000] - Training\n",
      "Epoch [199/1000] completed, Average Training Loss: 0.7380\n",
      "    Validation Batch [1/1], Loss: 0.8013\n",
      "Validation Loss: 0.8013, Validation Accuracy: 84.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [200/1000] - Training\n",
      "Epoch [200/1000] completed, Average Training Loss: 0.7257\n",
      "    Validation Batch [1/1], Loss: 0.7765\n",
      "Validation Loss: 0.7765, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 0.7810 to 0.7765. Saving model...\n",
      "\n",
      "LOG: Epoch [201/1000] - Training\n",
      "Epoch [201/1000] completed, Average Training Loss: 0.7144\n",
      "    Validation Batch [1/1], Loss: 0.7791\n",
      "Validation Loss: 0.7791, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [202/1000] - Training\n",
      "Epoch [202/1000] completed, Average Training Loss: 0.7109\n",
      "    Validation Batch [1/1], Loss: 0.7974\n",
      "Validation Loss: 0.7974, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [203/1000] - Training\n",
      "Epoch [203/1000] completed, Average Training Loss: 0.7268\n",
      "    Validation Batch [1/1], Loss: 0.7699\n",
      "Validation Loss: 0.7699, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 0.7765 to 0.7699. Saving model...\n",
      "\n",
      "LOG: Epoch [204/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [204/1000] completed, Average Training Loss: 0.7051\n",
      "    Validation Batch [1/1], Loss: 0.7745\n",
      "Validation Loss: 0.7745, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [205/1000] - Training\n",
      "Epoch [205/1000] completed, Average Training Loss: 0.7273\n",
      "    Validation Batch [1/1], Loss: 0.8586\n",
      "Validation Loss: 0.8586, Validation Accuracy: 84.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [206/1000] - Training\n",
      "Epoch [206/1000] completed, Average Training Loss: 0.7012\n",
      "    Validation Batch [1/1], Loss: 0.7574\n",
      "Validation Loss: 0.7574, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 0.7699 to 0.7574. Saving model...\n",
      "\n",
      "LOG: Epoch [207/1000] - Training\n",
      "Epoch [207/1000] completed, Average Training Loss: 0.7039\n",
      "    Validation Batch [1/1], Loss: 0.7367\n",
      "Validation Loss: 0.7367, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 0.7574 to 0.7367. Saving model...\n",
      "\n",
      "LOG: Epoch [208/1000] - Training\n",
      "Epoch [208/1000] completed, Average Training Loss: 0.6977\n",
      "    Validation Batch [1/1], Loss: 0.7790\n",
      "Validation Loss: 0.7790, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [209/1000] - Training\n",
      "Epoch [209/1000] completed, Average Training Loss: 0.7035\n",
      "    Validation Batch [1/1], Loss: 0.7656\n",
      "Validation Loss: 0.7656, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [210/1000] - Training\n",
      "Epoch [210/1000] completed, Average Training Loss: 0.6678\n",
      "    Validation Batch [1/1], Loss: 0.7414\n",
      "Validation Loss: 0.7414, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [211/1000] - Training\n",
      "Epoch [211/1000] completed, Average Training Loss: 0.6731\n",
      "    Validation Batch [1/1], Loss: 0.8108\n",
      "Validation Loss: 0.8108, Validation Accuracy: 82.86%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [212/1000] - Training\n",
      "Epoch [212/1000] completed, Average Training Loss: 0.6557\n",
      "    Validation Batch [1/1], Loss: 0.7813\n",
      "Validation Loss: 0.7813, Validation Accuracy: 85.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [213/1000] - Training\n",
      "Epoch [213/1000] completed, Average Training Loss: 0.6788\n",
      "    Validation Batch [1/1], Loss: 0.7204\n",
      "Validation Loss: 0.7204, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.7367 to 0.7204. Saving model...\n",
      "\n",
      "LOG: Epoch [214/1000] - Training\n",
      "Epoch [214/1000] completed, Average Training Loss: 0.6410\n",
      "    Validation Batch [1/1], Loss: 0.7115\n",
      "Validation Loss: 0.7115, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.7204 to 0.7115. Saving model...\n",
      "\n",
      "LOG: Epoch [215/1000] - Training\n",
      "Epoch [215/1000] completed, Average Training Loss: 0.6650\n",
      "    Validation Batch [1/1], Loss: 0.7645\n",
      "Validation Loss: 0.7645, Validation Accuracy: 82.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [216/1000] - Training\n",
      "Epoch [216/1000] completed, Average Training Loss: 0.6533\n",
      "    Validation Batch [1/1], Loss: 0.7333\n",
      "Validation Loss: 0.7333, Validation Accuracy: 84.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [217/1000] - Training\n",
      "Epoch [217/1000] completed, Average Training Loss: 0.6373\n",
      "    Validation Batch [1/1], Loss: 0.6971\n",
      "Validation Loss: 0.6971, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.7115 to 0.6971. Saving model...\n",
      "\n",
      "LOG: Epoch [218/1000] - Training\n",
      "Epoch [218/1000] completed, Average Training Loss: 0.6560\n",
      "    Validation Batch [1/1], Loss: 0.7069\n",
      "Validation Loss: 0.7069, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [219/1000] - Training\n",
      "Epoch [219/1000] completed, Average Training Loss: 0.6119\n",
      "    Validation Batch [1/1], Loss: 0.6998\n",
      "Validation Loss: 0.6998, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [220/1000] - Training\n",
      "Epoch [220/1000] completed, Average Training Loss: 0.6081\n",
      "    Validation Batch [1/1], Loss: 0.6791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6791, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.6971 to 0.6791. Saving model...\n",
      "\n",
      "LOG: Epoch [221/1000] - Training\n",
      "Epoch [221/1000] completed, Average Training Loss: 0.6000\n",
      "    Validation Batch [1/1], Loss: 0.6719\n",
      "Validation Loss: 0.6719, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.6791 to 0.6719. Saving model...\n",
      "\n",
      "LOG: Epoch [222/1000] - Training\n",
      "Epoch [222/1000] completed, Average Training Loss: 0.6111\n",
      "    Validation Batch [1/1], Loss: 0.7216\n",
      "Validation Loss: 0.7216, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [223/1000] - Training\n",
      "Epoch [223/1000] completed, Average Training Loss: 0.6052\n",
      "    Validation Batch [1/1], Loss: 0.7182\n",
      "Validation Loss: 0.7182, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [224/1000] - Training\n",
      "Epoch [224/1000] completed, Average Training Loss: 0.5921\n",
      "    Validation Batch [1/1], Loss: 0.7187\n",
      "Validation Loss: 0.7187, Validation Accuracy: 85.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [225/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [225/1000] completed, Average Training Loss: 0.6212\n",
      "    Validation Batch [1/1], Loss: 0.6984\n",
      "Validation Loss: 0.6984, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [226/1000] - Training\n",
      "Epoch [226/1000] completed, Average Training Loss: 0.6085\n",
      "    Validation Batch [1/1], Loss: 0.6891\n",
      "Validation Loss: 0.6891, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [227/1000] - Training\n",
      "Epoch [227/1000] completed, Average Training Loss: 0.5826\n",
      "    Validation Batch [1/1], Loss: 0.6721\n",
      "Validation Loss: 0.6721, Validation Accuracy: 85.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [228/1000] - Training\n",
      "Epoch [228/1000] completed, Average Training Loss: 0.5624\n",
      "    Validation Batch [1/1], Loss: 0.6630\n",
      "Validation Loss: 0.6630, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 0.6719 to 0.6630. Saving model...\n",
      "\n",
      "LOG: Epoch [229/1000] - Training\n",
      "Epoch [229/1000] completed, Average Training Loss: 0.5680\n",
      "    Validation Batch [1/1], Loss: 0.6558\n",
      "Validation Loss: 0.6558, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 0.6630 to 0.6558. Saving model...\n",
      "\n",
      "LOG: Epoch [230/1000] - Training\n",
      "Epoch [230/1000] completed, Average Training Loss: 0.5749\n",
      "    Validation Batch [1/1], Loss: 0.6951\n",
      "Validation Loss: 0.6951, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [231/1000] - Training\n",
      "Epoch [231/1000] completed, Average Training Loss: 0.5894\n",
      "    Validation Batch [1/1], Loss: 0.6676\n",
      "Validation Loss: 0.6676, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [232/1000] - Training\n",
      "Epoch [232/1000] completed, Average Training Loss: 0.5562\n",
      "    Validation Batch [1/1], Loss: 0.6716\n",
      "Validation Loss: 0.6716, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [233/1000] - Training\n",
      "Epoch [233/1000] completed, Average Training Loss: 0.5672\n",
      "    Validation Batch [1/1], Loss: 0.6494\n",
      "Validation Loss: 0.6494, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.6558 to 0.6494. Saving model...\n",
      "\n",
      "LOG: Epoch [234/1000] - Training\n",
      "Epoch [234/1000] completed, Average Training Loss: 0.5611\n",
      "    Validation Batch [1/1], Loss: 0.6320\n",
      "Validation Loss: 0.6320, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.6494 to 0.6320. Saving model...\n",
      "\n",
      "LOG: Epoch [235/1000] - Training\n",
      "Epoch [235/1000] completed, Average Training Loss: 0.5394\n",
      "    Validation Batch [1/1], Loss: 0.5995\n",
      "Validation Loss: 0.5995, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.6320 to 0.5995. Saving model...\n",
      "\n",
      "LOG: Epoch [236/1000] - Training\n",
      "Epoch [236/1000] completed, Average Training Loss: 0.5675\n",
      "    Validation Batch [1/1], Loss: 0.6527\n",
      "Validation Loss: 0.6527, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [237/1000] - Training\n",
      "Epoch [237/1000] completed, Average Training Loss: 0.5289\n",
      "    Validation Batch [1/1], Loss: 0.6652\n",
      "Validation Loss: 0.6652, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [238/1000] - Training\n",
      "Epoch [238/1000] completed, Average Training Loss: 0.5142\n",
      "    Validation Batch [1/1], Loss: 0.6343\n",
      "Validation Loss: 0.6343, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [239/1000] - Training\n",
      "Epoch [239/1000] completed, Average Training Loss: 0.5297\n",
      "    Validation Batch [1/1], Loss: 0.6160\n",
      "Validation Loss: 0.6160, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [240/1000] - Training\n",
      "Epoch [240/1000] completed, Average Training Loss: 0.5437\n",
      "    Validation Batch [1/1], Loss: 0.6270\n",
      "Validation Loss: 0.6270, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [241/1000] - Training\n",
      "Epoch [241/1000] completed, Average Training Loss: 0.5229\n",
      "    Validation Batch [1/1], Loss: 0.5915\n",
      "Validation Loss: 0.5915, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.5995 to 0.5915. Saving model...\n",
      "\n",
      "LOG: Epoch [242/1000] - Training\n",
      "Epoch [242/1000] completed, Average Training Loss: 0.4985\n",
      "    Validation Batch [1/1], Loss: 0.5885\n",
      "Validation Loss: 0.5885, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.5915 to 0.5885. Saving model...\n",
      "\n",
      "LOG: Epoch [243/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [243/1000] completed, Average Training Loss: 0.5112\n",
      "    Validation Batch [1/1], Loss: 0.6028\n",
      "Validation Loss: 0.6028, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [244/1000] - Training\n",
      "Epoch [244/1000] completed, Average Training Loss: 0.5053\n",
      "    Validation Batch [1/1], Loss: 0.6023\n",
      "Validation Loss: 0.6023, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [245/1000] - Training\n",
      "Epoch [245/1000] completed, Average Training Loss: 0.5048\n",
      "    Validation Batch [1/1], Loss: 0.5870\n",
      "Validation Loss: 0.5870, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 0.5885 to 0.5870. Saving model...\n",
      "\n",
      "LOG: Epoch [246/1000] - Training\n",
      "Epoch [246/1000] completed, Average Training Loss: 0.5142\n",
      "    Validation Batch [1/1], Loss: 0.5695\n",
      "Validation Loss: 0.5695, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.5870 to 0.5695. Saving model...\n",
      "\n",
      "LOG: Epoch [247/1000] - Training\n",
      "Epoch [247/1000] completed, Average Training Loss: 0.4785\n",
      "    Validation Batch [1/1], Loss: 0.5531\n",
      "Validation Loss: 0.5531, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.5695 to 0.5531. Saving model...\n",
      "\n",
      "LOG: Epoch [248/1000] - Training\n",
      "Epoch [248/1000] completed, Average Training Loss: 0.4817\n",
      "    Validation Batch [1/1], Loss: 0.5757\n",
      "Validation Loss: 0.5757, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [249/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [249/1000] completed, Average Training Loss: 0.5071\n",
      "    Validation Batch [1/1], Loss: 0.6361\n",
      "Validation Loss: 0.6361, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [250/1000] - Training\n",
      "Epoch [250/1000] completed, Average Training Loss: 0.4725\n",
      "    Validation Batch [1/1], Loss: 0.5862\n",
      "Validation Loss: 0.5862, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [251/1000] - Training\n",
      "Epoch [251/1000] completed, Average Training Loss: 0.4801\n",
      "    Validation Batch [1/1], Loss: 0.5566\n",
      "Validation Loss: 0.5566, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [252/1000] - Training\n",
      "Epoch [252/1000] completed, Average Training Loss: 0.4493\n",
      "    Validation Batch [1/1], Loss: 0.5657\n",
      "Validation Loss: 0.5657, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [253/1000] - Training\n",
      "Epoch [253/1000] completed, Average Training Loss: 0.4582\n",
      "    Validation Batch [1/1], Loss: 0.6070\n",
      "Validation Loss: 0.6070, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [254/1000] - Training\n",
      "Epoch [254/1000] completed, Average Training Loss: 0.4789\n",
      "    Validation Batch [1/1], Loss: 0.5641\n",
      "Validation Loss: 0.5641, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [255/1000] - Training\n",
      "Epoch [255/1000] completed, Average Training Loss: 0.4528\n",
      "    Validation Batch [1/1], Loss: 0.5095\n",
      "Validation Loss: 0.5095, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.5531 to 0.5095. Saving model...\n",
      "\n",
      "LOG: Epoch [256/1000] - Training\n",
      "Epoch [256/1000] completed, Average Training Loss: 0.4658\n",
      "    Validation Batch [1/1], Loss: 0.5434\n",
      "Validation Loss: 0.5434, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [257/1000] - Training\n",
      "Epoch [257/1000] completed, Average Training Loss: 0.4571\n",
      "    Validation Batch [1/1], Loss: 0.5784\n",
      "Validation Loss: 0.5784, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [258/1000] - Training\n",
      "Epoch [258/1000] completed, Average Training Loss: 0.4491\n",
      "    Validation Batch [1/1], Loss: 0.5311\n",
      "Validation Loss: 0.5311, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [259/1000] - Training\n",
      "Epoch [259/1000] completed, Average Training Loss: 0.4494\n",
      "    Validation Batch [1/1], Loss: 0.5059\n",
      "Validation Loss: 0.5059, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.5095 to 0.5059. Saving model...\n",
      "\n",
      "LOG: Epoch [260/1000] - Training\n",
      "Epoch [260/1000] completed, Average Training Loss: 0.4286\n",
      "    Validation Batch [1/1], Loss: 0.5430\n",
      "Validation Loss: 0.5430, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [261/1000] - Training\n",
      "Epoch [261/1000] completed, Average Training Loss: 0.4371\n",
      "    Validation Batch [1/1], Loss: 0.5475\n",
      "Validation Loss: 0.5475, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [262/1000] - Training\n",
      "Epoch [262/1000] completed, Average Training Loss: 0.4315\n",
      "    Validation Batch [1/1], Loss: 0.4966\n",
      "Validation Loss: 0.4966, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.5059 to 0.4966. Saving model...\n",
      "\n",
      "LOG: Epoch [263/1000] - Training\n",
      "Epoch [263/1000] completed, Average Training Loss: 0.4418\n",
      "    Validation Batch [1/1], Loss: 0.4952\n",
      "Validation Loss: 0.4952, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.4966 to 0.4952. Saving model...\n",
      "\n",
      "LOG: Epoch [264/1000] - Training\n",
      "Epoch [264/1000] completed, Average Training Loss: 0.4106\n",
      "    Validation Batch [1/1], Loss: 0.5095\n",
      "Validation Loss: 0.5095, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [265/1000] - Training\n",
      "Epoch [265/1000] completed, Average Training Loss: 0.4107\n",
      "    Validation Batch [1/1], Loss: 0.5345\n",
      "Validation Loss: 0.5345, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [266/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [266/1000] completed, Average Training Loss: 0.4151\n",
      "    Validation Batch [1/1], Loss: 0.4878\n",
      "Validation Loss: 0.4878, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.4952 to 0.4878. Saving model...\n",
      "\n",
      "LOG: Epoch [267/1000] - Training\n",
      "Epoch [267/1000] completed, Average Training Loss: 0.4109\n",
      "    Validation Batch [1/1], Loss: 0.4729\n",
      "Validation Loss: 0.4729, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.4878 to 0.4729. Saving model...\n",
      "\n",
      "LOG: Epoch [268/1000] - Training\n",
      "Epoch [268/1000] completed, Average Training Loss: 0.4179\n",
      "    Validation Batch [1/1], Loss: 0.5032\n",
      "Validation Loss: 0.5032, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [269/1000] - Training\n",
      "Epoch [269/1000] completed, Average Training Loss: 0.4002\n",
      "    Validation Batch [1/1], Loss: 0.5170\n",
      "Validation Loss: 0.5170, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [270/1000] - Training\n",
      "Epoch [270/1000] completed, Average Training Loss: 0.3828\n",
      "    Validation Batch [1/1], Loss: 0.4806\n",
      "Validation Loss: 0.4806, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [271/1000] - Training\n",
      "Epoch [271/1000] completed, Average Training Loss: 0.4045\n",
      "    Validation Batch [1/1], Loss: 0.4749\n",
      "Validation Loss: 0.4749, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [272/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [272/1000] completed, Average Training Loss: 0.4012\n",
      "    Validation Batch [1/1], Loss: 0.4806\n",
      "Validation Loss: 0.4806, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [273/1000] - Training\n",
      "Epoch [273/1000] completed, Average Training Loss: 0.3906\n",
      "    Validation Batch [1/1], Loss: 0.5134\n",
      "Validation Loss: 0.5134, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [274/1000] - Training\n",
      "Epoch [274/1000] completed, Average Training Loss: 0.3810\n",
      "    Validation Batch [1/1], Loss: 0.4834\n",
      "Validation Loss: 0.4834, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [275/1000] - Training\n",
      "Epoch [275/1000] completed, Average Training Loss: 0.3621\n",
      "    Validation Batch [1/1], Loss: 0.4322\n",
      "Validation Loss: 0.4322, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.4729 to 0.4322. Saving model...\n",
      "\n",
      "LOG: Epoch [276/1000] - Training\n",
      "Epoch [276/1000] completed, Average Training Loss: 0.3763\n",
      "    Validation Batch [1/1], Loss: 0.4342\n",
      "Validation Loss: 0.4342, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [277/1000] - Training\n",
      "Epoch [277/1000] completed, Average Training Loss: 0.3502\n",
      "    Validation Batch [1/1], Loss: 0.4519\n",
      "Validation Loss: 0.4519, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [278/1000] - Training\n",
      "Epoch [278/1000] completed, Average Training Loss: 0.3726\n",
      "    Validation Batch [1/1], Loss: 0.4883\n",
      "Validation Loss: 0.4883, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [279/1000] - Training\n",
      "Epoch [279/1000] completed, Average Training Loss: 0.3600\n",
      "    Validation Batch [1/1], Loss: 0.4464\n",
      "Validation Loss: 0.4464, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [280/1000] - Training\n",
      "Epoch [280/1000] completed, Average Training Loss: 0.3779\n",
      "    Validation Batch [1/1], Loss: 0.4290\n",
      "Validation Loss: 0.4290, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.4322 to 0.4290. Saving model...\n",
      "\n",
      "LOG: Epoch [281/1000] - Training\n",
      "Epoch [281/1000] completed, Average Training Loss: 0.3676\n",
      "    Validation Batch [1/1], Loss: 0.4551\n",
      "Validation Loss: 0.4551, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [282/1000] - Training\n",
      "Epoch [282/1000] completed, Average Training Loss: 0.3665\n",
      "    Validation Batch [1/1], Loss: 0.4457\n",
      "Validation Loss: 0.4457, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [283/1000] - Training\n",
      "Epoch [283/1000] completed, Average Training Loss: 0.3534\n",
      "    Validation Batch [1/1], Loss: 0.4525\n",
      "Validation Loss: 0.4525, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [284/1000] - Training\n",
      "Epoch [284/1000] completed, Average Training Loss: 0.3562\n",
      "    Validation Batch [1/1], Loss: 0.4639\n",
      "Validation Loss: 0.4639, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [285/1000] - Training\n",
      "Epoch [285/1000] completed, Average Training Loss: 0.3557\n",
      "    Validation Batch [1/1], Loss: 0.4243\n",
      "Validation Loss: 0.4243, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.4290 to 0.4243. Saving model...\n",
      "\n",
      "LOG: Epoch [286/1000] - Training\n",
      "Epoch [286/1000] completed, Average Training Loss: 0.3461\n",
      "    Validation Batch [1/1], Loss: 0.3960\n",
      "Validation Loss: 0.3960, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.4243 to 0.3960. Saving model...\n",
      "\n",
      "LOG: Epoch [287/1000] - Training\n",
      "Epoch [287/1000] completed, Average Training Loss: 0.3454\n",
      "    Validation Batch [1/1], Loss: 0.4199\n",
      "Validation Loss: 0.4199, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [288/1000] - Training\n",
      "Epoch [288/1000] completed, Average Training Loss: 0.3331\n",
      "    Validation Batch [1/1], Loss: 0.4461\n",
      "Validation Loss: 0.4461, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [289/1000] - Training\n",
      "Epoch [289/1000] completed, Average Training Loss: 0.3218\n",
      "    Validation Batch [1/1], Loss: 0.4215\n",
      "Validation Loss: 0.4215, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [290/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [290/1000] completed, Average Training Loss: 0.3347\n",
      "    Validation Batch [1/1], Loss: 0.3946\n",
      "Validation Loss: 0.3946, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.3960 to 0.3946. Saving model...\n",
      "\n",
      "LOG: Epoch [291/1000] - Training\n",
      "Epoch [291/1000] completed, Average Training Loss: 0.3114\n",
      "    Validation Batch [1/1], Loss: 0.4066\n",
      "Validation Loss: 0.4066, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [292/1000] - Training\n",
      "Epoch [292/1000] completed, Average Training Loss: 0.3187\n",
      "    Validation Batch [1/1], Loss: 0.4421\n",
      "Validation Loss: 0.4421, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [293/1000] - Training\n",
      "Epoch [293/1000] completed, Average Training Loss: 0.3098\n",
      "    Validation Batch [1/1], Loss: 0.4049\n",
      "Validation Loss: 0.4049, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [294/1000] - Training\n",
      "Epoch [294/1000] completed, Average Training Loss: 0.3296\n",
      "    Validation Batch [1/1], Loss: 0.3843\n",
      "Validation Loss: 0.3843, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.3946 to 0.3843. Saving model...\n",
      "\n",
      "LOG: Epoch [295/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [295/1000] completed, Average Training Loss: 0.3237\n",
      "    Validation Batch [1/1], Loss: 0.3743\n",
      "Validation Loss: 0.3743, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.3843 to 0.3743. Saving model...\n",
      "\n",
      "LOG: Epoch [296/1000] - Training\n",
      "Epoch [296/1000] completed, Average Training Loss: 0.3038\n",
      "    Validation Batch [1/1], Loss: 0.4032\n",
      "Validation Loss: 0.4032, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [297/1000] - Training\n",
      "Epoch [297/1000] completed, Average Training Loss: 0.3380\n",
      "    Validation Batch [1/1], Loss: 0.4150\n",
      "Validation Loss: 0.4150, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [298/1000] - Training\n",
      "Epoch [298/1000] completed, Average Training Loss: 0.3002\n",
      "    Validation Batch [1/1], Loss: 0.4046\n",
      "Validation Loss: 0.4046, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [299/1000] - Training\n",
      "Epoch [299/1000] completed, Average Training Loss: 0.2999\n",
      "    Validation Batch [1/1], Loss: 0.3788\n",
      "Validation Loss: 0.3788, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [300/1000] - Training\n",
      "Epoch [300/1000] completed, Average Training Loss: 0.3140\n",
      "    Validation Batch [1/1], Loss: 0.3749\n",
      "Validation Loss: 0.3749, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [301/1000] - Training\n",
      "Epoch [301/1000] completed, Average Training Loss: 0.2879\n",
      "    Validation Batch [1/1], Loss: 0.3686\n",
      "Validation Loss: 0.3686, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.3743 to 0.3686. Saving model...\n",
      "\n",
      "LOG: Epoch [302/1000] - Training\n",
      "Epoch [302/1000] completed, Average Training Loss: 0.2957\n",
      "    Validation Batch [1/1], Loss: 0.3577\n",
      "Validation Loss: 0.3577, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.3686 to 0.3577. Saving model...\n",
      "\n",
      "LOG: Epoch [303/1000] - Training\n",
      "Epoch [303/1000] completed, Average Training Loss: 0.2973\n",
      "    Validation Batch [1/1], Loss: 0.3569\n",
      "Validation Loss: 0.3569, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.3577 to 0.3569. Saving model...\n",
      "\n",
      "LOG: Epoch [304/1000] - Training\n",
      "Epoch [304/1000] completed, Average Training Loss: 0.2827\n",
      "    Validation Batch [1/1], Loss: 0.3699\n",
      "Validation Loss: 0.3699, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [305/1000] - Training\n",
      "Epoch [305/1000] completed, Average Training Loss: 0.2839\n",
      "    Validation Batch [1/1], Loss: 0.3919\n",
      "Validation Loss: 0.3919, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [306/1000] - Training\n",
      "Epoch [306/1000] completed, Average Training Loss: 0.2815\n",
      "    Validation Batch [1/1], Loss: 0.3839\n",
      "Validation Loss: 0.3839, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [307/1000] - Training\n",
      "Epoch [307/1000] completed, Average Training Loss: 0.3006\n",
      "    Validation Batch [1/1], Loss: 0.3907\n",
      "Validation Loss: 0.3907, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [308/1000] - Training\n",
      "Epoch [308/1000] completed, Average Training Loss: 0.2641\n",
      "    Validation Batch [1/1], Loss: 0.3826\n",
      "Validation Loss: 0.3826, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [309/1000] - Training\n",
      "Epoch [309/1000] completed, Average Training Loss: 0.2709\n",
      "    Validation Batch [1/1], Loss: 0.3607\n",
      "Validation Loss: 0.3607, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [310/1000] - Training\n",
      "Epoch [310/1000] completed, Average Training Loss: 0.2973\n",
      "    Validation Batch [1/1], Loss: 0.3593\n",
      "Validation Loss: 0.3593, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [311/1000] - Training\n",
      "Epoch [311/1000] completed, Average Training Loss: 0.2815\n",
      "    Validation Batch [1/1], Loss: 0.3412\n",
      "Validation Loss: 0.3412, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.3569 to 0.3412. Saving model...\n",
      "\n",
      "LOG: Epoch [312/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [312/1000] completed, Average Training Loss: 0.2689\n",
      "    Validation Batch [1/1], Loss: 0.3384\n",
      "Validation Loss: 0.3384, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.3412 to 0.3384. Saving model...\n",
      "\n",
      "LOG: Epoch [313/1000] - Training\n",
      "Epoch [313/1000] completed, Average Training Loss: 0.2658\n",
      "    Validation Batch [1/1], Loss: 0.3597\n",
      "Validation Loss: 0.3597, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [314/1000] - Training\n",
      "Epoch [314/1000] completed, Average Training Loss: 0.2588\n",
      "    Validation Batch [1/1], Loss: 0.3800\n",
      "Validation Loss: 0.3800, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [315/1000] - Training\n",
      "Epoch [315/1000] completed, Average Training Loss: 0.2829\n",
      "    Validation Batch [1/1], Loss: 0.3872\n",
      "Validation Loss: 0.3872, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [316/1000] - Training\n",
      "Epoch [316/1000] completed, Average Training Loss: 0.2562\n",
      "    Validation Batch [1/1], Loss: 0.3599\n",
      "Validation Loss: 0.3599, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [317/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [317/1000] completed, Average Training Loss: 0.2604\n",
      "    Validation Batch [1/1], Loss: 0.3471\n",
      "Validation Loss: 0.3471, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [318/1000] - Training\n",
      "Epoch [318/1000] completed, Average Training Loss: 0.2511\n",
      "    Validation Batch [1/1], Loss: 0.3592\n",
      "Validation Loss: 0.3592, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [319/1000] - Training\n",
      "Epoch [319/1000] completed, Average Training Loss: 0.2477\n",
      "    Validation Batch [1/1], Loss: 0.3999\n",
      "Validation Loss: 0.3999, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [320/1000] - Training\n",
      "Epoch [320/1000] completed, Average Training Loss: 0.2398\n",
      "    Validation Batch [1/1], Loss: 0.3770\n",
      "Validation Loss: 0.3770, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [321/1000] - Training\n",
      "Epoch [321/1000] completed, Average Training Loss: 0.2611\n",
      "    Validation Batch [1/1], Loss: 0.3259\n",
      "Validation Loss: 0.3259, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.3384 to 0.3259. Saving model...\n",
      "\n",
      "LOG: Epoch [322/1000] - Training\n",
      "Epoch [322/1000] completed, Average Training Loss: 0.2511\n",
      "    Validation Batch [1/1], Loss: 0.3113\n",
      "Validation Loss: 0.3113, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.3259 to 0.3113. Saving model...\n",
      "\n",
      "LOG: Epoch [323/1000] - Training\n",
      "Epoch [323/1000] completed, Average Training Loss: 0.2374\n",
      "    Validation Batch [1/1], Loss: 0.3145\n",
      "Validation Loss: 0.3145, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [324/1000] - Training\n",
      "Epoch [324/1000] completed, Average Training Loss: 0.2474\n",
      "    Validation Batch [1/1], Loss: 0.3448\n",
      "Validation Loss: 0.3448, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [325/1000] - Training\n",
      "Epoch [325/1000] completed, Average Training Loss: 0.2361\n",
      "    Validation Batch [1/1], Loss: 0.3417\n",
      "Validation Loss: 0.3417, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [326/1000] - Training\n",
      "Epoch [326/1000] completed, Average Training Loss: 0.2422\n",
      "    Validation Batch [1/1], Loss: 0.3043\n",
      "Validation Loss: 0.3043, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.3113 to 0.3043. Saving model...\n",
      "\n",
      "LOG: Epoch [327/1000] - Training\n",
      "Epoch [327/1000] completed, Average Training Loss: 0.2309\n",
      "    Validation Batch [1/1], Loss: 0.3043\n",
      "Validation Loss: 0.3043, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.3043 to 0.3043. Saving model...\n",
      "\n",
      "LOG: Epoch [328/1000] - Training\n",
      "Epoch [328/1000] completed, Average Training Loss: 0.2348\n",
      "    Validation Batch [1/1], Loss: 0.3354\n",
      "Validation Loss: 0.3354, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [329/1000] - Training\n",
      "Epoch [329/1000] completed, Average Training Loss: 0.2463\n",
      "    Validation Batch [1/1], Loss: 0.3508\n",
      "Validation Loss: 0.3508, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [330/1000] - Training\n",
      "Epoch [330/1000] completed, Average Training Loss: 0.2380\n",
      "    Validation Batch [1/1], Loss: 0.3593\n",
      "Validation Loss: 0.3593, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [331/1000] - Training\n",
      "Epoch [331/1000] completed, Average Training Loss: 0.2303\n",
      "    Validation Batch [1/1], Loss: 0.3236\n",
      "Validation Loss: 0.3236, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [332/1000] - Training\n",
      "Epoch [332/1000] completed, Average Training Loss: 0.2447\n",
      "    Validation Batch [1/1], Loss: 0.2937\n",
      "Validation Loss: 0.2937, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.3043 to 0.2937. Saving model...\n",
      "\n",
      "LOG: Epoch [333/1000] - Training\n",
      "Epoch [333/1000] completed, Average Training Loss: 0.2144\n",
      "    Validation Batch [1/1], Loss: 0.2957\n",
      "Validation Loss: 0.2957, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [334/1000] - Training\n",
      "Epoch [334/1000] completed, Average Training Loss: 0.2252\n",
      "    Validation Batch [1/1], Loss: 0.2991\n",
      "Validation Loss: 0.2991, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [335/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [335/1000] completed, Average Training Loss: 0.2219\n",
      "    Validation Batch [1/1], Loss: 0.3139\n",
      "Validation Loss: 0.3139, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [336/1000] - Training\n",
      "Epoch [336/1000] completed, Average Training Loss: 0.2227\n",
      "    Validation Batch [1/1], Loss: 0.3094\n",
      "Validation Loss: 0.3094, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [337/1000] - Training\n",
      "Epoch [337/1000] completed, Average Training Loss: 0.2229\n",
      "    Validation Batch [1/1], Loss: 0.2914\n",
      "Validation Loss: 0.2914, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2937 to 0.2914. Saving model...\n",
      "\n",
      "LOG: Epoch [338/1000] - Training\n",
      "Epoch [338/1000] completed, Average Training Loss: 0.2269\n",
      "    Validation Batch [1/1], Loss: 0.2986\n",
      "Validation Loss: 0.2986, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [339/1000] - Training\n",
      "Epoch [339/1000] completed, Average Training Loss: 0.2230\n",
      "    Validation Batch [1/1], Loss: 0.3135\n",
      "Validation Loss: 0.3135, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [340/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [340/1000] completed, Average Training Loss: 0.2096\n",
      "    Validation Batch [1/1], Loss: 0.3203\n",
      "Validation Loss: 0.3203, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [341/1000] - Training\n",
      "Epoch [341/1000] completed, Average Training Loss: 0.2052\n",
      "    Validation Batch [1/1], Loss: 0.3305\n",
      "Validation Loss: 0.3305, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [342/1000] - Training\n",
      "Epoch [342/1000] completed, Average Training Loss: 0.2295\n",
      "    Validation Batch [1/1], Loss: 0.3202\n",
      "Validation Loss: 0.3202, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [343/1000] - Training\n",
      "Epoch [343/1000] completed, Average Training Loss: 0.2183\n",
      "    Validation Batch [1/1], Loss: 0.2781\n",
      "Validation Loss: 0.2781, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2914 to 0.2781. Saving model...\n",
      "\n",
      "LOG: Epoch [344/1000] - Training\n",
      "Epoch [344/1000] completed, Average Training Loss: 0.2138\n",
      "    Validation Batch [1/1], Loss: 0.2655\n",
      "Validation Loss: 0.2655, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2781 to 0.2655. Saving model...\n",
      "\n",
      "LOG: Epoch [345/1000] - Training\n",
      "Epoch [345/1000] completed, Average Training Loss: 0.2007\n",
      "    Validation Batch [1/1], Loss: 0.2702\n",
      "Validation Loss: 0.2702, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [346/1000] - Training\n",
      "Epoch [346/1000] completed, Average Training Loss: 0.2132\n",
      "    Validation Batch [1/1], Loss: 0.2857\n",
      "Validation Loss: 0.2857, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [347/1000] - Training\n",
      "Epoch [347/1000] completed, Average Training Loss: 0.1915\n",
      "    Validation Batch [1/1], Loss: 0.3037\n",
      "Validation Loss: 0.3037, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [348/1000] - Training\n",
      "Epoch [348/1000] completed, Average Training Loss: 0.2220\n",
      "    Validation Batch [1/1], Loss: 0.2792\n",
      "Validation Loss: 0.2792, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [349/1000] - Training\n",
      "Epoch [349/1000] completed, Average Training Loss: 0.2065\n",
      "    Validation Batch [1/1], Loss: 0.2757\n",
      "Validation Loss: 0.2757, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [350/1000] - Training\n",
      "Epoch [350/1000] completed, Average Training Loss: 0.2072\n",
      "    Validation Batch [1/1], Loss: 0.2667\n",
      "Validation Loss: 0.2667, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [351/1000] - Training\n",
      "Epoch [351/1000] completed, Average Training Loss: 0.1813\n",
      "    Validation Batch [1/1], Loss: 0.2751\n",
      "Validation Loss: 0.2751, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [352/1000] - Training\n",
      "Epoch [352/1000] completed, Average Training Loss: 0.1825\n",
      "    Validation Batch [1/1], Loss: 0.3013\n",
      "Validation Loss: 0.3013, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [353/1000] - Training\n",
      "Epoch [353/1000] completed, Average Training Loss: 0.1900\n",
      "    Validation Batch [1/1], Loss: 0.3020\n",
      "Validation Loss: 0.3020, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [354/1000] - Training\n",
      "Epoch [354/1000] completed, Average Training Loss: 0.1912\n",
      "    Validation Batch [1/1], Loss: 0.3017\n",
      "Validation Loss: 0.3017, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [355/1000] - Training\n",
      "Epoch [355/1000] completed, Average Training Loss: 0.1907\n",
      "    Validation Batch [1/1], Loss: 0.2992\n",
      "Validation Loss: 0.2992, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [356/1000] - Training\n",
      "Epoch [356/1000] completed, Average Training Loss: 0.1884\n",
      "    Validation Batch [1/1], Loss: 0.2972\n",
      "Validation Loss: 0.2972, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [357/1000] - Training\n",
      "Epoch [357/1000] completed, Average Training Loss: 0.1942\n",
      "    Validation Batch [1/1], Loss: 0.3129\n",
      "Validation Loss: 0.3129, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [358/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [358/1000] completed, Average Training Loss: 0.1980\n",
      "    Validation Batch [1/1], Loss: 0.3025\n",
      "Validation Loss: 0.3025, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [359/1000] - Training\n",
      "Epoch [359/1000] completed, Average Training Loss: 0.1930\n",
      "    Validation Batch [1/1], Loss: 0.2699\n",
      "Validation Loss: 0.2699, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [360/1000] - Training\n",
      "Epoch [360/1000] completed, Average Training Loss: 0.1748\n",
      "    Validation Batch [1/1], Loss: 0.2720\n",
      "Validation Loss: 0.2720, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [361/1000] - Training\n",
      "Epoch [361/1000] completed, Average Training Loss: 0.1753\n",
      "    Validation Batch [1/1], Loss: 0.2900\n",
      "Validation Loss: 0.2900, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [362/1000] - Training\n",
      "Epoch [362/1000] completed, Average Training Loss: 0.1789\n",
      "    Validation Batch [1/1], Loss: 0.3075\n",
      "Validation Loss: 0.3075, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [363/1000] - Training\n",
      "Epoch [363/1000] completed, Average Training Loss: 0.1685\n",
      "    Validation Batch [1/1], Loss: 0.2762\n",
      "Validation Loss: 0.2762, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [364/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [364/1000] completed, Average Training Loss: 0.1846\n",
      "    Validation Batch [1/1], Loss: 0.2447\n",
      "Validation Loss: 0.2447, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2655 to 0.2447. Saving model...\n",
      "\n",
      "LOG: Epoch [365/1000] - Training\n",
      "Epoch [365/1000] completed, Average Training Loss: 0.1843\n",
      "    Validation Batch [1/1], Loss: 0.2224\n",
      "Validation Loss: 0.2224, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2447 to 0.2224. Saving model...\n",
      "\n",
      "LOG: Epoch [366/1000] - Training\n",
      "Epoch [366/1000] completed, Average Training Loss: 0.1829\n",
      "    Validation Batch [1/1], Loss: 0.2333\n",
      "Validation Loss: 0.2333, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [367/1000] - Training\n",
      "Epoch [367/1000] completed, Average Training Loss: 0.1891\n",
      "    Validation Batch [1/1], Loss: 0.3069\n",
      "Validation Loss: 0.3069, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [368/1000] - Training\n",
      "Epoch [368/1000] completed, Average Training Loss: 0.1703\n",
      "    Validation Batch [1/1], Loss: 0.2834\n",
      "Validation Loss: 0.2834, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [369/1000] - Training\n",
      "Epoch [369/1000] completed, Average Training Loss: 0.1572\n",
      "    Validation Batch [1/1], Loss: 0.2672\n",
      "Validation Loss: 0.2672, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [370/1000] - Training\n",
      "Epoch [370/1000] completed, Average Training Loss: 0.1622\n",
      "    Validation Batch [1/1], Loss: 0.2676\n",
      "Validation Loss: 0.2676, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [371/1000] - Training\n",
      "Epoch [371/1000] completed, Average Training Loss: 0.1536\n",
      "    Validation Batch [1/1], Loss: 0.2686\n",
      "Validation Loss: 0.2686, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [372/1000] - Training\n",
      "Epoch [372/1000] completed, Average Training Loss: 0.1731\n",
      "    Validation Batch [1/1], Loss: 0.3049\n",
      "Validation Loss: 0.3049, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [373/1000] - Training\n",
      "Epoch [373/1000] completed, Average Training Loss: 0.1528\n",
      "    Validation Batch [1/1], Loss: 0.2856\n",
      "Validation Loss: 0.2856, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [374/1000] - Training\n",
      "Epoch [374/1000] completed, Average Training Loss: 0.1631\n",
      "    Validation Batch [1/1], Loss: 0.2446\n",
      "Validation Loss: 0.2446, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [375/1000] - Training\n",
      "Epoch [375/1000] completed, Average Training Loss: 0.1575\n",
      "    Validation Batch [1/1], Loss: 0.2206\n",
      "Validation Loss: 0.2206, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2224 to 0.2206. Saving model...\n",
      "\n",
      "LOG: Epoch [376/1000] - Training\n",
      "Epoch [376/1000] completed, Average Training Loss: 0.1726\n",
      "    Validation Batch [1/1], Loss: 0.2290\n",
      "Validation Loss: 0.2290, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [377/1000] - Training\n",
      "Epoch [377/1000] completed, Average Training Loss: 0.1497\n",
      "    Validation Batch [1/1], Loss: 0.2698\n",
      "Validation Loss: 0.2698, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [378/1000] - Training\n",
      "Epoch [378/1000] completed, Average Training Loss: 0.1523\n",
      "    Validation Batch [1/1], Loss: 0.2627\n",
      "Validation Loss: 0.2627, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [379/1000] - Training\n",
      "Epoch [379/1000] completed, Average Training Loss: 0.1493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.2329\n",
      "Validation Loss: 0.2329, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [380/1000] - Training\n",
      "Epoch [380/1000] completed, Average Training Loss: 0.1472\n",
      "    Validation Batch [1/1], Loss: 0.2387\n",
      "Validation Loss: 0.2387, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [381/1000] - Training\n",
      "Epoch [381/1000] completed, Average Training Loss: 0.1534\n",
      "    Validation Batch [1/1], Loss: 0.2233\n",
      "Validation Loss: 0.2233, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [382/1000] - Training\n",
      "Epoch [382/1000] completed, Average Training Loss: 0.1544\n",
      "    Validation Batch [1/1], Loss: 0.2088\n",
      "Validation Loss: 0.2088, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2206 to 0.2088. Saving model...\n",
      "\n",
      "LOG: Epoch [383/1000] - Training\n",
      "Epoch [383/1000] completed, Average Training Loss: 0.1620\n",
      "    Validation Batch [1/1], Loss: 0.2241\n",
      "Validation Loss: 0.2241, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [384/1000] - Training\n",
      "Epoch [384/1000] completed, Average Training Loss: 0.1522\n",
      "    Validation Batch [1/1], Loss: 0.2286\n",
      "Validation Loss: 0.2286, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [385/1000] - Training\n",
      "Epoch [385/1000] completed, Average Training Loss: 0.1579\n",
      "    Validation Batch [1/1], Loss: 0.2219\n",
      "Validation Loss: 0.2219, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [386/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [386/1000] completed, Average Training Loss: 0.1470\n",
      "    Validation Batch [1/1], Loss: 0.2220\n",
      "Validation Loss: 0.2220, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [387/1000] - Training\n",
      "Epoch [387/1000] completed, Average Training Loss: 0.1565\n",
      "    Validation Batch [1/1], Loss: 0.2495\n",
      "Validation Loss: 0.2495, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [388/1000] - Training\n",
      "Epoch [388/1000] completed, Average Training Loss: 0.1460\n",
      "    Validation Batch [1/1], Loss: 0.2538\n",
      "Validation Loss: 0.2538, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [389/1000] - Training\n",
      "Epoch [389/1000] completed, Average Training Loss: 0.1479\n",
      "    Validation Batch [1/1], Loss: 0.2359\n",
      "Validation Loss: 0.2359, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [390/1000] - Training\n",
      "Epoch [390/1000] completed, Average Training Loss: 0.1501\n",
      "    Validation Batch [1/1], Loss: 0.2707\n",
      "Validation Loss: 0.2707, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [391/1000] - Training\n",
      "Epoch [391/1000] completed, Average Training Loss: 0.1340\n",
      "    Validation Batch [1/1], Loss: 0.3209\n",
      "Validation Loss: 0.3209, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [392/1000] - Training\n",
      "Epoch [392/1000] completed, Average Training Loss: 0.1499\n",
      "    Validation Batch [1/1], Loss: 0.2955\n",
      "Validation Loss: 0.2955, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [393/1000] - Training\n",
      "Epoch [393/1000] completed, Average Training Loss: 0.1390\n",
      "    Validation Batch [1/1], Loss: 0.2802\n",
      "Validation Loss: 0.2802, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [394/1000] - Training\n",
      "Epoch [394/1000] completed, Average Training Loss: 0.1534\n",
      "    Validation Batch [1/1], Loss: 0.2299\n",
      "Validation Loss: 0.2299, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [395/1000] - Training\n",
      "Epoch [395/1000] completed, Average Training Loss: 0.1446\n",
      "    Validation Batch [1/1], Loss: 0.2061\n",
      "Validation Loss: 0.2061, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2088 to 0.2061. Saving model...\n",
      "\n",
      "LOG: Epoch [396/1000] - Training\n",
      "Epoch [396/1000] completed, Average Training Loss: 0.1561\n",
      "    Validation Batch [1/1], Loss: 0.2107\n",
      "Validation Loss: 0.2107, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [397/1000] - Training\n",
      "Epoch [397/1000] completed, Average Training Loss: 0.1493\n",
      "    Validation Batch [1/1], Loss: 0.2461\n",
      "Validation Loss: 0.2461, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [398/1000] - Training\n",
      "Epoch [398/1000] completed, Average Training Loss: 0.1368\n",
      "    Validation Batch [1/1], Loss: 0.2437\n",
      "Validation Loss: 0.2437, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [399/1000] - Training\n",
      "Epoch [399/1000] completed, Average Training Loss: 0.1336\n",
      "    Validation Batch [1/1], Loss: 0.2263\n",
      "Validation Loss: 0.2263, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [400/1000] - Training\n",
      "Epoch [400/1000] completed, Average Training Loss: 0.1435\n",
      "    Validation Batch [1/1], Loss: 0.2246\n",
      "Validation Loss: 0.2246, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [401/1000] - Training\n",
      "Epoch [401/1000] completed, Average Training Loss: 0.1337\n",
      "    Validation Batch [1/1], Loss: 0.2396\n",
      "Validation Loss: 0.2396, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [402/1000] - Training\n",
      "Epoch [402/1000] completed, Average Training Loss: 0.1371\n",
      "    Validation Batch [1/1], Loss: 0.2505\n",
      "Validation Loss: 0.2505, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [403/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [403/1000] completed, Average Training Loss: 0.1418\n",
      "    Validation Batch [1/1], Loss: 0.2627\n",
      "Validation Loss: 0.2627, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [404/1000] - Training\n",
      "Epoch [404/1000] completed, Average Training Loss: 0.1377\n",
      "    Validation Batch [1/1], Loss: 0.2569\n",
      "Validation Loss: 0.2569, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [405/1000] - Training\n",
      "Epoch [405/1000] completed, Average Training Loss: 0.1191\n",
      "    Validation Batch [1/1], Loss: 0.2198\n",
      "Validation Loss: 0.2198, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [406/1000] - Training\n",
      "Epoch [406/1000] completed, Average Training Loss: 0.1358\n",
      "    Validation Batch [1/1], Loss: 0.1946\n",
      "Validation Loss: 0.1946, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2061 to 0.1946. Saving model...\n",
      "\n",
      "LOG: Epoch [407/1000] - Training\n",
      "Epoch [407/1000] completed, Average Training Loss: 0.1150\n",
      "    Validation Batch [1/1], Loss: 0.1872\n",
      "Validation Loss: 0.1872, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1946 to 0.1872. Saving model...\n",
      "\n",
      "LOG: Epoch [408/1000] - Training\n",
      "Epoch [408/1000] completed, Average Training Loss: 0.1405\n",
      "    Validation Batch [1/1], Loss: 0.2106\n",
      "Validation Loss: 0.2106, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [409/1000] - Training\n",
      "Epoch [409/1000] completed, Average Training Loss: 0.1327\n",
      "    Validation Batch [1/1], Loss: 0.2685\n",
      "Validation Loss: 0.2685, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [410/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [410/1000] completed, Average Training Loss: 0.1397\n",
      "    Validation Batch [1/1], Loss: 0.2553\n",
      "Validation Loss: 0.2553, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [411/1000] - Training\n",
      "Epoch [411/1000] completed, Average Training Loss: 0.1267\n",
      "    Validation Batch [1/1], Loss: 0.2268\n",
      "Validation Loss: 0.2268, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [412/1000] - Training\n",
      "Epoch [412/1000] completed, Average Training Loss: 0.1233\n",
      "    Validation Batch [1/1], Loss: 0.2111\n",
      "Validation Loss: 0.2111, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [413/1000] - Training\n",
      "Epoch [413/1000] completed, Average Training Loss: 0.1312\n",
      "    Validation Batch [1/1], Loss: 0.2288\n",
      "Validation Loss: 0.2288, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [414/1000] - Training\n",
      "Epoch [414/1000] completed, Average Training Loss: 0.1216\n",
      "    Validation Batch [1/1], Loss: 0.3170\n",
      "Validation Loss: 0.3170, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [415/1000] - Training\n",
      "Epoch [415/1000] completed, Average Training Loss: 0.1215\n",
      "    Validation Batch [1/1], Loss: 0.3601\n",
      "Validation Loss: 0.3601, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [416/1000] - Training\n",
      "Epoch [416/1000] completed, Average Training Loss: 0.1208\n",
      "    Validation Batch [1/1], Loss: 0.2662\n",
      "Validation Loss: 0.2662, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [417/1000] - Training\n",
      "Epoch [417/1000] completed, Average Training Loss: 0.1270\n",
      "    Validation Batch [1/1], Loss: 0.2035\n",
      "Validation Loss: 0.2035, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [418/1000] - Training\n",
      "Epoch [418/1000] completed, Average Training Loss: 0.1182\n",
      "    Validation Batch [1/1], Loss: 0.1902\n",
      "Validation Loss: 0.1902, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [419/1000] - Training\n",
      "Epoch [419/1000] completed, Average Training Loss: 0.1184\n",
      "    Validation Batch [1/1], Loss: 0.1829\n",
      "Validation Loss: 0.1829, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1872 to 0.1829. Saving model...\n",
      "\n",
      "LOG: Epoch [420/1000] - Training\n",
      "Epoch [420/1000] completed, Average Training Loss: 0.1180\n",
      "    Validation Batch [1/1], Loss: 0.2058\n",
      "Validation Loss: 0.2058, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [421/1000] - Training\n",
      "Epoch [421/1000] completed, Average Training Loss: 0.1075\n",
      "    Validation Batch [1/1], Loss: 0.2372\n",
      "Validation Loss: 0.2372, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [422/1000] - Training\n",
      "Epoch [422/1000] completed, Average Training Loss: 0.1194\n",
      "    Validation Batch [1/1], Loss: 0.2040\n",
      "Validation Loss: 0.2040, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [423/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [423/1000] completed, Average Training Loss: 0.1276\n",
      "    Validation Batch [1/1], Loss: 0.1921\n",
      "Validation Loss: 0.1921, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [424/1000] - Training\n",
      "Epoch [424/1000] completed, Average Training Loss: 0.1206\n",
      "    Validation Batch [1/1], Loss: 0.1924\n",
      "Validation Loss: 0.1924, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [425/1000] - Training\n",
      "Epoch [425/1000] completed, Average Training Loss: 0.1121\n",
      "    Validation Batch [1/1], Loss: 0.2222\n",
      "Validation Loss: 0.2222, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [426/1000] - Training\n",
      "Epoch [426/1000] completed, Average Training Loss: 0.1044\n",
      "    Validation Batch [1/1], Loss: 0.2745\n",
      "Validation Loss: 0.2745, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [427/1000] - Training\n",
      "Epoch [427/1000] completed, Average Training Loss: 0.1126\n",
      "    Validation Batch [1/1], Loss: 0.2493\n",
      "Validation Loss: 0.2493, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [428/1000] - Training\n",
      "Epoch [428/1000] completed, Average Training Loss: 0.1113\n",
      "    Validation Batch [1/1], Loss: 0.2039\n",
      "Validation Loss: 0.2039, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [429/1000] - Training\n",
      "Epoch [429/1000] completed, Average Training Loss: 0.1100\n",
      "    Validation Batch [1/1], Loss: 0.2061\n",
      "Validation Loss: 0.2061, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [430/1000] - Training\n",
      "Epoch [430/1000] completed, Average Training Loss: 0.1151\n",
      "    Validation Batch [1/1], Loss: 0.2417\n",
      "Validation Loss: 0.2417, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [431/1000] - Training\n",
      "Epoch [431/1000] completed, Average Training Loss: 0.0965\n",
      "    Validation Batch [1/1], Loss: 0.3050\n",
      "Validation Loss: 0.3050, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [432/1000] - Training\n",
      "Epoch [432/1000] completed, Average Training Loss: 0.1172\n",
      "    Validation Batch [1/1], Loss: 0.3207\n",
      "Validation Loss: 0.3207, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [433/1000] - Training\n",
      "Epoch [433/1000] completed, Average Training Loss: 0.1066\n",
      "    Validation Batch [1/1], Loss: 0.2467\n",
      "Validation Loss: 0.2467, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [434/1000] - Training\n",
      "Epoch [434/1000] completed, Average Training Loss: 0.0963\n",
      "    Validation Batch [1/1], Loss: 0.1997\n",
      "Validation Loss: 0.1997, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [435/1000] - Training\n",
      "Epoch [435/1000] completed, Average Training Loss: 0.1185\n",
      "    Validation Batch [1/1], Loss: 0.1733\n",
      "Validation Loss: 0.1733, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1829 to 0.1733. Saving model...\n",
      "\n",
      "LOG: Epoch [436/1000] - Training\n",
      "Epoch [436/1000] completed, Average Training Loss: 0.1019\n",
      "    Validation Batch [1/1], Loss: 0.1639\n",
      "Validation Loss: 0.1639, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1733 to 0.1639. Saving model...\n",
      "\n",
      "LOG: Epoch [437/1000] - Training\n",
      "Epoch [437/1000] completed, Average Training Loss: 0.1200\n",
      "    Validation Batch [1/1], Loss: 0.1866\n",
      "Validation Loss: 0.1866, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [438/1000] - Training\n",
      "Epoch [438/1000] completed, Average Training Loss: 0.1026\n",
      "    Validation Batch [1/1], Loss: 0.2027\n",
      "Validation Loss: 0.2027, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [439/1000] - Training\n",
      "Epoch [439/1000] completed, Average Training Loss: 0.1014\n",
      "    Validation Batch [1/1], Loss: 0.2045\n",
      "Validation Loss: 0.2045, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [440/1000] - Training\n",
      "Epoch [440/1000] completed, Average Training Loss: 0.1047\n",
      "    Validation Batch [1/1], Loss: 0.2225\n",
      "Validation Loss: 0.2225, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [441/1000] - Training\n",
      "Epoch [441/1000] completed, Average Training Loss: 0.0996\n",
      "    Validation Batch [1/1], Loss: 0.2188\n",
      "Validation Loss: 0.2188, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [442/1000] - Training\n",
      "Epoch [442/1000] completed, Average Training Loss: 0.1002\n",
      "    Validation Batch [1/1], Loss: 0.2148\n",
      "Validation Loss: 0.2148, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [443/1000] - Training\n",
      "Epoch [443/1000] completed, Average Training Loss: 0.0940\n",
      "    Validation Batch [1/1], Loss: 0.2312\n",
      "Validation Loss: 0.2312, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [444/1000] - Training\n",
      "Epoch [444/1000] completed, Average Training Loss: 0.1025\n",
      "    Validation Batch [1/1], Loss: 0.2115\n",
      "Validation Loss: 0.2115, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [445/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [445/1000] completed, Average Training Loss: 0.1137\n",
      "    Validation Batch [1/1], Loss: 0.1954\n",
      "Validation Loss: 0.1954, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [446/1000] - Training\n",
      "Epoch [446/1000] completed, Average Training Loss: 0.0868\n",
      "    Validation Batch [1/1], Loss: 0.2024\n",
      "Validation Loss: 0.2024, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [447/1000] - Training\n",
      "Epoch [447/1000] completed, Average Training Loss: 0.0950\n",
      "    Validation Batch [1/1], Loss: 0.2140\n",
      "Validation Loss: 0.2140, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [448/1000] - Training\n",
      "Epoch [448/1000] completed, Average Training Loss: 0.1046\n",
      "    Validation Batch [1/1], Loss: 0.2165\n",
      "Validation Loss: 0.2165, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [449/1000] - Training\n",
      "Epoch [449/1000] completed, Average Training Loss: 0.0986\n",
      "    Validation Batch [1/1], Loss: 0.2093\n",
      "Validation Loss: 0.2093, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [450/1000] - Training\n",
      "Epoch [450/1000] completed, Average Training Loss: 0.1048\n",
      "    Validation Batch [1/1], Loss: 0.1927\n",
      "Validation Loss: 0.1927, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [451/1000] - Training\n",
      "Epoch [451/1000] completed, Average Training Loss: 0.0929\n",
      "    Validation Batch [1/1], Loss: 0.1875\n",
      "Validation Loss: 0.1875, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [452/1000] - Training\n",
      "Epoch [452/1000] completed, Average Training Loss: 0.1003\n",
      "    Validation Batch [1/1], Loss: 0.1951\n",
      "Validation Loss: 0.1951, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [453/1000] - Training\n",
      "Epoch [453/1000] completed, Average Training Loss: 0.0837\n",
      "    Validation Batch [1/1], Loss: 0.1871\n",
      "Validation Loss: 0.1871, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [454/1000] - Training\n",
      "Epoch [454/1000] completed, Average Training Loss: 0.1042\n",
      "    Validation Batch [1/1], Loss: 0.2006\n",
      "Validation Loss: 0.2006, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [455/1000] - Training\n",
      "Epoch [455/1000] completed, Average Training Loss: 0.0908\n",
      "    Validation Batch [1/1], Loss: 0.2080\n",
      "Validation Loss: 0.2080, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [456/1000] - Training\n",
      "Epoch [456/1000] completed, Average Training Loss: 0.0910\n",
      "    Validation Batch [1/1], Loss: 0.2122\n",
      "Validation Loss: 0.2122, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [457/1000] - Training\n",
      "Epoch [457/1000] completed, Average Training Loss: 0.0928\n",
      "    Validation Batch [1/1], Loss: 0.2013\n",
      "Validation Loss: 0.2013, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [458/1000] - Training\n",
      "Epoch [458/1000] completed, Average Training Loss: 0.0872\n",
      "    Validation Batch [1/1], Loss: 0.1865\n",
      "Validation Loss: 0.1865, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [459/1000] - Training\n",
      "Epoch [459/1000] completed, Average Training Loss: 0.0789\n",
      "    Validation Batch [1/1], Loss: 0.1798\n",
      "Validation Loss: 0.1798, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [460/1000] - Training\n",
      "Epoch [460/1000] completed, Average Training Loss: 0.0875\n",
      "    Validation Batch [1/1], Loss: 0.1764\n",
      "Validation Loss: 0.1764, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [461/1000] - Training\n",
      "Epoch [461/1000] completed, Average Training Loss: 0.1072\n",
      "    Validation Batch [1/1], Loss: 0.1872\n",
      "Validation Loss: 0.1872, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [462/1000] - Training\n",
      "Epoch [462/1000] completed, Average Training Loss: 0.0825\n",
      "    Validation Batch [1/1], Loss: 0.2056\n",
      "Validation Loss: 0.2056, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [463/1000] - Training\n",
      "Epoch [463/1000] completed, Average Training Loss: 0.0952\n",
      "    Validation Batch [1/1], Loss: 0.2320\n",
      "Validation Loss: 0.2320, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [464/1000] - Training\n",
      "Epoch [464/1000] completed, Average Training Loss: 0.0988\n",
      "    Validation Batch [1/1], Loss: 0.2242\n",
      "Validation Loss: 0.2242, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [465/1000] - Training\n",
      "Epoch [465/1000] completed, Average Training Loss: 0.0992\n",
      "    Validation Batch [1/1], Loss: 0.1951\n",
      "Validation Loss: 0.1951, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [466/1000] - Training\n",
      "Epoch [466/1000] completed, Average Training Loss: 0.0973\n",
      "    Validation Batch [1/1], Loss: 0.1770\n",
      "Validation Loss: 0.1770, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [467/1000] - Training\n",
      "Epoch [467/1000] completed, Average Training Loss: 0.1028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1772\n",
      "Validation Loss: 0.1772, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [468/1000] - Training\n",
      "Epoch [468/1000] completed, Average Training Loss: 0.0867\n",
      "    Validation Batch [1/1], Loss: 0.2037\n",
      "Validation Loss: 0.2037, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [469/1000] - Training\n",
      "Epoch [469/1000] completed, Average Training Loss: 0.1055\n",
      "    Validation Batch [1/1], Loss: 0.2324\n",
      "Validation Loss: 0.2324, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [470/1000] - Training\n",
      "Epoch [470/1000] completed, Average Training Loss: 0.0855\n",
      "    Validation Batch [1/1], Loss: 0.2057\n",
      "Validation Loss: 0.2057, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [471/1000] - Training\n",
      "Epoch [471/1000] completed, Average Training Loss: 0.0827\n",
      "    Validation Batch [1/1], Loss: 0.1972\n",
      "Validation Loss: 0.1972, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [472/1000] - Training\n",
      "Epoch [472/1000] completed, Average Training Loss: 0.0909\n",
      "    Validation Batch [1/1], Loss: 0.1765\n",
      "Validation Loss: 0.1765, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [473/1000] - Training\n",
      "Epoch [473/1000] completed, Average Training Loss: 0.0921\n",
      "    Validation Batch [1/1], Loss: 0.1696\n",
      "Validation Loss: 0.1696, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [474/1000] - Training\n",
      "Epoch [474/1000] completed, Average Training Loss: 0.0861\n",
      "    Validation Batch [1/1], Loss: 0.1924\n",
      "Validation Loss: 0.1924, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [475/1000] - Training\n",
      "Epoch [475/1000] completed, Average Training Loss: 0.0932\n",
      "    Validation Batch [1/1], Loss: 0.2250\n",
      "Validation Loss: 0.2250, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [476/1000] - Training\n",
      "Epoch [476/1000] completed, Average Training Loss: 0.0930\n",
      "    Validation Batch [1/1], Loss: 0.2541\n",
      "Validation Loss: 0.2541, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [477/1000] - Training\n",
      "Epoch [477/1000] completed, Average Training Loss: 0.0884\n",
      "    Validation Batch [1/1], Loss: 0.2399\n",
      "Validation Loss: 0.2399, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [478/1000] - Training\n",
      "Epoch [478/1000] completed, Average Training Loss: 0.0873\n",
      "    Validation Batch [1/1], Loss: 0.1870\n",
      "Validation Loss: 0.1870, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [479/1000] - Training\n",
      "Epoch [479/1000] completed, Average Training Loss: 0.0789\n",
      "    Validation Batch [1/1], Loss: 0.1594\n",
      "Validation Loss: 0.1594, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.1639 to 0.1594. Saving model...\n",
      "\n",
      "LOG: Epoch [480/1000] - Training\n",
      "Epoch [480/1000] completed, Average Training Loss: 0.0823\n",
      "    Validation Batch [1/1], Loss: 0.1560\n",
      "Validation Loss: 0.1560, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.1594 to 0.1560. Saving model...\n",
      "\n",
      "LOG: Epoch [481/1000] - Training\n",
      "Epoch [481/1000] completed, Average Training Loss: 0.0764\n",
      "    Validation Batch [1/1], Loss: 0.1623\n",
      "Validation Loss: 0.1623, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [482/1000] - Training\n",
      "Epoch [482/1000] completed, Average Training Loss: 0.0841\n",
      "    Validation Batch [1/1], Loss: 0.1800\n",
      "Validation Loss: 0.1800, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [483/1000] - Training\n",
      "Epoch [483/1000] completed, Average Training Loss: 0.0727\n",
      "    Validation Batch [1/1], Loss: 0.1891\n",
      "Validation Loss: 0.1891, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [484/1000] - Training\n",
      "Epoch [484/1000] completed, Average Training Loss: 0.0846\n",
      "    Validation Batch [1/1], Loss: 0.2006\n",
      "Validation Loss: 0.2006, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [485/1000] - Training\n",
      "Epoch [485/1000] completed, Average Training Loss: 0.0920\n",
      "    Validation Batch [1/1], Loss: 0.1907\n",
      "Validation Loss: 0.1907, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [486/1000] - Training\n",
      "Epoch [486/1000] completed, Average Training Loss: 0.0867\n",
      "    Validation Batch [1/1], Loss: 0.1654\n",
      "Validation Loss: 0.1654, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [487/1000] - Training\n",
      "Epoch [487/1000] completed, Average Training Loss: 0.0709\n",
      "    Validation Batch [1/1], Loss: 0.1497\n",
      "Validation Loss: 0.1497, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1560 to 0.1497. Saving model...\n",
      "\n",
      "LOG: Epoch [488/1000] - Training\n",
      "Epoch [488/1000] completed, Average Training Loss: 0.0695\n",
      "    Validation Batch [1/1], Loss: 0.1477\n",
      "Validation Loss: 0.1477, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1497 to 0.1477. Saving model...\n",
      "\n",
      "LOG: Epoch [489/1000] - Training\n",
      "Epoch [489/1000] completed, Average Training Loss: 0.0764\n",
      "    Validation Batch [1/1], Loss: 0.1725\n",
      "Validation Loss: 0.1725, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [490/1000] - Training\n",
      "Epoch [490/1000] completed, Average Training Loss: 0.0776\n",
      "    Validation Batch [1/1], Loss: 0.2092\n",
      "Validation Loss: 0.2092, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [491/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [491/1000] completed, Average Training Loss: 0.0698\n",
      "    Validation Batch [1/1], Loss: 0.2312\n",
      "Validation Loss: 0.2312, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [492/1000] - Training\n",
      "Epoch [492/1000] completed, Average Training Loss: 0.0766\n",
      "    Validation Batch [1/1], Loss: 0.2062\n",
      "Validation Loss: 0.2062, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [493/1000] - Training\n",
      "Epoch [493/1000] completed, Average Training Loss: 0.0781\n",
      "    Validation Batch [1/1], Loss: 0.1948\n",
      "Validation Loss: 0.1948, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [494/1000] - Training\n",
      "Epoch [494/1000] completed, Average Training Loss: 0.0721\n",
      "    Validation Batch [1/1], Loss: 0.1800\n",
      "Validation Loss: 0.1800, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [495/1000] - Training\n",
      "Epoch [495/1000] completed, Average Training Loss: 0.0653\n",
      "    Validation Batch [1/1], Loss: 0.1674\n",
      "Validation Loss: 0.1674, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [496/1000] - Training\n",
      "Epoch [496/1000] completed, Average Training Loss: 0.0785\n",
      "    Validation Batch [1/1], Loss: 0.1540\n",
      "Validation Loss: 0.1540, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [497/1000] - Training\n",
      "Epoch [497/1000] completed, Average Training Loss: 0.0717\n",
      "    Validation Batch [1/1], Loss: 0.1495\n",
      "Validation Loss: 0.1495, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [498/1000] - Training\n",
      "Epoch [498/1000] completed, Average Training Loss: 0.0772\n",
      "    Validation Batch [1/1], Loss: 0.1503\n",
      "Validation Loss: 0.1503, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [499/1000] - Training\n",
      "Epoch [499/1000] completed, Average Training Loss: 0.0706\n",
      "    Validation Batch [1/1], Loss: 0.1636\n",
      "Validation Loss: 0.1636, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [500/1000] - Training\n",
      "Epoch [500/1000] completed, Average Training Loss: 0.0662\n",
      "    Validation Batch [1/1], Loss: 0.1825\n",
      "Validation Loss: 0.1825, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [501/1000] - Training\n",
      "Epoch [501/1000] completed, Average Training Loss: 0.0761\n",
      "    Validation Batch [1/1], Loss: 0.1912\n",
      "Validation Loss: 0.1912, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [502/1000] - Training\n",
      "Epoch [502/1000] completed, Average Training Loss: 0.0806\n",
      "    Validation Batch [1/1], Loss: 0.1689\n",
      "Validation Loss: 0.1689, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [503/1000] - Training\n",
      "Epoch [503/1000] completed, Average Training Loss: 0.0710\n",
      "    Validation Batch [1/1], Loss: 0.1428\n",
      "Validation Loss: 0.1428, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1477 to 0.1428. Saving model...\n",
      "\n",
      "LOG: Epoch [504/1000] - Training\n",
      "Epoch [504/1000] completed, Average Training Loss: 0.0688\n",
      "    Validation Batch [1/1], Loss: 0.1321\n",
      "Validation Loss: 0.1321, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1428 to 0.1321. Saving model...\n",
      "\n",
      "LOG: Epoch [505/1000] - Training\n",
      "Epoch [505/1000] completed, Average Training Loss: 0.0730\n",
      "    Validation Batch [1/1], Loss: 0.1381\n",
      "Validation Loss: 0.1381, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [506/1000] - Training\n",
      "Epoch [506/1000] completed, Average Training Loss: 0.0770\n",
      "    Validation Batch [1/1], Loss: 0.1417\n",
      "Validation Loss: 0.1417, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [507/1000] - Training\n",
      "Epoch [507/1000] completed, Average Training Loss: 0.0639\n",
      "    Validation Batch [1/1], Loss: 0.1514\n",
      "Validation Loss: 0.1514, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [508/1000] - Training\n",
      "Epoch [508/1000] completed, Average Training Loss: 0.0680\n",
      "    Validation Batch [1/1], Loss: 0.1608\n",
      "Validation Loss: 0.1608, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [509/1000] - Training\n",
      "Epoch [509/1000] completed, Average Training Loss: 0.0664\n",
      "    Validation Batch [1/1], Loss: 0.1701\n",
      "Validation Loss: 0.1701, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [510/1000] - Training\n",
      "Epoch [510/1000] completed, Average Training Loss: 0.0743\n",
      "    Validation Batch [1/1], Loss: 0.1579\n",
      "Validation Loss: 0.1579, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [511/1000] - Training\n",
      "Epoch [511/1000] completed, Average Training Loss: 0.0670\n",
      "    Validation Batch [1/1], Loss: 0.1571\n",
      "Validation Loss: 0.1571, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [512/1000] - Training\n",
      "Epoch [512/1000] completed, Average Training Loss: 0.0742\n",
      "    Validation Batch [1/1], Loss: 0.1659\n",
      "Validation Loss: 0.1659, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [513/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [513/1000] completed, Average Training Loss: 0.0730\n",
      "    Validation Batch [1/1], Loss: 0.1736\n",
      "Validation Loss: 0.1736, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [514/1000] - Training\n",
      "Epoch [514/1000] completed, Average Training Loss: 0.0659\n",
      "    Validation Batch [1/1], Loss: 0.1914\n",
      "Validation Loss: 0.1914, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [515/1000] - Training\n",
      "Epoch [515/1000] completed, Average Training Loss: 0.0612\n",
      "    Validation Batch [1/1], Loss: 0.1980\n",
      "Validation Loss: 0.1980, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [516/1000] - Training\n",
      "Epoch [516/1000] completed, Average Training Loss: 0.0597\n",
      "    Validation Batch [1/1], Loss: 0.1878\n",
      "Validation Loss: 0.1878, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [517/1000] - Training\n",
      "Epoch [517/1000] completed, Average Training Loss: 0.0654\n",
      "    Validation Batch [1/1], Loss: 0.1553\n",
      "Validation Loss: 0.1553, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [518/1000] - Training\n",
      "Epoch [518/1000] completed, Average Training Loss: 0.0562\n",
      "    Validation Batch [1/1], Loss: 0.1349\n",
      "Validation Loss: 0.1349, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [519/1000] - Training\n",
      "Epoch [519/1000] completed, Average Training Loss: 0.0621\n",
      "    Validation Batch [1/1], Loss: 0.1331\n",
      "Validation Loss: 0.1331, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [520/1000] - Training\n",
      "Epoch [520/1000] completed, Average Training Loss: 0.0631\n",
      "    Validation Batch [1/1], Loss: 0.1377\n",
      "Validation Loss: 0.1377, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [521/1000] - Training\n",
      "Epoch [521/1000] completed, Average Training Loss: 0.0591\n",
      "    Validation Batch [1/1], Loss: 0.1625\n",
      "Validation Loss: 0.1625, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [522/1000] - Training\n",
      "Epoch [522/1000] completed, Average Training Loss: 0.0613\n",
      "    Validation Batch [1/1], Loss: 0.1947\n",
      "Validation Loss: 0.1947, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [523/1000] - Training\n",
      "Epoch [523/1000] completed, Average Training Loss: 0.0662\n",
      "    Validation Batch [1/1], Loss: 0.2096\n",
      "Validation Loss: 0.2096, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [524/1000] - Training\n",
      "Epoch [524/1000] completed, Average Training Loss: 0.0505\n",
      "    Validation Batch [1/1], Loss: 0.2098\n",
      "Validation Loss: 0.2098, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [525/1000] - Training\n",
      "Epoch [525/1000] completed, Average Training Loss: 0.0654\n",
      "    Validation Batch [1/1], Loss: 0.1808\n",
      "Validation Loss: 0.1808, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [526/1000] - Training\n",
      "Epoch [526/1000] completed, Average Training Loss: 0.0641\n",
      "    Validation Batch [1/1], Loss: 0.1456\n",
      "Validation Loss: 0.1456, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [527/1000] - Training\n",
      "Epoch [527/1000] completed, Average Training Loss: 0.0652\n",
      "    Validation Batch [1/1], Loss: 0.1213\n",
      "Validation Loss: 0.1213, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1321 to 0.1213. Saving model...\n",
      "\n",
      "LOG: Epoch [528/1000] - Training\n",
      "Epoch [528/1000] completed, Average Training Loss: 0.0612\n",
      "    Validation Batch [1/1], Loss: 0.1207\n",
      "Validation Loss: 0.1207, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1213 to 0.1207. Saving model...\n",
      "\n",
      "LOG: Epoch [529/1000] - Training\n",
      "Epoch [529/1000] completed, Average Training Loss: 0.0585\n",
      "    Validation Batch [1/1], Loss: 0.1411\n",
      "Validation Loss: 0.1411, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [530/1000] - Training\n",
      "Epoch [530/1000] completed, Average Training Loss: 0.0674\n",
      "    Validation Batch [1/1], Loss: 0.1918\n",
      "Validation Loss: 0.1918, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [531/1000] - Training\n",
      "Epoch [531/1000] completed, Average Training Loss: 0.0607\n",
      "    Validation Batch [1/1], Loss: 0.2516\n",
      "Validation Loss: 0.2516, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [532/1000] - Training\n",
      "Epoch [532/1000] completed, Average Training Loss: 0.0533\n",
      "    Validation Batch [1/1], Loss: 0.2699\n",
      "Validation Loss: 0.2699, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [533/1000] - Training\n",
      "Epoch [533/1000] completed, Average Training Loss: 0.0642\n",
      "    Validation Batch [1/1], Loss: 0.2230\n",
      "Validation Loss: 0.2230, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [534/1000] - Training\n",
      "Epoch [534/1000] completed, Average Training Loss: 0.0618\n",
      "    Validation Batch [1/1], Loss: 0.1584\n",
      "Validation Loss: 0.1584, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [535/1000] - Training\n",
      "Epoch [535/1000] completed, Average Training Loss: 0.0707\n",
      "    Validation Batch [1/1], Loss: 0.1211\n",
      "Validation Loss: 0.1211, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [536/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [536/1000] completed, Average Training Loss: 0.0561\n",
      "    Validation Batch [1/1], Loss: 0.1098\n",
      "Validation Loss: 0.1098, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1207 to 0.1098. Saving model...\n",
      "\n",
      "LOG: Epoch [537/1000] - Training\n",
      "Epoch [537/1000] completed, Average Training Loss: 0.0586\n",
      "    Validation Batch [1/1], Loss: 0.1157\n",
      "Validation Loss: 0.1157, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [538/1000] - Training\n",
      "Epoch [538/1000] completed, Average Training Loss: 0.0635\n",
      "    Validation Batch [1/1], Loss: 0.1566\n",
      "Validation Loss: 0.1566, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [539/1000] - Training\n",
      "Epoch [539/1000] completed, Average Training Loss: 0.0582\n",
      "    Validation Batch [1/1], Loss: 0.2073\n",
      "Validation Loss: 0.2073, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [540/1000] - Training\n",
      "Epoch [540/1000] completed, Average Training Loss: 0.0596\n",
      "    Validation Batch [1/1], Loss: 0.2417\n",
      "Validation Loss: 0.2417, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [541/1000] - Training\n",
      "Epoch [541/1000] completed, Average Training Loss: 0.0550\n",
      "    Validation Batch [1/1], Loss: 0.2067\n",
      "Validation Loss: 0.2067, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [542/1000] - Training\n",
      "Epoch [542/1000] completed, Average Training Loss: 0.0528\n",
      "    Validation Batch [1/1], Loss: 0.1851\n",
      "Validation Loss: 0.1851, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [543/1000] - Training\n",
      "Epoch [543/1000] completed, Average Training Loss: 0.0572\n",
      "    Validation Batch [1/1], Loss: 0.1622\n",
      "Validation Loss: 0.1622, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [544/1000] - Training\n",
      "Epoch [544/1000] completed, Average Training Loss: 0.0711\n",
      "    Validation Batch [1/1], Loss: 0.1504\n",
      "Validation Loss: 0.1504, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [545/1000] - Training\n",
      "Epoch [545/1000] completed, Average Training Loss: 0.0682\n",
      "    Validation Batch [1/1], Loss: 0.1486\n",
      "Validation Loss: 0.1486, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [546/1000] - Training\n",
      "Epoch [546/1000] completed, Average Training Loss: 0.0707\n",
      "    Validation Batch [1/1], Loss: 0.1880\n",
      "Validation Loss: 0.1880, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [547/1000] - Training\n",
      "Epoch [547/1000] completed, Average Training Loss: 0.0593\n",
      "    Validation Batch [1/1], Loss: 0.1879\n",
      "Validation Loss: 0.1879, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [548/1000] - Training\n",
      "Epoch [548/1000] completed, Average Training Loss: 0.0615\n",
      "    Validation Batch [1/1], Loss: 0.1543\n",
      "Validation Loss: 0.1543, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [549/1000] - Training\n",
      "Epoch [549/1000] completed, Average Training Loss: 0.0609\n",
      "    Validation Batch [1/1], Loss: 0.1384\n",
      "Validation Loss: 0.1384, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [550/1000] - Training\n",
      "Epoch [550/1000] completed, Average Training Loss: 0.0538\n",
      "    Validation Batch [1/1], Loss: 0.1396\n",
      "Validation Loss: 0.1396, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [551/1000] - Training\n",
      "Epoch [551/1000] completed, Average Training Loss: 0.0626\n",
      "    Validation Batch [1/1], Loss: 0.1629\n",
      "Validation Loss: 0.1629, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [552/1000] - Training\n",
      "Epoch [552/1000] completed, Average Training Loss: 0.0597\n",
      "    Validation Batch [1/1], Loss: 0.2397\n",
      "Validation Loss: 0.2397, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [553/1000] - Training\n",
      "Epoch [553/1000] completed, Average Training Loss: 0.0633\n",
      "    Validation Batch [1/1], Loss: 0.2720\n",
      "Validation Loss: 0.2720, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [554/1000] - Training\n",
      "Epoch [554/1000] completed, Average Training Loss: 0.0488\n",
      "    Validation Batch [1/1], Loss: 0.2570\n",
      "Validation Loss: 0.2570, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [555/1000] - Training\n",
      "Epoch [555/1000] completed, Average Training Loss: 0.0543\n",
      "    Validation Batch [1/1], Loss: 0.1882\n",
      "Validation Loss: 0.1882, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [556/1000] - Training\n",
      "Epoch [556/1000] completed, Average Training Loss: 0.0532\n",
      "    Validation Batch [1/1], Loss: 0.1597\n",
      "Validation Loss: 0.1597, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [557/1000] - Training\n",
      "Epoch [557/1000] completed, Average Training Loss: 0.0579\n",
      "    Validation Batch [1/1], Loss: 0.1467\n",
      "Validation Loss: 0.1467, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [558/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [558/1000] completed, Average Training Loss: 0.0636\n",
      "    Validation Batch [1/1], Loss: 0.1422\n",
      "Validation Loss: 0.1422, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [559/1000] - Training\n",
      "Epoch [559/1000] completed, Average Training Loss: 0.0507\n",
      "    Validation Batch [1/1], Loss: 0.1451\n",
      "Validation Loss: 0.1451, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [560/1000] - Training\n",
      "Epoch [560/1000] completed, Average Training Loss: 0.0702\n",
      "    Validation Batch [1/1], Loss: 0.1684\n",
      "Validation Loss: 0.1684, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [561/1000] - Training\n",
      "Epoch [561/1000] completed, Average Training Loss: 0.0610\n",
      "    Validation Batch [1/1], Loss: 0.1560\n",
      "Validation Loss: 0.1560, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [562/1000] - Training\n",
      "Epoch [562/1000] completed, Average Training Loss: 0.0526\n",
      "    Validation Batch [1/1], Loss: 0.1588\n",
      "Validation Loss: 0.1588, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [563/1000] - Training\n",
      "Epoch [563/1000] completed, Average Training Loss: 0.0580\n",
      "    Validation Batch [1/1], Loss: 0.1779\n",
      "Validation Loss: 0.1779, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [564/1000] - Training\n",
      "Epoch [564/1000] completed, Average Training Loss: 0.0573\n",
      "    Validation Batch [1/1], Loss: 0.2068\n",
      "Validation Loss: 0.2068, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [565/1000] - Training\n",
      "Epoch [565/1000] completed, Average Training Loss: 0.0527\n",
      "    Validation Batch [1/1], Loss: 0.2200\n",
      "Validation Loss: 0.2200, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [566/1000] - Training\n",
      "Epoch [566/1000] completed, Average Training Loss: 0.0541\n",
      "    Validation Batch [1/1], Loss: 0.2317\n",
      "Validation Loss: 0.2317, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [567/1000] - Training\n",
      "Epoch [567/1000] completed, Average Training Loss: 0.0404\n",
      "    Validation Batch [1/1], Loss: 0.2249\n",
      "Validation Loss: 0.2249, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [568/1000] - Training\n",
      "Epoch [568/1000] completed, Average Training Loss: 0.0533\n",
      "    Validation Batch [1/1], Loss: 0.2131\n",
      "Validation Loss: 0.2131, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [569/1000] - Training\n",
      "Epoch [569/1000] completed, Average Training Loss: 0.0471\n",
      "    Validation Batch [1/1], Loss: 0.1756\n",
      "Validation Loss: 0.1756, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [570/1000] - Training\n",
      "Epoch [570/1000] completed, Average Training Loss: 0.0509\n",
      "    Validation Batch [1/1], Loss: 0.1489\n",
      "Validation Loss: 0.1489, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [571/1000] - Training\n",
      "Epoch [571/1000] completed, Average Training Loss: 0.0480\n",
      "    Validation Batch [1/1], Loss: 0.1333\n",
      "Validation Loss: 0.1333, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [572/1000] - Training\n",
      "Epoch [572/1000] completed, Average Training Loss: 0.0433\n",
      "    Validation Batch [1/1], Loss: 0.1380\n",
      "Validation Loss: 0.1380, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [573/1000] - Training\n",
      "Epoch [573/1000] completed, Average Training Loss: 0.0538\n",
      "    Validation Batch [1/1], Loss: 0.1470\n",
      "Validation Loss: 0.1470, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [574/1000] - Training\n",
      "Epoch [574/1000] completed, Average Training Loss: 0.0475\n",
      "    Validation Batch [1/1], Loss: 0.1528\n",
      "Validation Loss: 0.1528, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [575/1000] - Training\n",
      "Epoch [575/1000] completed, Average Training Loss: 0.0550\n",
      "    Validation Batch [1/1], Loss: 0.1551\n",
      "Validation Loss: 0.1551, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [576/1000] - Training\n",
      "Epoch [576/1000] completed, Average Training Loss: 0.0593\n",
      "    Validation Batch [1/1], Loss: 0.1696\n",
      "Validation Loss: 0.1696, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [577/1000] - Training\n",
      "Epoch [577/1000] completed, Average Training Loss: 0.0454\n",
      "    Validation Batch [1/1], Loss: 0.1991\n",
      "Validation Loss: 0.1991, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [578/1000] - Training\n",
      "Epoch [578/1000] completed, Average Training Loss: 0.0513\n",
      "    Validation Batch [1/1], Loss: 0.2107\n",
      "Validation Loss: 0.2107, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [579/1000] - Training\n",
      "Epoch [579/1000] completed, Average Training Loss: 0.0482\n",
      "    Validation Batch [1/1], Loss: 0.1921\n",
      "Validation Loss: 0.1921, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [580/1000] - Training\n",
      "Epoch [580/1000] completed, Average Training Loss: 0.0539\n",
      "    Validation Batch [1/1], Loss: 0.1660\n",
      "Validation Loss: 0.1660, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [581/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [581/1000] completed, Average Training Loss: 0.0434\n",
      "    Validation Batch [1/1], Loss: 0.1492\n",
      "Validation Loss: 0.1492, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [582/1000] - Training\n",
      "Epoch [582/1000] completed, Average Training Loss: 0.0433\n",
      "    Validation Batch [1/1], Loss: 0.1379\n",
      "Validation Loss: 0.1379, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [583/1000] - Training\n",
      "Epoch [583/1000] completed, Average Training Loss: 0.0496\n",
      "    Validation Batch [1/1], Loss: 0.1373\n",
      "Validation Loss: 0.1373, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [584/1000] - Training\n",
      "Epoch [584/1000] completed, Average Training Loss: 0.0481\n",
      "    Validation Batch [1/1], Loss: 0.1457\n",
      "Validation Loss: 0.1457, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [585/1000] - Training\n",
      "Epoch [585/1000] completed, Average Training Loss: 0.0516\n",
      "    Validation Batch [1/1], Loss: 0.1616\n",
      "Validation Loss: 0.1616, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [586/1000] - Training\n",
      "Epoch [586/1000] completed, Average Training Loss: 0.0447\n",
      "    Validation Batch [1/1], Loss: 0.1681\n",
      "Validation Loss: 0.1681, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [587/1000] - Training\n",
      "Epoch [587/1000] completed, Average Training Loss: 0.0527\n",
      "    Validation Batch [1/1], Loss: 0.1515\n",
      "Validation Loss: 0.1515, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [588/1000] - Training\n",
      "Epoch [588/1000] completed, Average Training Loss: 0.0537\n",
      "    Validation Batch [1/1], Loss: 0.1320\n",
      "Validation Loss: 0.1320, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [589/1000] - Training\n",
      "Epoch [589/1000] completed, Average Training Loss: 0.0493\n",
      "    Validation Batch [1/1], Loss: 0.1344\n",
      "Validation Loss: 0.1344, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [590/1000] - Training\n",
      "Epoch [590/1000] completed, Average Training Loss: 0.0421\n",
      "    Validation Batch [1/1], Loss: 0.1460\n",
      "Validation Loss: 0.1460, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [591/1000] - Training\n",
      "Epoch [591/1000] completed, Average Training Loss: 0.0425\n",
      "    Validation Batch [1/1], Loss: 0.1759\n",
      "Validation Loss: 0.1759, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [592/1000] - Training\n",
      "Epoch [592/1000] completed, Average Training Loss: 0.0507\n",
      "    Validation Batch [1/1], Loss: 0.2188\n",
      "Validation Loss: 0.2188, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [593/1000] - Training\n",
      "Epoch [593/1000] completed, Average Training Loss: 0.0410\n",
      "    Validation Batch [1/1], Loss: 0.2231\n",
      "Validation Loss: 0.2231, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [594/1000] - Training\n",
      "Epoch [594/1000] completed, Average Training Loss: 0.0441\n",
      "    Validation Batch [1/1], Loss: 0.1984\n",
      "Validation Loss: 0.1984, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [595/1000] - Training\n",
      "Epoch [595/1000] completed, Average Training Loss: 0.0623\n",
      "    Validation Batch [1/1], Loss: 0.1560\n",
      "Validation Loss: 0.1560, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [596/1000] - Training\n",
      "Epoch [596/1000] completed, Average Training Loss: 0.0423\n",
      "    Validation Batch [1/1], Loss: 0.1357\n",
      "Validation Loss: 0.1357, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [597/1000] - Training\n",
      "Epoch [597/1000] completed, Average Training Loss: 0.0535\n",
      "    Validation Batch [1/1], Loss: 0.1347\n",
      "Validation Loss: 0.1347, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [598/1000] - Training\n",
      "Epoch [598/1000] completed, Average Training Loss: 0.0436\n",
      "    Validation Batch [1/1], Loss: 0.1516\n",
      "Validation Loss: 0.1516, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [599/1000] - Training\n",
      "Epoch [599/1000] completed, Average Training Loss: 0.0460\n",
      "    Validation Batch [1/1], Loss: 0.1609\n",
      "Validation Loss: 0.1609, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [600/1000] - Training\n",
      "Epoch [600/1000] completed, Average Training Loss: 0.0465\n",
      "    Validation Batch [1/1], Loss: 0.1645\n",
      "Validation Loss: 0.1645, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [601/1000] - Training\n",
      "Epoch [601/1000] completed, Average Training Loss: 0.0502\n",
      "    Validation Batch [1/1], Loss: 0.1659\n",
      "Validation Loss: 0.1659, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [602/1000] - Training\n",
      "Epoch [602/1000] completed, Average Training Loss: 0.0471\n",
      "    Validation Batch [1/1], Loss: 0.1634\n",
      "Validation Loss: 0.1634, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [603/1000] - Training\n",
      "Epoch [603/1000] completed, Average Training Loss: 0.0442\n",
      "    Validation Batch [1/1], Loss: 0.1442\n",
      "Validation Loss: 0.1442, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [604/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [604/1000] completed, Average Training Loss: 0.0531\n",
      "    Validation Batch [1/1], Loss: 0.1237\n",
      "Validation Loss: 0.1237, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [605/1000] - Training\n",
      "Epoch [605/1000] completed, Average Training Loss: 0.0426\n",
      "    Validation Batch [1/1], Loss: 0.1098\n",
      "Validation Loss: 0.1098, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [606/1000] - Training\n",
      "Epoch [606/1000] completed, Average Training Loss: 0.0408\n",
      "    Validation Batch [1/1], Loss: 0.1161\n",
      "Validation Loss: 0.1161, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [607/1000] - Training\n",
      "Epoch [607/1000] completed, Average Training Loss: 0.0465\n",
      "    Validation Batch [1/1], Loss: 0.1402\n",
      "Validation Loss: 0.1402, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [608/1000] - Training\n",
      "Epoch [608/1000] completed, Average Training Loss: 0.0451\n",
      "    Validation Batch [1/1], Loss: 0.1661\n",
      "Validation Loss: 0.1661, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [609/1000] - Training\n",
      "Epoch [609/1000] completed, Average Training Loss: 0.0396\n",
      "    Validation Batch [1/1], Loss: 0.1797\n",
      "Validation Loss: 0.1797, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [610/1000] - Training\n",
      "Epoch [610/1000] completed, Average Training Loss: 0.0460\n",
      "    Validation Batch [1/1], Loss: 0.1654\n",
      "Validation Loss: 0.1654, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [611/1000] - Training\n",
      "Epoch [611/1000] completed, Average Training Loss: 0.0378\n",
      "    Validation Batch [1/1], Loss: 0.1379\n",
      "Validation Loss: 0.1379, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [612/1000] - Training\n",
      "Epoch [612/1000] completed, Average Training Loss: 0.0426\n",
      "    Validation Batch [1/1], Loss: 0.1128\n",
      "Validation Loss: 0.1128, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [613/1000] - Training\n",
      "Epoch [613/1000] completed, Average Training Loss: 0.0413\n",
      "    Validation Batch [1/1], Loss: 0.1037\n",
      "Validation Loss: 0.1037, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1098 to 0.1037. Saving model...\n",
      "\n",
      "LOG: Epoch [614/1000] - Training\n",
      "Epoch [614/1000] completed, Average Training Loss: 0.0344\n",
      "    Validation Batch [1/1], Loss: 0.1080\n",
      "Validation Loss: 0.1080, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [615/1000] - Training\n",
      "Epoch [615/1000] completed, Average Training Loss: 0.0386\n",
      "    Validation Batch [1/1], Loss: 0.1329\n",
      "Validation Loss: 0.1329, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [616/1000] - Training\n",
      "Epoch [616/1000] completed, Average Training Loss: 0.0422\n",
      "    Validation Batch [1/1], Loss: 0.1777\n",
      "Validation Loss: 0.1777, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [617/1000] - Training\n",
      "Epoch [617/1000] completed, Average Training Loss: 0.0489\n",
      "    Validation Batch [1/1], Loss: 0.1930\n",
      "Validation Loss: 0.1930, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [618/1000] - Training\n",
      "Epoch [618/1000] completed, Average Training Loss: 0.0463\n",
      "    Validation Batch [1/1], Loss: 0.1919\n",
      "Validation Loss: 0.1919, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [619/1000] - Training\n",
      "Epoch [619/1000] completed, Average Training Loss: 0.0470\n",
      "    Validation Batch [1/1], Loss: 0.1558\n",
      "Validation Loss: 0.1558, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [620/1000] - Training\n",
      "Epoch [620/1000] completed, Average Training Loss: 0.0415\n",
      "    Validation Batch [1/1], Loss: 0.1313\n",
      "Validation Loss: 0.1313, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [621/1000] - Training\n",
      "Epoch [621/1000] completed, Average Training Loss: 0.0411\n",
      "    Validation Batch [1/1], Loss: 0.1310\n",
      "Validation Loss: 0.1310, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [622/1000] - Training\n",
      "Epoch [622/1000] completed, Average Training Loss: 0.0408\n",
      "    Validation Batch [1/1], Loss: 0.1410\n",
      "Validation Loss: 0.1410, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [623/1000] - Training\n",
      "Epoch [623/1000] completed, Average Training Loss: 0.0481\n",
      "    Validation Batch [1/1], Loss: 0.1591\n",
      "Validation Loss: 0.1591, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [624/1000] - Training\n",
      "Epoch [624/1000] completed, Average Training Loss: 0.0443\n",
      "    Validation Batch [1/1], Loss: 0.1816\n",
      "Validation Loss: 0.1816, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [625/1000] - Training\n",
      "Epoch [625/1000] completed, Average Training Loss: 0.0435\n",
      "    Validation Batch [1/1], Loss: 0.2159\n",
      "Validation Loss: 0.2159, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [626/1000] - Training\n",
      "Epoch [626/1000] completed, Average Training Loss: 0.0402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.2057\n",
      "Validation Loss: 0.2057, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [627/1000] - Training\n",
      "Epoch [627/1000] completed, Average Training Loss: 0.0366\n",
      "    Validation Batch [1/1], Loss: 0.1791\n",
      "Validation Loss: 0.1791, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [628/1000] - Training\n",
      "Epoch [628/1000] completed, Average Training Loss: 0.0396\n",
      "    Validation Batch [1/1], Loss: 0.1541\n",
      "Validation Loss: 0.1541, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [629/1000] - Training\n",
      "Epoch [629/1000] completed, Average Training Loss: 0.0407\n",
      "    Validation Batch [1/1], Loss: 0.1491\n",
      "Validation Loss: 0.1491, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [630/1000] - Training\n",
      "Epoch [630/1000] completed, Average Training Loss: 0.0409\n",
      "    Validation Batch [1/1], Loss: 0.1556\n",
      "Validation Loss: 0.1556, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [631/1000] - Training\n",
      "Epoch [631/1000] completed, Average Training Loss: 0.0428\n",
      "    Validation Batch [1/1], Loss: 0.1761\n",
      "Validation Loss: 0.1761, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [632/1000] - Training\n",
      "Epoch [632/1000] completed, Average Training Loss: 0.0411\n",
      "    Validation Batch [1/1], Loss: 0.2047\n",
      "Validation Loss: 0.2047, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [633/1000] - Training\n",
      "Epoch [633/1000] completed, Average Training Loss: 0.0327\n",
      "    Validation Batch [1/1], Loss: 0.2189\n",
      "Validation Loss: 0.2189, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [634/1000] - Training\n",
      "Epoch [634/1000] completed, Average Training Loss: 0.0375\n",
      "    Validation Batch [1/1], Loss: 0.2143\n",
      "Validation Loss: 0.2143, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [635/1000] - Training\n",
      "Epoch [635/1000] completed, Average Training Loss: 0.0336\n",
      "    Validation Batch [1/1], Loss: 0.2048\n",
      "Validation Loss: 0.2048, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [636/1000] - Training\n",
      "Epoch [636/1000] completed, Average Training Loss: 0.0365\n",
      "    Validation Batch [1/1], Loss: 0.1836\n",
      "Validation Loss: 0.1836, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [637/1000] - Training\n",
      "Epoch [637/1000] completed, Average Training Loss: 0.0396\n",
      "    Validation Batch [1/1], Loss: 0.1644\n",
      "Validation Loss: 0.1644, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [638/1000] - Training\n",
      "Epoch [638/1000] completed, Average Training Loss: 0.0423\n",
      "    Validation Batch [1/1], Loss: 0.1482\n",
      "Validation Loss: 0.1482, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [639/1000] - Training\n",
      "Epoch [639/1000] completed, Average Training Loss: 0.0481\n",
      "    Validation Batch [1/1], Loss: 0.1433\n",
      "Validation Loss: 0.1433, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [640/1000] - Training\n",
      "Epoch [640/1000] completed, Average Training Loss: 0.0438\n",
      "    Validation Batch [1/1], Loss: 0.1467\n",
      "Validation Loss: 0.1467, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [641/1000] - Training\n",
      "Epoch [641/1000] completed, Average Training Loss: 0.0395\n",
      "    Validation Batch [1/1], Loss: 0.1390\n",
      "Validation Loss: 0.1390, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [642/1000] - Training\n",
      "Epoch [642/1000] completed, Average Training Loss: 0.0372\n",
      "    Validation Batch [1/1], Loss: 0.1480\n",
      "Validation Loss: 0.1480, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [643/1000] - Training\n",
      "Epoch [643/1000] completed, Average Training Loss: 0.0357\n",
      "    Validation Batch [1/1], Loss: 0.1390\n",
      "Validation Loss: 0.1390, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [644/1000] - Training\n",
      "Epoch [644/1000] completed, Average Training Loss: 0.0360\n",
      "    Validation Batch [1/1], Loss: 0.1255\n",
      "Validation Loss: 0.1255, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [645/1000] - Training\n",
      "Epoch [645/1000] completed, Average Training Loss: 0.0399\n",
      "    Validation Batch [1/1], Loss: 0.1070\n",
      "Validation Loss: 0.1070, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [646/1000] - Training\n",
      "Epoch [646/1000] completed, Average Training Loss: 0.0422\n",
      "    Validation Batch [1/1], Loss: 0.1031\n",
      "Validation Loss: 0.1031, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1037 to 0.1031. Saving model...\n",
      "\n",
      "LOG: Epoch [647/1000] - Training\n",
      "Epoch [647/1000] completed, Average Training Loss: 0.0406\n",
      "    Validation Batch [1/1], Loss: 0.1091\n",
      "Validation Loss: 0.1091, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [648/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [648/1000] completed, Average Training Loss: 0.0372\n",
      "    Validation Batch [1/1], Loss: 0.1165\n",
      "Validation Loss: 0.1165, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [649/1000] - Training\n",
      "Epoch [649/1000] completed, Average Training Loss: 0.0360\n",
      "    Validation Batch [1/1], Loss: 0.1317\n",
      "Validation Loss: 0.1317, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [650/1000] - Training\n",
      "Epoch [650/1000] completed, Average Training Loss: 0.0390\n",
      "    Validation Batch [1/1], Loss: 0.1481\n",
      "Validation Loss: 0.1481, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [651/1000] - Training\n",
      "Epoch [651/1000] completed, Average Training Loss: 0.0406\n",
      "    Validation Batch [1/1], Loss: 0.1573\n",
      "Validation Loss: 0.1573, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [652/1000] - Training\n",
      "Epoch [652/1000] completed, Average Training Loss: 0.0336\n",
      "    Validation Batch [1/1], Loss: 0.1526\n",
      "Validation Loss: 0.1526, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [653/1000] - Training\n",
      "Epoch [653/1000] completed, Average Training Loss: 0.0317\n",
      "    Validation Batch [1/1], Loss: 0.1411\n",
      "Validation Loss: 0.1411, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [654/1000] - Training\n",
      "Epoch [654/1000] completed, Average Training Loss: 0.0352\n",
      "    Validation Batch [1/1], Loss: 0.1289\n",
      "Validation Loss: 0.1289, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [655/1000] - Training\n",
      "Epoch [655/1000] completed, Average Training Loss: 0.0339\n",
      "    Validation Batch [1/1], Loss: 0.1303\n",
      "Validation Loss: 0.1303, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [656/1000] - Training\n",
      "Epoch [656/1000] completed, Average Training Loss: 0.0404\n",
      "    Validation Batch [1/1], Loss: 0.1295\n",
      "Validation Loss: 0.1295, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [657/1000] - Training\n",
      "Epoch [657/1000] completed, Average Training Loss: 0.0333\n",
      "    Validation Batch [1/1], Loss: 0.1408\n",
      "Validation Loss: 0.1408, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [658/1000] - Training\n",
      "Epoch [658/1000] completed, Average Training Loss: 0.0387\n",
      "    Validation Batch [1/1], Loss: 0.1775\n",
      "Validation Loss: 0.1775, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [659/1000] - Training\n",
      "Epoch [659/1000] completed, Average Training Loss: 0.0387\n",
      "    Validation Batch [1/1], Loss: 0.1793\n",
      "Validation Loss: 0.1793, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [660/1000] - Training\n",
      "Epoch [660/1000] completed, Average Training Loss: 0.0361\n",
      "    Validation Batch [1/1], Loss: 0.1543\n",
      "Validation Loss: 0.1543, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [661/1000] - Training\n",
      "Epoch [661/1000] completed, Average Training Loss: 0.0353\n",
      "    Validation Batch [1/1], Loss: 0.1462\n",
      "Validation Loss: 0.1462, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [662/1000] - Training\n",
      "Epoch [662/1000] completed, Average Training Loss: 0.0378\n",
      "    Validation Batch [1/1], Loss: 0.1418\n",
      "Validation Loss: 0.1418, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [663/1000] - Training\n",
      "Epoch [663/1000] completed, Average Training Loss: 0.0337\n",
      "    Validation Batch [1/1], Loss: 0.1404\n",
      "Validation Loss: 0.1404, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [664/1000] - Training\n",
      "Epoch [664/1000] completed, Average Training Loss: 0.0356\n",
      "    Validation Batch [1/1], Loss: 0.1331\n",
      "Validation Loss: 0.1331, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [665/1000] - Training\n",
      "Epoch [665/1000] completed, Average Training Loss: 0.0353\n",
      "    Validation Batch [1/1], Loss: 0.1333\n",
      "Validation Loss: 0.1333, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [666/1000] - Training\n",
      "Epoch [666/1000] completed, Average Training Loss: 0.0372\n",
      "    Validation Batch [1/1], Loss: 0.1434\n",
      "Validation Loss: 0.1434, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [667/1000] - Training\n",
      "Epoch [667/1000] completed, Average Training Loss: 0.0331\n",
      "    Validation Batch [1/1], Loss: 0.1658\n",
      "Validation Loss: 0.1658, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [668/1000] - Training\n",
      "Epoch [668/1000] completed, Average Training Loss: 0.0396\n",
      "    Validation Batch [1/1], Loss: 0.1744\n",
      "Validation Loss: 0.1744, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [669/1000] - Training\n",
      "Epoch [669/1000] completed, Average Training Loss: 0.0325\n",
      "    Validation Batch [1/1], Loss: 0.1435\n",
      "Validation Loss: 0.1435, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [670/1000] - Training\n",
      "Epoch [670/1000] completed, Average Training Loss: 0.0322\n",
      "    Validation Batch [1/1], Loss: 0.1308\n",
      "Validation Loss: 0.1308, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [671/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [671/1000] completed, Average Training Loss: 0.0370\n",
      "    Validation Batch [1/1], Loss: 0.1243\n",
      "Validation Loss: 0.1243, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [672/1000] - Training\n",
      "Epoch [672/1000] completed, Average Training Loss: 0.0302\n",
      "    Validation Batch [1/1], Loss: 0.1166\n",
      "Validation Loss: 0.1166, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [673/1000] - Training\n",
      "Epoch [673/1000] completed, Average Training Loss: 0.0404\n",
      "    Validation Batch [1/1], Loss: 0.1099\n",
      "Validation Loss: 0.1099, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [674/1000] - Training\n",
      "Epoch [674/1000] completed, Average Training Loss: 0.0335\n",
      "    Validation Batch [1/1], Loss: 0.1146\n",
      "Validation Loss: 0.1146, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [675/1000] - Training\n",
      "Epoch [675/1000] completed, Average Training Loss: 0.0349\n",
      "    Validation Batch [1/1], Loss: 0.1215\n",
      "Validation Loss: 0.1215, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [676/1000] - Training\n",
      "Epoch [676/1000] completed, Average Training Loss: 0.0387\n",
      "    Validation Batch [1/1], Loss: 0.1361\n",
      "Validation Loss: 0.1361, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [677/1000] - Training\n",
      "Epoch [677/1000] completed, Average Training Loss: 0.0452\n",
      "    Validation Batch [1/1], Loss: 0.1566\n",
      "Validation Loss: 0.1566, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [678/1000] - Training\n",
      "Epoch [678/1000] completed, Average Training Loss: 0.0395\n",
      "    Validation Batch [1/1], Loss: 0.1514\n",
      "Validation Loss: 0.1514, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [679/1000] - Training\n",
      "Epoch [679/1000] completed, Average Training Loss: 0.0374\n",
      "    Validation Batch [1/1], Loss: 0.1444\n",
      "Validation Loss: 0.1444, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [680/1000] - Training\n",
      "Epoch [680/1000] completed, Average Training Loss: 0.0324\n",
      "    Validation Batch [1/1], Loss: 0.1235\n",
      "Validation Loss: 0.1235, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [681/1000] - Training\n",
      "Epoch [681/1000] completed, Average Training Loss: 0.0295\n",
      "    Validation Batch [1/1], Loss: 0.1104\n",
      "Validation Loss: 0.1104, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [682/1000] - Training\n",
      "Epoch [682/1000] completed, Average Training Loss: 0.0301\n",
      "    Validation Batch [1/1], Loss: 0.1111\n",
      "Validation Loss: 0.1111, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [683/1000] - Training\n",
      "Epoch [683/1000] completed, Average Training Loss: 0.0351\n",
      "    Validation Batch [1/1], Loss: 0.1187\n",
      "Validation Loss: 0.1187, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [684/1000] - Training\n",
      "Epoch [684/1000] completed, Average Training Loss: 0.0300\n",
      "    Validation Batch [1/1], Loss: 0.1299\n",
      "Validation Loss: 0.1299, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [685/1000] - Training\n",
      "Epoch [685/1000] completed, Average Training Loss: 0.0391\n",
      "    Validation Batch [1/1], Loss: 0.1348\n",
      "Validation Loss: 0.1348, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [686/1000] - Training\n",
      "Epoch [686/1000] completed, Average Training Loss: 0.0457\n",
      "    Validation Batch [1/1], Loss: 0.1426\n",
      "Validation Loss: 0.1426, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [687/1000] - Training\n",
      "Epoch [687/1000] completed, Average Training Loss: 0.0350\n",
      "    Validation Batch [1/1], Loss: 0.1505\n",
      "Validation Loss: 0.1505, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [688/1000] - Training\n",
      "Epoch [688/1000] completed, Average Training Loss: 0.0296\n",
      "    Validation Batch [1/1], Loss: 0.1603\n",
      "Validation Loss: 0.1603, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [689/1000] - Training\n",
      "Epoch [689/1000] completed, Average Training Loss: 0.0345\n",
      "    Validation Batch [1/1], Loss: 0.1623\n",
      "Validation Loss: 0.1623, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [690/1000] - Training\n",
      "Epoch [690/1000] completed, Average Training Loss: 0.0363\n",
      "    Validation Batch [1/1], Loss: 0.1552\n",
      "Validation Loss: 0.1552, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [691/1000] - Training\n",
      "Epoch [691/1000] completed, Average Training Loss: 0.0345\n",
      "    Validation Batch [1/1], Loss: 0.1597\n",
      "Validation Loss: 0.1597, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [692/1000] - Training\n",
      "Epoch [692/1000] completed, Average Training Loss: 0.0347\n",
      "    Validation Batch [1/1], Loss: 0.1732\n",
      "Validation Loss: 0.1732, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [693/1000] - Training\n",
      "Epoch [693/1000] completed, Average Training Loss: 0.0330\n",
      "    Validation Batch [1/1], Loss: 0.1641\n",
      "Validation Loss: 0.1641, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [694/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [694/1000] completed, Average Training Loss: 0.0312\n",
      "    Validation Batch [1/1], Loss: 0.1670\n",
      "Validation Loss: 0.1670, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [695/1000] - Training\n",
      "Epoch [695/1000] completed, Average Training Loss: 0.0408\n",
      "    Validation Batch [1/1], Loss: 0.1609\n",
      "Validation Loss: 0.1609, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [696/1000] - Training\n",
      "Epoch [696/1000] completed, Average Training Loss: 0.0310\n",
      "    Validation Batch [1/1], Loss: 0.1438\n",
      "Validation Loss: 0.1438, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [697/1000] - Training\n",
      "Epoch [697/1000] completed, Average Training Loss: 0.0316\n",
      "    Validation Batch [1/1], Loss: 0.1247\n",
      "Validation Loss: 0.1247, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [698/1000] - Training\n",
      "Epoch [698/1000] completed, Average Training Loss: 0.0308\n",
      "    Validation Batch [1/1], Loss: 0.1075\n",
      "Validation Loss: 0.1075, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [699/1000] - Training\n",
      "Epoch [699/1000] completed, Average Training Loss: 0.0354\n",
      "    Validation Batch [1/1], Loss: 0.1004\n",
      "Validation Loss: 0.1004, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1031 to 0.1004. Saving model...\n",
      "\n",
      "LOG: Epoch [700/1000] - Training\n",
      "Epoch [700/1000] completed, Average Training Loss: 0.0274\n",
      "    Validation Batch [1/1], Loss: 0.1007\n",
      "Validation Loss: 0.1007, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [701/1000] - Training\n",
      "Epoch [701/1000] completed, Average Training Loss: 0.0277\n",
      "    Validation Batch [1/1], Loss: 0.1140\n",
      "Validation Loss: 0.1140, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [702/1000] - Training\n",
      "Epoch [702/1000] completed, Average Training Loss: 0.0377\n",
      "    Validation Batch [1/1], Loss: 0.1298\n",
      "Validation Loss: 0.1298, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [703/1000] - Training\n",
      "Epoch [703/1000] completed, Average Training Loss: 0.0337\n",
      "    Validation Batch [1/1], Loss: 0.1525\n",
      "Validation Loss: 0.1525, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [704/1000] - Training\n",
      "Epoch [704/1000] completed, Average Training Loss: 0.0324\n",
      "    Validation Batch [1/1], Loss: 0.1665\n",
      "Validation Loss: 0.1665, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [705/1000] - Training\n",
      "Epoch [705/1000] completed, Average Training Loss: 0.0346\n",
      "    Validation Batch [1/1], Loss: 0.1715\n",
      "Validation Loss: 0.1715, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [706/1000] - Training\n",
      "Epoch [706/1000] completed, Average Training Loss: 0.0315\n",
      "    Validation Batch [1/1], Loss: 0.1791\n",
      "Validation Loss: 0.1791, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [707/1000] - Training\n",
      "Epoch [707/1000] completed, Average Training Loss: 0.0338\n",
      "    Validation Batch [1/1], Loss: 0.1772\n",
      "Validation Loss: 0.1772, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [708/1000] - Training\n",
      "Epoch [708/1000] completed, Average Training Loss: 0.0297\n",
      "    Validation Batch [1/1], Loss: 0.1777\n",
      "Validation Loss: 0.1777, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [709/1000] - Training\n",
      "Epoch [709/1000] completed, Average Training Loss: 0.0342\n",
      "    Validation Batch [1/1], Loss: 0.1874\n",
      "Validation Loss: 0.1874, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [710/1000] - Training\n",
      "Epoch [710/1000] completed, Average Training Loss: 0.0240\n",
      "    Validation Batch [1/1], Loss: 0.1872\n",
      "Validation Loss: 0.1872, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [711/1000] - Training\n",
      "Epoch [711/1000] completed, Average Training Loss: 0.0372\n",
      "    Validation Batch [1/1], Loss: 0.1718\n",
      "Validation Loss: 0.1718, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [712/1000] - Training\n",
      "Epoch [712/1000] completed, Average Training Loss: 0.0321\n",
      "    Validation Batch [1/1], Loss: 0.1727\n",
      "Validation Loss: 0.1727, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [713/1000] - Training\n",
      "Epoch [713/1000] completed, Average Training Loss: 0.0318\n",
      "    Validation Batch [1/1], Loss: 0.1777\n",
      "Validation Loss: 0.1777, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [714/1000] - Training\n",
      "Epoch [714/1000] completed, Average Training Loss: 0.0275\n",
      "    Validation Batch [1/1], Loss: 0.1819\n",
      "Validation Loss: 0.1819, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [715/1000] - Training\n",
      "Epoch [715/1000] completed, Average Training Loss: 0.0296\n",
      "    Validation Batch [1/1], Loss: 0.1696\n",
      "Validation Loss: 0.1696, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [716/1000] - Training\n",
      "Epoch [716/1000] completed, Average Training Loss: 0.0253\n",
      "    Validation Batch [1/1], Loss: 0.1620\n",
      "Validation Loss: 0.1620, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [717/1000] - Training\n",
      "Epoch [717/1000] completed, Average Training Loss: 0.0341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1400\n",
      "Validation Loss: 0.1400, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [718/1000] - Training\n",
      "Epoch [718/1000] completed, Average Training Loss: 0.0295\n",
      "    Validation Batch [1/1], Loss: 0.1144\n",
      "Validation Loss: 0.1144, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [719/1000] - Training\n",
      "Epoch [719/1000] completed, Average Training Loss: 0.0300\n",
      "    Validation Batch [1/1], Loss: 0.1099\n",
      "Validation Loss: 0.1099, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [720/1000] - Training\n",
      "Epoch [720/1000] completed, Average Training Loss: 0.0335\n",
      "    Validation Batch [1/1], Loss: 0.1208\n",
      "Validation Loss: 0.1208, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [721/1000] - Training\n",
      "Epoch [721/1000] completed, Average Training Loss: 0.0282\n",
      "    Validation Batch [1/1], Loss: 0.1441\n",
      "Validation Loss: 0.1441, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [722/1000] - Training\n",
      "Epoch [722/1000] completed, Average Training Loss: 0.0377\n",
      "    Validation Batch [1/1], Loss: 0.1549\n",
      "Validation Loss: 0.1549, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [723/1000] - Training\n",
      "Epoch [723/1000] completed, Average Training Loss: 0.0346\n",
      "    Validation Batch [1/1], Loss: 0.1689\n",
      "Validation Loss: 0.1689, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [724/1000] - Training\n",
      "Epoch [724/1000] completed, Average Training Loss: 0.0265\n",
      "    Validation Batch [1/1], Loss: 0.1645\n",
      "Validation Loss: 0.1645, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [725/1000] - Training\n",
      "Epoch [725/1000] completed, Average Training Loss: 0.0326\n",
      "    Validation Batch [1/1], Loss: 0.1482\n",
      "Validation Loss: 0.1482, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [726/1000] - Training\n",
      "Epoch [726/1000] completed, Average Training Loss: 0.0273\n",
      "    Validation Batch [1/1], Loss: 0.1419\n",
      "Validation Loss: 0.1419, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [727/1000] - Training\n",
      "Epoch [727/1000] completed, Average Training Loss: 0.0342\n",
      "    Validation Batch [1/1], Loss: 0.1332\n",
      "Validation Loss: 0.1332, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [728/1000] - Training\n",
      "Epoch [728/1000] completed, Average Training Loss: 0.0269\n",
      "    Validation Batch [1/1], Loss: 0.1278\n",
      "Validation Loss: 0.1278, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [729/1000] - Training\n",
      "Epoch [729/1000] completed, Average Training Loss: 0.0285\n",
      "    Validation Batch [1/1], Loss: 0.1301\n",
      "Validation Loss: 0.1301, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [730/1000] - Training\n",
      "Epoch [730/1000] completed, Average Training Loss: 0.0244\n",
      "    Validation Batch [1/1], Loss: 0.1392\n",
      "Validation Loss: 0.1392, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [731/1000] - Training\n",
      "Epoch [731/1000] completed, Average Training Loss: 0.0383\n",
      "    Validation Batch [1/1], Loss: 0.1454\n",
      "Validation Loss: 0.1454, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [732/1000] - Training\n",
      "Epoch [732/1000] completed, Average Training Loss: 0.0355\n",
      "    Validation Batch [1/1], Loss: 0.1402\n",
      "Validation Loss: 0.1402, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [733/1000] - Training\n",
      "Epoch [733/1000] completed, Average Training Loss: 0.0316\n",
      "    Validation Batch [1/1], Loss: 0.1500\n",
      "Validation Loss: 0.1500, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [734/1000] - Training\n",
      "Epoch [734/1000] completed, Average Training Loss: 0.0255\n",
      "    Validation Batch [1/1], Loss: 0.1519\n",
      "Validation Loss: 0.1519, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [735/1000] - Training\n",
      "Epoch [735/1000] completed, Average Training Loss: 0.0307\n",
      "    Validation Batch [1/1], Loss: 0.1447\n",
      "Validation Loss: 0.1447, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [736/1000] - Training\n",
      "Epoch [736/1000] completed, Average Training Loss: 0.0274\n",
      "    Validation Batch [1/1], Loss: 0.1410\n",
      "Validation Loss: 0.1410, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [737/1000] - Training\n",
      "Epoch [737/1000] completed, Average Training Loss: 0.0249\n",
      "    Validation Batch [1/1], Loss: 0.1423\n",
      "Validation Loss: 0.1423, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [738/1000] - Training\n",
      "Epoch [738/1000] completed, Average Training Loss: 0.0266\n",
      "    Validation Batch [1/1], Loss: 0.1343\n",
      "Validation Loss: 0.1343, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [739/1000] - Training\n",
      "Epoch [739/1000] completed, Average Training Loss: 0.0282\n",
      "    Validation Batch [1/1], Loss: 0.1330\n",
      "Validation Loss: 0.1330, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [740/1000] - Training\n",
      "Epoch [740/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.1442\n",
      "Validation Loss: 0.1442, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [741/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [741/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.1529\n",
      "Validation Loss: 0.1529, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [742/1000] - Training\n",
      "Epoch [742/1000] completed, Average Training Loss: 0.0254\n",
      "    Validation Batch [1/1], Loss: 0.1583\n",
      "Validation Loss: 0.1583, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [743/1000] - Training\n",
      "Epoch [743/1000] completed, Average Training Loss: 0.0265\n",
      "    Validation Batch [1/1], Loss: 0.1451\n",
      "Validation Loss: 0.1451, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [744/1000] - Training\n",
      "Epoch [744/1000] completed, Average Training Loss: 0.0315\n",
      "    Validation Batch [1/1], Loss: 0.1435\n",
      "Validation Loss: 0.1435, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [745/1000] - Training\n",
      "Epoch [745/1000] completed, Average Training Loss: 0.0309\n",
      "    Validation Batch [1/1], Loss: 0.1495\n",
      "Validation Loss: 0.1495, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [746/1000] - Training\n",
      "Epoch [746/1000] completed, Average Training Loss: 0.0234\n",
      "    Validation Batch [1/1], Loss: 0.1543\n",
      "Validation Loss: 0.1543, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [747/1000] - Training\n",
      "Epoch [747/1000] completed, Average Training Loss: 0.0295\n",
      "    Validation Batch [1/1], Loss: 0.1707\n",
      "Validation Loss: 0.1707, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [748/1000] - Training\n",
      "Epoch [748/1000] completed, Average Training Loss: 0.0257\n",
      "    Validation Batch [1/1], Loss: 0.1747\n",
      "Validation Loss: 0.1747, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [749/1000] - Training\n",
      "Epoch [749/1000] completed, Average Training Loss: 0.0235\n",
      "    Validation Batch [1/1], Loss: 0.1593\n",
      "Validation Loss: 0.1593, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [750/1000] - Training\n",
      "Epoch [750/1000] completed, Average Training Loss: 0.0296\n",
      "    Validation Batch [1/1], Loss: 0.1604\n",
      "Validation Loss: 0.1604, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [751/1000] - Training\n",
      "Epoch [751/1000] completed, Average Training Loss: 0.0228\n",
      "    Validation Batch [1/1], Loss: 0.1678\n",
      "Validation Loss: 0.1678, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [752/1000] - Training\n",
      "Epoch [752/1000] completed, Average Training Loss: 0.0247\n",
      "    Validation Batch [1/1], Loss: 0.1666\n",
      "Validation Loss: 0.1666, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [753/1000] - Training\n",
      "Epoch [753/1000] completed, Average Training Loss: 0.0254\n",
      "    Validation Batch [1/1], Loss: 0.1556\n",
      "Validation Loss: 0.1556, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [754/1000] - Training\n",
      "Epoch [754/1000] completed, Average Training Loss: 0.0210\n",
      "    Validation Batch [1/1], Loss: 0.1352\n",
      "Validation Loss: 0.1352, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [755/1000] - Training\n",
      "Epoch [755/1000] completed, Average Training Loss: 0.0249\n",
      "    Validation Batch [1/1], Loss: 0.1064\n",
      "Validation Loss: 0.1064, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [756/1000] - Training\n",
      "Epoch [756/1000] completed, Average Training Loss: 0.0312\n",
      "    Validation Batch [1/1], Loss: 0.0906\n",
      "Validation Loss: 0.0906, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.1004 to 0.0906. Saving model...\n",
      "\n",
      "LOG: Epoch [757/1000] - Training\n",
      "Epoch [757/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.0818\n",
      "Validation Loss: 0.0818, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.0906 to 0.0818. Saving model...\n",
      "\n",
      "LOG: Epoch [758/1000] - Training\n",
      "Epoch [758/1000] completed, Average Training Loss: 0.0247\n",
      "    Validation Batch [1/1], Loss: 0.0818\n",
      "Validation Loss: 0.0818, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [759/1000] - Training\n",
      "Epoch [759/1000] completed, Average Training Loss: 0.0262\n",
      "    Validation Batch [1/1], Loss: 0.0879\n",
      "Validation Loss: 0.0879, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [760/1000] - Training\n",
      "Epoch [760/1000] completed, Average Training Loss: 0.0327\n",
      "    Validation Batch [1/1], Loss: 0.1061\n",
      "Validation Loss: 0.1061, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [761/1000] - Training\n",
      "Epoch [761/1000] completed, Average Training Loss: 0.0256\n",
      "    Validation Batch [1/1], Loss: 0.1301\n",
      "Validation Loss: 0.1301, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [762/1000] - Training\n",
      "Epoch [762/1000] completed, Average Training Loss: 0.0261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1279\n",
      "Validation Loss: 0.1279, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [763/1000] - Training\n",
      "Epoch [763/1000] completed, Average Training Loss: 0.0239\n",
      "    Validation Batch [1/1], Loss: 0.1183\n",
      "Validation Loss: 0.1183, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [764/1000] - Training\n",
      "Epoch [764/1000] completed, Average Training Loss: 0.0253\n",
      "    Validation Batch [1/1], Loss: 0.1044\n",
      "Validation Loss: 0.1044, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [765/1000] - Training\n",
      "Epoch [765/1000] completed, Average Training Loss: 0.0231\n",
      "    Validation Batch [1/1], Loss: 0.0950\n",
      "Validation Loss: 0.0950, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [766/1000] - Training\n",
      "Epoch [766/1000] completed, Average Training Loss: 0.0286\n",
      "    Validation Batch [1/1], Loss: 0.0912\n",
      "Validation Loss: 0.0912, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [767/1000] - Training\n",
      "Epoch [767/1000] completed, Average Training Loss: 0.0223\n",
      "    Validation Batch [1/1], Loss: 0.0948\n",
      "Validation Loss: 0.0948, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [768/1000] - Training\n",
      "Epoch [768/1000] completed, Average Training Loss: 0.0225\n",
      "    Validation Batch [1/1], Loss: 0.1078\n",
      "Validation Loss: 0.1078, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [769/1000] - Training\n",
      "Epoch [769/1000] completed, Average Training Loss: 0.0220\n",
      "    Validation Batch [1/1], Loss: 0.1244\n",
      "Validation Loss: 0.1244, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [770/1000] - Training\n",
      "Epoch [770/1000] completed, Average Training Loss: 0.0308\n",
      "    Validation Batch [1/1], Loss: 0.1405\n",
      "Validation Loss: 0.1405, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [771/1000] - Training\n",
      "Epoch [771/1000] completed, Average Training Loss: 0.0263\n",
      "    Validation Batch [1/1], Loss: 0.1510\n",
      "Validation Loss: 0.1510, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [772/1000] - Training\n",
      "Epoch [772/1000] completed, Average Training Loss: 0.0248\n",
      "    Validation Batch [1/1], Loss: 0.1622\n",
      "Validation Loss: 0.1622, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [773/1000] - Training\n",
      "Epoch [773/1000] completed, Average Training Loss: 0.0295\n",
      "    Validation Batch [1/1], Loss: 0.1600\n",
      "Validation Loss: 0.1600, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [774/1000] - Training\n",
      "Epoch [774/1000] completed, Average Training Loss: 0.0248\n",
      "    Validation Batch [1/1], Loss: 0.1597\n",
      "Validation Loss: 0.1597, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [775/1000] - Training\n",
      "Epoch [775/1000] completed, Average Training Loss: 0.0268\n",
      "    Validation Batch [1/1], Loss: 0.1557\n",
      "Validation Loss: 0.1557, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [776/1000] - Training\n",
      "Epoch [776/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.1411\n",
      "Validation Loss: 0.1411, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [777/1000] - Training\n",
      "Epoch [777/1000] completed, Average Training Loss: 0.0208\n",
      "    Validation Batch [1/1], Loss: 0.1277\n",
      "Validation Loss: 0.1277, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [778/1000] - Training\n",
      "Epoch [778/1000] completed, Average Training Loss: 0.0300\n",
      "    Validation Batch [1/1], Loss: 0.1248\n",
      "Validation Loss: 0.1248, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [779/1000] - Training\n",
      "Epoch [779/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.1229\n",
      "Validation Loss: 0.1229, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [780/1000] - Training\n",
      "Epoch [780/1000] completed, Average Training Loss: 0.0277\n",
      "    Validation Batch [1/1], Loss: 0.1283\n",
      "Validation Loss: 0.1283, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [781/1000] - Training\n",
      "Epoch [781/1000] completed, Average Training Loss: 0.0273\n",
      "    Validation Batch [1/1], Loss: 0.1392\n",
      "Validation Loss: 0.1392, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [782/1000] - Training\n",
      "Epoch [782/1000] completed, Average Training Loss: 0.0230\n",
      "    Validation Batch [1/1], Loss: 0.1532\n",
      "Validation Loss: 0.1532, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [783/1000] - Training\n",
      "Epoch [783/1000] completed, Average Training Loss: 0.0315\n",
      "    Validation Batch [1/1], Loss: 0.1593\n",
      "Validation Loss: 0.1593, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [784/1000] - Training\n",
      "Epoch [784/1000] completed, Average Training Loss: 0.0223\n",
      "    Validation Batch [1/1], Loss: 0.1602\n",
      "Validation Loss: 0.1602, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [785/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [785/1000] completed, Average Training Loss: 0.0199\n",
      "    Validation Batch [1/1], Loss: 0.1638\n",
      "Validation Loss: 0.1638, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [786/1000] - Training\n",
      "Epoch [786/1000] completed, Average Training Loss: 0.0266\n",
      "    Validation Batch [1/1], Loss: 0.1637\n",
      "Validation Loss: 0.1637, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [787/1000] - Training\n",
      "Epoch [787/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.1674\n",
      "Validation Loss: 0.1674, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [788/1000] - Training\n",
      "Epoch [788/1000] completed, Average Training Loss: 0.0264\n",
      "    Validation Batch [1/1], Loss: 0.1488\n",
      "Validation Loss: 0.1488, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [789/1000] - Training\n",
      "Epoch [789/1000] completed, Average Training Loss: 0.0262\n",
      "    Validation Batch [1/1], Loss: 0.1394\n",
      "Validation Loss: 0.1394, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [790/1000] - Training\n",
      "Epoch [790/1000] completed, Average Training Loss: 0.0269\n",
      "    Validation Batch [1/1], Loss: 0.1407\n",
      "Validation Loss: 0.1407, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [791/1000] - Training\n",
      "Epoch [791/1000] completed, Average Training Loss: 0.0250\n",
      "    Validation Batch [1/1], Loss: 0.1582\n",
      "Validation Loss: 0.1582, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [792/1000] - Training\n",
      "Epoch [792/1000] completed, Average Training Loss: 0.0269\n",
      "    Validation Batch [1/1], Loss: 0.1901\n",
      "Validation Loss: 0.1901, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [793/1000] - Training\n",
      "Epoch [793/1000] completed, Average Training Loss: 0.0288\n",
      "    Validation Batch [1/1], Loss: 0.2179\n",
      "Validation Loss: 0.2179, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [794/1000] - Training\n",
      "Epoch [794/1000] completed, Average Training Loss: 0.0248\n",
      "    Validation Batch [1/1], Loss: 0.2427\n",
      "Validation Loss: 0.2427, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [795/1000] - Training\n",
      "Epoch [795/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.2222\n",
      "Validation Loss: 0.2222, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [796/1000] - Training\n",
      "Epoch [796/1000] completed, Average Training Loss: 0.0225\n",
      "    Validation Batch [1/1], Loss: 0.1768\n",
      "Validation Loss: 0.1768, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [797/1000] - Training\n",
      "Epoch [797/1000] completed, Average Training Loss: 0.0258\n",
      "    Validation Batch [1/1], Loss: 0.1253\n",
      "Validation Loss: 0.1253, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [798/1000] - Training\n",
      "Epoch [798/1000] completed, Average Training Loss: 0.0242\n",
      "    Validation Batch [1/1], Loss: 0.0932\n",
      "Validation Loss: 0.0932, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [799/1000] - Training\n",
      "Epoch [799/1000] completed, Average Training Loss: 0.0229\n",
      "    Validation Batch [1/1], Loss: 0.0747\n",
      "Validation Loss: 0.0747, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.0818 to 0.0747. Saving model...\n",
      "\n",
      "LOG: Epoch [800/1000] - Training\n",
      "Epoch [800/1000] completed, Average Training Loss: 0.0203\n",
      "    Validation Batch [1/1], Loss: 0.0750\n",
      "Validation Loss: 0.0750, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [801/1000] - Training\n",
      "Epoch [801/1000] completed, Average Training Loss: 0.0192\n",
      "    Validation Batch [1/1], Loss: 0.0894\n",
      "Validation Loss: 0.0894, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [802/1000] - Training\n",
      "Epoch [802/1000] completed, Average Training Loss: 0.0199\n",
      "    Validation Batch [1/1], Loss: 0.1224\n",
      "Validation Loss: 0.1224, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [803/1000] - Training\n",
      "Epoch [803/1000] completed, Average Training Loss: 0.0221\n",
      "    Validation Batch [1/1], Loss: 0.1688\n",
      "Validation Loss: 0.1688, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [804/1000] - Training\n",
      "Epoch [804/1000] completed, Average Training Loss: 0.0227\n",
      "    Validation Batch [1/1], Loss: 0.2305\n",
      "Validation Loss: 0.2305, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [805/1000] - Training\n",
      "Epoch [805/1000] completed, Average Training Loss: 0.0262\n",
      "    Validation Batch [1/1], Loss: 0.2702\n",
      "Validation Loss: 0.2702, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [806/1000] - Training\n",
      "Epoch [806/1000] completed, Average Training Loss: 0.0216\n",
      "    Validation Batch [1/1], Loss: 0.2611\n",
      "Validation Loss: 0.2611, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [807/1000] - Training\n",
      "Epoch [807/1000] completed, Average Training Loss: 0.0239\n",
      "    Validation Batch [1/1], Loss: 0.2041\n",
      "Validation Loss: 0.2041, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [808/1000] - Training\n",
      "Epoch [808/1000] completed, Average Training Loss: 0.0218\n",
      "    Validation Batch [1/1], Loss: 0.1589\n",
      "Validation Loss: 0.1589, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [809/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [809/1000] completed, Average Training Loss: 0.0225\n",
      "    Validation Batch [1/1], Loss: 0.1186\n",
      "Validation Loss: 0.1186, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [810/1000] - Training\n",
      "Epoch [810/1000] completed, Average Training Loss: 0.0229\n",
      "    Validation Batch [1/1], Loss: 0.0959\n",
      "Validation Loss: 0.0959, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [811/1000] - Training\n",
      "Epoch [811/1000] completed, Average Training Loss: 0.0227\n",
      "    Validation Batch [1/1], Loss: 0.0893\n",
      "Validation Loss: 0.0893, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [812/1000] - Training\n",
      "Epoch [812/1000] completed, Average Training Loss: 0.0251\n",
      "    Validation Batch [1/1], Loss: 0.0931\n",
      "Validation Loss: 0.0931, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [813/1000] - Training\n",
      "Epoch [813/1000] completed, Average Training Loss: 0.0216\n",
      "    Validation Batch [1/1], Loss: 0.1051\n",
      "Validation Loss: 0.1051, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [814/1000] - Training\n",
      "Epoch [814/1000] completed, Average Training Loss: 0.0200\n",
      "    Validation Batch [1/1], Loss: 0.1316\n",
      "Validation Loss: 0.1316, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [815/1000] - Training\n",
      "Epoch [815/1000] completed, Average Training Loss: 0.0215\n",
      "    Validation Batch [1/1], Loss: 0.1801\n",
      "Validation Loss: 0.1801, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [816/1000] - Training\n",
      "Epoch [816/1000] completed, Average Training Loss: 0.0219\n",
      "    Validation Batch [1/1], Loss: 0.1986\n",
      "Validation Loss: 0.1986, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [817/1000] - Training\n",
      "Epoch [817/1000] completed, Average Training Loss: 0.0215\n",
      "    Validation Batch [1/1], Loss: 0.2153\n",
      "Validation Loss: 0.2153, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [818/1000] - Training\n",
      "Epoch [818/1000] completed, Average Training Loss: 0.0239\n",
      "    Validation Batch [1/1], Loss: 0.2084\n",
      "Validation Loss: 0.2084, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [819/1000] - Training\n",
      "Epoch [819/1000] completed, Average Training Loss: 0.0208\n",
      "    Validation Batch [1/1], Loss: 0.1925\n",
      "Validation Loss: 0.1925, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [820/1000] - Training\n",
      "Epoch [820/1000] completed, Average Training Loss: 0.0228\n",
      "    Validation Batch [1/1], Loss: 0.1620\n",
      "Validation Loss: 0.1620, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [821/1000] - Training\n",
      "Epoch [821/1000] completed, Average Training Loss: 0.0181\n",
      "    Validation Batch [1/1], Loss: 0.1384\n",
      "Validation Loss: 0.1384, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [822/1000] - Training\n",
      "Epoch [822/1000] completed, Average Training Loss: 0.0239\n",
      "    Validation Batch [1/1], Loss: 0.1298\n",
      "Validation Loss: 0.1298, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [823/1000] - Training\n",
      "Epoch [823/1000] completed, Average Training Loss: 0.0205\n",
      "    Validation Batch [1/1], Loss: 0.1270\n",
      "Validation Loss: 0.1270, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [824/1000] - Training\n",
      "Epoch [824/1000] completed, Average Training Loss: 0.0255\n",
      "    Validation Batch [1/1], Loss: 0.1295\n",
      "Validation Loss: 0.1295, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [825/1000] - Training\n",
      "Epoch [825/1000] completed, Average Training Loss: 0.0202\n",
      "    Validation Batch [1/1], Loss: 0.1232\n",
      "Validation Loss: 0.1232, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [826/1000] - Training\n",
      "Epoch [826/1000] completed, Average Training Loss: 0.0227\n",
      "    Validation Batch [1/1], Loss: 0.1134\n",
      "Validation Loss: 0.1134, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [827/1000] - Training\n",
      "Epoch [827/1000] completed, Average Training Loss: 0.0213\n",
      "    Validation Batch [1/1], Loss: 0.1148\n",
      "Validation Loss: 0.1148, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [828/1000] - Training\n",
      "Epoch [828/1000] completed, Average Training Loss: 0.0176\n",
      "    Validation Batch [1/1], Loss: 0.1306\n",
      "Validation Loss: 0.1306, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [829/1000] - Training\n",
      "Epoch [829/1000] completed, Average Training Loss: 0.0186\n",
      "    Validation Batch [1/1], Loss: 0.1296\n",
      "Validation Loss: 0.1296, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [830/1000] - Training\n",
      "Epoch [830/1000] completed, Average Training Loss: 0.0181\n",
      "    Validation Batch [1/1], Loss: 0.1265\n",
      "Validation Loss: 0.1265, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [831/1000] - Training\n",
      "Epoch [831/1000] completed, Average Training Loss: 0.0263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1222\n",
      "Validation Loss: 0.1222, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [832/1000] - Training\n",
      "Epoch [832/1000] completed, Average Training Loss: 0.0200\n",
      "    Validation Batch [1/1], Loss: 0.1297\n",
      "Validation Loss: 0.1297, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [833/1000] - Training\n",
      "Epoch [833/1000] completed, Average Training Loss: 0.0216\n",
      "    Validation Batch [1/1], Loss: 0.1336\n",
      "Validation Loss: 0.1336, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [834/1000] - Training\n",
      "Epoch [834/1000] completed, Average Training Loss: 0.0206\n",
      "    Validation Batch [1/1], Loss: 0.1234\n",
      "Validation Loss: 0.1234, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [835/1000] - Training\n",
      "Epoch [835/1000] completed, Average Training Loss: 0.0250\n",
      "    Validation Batch [1/1], Loss: 0.1025\n",
      "Validation Loss: 0.1025, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [836/1000] - Training\n",
      "Epoch [836/1000] completed, Average Training Loss: 0.0209\n",
      "    Validation Batch [1/1], Loss: 0.0913\n",
      "Validation Loss: 0.0913, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [837/1000] - Training\n",
      "Epoch [837/1000] completed, Average Training Loss: 0.0190\n",
      "    Validation Batch [1/1], Loss: 0.1002\n",
      "Validation Loss: 0.1002, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [838/1000] - Training\n",
      "Epoch [838/1000] completed, Average Training Loss: 0.0195\n",
      "    Validation Batch [1/1], Loss: 0.1292\n",
      "Validation Loss: 0.1292, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [839/1000] - Training\n",
      "Epoch [839/1000] completed, Average Training Loss: 0.0190\n",
      "    Validation Batch [1/1], Loss: 0.1582\n",
      "Validation Loss: 0.1582, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [840/1000] - Training\n",
      "Epoch [840/1000] completed, Average Training Loss: 0.0213\n",
      "    Validation Batch [1/1], Loss: 0.1937\n",
      "Validation Loss: 0.1937, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [841/1000] - Training\n",
      "Epoch [841/1000] completed, Average Training Loss: 0.0186\n",
      "    Validation Batch [1/1], Loss: 0.2011\n",
      "Validation Loss: 0.2011, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [842/1000] - Training\n",
      "Epoch [842/1000] completed, Average Training Loss: 0.0190\n",
      "    Validation Batch [1/1], Loss: 0.1889\n",
      "Validation Loss: 0.1889, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [843/1000] - Training\n",
      "Epoch [843/1000] completed, Average Training Loss: 0.0215\n",
      "    Validation Batch [1/1], Loss: 0.1606\n",
      "Validation Loss: 0.1606, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [844/1000] - Training\n",
      "Epoch [844/1000] completed, Average Training Loss: 0.0191\n",
      "    Validation Batch [1/1], Loss: 0.1414\n",
      "Validation Loss: 0.1414, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [845/1000] - Training\n",
      "Epoch [845/1000] completed, Average Training Loss: 0.0215\n",
      "    Validation Batch [1/1], Loss: 0.1131\n",
      "Validation Loss: 0.1131, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [846/1000] - Training\n",
      "Epoch [846/1000] completed, Average Training Loss: 0.0245\n",
      "    Validation Batch [1/1], Loss: 0.0900\n",
      "Validation Loss: 0.0900, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [847/1000] - Training\n",
      "Epoch [847/1000] completed, Average Training Loss: 0.0246\n",
      "    Validation Batch [1/1], Loss: 0.0954\n",
      "Validation Loss: 0.0954, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [848/1000] - Training\n",
      "Epoch [848/1000] completed, Average Training Loss: 0.0211\n",
      "    Validation Batch [1/1], Loss: 0.1073\n",
      "Validation Loss: 0.1073, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [849/1000] - Training\n",
      "Epoch [849/1000] completed, Average Training Loss: 0.0201\n",
      "    Validation Batch [1/1], Loss: 0.1238\n",
      "Validation Loss: 0.1238, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [850/1000] - Training\n",
      "Epoch [850/1000] completed, Average Training Loss: 0.0225\n",
      "    Validation Batch [1/1], Loss: 0.1480\n",
      "Validation Loss: 0.1480, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [851/1000] - Training\n",
      "Epoch [851/1000] completed, Average Training Loss: 0.0168\n",
      "    Validation Batch [1/1], Loss: 0.1638\n",
      "Validation Loss: 0.1638, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [852/1000] - Training\n",
      "Epoch [852/1000] completed, Average Training Loss: 0.0214\n",
      "    Validation Batch [1/1], Loss: 0.1715\n",
      "Validation Loss: 0.1715, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [853/1000] - Training\n",
      "Epoch [853/1000] completed, Average Training Loss: 0.0200\n",
      "    Validation Batch [1/1], Loss: 0.1748\n",
      "Validation Loss: 0.1748, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [854/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [854/1000] completed, Average Training Loss: 0.0237\n",
      "    Validation Batch [1/1], Loss: 0.1742\n",
      "Validation Loss: 0.1742, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [855/1000] - Training\n",
      "Epoch [855/1000] completed, Average Training Loss: 0.0192\n",
      "    Validation Batch [1/1], Loss: 0.1511\n",
      "Validation Loss: 0.1511, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [856/1000] - Training\n",
      "Epoch [856/1000] completed, Average Training Loss: 0.0183\n",
      "    Validation Batch [1/1], Loss: 0.1327\n",
      "Validation Loss: 0.1327, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [857/1000] - Training\n",
      "Epoch [857/1000] completed, Average Training Loss: 0.0191\n",
      "    Validation Batch [1/1], Loss: 0.1261\n",
      "Validation Loss: 0.1261, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [858/1000] - Training\n",
      "Epoch [858/1000] completed, Average Training Loss: 0.0231\n",
      "    Validation Batch [1/1], Loss: 0.1257\n",
      "Validation Loss: 0.1257, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [859/1000] - Training\n",
      "Epoch [859/1000] completed, Average Training Loss: 0.0209\n",
      "    Validation Batch [1/1], Loss: 0.1423\n",
      "Validation Loss: 0.1423, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [860/1000] - Training\n",
      "Epoch [860/1000] completed, Average Training Loss: 0.0195\n",
      "    Validation Batch [1/1], Loss: 0.1566\n",
      "Validation Loss: 0.1566, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [861/1000] - Training\n",
      "Epoch [861/1000] completed, Average Training Loss: 0.0196\n",
      "    Validation Batch [1/1], Loss: 0.1513\n",
      "Validation Loss: 0.1513, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [862/1000] - Training\n",
      "Epoch [862/1000] completed, Average Training Loss: 0.0183\n",
      "    Validation Batch [1/1], Loss: 0.1348\n",
      "Validation Loss: 0.1348, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [863/1000] - Training\n",
      "Epoch [863/1000] completed, Average Training Loss: 0.0177\n",
      "    Validation Batch [1/1], Loss: 0.1190\n",
      "Validation Loss: 0.1190, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [864/1000] - Training\n",
      "Epoch [864/1000] completed, Average Training Loss: 0.0184\n",
      "    Validation Batch [1/1], Loss: 0.1173\n",
      "Validation Loss: 0.1173, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [865/1000] - Training\n",
      "Epoch [865/1000] completed, Average Training Loss: 0.0194\n",
      "    Validation Batch [1/1], Loss: 0.1160\n",
      "Validation Loss: 0.1160, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [866/1000] - Training\n",
      "Epoch [866/1000] completed, Average Training Loss: 0.0180\n",
      "    Validation Batch [1/1], Loss: 0.1137\n",
      "Validation Loss: 0.1137, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [867/1000] - Training\n",
      "Epoch [867/1000] completed, Average Training Loss: 0.0173\n",
      "    Validation Batch [1/1], Loss: 0.1111\n",
      "Validation Loss: 0.1111, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [868/1000] - Training\n",
      "Epoch [868/1000] completed, Average Training Loss: 0.0174\n",
      "    Validation Batch [1/1], Loss: 0.1022\n",
      "Validation Loss: 0.1022, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [869/1000] - Training\n",
      "Epoch [869/1000] completed, Average Training Loss: 0.0167\n",
      "    Validation Batch [1/1], Loss: 0.1189\n",
      "Validation Loss: 0.1189, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [870/1000] - Training\n",
      "Epoch [870/1000] completed, Average Training Loss: 0.0172\n",
      "    Validation Batch [1/1], Loss: 0.1606\n",
      "Validation Loss: 0.1606, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [871/1000] - Training\n",
      "Epoch [871/1000] completed, Average Training Loss: 0.0232\n",
      "    Validation Batch [1/1], Loss: 0.1898\n",
      "Validation Loss: 0.1898, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [872/1000] - Training\n",
      "Epoch [872/1000] completed, Average Training Loss: 0.0245\n",
      "    Validation Batch [1/1], Loss: 0.2081\n",
      "Validation Loss: 0.2081, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [873/1000] - Training\n",
      "Epoch [873/1000] completed, Average Training Loss: 0.0128\n",
      "    Validation Batch [1/1], Loss: 0.2157\n",
      "Validation Loss: 0.2157, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [874/1000] - Training\n",
      "Epoch [874/1000] completed, Average Training Loss: 0.0181\n",
      "    Validation Batch [1/1], Loss: 0.2081\n",
      "Validation Loss: 0.2081, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [875/1000] - Training\n",
      "Epoch [875/1000] completed, Average Training Loss: 0.0178\n",
      "    Validation Batch [1/1], Loss: 0.1848\n",
      "Validation Loss: 0.1848, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [876/1000] - Training\n",
      "Epoch [876/1000] completed, Average Training Loss: 0.0197\n",
      "    Validation Batch [1/1], Loss: 0.1641\n",
      "Validation Loss: 0.1641, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [877/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [877/1000] completed, Average Training Loss: 0.0201\n",
      "    Validation Batch [1/1], Loss: 0.1459\n",
      "Validation Loss: 0.1459, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [878/1000] - Training\n",
      "Epoch [878/1000] completed, Average Training Loss: 0.0231\n",
      "    Validation Batch [1/1], Loss: 0.1316\n",
      "Validation Loss: 0.1316, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [879/1000] - Training\n",
      "Epoch [879/1000] completed, Average Training Loss: 0.0158\n",
      "    Validation Batch [1/1], Loss: 0.1209\n",
      "Validation Loss: 0.1209, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [880/1000] - Training\n",
      "Epoch [880/1000] completed, Average Training Loss: 0.0214\n",
      "    Validation Batch [1/1], Loss: 0.1197\n",
      "Validation Loss: 0.1197, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [881/1000] - Training\n",
      "Epoch [881/1000] completed, Average Training Loss: 0.0161\n",
      "    Validation Batch [1/1], Loss: 0.1074\n",
      "Validation Loss: 0.1074, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [882/1000] - Training\n",
      "Epoch [882/1000] completed, Average Training Loss: 0.0194\n",
      "    Validation Batch [1/1], Loss: 0.0809\n",
      "Validation Loss: 0.0809, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [883/1000] - Training\n",
      "Epoch [883/1000] completed, Average Training Loss: 0.0177\n",
      "    Validation Batch [1/1], Loss: 0.0810\n",
      "Validation Loss: 0.0810, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [884/1000] - Training\n",
      "Epoch [884/1000] completed, Average Training Loss: 0.0174\n",
      "    Validation Batch [1/1], Loss: 0.1032\n",
      "Validation Loss: 0.1032, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [885/1000] - Training\n",
      "Epoch [885/1000] completed, Average Training Loss: 0.0156\n",
      "    Validation Batch [1/1], Loss: 0.1450\n",
      "Validation Loss: 0.1450, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [886/1000] - Training\n",
      "Epoch [886/1000] completed, Average Training Loss: 0.0185\n",
      "    Validation Batch [1/1], Loss: 0.2005\n",
      "Validation Loss: 0.2005, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [887/1000] - Training\n",
      "Epoch [887/1000] completed, Average Training Loss: 0.0162\n",
      "    Validation Batch [1/1], Loss: 0.2277\n",
      "Validation Loss: 0.2277, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [888/1000] - Training\n",
      "Epoch [888/1000] completed, Average Training Loss: 0.0157\n",
      "    Validation Batch [1/1], Loss: 0.2570\n",
      "Validation Loss: 0.2570, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [889/1000] - Training\n",
      "Epoch [889/1000] completed, Average Training Loss: 0.0242\n",
      "    Validation Batch [1/1], Loss: 0.2367\n",
      "Validation Loss: 0.2367, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [890/1000] - Training\n",
      "Epoch [890/1000] completed, Average Training Loss: 0.0215\n",
      "    Validation Batch [1/1], Loss: 0.2173\n",
      "Validation Loss: 0.2173, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [891/1000] - Training\n",
      "Epoch [891/1000] completed, Average Training Loss: 0.0239\n",
      "    Validation Batch [1/1], Loss: 0.1777\n",
      "Validation Loss: 0.1777, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 92/100\n",
      "\n",
      "LOG: Epoch [892/1000] - Training\n",
      "Epoch [892/1000] completed, Average Training Loss: 0.0187\n",
      "    Validation Batch [1/1], Loss: 0.1472\n",
      "Validation Loss: 0.1472, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 93/100\n",
      "\n",
      "LOG: Epoch [893/1000] - Training\n",
      "Epoch [893/1000] completed, Average Training Loss: 0.0190\n",
      "    Validation Batch [1/1], Loss: 0.1234\n",
      "Validation Loss: 0.1234, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 94/100\n",
      "\n",
      "LOG: Epoch [894/1000] - Training\n",
      "Epoch [894/1000] completed, Average Training Loss: 0.0174\n",
      "    Validation Batch [1/1], Loss: 0.1092\n",
      "Validation Loss: 0.1092, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 95/100\n",
      "\n",
      "LOG: Epoch [895/1000] - Training\n",
      "Epoch [895/1000] completed, Average Training Loss: 0.0150\n",
      "    Validation Batch [1/1], Loss: 0.1043\n",
      "Validation Loss: 0.1043, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 96/100\n",
      "\n",
      "LOG: Epoch [896/1000] - Training\n",
      "Epoch [896/1000] completed, Average Training Loss: 0.0164\n",
      "    Validation Batch [1/1], Loss: 0.1001\n",
      "Validation Loss: 0.1001, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 97/100\n",
      "\n",
      "LOG: Epoch [897/1000] - Training\n",
      "Epoch [897/1000] completed, Average Training Loss: 0.0159\n",
      "    Validation Batch [1/1], Loss: 0.1122\n",
      "Validation Loss: 0.1122, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 98/100\n",
      "\n",
      "LOG: Epoch [898/1000] - Training\n",
      "Epoch [898/1000] completed, Average Training Loss: 0.0201\n",
      "    Validation Batch [1/1], Loss: 0.1360\n",
      "Validation Loss: 0.1360, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 99/100\n",
      "\n",
      "LOG: Epoch [899/1000] - Training\n",
      "Epoch [899/1000] completed, Average Training Loss: 0.0165\n",
      "    Validation Batch [1/1], Loss: 0.1563\n",
      "Validation Loss: 0.1563, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 100/100\n",
      "Early stopping triggered at epoch 899. No improvement for 100 epochs.\n",
      "Loading the best model weights...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on the test set...\n",
      "    Test Batch [1/12], Loss: 0.0647\n",
      "\n",
      "Final Test Loss: 0.1177, Test Accuracy: 96.58%\n",
      "Saved E2E CNN predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "#init the model, CrossEntropy loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#getting unique labels from entire dataset (train, validation, test)\n",
    "all_labels = []\n",
    "for loader in [train_loader, val_loader, test_loader]:\n",
    "    for _, labels in loader:\n",
    "        all_labels.extend(labels.tolist())\n",
    "all_labels = np.unique(all_labels)\n",
    "\n",
    "# init model with correct number of classes\n",
    "num_classes = len(all_labels)\n",
    "model = hyperspectralCNN(input_channels=window_num_channels, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#lists to store losses and accuracies\n",
    "classification_epoch_losses = []\n",
    "validation_epoch_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 100\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "best_model_weights = None\n",
    "\n",
    "#training loop + validation with early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    # TRAINING\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs}] - Training\")\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2) \n",
    "        target = target.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        # backward pass + optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accum loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"    Training Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store average training loss per epoch\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    classification_epoch_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] completed, Average Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "            target = target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # accu calculation\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Validation Batch [{batch_idx + 1}/{len(val_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store validation metrics\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    validation_epoch_losses.append(avg_val_loss)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss <= best_val_loss:\n",
    "        print(f\"Validation loss improved from {best_val_loss:.4f} to {avg_val_loss:.4f}. Saving model...\")\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        best_model_weights = model.state_dict()\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {epochs_without_improvement}/{patience}\")\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "# loading the best model weights\n",
    "if best_model_weights is not None:\n",
    "    print(\"Loading the best model weights...\")\n",
    "    model.load_state_dict(best_model_weights)\n",
    "\n",
    "completed_epochs = len(classification_epoch_losses)\n",
    "\n",
    "# plot for loss and accuracy trends over epochs\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), classification_epoch_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, completed_epochs + 1), validation_epoch_losses, label=\"Validation Loss\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), val_accuracies, label=\"Validation Accuracy\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Validation Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#test Set Evaluation\n",
    "print(\"\\nEvaluating on the test set...\")\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "e2ecnn_test_predictions = []\n",
    "e2ecnn_test_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "        target = target.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        #accuracy calc\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "        e2ecnn_test_predictions.extend(predicted.cpu().numpy())\n",
    "        e2ecnn_test_true_labels.extend(target.cpu().numpy())\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 1000 == 0:\n",
    "            print(f\"    Test Batch [{batch_idx + 1}/{len(test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "#calc + print test metrics\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"\\nFinal Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Convert to numpy arrays and save\n",
    "e2e_test_predictions = np.array(e2ecnn_test_predictions)\n",
    "e2e_test_true_labels = np.array(e2ecnn_test_true_labels)\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_predictions.npy'), e2e_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_true_labels.npy'), e2e_test_true_labels)\n",
    "print(f\"Saved E2E CNN predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:16.352518Z",
     "iopub.status.busy": "2025-05-08T19:08:16.351518Z",
     "iopub.status.idle": "2025-05-08T19:08:16.436632Z",
     "shell.execute_reply": "2025-05-08T19:08:16.436632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'e2ecnn_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'e2ecnn_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/12 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'e2ecnn_representations\\test'.\n",
      "E2E CNN representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the cnn representations\n",
    "e2ecnn_rep_dir = \"e2ecnn_representations\"\n",
    "os.makedirs(e2ecnn_rep_dir, exist_ok=True)\n",
    "\n",
    "e2ecnn_loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for e2ecnn_split_name, e2ecnn_loader in e2ecnn_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {e2ecnn_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        e2ecnn_split_dir = os.path.join(e2ecnn_rep_dir, e2ecnn_split_name)\n",
    "        os.makedirs(e2ecnn_split_dir, exist_ok=True)\n",
    "\n",
    "        # processing the data batch-wise\n",
    "        for e2ecnn_batch_idx, (e2ecnn_vectors, e2ecnn_labels) in enumerate(e2ecnn_loader):\n",
    "            e2ecnn_vectors = e2ecnn_vectors.permute(0, 3, 1, 2) \n",
    "            e2ecnn_vectors = e2ecnn_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            e2ecnn_projections = model(e2ecnn_vectors)\n",
    "\n",
    "            # converting projections and labels to np arrays\n",
    "            e2ecnn_projections_np = e2ecnn_projections.cpu().numpy()\n",
    "            e2ecnn_labels_np = e2ecnn_labels.cpu().numpy()\n",
    "\n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_encoded_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_projections_np)\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_labels_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_labels_np)\n",
    "\n",
    "            if (e2ecnn_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {e2ecnn_batch_idx + 1}/{len(e2ecnn_loader)} for {e2ecnn_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {e2ecnn_split_name} dataset. Representations saved in '{e2ecnn_split_dir}'.\")\n",
    "\n",
    "print(\"E2E CNN representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:16.439642Z",
     "iopub.status.busy": "2025-05-08T19:08:16.438652Z",
     "iopub.status.idle": "2025-05-08T19:08:16.442856Z",
     "shell.execute_reply": "2025-05-08T19:08:16.442856Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_cnn_reps_and_labels(split_dir):\n",
    "    #gather all the cnn_encoded_batch npy files in sorted order\n",
    "    cnn_rep_files = sorted(glob.glob(os.path.join(split_dir, \"cnn_encoded_batch_*.npy\")))\n",
    "\n",
    "    cnn_all_reps = []\n",
    "    cnn_all_labels = []\n",
    "\n",
    "    for cnn_rep_file in cnn_rep_files:\n",
    "        #deriving label filenames\n",
    "        cnn_label_file = cnn_rep_file.replace(\"cnn_encoded_batch_\", \"cnn_labels_batch_\")\n",
    "\n",
    "        cnn_reps = np.load(cnn_rep_file)\n",
    "        cnn_labels = np.load(cnn_label_file)\n",
    "\n",
    "        cnn_all_reps.append(cnn_reps)\n",
    "        cnn_all_labels.append(cnn_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    cnn_all_reps = np.concatenate(cnn_all_reps, axis = 0)\n",
    "    cnn_all_labels = np.concatenate(cnn_all_labels, axis = 0)\n",
    "\n",
    "    return cnn_all_reps, cnn_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:16.445865Z",
     "iopub.status.busy": "2025-05-08T19:08:16.444864Z",
     "iopub.status.idle": "2025-05-08T19:08:16.653079Z",
     "shell.execute_reply": "2025-05-08T19:08:16.653079Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_train_dir = os.path.join(\"e2ecnn_representations\", \"train\")\n",
    "cnn_val_dir   = os.path.join(\"e2ecnn_representations\", \"val\")\n",
    "cnn_test_dir  = os.path.join(\"e2ecnn_representations\", \"test\")\n",
    "\n",
    "cnn_train_reps, cnn_train_labels = load_cnn_reps_and_labels(cnn_train_dir)\n",
    "cnn_val_reps, cnn_val_labels = load_cnn_reps_and_labels(cnn_val_dir)\n",
    "cnn_test_reps, cnn_test_labels = load_cnn_reps_and_labels(cnn_test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:16.656087Z",
     "iopub.status.busy": "2025-05-08T19:08:16.655088Z",
     "iopub.status.idle": "2025-05-08T19:08:16.660103Z",
     "shell.execute_reply": "2025-05-08T19:08:16.660103Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_encoded_data(encoded_dir):\n",
    "    print(f\"LOG: Loading encoded data (representations) from {encoded_dir}...\")\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    #iter through batches\n",
    "    for filename in sorted(os.listdir(encoded_dir)):\n",
    "        if filename.startswith('encoded_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load the features\n",
    "            features = np.load(os.path.join(encoded_dir, filename))\n",
    "            features_flat = features.reshape(features.shape[0], -1) #flatten features for LRM\n",
    "            features_list.append(features_flat)\n",
    "        \n",
    "        elif filename.startswith('labels_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load labels\n",
    "            labels = np.load(os.path.join(encoded_dir, filename))\n",
    "            labels_list.append(labels)\n",
    "\n",
    "    #concat all batches into a single array\n",
    "    encoded_features = np.vstack(features_list)\n",
    "    encoded_labels = np.hstack(labels_list)\n",
    "\n",
    "    print(f\"LOG: Loaded {encoded_features.shape[0]} samples with {encoded_features.shape[1]} features each\")\n",
    "    print(f\"LOG: Labels shape: {encoded_labels.shape}\")\n",
    "\n",
    "    return encoded_features, encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:16.662107Z",
     "iopub.status.busy": "2025-05-08T19:08:16.662107Z",
     "iopub.status.idle": "2025-05-08T19:08:16.853050Z",
     "shell.execute_reply": "2025-05-08T19:08:16.853050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 280 samples with 64 features each\n",
      "LOG: Labels shape: (280,)\n",
      "\n",
      "Loading validation data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "\n",
      "Loading test data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2898 samples with 64 features each\n",
      "LOG: Labels shape: (2898,)\n",
      "\n",
      "LOG: Training features shape: (280, 64), Training labels shape: (280,)\n",
      "LOG: Validation features shape: (70, 64), Validation labels shape: (70,)\n",
      "LOG: Test features shape: (2898, 64), Test labels shape: (2898,)\n",
      "\n",
      "LOG: Training Logistic Regression model...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 72.86%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       0.62      1.00      0.77         5\n",
      "           2       1.00      0.60      0.75         5\n",
      "           3       0.80      0.80      0.80         5\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.67      0.40      0.50         5\n",
      "           6       0.83      1.00      0.91         5\n",
      "           7       0.75      0.60      0.67         5\n",
      "           8       0.67      0.80      0.73         5\n",
      "           9       0.44      0.80      0.57         5\n",
      "          10       0.71      1.00      0.83         5\n",
      "          11       0.71      1.00      0.83         5\n",
      "          12       0.50      0.20      0.29         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.73        70\n",
      "   macro avg       0.69      0.73      0.69        70\n",
      "weighted avg       0.69      0.73      0.69        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 78.88%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       245\n",
      "           1       0.43      1.00      0.60        76\n",
      "           2       0.82      0.88      0.85       226\n",
      "           3       0.75      0.86      0.80       190\n",
      "           4       0.85      0.46      0.60       244\n",
      "           5       0.61      0.39      0.47       244\n",
      "           6       0.92      0.97      0.95       234\n",
      "           7       0.77      0.87      0.82       178\n",
      "           8       0.76      0.71      0.73       289\n",
      "           9       0.73      0.85      0.79       223\n",
      "          10       0.90      0.84      0.87       280\n",
      "          11       0.80      1.00      0.89       156\n",
      "          12       0.72      0.66      0.69       243\n",
      "          13       0.91      0.96      0.93        70\n",
      "\n",
      "    accuracy                           0.79      2898\n",
      "   macro avg       0.78      0.82      0.78      2898\n",
      "weighted avg       0.80      0.79      0.78      2898\n",
      "\n",
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vella\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vella\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vella\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "lrm_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "lrm_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "lrm_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "print(\"\\nLoading training data for LRM...\")\n",
    "lrm_train_features, lrm_train_labels = load_encoded_data(lrm_encoded_train_dir)\n",
    "\n",
    "print(\"\\nLoading validation data for LRM...\")\n",
    "lrm_val_features, lrm_val_labels = load_encoded_data(lrm_encoded_val_dir)\n",
    "\n",
    "print(\"\\nLoading test data for LRM...\")\n",
    "lrm_test_features, lrm_test_labels = load_encoded_data(lrm_encoded_test_dir)\n",
    "\n",
    "#verify shapes\n",
    "print(f\"\\nLOG: Training features shape: {lrm_train_features.shape}, Training labels shape: {lrm_train_labels.shape}\")\n",
    "print(f\"LOG: Validation features shape: {lrm_val_features.shape}, Validation labels shape: {lrm_val_labels.shape}\")\n",
    "print(f\"LOG: Test features shape: {lrm_test_features.shape}, Test labels shape: {lrm_test_labels.shape}\")\n",
    "\n",
    "print(\"\\nLOG: Training Logistic Regression model...\")\n",
    "logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight = 'balanced')\n",
    "logistic_clf.fit(lrm_train_features, lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "#eval on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "lrm_val_predictions = logistic_clf.predict(lrm_val_features)\n",
    "lrm_val_accuracy = accuracy_score(lrm_val_labels, lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(lrm_val_labels, lrm_val_predictions))\n",
    "\n",
    "#eval on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "lrm_test_predictions = logistic_clf.predict(lrm_test_features)\n",
    "lrm_test_accuracy = accuracy_score(lrm_test_labels, lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(lrm_test_labels, lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_predictions.npy'), lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_true_labels.npy'), lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying CAE Embeddings with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:16.856059Z",
     "iopub.status.busy": "2025-05-08T19:08:16.856059Z",
     "iopub.status.idle": "2025-05-08T19:08:16.860085Z",
     "shell.execute_reply": "2025-05-08T19:08:16.860085Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:16.863096Z",
     "iopub.status.busy": "2025-05-08T19:08:16.862093Z",
     "iopub.status.idle": "2025-05-08T19:08:16.871602Z",
     "shell.execute_reply": "2025-05-08T19:08:16.871602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 280 samples with 64 features each\n",
      "LOG: Labels shape: (280,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2898 samples with 64 features each\n",
      "LOG: Labels shape: (2898,)\n",
      "Train reps shape: (280, 64)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 64)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 64)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "cae_mlp_train_dir = os.path.join(\"encoded_representations\", \"train\")\n",
    "cae_mlp_val_dir   = os.path.join(\"encoded_representations\", \"val\")\n",
    "cae_mlp_test_dir  = os.path.join(\"encoded_representations\", \"test\")\n",
    "\n",
    "cae_mlp_train_reps, cae_mlp_train_labels = load_encoded_data(cae_mlp_train_dir)\n",
    "cae_mlp_val_reps, cae_mlp_val_labels = load_encoded_data(cae_mlp_val_dir)\n",
    "cae_mlp_test_reps, cae_mlp_test_labels = load_encoded_data(cae_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",cae_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", cae_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", cae_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", cae_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", cae_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", cae_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:16.873847Z",
     "iopub.status.busy": "2025-05-08T19:08:16.873847Z",
     "iopub.status.idle": "2025-05-08T19:08:16.879611Z",
     "shell.execute_reply": "2025-05-08T19:08:16.879103Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "cae_mlp_train_embeddings_torch = torch.tensor(cae_mlp_train_reps, dtype=torch.float32)\n",
    "cae_mlp_train_labels_torch = torch.tensor(cae_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_val_embeddings_torch = torch.tensor(cae_mlp_val_reps, dtype=torch.float32)\n",
    "cae_mlp_val_labels_torch = torch.tensor(cae_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_test_embeddings_torch = torch.tensor(cae_mlp_test_reps, dtype=torch.float32)\n",
    "cae_mlp_test_labels_torch = torch.tensor(cae_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "cae_mlp_train_dataset = TensorDataset(cae_mlp_train_embeddings_torch, cae_mlp_train_labels_torch)\n",
    "cae_mlp_val_dataset = TensorDataset(cae_mlp_val_embeddings_torch, cae_mlp_val_labels_torch)\n",
    "cae_mlp_test_dataset = TensorDataset(cae_mlp_test_embeddings_torch, cae_mlp_test_labels_torch)\n",
    "\n",
    "cae_mlp_batch_size = 64\n",
    "cae_mlp_train_loader = DataLoader(cae_mlp_train_dataset, batch_size=cae_mlp_batch_size, shuffle=True)\n",
    "cae_mlp_val_loader = DataLoader(cae_mlp_val_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n",
    "cae_mlp_test_loader = DataLoader(cae_mlp_test_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:16.881616Z",
     "iopub.status.busy": "2025-05-08T19:08:16.881616Z",
     "iopub.status.idle": "2025-05-08T19:08:22.079468Z",
     "shell.execute_reply": "2025-05-08T19:08:22.079468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.7791  |  Val Loss: 2.6683\n",
      "Validation loss improved from inf to 2.6683.\n",
      "[Epoch 2/1000] Train Loss: 2.6540  |  Val Loss: 2.6288\n",
      "Validation loss improved from 2.6683 to 2.6288.\n",
      "[Epoch 3/1000] Train Loss: 2.6228  |  Val Loss: 2.6118\n",
      "Validation loss improved from 2.6288 to 2.6118.\n",
      "[Epoch 4/1000] Train Loss: 2.6103  |  Val Loss: 2.6055\n",
      "Validation loss improved from 2.6118 to 2.6055.\n",
      "[Epoch 5/1000] Train Loss: 2.6052  |  Val Loss: 2.5986\n",
      "Validation loss improved from 2.6055 to 2.5986.\n",
      "[Epoch 6/1000] Train Loss: 2.5949  |  Val Loss: 2.5867\n",
      "Validation loss improved from 2.5986 to 2.5867.\n",
      "[Epoch 7/1000] Train Loss: 2.5857  |  Val Loss: 2.5801\n",
      "Validation loss improved from 2.5867 to 2.5801.\n",
      "[Epoch 8/1000] Train Loss: 2.5785  |  Val Loss: 2.5638\n",
      "Validation loss improved from 2.5801 to 2.5638.\n",
      "[Epoch 9/1000] Train Loss: 2.5627  |  Val Loss: 2.5491\n",
      "Validation loss improved from 2.5638 to 2.5491.\n",
      "[Epoch 10/1000] Train Loss: 2.5497  |  Val Loss: 2.5345\n",
      "Validation loss improved from 2.5491 to 2.5345.\n",
      "[Epoch 11/1000] Train Loss: 2.5388  |  Val Loss: 2.5198\n",
      "Validation loss improved from 2.5345 to 2.5198.\n",
      "[Epoch 12/1000] Train Loss: 2.5179  |  Val Loss: 2.5028\n",
      "Validation loss improved from 2.5198 to 2.5028.\n",
      "[Epoch 13/1000] Train Loss: 2.5031  |  Val Loss: 2.4791\n",
      "Validation loss improved from 2.5028 to 2.4791.\n",
      "[Epoch 14/1000] Train Loss: 2.4808  |  Val Loss: 2.4558\n",
      "Validation loss improved from 2.4791 to 2.4558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/1000] Train Loss: 2.4598  |  Val Loss: 2.4256\n",
      "Validation loss improved from 2.4558 to 2.4256.\n",
      "[Epoch 16/1000] Train Loss: 2.4296  |  Val Loss: 2.3979\n",
      "Validation loss improved from 2.4256 to 2.3979.\n",
      "[Epoch 17/1000] Train Loss: 2.4005  |  Val Loss: 2.3704\n",
      "Validation loss improved from 2.3979 to 2.3704.\n",
      "[Epoch 18/1000] Train Loss: 2.3694  |  Val Loss: 2.3328\n",
      "Validation loss improved from 2.3704 to 2.3328.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/1000] Train Loss: 2.3349  |  Val Loss: 2.2984\n",
      "Validation loss improved from 2.3328 to 2.2984.\n",
      "[Epoch 20/1000] Train Loss: 2.3045  |  Val Loss: 2.2607\n",
      "Validation loss improved from 2.2984 to 2.2607.\n",
      "[Epoch 21/1000] Train Loss: 2.2751  |  Val Loss: 2.2202\n",
      "Validation loss improved from 2.2607 to 2.2202.\n",
      "[Epoch 22/1000] Train Loss: 2.2298  |  Val Loss: 2.1800\n",
      "Validation loss improved from 2.2202 to 2.1800.\n",
      "[Epoch 23/1000] Train Loss: 2.1862  |  Val Loss: 2.1416\n",
      "Validation loss improved from 2.1800 to 2.1416.\n",
      "[Epoch 24/1000] Train Loss: 2.1545  |  Val Loss: 2.1073\n",
      "Validation loss improved from 2.1416 to 2.1073.\n",
      "[Epoch 25/1000] Train Loss: 2.1078  |  Val Loss: 2.0589\n",
      "Validation loss improved from 2.1073 to 2.0589.\n",
      "[Epoch 26/1000] Train Loss: 2.0697  |  Val Loss: 2.0242\n",
      "Validation loss improved from 2.0589 to 2.0242.\n",
      "[Epoch 27/1000] Train Loss: 2.0378  |  Val Loss: 1.9908\n",
      "Validation loss improved from 2.0242 to 1.9908.\n",
      "[Epoch 28/1000] Train Loss: 1.9963  |  Val Loss: 1.9502\n",
      "Validation loss improved from 1.9908 to 1.9502.\n",
      "[Epoch 29/1000] Train Loss: 1.9592  |  Val Loss: 1.9234\n",
      "Validation loss improved from 1.9502 to 1.9234.\n",
      "[Epoch 30/1000] Train Loss: 1.9256  |  Val Loss: 1.8702\n",
      "Validation loss improved from 1.9234 to 1.8702.\n",
      "[Epoch 31/1000] Train Loss: 1.8845  |  Val Loss: 1.8374\n",
      "Validation loss improved from 1.8702 to 1.8374.\n",
      "[Epoch 32/1000] Train Loss: 1.8611  |  Val Loss: 1.8092\n",
      "Validation loss improved from 1.8374 to 1.8092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33/1000] Train Loss: 1.8258  |  Val Loss: 1.8245\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 34/1000] Train Loss: 1.8223  |  Val Loss: 1.7593\n",
      "Validation loss improved from 1.8092 to 1.7593.\n",
      "[Epoch 35/1000] Train Loss: 1.7796  |  Val Loss: 1.7206\n",
      "Validation loss improved from 1.7593 to 1.7206.\n",
      "[Epoch 36/1000] Train Loss: 1.7483  |  Val Loss: 1.7114\n",
      "Validation loss improved from 1.7206 to 1.7114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37/1000] Train Loss: 1.7152  |  Val Loss: 1.6947\n",
      "Validation loss improved from 1.7114 to 1.6947.\n",
      "[Epoch 38/1000] Train Loss: 1.7107  |  Val Loss: 1.7039\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 39/1000] Train Loss: 1.6814  |  Val Loss: 1.6379\n",
      "Validation loss improved from 1.6947 to 1.6379.\n",
      "[Epoch 40/1000] Train Loss: 1.6587  |  Val Loss: 1.6156\n",
      "Validation loss improved from 1.6379 to 1.6156.\n",
      "[Epoch 41/1000] Train Loss: 1.6320  |  Val Loss: 1.6072\n",
      "Validation loss improved from 1.6156 to 1.6072.\n",
      "[Epoch 42/1000] Train Loss: 1.6108  |  Val Loss: 1.5864\n",
      "Validation loss improved from 1.6072 to 1.5864.\n",
      "[Epoch 43/1000] Train Loss: 1.6019  |  Val Loss: 1.6078\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 44/1000] Train Loss: 1.5785  |  Val Loss: 1.5545\n",
      "Validation loss improved from 1.5864 to 1.5545.\n",
      "[Epoch 45/1000] Train Loss: 1.5759  |  Val Loss: 1.5521\n",
      "Validation loss improved from 1.5545 to 1.5521.\n",
      "[Epoch 46/1000] Train Loss: 1.5550  |  Val Loss: 1.5441\n",
      "Validation loss improved from 1.5521 to 1.5441.\n",
      "[Epoch 47/1000] Train Loss: 1.5316  |  Val Loss: 1.5118\n",
      "Validation loss improved from 1.5441 to 1.5118.\n",
      "[Epoch 48/1000] Train Loss: 1.5161  |  Val Loss: 1.5083\n",
      "Validation loss improved from 1.5118 to 1.5083.\n",
      "[Epoch 49/1000] Train Loss: 1.5026  |  Val Loss: 1.5040\n",
      "Validation loss improved from 1.5083 to 1.5040.\n",
      "[Epoch 50/1000] Train Loss: 1.4987  |  Val Loss: 1.4977\n",
      "Validation loss improved from 1.5040 to 1.4977.\n",
      "[Epoch 51/1000] Train Loss: 1.4912  |  Val Loss: 1.5012\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 52/1000] Train Loss: 1.4765  |  Val Loss: 1.4748\n",
      "Validation loss improved from 1.4977 to 1.4748.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 53/1000] Train Loss: 1.4656  |  Val Loss: 1.4644\n",
      "Validation loss improved from 1.4748 to 1.4644.\n",
      "[Epoch 54/1000] Train Loss: 1.4612  |  Val Loss: 1.4402\n",
      "Validation loss improved from 1.4644 to 1.4402.\n",
      "[Epoch 55/1000] Train Loss: 1.4415  |  Val Loss: 1.4641\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 56/1000] Train Loss: 1.4364  |  Val Loss: 1.4651\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 57/1000] Train Loss: 1.4283  |  Val Loss: 1.4193\n",
      "Validation loss improved from 1.4402 to 1.4193.\n",
      "[Epoch 58/1000] Train Loss: 1.4160  |  Val Loss: 1.4274\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 59/1000] Train Loss: 1.4132  |  Val Loss: 1.4279\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 60/1000] Train Loss: 1.4162  |  Val Loss: 1.4061\n",
      "Validation loss improved from 1.4193 to 1.4061.\n",
      "[Epoch 61/1000] Train Loss: 1.4017  |  Val Loss: 1.4122\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 62/1000] Train Loss: 1.3862  |  Val Loss: 1.4118\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 63/1000] Train Loss: 1.3827  |  Val Loss: 1.4117\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 64/1000] Train Loss: 1.3936  |  Val Loss: 1.3767\n",
      "Validation loss improved from 1.4061 to 1.3767.\n",
      "[Epoch 65/1000] Train Loss: 1.3922  |  Val Loss: 1.3772\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 66/1000] Train Loss: 1.3694  |  Val Loss: 1.3986\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 67/1000] Train Loss: 1.3662  |  Val Loss: 1.4120\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 68/1000] Train Loss: 1.3601  |  Val Loss: 1.3611\n",
      "Validation loss improved from 1.3767 to 1.3611.\n",
      "[Epoch 69/1000] Train Loss: 1.3476  |  Val Loss: 1.3667\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 70/1000] Train Loss: 1.3433  |  Val Loss: 1.3641\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 71/1000] Train Loss: 1.3407  |  Val Loss: 1.3770\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 72/1000] Train Loss: 1.3365  |  Val Loss: 1.3645\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 73/1000] Train Loss: 1.3279  |  Val Loss: 1.3615\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 74/1000] Train Loss: 1.3223  |  Val Loss: 1.3417\n",
      "Validation loss improved from 1.3611 to 1.3417.\n",
      "[Epoch 75/1000] Train Loss: 1.3302  |  Val Loss: 1.3762\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 76/1000] Train Loss: 1.3205  |  Val Loss: 1.3398\n",
      "Validation loss improved from 1.3417 to 1.3398.\n",
      "[Epoch 77/1000] Train Loss: 1.3250  |  Val Loss: 1.3509\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 78/1000] Train Loss: 1.3038  |  Val Loss: 1.3464\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 79/1000] Train Loss: 1.3068  |  Val Loss: 1.3579\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 80/1000] Train Loss: 1.3101  |  Val Loss: 1.3569\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 81/1000] Train Loss: 1.3064  |  Val Loss: 1.3527\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 82/1000] Train Loss: 1.3253  |  Val Loss: 1.3359\n",
      "Validation loss improved from 1.3398 to 1.3359.\n",
      "[Epoch 83/1000] Train Loss: 1.3060  |  Val Loss: 1.3803\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 84/1000] Train Loss: 1.3003  |  Val Loss: 1.3184\n",
      "Validation loss improved from 1.3359 to 1.3184.\n",
      "[Epoch 85/1000] Train Loss: 1.2870  |  Val Loss: 1.4004\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 86/1000] Train Loss: 1.3027  |  Val Loss: 1.3223\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 87/1000] Train Loss: 1.2992  |  Val Loss: 1.3194\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 88/1000] Train Loss: 1.2856  |  Val Loss: 1.3259\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 89/1000] Train Loss: 1.2740  |  Val Loss: 1.3178\n",
      "Validation loss improved from 1.3184 to 1.3178.\n",
      "[Epoch 90/1000] Train Loss: 1.2731  |  Val Loss: 1.3495\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 91/1000] Train Loss: 1.2977  |  Val Loss: 1.3113\n",
      "Validation loss improved from 1.3178 to 1.3113.\n",
      "[Epoch 92/1000] Train Loss: 1.2937  |  Val Loss: 1.3224\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 93/1000] Train Loss: 1.2961  |  Val Loss: 1.3804\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 94/1000] Train Loss: 1.3059  |  Val Loss: 1.3301\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 95/1000] Train Loss: 1.2841  |  Val Loss: 1.3212\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 96/1000] Train Loss: 1.2611  |  Val Loss: 1.3087\n",
      "Validation loss improved from 1.3113 to 1.3087.\n",
      "[Epoch 97/1000] Train Loss: 1.2730  |  Val Loss: 1.3147\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 98/1000] Train Loss: 1.2639  |  Val Loss: 1.3247\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 99/1000] Train Loss: 1.2592  |  Val Loss: 1.3142\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 100/1000] Train Loss: 1.2531  |  Val Loss: 1.3112\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 101/1000] Train Loss: 1.2603  |  Val Loss: 1.3143\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 102/1000] Train Loss: 1.2673  |  Val Loss: 1.3531\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 103/1000] Train Loss: 1.2503  |  Val Loss: 1.3102\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 104/1000] Train Loss: 1.2471  |  Val Loss: 1.3053\n",
      "Validation loss improved from 1.3087 to 1.3053.\n",
      "[Epoch 105/1000] Train Loss: 1.2501  |  Val Loss: 1.3179\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 106/1000] Train Loss: 1.2415  |  Val Loss: 1.2921\n",
      "Validation loss improved from 1.3053 to 1.2921.\n",
      "[Epoch 107/1000] Train Loss: 1.2440  |  Val Loss: 1.3040\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 108/1000] Train Loss: 1.2550  |  Val Loss: 1.3034\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 109/1000] Train Loss: 1.2505  |  Val Loss: 1.2974\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 110/1000] Train Loss: 1.2309  |  Val Loss: 1.3232\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 111/1000] Train Loss: 1.2421  |  Val Loss: 1.3463\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 112/1000] Train Loss: 1.2507  |  Val Loss: 1.3509\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 113/1000] Train Loss: 1.2800  |  Val Loss: 1.2969\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 114/1000] Train Loss: 1.2716  |  Val Loss: 1.2873\n",
      "Validation loss improved from 1.2921 to 1.2873.\n",
      "[Epoch 115/1000] Train Loss: 1.2330  |  Val Loss: 1.2978\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 116/1000] Train Loss: 1.2282  |  Val Loss: 1.3609\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 117/1000] Train Loss: 1.2388  |  Val Loss: 1.2794\n",
      "Validation loss improved from 1.2873 to 1.2794.\n",
      "[Epoch 118/1000] Train Loss: 1.2278  |  Val Loss: 1.3049\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 119/1000] Train Loss: 1.2243  |  Val Loss: 1.3029\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 120/1000] Train Loss: 1.2346  |  Val Loss: 1.2842\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 121/1000] Train Loss: 1.2462  |  Val Loss: 1.2845\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 122/1000] Train Loss: 1.2444  |  Val Loss: 1.2827\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 123/1000] Train Loss: 1.2540  |  Val Loss: 1.4165\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 124/1000] Train Loss: 1.2511  |  Val Loss: 1.2993\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 125/1000] Train Loss: 1.2682  |  Val Loss: 1.2959\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 126/1000] Train Loss: 1.2457  |  Val Loss: 1.3800\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 127/1000] Train Loss: 1.2317  |  Val Loss: 1.2817\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 128/1000] Train Loss: 1.2335  |  Val Loss: 1.2924\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 129/1000] Train Loss: 1.2408  |  Val Loss: 1.3127\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 130/1000] Train Loss: 1.2171  |  Val Loss: 1.3225\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 131/1000] Train Loss: 1.2132  |  Val Loss: 1.2992\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 132/1000] Train Loss: 1.2215  |  Val Loss: 1.2593\n",
      "Validation loss improved from 1.2794 to 1.2593.\n",
      "[Epoch 133/1000] Train Loss: 1.2075  |  Val Loss: 1.3614\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 134/1000] Train Loss: 1.2452  |  Val Loss: 1.3104\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 135/1000] Train Loss: 1.2076  |  Val Loss: 1.2861\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 136/1000] Train Loss: 1.2084  |  Val Loss: 1.3014\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 137/1000] Train Loss: 1.2009  |  Val Loss: 1.3094\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 138/1000] Train Loss: 1.1941  |  Val Loss: 1.2792\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 139/1000] Train Loss: 1.1914  |  Val Loss: 1.2800\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 140/1000] Train Loss: 1.2037  |  Val Loss: 1.2657\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 141/1000] Train Loss: 1.2007  |  Val Loss: 1.2723\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 142/1000] Train Loss: 1.1918  |  Val Loss: 1.2833\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 143/1000] Train Loss: 1.1876  |  Val Loss: 1.3007\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 144/1000] Train Loss: 1.1905  |  Val Loss: 1.2827\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 145/1000] Train Loss: 1.1857  |  Val Loss: 1.2728\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 146/1000] Train Loss: 1.1903  |  Val Loss: 1.2933\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 147/1000] Train Loss: 1.1865  |  Val Loss: 1.2518\n",
      "Validation loss improved from 1.2593 to 1.2518.\n",
      "[Epoch 148/1000] Train Loss: 1.1823  |  Val Loss: 1.2952\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 149/1000] Train Loss: 1.1830  |  Val Loss: 1.2897\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 150/1000] Train Loss: 1.1839  |  Val Loss: 1.2725\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 151/1000] Train Loss: 1.1805  |  Val Loss: 1.2697\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 152/1000] Train Loss: 1.1985  |  Val Loss: 1.2803\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 153/1000] Train Loss: 1.1839  |  Val Loss: 1.3461\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 154/1000] Train Loss: 1.2104  |  Val Loss: 1.2930\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 155/1000] Train Loss: 1.1975  |  Val Loss: 1.3050\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 156/1000] Train Loss: 1.1739  |  Val Loss: 1.2688\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 157/1000] Train Loss: 1.2042  |  Val Loss: 1.3254\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 158/1000] Train Loss: 1.2126  |  Val Loss: 1.3037\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 159/1000] Train Loss: 1.1806  |  Val Loss: 1.2604\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 160/1000] Train Loss: 1.2034  |  Val Loss: 1.2715\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 161/1000] Train Loss: 1.2021  |  Val Loss: 1.4057\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 162/1000] Train Loss: 1.2087  |  Val Loss: 1.2589\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 163/1000] Train Loss: 1.2072  |  Val Loss: 1.2592\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 164/1000] Train Loss: 1.1990  |  Val Loss: 1.2937\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 165/1000] Train Loss: 1.1651  |  Val Loss: 1.2369\n",
      "Validation loss improved from 1.2518 to 1.2369.\n",
      "[Epoch 166/1000] Train Loss: 1.1745  |  Val Loss: 1.2720\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 167/1000] Train Loss: 1.1935  |  Val Loss: 1.3975\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 168/1000] Train Loss: 1.2094  |  Val Loss: 1.2553\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 169/1000] Train Loss: 1.1763  |  Val Loss: 1.3423\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 170/1000] Train Loss: 1.1875  |  Val Loss: 1.2598\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 171/1000] Train Loss: 1.1816  |  Val Loss: 1.2464\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 172/1000] Train Loss: 1.1741  |  Val Loss: 1.4241\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 173/1000] Train Loss: 1.1779  |  Val Loss: 1.2283\n",
      "Validation loss improved from 1.2369 to 1.2283.\n",
      "[Epoch 174/1000] Train Loss: 1.1709  |  Val Loss: 1.5137\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 175/1000] Train Loss: 1.2621  |  Val Loss: 1.2837\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 176/1000] Train Loss: 1.2130  |  Val Loss: 1.2277\n",
      "Validation loss improved from 1.2283 to 1.2277.\n",
      "[Epoch 177/1000] Train Loss: 1.1831  |  Val Loss: 1.4252\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 178/1000] Train Loss: 1.1918  |  Val Loss: 1.2403\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 179/1000] Train Loss: 1.2092  |  Val Loss: 1.2732\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 180/1000] Train Loss: 1.1759  |  Val Loss: 1.3197\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 181/1000] Train Loss: 1.1618  |  Val Loss: 1.2487\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 182/1000] Train Loss: 1.1694  |  Val Loss: 1.2980\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 183/1000] Train Loss: 1.1488  |  Val Loss: 1.2704\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 184/1000] Train Loss: 1.1476  |  Val Loss: 1.3367\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 185/1000] Train Loss: 1.1763  |  Val Loss: 1.2329\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 186/1000] Train Loss: 1.1503  |  Val Loss: 1.2766\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 187/1000] Train Loss: 1.1508  |  Val Loss: 1.2554\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 188/1000] Train Loss: 1.1501  |  Val Loss: 1.3731\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 189/1000] Train Loss: 1.1889  |  Val Loss: 1.2362\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 190/1000] Train Loss: 1.1821  |  Val Loss: 1.3251\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 191/1000] Train Loss: 1.2048  |  Val Loss: 1.3138\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 192/1000] Train Loss: 1.1752  |  Val Loss: 1.2805\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 193/1000] Train Loss: 1.1581  |  Val Loss: 1.3145\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 194/1000] Train Loss: 1.1739  |  Val Loss: 1.2864\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 195/1000] Train Loss: 1.1494  |  Val Loss: 1.2339\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 196/1000] Train Loss: 1.1592  |  Val Loss: 1.3824\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 197/1000] Train Loss: 1.1792  |  Val Loss: 1.2317\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 198/1000] Train Loss: 1.1403  |  Val Loss: 1.3652\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 199/1000] Train Loss: 1.1620  |  Val Loss: 1.2972\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 200/1000] Train Loss: 1.2018  |  Val Loss: 1.2279\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 201/1000] Train Loss: 1.1607  |  Val Loss: 1.2820\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 202/1000] Train Loss: 1.1444  |  Val Loss: 1.3230\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 203/1000] Train Loss: 1.1494  |  Val Loss: 1.2634\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 204/1000] Train Loss: 1.1646  |  Val Loss: 1.3266\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 205/1000] Train Loss: 1.1303  |  Val Loss: 1.2276\n",
      "Validation loss improved from 1.2277 to 1.2276.\n",
      "[Epoch 206/1000] Train Loss: 1.1328  |  Val Loss: 1.2717\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 207/1000] Train Loss: 1.1255  |  Val Loss: 1.2479\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 208/1000] Train Loss: 1.1261  |  Val Loss: 1.2867\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 209/1000] Train Loss: 1.1260  |  Val Loss: 1.2349\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 210/1000] Train Loss: 1.1559  |  Val Loss: 1.3136\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 211/1000] Train Loss: 1.1419  |  Val Loss: 1.2966\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 212/1000] Train Loss: 1.1408  |  Val Loss: 1.2996\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 213/1000] Train Loss: 1.1784  |  Val Loss: 1.4877\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 214/1000] Train Loss: 1.1916  |  Val Loss: 1.2261\n",
      "Validation loss improved from 1.2276 to 1.2261.\n",
      "[Epoch 215/1000] Train Loss: 1.1560  |  Val Loss: 1.2455\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 216/1000] Train Loss: 1.1397  |  Val Loss: 1.2650\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 217/1000] Train Loss: 1.1213  |  Val Loss: 1.2297\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 218/1000] Train Loss: 1.1388  |  Val Loss: 1.3086\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 219/1000] Train Loss: 1.1432  |  Val Loss: 1.2877\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 220/1000] Train Loss: 1.1142  |  Val Loss: 1.2760\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 221/1000] Train Loss: 1.1180  |  Val Loss: 1.2492\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 222/1000] Train Loss: 1.1217  |  Val Loss: 1.2797\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 223/1000] Train Loss: 1.1209  |  Val Loss: 1.2870\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 224/1000] Train Loss: 1.1381  |  Val Loss: 1.2332\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 225/1000] Train Loss: 1.1303  |  Val Loss: 1.3675\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 226/1000] Train Loss: 1.1494  |  Val Loss: 1.2543\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 227/1000] Train Loss: 1.1789  |  Val Loss: 1.3710\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 228/1000] Train Loss: 1.1511  |  Val Loss: 1.2083\n",
      "Validation loss improved from 1.2261 to 1.2083.\n",
      "[Epoch 229/1000] Train Loss: 1.1065  |  Val Loss: 1.2789\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 230/1000] Train Loss: 1.1335  |  Val Loss: 1.2887\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 231/1000] Train Loss: 1.1317  |  Val Loss: 1.2192\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 232/1000] Train Loss: 1.1459  |  Val Loss: 1.3608\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 233/1000] Train Loss: 1.1190  |  Val Loss: 1.2290\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 234/1000] Train Loss: 1.0999  |  Val Loss: 1.3247\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 235/1000] Train Loss: 1.0990  |  Val Loss: 1.2209\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 236/1000] Train Loss: 1.1248  |  Val Loss: 1.2695\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 237/1000] Train Loss: 1.0994  |  Val Loss: 1.2740\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 238/1000] Train Loss: 1.0843  |  Val Loss: 1.2617\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 239/1000] Train Loss: 1.0959  |  Val Loss: 1.2893\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 240/1000] Train Loss: 1.0984  |  Val Loss: 1.2365\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 241/1000] Train Loss: 1.0953  |  Val Loss: 1.2218\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 242/1000] Train Loss: 1.1021  |  Val Loss: 1.2533\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 243/1000] Train Loss: 1.0821  |  Val Loss: 1.2774\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 244/1000] Train Loss: 1.0967  |  Val Loss: 1.2449\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 245/1000] Train Loss: 1.0955  |  Val Loss: 1.3206\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 246/1000] Train Loss: 1.0926  |  Val Loss: 1.2290\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 247/1000] Train Loss: 1.1032  |  Val Loss: 1.2171\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 248/1000] Train Loss: 1.1087  |  Val Loss: 1.2936\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 249/1000] Train Loss: 1.0924  |  Val Loss: 1.2306\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 250/1000] Train Loss: 1.0838  |  Val Loss: 1.2515\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 251/1000] Train Loss: 1.0777  |  Val Loss: 1.2558\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 252/1000] Train Loss: 1.0942  |  Val Loss: 1.3089\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 253/1000] Train Loss: 1.0826  |  Val Loss: 1.2285\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 254/1000] Train Loss: 1.0867  |  Val Loss: 1.3107\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 255/1000] Train Loss: 1.0728  |  Val Loss: 1.2076\n",
      "Validation loss improved from 1.2083 to 1.2076.\n",
      "[Epoch 256/1000] Train Loss: 1.0926  |  Val Loss: 1.3182\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 257/1000] Train Loss: 1.0869  |  Val Loss: 1.2357\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 258/1000] Train Loss: 1.0694  |  Val Loss: 1.2976\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 259/1000] Train Loss: 1.0818  |  Val Loss: 1.2458\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 260/1000] Train Loss: 1.0804  |  Val Loss: 1.2731\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 261/1000] Train Loss: 1.0901  |  Val Loss: 1.2388\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 262/1000] Train Loss: 1.0775  |  Val Loss: 1.2085\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 263/1000] Train Loss: 1.1335  |  Val Loss: 1.3897\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 264/1000] Train Loss: 1.0894  |  Val Loss: 1.2053\n",
      "Validation loss improved from 1.2076 to 1.2053.\n",
      "[Epoch 265/1000] Train Loss: 1.0556  |  Val Loss: 1.3482\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 266/1000] Train Loss: 1.0891  |  Val Loss: 1.2101\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 267/1000] Train Loss: 1.1193  |  Val Loss: 1.1969\n",
      "Validation loss improved from 1.2053 to 1.1969.\n",
      "[Epoch 268/1000] Train Loss: 1.1003  |  Val Loss: 1.4539\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 269/1000] Train Loss: 1.1562  |  Val Loss: 1.2320\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 270/1000] Train Loss: 1.1422  |  Val Loss: 1.4339\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 271/1000] Train Loss: 1.1392  |  Val Loss: 1.2136\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 272/1000] Train Loss: 1.1065  |  Val Loss: 1.2140\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 273/1000] Train Loss: 1.1219  |  Val Loss: 1.3062\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 274/1000] Train Loss: 1.1280  |  Val Loss: 1.2391\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 275/1000] Train Loss: 1.1139  |  Val Loss: 1.3404\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 276/1000] Train Loss: 1.0818  |  Val Loss: 1.2391\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 277/1000] Train Loss: 1.1186  |  Val Loss: 1.2111\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 278/1000] Train Loss: 1.0912  |  Val Loss: 1.2650\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 279/1000] Train Loss: 1.0546  |  Val Loss: 1.2103\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 280/1000] Train Loss: 1.0511  |  Val Loss: 1.2570\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 281/1000] Train Loss: 1.0508  |  Val Loss: 1.2694\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 282/1000] Train Loss: 1.0555  |  Val Loss: 1.2139\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 283/1000] Train Loss: 1.0656  |  Val Loss: 1.2434\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 284/1000] Train Loss: 1.0566  |  Val Loss: 1.2347\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 285/1000] Train Loss: 1.0322  |  Val Loss: 1.2622\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 286/1000] Train Loss: 1.0548  |  Val Loss: 1.2480\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 287/1000] Train Loss: 1.0462  |  Val Loss: 1.2913\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 288/1000] Train Loss: 1.0416  |  Val Loss: 1.2153\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 289/1000] Train Loss: 1.0701  |  Val Loss: 1.3162\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 290/1000] Train Loss: 1.0515  |  Val Loss: 1.2323\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 291/1000] Train Loss: 1.1130  |  Val Loss: 1.3126\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 292/1000] Train Loss: 1.1358  |  Val Loss: 1.2631\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 293/1000] Train Loss: 1.1475  |  Val Loss: 1.2922\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 294/1000] Train Loss: 1.1186  |  Val Loss: 1.2422\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 295/1000] Train Loss: 1.1036  |  Val Loss: 1.2471\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 296/1000] Train Loss: 1.0918  |  Val Loss: 1.2756\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 297/1000] Train Loss: 1.0645  |  Val Loss: 1.2924\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 298/1000] Train Loss: 1.0902  |  Val Loss: 1.2421\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 299/1000] Train Loss: 1.0675  |  Val Loss: 1.2630\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 300/1000] Train Loss: 1.0378  |  Val Loss: 1.1884\n",
      "Validation loss improved from 1.1969 to 1.1884.\n",
      "[Epoch 301/1000] Train Loss: 1.0636  |  Val Loss: 1.3257\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 302/1000] Train Loss: 1.0661  |  Val Loss: 1.2095\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 303/1000] Train Loss: 1.0706  |  Val Loss: 1.3203\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 304/1000] Train Loss: 1.0804  |  Val Loss: 1.2300\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 305/1000] Train Loss: 1.0597  |  Val Loss: 1.3067\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 306/1000] Train Loss: 1.0830  |  Val Loss: 1.2012\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 307/1000] Train Loss: 1.1320  |  Val Loss: 1.3559\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 308/1000] Train Loss: 1.0596  |  Val Loss: 1.1858\n",
      "Validation loss improved from 1.1884 to 1.1858.\n",
      "[Epoch 309/1000] Train Loss: 1.1400  |  Val Loss: 1.2747\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 310/1000] Train Loss: 1.0384  |  Val Loss: 1.2165\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 311/1000] Train Loss: 1.0653  |  Val Loss: 1.2381\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 312/1000] Train Loss: 1.0453  |  Val Loss: 1.1845\n",
      "Validation loss improved from 1.1858 to 1.1845.\n",
      "[Epoch 313/1000] Train Loss: 1.0714  |  Val Loss: 1.3013\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 314/1000] Train Loss: 1.0451  |  Val Loss: 1.2177\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 315/1000] Train Loss: 1.0326  |  Val Loss: 1.2250\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 316/1000] Train Loss: 1.0147  |  Val Loss: 1.3045\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 317/1000] Train Loss: 1.0374  |  Val Loss: 1.2016\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 318/1000] Train Loss: 1.0828  |  Val Loss: 1.3740\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 319/1000] Train Loss: 1.0209  |  Val Loss: 1.1903\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 320/1000] Train Loss: 1.0495  |  Val Loss: 1.2950\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 321/1000] Train Loss: 1.0238  |  Val Loss: 1.1975\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 322/1000] Train Loss: 1.0230  |  Val Loss: 1.2612\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 323/1000] Train Loss: 1.0132  |  Val Loss: 1.2204\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 324/1000] Train Loss: 1.0124  |  Val Loss: 1.2365\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 325/1000] Train Loss: 1.0140  |  Val Loss: 1.3266\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 326/1000] Train Loss: 1.0542  |  Val Loss: 1.2163\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 327/1000] Train Loss: 1.0323  |  Val Loss: 1.3368\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 328/1000] Train Loss: 1.0311  |  Val Loss: 1.2405\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 329/1000] Train Loss: 1.0260  |  Val Loss: 1.2248\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 330/1000] Train Loss: 1.0185  |  Val Loss: 1.2434\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 331/1000] Train Loss: 1.0113  |  Val Loss: 1.2640\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 332/1000] Train Loss: 1.0513  |  Val Loss: 1.1967\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 333/1000] Train Loss: 1.0195  |  Val Loss: 1.2301\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 334/1000] Train Loss: 1.0063  |  Val Loss: 1.2634\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 335/1000] Train Loss: 1.0496  |  Val Loss: 1.2073\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 336/1000] Train Loss: 1.0243  |  Val Loss: 1.3958\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 337/1000] Train Loss: 1.0129  |  Val Loss: 1.3373\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 338/1000] Train Loss: 1.1392  |  Val Loss: 1.5023\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 339/1000] Train Loss: 1.2042  |  Val Loss: 1.1660\n",
      "Validation loss improved from 1.1845 to 1.1660.\n",
      "[Epoch 340/1000] Train Loss: 1.0491  |  Val Loss: 1.2519\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 341/1000] Train Loss: 1.0257  |  Val Loss: 1.2173\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 342/1000] Train Loss: 0.9949  |  Val Loss: 1.2653\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 343/1000] Train Loss: 1.0027  |  Val Loss: 1.2467\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 344/1000] Train Loss: 0.9956  |  Val Loss: 1.1928\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 345/1000] Train Loss: 1.0006  |  Val Loss: 1.2226\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 346/1000] Train Loss: 0.9957  |  Val Loss: 1.2202\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 347/1000] Train Loss: 0.9890  |  Val Loss: 1.1693\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 348/1000] Train Loss: 0.9820  |  Val Loss: 1.2785\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 349/1000] Train Loss: 1.0541  |  Val Loss: 1.2115\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 350/1000] Train Loss: 1.0057  |  Val Loss: 1.3844\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 351/1000] Train Loss: 1.0593  |  Val Loss: 1.1887\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 352/1000] Train Loss: 1.0169  |  Val Loss: 1.2025\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 353/1000] Train Loss: 1.0361  |  Val Loss: 1.2673\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 354/1000] Train Loss: 1.0310  |  Val Loss: 1.1967\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 355/1000] Train Loss: 1.0191  |  Val Loss: 1.2875\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 356/1000] Train Loss: 0.9909  |  Val Loss: 1.1866\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 357/1000] Train Loss: 1.0197  |  Val Loss: 1.2297\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 358/1000] Train Loss: 0.9860  |  Val Loss: 1.2290\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 359/1000] Train Loss: 0.9835  |  Val Loss: 1.2129\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 360/1000] Train Loss: 0.9929  |  Val Loss: 1.2669\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 361/1000] Train Loss: 0.9870  |  Val Loss: 1.1935\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 362/1000] Train Loss: 0.9848  |  Val Loss: 1.2659\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 363/1000] Train Loss: 0.9881  |  Val Loss: 1.2304\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 364/1000] Train Loss: 1.0428  |  Val Loss: 1.2821\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 365/1000] Train Loss: 1.0091  |  Val Loss: 1.2062\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 366/1000] Train Loss: 1.0211  |  Val Loss: 1.2749\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 367/1000] Train Loss: 1.0924  |  Val Loss: 1.2378\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 368/1000] Train Loss: 1.0055  |  Val Loss: 1.2514\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 369/1000] Train Loss: 1.0106  |  Val Loss: 1.3514\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 370/1000] Train Loss: 1.0286  |  Val Loss: 1.1829\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 371/1000] Train Loss: 1.0106  |  Val Loss: 1.2665\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 372/1000] Train Loss: 0.9824  |  Val Loss: 1.1915\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 373/1000] Train Loss: 0.9657  |  Val Loss: 1.2709\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 374/1000] Train Loss: 0.9798  |  Val Loss: 1.2147\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 375/1000] Train Loss: 0.9709  |  Val Loss: 1.3027\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 376/1000] Train Loss: 0.9708  |  Val Loss: 1.1744\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 377/1000] Train Loss: 0.9707  |  Val Loss: 1.2648\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 378/1000] Train Loss: 0.9517  |  Val Loss: 1.1866\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 379/1000] Train Loss: 0.9858  |  Val Loss: 1.2590\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 380/1000] Train Loss: 1.0388  |  Val Loss: 1.3292\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 381/1000] Train Loss: 0.9910  |  Val Loss: 1.2433\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 382/1000] Train Loss: 0.9858  |  Val Loss: 1.3357\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 383/1000] Train Loss: 1.0103  |  Val Loss: 1.2203\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 384/1000] Train Loss: 0.9915  |  Val Loss: 1.2003\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 385/1000] Train Loss: 0.9972  |  Val Loss: 1.2717\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 386/1000] Train Loss: 1.0124  |  Val Loss: 1.2345\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 387/1000] Train Loss: 0.9847  |  Val Loss: 1.2484\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 388/1000] Train Loss: 0.9768  |  Val Loss: 1.1922\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 389/1000] Train Loss: 0.9972  |  Val Loss: 1.3731\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 390/1000] Train Loss: 1.0428  |  Val Loss: 1.1714\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 391/1000] Train Loss: 0.9704  |  Val Loss: 1.2284\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 392/1000] Train Loss: 1.0004  |  Val Loss: 1.2408\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 393/1000] Train Loss: 0.9955  |  Val Loss: 1.2428\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 394/1000] Train Loss: 0.9825  |  Val Loss: 1.2028\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 395/1000] Train Loss: 1.0414  |  Val Loss: 1.3671\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 396/1000] Train Loss: 1.0039  |  Val Loss: 1.2316\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 397/1000] Train Loss: 1.0127  |  Val Loss: 1.2375\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 398/1000] Train Loss: 0.9789  |  Val Loss: 1.2524\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 399/1000] Train Loss: 0.9464  |  Val Loss: 1.1896\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 400/1000] Train Loss: 0.9486  |  Val Loss: 1.2369\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 401/1000] Train Loss: 0.9534  |  Val Loss: 1.1665\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 402/1000] Train Loss: 0.9543  |  Val Loss: 1.2290\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 403/1000] Train Loss: 0.9351  |  Val Loss: 1.2397\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 404/1000] Train Loss: 0.9561  |  Val Loss: 1.2162\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 405/1000] Train Loss: 0.9492  |  Val Loss: 1.2488\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 406/1000] Train Loss: 0.9564  |  Val Loss: 1.1831\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 407/1000] Train Loss: 0.9326  |  Val Loss: 1.3073\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 408/1000] Train Loss: 0.9949  |  Val Loss: 1.2021\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 409/1000] Train Loss: 0.9621  |  Val Loss: 1.2946\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 410/1000] Train Loss: 0.9435  |  Val Loss: 1.2525\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 411/1000] Train Loss: 1.0841  |  Val Loss: 1.3841\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 412/1000] Train Loss: 0.9612  |  Val Loss: 1.2128\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 413/1000] Train Loss: 0.9665  |  Val Loss: 1.3363\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 414/1000] Train Loss: 0.9584  |  Val Loss: 1.1895\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 415/1000] Train Loss: 0.9595  |  Val Loss: 1.2023\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 416/1000] Train Loss: 0.9411  |  Val Loss: 1.2149\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 417/1000] Train Loss: 0.9552  |  Val Loss: 1.1920\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 418/1000] Train Loss: 0.9907  |  Val Loss: 1.3417\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 419/1000] Train Loss: 0.9552  |  Val Loss: 1.2045\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 420/1000] Train Loss: 0.9461  |  Val Loss: 1.2674\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 421/1000] Train Loss: 0.9335  |  Val Loss: 1.1868\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 422/1000] Train Loss: 0.9301  |  Val Loss: 1.2548\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 423/1000] Train Loss: 0.9259  |  Val Loss: 1.1824\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 424/1000] Train Loss: 0.9342  |  Val Loss: 1.3425\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 425/1000] Train Loss: 0.9862  |  Val Loss: 1.2345\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 426/1000] Train Loss: 0.9927  |  Val Loss: 1.2403\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 427/1000] Train Loss: 0.9343  |  Val Loss: 1.1973\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 428/1000] Train Loss: 0.9233  |  Val Loss: 1.2804\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 429/1000] Train Loss: 0.9326  |  Val Loss: 1.1721\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 430/1000] Train Loss: 0.9334  |  Val Loss: 1.2851\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 431/1000] Train Loss: 0.9547  |  Val Loss: 1.1935\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 432/1000] Train Loss: 0.9313  |  Val Loss: 1.2190\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 433/1000] Train Loss: 0.9127  |  Val Loss: 1.1924\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 434/1000] Train Loss: 0.9135  |  Val Loss: 1.2173\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 435/1000] Train Loss: 0.9266  |  Val Loss: 1.2388\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 436/1000] Train Loss: 0.9344  |  Val Loss: 1.1932\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 437/1000] Train Loss: 0.9115  |  Val Loss: 1.2007\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 438/1000] Train Loss: 0.9217  |  Val Loss: 1.2281\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 439/1000] Train Loss: 0.9090  |  Val Loss: 1.1731\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 439 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_input_dim = cae_mlp_train_reps.shape[1]\n",
    "cae_mlp_num_classes = len(torch.unique(cae_mlp_train_labels_torch))\n",
    "cae_mlp_model = MLPClassifier(cae_mlp_input_dim, cae_mlp_num_classes).to(device)\n",
    "\n",
    "cae_mlp_criterion = nn.CrossEntropyLoss()\n",
    "cae_mlp_optimizer = optim.Adam(cae_mlp_model.parameters(), lr=1e-3)\n",
    "\n",
    "cae_mlp_num_epochs = 1000\n",
    "cae_mlp_patience = 100\n",
    "\n",
    "cae_mlp_train_losses = []\n",
    "cae_mlp_val_losses = []\n",
    "\n",
    "cae_mlp_best_val_loss = float('inf')\n",
    "cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for cae_mlp_epoch in range(cae_mlp_num_epochs):\n",
    "    # Training\n",
    "    cae_mlp_model.train()\n",
    "    cae_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for cae_mlp_embeddings_batch, cae_mlp_labels_batch in cae_mlp_train_loader:\n",
    "        cae_mlp_embeddings_batch = cae_mlp_embeddings_batch.to(device)\n",
    "        cae_mlp_labels_batch = cae_mlp_labels_batch.to(device)\n",
    "        \n",
    "        cae_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        cae_mlp_outputs = cae_mlp_model(cae_mlp_embeddings_batch)\n",
    "        cae_mlp_loss = cae_mlp_criterion(cae_mlp_outputs, cae_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        cae_mlp_loss.backward()\n",
    "        cae_mlp_optimizer.step()\n",
    "        \n",
    "        cae_mlp_train_running_loss += cae_mlp_loss.item() * cae_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    cae_mlp_epoch_train_loss = cae_mlp_train_running_loss / len(cae_mlp_train_loader.dataset)\n",
    "    cae_mlp_train_losses.append(cae_mlp_epoch_train_loss)\n",
    "\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    cae_mlp_model.eval()\n",
    "    cae_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for cae_mlp_val_embeddings_batch, cae_mlp_val_labels_batch in cae_mlp_val_loader:\n",
    "            cae_mlp_val_embeddings_batch = cae_mlp_val_embeddings_batch.to(device)\n",
    "            cae_mlp_val_labels_batch = cae_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            cae_mlp_val_outputs = cae_mlp_model(cae_mlp_val_embeddings_batch)\n",
    "            cae_mlp_val_loss = cae_mlp_criterion(cae_mlp_val_outputs, cae_mlp_val_labels_batch)\n",
    "\n",
    "            cae_mlp_val_running_loss += cae_mlp_val_loss.item() * cae_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    cae_mlp_epoch_val_loss = cae_mlp_val_running_loss / len(cae_mlp_val_loader.dataset)\n",
    "    cae_mlp_val_losses.append(cae_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {cae_mlp_epoch+1}/{cae_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {cae_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {cae_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "\n",
    "    if cae_mlp_epoch_val_loss < cae_mlp_best_val_loss:\n",
    "        # improvement, reset patience\n",
    "        print(f\"Validation loss improved from {cae_mlp_best_val_loss:.4f} to {cae_mlp_epoch_val_loss:.4f}.\")\n",
    "        cae_mlp_best_val_loss = cae_mlp_epoch_val_loss\n",
    "        cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        cae_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {cae_mlp_epochs_without_improvement}/{cae_mlp_patience}\")\n",
    "        \n",
    "        if cae_mlp_epochs_without_improvement >= cae_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {cae_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {cae_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(cae_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(cae_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:22.081872Z",
     "iopub.status.busy": "2025-05-08T19:08:22.081872Z",
     "iopub.status.idle": "2025-05-08T19:08:22.236208Z",
     "shell.execute_reply": "2025-05-08T19:08:22.236208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CAE+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 1.0983 | Test Accuracy: 52.69%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_model.eval()\n",
    "\n",
    "cae_mlp_test_running_loss = 0.0\n",
    "cae_mlp_test_correct = 0\n",
    "cae_mlp_all_predictions = []\n",
    "cae_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cae_mlp_test_embeddings_batch, cae_mlp_test_labels_batch in cae_mlp_test_loader:\n",
    "        cae_mlp_test_embeddings_batch = cae_mlp_test_embeddings_batch.to(device)\n",
    "        cae_mlp_test_labels_batch = cae_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        cae_mlp_test_outputs = cae_mlp_model(cae_mlp_test_embeddings_batch)\n",
    "        \n",
    "        cae_mlp_test_loss_batch = cae_mlp_criterion(cae_mlp_test_outputs, cae_mlp_test_labels_batch)\n",
    "        cae_mlp_test_running_loss += cae_mlp_test_loss_batch.item() * cae_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, cae_mlp_test_predicted = torch.max(cae_mlp_test_outputs, dim=1)\n",
    "        cae_mlp_test_correct += (cae_mlp_test_predicted == cae_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        #saving predictions for conf matrix\n",
    "        cae_mlp_all_predictions.extend(cae_mlp_test_predicted.cpu().numpy())\n",
    "        cae_mlp_all_true_labels.extend(cae_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_predictions.npy'), np.array(cae_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_true_labels.npy'), np.array(cae_mlp_all_true_labels))\n",
    "print(f\"Saved CAE+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "cae_mlp_epoch_test_loss = cae_mlp_test_running_loss / len(cae_mlp_test_loader.dataset)\n",
    "cae_mlp_test_accuracy = cae_mlp_test_correct / len(cae_mlp_test_loader.dataset)\n",
    "\n",
    "cae_mlp_test_accuracy_pct = cae_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {cae_mlp_epoch_test_loss:.4f} | Test Accuracy: {cae_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "cae_mlp_num_epochs_run = len(cae_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         [cae_mlp_epoch_test_loss]*cae_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical SCL with Cosine Similarity (Supervised Contrastive Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:22.239224Z",
     "iopub.status.busy": "2025-05-08T19:08:22.237709Z",
     "iopub.status.idle": "2025-05-08T19:08:22.249236Z",
     "shell.execute_reply": "2025-05-08T19:08:22.249236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 280 samples with 64 features each\n",
      "LOG: Labels shape: (280,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2898 samples with 64 features each\n",
      "LOG: Labels shape: (2898,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (280, 64), \n",
      "Train labels shape: (280,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (70, 64), \n",
      "Val labels shape: (70,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (2898, 64), \n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "tscl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "tscl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "tscl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "tscl_train_embeddings, tscl_train_labels = load_encoded_data(tscl_encoded_train_dir)\n",
    "tscl_val_embeddings, tscl_val_labels = load_encoded_data(tscl_encoded_val_dir)\n",
    "tscl_test_embeddings, tscl_test_labels = load_encoded_data(tscl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {tscl_train_embeddings.shape}, \\nTrain labels shape: {tscl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {tscl_val_embeddings.shape}, \\nVal labels shape: {tscl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {tscl_test_embeddings.shape}, \\nTest labels shape: {tscl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:22.252451Z",
     "iopub.status.busy": "2025-05-08T19:08:22.251452Z",
     "iopub.status.idle": "2025-05-08T19:08:22.262987Z",
     "shell.execute_reply": "2025-05-08T19:08:22.262987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20}\n",
      "Training batch size: 280\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "tscl_train_embeddings = tscl_train_embeddings.reshape(tscl_train_embeddings.shape[0], -1)\n",
    "tscl_val_embeddings = tscl_val_embeddings.reshape(tscl_val_embeddings.shape[0], -1)\n",
    "tscl_test_embeddings = tscl_test_embeddings.reshape(tscl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "tscl_train_mean = np.mean(tscl_train_embeddings, axis=0)\n",
    "tscl_train_std = np.std(tscl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "tscl_train_embeddings = (tscl_train_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_val_embeddings = (tscl_val_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_test_embeddings = (tscl_test_embeddings - tscl_train_mean) / tscl_train_std\n",
    "\n",
    "tscl_train_dataset = TensorDataset(torch.tensor(tscl_train_embeddings, dtype=torch.float32), torch.tensor(tscl_train_labels, dtype=torch.long))\n",
    "tscl_val_dataset = TensorDataset(torch.tensor(tscl_val_embeddings, dtype=torch.float32), torch.tensor(tscl_val_labels, dtype=torch.long))\n",
    "tscl_test_dataset = TensorDataset(torch.tensor(tscl_test_embeddings, dtype=torch.float32), torch.tensor(tscl_test_labels, dtype=torch.long))\n",
    "\n",
    "tscl_m = 20\n",
    "tscl_num_classes = len(np.unique(tscl_train_labels))\n",
    "\n",
    "# Calculate theoretical required batch size\n",
    "tscl_required_batch_size = tscl_m * tscl_num_classes\n",
    "\n",
    "# Ensure batch size doesn't exceed training set size\n",
    "if tscl_required_batch_size > len(tscl_train_dataset):\n",
    "    #case 1: Not enough samples - reduce m proportionally\n",
    "    tscl_max_possible_m = len(tscl_train_dataset) // tscl_num_classes\n",
    "    tscl_m = max(1, tscl_max_possible_m)  # Ensure m >= 1\n",
    "    tscl_batch_size_train = tscl_m * tscl_num_classes\n",
    "else:\n",
    "    #case 2: Use full batch size\n",
    "    tscl_batch_size_train = tscl_required_batch_size\n",
    "\n",
    "tscl_sampler = MPerClassSampler(labels = tscl_train_labels, m = tscl_m, batch_size = tscl_batch_size_train, length_before_new_iter=len(tscl_train_dataset))\n",
    "tscl_train_loader = DataLoader(tscl_train_dataset, batch_size=tscl_batch_size_train, sampler=tscl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "tscl_dataloader_bs = 256\n",
    "tscl_val_loader = DataLoader(tscl_val_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "tscl_test_loader = DataLoader(tscl_test_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for tscl_X_batch, tscl_y_batch in tscl_train_loader:\n",
    "    tscl_unique, tscl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(tscl_unique, tscl_counts)))\n",
    "    print(f\"Training batch size: {tscl_batch_size_train}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:22.265566Z",
     "iopub.status.busy": "2025-05-08T19:08:22.265566Z",
     "iopub.status.idle": "2025-05-08T19:08:22.270645Z",
     "shell.execute_reply": "2025-05-08T19:08:22.270645Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature = 0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        #normalize feat vectors\n",
    "        features = F.normalize(features, p=2, dim = 1)\n",
    "\n",
    "        #compute cosine simi matrix\n",
    "        similarity_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "\n",
    "        #create a mask for +ve pairs - i.e. same class\n",
    "        labels = labels.unsqueeze(1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(features.device)\n",
    "\n",
    "        #loss computation\n",
    "        exp_sim = torch.exp(similarity_matrix)\n",
    "        log_prob = similarity_matrix - torch.log(exp_sim.sum(dim = 1, keepdim=True))\n",
    "\n",
    "        #mask out diagonal - i.e. self similarity\n",
    "        mask_self = torch.eye(mask.shape[0], dtype = torch.bool).to(features.device)\n",
    "        mask = mask * (~mask_self)\n",
    "\n",
    "        #handling edge cases when there is no +ve pair\n",
    "        mask_pos_pairs = mask.sum(dim=1)\n",
    "        mask_pos_pairs = torch.where(mask_pos_pairs < 1e-6, 1, mask_pos_pairs)\n",
    "\n",
    "        loss = -(mask * log_prob).sum(dim=1) / mask_pos_pairs\n",
    "\n",
    "        return loss.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:22.273651Z",
     "iopub.status.busy": "2025-05-08T19:08:22.273651Z",
     "iopub.status.idle": "2025-05-08T19:08:22.277619Z",
     "shell.execute_reply": "2025-05-08T19:08:22.277619Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128), #expects input of shape (batch_size, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #flattening input tensor\n",
    "        #x = x.view(x.size(0), -1)  #reshaping -> (batch_size, channels * height * width)\n",
    "        projections = self.projection_head(x)\n",
    "        return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:22.280131Z",
     "iopub.status.busy": "2025-05-08T19:08:22.280131Z",
     "iopub.status.idle": "2025-05-08T19:08:35.406674Z",
     "shell.execute_reply": "2025-05-08T19:08:35.406674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 8.3909\n",
      "Epoch [1/2000], Avg Train Loss: 8.3909\n",
      "Epoch [1/2000], Avg Val Loss: 3.6736\n",
      "Validation loss improved from inf to 3.6736. Saving model...\n",
      "\n",
      "LOG: Epoch [2/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.3708\n",
      "Epoch [2/2000], Avg Train Loss: 8.3708\n",
      "Epoch [2/2000], Avg Val Loss: 3.6560\n",
      "Validation loss improved from 3.6736 to 3.6560. Saving model...\n",
      "\n",
      "LOG: Epoch [3/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.2225\n",
      "Epoch [3/2000], Avg Train Loss: 8.2225\n",
      "Epoch [3/2000], Avg Val Loss: 3.6393\n",
      "Validation loss improved from 3.6560 to 3.6393. Saving model...\n",
      "\n",
      "LOG: Epoch [4/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.3124\n",
      "Epoch [4/2000], Avg Train Loss: 8.3124\n",
      "Epoch [4/2000], Avg Val Loss: 3.6233\n",
      "Validation loss improved from 3.6393 to 3.6233. Saving model...\n",
      "\n",
      "LOG: Epoch [5/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.0153\n",
      "Epoch [5/2000], Avg Train Loss: 8.0153\n",
      "Epoch [5/2000], Avg Val Loss: 3.6079\n",
      "Validation loss improved from 3.6233 to 3.6079. Saving model...\n",
      "\n",
      "LOG: Epoch [6/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.0551\n",
      "Epoch [6/2000], Avg Train Loss: 8.0551\n",
      "Epoch [6/2000], Avg Val Loss: 3.5933\n",
      "Validation loss improved from 3.6079 to 3.5933. Saving model...\n",
      "\n",
      "LOG: Epoch [7/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.8546\n",
      "Epoch [7/2000], Avg Train Loss: 7.8546\n",
      "Epoch [7/2000], Avg Val Loss: 3.5794\n",
      "Validation loss improved from 3.5933 to 3.5794. Saving model...\n",
      "\n",
      "LOG: Epoch [8/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.7203\n",
      "Epoch [8/2000], Avg Train Loss: 7.7203\n",
      "Epoch [8/2000], Avg Val Loss: 3.5662\n",
      "Validation loss improved from 3.5794 to 3.5662. Saving model...\n",
      "\n",
      "LOG: Epoch [9/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.8069\n",
      "Epoch [9/2000], Avg Train Loss: 7.8069\n",
      "Epoch [9/2000], Avg Val Loss: 3.5536\n",
      "Validation loss improved from 3.5662 to 3.5536. Saving model...\n",
      "\n",
      "LOG: Epoch [10/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.6355\n",
      "Epoch [10/2000], Avg Train Loss: 7.6355\n",
      "Epoch [10/2000], Avg Val Loss: 3.5415\n",
      "Validation loss improved from 3.5536 to 3.5415. Saving model...\n",
      "\n",
      "LOG: Epoch [11/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.5560\n",
      "Epoch [11/2000], Avg Train Loss: 7.5560\n",
      "Epoch [11/2000], Avg Val Loss: 3.5298\n",
      "Validation loss improved from 3.5415 to 3.5298. Saving model...\n",
      "\n",
      "LOG: Epoch [12/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.4855\n",
      "Epoch [12/2000], Avg Train Loss: 7.4855\n",
      "Epoch [12/2000], Avg Val Loss: 3.5187\n",
      "Validation loss improved from 3.5298 to 3.5187. Saving model...\n",
      "\n",
      "LOG: Epoch [13/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.4618\n",
      "Epoch [13/2000], Avg Train Loss: 7.4618\n",
      "Epoch [13/2000], Avg Val Loss: 3.5079\n",
      "Validation loss improved from 3.5187 to 3.5079. Saving model...\n",
      "\n",
      "LOG: Epoch [14/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.3173\n",
      "Epoch [14/2000], Avg Train Loss: 7.3173\n",
      "Epoch [14/2000], Avg Val Loss: 3.4976\n",
      "Validation loss improved from 3.5079 to 3.4976. Saving model...\n",
      "\n",
      "LOG: Epoch [15/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.2949\n",
      "Epoch [15/2000], Avg Train Loss: 7.2949\n",
      "Epoch [15/2000], Avg Val Loss: 3.4877\n",
      "Validation loss improved from 3.4976 to 3.4877. Saving model...\n",
      "\n",
      "LOG: Epoch [16/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 7.2285\n",
      "Epoch [16/2000], Avg Train Loss: 7.2285\n",
      "Epoch [16/2000], Avg Val Loss: 3.4783\n",
      "Validation loss improved from 3.4877 to 3.4783. Saving model...\n",
      "\n",
      "LOG: Epoch [17/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.2217\n",
      "Epoch [17/2000], Avg Train Loss: 7.2217\n",
      "Epoch [17/2000], Avg Val Loss: 3.4693\n",
      "Validation loss improved from 3.4783 to 3.4693. Saving model...\n",
      "\n",
      "LOG: Epoch [18/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.1992\n",
      "Epoch [18/2000], Avg Train Loss: 7.1992\n",
      "Epoch [18/2000], Avg Val Loss: 3.4606\n",
      "Validation loss improved from 3.4693 to 3.4606. Saving model...\n",
      "\n",
      "LOG: Epoch [19/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.0861\n",
      "Epoch [19/2000], Avg Train Loss: 7.0861\n",
      "Epoch [19/2000], Avg Val Loss: 3.4524\n",
      "Validation loss improved from 3.4606 to 3.4524. Saving model...\n",
      "\n",
      "LOG: Epoch [20/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.0230\n",
      "Epoch [20/2000], Avg Train Loss: 7.0230\n",
      "Epoch [20/2000], Avg Val Loss: 3.4444\n",
      "Validation loss improved from 3.4524 to 3.4444. Saving model...\n",
      "\n",
      "LOG: Epoch [21/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.9042\n",
      "Epoch [21/2000], Avg Train Loss: 6.9042\n",
      "Epoch [21/2000], Avg Val Loss: 3.4369\n",
      "Validation loss improved from 3.4444 to 3.4369. Saving model...\n",
      "\n",
      "LOG: Epoch [22/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.8485\n",
      "Epoch [22/2000], Avg Train Loss: 6.8485\n",
      "Epoch [22/2000], Avg Val Loss: 3.4297\n",
      "Validation loss improved from 3.4369 to 3.4297. Saving model...\n",
      "\n",
      "LOG: Epoch [23/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.8180\n",
      "Epoch [23/2000], Avg Train Loss: 6.8180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/2000], Avg Val Loss: 3.4228\n",
      "Validation loss improved from 3.4297 to 3.4228. Saving model...\n",
      "\n",
      "LOG: Epoch [24/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6645\n",
      "Epoch [24/2000], Avg Train Loss: 6.6645\n",
      "Epoch [24/2000], Avg Val Loss: 3.4163\n",
      "Validation loss improved from 3.4228 to 3.4163. Saving model...\n",
      "\n",
      "LOG: Epoch [25/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.7145\n",
      "Epoch [25/2000], Avg Train Loss: 6.7145\n",
      "Epoch [25/2000], Avg Val Loss: 3.4101\n",
      "Validation loss improved from 3.4163 to 3.4101. Saving model...\n",
      "\n",
      "LOG: Epoch [26/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.7261\n",
      "Epoch [26/2000], Avg Train Loss: 6.7261\n",
      "Epoch [26/2000], Avg Val Loss: 3.4043\n",
      "Validation loss improved from 3.4101 to 3.4043. Saving model...\n",
      "\n",
      "LOG: Epoch [27/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6846\n",
      "Epoch [27/2000], Avg Train Loss: 6.6846\n",
      "Epoch [27/2000], Avg Val Loss: 3.3986\n",
      "Validation loss improved from 3.4043 to 3.3986. Saving model...\n",
      "\n",
      "LOG: Epoch [28/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.5093\n",
      "Epoch [28/2000], Avg Train Loss: 6.5093\n",
      "Epoch [28/2000], Avg Val Loss: 3.3933\n",
      "Validation loss improved from 3.3986 to 3.3933. Saving model...\n",
      "\n",
      "LOG: Epoch [29/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6376\n",
      "Epoch [29/2000], Avg Train Loss: 6.6376\n",
      "Epoch [29/2000], Avg Val Loss: 3.3882\n",
      "Validation loss improved from 3.3933 to 3.3882. Saving model...\n",
      "\n",
      "LOG: Epoch [30/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.5442\n",
      "Epoch [30/2000], Avg Train Loss: 6.5442\n",
      "Epoch [30/2000], Avg Val Loss: 3.3833\n",
      "Validation loss improved from 3.3882 to 3.3833. Saving model...\n",
      "\n",
      "LOG: Epoch [31/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.4064\n",
      "Epoch [31/2000], Avg Train Loss: 6.4064\n",
      "Epoch [31/2000], Avg Val Loss: 3.3786\n",
      "Validation loss improved from 3.3833 to 3.3786. Saving model...\n",
      "\n",
      "LOG: Epoch [32/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3925\n",
      "Epoch [32/2000], Avg Train Loss: 6.3925\n",
      "Epoch [32/2000], Avg Val Loss: 3.3742\n",
      "Validation loss improved from 3.3786 to 3.3742. Saving model...\n",
      "\n",
      "LOG: Epoch [33/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.4504\n",
      "Epoch [33/2000], Avg Train Loss: 6.4504\n",
      "Epoch [33/2000], Avg Val Loss: 3.3699\n",
      "Validation loss improved from 3.3742 to 3.3699. Saving model...\n",
      "\n",
      "LOG: Epoch [34/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3209\n",
      "Epoch [34/2000], Avg Train Loss: 6.3209\n",
      "Epoch [34/2000], Avg Val Loss: 3.3658\n",
      "Validation loss improved from 3.3699 to 3.3658. Saving model...\n",
      "\n",
      "LOG: Epoch [35/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3126\n",
      "Epoch [35/2000], Avg Train Loss: 6.3126\n",
      "Epoch [35/2000], Avg Val Loss: 3.3617\n",
      "Validation loss improved from 3.3658 to 3.3617. Saving model...\n",
      "\n",
      "LOG: Epoch [36/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 6.2387\n",
      "Epoch [36/2000], Avg Train Loss: 6.2387\n",
      "Epoch [36/2000], Avg Val Loss: 3.3578\n",
      "Validation loss improved from 3.3617 to 3.3578. Saving model...\n",
      "\n",
      "LOG: Epoch [37/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2331\n",
      "Epoch [37/2000], Avg Train Loss: 6.2331\n",
      "Epoch [37/2000], Avg Val Loss: 3.3541\n",
      "Validation loss improved from 3.3578 to 3.3541. Saving model...\n",
      "\n",
      "LOG: Epoch [38/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1635\n",
      "Epoch [38/2000], Avg Train Loss: 6.1635\n",
      "Epoch [38/2000], Avg Val Loss: 3.3505\n",
      "Validation loss improved from 3.3541 to 3.3505. Saving model...\n",
      "\n",
      "LOG: Epoch [39/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1933\n",
      "Epoch [39/2000], Avg Train Loss: 6.1933\n",
      "Epoch [39/2000], Avg Val Loss: 3.3472\n",
      "Validation loss improved from 3.3505 to 3.3472. Saving model...\n",
      "\n",
      "LOG: Epoch [40/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0917\n",
      "Epoch [40/2000], Avg Train Loss: 6.0917\n",
      "Epoch [40/2000], Avg Val Loss: 3.3440\n",
      "Validation loss improved from 3.3472 to 3.3440. Saving model...\n",
      "\n",
      "LOG: Epoch [41/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1278\n",
      "Epoch [41/2000], Avg Train Loss: 6.1278\n",
      "Epoch [41/2000], Avg Val Loss: 3.3410\n",
      "Validation loss improved from 3.3440 to 3.3410. Saving model...\n",
      "\n",
      "LOG: Epoch [42/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.1140\n",
      "Epoch [42/2000], Avg Train Loss: 6.1140\n",
      "Epoch [42/2000], Avg Val Loss: 3.3380\n",
      "Validation loss improved from 3.3410 to 3.3380. Saving model...\n",
      "\n",
      "LOG: Epoch [43/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9430\n",
      "Epoch [43/2000], Avg Train Loss: 5.9430\n",
      "Epoch [43/2000], Avg Val Loss: 3.3352\n",
      "Validation loss improved from 3.3380 to 3.3352. Saving model...\n",
      "\n",
      "LOG: Epoch [44/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0070\n",
      "Epoch [44/2000], Avg Train Loss: 6.0070\n",
      "Epoch [44/2000], Avg Val Loss: 3.3325\n",
      "Validation loss improved from 3.3352 to 3.3325. Saving model...\n",
      "\n",
      "LOG: Epoch [45/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9098\n",
      "Epoch [45/2000], Avg Train Loss: 5.9098\n",
      "Epoch [45/2000], Avg Val Loss: 3.3298\n",
      "Validation loss improved from 3.3325 to 3.3298. Saving model...\n",
      "\n",
      "LOG: Epoch [46/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9041\n",
      "Epoch [46/2000], Avg Train Loss: 5.9041\n",
      "Epoch [46/2000], Avg Val Loss: 3.3273\n",
      "Validation loss improved from 3.3298 to 3.3273. Saving model...\n",
      "\n",
      "LOG: Epoch [47/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8777\n",
      "Epoch [47/2000], Avg Train Loss: 5.8777\n",
      "Epoch [47/2000], Avg Val Loss: 3.3248\n",
      "Validation loss improved from 3.3273 to 3.3248. Saving model...\n",
      "\n",
      "LOG: Epoch [48/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8707\n",
      "Epoch [48/2000], Avg Train Loss: 5.8707\n",
      "Epoch [48/2000], Avg Val Loss: 3.3225\n",
      "Validation loss improved from 3.3248 to 3.3225. Saving model...\n",
      "\n",
      "LOG: Epoch [49/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8784\n",
      "Epoch [49/2000], Avg Train Loss: 5.8784\n",
      "Epoch [49/2000], Avg Val Loss: 3.3201\n",
      "Validation loss improved from 3.3225 to 3.3201. Saving model...\n",
      "\n",
      "LOG: Epoch [50/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8681\n",
      "Epoch [50/2000], Avg Train Loss: 5.8681\n",
      "Epoch [50/2000], Avg Val Loss: 3.3179\n",
      "Validation loss improved from 3.3201 to 3.3179. Saving model...\n",
      "\n",
      "LOG: Epoch [51/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.8606\n",
      "Epoch [51/2000], Avg Train Loss: 5.8606\n",
      "Epoch [51/2000], Avg Val Loss: 3.3157\n",
      "Validation loss improved from 3.3179 to 3.3157. Saving model...\n",
      "\n",
      "LOG: Epoch [52/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7977\n",
      "Epoch [52/2000], Avg Train Loss: 5.7977\n",
      "Epoch [52/2000], Avg Val Loss: 3.3135\n",
      "Validation loss improved from 3.3157 to 3.3135. Saving model...\n",
      "\n",
      "LOG: Epoch [53/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8031\n",
      "Epoch [53/2000], Avg Train Loss: 5.8031\n",
      "Epoch [53/2000], Avg Val Loss: 3.3113\n",
      "Validation loss improved from 3.3135 to 3.3113. Saving model...\n",
      "\n",
      "LOG: Epoch [54/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8396\n",
      "Epoch [54/2000], Avg Train Loss: 5.8396\n",
      "Epoch [54/2000], Avg Val Loss: 3.3092\n",
      "Validation loss improved from 3.3113 to 3.3092. Saving model...\n",
      "\n",
      "LOG: Epoch [55/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6910\n",
      "Epoch [55/2000], Avg Train Loss: 5.6910\n",
      "Epoch [55/2000], Avg Val Loss: 3.3072\n",
      "Validation loss improved from 3.3092 to 3.3072. Saving model...\n",
      "\n",
      "LOG: Epoch [56/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7100\n",
      "Epoch [56/2000], Avg Train Loss: 5.7100\n",
      "Epoch [56/2000], Avg Val Loss: 3.3054\n",
      "Validation loss improved from 3.3072 to 3.3054. Saving model...\n",
      "\n",
      "LOG: Epoch [57/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6795\n",
      "Epoch [57/2000], Avg Train Loss: 5.6795\n",
      "Epoch [57/2000], Avg Val Loss: 3.3036\n",
      "Validation loss improved from 3.3054 to 3.3036. Saving model...\n",
      "\n",
      "LOG: Epoch [58/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.6356\n",
      "Epoch [58/2000], Avg Train Loss: 5.6356\n",
      "Epoch [58/2000], Avg Val Loss: 3.3018\n",
      "Validation loss improved from 3.3036 to 3.3018. Saving model...\n",
      "\n",
      "LOG: Epoch [59/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7104\n",
      "Epoch [59/2000], Avg Train Loss: 5.7104\n",
      "Epoch [59/2000], Avg Val Loss: 3.3001\n",
      "Validation loss improved from 3.3018 to 3.3001. Saving model...\n",
      "\n",
      "LOG: Epoch [60/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6341\n",
      "Epoch [60/2000], Avg Train Loss: 5.6341\n",
      "Epoch [60/2000], Avg Val Loss: 3.2985\n",
      "Validation loss improved from 3.3001 to 3.2985. Saving model...\n",
      "\n",
      "LOG: Epoch [61/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5632\n",
      "Epoch [61/2000], Avg Train Loss: 5.5632\n",
      "Epoch [61/2000], Avg Val Loss: 3.2968\n",
      "Validation loss improved from 3.2985 to 3.2968. Saving model...\n",
      "\n",
      "LOG: Epoch [62/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6052\n",
      "Epoch [62/2000], Avg Train Loss: 5.6052\n",
      "Epoch [62/2000], Avg Val Loss: 3.2952\n",
      "Validation loss improved from 3.2968 to 3.2952. Saving model...\n",
      "\n",
      "LOG: Epoch [63/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6086\n",
      "Epoch [63/2000], Avg Train Loss: 5.6086\n",
      "Epoch [63/2000], Avg Val Loss: 3.2936\n",
      "Validation loss improved from 3.2952 to 3.2936. Saving model...\n",
      "\n",
      "LOG: Epoch [64/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5138\n",
      "Epoch [64/2000], Avg Train Loss: 5.5138\n",
      "Epoch [64/2000], Avg Val Loss: 3.2921\n",
      "Validation loss improved from 3.2936 to 3.2921. Saving model...\n",
      "\n",
      "LOG: Epoch [65/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5371\n",
      "Epoch [65/2000], Avg Train Loss: 5.5371\n",
      "Epoch [65/2000], Avg Val Loss: 3.2906\n",
      "Validation loss improved from 3.2921 to 3.2906. Saving model...\n",
      "\n",
      "LOG: Epoch [66/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5229\n",
      "Epoch [66/2000], Avg Train Loss: 5.5229\n",
      "Epoch [66/2000], Avg Val Loss: 3.2892\n",
      "Validation loss improved from 3.2906 to 3.2892. Saving model...\n",
      "\n",
      "LOG: Epoch [67/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5122\n",
      "Epoch [67/2000], Avg Train Loss: 5.5122\n",
      "Epoch [67/2000], Avg Val Loss: 3.2877\n",
      "Validation loss improved from 3.2892 to 3.2877. Saving model...\n",
      "\n",
      "LOG: Epoch [68/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5389\n",
      "Epoch [68/2000], Avg Train Loss: 5.5389\n",
      "Epoch [68/2000], Avg Val Loss: 3.2863\n",
      "Validation loss improved from 3.2877 to 3.2863. Saving model...\n",
      "\n",
      "LOG: Epoch [69/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4587\n",
      "Epoch [69/2000], Avg Train Loss: 5.4587\n",
      "Epoch [69/2000], Avg Val Loss: 3.2849\n",
      "Validation loss improved from 3.2863 to 3.2849. Saving model...\n",
      "\n",
      "LOG: Epoch [70/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4779\n",
      "Epoch [70/2000], Avg Train Loss: 5.4779\n",
      "Epoch [70/2000], Avg Val Loss: 3.2835\n",
      "Validation loss improved from 3.2849 to 3.2835. Saving model...\n",
      "\n",
      "LOG: Epoch [71/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3710\n",
      "Epoch [71/2000], Avg Train Loss: 5.3710\n",
      "Epoch [71/2000], Avg Val Loss: 3.2822\n",
      "Validation loss improved from 3.2835 to 3.2822. Saving model...\n",
      "\n",
      "LOG: Epoch [72/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3967\n",
      "Epoch [72/2000], Avg Train Loss: 5.3967\n",
      "Epoch [72/2000], Avg Val Loss: 3.2809\n",
      "Validation loss improved from 3.2822 to 3.2809. Saving model...\n",
      "\n",
      "LOG: Epoch [73/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4701\n",
      "Epoch [73/2000], Avg Train Loss: 5.4701\n",
      "Epoch [73/2000], Avg Val Loss: 3.2797\n",
      "Validation loss improved from 3.2809 to 3.2797. Saving model...\n",
      "\n",
      "LOG: Epoch [74/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.4282\n",
      "Epoch [74/2000], Avg Train Loss: 5.4282\n",
      "Epoch [74/2000], Avg Val Loss: 3.2785\n",
      "Validation loss improved from 3.2797 to 3.2785. Saving model...\n",
      "\n",
      "LOG: Epoch [75/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3811\n",
      "Epoch [75/2000], Avg Train Loss: 5.3811\n",
      "Epoch [75/2000], Avg Val Loss: 3.2773\n",
      "Validation loss improved from 3.2785 to 3.2773. Saving model...\n",
      "\n",
      "LOG: Epoch [76/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4446\n",
      "Epoch [76/2000], Avg Train Loss: 5.4446\n",
      "Epoch [76/2000], Avg Val Loss: 3.2761\n",
      "Validation loss improved from 3.2773 to 3.2761. Saving model...\n",
      "\n",
      "LOG: Epoch [77/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3808\n",
      "Epoch [77/2000], Avg Train Loss: 5.3808\n",
      "Epoch [77/2000], Avg Val Loss: 3.2749\n",
      "Validation loss improved from 3.2761 to 3.2749. Saving model...\n",
      "\n",
      "LOG: Epoch [78/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3962\n",
      "Epoch [78/2000], Avg Train Loss: 5.3962\n",
      "Epoch [78/2000], Avg Val Loss: 3.2738\n",
      "Validation loss improved from 3.2749 to 3.2738. Saving model...\n",
      "\n",
      "LOG: Epoch [79/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3489\n",
      "Epoch [79/2000], Avg Train Loss: 5.3489\n",
      "Epoch [79/2000], Avg Val Loss: 3.2727\n",
      "Validation loss improved from 3.2738 to 3.2727. Saving model...\n",
      "\n",
      "LOG: Epoch [80/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3405\n",
      "Epoch [80/2000], Avg Train Loss: 5.3405\n",
      "Epoch [80/2000], Avg Val Loss: 3.2716\n",
      "Validation loss improved from 3.2727 to 3.2716. Saving model...\n",
      "\n",
      "LOG: Epoch [81/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3815\n",
      "Epoch [81/2000], Avg Train Loss: 5.3815\n",
      "Epoch [81/2000], Avg Val Loss: 3.2705\n",
      "Validation loss improved from 3.2716 to 3.2705. Saving model...\n",
      "\n",
      "LOG: Epoch [82/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3535\n",
      "Epoch [82/2000], Avg Train Loss: 5.3535\n",
      "Epoch [82/2000], Avg Val Loss: 3.2695\n",
      "Validation loss improved from 3.2705 to 3.2695. Saving model...\n",
      "\n",
      "LOG: Epoch [83/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2974\n",
      "Epoch [83/2000], Avg Train Loss: 5.2974\n",
      "Epoch [83/2000], Avg Val Loss: 3.2684\n",
      "Validation loss improved from 3.2695 to 3.2684. Saving model...\n",
      "\n",
      "LOG: Epoch [84/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2853\n",
      "Epoch [84/2000], Avg Train Loss: 5.2853\n",
      "Epoch [84/2000], Avg Val Loss: 3.2673\n",
      "Validation loss improved from 3.2684 to 3.2673. Saving model...\n",
      "\n",
      "LOG: Epoch [85/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2955\n",
      "Epoch [85/2000], Avg Train Loss: 5.2955\n",
      "Epoch [85/2000], Avg Val Loss: 3.2663\n",
      "Validation loss improved from 3.2673 to 3.2663. Saving model...\n",
      "\n",
      "LOG: Epoch [86/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2635\n",
      "Epoch [86/2000], Avg Train Loss: 5.2635\n",
      "Epoch [86/2000], Avg Val Loss: 3.2652\n",
      "Validation loss improved from 3.2663 to 3.2652. Saving model...\n",
      "\n",
      "LOG: Epoch [87/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3244\n",
      "Epoch [87/2000], Avg Train Loss: 5.3244\n",
      "Epoch [87/2000], Avg Val Loss: 3.2642\n",
      "Validation loss improved from 3.2652 to 3.2642. Saving model...\n",
      "\n",
      "LOG: Epoch [88/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2497\n",
      "Epoch [88/2000], Avg Train Loss: 5.2497\n",
      "Epoch [88/2000], Avg Val Loss: 3.2631\n",
      "Validation loss improved from 3.2642 to 3.2631. Saving model...\n",
      "\n",
      "LOG: Epoch [89/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3105\n",
      "Epoch [89/2000], Avg Train Loss: 5.3105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/2000], Avg Val Loss: 3.2621\n",
      "Validation loss improved from 3.2631 to 3.2621. Saving model...\n",
      "\n",
      "LOG: Epoch [90/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2749\n",
      "Epoch [90/2000], Avg Train Loss: 5.2749\n",
      "Epoch [90/2000], Avg Val Loss: 3.2611\n",
      "Validation loss improved from 3.2621 to 3.2611. Saving model...\n",
      "\n",
      "LOG: Epoch [91/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2283\n",
      "Epoch [91/2000], Avg Train Loss: 5.2283\n",
      "Epoch [91/2000], Avg Val Loss: 3.2600\n",
      "Validation loss improved from 3.2611 to 3.2600. Saving model...\n",
      "\n",
      "LOG: Epoch [92/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2647\n",
      "Epoch [92/2000], Avg Train Loss: 5.2647\n",
      "Epoch [92/2000], Avg Val Loss: 3.2591\n",
      "Validation loss improved from 3.2600 to 3.2591. Saving model...\n",
      "\n",
      "LOG: Epoch [93/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2352\n",
      "Epoch [93/2000], Avg Train Loss: 5.2352\n",
      "Epoch [93/2000], Avg Val Loss: 3.2581\n",
      "Validation loss improved from 3.2591 to 3.2581. Saving model...\n",
      "\n",
      "LOG: Epoch [94/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2219\n",
      "Epoch [94/2000], Avg Train Loss: 5.2219\n",
      "Epoch [94/2000], Avg Val Loss: 3.2571\n",
      "Validation loss improved from 3.2581 to 3.2571. Saving model...\n",
      "\n",
      "LOG: Epoch [95/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2312\n",
      "Epoch [95/2000], Avg Train Loss: 5.2312\n",
      "Epoch [95/2000], Avg Val Loss: 3.2561\n",
      "Validation loss improved from 3.2571 to 3.2561. Saving model...\n",
      "\n",
      "LOG: Epoch [96/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1815\n",
      "Epoch [96/2000], Avg Train Loss: 5.1815\n",
      "Epoch [96/2000], Avg Val Loss: 3.2551\n",
      "Validation loss improved from 3.2561 to 3.2551. Saving model...\n",
      "\n",
      "LOG: Epoch [97/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1751\n",
      "Epoch [97/2000], Avg Train Loss: 5.1751\n",
      "Epoch [97/2000], Avg Val Loss: 3.2541\n",
      "Validation loss improved from 3.2551 to 3.2541. Saving model...\n",
      "\n",
      "LOG: Epoch [98/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1855\n",
      "Epoch [98/2000], Avg Train Loss: 5.1855\n",
      "Epoch [98/2000], Avg Val Loss: 3.2532\n",
      "Validation loss improved from 3.2541 to 3.2532. Saving model...\n",
      "\n",
      "LOG: Epoch [99/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1177\n",
      "Epoch [99/2000], Avg Train Loss: 5.1177\n",
      "Epoch [99/2000], Avg Val Loss: 3.2522\n",
      "Validation loss improved from 3.2532 to 3.2522. Saving model...\n",
      "\n",
      "LOG: Epoch [100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2130\n",
      "Epoch [100/2000], Avg Train Loss: 5.2130\n",
      "Epoch [100/2000], Avg Val Loss: 3.2513\n",
      "Validation loss improved from 3.2522 to 3.2513. Saving model...\n",
      "\n",
      "LOG: Epoch [101/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1142\n",
      "Epoch [101/2000], Avg Train Loss: 5.1142\n",
      "Epoch [101/2000], Avg Val Loss: 3.2503\n",
      "Validation loss improved from 3.2513 to 3.2503. Saving model...\n",
      "\n",
      "LOG: Epoch [102/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1823\n",
      "Epoch [102/2000], Avg Train Loss: 5.1823\n",
      "Epoch [102/2000], Avg Val Loss: 3.2494\n",
      "Validation loss improved from 3.2503 to 3.2494. Saving model...\n",
      "\n",
      "LOG: Epoch [103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1695\n",
      "Epoch [103/2000], Avg Train Loss: 5.1695\n",
      "Epoch [103/2000], Avg Val Loss: 3.2484\n",
      "Validation loss improved from 3.2494 to 3.2484. Saving model...\n",
      "\n",
      "LOG: Epoch [104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1404\n",
      "Epoch [104/2000], Avg Train Loss: 5.1404\n",
      "Epoch [104/2000], Avg Val Loss: 3.2474\n",
      "Validation loss improved from 3.2484 to 3.2474. Saving model...\n",
      "\n",
      "LOG: Epoch [105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0881\n",
      "Epoch [105/2000], Avg Train Loss: 5.0881\n",
      "Epoch [105/2000], Avg Val Loss: 3.2465\n",
      "Validation loss improved from 3.2474 to 3.2465. Saving model...\n",
      "\n",
      "LOG: Epoch [106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1427\n",
      "Epoch [106/2000], Avg Train Loss: 5.1427\n",
      "Epoch [106/2000], Avg Val Loss: 3.2455\n",
      "Validation loss improved from 3.2465 to 3.2455. Saving model...\n",
      "\n",
      "LOG: Epoch [107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1692\n",
      "Epoch [107/2000], Avg Train Loss: 5.1692\n",
      "Epoch [107/2000], Avg Val Loss: 3.2445\n",
      "Validation loss improved from 3.2455 to 3.2445. Saving model...\n",
      "\n",
      "LOG: Epoch [108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1124\n",
      "Epoch [108/2000], Avg Train Loss: 5.1124\n",
      "Epoch [108/2000], Avg Val Loss: 3.2436\n",
      "Validation loss improved from 3.2445 to 3.2436. Saving model...\n",
      "\n",
      "LOG: Epoch [109/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.0923\n",
      "Epoch [109/2000], Avg Train Loss: 5.0923\n",
      "Epoch [109/2000], Avg Val Loss: 3.2426\n",
      "Validation loss improved from 3.2436 to 3.2426. Saving model...\n",
      "\n",
      "LOG: Epoch [110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1605\n",
      "Epoch [110/2000], Avg Train Loss: 5.1605\n",
      "Epoch [110/2000], Avg Val Loss: 3.2417\n",
      "Validation loss improved from 3.2426 to 3.2417. Saving model...\n",
      "\n",
      "LOG: Epoch [111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1444\n",
      "Epoch [111/2000], Avg Train Loss: 5.1444\n",
      "Epoch [111/2000], Avg Val Loss: 3.2407\n",
      "Validation loss improved from 3.2417 to 3.2407. Saving model...\n",
      "\n",
      "LOG: Epoch [112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1008\n",
      "Epoch [112/2000], Avg Train Loss: 5.1008\n",
      "Epoch [112/2000], Avg Val Loss: 3.2398\n",
      "Validation loss improved from 3.2407 to 3.2398. Saving model...\n",
      "\n",
      "LOG: Epoch [113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1054\n",
      "Epoch [113/2000], Avg Train Loss: 5.1054\n",
      "Epoch [113/2000], Avg Val Loss: 3.2389\n",
      "Validation loss improved from 3.2398 to 3.2389. Saving model...\n",
      "\n",
      "LOG: Epoch [114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1501\n",
      "Epoch [114/2000], Avg Train Loss: 5.1501\n",
      "Epoch [114/2000], Avg Val Loss: 3.2380\n",
      "Validation loss improved from 3.2389 to 3.2380. Saving model...\n",
      "\n",
      "LOG: Epoch [115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1420\n",
      "Epoch [115/2000], Avg Train Loss: 5.1420\n",
      "Epoch [115/2000], Avg Val Loss: 3.2371\n",
      "Validation loss improved from 3.2380 to 3.2371. Saving model...\n",
      "\n",
      "LOG: Epoch [116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0422\n",
      "Epoch [116/2000], Avg Train Loss: 5.0422\n",
      "Epoch [116/2000], Avg Val Loss: 3.2362\n",
      "Validation loss improved from 3.2371 to 3.2362. Saving model...\n",
      "\n",
      "LOG: Epoch [117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0855\n",
      "Epoch [117/2000], Avg Train Loss: 5.0855\n",
      "Epoch [117/2000], Avg Val Loss: 3.2353\n",
      "Validation loss improved from 3.2362 to 3.2353. Saving model...\n",
      "\n",
      "LOG: Epoch [118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0809\n",
      "Epoch [118/2000], Avg Train Loss: 5.0809\n",
      "Epoch [118/2000], Avg Val Loss: 3.2344\n",
      "Validation loss improved from 3.2353 to 3.2344. Saving model...\n",
      "\n",
      "LOG: Epoch [119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0627\n",
      "Epoch [119/2000], Avg Train Loss: 5.0627\n",
      "Epoch [119/2000], Avg Val Loss: 3.2336\n",
      "Validation loss improved from 3.2344 to 3.2336. Saving model...\n",
      "\n",
      "LOG: Epoch [120/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0517\n",
      "Epoch [120/2000], Avg Train Loss: 5.0517\n",
      "Epoch [120/2000], Avg Val Loss: 3.2327\n",
      "Validation loss improved from 3.2336 to 3.2327. Saving model...\n",
      "\n",
      "LOG: Epoch [121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0711\n",
      "Epoch [121/2000], Avg Train Loss: 5.0711\n",
      "Epoch [121/2000], Avg Val Loss: 3.2318\n",
      "Validation loss improved from 3.2327 to 3.2318. Saving model...\n",
      "\n",
      "LOG: Epoch [122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0318\n",
      "Epoch [122/2000], Avg Train Loss: 5.0318\n",
      "Epoch [122/2000], Avg Val Loss: 3.2310\n",
      "Validation loss improved from 3.2318 to 3.2310. Saving model...\n",
      "\n",
      "LOG: Epoch [123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0709\n",
      "Epoch [123/2000], Avg Train Loss: 5.0709\n",
      "Epoch [123/2000], Avg Val Loss: 3.2301\n",
      "Validation loss improved from 3.2310 to 3.2301. Saving model...\n",
      "\n",
      "LOG: Epoch [124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0265\n",
      "Epoch [124/2000], Avg Train Loss: 5.0265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124/2000], Avg Val Loss: 3.2292\n",
      "Validation loss improved from 3.2301 to 3.2292. Saving model...\n",
      "\n",
      "LOG: Epoch [125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0618\n",
      "Epoch [125/2000], Avg Train Loss: 5.0618\n",
      "Epoch [125/2000], Avg Val Loss: 3.2284\n",
      "Validation loss improved from 3.2292 to 3.2284. Saving model...\n",
      "\n",
      "LOG: Epoch [126/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0643\n",
      "Epoch [126/2000], Avg Train Loss: 5.0643\n",
      "Epoch [126/2000], Avg Val Loss: 3.2275\n",
      "Validation loss improved from 3.2284 to 3.2275. Saving model...\n",
      "\n",
      "LOG: Epoch [127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0683\n",
      "Epoch [127/2000], Avg Train Loss: 5.0683\n",
      "Epoch [127/2000], Avg Val Loss: 3.2266\n",
      "Validation loss improved from 3.2275 to 3.2266. Saving model...\n",
      "\n",
      "LOG: Epoch [128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0579\n",
      "Epoch [128/2000], Avg Train Loss: 5.0579\n",
      "Epoch [128/2000], Avg Val Loss: 3.2257\n",
      "Validation loss improved from 3.2266 to 3.2257. Saving model...\n",
      "\n",
      "LOG: Epoch [129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0216\n",
      "Epoch [129/2000], Avg Train Loss: 5.0216\n",
      "Epoch [129/2000], Avg Val Loss: 3.2248\n",
      "Validation loss improved from 3.2257 to 3.2248. Saving model...\n",
      "\n",
      "LOG: Epoch [130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0097\n",
      "Epoch [130/2000], Avg Train Loss: 5.0097\n",
      "Epoch [130/2000], Avg Val Loss: 3.2239\n",
      "Validation loss improved from 3.2248 to 3.2239. Saving model...\n",
      "\n",
      "LOG: Epoch [131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0200\n",
      "Epoch [131/2000], Avg Train Loss: 5.0200\n",
      "Epoch [131/2000], Avg Val Loss: 3.2231\n",
      "Validation loss improved from 3.2239 to 3.2231. Saving model...\n",
      "\n",
      "LOG: Epoch [132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0162\n",
      "Epoch [132/2000], Avg Train Loss: 5.0162\n",
      "Epoch [132/2000], Avg Val Loss: 3.2222\n",
      "Validation loss improved from 3.2231 to 3.2222. Saving model...\n",
      "\n",
      "LOG: Epoch [133/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9629\n",
      "Epoch [133/2000], Avg Train Loss: 4.9629\n",
      "Epoch [133/2000], Avg Val Loss: 3.2214\n",
      "Validation loss improved from 3.2222 to 3.2214. Saving model...\n",
      "\n",
      "LOG: Epoch [134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0285\n",
      "Epoch [134/2000], Avg Train Loss: 5.0285\n",
      "Epoch [134/2000], Avg Val Loss: 3.2205\n",
      "Validation loss improved from 3.2214 to 3.2205. Saving model...\n",
      "\n",
      "LOG: Epoch [135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9871\n",
      "Epoch [135/2000], Avg Train Loss: 4.9871\n",
      "Epoch [135/2000], Avg Val Loss: 3.2196\n",
      "Validation loss improved from 3.2205 to 3.2196. Saving model...\n",
      "\n",
      "LOG: Epoch [136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0086\n",
      "Epoch [136/2000], Avg Train Loss: 5.0086\n",
      "Epoch [136/2000], Avg Val Loss: 3.2187\n",
      "Validation loss improved from 3.2196 to 3.2187. Saving model...\n",
      "\n",
      "LOG: Epoch [137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0347\n",
      "Epoch [137/2000], Avg Train Loss: 5.0347\n",
      "Epoch [137/2000], Avg Val Loss: 3.2177\n",
      "Validation loss improved from 3.2187 to 3.2177. Saving model...\n",
      "\n",
      "LOG: Epoch [138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9552\n",
      "Epoch [138/2000], Avg Train Loss: 4.9552\n",
      "Epoch [138/2000], Avg Val Loss: 3.2168\n",
      "Validation loss improved from 3.2177 to 3.2168. Saving model...\n",
      "\n",
      "LOG: Epoch [139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0043\n",
      "Epoch [139/2000], Avg Train Loss: 5.0043\n",
      "Epoch [139/2000], Avg Val Loss: 3.2159\n",
      "Validation loss improved from 3.2168 to 3.2159. Saving model...\n",
      "\n",
      "LOG: Epoch [140/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9772\n",
      "Epoch [140/2000], Avg Train Loss: 4.9772\n",
      "Epoch [140/2000], Avg Val Loss: 3.2149\n",
      "Validation loss improved from 3.2159 to 3.2149. Saving model...\n",
      "\n",
      "LOG: Epoch [141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9655\n",
      "Epoch [141/2000], Avg Train Loss: 4.9655\n",
      "Epoch [141/2000], Avg Val Loss: 3.2140\n",
      "Validation loss improved from 3.2149 to 3.2140. Saving model...\n",
      "\n",
      "LOG: Epoch [142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9228\n",
      "Epoch [142/2000], Avg Train Loss: 4.9228\n",
      "Epoch [142/2000], Avg Val Loss: 3.2130\n",
      "Validation loss improved from 3.2140 to 3.2130. Saving model...\n",
      "\n",
      "LOG: Epoch [143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9555\n",
      "Epoch [143/2000], Avg Train Loss: 4.9555\n",
      "Epoch [143/2000], Avg Val Loss: 3.2121\n",
      "Validation loss improved from 3.2130 to 3.2121. Saving model...\n",
      "\n",
      "LOG: Epoch [144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9522\n",
      "Epoch [144/2000], Avg Train Loss: 4.9522\n",
      "Epoch [144/2000], Avg Val Loss: 3.2111\n",
      "Validation loss improved from 3.2121 to 3.2111. Saving model...\n",
      "\n",
      "LOG: Epoch [145/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.0318\n",
      "Epoch [145/2000], Avg Train Loss: 5.0318\n",
      "Epoch [145/2000], Avg Val Loss: 3.2102\n",
      "Validation loss improved from 3.2111 to 3.2102. Saving model...\n",
      "\n",
      "LOG: Epoch [146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9363\n",
      "Epoch [146/2000], Avg Train Loss: 4.9363\n",
      "Epoch [146/2000], Avg Val Loss: 3.2092\n",
      "Validation loss improved from 3.2102 to 3.2092. Saving model...\n",
      "\n",
      "LOG: Epoch [147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9143\n",
      "Epoch [147/2000], Avg Train Loss: 4.9143\n",
      "Epoch [147/2000], Avg Val Loss: 3.2083\n",
      "Validation loss improved from 3.2092 to 3.2083. Saving model...\n",
      "\n",
      "LOG: Epoch [148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9312\n",
      "Epoch [148/2000], Avg Train Loss: 4.9312\n",
      "Epoch [148/2000], Avg Val Loss: 3.2073\n",
      "Validation loss improved from 3.2083 to 3.2073. Saving model...\n",
      "\n",
      "LOG: Epoch [149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9425\n",
      "Epoch [149/2000], Avg Train Loss: 4.9425\n",
      "Epoch [149/2000], Avg Val Loss: 3.2064\n",
      "Validation loss improved from 3.2073 to 3.2064. Saving model...\n",
      "\n",
      "LOG: Epoch [150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9382\n",
      "Epoch [150/2000], Avg Train Loss: 4.9382\n",
      "Epoch [150/2000], Avg Val Loss: 3.2054\n",
      "Validation loss improved from 3.2064 to 3.2054. Saving model...\n",
      "\n",
      "LOG: Epoch [151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9414\n",
      "Epoch [151/2000], Avg Train Loss: 4.9414\n",
      "Epoch [151/2000], Avg Val Loss: 3.2044\n",
      "Validation loss improved from 3.2054 to 3.2044. Saving model...\n",
      "\n",
      "LOG: Epoch [152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9004\n",
      "Epoch [152/2000], Avg Train Loss: 4.9004\n",
      "Epoch [152/2000], Avg Val Loss: 3.2035\n",
      "Validation loss improved from 3.2044 to 3.2035. Saving model...\n",
      "\n",
      "LOG: Epoch [153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9559\n",
      "Epoch [153/2000], Avg Train Loss: 4.9559\n",
      "Epoch [153/2000], Avg Val Loss: 3.2025\n",
      "Validation loss improved from 3.2035 to 3.2025. Saving model...\n",
      "\n",
      "LOG: Epoch [154/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9317\n",
      "Epoch [154/2000], Avg Train Loss: 4.9317\n",
      "Epoch [154/2000], Avg Val Loss: 3.2015\n",
      "Validation loss improved from 3.2025 to 3.2015. Saving model...\n",
      "\n",
      "LOG: Epoch [155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8917\n",
      "Epoch [155/2000], Avg Train Loss: 4.8917\n",
      "Epoch [155/2000], Avg Val Loss: 3.2005\n",
      "Validation loss improved from 3.2015 to 3.2005. Saving model...\n",
      "\n",
      "LOG: Epoch [156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9715\n",
      "Epoch [156/2000], Avg Train Loss: 4.9715\n",
      "Epoch [156/2000], Avg Val Loss: 3.1995\n",
      "Validation loss improved from 3.2005 to 3.1995. Saving model...\n",
      "\n",
      "LOG: Epoch [157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9412\n",
      "Epoch [157/2000], Avg Train Loss: 4.9412\n",
      "Epoch [157/2000], Avg Val Loss: 3.1986\n",
      "Validation loss improved from 3.1995 to 3.1986. Saving model...\n",
      "\n",
      "LOG: Epoch [158/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9161\n",
      "Epoch [158/2000], Avg Train Loss: 4.9161\n",
      "Epoch [158/2000], Avg Val Loss: 3.1976\n",
      "Validation loss improved from 3.1986 to 3.1976. Saving model...\n",
      "\n",
      "LOG: Epoch [159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8848\n",
      "Epoch [159/2000], Avg Train Loss: 4.8848\n",
      "Epoch [159/2000], Avg Val Loss: 3.1966\n",
      "Validation loss improved from 3.1976 to 3.1966. Saving model...\n",
      "\n",
      "LOG: Epoch [160/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.8618\n",
      "Epoch [160/2000], Avg Train Loss: 4.8618\n",
      "Epoch [160/2000], Avg Val Loss: 3.1956\n",
      "Validation loss improved from 3.1966 to 3.1956. Saving model...\n",
      "\n",
      "LOG: Epoch [161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9102\n",
      "Epoch [161/2000], Avg Train Loss: 4.9102\n",
      "Epoch [161/2000], Avg Val Loss: 3.1946\n",
      "Validation loss improved from 3.1956 to 3.1946. Saving model...\n",
      "\n",
      "LOG: Epoch [162/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8667\n",
      "Epoch [162/2000], Avg Train Loss: 4.8667\n",
      "Epoch [162/2000], Avg Val Loss: 3.1936\n",
      "Validation loss improved from 3.1946 to 3.1936. Saving model...\n",
      "\n",
      "LOG: Epoch [163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8624\n",
      "Epoch [163/2000], Avg Train Loss: 4.8624\n",
      "Epoch [163/2000], Avg Val Loss: 3.1926\n",
      "Validation loss improved from 3.1936 to 3.1926. Saving model...\n",
      "\n",
      "LOG: Epoch [164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8808\n",
      "Epoch [164/2000], Avg Train Loss: 4.8808\n",
      "Epoch [164/2000], Avg Val Loss: 3.1916\n",
      "Validation loss improved from 3.1926 to 3.1916. Saving model...\n",
      "\n",
      "LOG: Epoch [165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9351\n",
      "Epoch [165/2000], Avg Train Loss: 4.9351\n",
      "Epoch [165/2000], Avg Val Loss: 3.1906\n",
      "Validation loss improved from 3.1916 to 3.1906. Saving model...\n",
      "\n",
      "LOG: Epoch [166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8878\n",
      "Epoch [166/2000], Avg Train Loss: 4.8878\n",
      "Epoch [166/2000], Avg Val Loss: 3.1895\n",
      "Validation loss improved from 3.1906 to 3.1895. Saving model...\n",
      "\n",
      "LOG: Epoch [167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8963\n",
      "Epoch [167/2000], Avg Train Loss: 4.8963\n",
      "Epoch [167/2000], Avg Val Loss: 3.1885\n",
      "Validation loss improved from 3.1895 to 3.1885. Saving model...\n",
      "\n",
      "LOG: Epoch [168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9134\n",
      "Epoch [168/2000], Avg Train Loss: 4.9134\n",
      "Epoch [168/2000], Avg Val Loss: 3.1875\n",
      "Validation loss improved from 3.1885 to 3.1875. Saving model...\n",
      "\n",
      "LOG: Epoch [169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8998\n",
      "Epoch [169/2000], Avg Train Loss: 4.8998\n",
      "Epoch [169/2000], Avg Val Loss: 3.1864\n",
      "Validation loss improved from 3.1875 to 3.1864. Saving model...\n",
      "\n",
      "LOG: Epoch [170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9242\n",
      "Epoch [170/2000], Avg Train Loss: 4.9242\n",
      "Epoch [170/2000], Avg Val Loss: 3.1854\n",
      "Validation loss improved from 3.1864 to 3.1854. Saving model...\n",
      "\n",
      "LOG: Epoch [171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8422\n",
      "Epoch [171/2000], Avg Train Loss: 4.8422\n",
      "Epoch [171/2000], Avg Val Loss: 3.1844\n",
      "Validation loss improved from 3.1854 to 3.1844. Saving model...\n",
      "\n",
      "LOG: Epoch [172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8789\n",
      "Epoch [172/2000], Avg Train Loss: 4.8789\n",
      "Epoch [172/2000], Avg Val Loss: 3.1834\n",
      "Validation loss improved from 3.1844 to 3.1834. Saving model...\n",
      "\n",
      "LOG: Epoch [173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9010\n",
      "Epoch [173/2000], Avg Train Loss: 4.9010\n",
      "Epoch [173/2000], Avg Val Loss: 3.1823\n",
      "Validation loss improved from 3.1834 to 3.1823. Saving model...\n",
      "\n",
      "LOG: Epoch [174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8747\n",
      "Epoch [174/2000], Avg Train Loss: 4.8747\n",
      "Epoch [174/2000], Avg Val Loss: 3.1813\n",
      "Validation loss improved from 3.1823 to 3.1813. Saving model...\n",
      "\n",
      "LOG: Epoch [175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8536\n",
      "Epoch [175/2000], Avg Train Loss: 4.8536\n",
      "Epoch [175/2000], Avg Val Loss: 3.1803\n",
      "Validation loss improved from 3.1813 to 3.1803. Saving model...\n",
      "\n",
      "LOG: Epoch [176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8652\n",
      "Epoch [176/2000], Avg Train Loss: 4.8652\n",
      "Epoch [176/2000], Avg Val Loss: 3.1793\n",
      "Validation loss improved from 3.1803 to 3.1793. Saving model...\n",
      "\n",
      "LOG: Epoch [177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8836\n",
      "Epoch [177/2000], Avg Train Loss: 4.8836\n",
      "Epoch [177/2000], Avg Val Loss: 3.1782\n",
      "Validation loss improved from 3.1793 to 3.1782. Saving model...\n",
      "\n",
      "LOG: Epoch [178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8815\n",
      "Epoch [178/2000], Avg Train Loss: 4.8815\n",
      "Epoch [178/2000], Avg Val Loss: 3.1772\n",
      "Validation loss improved from 3.1782 to 3.1772. Saving model...\n",
      "\n",
      "LOG: Epoch [179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8502\n",
      "Epoch [179/2000], Avg Train Loss: 4.8502\n",
      "Epoch [179/2000], Avg Val Loss: 3.1762\n",
      "Validation loss improved from 3.1772 to 3.1762. Saving model...\n",
      "\n",
      "LOG: Epoch [180/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.8867\n",
      "Epoch [180/2000], Avg Train Loss: 4.8867\n",
      "Epoch [180/2000], Avg Val Loss: 3.1752\n",
      "Validation loss improved from 3.1762 to 3.1752. Saving model...\n",
      "\n",
      "LOG: Epoch [181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8671\n",
      "Epoch [181/2000], Avg Train Loss: 4.8671\n",
      "Epoch [181/2000], Avg Val Loss: 3.1741\n",
      "Validation loss improved from 3.1752 to 3.1741. Saving model...\n",
      "\n",
      "LOG: Epoch [182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8284\n",
      "Epoch [182/2000], Avg Train Loss: 4.8284\n",
      "Epoch [182/2000], Avg Val Loss: 3.1731\n",
      "Validation loss improved from 3.1741 to 3.1731. Saving model...\n",
      "\n",
      "LOG: Epoch [183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8357\n",
      "Epoch [183/2000], Avg Train Loss: 4.8357\n",
      "Epoch [183/2000], Avg Val Loss: 3.1721\n",
      "Validation loss improved from 3.1731 to 3.1721. Saving model...\n",
      "\n",
      "LOG: Epoch [184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9081\n",
      "Epoch [184/2000], Avg Train Loss: 4.9081\n",
      "Epoch [184/2000], Avg Val Loss: 3.1710\n",
      "Validation loss improved from 3.1721 to 3.1710. Saving model...\n",
      "\n",
      "LOG: Epoch [185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8567\n",
      "Epoch [185/2000], Avg Train Loss: 4.8567\n",
      "Epoch [185/2000], Avg Val Loss: 3.1700\n",
      "Validation loss improved from 3.1710 to 3.1700. Saving model...\n",
      "\n",
      "LOG: Epoch [186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8244\n",
      "Epoch [186/2000], Avg Train Loss: 4.8244\n",
      "Epoch [186/2000], Avg Val Loss: 3.1690\n",
      "Validation loss improved from 3.1700 to 3.1690. Saving model...\n",
      "\n",
      "LOG: Epoch [187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7949\n",
      "Epoch [187/2000], Avg Train Loss: 4.7949\n",
      "Epoch [187/2000], Avg Val Loss: 3.1679\n",
      "Validation loss improved from 3.1690 to 3.1679. Saving model...\n",
      "\n",
      "LOG: Epoch [188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8459\n",
      "Epoch [188/2000], Avg Train Loss: 4.8459\n",
      "Epoch [188/2000], Avg Val Loss: 3.1669\n",
      "Validation loss improved from 3.1679 to 3.1669. Saving model...\n",
      "\n",
      "LOG: Epoch [189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8220\n",
      "Epoch [189/2000], Avg Train Loss: 4.8220\n",
      "Epoch [189/2000], Avg Val Loss: 3.1658\n",
      "Validation loss improved from 3.1669 to 3.1658. Saving model...\n",
      "\n",
      "LOG: Epoch [190/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8468\n",
      "Epoch [190/2000], Avg Train Loss: 4.8468\n",
      "Epoch [190/2000], Avg Val Loss: 3.1648\n",
      "Validation loss improved from 3.1658 to 3.1648. Saving model...\n",
      "\n",
      "LOG: Epoch [191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8306\n",
      "Epoch [191/2000], Avg Train Loss: 4.8306\n",
      "Epoch [191/2000], Avg Val Loss: 3.1638\n",
      "Validation loss improved from 3.1648 to 3.1638. Saving model...\n",
      "\n",
      "LOG: Epoch [192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8029\n",
      "Epoch [192/2000], Avg Train Loss: 4.8029\n",
      "Epoch [192/2000], Avg Val Loss: 3.1628\n",
      "Validation loss improved from 3.1638 to 3.1628. Saving model...\n",
      "\n",
      "LOG: Epoch [193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.8176\n",
      "Epoch [193/2000], Avg Train Loss: 4.8176\n",
      "Epoch [193/2000], Avg Val Loss: 3.1617\n",
      "Validation loss improved from 3.1628 to 3.1617. Saving model...\n",
      "\n",
      "LOG: Epoch [194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8030\n",
      "Epoch [194/2000], Avg Train Loss: 4.8030\n",
      "Epoch [194/2000], Avg Val Loss: 3.1607\n",
      "Validation loss improved from 3.1617 to 3.1607. Saving model...\n",
      "\n",
      "LOG: Epoch [195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7978\n",
      "Epoch [195/2000], Avg Train Loss: 4.7978\n",
      "Epoch [195/2000], Avg Val Loss: 3.1596\n",
      "Validation loss improved from 3.1607 to 3.1596. Saving model...\n",
      "\n",
      "LOG: Epoch [196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8071\n",
      "Epoch [196/2000], Avg Train Loss: 4.8071\n",
      "Epoch [196/2000], Avg Val Loss: 3.1586\n",
      "Validation loss improved from 3.1596 to 3.1586. Saving model...\n",
      "\n",
      "LOG: Epoch [197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8278\n",
      "Epoch [197/2000], Avg Train Loss: 4.8278\n",
      "Epoch [197/2000], Avg Val Loss: 3.1576\n",
      "Validation loss improved from 3.1586 to 3.1576. Saving model...\n",
      "\n",
      "LOG: Epoch [198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7959\n",
      "Epoch [198/2000], Avg Train Loss: 4.7959\n",
      "Epoch [198/2000], Avg Val Loss: 3.1565\n",
      "Validation loss improved from 3.1576 to 3.1565. Saving model...\n",
      "\n",
      "LOG: Epoch [199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8111\n",
      "Epoch [199/2000], Avg Train Loss: 4.8111\n",
      "Epoch [199/2000], Avg Val Loss: 3.1555\n",
      "Validation loss improved from 3.1565 to 3.1555. Saving model...\n",
      "\n",
      "LOG: Epoch [200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7972\n",
      "Epoch [200/2000], Avg Train Loss: 4.7972\n",
      "Epoch [200/2000], Avg Val Loss: 3.1545\n",
      "Validation loss improved from 3.1555 to 3.1545. Saving model...\n",
      "\n",
      "LOG: Epoch [201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7961\n",
      "Epoch [201/2000], Avg Train Loss: 4.7961\n",
      "Epoch [201/2000], Avg Val Loss: 3.1535\n",
      "Validation loss improved from 3.1545 to 3.1535. Saving model...\n",
      "\n",
      "LOG: Epoch [202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8209\n",
      "Epoch [202/2000], Avg Train Loss: 4.8209\n",
      "Epoch [202/2000], Avg Val Loss: 3.1525\n",
      "Validation loss improved from 3.1535 to 3.1525. Saving model...\n",
      "\n",
      "LOG: Epoch [203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7678\n",
      "Epoch [203/2000], Avg Train Loss: 4.7678\n",
      "Epoch [203/2000], Avg Val Loss: 3.1515\n",
      "Validation loss improved from 3.1525 to 3.1515. Saving model...\n",
      "\n",
      "LOG: Epoch [204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7755\n",
      "Epoch [204/2000], Avg Train Loss: 4.7755\n",
      "Epoch [204/2000], Avg Val Loss: 3.1505\n",
      "Validation loss improved from 3.1515 to 3.1505. Saving model...\n",
      "\n",
      "LOG: Epoch [205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8090\n",
      "Epoch [205/2000], Avg Train Loss: 4.8090\n",
      "Epoch [205/2000], Avg Val Loss: 3.1495\n",
      "Validation loss improved from 3.1505 to 3.1495. Saving model...\n",
      "\n",
      "LOG: Epoch [206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7918\n",
      "Epoch [206/2000], Avg Train Loss: 4.7918\n",
      "Epoch [206/2000], Avg Val Loss: 3.1484\n",
      "Validation loss improved from 3.1495 to 3.1484. Saving model...\n",
      "\n",
      "LOG: Epoch [207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7815\n",
      "Epoch [207/2000], Avg Train Loss: 4.7815\n",
      "Epoch [207/2000], Avg Val Loss: 3.1474\n",
      "Validation loss improved from 3.1484 to 3.1474. Saving model...\n",
      "\n",
      "LOG: Epoch [208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7745\n",
      "Epoch [208/2000], Avg Train Loss: 4.7745\n",
      "Epoch [208/2000], Avg Val Loss: 3.1463\n",
      "Validation loss improved from 3.1474 to 3.1463. Saving model...\n",
      "\n",
      "LOG: Epoch [209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7640\n",
      "Epoch [209/2000], Avg Train Loss: 4.7640\n",
      "Epoch [209/2000], Avg Val Loss: 3.1452\n",
      "Validation loss improved from 3.1463 to 3.1452. Saving model...\n",
      "\n",
      "LOG: Epoch [210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7590\n",
      "Epoch [210/2000], Avg Train Loss: 4.7590\n",
      "Epoch [210/2000], Avg Val Loss: 3.1441\n",
      "Validation loss improved from 3.1452 to 3.1441. Saving model...\n",
      "\n",
      "LOG: Epoch [211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7413\n",
      "Epoch [211/2000], Avg Train Loss: 4.7413\n",
      "Epoch [211/2000], Avg Val Loss: 3.1429\n",
      "Validation loss improved from 3.1441 to 3.1429. Saving model...\n",
      "\n",
      "LOG: Epoch [212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7767\n",
      "Epoch [212/2000], Avg Train Loss: 4.7767\n",
      "Epoch [212/2000], Avg Val Loss: 3.1418\n",
      "Validation loss improved from 3.1429 to 3.1418. Saving model...\n",
      "\n",
      "LOG: Epoch [213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7632\n",
      "Epoch [213/2000], Avg Train Loss: 4.7632\n",
      "Epoch [213/2000], Avg Val Loss: 3.1406\n",
      "Validation loss improved from 3.1418 to 3.1406. Saving model...\n",
      "\n",
      "LOG: Epoch [214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7461\n",
      "Epoch [214/2000], Avg Train Loss: 4.7461\n",
      "Epoch [214/2000], Avg Val Loss: 3.1395\n",
      "Validation loss improved from 3.1406 to 3.1395. Saving model...\n",
      "\n",
      "LOG: Epoch [215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7863\n",
      "Epoch [215/2000], Avg Train Loss: 4.7863\n",
      "Epoch [215/2000], Avg Val Loss: 3.1383\n",
      "Validation loss improved from 3.1395 to 3.1383. Saving model...\n",
      "\n",
      "LOG: Epoch [216/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.7436\n",
      "Epoch [216/2000], Avg Train Loss: 4.7436\n",
      "Epoch [216/2000], Avg Val Loss: 3.1372\n",
      "Validation loss improved from 3.1383 to 3.1372. Saving model...\n",
      "\n",
      "LOG: Epoch [217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7869\n",
      "Epoch [217/2000], Avg Train Loss: 4.7869\n",
      "Epoch [217/2000], Avg Val Loss: 3.1360\n",
      "Validation loss improved from 3.1372 to 3.1360. Saving model...\n",
      "\n",
      "LOG: Epoch [218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7443\n",
      "Epoch [218/2000], Avg Train Loss: 4.7443\n",
      "Epoch [218/2000], Avg Val Loss: 3.1348\n",
      "Validation loss improved from 3.1360 to 3.1348. Saving model...\n",
      "\n",
      "LOG: Epoch [219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7371\n",
      "Epoch [219/2000], Avg Train Loss: 4.7371\n",
      "Epoch [219/2000], Avg Val Loss: 3.1336\n",
      "Validation loss improved from 3.1348 to 3.1336. Saving model...\n",
      "\n",
      "LOG: Epoch [220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7369\n",
      "Epoch [220/2000], Avg Train Loss: 4.7369\n",
      "Epoch [220/2000], Avg Val Loss: 3.1324\n",
      "Validation loss improved from 3.1336 to 3.1324. Saving model...\n",
      "\n",
      "LOG: Epoch [221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7433\n",
      "Epoch [221/2000], Avg Train Loss: 4.7433\n",
      "Epoch [221/2000], Avg Val Loss: 3.1312\n",
      "Validation loss improved from 3.1324 to 3.1312. Saving model...\n",
      "\n",
      "LOG: Epoch [222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7082\n",
      "Epoch [222/2000], Avg Train Loss: 4.7082\n",
      "Epoch [222/2000], Avg Val Loss: 3.1300\n",
      "Validation loss improved from 3.1312 to 3.1300. Saving model...\n",
      "\n",
      "LOG: Epoch [223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7735\n",
      "Epoch [223/2000], Avg Train Loss: 4.7735\n",
      "Epoch [223/2000], Avg Val Loss: 3.1288\n",
      "Validation loss improved from 3.1300 to 3.1288. Saving model...\n",
      "\n",
      "LOG: Epoch [224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7678\n",
      "Epoch [224/2000], Avg Train Loss: 4.7678\n",
      "Epoch [224/2000], Avg Val Loss: 3.1275\n",
      "Validation loss improved from 3.1288 to 3.1275. Saving model...\n",
      "\n",
      "LOG: Epoch [225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7346\n",
      "Epoch [225/2000], Avg Train Loss: 4.7346\n",
      "Epoch [225/2000], Avg Val Loss: 3.1263\n",
      "Validation loss improved from 3.1275 to 3.1263. Saving model...\n",
      "\n",
      "LOG: Epoch [226/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7529\n",
      "Epoch [226/2000], Avg Train Loss: 4.7529\n",
      "Epoch [226/2000], Avg Val Loss: 3.1251\n",
      "Validation loss improved from 3.1263 to 3.1251. Saving model...\n",
      "\n",
      "LOG: Epoch [227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7692\n",
      "Epoch [227/2000], Avg Train Loss: 4.7692\n",
      "Epoch [227/2000], Avg Val Loss: 3.1239\n",
      "Validation loss improved from 3.1251 to 3.1239. Saving model...\n",
      "\n",
      "LOG: Epoch [228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6966\n",
      "Epoch [228/2000], Avg Train Loss: 4.6966\n",
      "Epoch [228/2000], Avg Val Loss: 3.1226\n",
      "Validation loss improved from 3.1239 to 3.1226. Saving model...\n",
      "\n",
      "LOG: Epoch [229/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.7406\n",
      "Epoch [229/2000], Avg Train Loss: 4.7406\n",
      "Epoch [229/2000], Avg Val Loss: 3.1214\n",
      "Validation loss improved from 3.1226 to 3.1214. Saving model...\n",
      "\n",
      "LOG: Epoch [230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6741\n",
      "Epoch [230/2000], Avg Train Loss: 4.6741\n",
      "Epoch [230/2000], Avg Val Loss: 3.1201\n",
      "Validation loss improved from 3.1214 to 3.1201. Saving model...\n",
      "\n",
      "LOG: Epoch [231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7218\n",
      "Epoch [231/2000], Avg Train Loss: 4.7218\n",
      "Epoch [231/2000], Avg Val Loss: 3.1189\n",
      "Validation loss improved from 3.1201 to 3.1189. Saving model...\n",
      "\n",
      "LOG: Epoch [232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6994\n",
      "Epoch [232/2000], Avg Train Loss: 4.6994\n",
      "Epoch [232/2000], Avg Val Loss: 3.1176\n",
      "Validation loss improved from 3.1189 to 3.1176. Saving model...\n",
      "\n",
      "LOG: Epoch [233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7656\n",
      "Epoch [233/2000], Avg Train Loss: 4.7656\n",
      "Epoch [233/2000], Avg Val Loss: 3.1164\n",
      "Validation loss improved from 3.1176 to 3.1164. Saving model...\n",
      "\n",
      "LOG: Epoch [234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7060\n",
      "Epoch [234/2000], Avg Train Loss: 4.7060\n",
      "Epoch [234/2000], Avg Val Loss: 3.1152\n",
      "Validation loss improved from 3.1164 to 3.1152. Saving model...\n",
      "\n",
      "LOG: Epoch [235/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7145\n",
      "Epoch [235/2000], Avg Train Loss: 4.7145\n",
      "Epoch [235/2000], Avg Val Loss: 3.1140\n",
      "Validation loss improved from 3.1152 to 3.1140. Saving model...\n",
      "\n",
      "LOG: Epoch [236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7728\n",
      "Epoch [236/2000], Avg Train Loss: 4.7728\n",
      "Epoch [236/2000], Avg Val Loss: 3.1128\n",
      "Validation loss improved from 3.1140 to 3.1128. Saving model...\n",
      "\n",
      "LOG: Epoch [237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7310\n",
      "Epoch [237/2000], Avg Train Loss: 4.7310\n",
      "Epoch [237/2000], Avg Val Loss: 3.1116\n",
      "Validation loss improved from 3.1128 to 3.1116. Saving model...\n",
      "\n",
      "LOG: Epoch [238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6864\n",
      "Epoch [238/2000], Avg Train Loss: 4.6864\n",
      "Epoch [238/2000], Avg Val Loss: 3.1105\n",
      "Validation loss improved from 3.1116 to 3.1105. Saving model...\n",
      "\n",
      "LOG: Epoch [239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7185\n",
      "Epoch [239/2000], Avg Train Loss: 4.7185\n",
      "Epoch [239/2000], Avg Val Loss: 3.1093\n",
      "Validation loss improved from 3.1105 to 3.1093. Saving model...\n",
      "\n",
      "LOG: Epoch [240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6753\n",
      "Epoch [240/2000], Avg Train Loss: 4.6753\n",
      "Epoch [240/2000], Avg Val Loss: 3.1082\n",
      "Validation loss improved from 3.1093 to 3.1082. Saving model...\n",
      "\n",
      "LOG: Epoch [241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7059\n",
      "Epoch [241/2000], Avg Train Loss: 4.7059\n",
      "Epoch [241/2000], Avg Val Loss: 3.1070\n",
      "Validation loss improved from 3.1082 to 3.1070. Saving model...\n",
      "\n",
      "LOG: Epoch [242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6856\n",
      "Epoch [242/2000], Avg Train Loss: 4.6856\n",
      "Epoch [242/2000], Avg Val Loss: 3.1058\n",
      "Validation loss improved from 3.1070 to 3.1058. Saving model...\n",
      "\n",
      "LOG: Epoch [243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7149\n",
      "Epoch [243/2000], Avg Train Loss: 4.7149\n",
      "Epoch [243/2000], Avg Val Loss: 3.1045\n",
      "Validation loss improved from 3.1058 to 3.1045. Saving model...\n",
      "\n",
      "LOG: Epoch [244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7119\n",
      "Epoch [244/2000], Avg Train Loss: 4.7119\n",
      "Epoch [244/2000], Avg Val Loss: 3.1033\n",
      "Validation loss improved from 3.1045 to 3.1033. Saving model...\n",
      "\n",
      "LOG: Epoch [245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6873\n",
      "Epoch [245/2000], Avg Train Loss: 4.6873\n",
      "Epoch [245/2000], Avg Val Loss: 3.1021\n",
      "Validation loss improved from 3.1033 to 3.1021. Saving model...\n",
      "\n",
      "LOG: Epoch [246/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6918\n",
      "Epoch [246/2000], Avg Train Loss: 4.6918\n",
      "Epoch [246/2000], Avg Val Loss: 3.1008\n",
      "Validation loss improved from 3.1021 to 3.1008. Saving model...\n",
      "\n",
      "LOG: Epoch [247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7025\n",
      "Epoch [247/2000], Avg Train Loss: 4.7025\n",
      "Epoch [247/2000], Avg Val Loss: 3.0996\n",
      "Validation loss improved from 3.1008 to 3.0996. Saving model...\n",
      "\n",
      "LOG: Epoch [248/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7063\n",
      "Epoch [248/2000], Avg Train Loss: 4.7063\n",
      "Epoch [248/2000], Avg Val Loss: 3.0984\n",
      "Validation loss improved from 3.0996 to 3.0984. Saving model...\n",
      "\n",
      "LOG: Epoch [249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6546\n",
      "Epoch [249/2000], Avg Train Loss: 4.6546\n",
      "Epoch [249/2000], Avg Val Loss: 3.0972\n",
      "Validation loss improved from 3.0984 to 3.0972. Saving model...\n",
      "\n",
      "LOG: Epoch [250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7032\n",
      "Epoch [250/2000], Avg Train Loss: 4.7032\n",
      "Epoch [250/2000], Avg Val Loss: 3.0959\n",
      "Validation loss improved from 3.0972 to 3.0959. Saving model...\n",
      "\n",
      "LOG: Epoch [251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6978\n",
      "Epoch [251/2000], Avg Train Loss: 4.6978\n",
      "Epoch [251/2000], Avg Val Loss: 3.0947\n",
      "Validation loss improved from 3.0959 to 3.0947. Saving model...\n",
      "\n",
      "LOG: Epoch [252/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.6651\n",
      "Epoch [252/2000], Avg Train Loss: 4.6651\n",
      "Epoch [252/2000], Avg Val Loss: 3.0935\n",
      "Validation loss improved from 3.0947 to 3.0935. Saving model...\n",
      "\n",
      "LOG: Epoch [253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7157\n",
      "Epoch [253/2000], Avg Train Loss: 4.7157\n",
      "Epoch [253/2000], Avg Val Loss: 3.0922\n",
      "Validation loss improved from 3.0935 to 3.0922. Saving model...\n",
      "\n",
      "LOG: Epoch [254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6352\n",
      "Epoch [254/2000], Avg Train Loss: 4.6352\n",
      "Epoch [254/2000], Avg Val Loss: 3.0910\n",
      "Validation loss improved from 3.0922 to 3.0910. Saving model...\n",
      "\n",
      "LOG: Epoch [255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6758\n",
      "Epoch [255/2000], Avg Train Loss: 4.6758\n",
      "Epoch [255/2000], Avg Val Loss: 3.0898\n",
      "Validation loss improved from 3.0910 to 3.0898. Saving model...\n",
      "\n",
      "LOG: Epoch [256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6816\n",
      "Epoch [256/2000], Avg Train Loss: 4.6816\n",
      "Epoch [256/2000], Avg Val Loss: 3.0886\n",
      "Validation loss improved from 3.0898 to 3.0886. Saving model...\n",
      "\n",
      "LOG: Epoch [257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6794\n",
      "Epoch [257/2000], Avg Train Loss: 4.6794\n",
      "Epoch [257/2000], Avg Val Loss: 3.0874\n",
      "Validation loss improved from 3.0886 to 3.0874. Saving model...\n",
      "\n",
      "LOG: Epoch [258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6911\n",
      "Epoch [258/2000], Avg Train Loss: 4.6911\n",
      "Epoch [258/2000], Avg Val Loss: 3.0862\n",
      "Validation loss improved from 3.0874 to 3.0862. Saving model...\n",
      "\n",
      "LOG: Epoch [259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6695\n",
      "Epoch [259/2000], Avg Train Loss: 4.6695\n",
      "Epoch [259/2000], Avg Val Loss: 3.0849\n",
      "Validation loss improved from 3.0862 to 3.0849. Saving model...\n",
      "\n",
      "LOG: Epoch [260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6802\n",
      "Epoch [260/2000], Avg Train Loss: 4.6802\n",
      "Epoch [260/2000], Avg Val Loss: 3.0836\n",
      "Validation loss improved from 3.0849 to 3.0836. Saving model...\n",
      "\n",
      "LOG: Epoch [261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6195\n",
      "Epoch [261/2000], Avg Train Loss: 4.6195\n",
      "Epoch [261/2000], Avg Val Loss: 3.0823\n",
      "Validation loss improved from 3.0836 to 3.0823. Saving model...\n",
      "\n",
      "LOG: Epoch [262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6679\n",
      "Epoch [262/2000], Avg Train Loss: 4.6679\n",
      "Epoch [262/2000], Avg Val Loss: 3.0811\n",
      "Validation loss improved from 3.0823 to 3.0811. Saving model...\n",
      "\n",
      "LOG: Epoch [263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6309\n",
      "Epoch [263/2000], Avg Train Loss: 4.6309\n",
      "Epoch [263/2000], Avg Val Loss: 3.0798\n",
      "Validation loss improved from 3.0811 to 3.0798. Saving model...\n",
      "\n",
      "LOG: Epoch [264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6329\n",
      "Epoch [264/2000], Avg Train Loss: 4.6329\n",
      "Epoch [264/2000], Avg Val Loss: 3.0785\n",
      "Validation loss improved from 3.0798 to 3.0785. Saving model...\n",
      "\n",
      "LOG: Epoch [265/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.6546\n",
      "Epoch [265/2000], Avg Train Loss: 4.6546\n",
      "Epoch [265/2000], Avg Val Loss: 3.0772\n",
      "Validation loss improved from 3.0785 to 3.0772. Saving model...\n",
      "\n",
      "LOG: Epoch [266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6717\n",
      "Epoch [266/2000], Avg Train Loss: 4.6717\n",
      "Epoch [266/2000], Avg Val Loss: 3.0759\n",
      "Validation loss improved from 3.0772 to 3.0759. Saving model...\n",
      "\n",
      "LOG: Epoch [267/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6393\n",
      "Epoch [267/2000], Avg Train Loss: 4.6393\n",
      "Epoch [267/2000], Avg Val Loss: 3.0747\n",
      "Validation loss improved from 3.0759 to 3.0747. Saving model...\n",
      "\n",
      "LOG: Epoch [268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6572\n",
      "Epoch [268/2000], Avg Train Loss: 4.6572\n",
      "Epoch [268/2000], Avg Val Loss: 3.0734\n",
      "Validation loss improved from 3.0747 to 3.0734. Saving model...\n",
      "\n",
      "LOG: Epoch [269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6537\n",
      "Epoch [269/2000], Avg Train Loss: 4.6537\n",
      "Epoch [269/2000], Avg Val Loss: 3.0721\n",
      "Validation loss improved from 3.0734 to 3.0721. Saving model...\n",
      "\n",
      "LOG: Epoch [270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6310\n",
      "Epoch [270/2000], Avg Train Loss: 4.6310\n",
      "Epoch [270/2000], Avg Val Loss: 3.0708\n",
      "Validation loss improved from 3.0721 to 3.0708. Saving model...\n",
      "\n",
      "LOG: Epoch [271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6179\n",
      "Epoch [271/2000], Avg Train Loss: 4.6179\n",
      "Epoch [271/2000], Avg Val Loss: 3.0695\n",
      "Validation loss improved from 3.0708 to 3.0695. Saving model...\n",
      "\n",
      "LOG: Epoch [272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6270\n",
      "Epoch [272/2000], Avg Train Loss: 4.6270\n",
      "Epoch [272/2000], Avg Val Loss: 3.0682\n",
      "Validation loss improved from 3.0695 to 3.0682. Saving model...\n",
      "\n",
      "LOG: Epoch [273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6833\n",
      "Epoch [273/2000], Avg Train Loss: 4.6833\n",
      "Epoch [273/2000], Avg Val Loss: 3.0668\n",
      "Validation loss improved from 3.0682 to 3.0668. Saving model...\n",
      "\n",
      "LOG: Epoch [274/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6169\n",
      "Epoch [274/2000], Avg Train Loss: 4.6169\n",
      "Epoch [274/2000], Avg Val Loss: 3.0655\n",
      "Validation loss improved from 3.0668 to 3.0655. Saving model...\n",
      "\n",
      "LOG: Epoch [275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6915\n",
      "Epoch [275/2000], Avg Train Loss: 4.6915\n",
      "Epoch [275/2000], Avg Val Loss: 3.0643\n",
      "Validation loss improved from 3.0655 to 3.0643. Saving model...\n",
      "\n",
      "LOG: Epoch [276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6322\n",
      "Epoch [276/2000], Avg Train Loss: 4.6322\n",
      "Epoch [276/2000], Avg Val Loss: 3.0630\n",
      "Validation loss improved from 3.0643 to 3.0630. Saving model...\n",
      "\n",
      "LOG: Epoch [277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6563\n",
      "Epoch [277/2000], Avg Train Loss: 4.6563\n",
      "Epoch [277/2000], Avg Val Loss: 3.0617\n",
      "Validation loss improved from 3.0630 to 3.0617. Saving model...\n",
      "\n",
      "LOG: Epoch [278/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6276\n",
      "Epoch [278/2000], Avg Train Loss: 4.6276\n",
      "Epoch [278/2000], Avg Val Loss: 3.0604\n",
      "Validation loss improved from 3.0617 to 3.0604. Saving model...\n",
      "\n",
      "LOG: Epoch [279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6521\n",
      "Epoch [279/2000], Avg Train Loss: 4.6521\n",
      "Epoch [279/2000], Avg Val Loss: 3.0591\n",
      "Validation loss improved from 3.0604 to 3.0591. Saving model...\n",
      "\n",
      "LOG: Epoch [280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6100\n",
      "Epoch [280/2000], Avg Train Loss: 4.6100\n",
      "Epoch [280/2000], Avg Val Loss: 3.0578\n",
      "Validation loss improved from 3.0591 to 3.0578. Saving model...\n",
      "\n",
      "LOG: Epoch [281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6276\n",
      "Epoch [281/2000], Avg Train Loss: 4.6276\n",
      "Epoch [281/2000], Avg Val Loss: 3.0564\n",
      "Validation loss improved from 3.0578 to 3.0564. Saving model...\n",
      "\n",
      "LOG: Epoch [282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6130\n",
      "Epoch [282/2000], Avg Train Loss: 4.6130\n",
      "Epoch [282/2000], Avg Val Loss: 3.0551\n",
      "Validation loss improved from 3.0564 to 3.0551. Saving model...\n",
      "\n",
      "LOG: Epoch [283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6223\n",
      "Epoch [283/2000], Avg Train Loss: 4.6223\n",
      "Epoch [283/2000], Avg Val Loss: 3.0537\n",
      "Validation loss improved from 3.0551 to 3.0537. Saving model...\n",
      "\n",
      "LOG: Epoch [284/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6266\n",
      "Epoch [284/2000], Avg Train Loss: 4.6266\n",
      "Epoch [284/2000], Avg Val Loss: 3.0524\n",
      "Validation loss improved from 3.0537 to 3.0524. Saving model...\n",
      "\n",
      "LOG: Epoch [285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5985\n",
      "Epoch [285/2000], Avg Train Loss: 4.5985\n",
      "Epoch [285/2000], Avg Val Loss: 3.0510\n",
      "Validation loss improved from 3.0524 to 3.0510. Saving model...\n",
      "\n",
      "LOG: Epoch [286/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5908\n",
      "Epoch [286/2000], Avg Train Loss: 4.5908\n",
      "Epoch [286/2000], Avg Val Loss: 3.0496\n",
      "Validation loss improved from 3.0510 to 3.0496. Saving model...\n",
      "\n",
      "LOG: Epoch [287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6441\n",
      "Epoch [287/2000], Avg Train Loss: 4.6441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [287/2000], Avg Val Loss: 3.0482\n",
      "Validation loss improved from 3.0496 to 3.0482. Saving model...\n",
      "\n",
      "LOG: Epoch [288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6289\n",
      "Epoch [288/2000], Avg Train Loss: 4.6289\n",
      "Epoch [288/2000], Avg Val Loss: 3.0468\n",
      "Validation loss improved from 3.0482 to 3.0468. Saving model...\n",
      "\n",
      "LOG: Epoch [289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6025\n",
      "Epoch [289/2000], Avg Train Loss: 4.6025\n",
      "Epoch [289/2000], Avg Val Loss: 3.0454\n",
      "Validation loss improved from 3.0468 to 3.0454. Saving model...\n",
      "\n",
      "LOG: Epoch [290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5661\n",
      "Epoch [290/2000], Avg Train Loss: 4.5661\n",
      "Epoch [290/2000], Avg Val Loss: 3.0439\n",
      "Validation loss improved from 3.0454 to 3.0439. Saving model...\n",
      "\n",
      "LOG: Epoch [291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6142\n",
      "Epoch [291/2000], Avg Train Loss: 4.6142\n",
      "Epoch [291/2000], Avg Val Loss: 3.0425\n",
      "Validation loss improved from 3.0439 to 3.0425. Saving model...\n",
      "\n",
      "LOG: Epoch [292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6012\n",
      "Epoch [292/2000], Avg Train Loss: 4.6012\n",
      "Epoch [292/2000], Avg Val Loss: 3.0411\n",
      "Validation loss improved from 3.0425 to 3.0411. Saving model...\n",
      "\n",
      "LOG: Epoch [293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6087\n",
      "Epoch [293/2000], Avg Train Loss: 4.6087\n",
      "Epoch [293/2000], Avg Val Loss: 3.0396\n",
      "Validation loss improved from 3.0411 to 3.0396. Saving model...\n",
      "\n",
      "LOG: Epoch [294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6272\n",
      "Epoch [294/2000], Avg Train Loss: 4.6272\n",
      "Epoch [294/2000], Avg Val Loss: 3.0382\n",
      "Validation loss improved from 3.0396 to 3.0382. Saving model...\n",
      "\n",
      "LOG: Epoch [295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5604\n",
      "Epoch [295/2000], Avg Train Loss: 4.5604\n",
      "Epoch [295/2000], Avg Val Loss: 3.0368\n",
      "Validation loss improved from 3.0382 to 3.0368. Saving model...\n",
      "\n",
      "LOG: Epoch [296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5704\n",
      "Epoch [296/2000], Avg Train Loss: 4.5704\n",
      "Epoch [296/2000], Avg Val Loss: 3.0353\n",
      "Validation loss improved from 3.0368 to 3.0353. Saving model...\n",
      "\n",
      "LOG: Epoch [297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5835\n",
      "Epoch [297/2000], Avg Train Loss: 4.5835\n",
      "Epoch [297/2000], Avg Val Loss: 3.0339\n",
      "Validation loss improved from 3.0353 to 3.0339. Saving model...\n",
      "\n",
      "LOG: Epoch [298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6062\n",
      "Epoch [298/2000], Avg Train Loss: 4.6062\n",
      "Epoch [298/2000], Avg Val Loss: 3.0325\n",
      "Validation loss improved from 3.0339 to 3.0325. Saving model...\n",
      "\n",
      "LOG: Epoch [299/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.5995\n",
      "Epoch [299/2000], Avg Train Loss: 4.5995\n",
      "Epoch [299/2000], Avg Val Loss: 3.0311\n",
      "Validation loss improved from 3.0325 to 3.0311. Saving model...\n",
      "\n",
      "LOG: Epoch [300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5787\n",
      "Epoch [300/2000], Avg Train Loss: 4.5787\n",
      "Epoch [300/2000], Avg Val Loss: 3.0297\n",
      "Validation loss improved from 3.0311 to 3.0297. Saving model...\n",
      "\n",
      "LOG: Epoch [301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5943\n",
      "Epoch [301/2000], Avg Train Loss: 4.5943\n",
      "Epoch [301/2000], Avg Val Loss: 3.0283\n",
      "Validation loss improved from 3.0297 to 3.0283. Saving model...\n",
      "\n",
      "LOG: Epoch [302/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5440\n",
      "Epoch [302/2000], Avg Train Loss: 4.5440\n",
      "Epoch [302/2000], Avg Val Loss: 3.0269\n",
      "Validation loss improved from 3.0283 to 3.0269. Saving model...\n",
      "\n",
      "LOG: Epoch [303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5973\n",
      "Epoch [303/2000], Avg Train Loss: 4.5973\n",
      "Epoch [303/2000], Avg Val Loss: 3.0255\n",
      "Validation loss improved from 3.0269 to 3.0255. Saving model...\n",
      "\n",
      "LOG: Epoch [304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5730\n",
      "Epoch [304/2000], Avg Train Loss: 4.5730\n",
      "Epoch [304/2000], Avg Val Loss: 3.0241\n",
      "Validation loss improved from 3.0255 to 3.0241. Saving model...\n",
      "\n",
      "LOG: Epoch [305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5899\n",
      "Epoch [305/2000], Avg Train Loss: 4.5899\n",
      "Epoch [305/2000], Avg Val Loss: 3.0227\n",
      "Validation loss improved from 3.0241 to 3.0227. Saving model...\n",
      "\n",
      "LOG: Epoch [306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5755\n",
      "Epoch [306/2000], Avg Train Loss: 4.5755\n",
      "Epoch [306/2000], Avg Val Loss: 3.0213\n",
      "Validation loss improved from 3.0227 to 3.0213. Saving model...\n",
      "\n",
      "LOG: Epoch [307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5764\n",
      "Epoch [307/2000], Avg Train Loss: 4.5764\n",
      "Epoch [307/2000], Avg Val Loss: 3.0199\n",
      "Validation loss improved from 3.0213 to 3.0199. Saving model...\n",
      "\n",
      "LOG: Epoch [308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5362\n",
      "Epoch [308/2000], Avg Train Loss: 4.5362\n",
      "Epoch [308/2000], Avg Val Loss: 3.0185\n",
      "Validation loss improved from 3.0199 to 3.0185. Saving model...\n",
      "\n",
      "LOG: Epoch [309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6049\n",
      "Epoch [309/2000], Avg Train Loss: 4.6049\n",
      "Epoch [309/2000], Avg Val Loss: 3.0171\n",
      "Validation loss improved from 3.0185 to 3.0171. Saving model...\n",
      "\n",
      "LOG: Epoch [310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5833\n",
      "Epoch [310/2000], Avg Train Loss: 4.5833\n",
      "Epoch [310/2000], Avg Val Loss: 3.0157\n",
      "Validation loss improved from 3.0171 to 3.0157. Saving model...\n",
      "\n",
      "LOG: Epoch [311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5602\n",
      "Epoch [311/2000], Avg Train Loss: 4.5602\n",
      "Epoch [311/2000], Avg Val Loss: 3.0143\n",
      "Validation loss improved from 3.0157 to 3.0143. Saving model...\n",
      "\n",
      "LOG: Epoch [312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5823\n",
      "Epoch [312/2000], Avg Train Loss: 4.5823\n",
      "Epoch [312/2000], Avg Val Loss: 3.0130\n",
      "Validation loss improved from 3.0143 to 3.0130. Saving model...\n",
      "\n",
      "LOG: Epoch [313/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5123\n",
      "Epoch [313/2000], Avg Train Loss: 4.5123\n",
      "Epoch [313/2000], Avg Val Loss: 3.0116\n",
      "Validation loss improved from 3.0130 to 3.0116. Saving model...\n",
      "\n",
      "LOG: Epoch [314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5888\n",
      "Epoch [314/2000], Avg Train Loss: 4.5888\n",
      "Epoch [314/2000], Avg Val Loss: 3.0102\n",
      "Validation loss improved from 3.0116 to 3.0102. Saving model...\n",
      "\n",
      "LOG: Epoch [315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5779\n",
      "Epoch [315/2000], Avg Train Loss: 4.5779\n",
      "Epoch [315/2000], Avg Val Loss: 3.0088\n",
      "Validation loss improved from 3.0102 to 3.0088. Saving model...\n",
      "\n",
      "LOG: Epoch [316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5283\n",
      "Epoch [316/2000], Avg Train Loss: 4.5283\n",
      "Epoch [316/2000], Avg Val Loss: 3.0075\n",
      "Validation loss improved from 3.0088 to 3.0075. Saving model...\n",
      "\n",
      "LOG: Epoch [317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5830\n",
      "Epoch [317/2000], Avg Train Loss: 4.5830\n",
      "Epoch [317/2000], Avg Val Loss: 3.0061\n",
      "Validation loss improved from 3.0075 to 3.0061. Saving model...\n",
      "\n",
      "LOG: Epoch [318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5639\n",
      "Epoch [318/2000], Avg Train Loss: 4.5639\n",
      "Epoch [318/2000], Avg Val Loss: 3.0048\n",
      "Validation loss improved from 3.0061 to 3.0048. Saving model...\n",
      "\n",
      "LOG: Epoch [319/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5471\n",
      "Epoch [319/2000], Avg Train Loss: 4.5471\n",
      "Epoch [319/2000], Avg Val Loss: 3.0034\n",
      "Validation loss improved from 3.0048 to 3.0034. Saving model...\n",
      "\n",
      "LOG: Epoch [320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5359\n",
      "Epoch [320/2000], Avg Train Loss: 4.5359\n",
      "Epoch [320/2000], Avg Val Loss: 3.0021\n",
      "Validation loss improved from 3.0034 to 3.0021. Saving model...\n",
      "\n",
      "LOG: Epoch [321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5478\n",
      "Epoch [321/2000], Avg Train Loss: 4.5478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [321/2000], Avg Val Loss: 3.0007\n",
      "Validation loss improved from 3.0021 to 3.0007. Saving model...\n",
      "\n",
      "LOG: Epoch [322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5143\n",
      "Epoch [322/2000], Avg Train Loss: 4.5143\n",
      "Epoch [322/2000], Avg Val Loss: 2.9993\n",
      "Validation loss improved from 3.0007 to 2.9993. Saving model...\n",
      "\n",
      "LOG: Epoch [323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5314\n",
      "Epoch [323/2000], Avg Train Loss: 4.5314\n",
      "Epoch [323/2000], Avg Val Loss: 2.9979\n",
      "Validation loss improved from 2.9993 to 2.9979. Saving model...\n",
      "\n",
      "LOG: Epoch [324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5933\n",
      "Epoch [324/2000], Avg Train Loss: 4.5933\n",
      "Epoch [324/2000], Avg Val Loss: 2.9964\n",
      "Validation loss improved from 2.9979 to 2.9964. Saving model...\n",
      "\n",
      "LOG: Epoch [325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5686\n",
      "Epoch [325/2000], Avg Train Loss: 4.5686\n",
      "Epoch [325/2000], Avg Val Loss: 2.9950\n",
      "Validation loss improved from 2.9964 to 2.9950. Saving model...\n",
      "\n",
      "LOG: Epoch [326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4986\n",
      "Epoch [326/2000], Avg Train Loss: 4.4986\n",
      "Epoch [326/2000], Avg Val Loss: 2.9936\n",
      "Validation loss improved from 2.9950 to 2.9936. Saving model...\n",
      "\n",
      "LOG: Epoch [327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5405\n",
      "Epoch [327/2000], Avg Train Loss: 4.5405\n",
      "Epoch [327/2000], Avg Val Loss: 2.9922\n",
      "Validation loss improved from 2.9936 to 2.9922. Saving model...\n",
      "\n",
      "LOG: Epoch [328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5571\n",
      "Epoch [328/2000], Avg Train Loss: 4.5571\n",
      "Epoch [328/2000], Avg Val Loss: 2.9908\n",
      "Validation loss improved from 2.9922 to 2.9908. Saving model...\n",
      "\n",
      "LOG: Epoch [329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5280\n",
      "Epoch [329/2000], Avg Train Loss: 4.5280\n",
      "Epoch [329/2000], Avg Val Loss: 2.9893\n",
      "Validation loss improved from 2.9908 to 2.9893. Saving model...\n",
      "\n",
      "LOG: Epoch [330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5176\n",
      "Epoch [330/2000], Avg Train Loss: 4.5176\n",
      "Epoch [330/2000], Avg Val Loss: 2.9879\n",
      "Validation loss improved from 2.9893 to 2.9879. Saving model...\n",
      "\n",
      "LOG: Epoch [331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5056\n",
      "Epoch [331/2000], Avg Train Loss: 4.5056\n",
      "Epoch [331/2000], Avg Val Loss: 2.9865\n",
      "Validation loss improved from 2.9879 to 2.9865. Saving model...\n",
      "\n",
      "LOG: Epoch [332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5755\n",
      "Epoch [332/2000], Avg Train Loss: 4.5755\n",
      "Epoch [332/2000], Avg Val Loss: 2.9851\n",
      "Validation loss improved from 2.9865 to 2.9851. Saving model...\n",
      "\n",
      "LOG: Epoch [333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5366\n",
      "Epoch [333/2000], Avg Train Loss: 4.5366\n",
      "Epoch [333/2000], Avg Val Loss: 2.9837\n",
      "Validation loss improved from 2.9851 to 2.9837. Saving model...\n",
      "\n",
      "LOG: Epoch [334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5197\n",
      "Epoch [334/2000], Avg Train Loss: 4.5197\n",
      "Epoch [334/2000], Avg Val Loss: 2.9822\n",
      "Validation loss improved from 2.9837 to 2.9822. Saving model...\n",
      "\n",
      "LOG: Epoch [335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4910\n",
      "Epoch [335/2000], Avg Train Loss: 4.4910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [335/2000], Avg Val Loss: 2.9807\n",
      "Validation loss improved from 2.9822 to 2.9807. Saving model...\n",
      "\n",
      "LOG: Epoch [336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5101\n",
      "Epoch [336/2000], Avg Train Loss: 4.5101\n",
      "Epoch [336/2000], Avg Val Loss: 2.9793\n",
      "Validation loss improved from 2.9807 to 2.9793. Saving model...\n",
      "\n",
      "LOG: Epoch [337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4826\n",
      "Epoch [337/2000], Avg Train Loss: 4.4826\n",
      "Epoch [337/2000], Avg Val Loss: 2.9779\n",
      "Validation loss improved from 2.9793 to 2.9779. Saving model...\n",
      "\n",
      "LOG: Epoch [338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4660\n",
      "Epoch [338/2000], Avg Train Loss: 4.4660\n",
      "Epoch [338/2000], Avg Val Loss: 2.9764\n",
      "Validation loss improved from 2.9779 to 2.9764. Saving model...\n",
      "\n",
      "LOG: Epoch [339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4933\n",
      "Epoch [339/2000], Avg Train Loss: 4.4933\n",
      "Epoch [339/2000], Avg Val Loss: 2.9750\n",
      "Validation loss improved from 2.9764 to 2.9750. Saving model...\n",
      "\n",
      "LOG: Epoch [340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5050\n",
      "Epoch [340/2000], Avg Train Loss: 4.5050\n",
      "Epoch [340/2000], Avg Val Loss: 2.9736\n",
      "Validation loss improved from 2.9750 to 2.9736. Saving model...\n",
      "\n",
      "LOG: Epoch [341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5186\n",
      "Epoch [341/2000], Avg Train Loss: 4.5186\n",
      "Epoch [341/2000], Avg Val Loss: 2.9722\n",
      "Validation loss improved from 2.9736 to 2.9722. Saving model...\n",
      "\n",
      "LOG: Epoch [342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5384\n",
      "Epoch [342/2000], Avg Train Loss: 4.5384\n",
      "Epoch [342/2000], Avg Val Loss: 2.9708\n",
      "Validation loss improved from 2.9722 to 2.9708. Saving model...\n",
      "\n",
      "LOG: Epoch [343/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5231\n",
      "Epoch [343/2000], Avg Train Loss: 4.5231\n",
      "Epoch [343/2000], Avg Val Loss: 2.9694\n",
      "Validation loss improved from 2.9708 to 2.9694. Saving model...\n",
      "\n",
      "LOG: Epoch [344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5058\n",
      "Epoch [344/2000], Avg Train Loss: 4.5058\n",
      "Epoch [344/2000], Avg Val Loss: 2.9680\n",
      "Validation loss improved from 2.9694 to 2.9680. Saving model...\n",
      "\n",
      "LOG: Epoch [345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4497\n",
      "Epoch [345/2000], Avg Train Loss: 4.4497\n",
      "Epoch [345/2000], Avg Val Loss: 2.9666\n",
      "Validation loss improved from 2.9680 to 2.9666. Saving model...\n",
      "\n",
      "LOG: Epoch [346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5005\n",
      "Epoch [346/2000], Avg Train Loss: 4.5005\n",
      "Epoch [346/2000], Avg Val Loss: 2.9653\n",
      "Validation loss improved from 2.9666 to 2.9653. Saving model...\n",
      "\n",
      "LOG: Epoch [347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4994\n",
      "Epoch [347/2000], Avg Train Loss: 4.4994\n",
      "Epoch [347/2000], Avg Val Loss: 2.9638\n",
      "Validation loss improved from 2.9653 to 2.9638. Saving model...\n",
      "\n",
      "LOG: Epoch [348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4462\n",
      "Epoch [348/2000], Avg Train Loss: 4.4462\n",
      "Epoch [348/2000], Avg Val Loss: 2.9624\n",
      "Validation loss improved from 2.9638 to 2.9624. Saving model...\n",
      "\n",
      "LOG: Epoch [349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5382\n",
      "Epoch [349/2000], Avg Train Loss: 4.5382\n",
      "Epoch [349/2000], Avg Val Loss: 2.9609\n",
      "Validation loss improved from 2.9624 to 2.9609. Saving model...\n",
      "\n",
      "LOG: Epoch [350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4805\n",
      "Epoch [350/2000], Avg Train Loss: 4.4805\n",
      "Epoch [350/2000], Avg Val Loss: 2.9595\n",
      "Validation loss improved from 2.9609 to 2.9595. Saving model...\n",
      "\n",
      "LOG: Epoch [351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5170\n",
      "Epoch [351/2000], Avg Train Loss: 4.5170\n",
      "Epoch [351/2000], Avg Val Loss: 2.9581\n",
      "Validation loss improved from 2.9595 to 2.9581. Saving model...\n",
      "\n",
      "LOG: Epoch [352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5195\n",
      "Epoch [352/2000], Avg Train Loss: 4.5195\n",
      "Epoch [352/2000], Avg Val Loss: 2.9566\n",
      "Validation loss improved from 2.9581 to 2.9566. Saving model...\n",
      "\n",
      "LOG: Epoch [353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5190\n",
      "Epoch [353/2000], Avg Train Loss: 4.5190\n",
      "Epoch [353/2000], Avg Val Loss: 2.9551\n",
      "Validation loss improved from 2.9566 to 2.9551. Saving model...\n",
      "\n",
      "LOG: Epoch [354/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4672\n",
      "Epoch [354/2000], Avg Train Loss: 4.4672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [354/2000], Avg Val Loss: 2.9536\n",
      "Validation loss improved from 2.9551 to 2.9536. Saving model...\n",
      "\n",
      "LOG: Epoch [355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4458\n",
      "Epoch [355/2000], Avg Train Loss: 4.4458\n",
      "Epoch [355/2000], Avg Val Loss: 2.9521\n",
      "Validation loss improved from 2.9536 to 2.9521. Saving model...\n",
      "\n",
      "LOG: Epoch [356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4852\n",
      "Epoch [356/2000], Avg Train Loss: 4.4852\n",
      "Epoch [356/2000], Avg Val Loss: 2.9505\n",
      "Validation loss improved from 2.9521 to 2.9505. Saving model...\n",
      "\n",
      "LOG: Epoch [357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5016\n",
      "Epoch [357/2000], Avg Train Loss: 4.5016\n",
      "Epoch [357/2000], Avg Val Loss: 2.9490\n",
      "Validation loss improved from 2.9505 to 2.9490. Saving model...\n",
      "\n",
      "LOG: Epoch [358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4894\n",
      "Epoch [358/2000], Avg Train Loss: 4.4894\n",
      "Epoch [358/2000], Avg Val Loss: 2.9474\n",
      "Validation loss improved from 2.9490 to 2.9474. Saving model...\n",
      "\n",
      "LOG: Epoch [359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4757\n",
      "Epoch [359/2000], Avg Train Loss: 4.4757\n",
      "Epoch [359/2000], Avg Val Loss: 2.9459\n",
      "Validation loss improved from 2.9474 to 2.9459. Saving model...\n",
      "\n",
      "LOG: Epoch [360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5125\n",
      "Epoch [360/2000], Avg Train Loss: 4.5125\n",
      "Epoch [360/2000], Avg Val Loss: 2.9445\n",
      "Validation loss improved from 2.9459 to 2.9445. Saving model...\n",
      "\n",
      "LOG: Epoch [361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4191\n",
      "Epoch [361/2000], Avg Train Loss: 4.4191\n",
      "Epoch [361/2000], Avg Val Loss: 2.9430\n",
      "Validation loss improved from 2.9445 to 2.9430. Saving model...\n",
      "\n",
      "LOG: Epoch [362/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4743\n",
      "Epoch [362/2000], Avg Train Loss: 4.4743\n",
      "Epoch [362/2000], Avg Val Loss: 2.9415\n",
      "Validation loss improved from 2.9430 to 2.9415. Saving model...\n",
      "\n",
      "LOG: Epoch [363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4677\n",
      "Epoch [363/2000], Avg Train Loss: 4.4677\n",
      "Epoch [363/2000], Avg Val Loss: 2.9400\n",
      "Validation loss improved from 2.9415 to 2.9400. Saving model...\n",
      "\n",
      "LOG: Epoch [364/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4684\n",
      "Epoch [364/2000], Avg Train Loss: 4.4684\n",
      "Epoch [364/2000], Avg Val Loss: 2.9385\n",
      "Validation loss improved from 2.9400 to 2.9385. Saving model...\n",
      "\n",
      "LOG: Epoch [365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4526\n",
      "Epoch [365/2000], Avg Train Loss: 4.4526\n",
      "Epoch [365/2000], Avg Val Loss: 2.9370\n",
      "Validation loss improved from 2.9385 to 2.9370. Saving model...\n",
      "\n",
      "LOG: Epoch [366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4499\n",
      "Epoch [366/2000], Avg Train Loss: 4.4499\n",
      "Epoch [366/2000], Avg Val Loss: 2.9355\n",
      "Validation loss improved from 2.9370 to 2.9355. Saving model...\n",
      "\n",
      "LOG: Epoch [367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4249\n",
      "Epoch [367/2000], Avg Train Loss: 4.4249\n",
      "Epoch [367/2000], Avg Val Loss: 2.9340\n",
      "Validation loss improved from 2.9355 to 2.9340. Saving model...\n",
      "\n",
      "LOG: Epoch [368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4313\n",
      "Epoch [368/2000], Avg Train Loss: 4.4313\n",
      "Epoch [368/2000], Avg Val Loss: 2.9325\n",
      "Validation loss improved from 2.9340 to 2.9325. Saving model...\n",
      "\n",
      "LOG: Epoch [369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4698\n",
      "Epoch [369/2000], Avg Train Loss: 4.4698\n",
      "Epoch [369/2000], Avg Val Loss: 2.9310\n",
      "Validation loss improved from 2.9325 to 2.9310. Saving model...\n",
      "\n",
      "LOG: Epoch [370/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.4728\n",
      "Epoch [370/2000], Avg Train Loss: 4.4728\n",
      "Epoch [370/2000], Avg Val Loss: 2.9294\n",
      "Validation loss improved from 2.9310 to 2.9294. Saving model...\n",
      "\n",
      "LOG: Epoch [371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4718\n",
      "Epoch [371/2000], Avg Train Loss: 4.4718\n",
      "Epoch [371/2000], Avg Val Loss: 2.9279\n",
      "Validation loss improved from 2.9294 to 2.9279. Saving model...\n",
      "\n",
      "LOG: Epoch [372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4307\n",
      "Epoch [372/2000], Avg Train Loss: 4.4307\n",
      "Epoch [372/2000], Avg Val Loss: 2.9263\n",
      "Validation loss improved from 2.9279 to 2.9263. Saving model...\n",
      "\n",
      "LOG: Epoch [373/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4562\n",
      "Epoch [373/2000], Avg Train Loss: 4.4562\n",
      "Epoch [373/2000], Avg Val Loss: 2.9246\n",
      "Validation loss improved from 2.9263 to 2.9246. Saving model...\n",
      "\n",
      "LOG: Epoch [374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4845\n",
      "Epoch [374/2000], Avg Train Loss: 4.4845\n",
      "Epoch [374/2000], Avg Val Loss: 2.9230\n",
      "Validation loss improved from 2.9246 to 2.9230. Saving model...\n",
      "\n",
      "LOG: Epoch [375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4162\n",
      "Epoch [375/2000], Avg Train Loss: 4.4162\n",
      "Epoch [375/2000], Avg Val Loss: 2.9214\n",
      "Validation loss improved from 2.9230 to 2.9214. Saving model...\n",
      "\n",
      "LOG: Epoch [376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4574\n",
      "Epoch [376/2000], Avg Train Loss: 4.4574\n",
      "Epoch [376/2000], Avg Val Loss: 2.9197\n",
      "Validation loss improved from 2.9214 to 2.9197. Saving model...\n",
      "\n",
      "LOG: Epoch [377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4768\n",
      "Epoch [377/2000], Avg Train Loss: 4.4768\n",
      "Epoch [377/2000], Avg Val Loss: 2.9182\n",
      "Validation loss improved from 2.9197 to 2.9182. Saving model...\n",
      "\n",
      "LOG: Epoch [378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4382\n",
      "Epoch [378/2000], Avg Train Loss: 4.4382\n",
      "Epoch [378/2000], Avg Val Loss: 2.9166\n",
      "Validation loss improved from 2.9182 to 2.9166. Saving model...\n",
      "\n",
      "LOG: Epoch [379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4389\n",
      "Epoch [379/2000], Avg Train Loss: 4.4389\n",
      "Epoch [379/2000], Avg Val Loss: 2.9150\n",
      "Validation loss improved from 2.9166 to 2.9150. Saving model...\n",
      "\n",
      "LOG: Epoch [380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4196\n",
      "Epoch [380/2000], Avg Train Loss: 4.4196\n",
      "Epoch [380/2000], Avg Val Loss: 2.9134\n",
      "Validation loss improved from 2.9150 to 2.9134. Saving model...\n",
      "\n",
      "LOG: Epoch [381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4635\n",
      "Epoch [381/2000], Avg Train Loss: 4.4635\n",
      "Epoch [381/2000], Avg Val Loss: 2.9118\n",
      "Validation loss improved from 2.9134 to 2.9118. Saving model...\n",
      "\n",
      "LOG: Epoch [382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4230\n",
      "Epoch [382/2000], Avg Train Loss: 4.4230\n",
      "Epoch [382/2000], Avg Val Loss: 2.9102\n",
      "Validation loss improved from 2.9118 to 2.9102. Saving model...\n",
      "\n",
      "LOG: Epoch [383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4400\n",
      "Epoch [383/2000], Avg Train Loss: 4.4400\n",
      "Epoch [383/2000], Avg Val Loss: 2.9086\n",
      "Validation loss improved from 2.9102 to 2.9086. Saving model...\n",
      "\n",
      "LOG: Epoch [384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4445\n",
      "Epoch [384/2000], Avg Train Loss: 4.4445\n",
      "Epoch [384/2000], Avg Val Loss: 2.9071\n",
      "Validation loss improved from 2.9086 to 2.9071. Saving model...\n",
      "\n",
      "LOG: Epoch [385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4470\n",
      "Epoch [385/2000], Avg Train Loss: 4.4470\n",
      "Epoch [385/2000], Avg Val Loss: 2.9056\n",
      "Validation loss improved from 2.9071 to 2.9056. Saving model...\n",
      "\n",
      "LOG: Epoch [386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4311\n",
      "Epoch [386/2000], Avg Train Loss: 4.4311\n",
      "Epoch [386/2000], Avg Val Loss: 2.9041\n",
      "Validation loss improved from 2.9056 to 2.9041. Saving model...\n",
      "\n",
      "LOG: Epoch [387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4115\n",
      "Epoch [387/2000], Avg Train Loss: 4.4115\n",
      "Epoch [387/2000], Avg Val Loss: 2.9026\n",
      "Validation loss improved from 2.9041 to 2.9026. Saving model...\n",
      "\n",
      "LOG: Epoch [388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4630\n",
      "Epoch [388/2000], Avg Train Loss: 4.4630\n",
      "Epoch [388/2000], Avg Val Loss: 2.9011\n",
      "Validation loss improved from 2.9026 to 2.9011. Saving model...\n",
      "\n",
      "LOG: Epoch [389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4287\n",
      "Epoch [389/2000], Avg Train Loss: 4.4287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [389/2000], Avg Val Loss: 2.8996\n",
      "Validation loss improved from 2.9011 to 2.8996. Saving model...\n",
      "\n",
      "LOG: Epoch [390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4584\n",
      "Epoch [390/2000], Avg Train Loss: 4.4584\n",
      "Epoch [390/2000], Avg Val Loss: 2.8982\n",
      "Validation loss improved from 2.8996 to 2.8982. Saving model...\n",
      "\n",
      "LOG: Epoch [391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4253\n",
      "Epoch [391/2000], Avg Train Loss: 4.4253\n",
      "Epoch [391/2000], Avg Val Loss: 2.8966\n",
      "Validation loss improved from 2.8982 to 2.8966. Saving model...\n",
      "\n",
      "LOG: Epoch [392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3910\n",
      "Epoch [392/2000], Avg Train Loss: 4.3910\n",
      "Epoch [392/2000], Avg Val Loss: 2.8951\n",
      "Validation loss improved from 2.8966 to 2.8951. Saving model...\n",
      "\n",
      "LOG: Epoch [393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4470\n",
      "Epoch [393/2000], Avg Train Loss: 4.4470\n",
      "Epoch [393/2000], Avg Val Loss: 2.8936\n",
      "Validation loss improved from 2.8951 to 2.8936. Saving model...\n",
      "\n",
      "LOG: Epoch [394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4223\n",
      "Epoch [394/2000], Avg Train Loss: 4.4223\n",
      "Epoch [394/2000], Avg Val Loss: 2.8922\n",
      "Validation loss improved from 2.8936 to 2.8922. Saving model...\n",
      "\n",
      "LOG: Epoch [395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4693\n",
      "Epoch [395/2000], Avg Train Loss: 4.4693\n",
      "Epoch [395/2000], Avg Val Loss: 2.8907\n",
      "Validation loss improved from 2.8922 to 2.8907. Saving model...\n",
      "\n",
      "LOG: Epoch [396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3968\n",
      "Epoch [396/2000], Avg Train Loss: 4.3968\n",
      "Epoch [396/2000], Avg Val Loss: 2.8893\n",
      "Validation loss improved from 2.8907 to 2.8893. Saving model...\n",
      "\n",
      "LOG: Epoch [397/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4209\n",
      "Epoch [397/2000], Avg Train Loss: 4.4209\n",
      "Epoch [397/2000], Avg Val Loss: 2.8878\n",
      "Validation loss improved from 2.8893 to 2.8878. Saving model...\n",
      "\n",
      "LOG: Epoch [398/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4554\n",
      "Epoch [398/2000], Avg Train Loss: 4.4554\n",
      "Epoch [398/2000], Avg Val Loss: 2.8864\n",
      "Validation loss improved from 2.8878 to 2.8864. Saving model...\n",
      "\n",
      "LOG: Epoch [399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3674\n",
      "Epoch [399/2000], Avg Train Loss: 4.3674\n",
      "Epoch [399/2000], Avg Val Loss: 2.8849\n",
      "Validation loss improved from 2.8864 to 2.8849. Saving model...\n",
      "\n",
      "LOG: Epoch [400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4478\n",
      "Epoch [400/2000], Avg Train Loss: 4.4478\n",
      "Epoch [400/2000], Avg Val Loss: 2.8836\n",
      "Validation loss improved from 2.8849 to 2.8836. Saving model...\n",
      "\n",
      "LOG: Epoch [401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3904\n",
      "Epoch [401/2000], Avg Train Loss: 4.3904\n",
      "Epoch [401/2000], Avg Val Loss: 2.8822\n",
      "Validation loss improved from 2.8836 to 2.8822. Saving model...\n",
      "\n",
      "LOG: Epoch [402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4172\n",
      "Epoch [402/2000], Avg Train Loss: 4.4172\n",
      "Epoch [402/2000], Avg Val Loss: 2.8808\n",
      "Validation loss improved from 2.8822 to 2.8808. Saving model...\n",
      "\n",
      "LOG: Epoch [403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3944\n",
      "Epoch [403/2000], Avg Train Loss: 4.3944\n",
      "Epoch [403/2000], Avg Val Loss: 2.8795\n",
      "Validation loss improved from 2.8808 to 2.8795. Saving model...\n",
      "\n",
      "LOG: Epoch [404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4105\n",
      "Epoch [404/2000], Avg Train Loss: 4.4105\n",
      "Epoch [404/2000], Avg Val Loss: 2.8782\n",
      "Validation loss improved from 2.8795 to 2.8782. Saving model...\n",
      "\n",
      "LOG: Epoch [405/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3912\n",
      "Epoch [405/2000], Avg Train Loss: 4.3912\n",
      "Epoch [405/2000], Avg Val Loss: 2.8769\n",
      "Validation loss improved from 2.8782 to 2.8769. Saving model...\n",
      "\n",
      "LOG: Epoch [406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3907\n",
      "Epoch [406/2000], Avg Train Loss: 4.3907\n",
      "Epoch [406/2000], Avg Val Loss: 2.8756\n",
      "Validation loss improved from 2.8769 to 2.8756. Saving model...\n",
      "\n",
      "LOG: Epoch [407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3925\n",
      "Epoch [407/2000], Avg Train Loss: 4.3925\n",
      "Epoch [407/2000], Avg Val Loss: 2.8743\n",
      "Validation loss improved from 2.8756 to 2.8743. Saving model...\n",
      "\n",
      "LOG: Epoch [408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3964\n",
      "Epoch [408/2000], Avg Train Loss: 4.3964\n",
      "Epoch [408/2000], Avg Val Loss: 2.8730\n",
      "Validation loss improved from 2.8743 to 2.8730. Saving model...\n",
      "\n",
      "LOG: Epoch [409/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3433\n",
      "Epoch [409/2000], Avg Train Loss: 4.3433\n",
      "Epoch [409/2000], Avg Val Loss: 2.8717\n",
      "Validation loss improved from 2.8730 to 2.8717. Saving model...\n",
      "\n",
      "LOG: Epoch [410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3741\n",
      "Epoch [410/2000], Avg Train Loss: 4.3741\n",
      "Epoch [410/2000], Avg Val Loss: 2.8703\n",
      "Validation loss improved from 2.8717 to 2.8703. Saving model...\n",
      "\n",
      "LOG: Epoch [411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3822\n",
      "Epoch [411/2000], Avg Train Loss: 4.3822\n",
      "Epoch [411/2000], Avg Val Loss: 2.8689\n",
      "Validation loss improved from 2.8703 to 2.8689. Saving model...\n",
      "\n",
      "LOG: Epoch [412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3638\n",
      "Epoch [412/2000], Avg Train Loss: 4.3638\n",
      "Epoch [412/2000], Avg Val Loss: 2.8675\n",
      "Validation loss improved from 2.8689 to 2.8675. Saving model...\n",
      "\n",
      "LOG: Epoch [413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4158\n",
      "Epoch [413/2000], Avg Train Loss: 4.4158\n",
      "Epoch [413/2000], Avg Val Loss: 2.8661\n",
      "Validation loss improved from 2.8675 to 2.8661. Saving model...\n",
      "\n",
      "LOG: Epoch [414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3802\n",
      "Epoch [414/2000], Avg Train Loss: 4.3802\n",
      "Epoch [414/2000], Avg Val Loss: 2.8647\n",
      "Validation loss improved from 2.8661 to 2.8647. Saving model...\n",
      "\n",
      "LOG: Epoch [415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3630\n",
      "Epoch [415/2000], Avg Train Loss: 4.3630\n",
      "Epoch [415/2000], Avg Val Loss: 2.8633\n",
      "Validation loss improved from 2.8647 to 2.8633. Saving model...\n",
      "\n",
      "LOG: Epoch [416/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3722\n",
      "Epoch [416/2000], Avg Train Loss: 4.3722\n",
      "Epoch [416/2000], Avg Val Loss: 2.8618\n",
      "Validation loss improved from 2.8633 to 2.8618. Saving model...\n",
      "\n",
      "LOG: Epoch [417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3766\n",
      "Epoch [417/2000], Avg Train Loss: 4.3766\n",
      "Epoch [417/2000], Avg Val Loss: 2.8604\n",
      "Validation loss improved from 2.8618 to 2.8604. Saving model...\n",
      "\n",
      "LOG: Epoch [418/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3490\n",
      "Epoch [418/2000], Avg Train Loss: 4.3490\n",
      "Epoch [418/2000], Avg Val Loss: 2.8590\n",
      "Validation loss improved from 2.8604 to 2.8590. Saving model...\n",
      "\n",
      "LOG: Epoch [419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3911\n",
      "Epoch [419/2000], Avg Train Loss: 4.3911\n",
      "Epoch [419/2000], Avg Val Loss: 2.8575\n",
      "Validation loss improved from 2.8590 to 2.8575. Saving model...\n",
      "\n",
      "LOG: Epoch [420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3137\n",
      "Epoch [420/2000], Avg Train Loss: 4.3137\n",
      "Epoch [420/2000], Avg Val Loss: 2.8560\n",
      "Validation loss improved from 2.8575 to 2.8560. Saving model...\n",
      "\n",
      "LOG: Epoch [421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3776\n",
      "Epoch [421/2000], Avg Train Loss: 4.3776\n",
      "Epoch [421/2000], Avg Val Loss: 2.8546\n",
      "Validation loss improved from 2.8560 to 2.8546. Saving model...\n",
      "\n",
      "LOG: Epoch [422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4178\n",
      "Epoch [422/2000], Avg Train Loss: 4.4178\n",
      "Epoch [422/2000], Avg Val Loss: 2.8532\n",
      "Validation loss improved from 2.8546 to 2.8532. Saving model...\n",
      "\n",
      "LOG: Epoch [423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3492\n",
      "Epoch [423/2000], Avg Train Loss: 4.3492\n",
      "Epoch [423/2000], Avg Val Loss: 2.8518\n",
      "Validation loss improved from 2.8532 to 2.8518. Saving model...\n",
      "\n",
      "LOG: Epoch [424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3520\n",
      "Epoch [424/2000], Avg Train Loss: 4.3520\n",
      "Epoch [424/2000], Avg Val Loss: 2.8504\n",
      "Validation loss improved from 2.8518 to 2.8504. Saving model...\n",
      "\n",
      "LOG: Epoch [425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2931\n",
      "Epoch [425/2000], Avg Train Loss: 4.2931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [425/2000], Avg Val Loss: 2.8489\n",
      "Validation loss improved from 2.8504 to 2.8489. Saving model...\n",
      "\n",
      "LOG: Epoch [426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3614\n",
      "Epoch [426/2000], Avg Train Loss: 4.3614\n",
      "Epoch [426/2000], Avg Val Loss: 2.8474\n",
      "Validation loss improved from 2.8489 to 2.8474. Saving model...\n",
      "\n",
      "LOG: Epoch [427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3685\n",
      "Epoch [427/2000], Avg Train Loss: 4.3685\n",
      "Epoch [427/2000], Avg Val Loss: 2.8459\n",
      "Validation loss improved from 2.8474 to 2.8459. Saving model...\n",
      "\n",
      "LOG: Epoch [428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3326\n",
      "Epoch [428/2000], Avg Train Loss: 4.3326\n",
      "Epoch [428/2000], Avg Val Loss: 2.8444\n",
      "Validation loss improved from 2.8459 to 2.8444. Saving model...\n",
      "\n",
      "LOG: Epoch [429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3775\n",
      "Epoch [429/2000], Avg Train Loss: 4.3775\n",
      "Epoch [429/2000], Avg Val Loss: 2.8430\n",
      "Validation loss improved from 2.8444 to 2.8430. Saving model...\n",
      "\n",
      "LOG: Epoch [430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3091\n",
      "Epoch [430/2000], Avg Train Loss: 4.3091\n",
      "Epoch [430/2000], Avg Val Loss: 2.8415\n",
      "Validation loss improved from 2.8430 to 2.8415. Saving model...\n",
      "\n",
      "LOG: Epoch [431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3377\n",
      "Epoch [431/2000], Avg Train Loss: 4.3377\n",
      "Epoch [431/2000], Avg Val Loss: 2.8401\n",
      "Validation loss improved from 2.8415 to 2.8401. Saving model...\n",
      "\n",
      "LOG: Epoch [432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3453\n",
      "Epoch [432/2000], Avg Train Loss: 4.3453\n",
      "Epoch [432/2000], Avg Val Loss: 2.8386\n",
      "Validation loss improved from 2.8401 to 2.8386. Saving model...\n",
      "\n",
      "LOG: Epoch [433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3147\n",
      "Epoch [433/2000], Avg Train Loss: 4.3147\n",
      "Epoch [433/2000], Avg Val Loss: 2.8371\n",
      "Validation loss improved from 2.8386 to 2.8371. Saving model...\n",
      "\n",
      "LOG: Epoch [434/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3434\n",
      "Epoch [434/2000], Avg Train Loss: 4.3434\n",
      "Epoch [434/2000], Avg Val Loss: 2.8356\n",
      "Validation loss improved from 2.8371 to 2.8356. Saving model...\n",
      "\n",
      "LOG: Epoch [435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3483\n",
      "Epoch [435/2000], Avg Train Loss: 4.3483\n",
      "Epoch [435/2000], Avg Val Loss: 2.8342\n",
      "Validation loss improved from 2.8356 to 2.8342. Saving model...\n",
      "\n",
      "LOG: Epoch [436/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3412\n",
      "Epoch [436/2000], Avg Train Loss: 4.3412\n",
      "Epoch [436/2000], Avg Val Loss: 2.8328\n",
      "Validation loss improved from 2.8342 to 2.8328. Saving model...\n",
      "\n",
      "LOG: Epoch [437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3338\n",
      "Epoch [437/2000], Avg Train Loss: 4.3338\n",
      "Epoch [437/2000], Avg Val Loss: 2.8314\n",
      "Validation loss improved from 2.8328 to 2.8314. Saving model...\n",
      "\n",
      "LOG: Epoch [438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3277\n",
      "Epoch [438/2000], Avg Train Loss: 4.3277\n",
      "Epoch [438/2000], Avg Val Loss: 2.8300\n",
      "Validation loss improved from 2.8314 to 2.8300. Saving model...\n",
      "\n",
      "LOG: Epoch [439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2861\n",
      "Epoch [439/2000], Avg Train Loss: 4.2861\n",
      "Epoch [439/2000], Avg Val Loss: 2.8286\n",
      "Validation loss improved from 2.8300 to 2.8286. Saving model...\n",
      "\n",
      "LOG: Epoch [440/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3835\n",
      "Epoch [440/2000], Avg Train Loss: 4.3835\n",
      "Epoch [440/2000], Avg Val Loss: 2.8272\n",
      "Validation loss improved from 2.8286 to 2.8272. Saving model...\n",
      "\n",
      "LOG: Epoch [441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3039\n",
      "Epoch [441/2000], Avg Train Loss: 4.3039\n",
      "Epoch [441/2000], Avg Val Loss: 2.8258\n",
      "Validation loss improved from 2.8272 to 2.8258. Saving model...\n",
      "\n",
      "LOG: Epoch [442/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3529\n",
      "Epoch [442/2000], Avg Train Loss: 4.3529\n",
      "Epoch [442/2000], Avg Val Loss: 2.8244\n",
      "Validation loss improved from 2.8258 to 2.8244. Saving model...\n",
      "\n",
      "LOG: Epoch [443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3295\n",
      "Epoch [443/2000], Avg Train Loss: 4.3295\n",
      "Epoch [443/2000], Avg Val Loss: 2.8231\n",
      "Validation loss improved from 2.8244 to 2.8231. Saving model...\n",
      "\n",
      "LOG: Epoch [444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3514\n",
      "Epoch [444/2000], Avg Train Loss: 4.3514\n",
      "Epoch [444/2000], Avg Val Loss: 2.8217\n",
      "Validation loss improved from 2.8231 to 2.8217. Saving model...\n",
      "\n",
      "LOG: Epoch [445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3568\n",
      "Epoch [445/2000], Avg Train Loss: 4.3568\n",
      "Epoch [445/2000], Avg Val Loss: 2.8204\n",
      "Validation loss improved from 2.8217 to 2.8204. Saving model...\n",
      "\n",
      "LOG: Epoch [446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3541\n",
      "Epoch [446/2000], Avg Train Loss: 4.3541\n",
      "Epoch [446/2000], Avg Val Loss: 2.8191\n",
      "Validation loss improved from 2.8204 to 2.8191. Saving model...\n",
      "\n",
      "LOG: Epoch [447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3010\n",
      "Epoch [447/2000], Avg Train Loss: 4.3010\n",
      "Epoch [447/2000], Avg Val Loss: 2.8178\n",
      "Validation loss improved from 2.8191 to 2.8178. Saving model...\n",
      "\n",
      "LOG: Epoch [448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3071\n",
      "Epoch [448/2000], Avg Train Loss: 4.3071\n",
      "Epoch [448/2000], Avg Val Loss: 2.8165\n",
      "Validation loss improved from 2.8178 to 2.8165. Saving model...\n",
      "\n",
      "LOG: Epoch [449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2952\n",
      "Epoch [449/2000], Avg Train Loss: 4.2952\n",
      "Epoch [449/2000], Avg Val Loss: 2.8152\n",
      "Validation loss improved from 2.8165 to 2.8152. Saving model...\n",
      "\n",
      "LOG: Epoch [450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2875\n",
      "Epoch [450/2000], Avg Train Loss: 4.2875\n",
      "Epoch [450/2000], Avg Val Loss: 2.8139\n",
      "Validation loss improved from 2.8152 to 2.8139. Saving model...\n",
      "\n",
      "LOG: Epoch [451/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3399\n",
      "Epoch [451/2000], Avg Train Loss: 4.3399\n",
      "Epoch [451/2000], Avg Val Loss: 2.8126\n",
      "Validation loss improved from 2.8139 to 2.8126. Saving model...\n",
      "\n",
      "LOG: Epoch [452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3168\n",
      "Epoch [452/2000], Avg Train Loss: 4.3168\n",
      "Epoch [452/2000], Avg Val Loss: 2.8113\n",
      "Validation loss improved from 2.8126 to 2.8113. Saving model...\n",
      "\n",
      "LOG: Epoch [453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3536\n",
      "Epoch [453/2000], Avg Train Loss: 4.3536\n",
      "Epoch [453/2000], Avg Val Loss: 2.8100\n",
      "Validation loss improved from 2.8113 to 2.8100. Saving model...\n",
      "\n",
      "LOG: Epoch [454/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3337\n",
      "Epoch [454/2000], Avg Train Loss: 4.3337\n",
      "Epoch [454/2000], Avg Val Loss: 2.8086\n",
      "Validation loss improved from 2.8100 to 2.8086. Saving model...\n",
      "\n",
      "LOG: Epoch [455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3455\n",
      "Epoch [455/2000], Avg Train Loss: 4.3455\n",
      "Epoch [455/2000], Avg Val Loss: 2.8072\n",
      "Validation loss improved from 2.8086 to 2.8072. Saving model...\n",
      "\n",
      "LOG: Epoch [456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3167\n",
      "Epoch [456/2000], Avg Train Loss: 4.3167\n",
      "Epoch [456/2000], Avg Val Loss: 2.8059\n",
      "Validation loss improved from 2.8072 to 2.8059. Saving model...\n",
      "\n",
      "LOG: Epoch [457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2757\n",
      "Epoch [457/2000], Avg Train Loss: 4.2757\n",
      "Epoch [457/2000], Avg Val Loss: 2.8046\n",
      "Validation loss improved from 2.8059 to 2.8046. Saving model...\n",
      "\n",
      "LOG: Epoch [458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3140\n",
      "Epoch [458/2000], Avg Train Loss: 4.3140\n",
      "Epoch [458/2000], Avg Val Loss: 2.8032\n",
      "Validation loss improved from 2.8046 to 2.8032. Saving model...\n",
      "\n",
      "LOG: Epoch [459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3029\n",
      "Epoch [459/2000], Avg Train Loss: 4.3029\n",
      "Epoch [459/2000], Avg Val Loss: 2.8018\n",
      "Validation loss improved from 2.8032 to 2.8018. Saving model...\n",
      "\n",
      "LOG: Epoch [460/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3069\n",
      "Epoch [460/2000], Avg Train Loss: 4.3069\n",
      "Epoch [460/2000], Avg Val Loss: 2.8004\n",
      "Validation loss improved from 2.8018 to 2.8004. Saving model...\n",
      "\n",
      "LOG: Epoch [461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2858\n",
      "Epoch [461/2000], Avg Train Loss: 4.2858\n",
      "Epoch [461/2000], Avg Val Loss: 2.7990\n",
      "Validation loss improved from 2.8004 to 2.7990. Saving model...\n",
      "\n",
      "LOG: Epoch [462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2799\n",
      "Epoch [462/2000], Avg Train Loss: 4.2799\n",
      "Epoch [462/2000], Avg Val Loss: 2.7975\n",
      "Validation loss improved from 2.7990 to 2.7975. Saving model...\n",
      "\n",
      "LOG: Epoch [463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3001\n",
      "Epoch [463/2000], Avg Train Loss: 4.3001\n",
      "Epoch [463/2000], Avg Val Loss: 2.7962\n",
      "Validation loss improved from 2.7975 to 2.7962. Saving model...\n",
      "\n",
      "LOG: Epoch [464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3226\n",
      "Epoch [464/2000], Avg Train Loss: 4.3226\n",
      "Epoch [464/2000], Avg Val Loss: 2.7948\n",
      "Validation loss improved from 2.7962 to 2.7948. Saving model...\n",
      "\n",
      "LOG: Epoch [465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2873\n",
      "Epoch [465/2000], Avg Train Loss: 4.2873\n",
      "Epoch [465/2000], Avg Val Loss: 2.7934\n",
      "Validation loss improved from 2.7948 to 2.7934. Saving model...\n",
      "\n",
      "LOG: Epoch [466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3420\n",
      "Epoch [466/2000], Avg Train Loss: 4.3420\n",
      "Epoch [466/2000], Avg Val Loss: 2.7920\n",
      "Validation loss improved from 2.7934 to 2.7920. Saving model...\n",
      "\n",
      "LOG: Epoch [467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2855\n",
      "Epoch [467/2000], Avg Train Loss: 4.2855\n",
      "Epoch [467/2000], Avg Val Loss: 2.7906\n",
      "Validation loss improved from 2.7920 to 2.7906. Saving model...\n",
      "\n",
      "LOG: Epoch [468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3014\n",
      "Epoch [468/2000], Avg Train Loss: 4.3014\n",
      "Epoch [468/2000], Avg Val Loss: 2.7893\n",
      "Validation loss improved from 2.7906 to 2.7893. Saving model...\n",
      "\n",
      "LOG: Epoch [469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3004\n",
      "Epoch [469/2000], Avg Train Loss: 4.3004\n",
      "Epoch [469/2000], Avg Val Loss: 2.7879\n",
      "Validation loss improved from 2.7893 to 2.7879. Saving model...\n",
      "\n",
      "LOG: Epoch [470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2739\n",
      "Epoch [470/2000], Avg Train Loss: 4.2739\n",
      "Epoch [470/2000], Avg Val Loss: 2.7865\n",
      "Validation loss improved from 2.7879 to 2.7865. Saving model...\n",
      "\n",
      "LOG: Epoch [471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2762\n",
      "Epoch [471/2000], Avg Train Loss: 4.2762\n",
      "Epoch [471/2000], Avg Val Loss: 2.7851\n",
      "Validation loss improved from 2.7865 to 2.7851. Saving model...\n",
      "\n",
      "LOG: Epoch [472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3201\n",
      "Epoch [472/2000], Avg Train Loss: 4.3201\n",
      "Epoch [472/2000], Avg Val Loss: 2.7838\n",
      "Validation loss improved from 2.7851 to 2.7838. Saving model...\n",
      "\n",
      "LOG: Epoch [473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2717\n",
      "Epoch [473/2000], Avg Train Loss: 4.2717\n",
      "Epoch [473/2000], Avg Val Loss: 2.7825\n",
      "Validation loss improved from 2.7838 to 2.7825. Saving model...\n",
      "\n",
      "LOG: Epoch [474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2694\n",
      "Epoch [474/2000], Avg Train Loss: 4.2694\n",
      "Epoch [474/2000], Avg Val Loss: 2.7812\n",
      "Validation loss improved from 2.7825 to 2.7812. Saving model...\n",
      "\n",
      "LOG: Epoch [475/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2803\n",
      "Epoch [475/2000], Avg Train Loss: 4.2803\n",
      "Epoch [475/2000], Avg Val Loss: 2.7799\n",
      "Validation loss improved from 2.7812 to 2.7799. Saving model...\n",
      "\n",
      "LOG: Epoch [476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2733\n",
      "Epoch [476/2000], Avg Train Loss: 4.2733\n",
      "Epoch [476/2000], Avg Val Loss: 2.7786\n",
      "Validation loss improved from 2.7799 to 2.7786. Saving model...\n",
      "\n",
      "LOG: Epoch [477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2783\n",
      "Epoch [477/2000], Avg Train Loss: 4.2783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [477/2000], Avg Val Loss: 2.7773\n",
      "Validation loss improved from 2.7786 to 2.7773. Saving model...\n",
      "\n",
      "LOG: Epoch [478/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2706\n",
      "Epoch [478/2000], Avg Train Loss: 4.2706\n",
      "Epoch [478/2000], Avg Val Loss: 2.7760\n",
      "Validation loss improved from 2.7773 to 2.7760. Saving model...\n",
      "\n",
      "LOG: Epoch [479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2584\n",
      "Epoch [479/2000], Avg Train Loss: 4.2584\n",
      "Epoch [479/2000], Avg Val Loss: 2.7747\n",
      "Validation loss improved from 2.7760 to 2.7747. Saving model...\n",
      "\n",
      "LOG: Epoch [480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2633\n",
      "Epoch [480/2000], Avg Train Loss: 4.2633\n",
      "Epoch [480/2000], Avg Val Loss: 2.7735\n",
      "Validation loss improved from 2.7747 to 2.7735. Saving model...\n",
      "\n",
      "LOG: Epoch [481/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2968\n",
      "Epoch [481/2000], Avg Train Loss: 4.2968\n",
      "Epoch [481/2000], Avg Val Loss: 2.7723\n",
      "Validation loss improved from 2.7735 to 2.7723. Saving model...\n",
      "\n",
      "LOG: Epoch [482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2588\n",
      "Epoch [482/2000], Avg Train Loss: 4.2588\n",
      "Epoch [482/2000], Avg Val Loss: 2.7711\n",
      "Validation loss improved from 2.7723 to 2.7711. Saving model...\n",
      "\n",
      "LOG: Epoch [483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2725\n",
      "Epoch [483/2000], Avg Train Loss: 4.2725\n",
      "Epoch [483/2000], Avg Val Loss: 2.7699\n",
      "Validation loss improved from 2.7711 to 2.7699. Saving model...\n",
      "\n",
      "LOG: Epoch [484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2435\n",
      "Epoch [484/2000], Avg Train Loss: 4.2435\n",
      "Epoch [484/2000], Avg Val Loss: 2.7688\n",
      "Validation loss improved from 2.7699 to 2.7688. Saving model...\n",
      "\n",
      "LOG: Epoch [485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2586\n",
      "Epoch [485/2000], Avg Train Loss: 4.2586\n",
      "Epoch [485/2000], Avg Val Loss: 2.7676\n",
      "Validation loss improved from 2.7688 to 2.7676. Saving model...\n",
      "\n",
      "LOG: Epoch [486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2989\n",
      "Epoch [486/2000], Avg Train Loss: 4.2989\n",
      "Epoch [486/2000], Avg Val Loss: 2.7664\n",
      "Validation loss improved from 2.7676 to 2.7664. Saving model...\n",
      "\n",
      "LOG: Epoch [487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2950\n",
      "Epoch [487/2000], Avg Train Loss: 4.2950\n",
      "Epoch [487/2000], Avg Val Loss: 2.7653\n",
      "Validation loss improved from 2.7664 to 2.7653. Saving model...\n",
      "\n",
      "LOG: Epoch [488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2256\n",
      "Epoch [488/2000], Avg Train Loss: 4.2256\n",
      "Epoch [488/2000], Avg Val Loss: 2.7640\n",
      "Validation loss improved from 2.7653 to 2.7640. Saving model...\n",
      "\n",
      "LOG: Epoch [489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2811\n",
      "Epoch [489/2000], Avg Train Loss: 4.2811\n",
      "Epoch [489/2000], Avg Val Loss: 2.7628\n",
      "Validation loss improved from 2.7640 to 2.7628. Saving model...\n",
      "\n",
      "LOG: Epoch [490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2482\n",
      "Epoch [490/2000], Avg Train Loss: 4.2482\n",
      "Epoch [490/2000], Avg Val Loss: 2.7617\n",
      "Validation loss improved from 2.7628 to 2.7617. Saving model...\n",
      "\n",
      "LOG: Epoch [491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2561\n",
      "Epoch [491/2000], Avg Train Loss: 4.2561\n",
      "Epoch [491/2000], Avg Val Loss: 2.7605\n",
      "Validation loss improved from 2.7617 to 2.7605. Saving model...\n",
      "\n",
      "LOG: Epoch [492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2683\n",
      "Epoch [492/2000], Avg Train Loss: 4.2683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [492/2000], Avg Val Loss: 2.7594\n",
      "Validation loss improved from 2.7605 to 2.7594. Saving model...\n",
      "\n",
      "LOG: Epoch [493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2398\n",
      "Epoch [493/2000], Avg Train Loss: 4.2398\n",
      "Epoch [493/2000], Avg Val Loss: 2.7583\n",
      "Validation loss improved from 2.7594 to 2.7583. Saving model...\n",
      "\n",
      "LOG: Epoch [494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2467\n",
      "Epoch [494/2000], Avg Train Loss: 4.2467\n",
      "Epoch [494/2000], Avg Val Loss: 2.7572\n",
      "Validation loss improved from 2.7583 to 2.7572. Saving model...\n",
      "\n",
      "LOG: Epoch [495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2322\n",
      "Epoch [495/2000], Avg Train Loss: 4.2322\n",
      "Epoch [495/2000], Avg Val Loss: 2.7561\n",
      "Validation loss improved from 2.7572 to 2.7561. Saving model...\n",
      "\n",
      "LOG: Epoch [496/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2384\n",
      "Epoch [496/2000], Avg Train Loss: 4.2384\n",
      "Epoch [496/2000], Avg Val Loss: 2.7551\n",
      "Validation loss improved from 2.7561 to 2.7551. Saving model...\n",
      "\n",
      "LOG: Epoch [497/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2770\n",
      "Epoch [497/2000], Avg Train Loss: 4.2770\n",
      "Epoch [497/2000], Avg Val Loss: 2.7540\n",
      "Validation loss improved from 2.7551 to 2.7540. Saving model...\n",
      "\n",
      "LOG: Epoch [498/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2154\n",
      "Epoch [498/2000], Avg Train Loss: 4.2154\n",
      "Epoch [498/2000], Avg Val Loss: 2.7530\n",
      "Validation loss improved from 2.7540 to 2.7530. Saving model...\n",
      "\n",
      "LOG: Epoch [499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2690\n",
      "Epoch [499/2000], Avg Train Loss: 4.2690\n",
      "Epoch [499/2000], Avg Val Loss: 2.7519\n",
      "Validation loss improved from 2.7530 to 2.7519. Saving model...\n",
      "\n",
      "LOG: Epoch [500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2138\n",
      "Epoch [500/2000], Avg Train Loss: 4.2138\n",
      "Epoch [500/2000], Avg Val Loss: 2.7509\n",
      "Validation loss improved from 2.7519 to 2.7509. Saving model...\n",
      "\n",
      "LOG: Epoch [501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2631\n",
      "Epoch [501/2000], Avg Train Loss: 4.2631\n",
      "Epoch [501/2000], Avg Val Loss: 2.7499\n",
      "Validation loss improved from 2.7509 to 2.7499. Saving model...\n",
      "\n",
      "LOG: Epoch [502/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2723\n",
      "Epoch [502/2000], Avg Train Loss: 4.2723\n",
      "Epoch [502/2000], Avg Val Loss: 2.7489\n",
      "Validation loss improved from 2.7499 to 2.7489. Saving model...\n",
      "\n",
      "LOG: Epoch [503/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2555\n",
      "Epoch [503/2000], Avg Train Loss: 4.2555\n",
      "Epoch [503/2000], Avg Val Loss: 2.7479\n",
      "Validation loss improved from 2.7489 to 2.7479. Saving model...\n",
      "\n",
      "LOG: Epoch [504/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2347\n",
      "Epoch [504/2000], Avg Train Loss: 4.2347\n",
      "Epoch [504/2000], Avg Val Loss: 2.7468\n",
      "Validation loss improved from 2.7479 to 2.7468. Saving model...\n",
      "\n",
      "LOG: Epoch [505/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2059\n",
      "Epoch [505/2000], Avg Train Loss: 4.2059\n",
      "Epoch [505/2000], Avg Val Loss: 2.7458\n",
      "Validation loss improved from 2.7468 to 2.7458. Saving model...\n",
      "\n",
      "LOG: Epoch [506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2520\n",
      "Epoch [506/2000], Avg Train Loss: 4.2520\n",
      "Epoch [506/2000], Avg Val Loss: 2.7447\n",
      "Validation loss improved from 2.7458 to 2.7447. Saving model...\n",
      "\n",
      "LOG: Epoch [507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2365\n",
      "Epoch [507/2000], Avg Train Loss: 4.2365\n",
      "Epoch [507/2000], Avg Val Loss: 2.7437\n",
      "Validation loss improved from 2.7447 to 2.7437. Saving model...\n",
      "\n",
      "LOG: Epoch [508/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2005\n",
      "Epoch [508/2000], Avg Train Loss: 4.2005\n",
      "Epoch [508/2000], Avg Val Loss: 2.7426\n",
      "Validation loss improved from 2.7437 to 2.7426. Saving model...\n",
      "\n",
      "LOG: Epoch [509/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2129\n",
      "Epoch [509/2000], Avg Train Loss: 4.2129\n",
      "Epoch [509/2000], Avg Val Loss: 2.7415\n",
      "Validation loss improved from 2.7426 to 2.7415. Saving model...\n",
      "\n",
      "LOG: Epoch [510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2424\n",
      "Epoch [510/2000], Avg Train Loss: 4.2424\n",
      "Epoch [510/2000], Avg Val Loss: 2.7404\n",
      "Validation loss improved from 2.7415 to 2.7404. Saving model...\n",
      "\n",
      "LOG: Epoch [511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2140\n",
      "Epoch [511/2000], Avg Train Loss: 4.2140\n",
      "Epoch [511/2000], Avg Val Loss: 2.7394\n",
      "Validation loss improved from 2.7404 to 2.7394. Saving model...\n",
      "\n",
      "LOG: Epoch [512/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2121\n",
      "Epoch [512/2000], Avg Train Loss: 4.2121\n",
      "Epoch [512/2000], Avg Val Loss: 2.7383\n",
      "Validation loss improved from 2.7394 to 2.7383. Saving model...\n",
      "\n",
      "LOG: Epoch [513/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1949\n",
      "Epoch [513/2000], Avg Train Loss: 4.1949\n",
      "Epoch [513/2000], Avg Val Loss: 2.7373\n",
      "Validation loss improved from 2.7383 to 2.7373. Saving model...\n",
      "\n",
      "LOG: Epoch [514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1818\n",
      "Epoch [514/2000], Avg Train Loss: 4.1818\n",
      "Epoch [514/2000], Avg Val Loss: 2.7363\n",
      "Validation loss improved from 2.7373 to 2.7363. Saving model...\n",
      "\n",
      "LOG: Epoch [515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2190\n",
      "Epoch [515/2000], Avg Train Loss: 4.2190\n",
      "Epoch [515/2000], Avg Val Loss: 2.7352\n",
      "Validation loss improved from 2.7363 to 2.7352. Saving model...\n",
      "\n",
      "LOG: Epoch [516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1875\n",
      "Epoch [516/2000], Avg Train Loss: 4.1875\n",
      "Epoch [516/2000], Avg Val Loss: 2.7342\n",
      "Validation loss improved from 2.7352 to 2.7342. Saving model...\n",
      "\n",
      "LOG: Epoch [517/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2055\n",
      "Epoch [517/2000], Avg Train Loss: 4.2055\n",
      "Epoch [517/2000], Avg Val Loss: 2.7333\n",
      "Validation loss improved from 2.7342 to 2.7333. Saving model...\n",
      "\n",
      "LOG: Epoch [518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1637\n",
      "Epoch [518/2000], Avg Train Loss: 4.1637\n",
      "Epoch [518/2000], Avg Val Loss: 2.7323\n",
      "Validation loss improved from 2.7333 to 2.7323. Saving model...\n",
      "\n",
      "LOG: Epoch [519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2538\n",
      "Epoch [519/2000], Avg Train Loss: 4.2538\n",
      "Epoch [519/2000], Avg Val Loss: 2.7314\n",
      "Validation loss improved from 2.7323 to 2.7314. Saving model...\n",
      "\n",
      "LOG: Epoch [520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2121\n",
      "Epoch [520/2000], Avg Train Loss: 4.2121\n",
      "Epoch [520/2000], Avg Val Loss: 2.7304\n",
      "Validation loss improved from 2.7314 to 2.7304. Saving model...\n",
      "\n",
      "LOG: Epoch [521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2142\n",
      "Epoch [521/2000], Avg Train Loss: 4.2142\n",
      "Epoch [521/2000], Avg Val Loss: 2.7293\n",
      "Validation loss improved from 2.7304 to 2.7293. Saving model...\n",
      "\n",
      "LOG: Epoch [522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1990\n",
      "Epoch [522/2000], Avg Train Loss: 4.1990\n",
      "Epoch [522/2000], Avg Val Loss: 2.7282\n",
      "Validation loss improved from 2.7293 to 2.7282. Saving model...\n",
      "\n",
      "LOG: Epoch [523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2312\n",
      "Epoch [523/2000], Avg Train Loss: 4.2312\n",
      "Epoch [523/2000], Avg Val Loss: 2.7272\n",
      "Validation loss improved from 2.7282 to 2.7272. Saving model...\n",
      "\n",
      "LOG: Epoch [524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1951\n",
      "Epoch [524/2000], Avg Train Loss: 4.1951\n",
      "Epoch [524/2000], Avg Val Loss: 2.7262\n",
      "Validation loss improved from 2.7272 to 2.7262. Saving model...\n",
      "\n",
      "LOG: Epoch [525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1756\n",
      "Epoch [525/2000], Avg Train Loss: 4.1756\n",
      "Epoch [525/2000], Avg Val Loss: 2.7253\n",
      "Validation loss improved from 2.7262 to 2.7253. Saving model...\n",
      "\n",
      "LOG: Epoch [526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2340\n",
      "Epoch [526/2000], Avg Train Loss: 4.2340\n",
      "Epoch [526/2000], Avg Val Loss: 2.7243\n",
      "Validation loss improved from 2.7253 to 2.7243. Saving model...\n",
      "\n",
      "LOG: Epoch [527/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2038\n",
      "Epoch [527/2000], Avg Train Loss: 4.2038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [527/2000], Avg Val Loss: 2.7234\n",
      "Validation loss improved from 2.7243 to 2.7234. Saving model...\n",
      "\n",
      "LOG: Epoch [528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1793\n",
      "Epoch [528/2000], Avg Train Loss: 4.1793\n",
      "Epoch [528/2000], Avg Val Loss: 2.7224\n",
      "Validation loss improved from 2.7234 to 2.7224. Saving model...\n",
      "\n",
      "LOG: Epoch [529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1963\n",
      "Epoch [529/2000], Avg Train Loss: 4.1963\n",
      "Epoch [529/2000], Avg Val Loss: 2.7215\n",
      "Validation loss improved from 2.7224 to 2.7215. Saving model...\n",
      "\n",
      "LOG: Epoch [530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1917\n",
      "Epoch [530/2000], Avg Train Loss: 4.1917\n",
      "Epoch [530/2000], Avg Val Loss: 2.7206\n",
      "Validation loss improved from 2.7215 to 2.7206. Saving model...\n",
      "\n",
      "LOG: Epoch [531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1730\n",
      "Epoch [531/2000], Avg Train Loss: 4.1730\n",
      "Epoch [531/2000], Avg Val Loss: 2.7196\n",
      "Validation loss improved from 2.7206 to 2.7196. Saving model...\n",
      "\n",
      "LOG: Epoch [532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2427\n",
      "Epoch [532/2000], Avg Train Loss: 4.2427\n",
      "Epoch [532/2000], Avg Val Loss: 2.7187\n",
      "Validation loss improved from 2.7196 to 2.7187. Saving model...\n",
      "\n",
      "LOG: Epoch [533/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2087\n",
      "Epoch [533/2000], Avg Train Loss: 4.2087\n",
      "Epoch [533/2000], Avg Val Loss: 2.7178\n",
      "Validation loss improved from 2.7187 to 2.7178. Saving model...\n",
      "\n",
      "LOG: Epoch [534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1589\n",
      "Epoch [534/2000], Avg Train Loss: 4.1589\n",
      "Epoch [534/2000], Avg Val Loss: 2.7169\n",
      "Validation loss improved from 2.7178 to 2.7169. Saving model...\n",
      "\n",
      "LOG: Epoch [535/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2181\n",
      "Epoch [535/2000], Avg Train Loss: 4.2181\n",
      "Epoch [535/2000], Avg Val Loss: 2.7160\n",
      "Validation loss improved from 2.7169 to 2.7160. Saving model...\n",
      "\n",
      "LOG: Epoch [536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2080\n",
      "Epoch [536/2000], Avg Train Loss: 4.2080\n",
      "Epoch [536/2000], Avg Val Loss: 2.7151\n",
      "Validation loss improved from 2.7160 to 2.7151. Saving model...\n",
      "\n",
      "LOG: Epoch [537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2100\n",
      "Epoch [537/2000], Avg Train Loss: 4.2100\n",
      "Epoch [537/2000], Avg Val Loss: 2.7142\n",
      "Validation loss improved from 2.7151 to 2.7142. Saving model...\n",
      "\n",
      "LOG: Epoch [538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1618\n",
      "Epoch [538/2000], Avg Train Loss: 4.1618\n",
      "Epoch [538/2000], Avg Val Loss: 2.7133\n",
      "Validation loss improved from 2.7142 to 2.7133. Saving model...\n",
      "\n",
      "LOG: Epoch [539/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1680\n",
      "Epoch [539/2000], Avg Train Loss: 4.1680\n",
      "Epoch [539/2000], Avg Val Loss: 2.7125\n",
      "Validation loss improved from 2.7133 to 2.7125. Saving model...\n",
      "\n",
      "LOG: Epoch [540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1859\n",
      "Epoch [540/2000], Avg Train Loss: 4.1859\n",
      "Epoch [540/2000], Avg Val Loss: 2.7116\n",
      "Validation loss improved from 2.7125 to 2.7116. Saving model...\n",
      "\n",
      "LOG: Epoch [541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2169\n",
      "Epoch [541/2000], Avg Train Loss: 4.2169\n",
      "Epoch [541/2000], Avg Val Loss: 2.7107\n",
      "Validation loss improved from 2.7116 to 2.7107. Saving model...\n",
      "\n",
      "LOG: Epoch [542/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2024\n",
      "Epoch [542/2000], Avg Train Loss: 4.2024\n",
      "Epoch [542/2000], Avg Val Loss: 2.7099\n",
      "Validation loss improved from 2.7107 to 2.7099. Saving model...\n",
      "\n",
      "LOG: Epoch [543/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1627\n",
      "Epoch [543/2000], Avg Train Loss: 4.1627\n",
      "Epoch [543/2000], Avg Val Loss: 2.7091\n",
      "Validation loss improved from 2.7099 to 2.7091. Saving model...\n",
      "\n",
      "LOG: Epoch [544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1803\n",
      "Epoch [544/2000], Avg Train Loss: 4.1803\n",
      "Epoch [544/2000], Avg Val Loss: 2.7083\n",
      "Validation loss improved from 2.7091 to 2.7083. Saving model...\n",
      "\n",
      "LOG: Epoch [545/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1526\n",
      "Epoch [545/2000], Avg Train Loss: 4.1526\n",
      "Epoch [545/2000], Avg Val Loss: 2.7074\n",
      "Validation loss improved from 2.7083 to 2.7074. Saving model...\n",
      "\n",
      "LOG: Epoch [546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1460\n",
      "Epoch [546/2000], Avg Train Loss: 4.1460\n",
      "Epoch [546/2000], Avg Val Loss: 2.7065\n",
      "Validation loss improved from 2.7074 to 2.7065. Saving model...\n",
      "\n",
      "LOG: Epoch [547/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2035\n",
      "Epoch [547/2000], Avg Train Loss: 4.2035\n",
      "Epoch [547/2000], Avg Val Loss: 2.7056\n",
      "Validation loss improved from 2.7065 to 2.7056. Saving model...\n",
      "\n",
      "LOG: Epoch [548/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1492\n",
      "Epoch [548/2000], Avg Train Loss: 4.1492\n",
      "Epoch [548/2000], Avg Val Loss: 2.7047\n",
      "Validation loss improved from 2.7056 to 2.7047. Saving model...\n",
      "\n",
      "LOG: Epoch [549/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1999\n",
      "Epoch [549/2000], Avg Train Loss: 4.1999\n",
      "Epoch [549/2000], Avg Val Loss: 2.7038\n",
      "Validation loss improved from 2.7047 to 2.7038. Saving model...\n",
      "\n",
      "LOG: Epoch [550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1935\n",
      "Epoch [550/2000], Avg Train Loss: 4.1935\n",
      "Epoch [550/2000], Avg Val Loss: 2.7030\n",
      "Validation loss improved from 2.7038 to 2.7030. Saving model...\n",
      "\n",
      "LOG: Epoch [551/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2243\n",
      "Epoch [551/2000], Avg Train Loss: 4.2243\n",
      "Epoch [551/2000], Avg Val Loss: 2.7022\n",
      "Validation loss improved from 2.7030 to 2.7022. Saving model...\n",
      "\n",
      "LOG: Epoch [552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1831\n",
      "Epoch [552/2000], Avg Train Loss: 4.1831\n",
      "Epoch [552/2000], Avg Val Loss: 2.7013\n",
      "Validation loss improved from 2.7022 to 2.7013. Saving model...\n",
      "\n",
      "LOG: Epoch [553/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1418\n",
      "Epoch [553/2000], Avg Train Loss: 4.1418\n",
      "Epoch [553/2000], Avg Val Loss: 2.7005\n",
      "Validation loss improved from 2.7013 to 2.7005. Saving model...\n",
      "\n",
      "LOG: Epoch [554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1822\n",
      "Epoch [554/2000], Avg Train Loss: 4.1822\n",
      "Epoch [554/2000], Avg Val Loss: 2.6996\n",
      "Validation loss improved from 2.7005 to 2.6996. Saving model...\n",
      "\n",
      "LOG: Epoch [555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1592\n",
      "Epoch [555/2000], Avg Train Loss: 4.1592\n",
      "Epoch [555/2000], Avg Val Loss: 2.6989\n",
      "Validation loss improved from 2.6996 to 2.6989. Saving model...\n",
      "\n",
      "LOG: Epoch [556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1408\n",
      "Epoch [556/2000], Avg Train Loss: 4.1408\n",
      "Epoch [556/2000], Avg Val Loss: 2.6981\n",
      "Validation loss improved from 2.6989 to 2.6981. Saving model...\n",
      "\n",
      "LOG: Epoch [557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1600\n",
      "Epoch [557/2000], Avg Train Loss: 4.1600\n",
      "Epoch [557/2000], Avg Val Loss: 2.6973\n",
      "Validation loss improved from 2.6981 to 2.6973. Saving model...\n",
      "\n",
      "LOG: Epoch [558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1627\n",
      "Epoch [558/2000], Avg Train Loss: 4.1627\n",
      "Epoch [558/2000], Avg Val Loss: 2.6964\n",
      "Validation loss improved from 2.6973 to 2.6964. Saving model...\n",
      "\n",
      "LOG: Epoch [559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1853\n",
      "Epoch [559/2000], Avg Train Loss: 4.1853\n",
      "Epoch [559/2000], Avg Val Loss: 2.6956\n",
      "Validation loss improved from 2.6964 to 2.6956. Saving model...\n",
      "\n",
      "LOG: Epoch [560/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1321\n",
      "Epoch [560/2000], Avg Train Loss: 4.1321\n",
      "Epoch [560/2000], Avg Val Loss: 2.6948\n",
      "Validation loss improved from 2.6956 to 2.6948. Saving model...\n",
      "\n",
      "LOG: Epoch [561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1451\n",
      "Epoch [561/2000], Avg Train Loss: 4.1451\n",
      "Epoch [561/2000], Avg Val Loss: 2.6939\n",
      "Validation loss improved from 2.6948 to 2.6939. Saving model...\n",
      "\n",
      "LOG: Epoch [562/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1279\n",
      "Epoch [562/2000], Avg Train Loss: 4.1279\n",
      "Epoch [562/2000], Avg Val Loss: 2.6931\n",
      "Validation loss improved from 2.6939 to 2.6931. Saving model...\n",
      "\n",
      "LOG: Epoch [563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1393\n",
      "Epoch [563/2000], Avg Train Loss: 4.1393\n",
      "Epoch [563/2000], Avg Val Loss: 2.6924\n",
      "Validation loss improved from 2.6931 to 2.6924. Saving model...\n",
      "\n",
      "LOG: Epoch [564/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1124\n",
      "Epoch [564/2000], Avg Train Loss: 4.1124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [564/2000], Avg Val Loss: 2.6916\n",
      "Validation loss improved from 2.6924 to 2.6916. Saving model...\n",
      "\n",
      "LOG: Epoch [565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1641\n",
      "Epoch [565/2000], Avg Train Loss: 4.1641\n",
      "Epoch [565/2000], Avg Val Loss: 2.6909\n",
      "Validation loss improved from 2.6916 to 2.6909. Saving model...\n",
      "\n",
      "LOG: Epoch [566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1793\n",
      "Epoch [566/2000], Avg Train Loss: 4.1793\n",
      "Epoch [566/2000], Avg Val Loss: 2.6902\n",
      "Validation loss improved from 2.6909 to 2.6902. Saving model...\n",
      "\n",
      "LOG: Epoch [567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1822\n",
      "Epoch [567/2000], Avg Train Loss: 4.1822\n",
      "Epoch [567/2000], Avg Val Loss: 2.6894\n",
      "Validation loss improved from 2.6902 to 2.6894. Saving model...\n",
      "\n",
      "LOG: Epoch [568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1035\n",
      "Epoch [568/2000], Avg Train Loss: 4.1035\n",
      "Epoch [568/2000], Avg Val Loss: 2.6886\n",
      "Validation loss improved from 2.6894 to 2.6886. Saving model...\n",
      "\n",
      "LOG: Epoch [569/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1162\n",
      "Epoch [569/2000], Avg Train Loss: 4.1162\n",
      "Epoch [569/2000], Avg Val Loss: 2.6878\n",
      "Validation loss improved from 2.6886 to 2.6878. Saving model...\n",
      "\n",
      "LOG: Epoch [570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1947\n",
      "Epoch [570/2000], Avg Train Loss: 4.1947\n",
      "Epoch [570/2000], Avg Val Loss: 2.6871\n",
      "Validation loss improved from 2.6878 to 2.6871. Saving model...\n",
      "\n",
      "LOG: Epoch [571/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1239\n",
      "Epoch [571/2000], Avg Train Loss: 4.1239\n",
      "Epoch [571/2000], Avg Val Loss: 2.6865\n",
      "Validation loss improved from 2.6871 to 2.6865. Saving model...\n",
      "\n",
      "LOG: Epoch [572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1789\n",
      "Epoch [572/2000], Avg Train Loss: 4.1789\n",
      "Epoch [572/2000], Avg Val Loss: 2.6859\n",
      "Validation loss improved from 2.6865 to 2.6859. Saving model...\n",
      "\n",
      "LOG: Epoch [573/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1953\n",
      "Epoch [573/2000], Avg Train Loss: 4.1953\n",
      "Epoch [573/2000], Avg Val Loss: 2.6852\n",
      "Validation loss improved from 2.6859 to 2.6852. Saving model...\n",
      "\n",
      "LOG: Epoch [574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1565\n",
      "Epoch [574/2000], Avg Train Loss: 4.1565\n",
      "Epoch [574/2000], Avg Val Loss: 2.6845\n",
      "Validation loss improved from 2.6852 to 2.6845. Saving model...\n",
      "\n",
      "LOG: Epoch [575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1715\n",
      "Epoch [575/2000], Avg Train Loss: 4.1715\n",
      "Epoch [575/2000], Avg Val Loss: 2.6837\n",
      "Validation loss improved from 2.6845 to 2.6837. Saving model...\n",
      "\n",
      "LOG: Epoch [576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1888\n",
      "Epoch [576/2000], Avg Train Loss: 4.1888\n",
      "Epoch [576/2000], Avg Val Loss: 2.6830\n",
      "Validation loss improved from 2.6837 to 2.6830. Saving model...\n",
      "\n",
      "LOG: Epoch [577/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1725\n",
      "Epoch [577/2000], Avg Train Loss: 4.1725\n",
      "Epoch [577/2000], Avg Val Loss: 2.6824\n",
      "Validation loss improved from 2.6830 to 2.6824. Saving model...\n",
      "\n",
      "LOG: Epoch [578/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1507\n",
      "Epoch [578/2000], Avg Train Loss: 4.1507\n",
      "Epoch [578/2000], Avg Val Loss: 2.6817\n",
      "Validation loss improved from 2.6824 to 2.6817. Saving model...\n",
      "\n",
      "LOG: Epoch [579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1284\n",
      "Epoch [579/2000], Avg Train Loss: 4.1284\n",
      "Epoch [579/2000], Avg Val Loss: 2.6810\n",
      "Validation loss improved from 2.6817 to 2.6810. Saving model...\n",
      "\n",
      "LOG: Epoch [580/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1867\n",
      "Epoch [580/2000], Avg Train Loss: 4.1867\n",
      "Epoch [580/2000], Avg Val Loss: 2.6804\n",
      "Validation loss improved from 2.6810 to 2.6804. Saving model...\n",
      "\n",
      "LOG: Epoch [581/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1120\n",
      "Epoch [581/2000], Avg Train Loss: 4.1120\n",
      "Epoch [581/2000], Avg Val Loss: 2.6799\n",
      "Validation loss improved from 2.6804 to 2.6799. Saving model...\n",
      "\n",
      "LOG: Epoch [582/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1150\n",
      "Epoch [582/2000], Avg Train Loss: 4.1150\n",
      "Epoch [582/2000], Avg Val Loss: 2.6793\n",
      "Validation loss improved from 2.6799 to 2.6793. Saving model...\n",
      "\n",
      "LOG: Epoch [583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1577\n",
      "Epoch [583/2000], Avg Train Loss: 4.1577\n",
      "Epoch [583/2000], Avg Val Loss: 2.6788\n",
      "Validation loss improved from 2.6793 to 2.6788. Saving model...\n",
      "\n",
      "LOG: Epoch [584/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1155\n",
      "Epoch [584/2000], Avg Train Loss: 4.1155\n",
      "Epoch [584/2000], Avg Val Loss: 2.6783\n",
      "Validation loss improved from 2.6788 to 2.6783. Saving model...\n",
      "\n",
      "LOG: Epoch [585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1391\n",
      "Epoch [585/2000], Avg Train Loss: 4.1391\n",
      "Epoch [585/2000], Avg Val Loss: 2.6778\n",
      "Validation loss improved from 2.6783 to 2.6778. Saving model...\n",
      "\n",
      "LOG: Epoch [586/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1139\n",
      "Epoch [586/2000], Avg Train Loss: 4.1139\n",
      "Epoch [586/2000], Avg Val Loss: 2.6773\n",
      "Validation loss improved from 2.6778 to 2.6773. Saving model...\n",
      "\n",
      "LOG: Epoch [587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1159\n",
      "Epoch [587/2000], Avg Train Loss: 4.1159\n",
      "Epoch [587/2000], Avg Val Loss: 2.6767\n",
      "Validation loss improved from 2.6773 to 2.6767. Saving model...\n",
      "\n",
      "LOG: Epoch [588/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1385\n",
      "Epoch [588/2000], Avg Train Loss: 4.1385\n",
      "Epoch [588/2000], Avg Val Loss: 2.6762\n",
      "Validation loss improved from 2.6767 to 2.6762. Saving model...\n",
      "\n",
      "LOG: Epoch [589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1155\n",
      "Epoch [589/2000], Avg Train Loss: 4.1155\n",
      "Epoch [589/2000], Avg Val Loss: 2.6757\n",
      "Validation loss improved from 2.6762 to 2.6757. Saving model...\n",
      "\n",
      "LOG: Epoch [590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1203\n",
      "Epoch [590/2000], Avg Train Loss: 4.1203\n",
      "Epoch [590/2000], Avg Val Loss: 2.6753\n",
      "Validation loss improved from 2.6757 to 2.6753. Saving model...\n",
      "\n",
      "LOG: Epoch [591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1147\n",
      "Epoch [591/2000], Avg Train Loss: 4.1147\n",
      "Epoch [591/2000], Avg Val Loss: 2.6748\n",
      "Validation loss improved from 2.6753 to 2.6748. Saving model...\n",
      "\n",
      "LOG: Epoch [592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1110\n",
      "Epoch [592/2000], Avg Train Loss: 4.1110\n",
      "Epoch [592/2000], Avg Val Loss: 2.6743\n",
      "Validation loss improved from 2.6748 to 2.6743. Saving model...\n",
      "\n",
      "LOG: Epoch [593/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1222\n",
      "Epoch [593/2000], Avg Train Loss: 4.1222\n",
      "Epoch [593/2000], Avg Val Loss: 2.6737\n",
      "Validation loss improved from 2.6743 to 2.6737. Saving model...\n",
      "\n",
      "LOG: Epoch [594/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0936\n",
      "Epoch [594/2000], Avg Train Loss: 4.0936\n",
      "Epoch [594/2000], Avg Val Loss: 2.6731\n",
      "Validation loss improved from 2.6737 to 2.6731. Saving model...\n",
      "\n",
      "LOG: Epoch [595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1448\n",
      "Epoch [595/2000], Avg Train Loss: 4.1448\n",
      "Epoch [595/2000], Avg Val Loss: 2.6725\n",
      "Validation loss improved from 2.6731 to 2.6725. Saving model...\n",
      "\n",
      "LOG: Epoch [596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0966\n",
      "Epoch [596/2000], Avg Train Loss: 4.0966\n",
      "Epoch [596/2000], Avg Val Loss: 2.6718\n",
      "Validation loss improved from 2.6725 to 2.6718. Saving model...\n",
      "\n",
      "LOG: Epoch [597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1465\n",
      "Epoch [597/2000], Avg Train Loss: 4.1465\n",
      "Epoch [597/2000], Avg Val Loss: 2.6713\n",
      "Validation loss improved from 2.6718 to 2.6713. Saving model...\n",
      "\n",
      "LOG: Epoch [598/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1368\n",
      "Epoch [598/2000], Avg Train Loss: 4.1368\n",
      "Epoch [598/2000], Avg Val Loss: 2.6708\n",
      "Validation loss improved from 2.6713 to 2.6708. Saving model...\n",
      "\n",
      "LOG: Epoch [599/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1061\n",
      "Epoch [599/2000], Avg Train Loss: 4.1061\n",
      "Epoch [599/2000], Avg Val Loss: 2.6703\n",
      "Validation loss improved from 2.6708 to 2.6703. Saving model...\n",
      "\n",
      "LOG: Epoch [600/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1122\n",
      "Epoch [600/2000], Avg Train Loss: 4.1122\n",
      "Epoch [600/2000], Avg Val Loss: 2.6697\n",
      "Validation loss improved from 2.6703 to 2.6697. Saving model...\n",
      "\n",
      "LOG: Epoch [601/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0883\n",
      "Epoch [601/2000], Avg Train Loss: 4.0883\n",
      "Epoch [601/2000], Avg Val Loss: 2.6691\n",
      "Validation loss improved from 2.6697 to 2.6691. Saving model...\n",
      "\n",
      "LOG: Epoch [602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1295\n",
      "Epoch [602/2000], Avg Train Loss: 4.1295\n",
      "Epoch [602/2000], Avg Val Loss: 2.6685\n",
      "Validation loss improved from 2.6691 to 2.6685. Saving model...\n",
      "\n",
      "LOG: Epoch [603/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1259\n",
      "Epoch [603/2000], Avg Train Loss: 4.1259\n",
      "Epoch [603/2000], Avg Val Loss: 2.6678\n",
      "Validation loss improved from 2.6685 to 2.6678. Saving model...\n",
      "\n",
      "LOG: Epoch [604/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0997\n",
      "Epoch [604/2000], Avg Train Loss: 4.0997\n",
      "Epoch [604/2000], Avg Val Loss: 2.6672\n",
      "Validation loss improved from 2.6678 to 2.6672. Saving model...\n",
      "\n",
      "LOG: Epoch [605/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1259\n",
      "Epoch [605/2000], Avg Train Loss: 4.1259\n",
      "Epoch [605/2000], Avg Val Loss: 2.6667\n",
      "Validation loss improved from 2.6672 to 2.6667. Saving model...\n",
      "\n",
      "LOG: Epoch [606/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0621\n",
      "Epoch [606/2000], Avg Train Loss: 4.0621\n",
      "Epoch [606/2000], Avg Val Loss: 2.6661\n",
      "Validation loss improved from 2.6667 to 2.6661. Saving model...\n",
      "\n",
      "LOG: Epoch [607/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0916\n",
      "Epoch [607/2000], Avg Train Loss: 4.0916\n",
      "Epoch [607/2000], Avg Val Loss: 2.6657\n",
      "Validation loss improved from 2.6661 to 2.6657. Saving model...\n",
      "\n",
      "LOG: Epoch [608/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0675\n",
      "Epoch [608/2000], Avg Train Loss: 4.0675\n",
      "Epoch [608/2000], Avg Val Loss: 2.6652\n",
      "Validation loss improved from 2.6657 to 2.6652. Saving model...\n",
      "\n",
      "LOG: Epoch [609/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1103\n",
      "Epoch [609/2000], Avg Train Loss: 4.1103\n",
      "Epoch [609/2000], Avg Val Loss: 2.6648\n",
      "Validation loss improved from 2.6652 to 2.6648. Saving model...\n",
      "\n",
      "LOG: Epoch [610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0842\n",
      "Epoch [610/2000], Avg Train Loss: 4.0842\n",
      "Epoch [610/2000], Avg Val Loss: 2.6644\n",
      "Validation loss improved from 2.6648 to 2.6644. Saving model...\n",
      "\n",
      "LOG: Epoch [611/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1226\n",
      "Epoch [611/2000], Avg Train Loss: 4.1226\n",
      "Epoch [611/2000], Avg Val Loss: 2.6639\n",
      "Validation loss improved from 2.6644 to 2.6639. Saving model...\n",
      "\n",
      "LOG: Epoch [612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1223\n",
      "Epoch [612/2000], Avg Train Loss: 4.1223\n",
      "Epoch [612/2000], Avg Val Loss: 2.6635\n",
      "Validation loss improved from 2.6639 to 2.6635. Saving model...\n",
      "\n",
      "LOG: Epoch [613/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1199\n",
      "Epoch [613/2000], Avg Train Loss: 4.1199\n",
      "Epoch [613/2000], Avg Val Loss: 2.6629\n",
      "Validation loss improved from 2.6635 to 2.6629. Saving model...\n",
      "\n",
      "LOG: Epoch [614/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0636\n",
      "Epoch [614/2000], Avg Train Loss: 4.0636\n",
      "Epoch [614/2000], Avg Val Loss: 2.6624\n",
      "Validation loss improved from 2.6629 to 2.6624. Saving model...\n",
      "\n",
      "LOG: Epoch [615/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1012\n",
      "Epoch [615/2000], Avg Train Loss: 4.1012\n",
      "Epoch [615/2000], Avg Val Loss: 2.6619\n",
      "Validation loss improved from 2.6624 to 2.6619. Saving model...\n",
      "\n",
      "LOG: Epoch [616/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0872\n",
      "Epoch [616/2000], Avg Train Loss: 4.0872\n",
      "Epoch [616/2000], Avg Val Loss: 2.6615\n",
      "Validation loss improved from 2.6619 to 2.6615. Saving model...\n",
      "\n",
      "LOG: Epoch [617/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0901\n",
      "Epoch [617/2000], Avg Train Loss: 4.0901\n",
      "Epoch [617/2000], Avg Val Loss: 2.6611\n",
      "Validation loss improved from 2.6615 to 2.6611. Saving model...\n",
      "\n",
      "LOG: Epoch [618/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0943\n",
      "Epoch [618/2000], Avg Train Loss: 4.0943\n",
      "Epoch [618/2000], Avg Val Loss: 2.6607\n",
      "Validation loss improved from 2.6611 to 2.6607. Saving model...\n",
      "\n",
      "LOG: Epoch [619/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1041\n",
      "Epoch [619/2000], Avg Train Loss: 4.1041\n",
      "Epoch [619/2000], Avg Val Loss: 2.6603\n",
      "Validation loss improved from 2.6607 to 2.6603. Saving model...\n",
      "\n",
      "LOG: Epoch [620/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0656\n",
      "Epoch [620/2000], Avg Train Loss: 4.0656\n",
      "Epoch [620/2000], Avg Val Loss: 2.6598\n",
      "Validation loss improved from 2.6603 to 2.6598. Saving model...\n",
      "\n",
      "LOG: Epoch [621/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0766\n",
      "Epoch [621/2000], Avg Train Loss: 4.0766\n",
      "Epoch [621/2000], Avg Val Loss: 2.6595\n",
      "Validation loss improved from 2.6598 to 2.6595. Saving model...\n",
      "\n",
      "LOG: Epoch [622/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1305\n",
      "Epoch [622/2000], Avg Train Loss: 4.1305\n",
      "Epoch [622/2000], Avg Val Loss: 2.6591\n",
      "Validation loss improved from 2.6595 to 2.6591. Saving model...\n",
      "\n",
      "LOG: Epoch [623/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0908\n",
      "Epoch [623/2000], Avg Train Loss: 4.0908\n",
      "Epoch [623/2000], Avg Val Loss: 2.6586\n",
      "Validation loss improved from 2.6591 to 2.6586. Saving model...\n",
      "\n",
      "LOG: Epoch [624/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0407\n",
      "Epoch [624/2000], Avg Train Loss: 4.0407\n",
      "Epoch [624/2000], Avg Val Loss: 2.6580\n",
      "Validation loss improved from 2.6586 to 2.6580. Saving model...\n",
      "\n",
      "LOG: Epoch [625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0877\n",
      "Epoch [625/2000], Avg Train Loss: 4.0877\n",
      "Epoch [625/2000], Avg Val Loss: 2.6574\n",
      "Validation loss improved from 2.6580 to 2.6574. Saving model...\n",
      "\n",
      "LOG: Epoch [626/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0875\n",
      "Epoch [626/2000], Avg Train Loss: 4.0875\n",
      "Epoch [626/2000], Avg Val Loss: 2.6568\n",
      "Validation loss improved from 2.6574 to 2.6568. Saving model...\n",
      "\n",
      "LOG: Epoch [627/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1435\n",
      "Epoch [627/2000], Avg Train Loss: 4.1435\n",
      "Epoch [627/2000], Avg Val Loss: 2.6560\n",
      "Validation loss improved from 2.6568 to 2.6560. Saving model...\n",
      "\n",
      "LOG: Epoch [628/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1017\n",
      "Epoch [628/2000], Avg Train Loss: 4.1017\n",
      "Epoch [628/2000], Avg Val Loss: 2.6554\n",
      "Validation loss improved from 2.6560 to 2.6554. Saving model...\n",
      "\n",
      "LOG: Epoch [629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0931\n",
      "Epoch [629/2000], Avg Train Loss: 4.0931\n",
      "Epoch [629/2000], Avg Val Loss: 2.6547\n",
      "Validation loss improved from 2.6554 to 2.6547. Saving model...\n",
      "\n",
      "LOG: Epoch [630/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0296\n",
      "Epoch [630/2000], Avg Train Loss: 4.0296\n",
      "Epoch [630/2000], Avg Val Loss: 2.6541\n",
      "Validation loss improved from 2.6547 to 2.6541. Saving model...\n",
      "\n",
      "LOG: Epoch [631/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0912\n",
      "Epoch [631/2000], Avg Train Loss: 4.0912\n",
      "Epoch [631/2000], Avg Val Loss: 2.6534\n",
      "Validation loss improved from 2.6541 to 2.6534. Saving model...\n",
      "\n",
      "LOG: Epoch [632/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1004\n",
      "Epoch [632/2000], Avg Train Loss: 4.1004\n",
      "Epoch [632/2000], Avg Val Loss: 2.6527\n",
      "Validation loss improved from 2.6534 to 2.6527. Saving model...\n",
      "\n",
      "LOG: Epoch [633/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0709\n",
      "Epoch [633/2000], Avg Train Loss: 4.0709\n",
      "Epoch [633/2000], Avg Val Loss: 2.6520\n",
      "Validation loss improved from 2.6527 to 2.6520. Saving model...\n",
      "\n",
      "LOG: Epoch [634/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0791\n",
      "Epoch [634/2000], Avg Train Loss: 4.0791\n",
      "Epoch [634/2000], Avg Val Loss: 2.6512\n",
      "Validation loss improved from 2.6520 to 2.6512. Saving model...\n",
      "\n",
      "LOG: Epoch [635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1324\n",
      "Epoch [635/2000], Avg Train Loss: 4.1324\n",
      "Epoch [635/2000], Avg Val Loss: 2.6505\n",
      "Validation loss improved from 2.6512 to 2.6505. Saving model...\n",
      "\n",
      "LOG: Epoch [636/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1051\n",
      "Epoch [636/2000], Avg Train Loss: 4.1051\n",
      "Epoch [636/2000], Avg Val Loss: 2.6496\n",
      "Validation loss improved from 2.6505 to 2.6496. Saving model...\n",
      "\n",
      "LOG: Epoch [637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0682\n",
      "Epoch [637/2000], Avg Train Loss: 4.0682\n",
      "Epoch [637/2000], Avg Val Loss: 2.6488\n",
      "Validation loss improved from 2.6496 to 2.6488. Saving model...\n",
      "\n",
      "LOG: Epoch [638/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0765\n",
      "Epoch [638/2000], Avg Train Loss: 4.0765\n",
      "Epoch [638/2000], Avg Val Loss: 2.6481\n",
      "Validation loss improved from 2.6488 to 2.6481. Saving model...\n",
      "\n",
      "LOG: Epoch [639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0450\n",
      "Epoch [639/2000], Avg Train Loss: 4.0450\n",
      "Epoch [639/2000], Avg Val Loss: 2.6474\n",
      "Validation loss improved from 2.6481 to 2.6474. Saving model...\n",
      "\n",
      "LOG: Epoch [640/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0705\n",
      "Epoch [640/2000], Avg Train Loss: 4.0705\n",
      "Epoch [640/2000], Avg Val Loss: 2.6467\n",
      "Validation loss improved from 2.6474 to 2.6467. Saving model...\n",
      "\n",
      "LOG: Epoch [641/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1327\n",
      "Epoch [641/2000], Avg Train Loss: 4.1327\n",
      "Epoch [641/2000], Avg Val Loss: 2.6460\n",
      "Validation loss improved from 2.6467 to 2.6460. Saving model...\n",
      "\n",
      "LOG: Epoch [642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0605\n",
      "Epoch [642/2000], Avg Train Loss: 4.0605\n",
      "Epoch [642/2000], Avg Val Loss: 2.6453\n",
      "Validation loss improved from 2.6460 to 2.6453. Saving model...\n",
      "\n",
      "LOG: Epoch [643/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0626\n",
      "Epoch [643/2000], Avg Train Loss: 4.0626\n",
      "Epoch [643/2000], Avg Val Loss: 2.6446\n",
      "Validation loss improved from 2.6453 to 2.6446. Saving model...\n",
      "\n",
      "LOG: Epoch [644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0545\n",
      "Epoch [644/2000], Avg Train Loss: 4.0545\n",
      "Epoch [644/2000], Avg Val Loss: 2.6439\n",
      "Validation loss improved from 2.6446 to 2.6439. Saving model...\n",
      "\n",
      "LOG: Epoch [645/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1167\n",
      "Epoch [645/2000], Avg Train Loss: 4.1167\n",
      "Epoch [645/2000], Avg Val Loss: 2.6433\n",
      "Validation loss improved from 2.6439 to 2.6433. Saving model...\n",
      "\n",
      "LOG: Epoch [646/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0733\n",
      "Epoch [646/2000], Avg Train Loss: 4.0733\n",
      "Epoch [646/2000], Avg Val Loss: 2.6426\n",
      "Validation loss improved from 2.6433 to 2.6426. Saving model...\n",
      "\n",
      "LOG: Epoch [647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0857\n",
      "Epoch [647/2000], Avg Train Loss: 4.0857\n",
      "Epoch [647/2000], Avg Val Loss: 2.6419\n",
      "Validation loss improved from 2.6426 to 2.6419. Saving model...\n",
      "\n",
      "LOG: Epoch [648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9904\n",
      "Epoch [648/2000], Avg Train Loss: 3.9904\n",
      "Epoch [648/2000], Avg Val Loss: 2.6413\n",
      "Validation loss improved from 2.6419 to 2.6413. Saving model...\n",
      "\n",
      "LOG: Epoch [649/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0205\n",
      "Epoch [649/2000], Avg Train Loss: 4.0205\n",
      "Epoch [649/2000], Avg Val Loss: 2.6407\n",
      "Validation loss improved from 2.6413 to 2.6407. Saving model...\n",
      "\n",
      "LOG: Epoch [650/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0480\n",
      "Epoch [650/2000], Avg Train Loss: 4.0480\n",
      "Epoch [650/2000], Avg Val Loss: 2.6400\n",
      "Validation loss improved from 2.6407 to 2.6400. Saving model...\n",
      "\n",
      "LOG: Epoch [651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0897\n",
      "Epoch [651/2000], Avg Train Loss: 4.0897\n",
      "Epoch [651/2000], Avg Val Loss: 2.6395\n",
      "Validation loss improved from 2.6400 to 2.6395. Saving model...\n",
      "\n",
      "LOG: Epoch [652/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0652\n",
      "Epoch [652/2000], Avg Train Loss: 4.0652\n",
      "Epoch [652/2000], Avg Val Loss: 2.6391\n",
      "Validation loss improved from 2.6395 to 2.6391. Saving model...\n",
      "\n",
      "LOG: Epoch [653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0327\n",
      "Epoch [653/2000], Avg Train Loss: 4.0327\n",
      "Epoch [653/2000], Avg Val Loss: 2.6386\n",
      "Validation loss improved from 2.6391 to 2.6386. Saving model...\n",
      "\n",
      "LOG: Epoch [654/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0543\n",
      "Epoch [654/2000], Avg Train Loss: 4.0543\n",
      "Epoch [654/2000], Avg Val Loss: 2.6382\n",
      "Validation loss improved from 2.6386 to 2.6382. Saving model...\n",
      "\n",
      "LOG: Epoch [655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0325\n",
      "Epoch [655/2000], Avg Train Loss: 4.0325\n",
      "Epoch [655/2000], Avg Val Loss: 2.6378\n",
      "Validation loss improved from 2.6382 to 2.6378. Saving model...\n",
      "\n",
      "LOG: Epoch [656/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0717\n",
      "Epoch [656/2000], Avg Train Loss: 4.0717\n",
      "Epoch [656/2000], Avg Val Loss: 2.6375\n",
      "Validation loss improved from 2.6378 to 2.6375. Saving model...\n",
      "\n",
      "LOG: Epoch [657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0888\n",
      "Epoch [657/2000], Avg Train Loss: 4.0888\n",
      "Epoch [657/2000], Avg Val Loss: 2.6371\n",
      "Validation loss improved from 2.6375 to 2.6371. Saving model...\n",
      "\n",
      "LOG: Epoch [658/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0262\n",
      "Epoch [658/2000], Avg Train Loss: 4.0262\n",
      "Epoch [658/2000], Avg Val Loss: 2.6367\n",
      "Validation loss improved from 2.6371 to 2.6367. Saving model...\n",
      "\n",
      "LOG: Epoch [659/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0647\n",
      "Epoch [659/2000], Avg Train Loss: 4.0647\n",
      "Epoch [659/2000], Avg Val Loss: 2.6364\n",
      "Validation loss improved from 2.6367 to 2.6364. Saving model...\n",
      "\n",
      "LOG: Epoch [660/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0560\n",
      "Epoch [660/2000], Avg Train Loss: 4.0560\n",
      "Epoch [660/2000], Avg Val Loss: 2.6360\n",
      "Validation loss improved from 2.6364 to 2.6360. Saving model...\n",
      "\n",
      "LOG: Epoch [661/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0143\n",
      "Epoch [661/2000], Avg Train Loss: 4.0143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [661/2000], Avg Val Loss: 2.6357\n",
      "Validation loss improved from 2.6360 to 2.6357. Saving model...\n",
      "\n",
      "LOG: Epoch [662/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0481\n",
      "Epoch [662/2000], Avg Train Loss: 4.0481\n",
      "Epoch [662/2000], Avg Val Loss: 2.6353\n",
      "Validation loss improved from 2.6357 to 2.6353. Saving model...\n",
      "\n",
      "LOG: Epoch [663/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0090\n",
      "Epoch [663/2000], Avg Train Loss: 4.0090\n",
      "Epoch [663/2000], Avg Val Loss: 2.6349\n",
      "Validation loss improved from 2.6353 to 2.6349. Saving model...\n",
      "\n",
      "LOG: Epoch [664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0301\n",
      "Epoch [664/2000], Avg Train Loss: 4.0301\n",
      "Epoch [664/2000], Avg Val Loss: 2.6345\n",
      "Validation loss improved from 2.6349 to 2.6345. Saving model...\n",
      "\n",
      "LOG: Epoch [665/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0459\n",
      "Epoch [665/2000], Avg Train Loss: 4.0459\n",
      "Epoch [665/2000], Avg Val Loss: 2.6341\n",
      "Validation loss improved from 2.6345 to 2.6341. Saving model...\n",
      "\n",
      "LOG: Epoch [666/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0248\n",
      "Epoch [666/2000], Avg Train Loss: 4.0248\n",
      "Epoch [666/2000], Avg Val Loss: 2.6337\n",
      "Validation loss improved from 2.6341 to 2.6337. Saving model...\n",
      "\n",
      "LOG: Epoch [667/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0696\n",
      "Epoch [667/2000], Avg Train Loss: 4.0696\n",
      "Epoch [667/2000], Avg Val Loss: 2.6333\n",
      "Validation loss improved from 2.6337 to 2.6333. Saving model...\n",
      "\n",
      "LOG: Epoch [668/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0427\n",
      "Epoch [668/2000], Avg Train Loss: 4.0427\n",
      "Epoch [668/2000], Avg Val Loss: 2.6329\n",
      "Validation loss improved from 2.6333 to 2.6329. Saving model...\n",
      "\n",
      "LOG: Epoch [669/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0151\n",
      "Epoch [669/2000], Avg Train Loss: 4.0151\n",
      "Epoch [669/2000], Avg Val Loss: 2.6325\n",
      "Validation loss improved from 2.6329 to 2.6325. Saving model...\n",
      "\n",
      "LOG: Epoch [670/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0091\n",
      "Epoch [670/2000], Avg Train Loss: 4.0091\n",
      "Epoch [670/2000], Avg Val Loss: 2.6319\n",
      "Validation loss improved from 2.6325 to 2.6319. Saving model...\n",
      "\n",
      "LOG: Epoch [671/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0380\n",
      "Epoch [671/2000], Avg Train Loss: 4.0380\n",
      "Epoch [671/2000], Avg Val Loss: 2.6313\n",
      "Validation loss improved from 2.6319 to 2.6313. Saving model...\n",
      "\n",
      "LOG: Epoch [672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0360\n",
      "Epoch [672/2000], Avg Train Loss: 4.0360\n",
      "Epoch [672/2000], Avg Val Loss: 2.6308\n",
      "Validation loss improved from 2.6313 to 2.6308. Saving model...\n",
      "\n",
      "LOG: Epoch [673/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0360\n",
      "Epoch [673/2000], Avg Train Loss: 4.0360\n",
      "Epoch [673/2000], Avg Val Loss: 2.6302\n",
      "Validation loss improved from 2.6308 to 2.6302. Saving model...\n",
      "\n",
      "LOG: Epoch [674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9983\n",
      "Epoch [674/2000], Avg Train Loss: 3.9983\n",
      "Epoch [674/2000], Avg Val Loss: 2.6297\n",
      "Validation loss improved from 2.6302 to 2.6297. Saving model...\n",
      "\n",
      "LOG: Epoch [675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0850\n",
      "Epoch [675/2000], Avg Train Loss: 4.0850\n",
      "Epoch [675/2000], Avg Val Loss: 2.6291\n",
      "Validation loss improved from 2.6297 to 2.6291. Saving model...\n",
      "\n",
      "LOG: Epoch [676/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0336\n",
      "Epoch [676/2000], Avg Train Loss: 4.0336\n",
      "Epoch [676/2000], Avg Val Loss: 2.6285\n",
      "Validation loss improved from 2.6291 to 2.6285. Saving model...\n",
      "\n",
      "LOG: Epoch [677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0158\n",
      "Epoch [677/2000], Avg Train Loss: 4.0158\n",
      "Epoch [677/2000], Avg Val Loss: 2.6280\n",
      "Validation loss improved from 2.6285 to 2.6280. Saving model...\n",
      "\n",
      "LOG: Epoch [678/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9831\n",
      "Epoch [678/2000], Avg Train Loss: 3.9831\n",
      "Epoch [678/2000], Avg Val Loss: 2.6274\n",
      "Validation loss improved from 2.6280 to 2.6274. Saving model...\n",
      "\n",
      "LOG: Epoch [679/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0255\n",
      "Epoch [679/2000], Avg Train Loss: 4.0255\n",
      "Epoch [679/2000], Avg Val Loss: 2.6269\n",
      "Validation loss improved from 2.6274 to 2.6269. Saving model...\n",
      "\n",
      "LOG: Epoch [680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0382\n",
      "Epoch [680/2000], Avg Train Loss: 4.0382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [680/2000], Avg Val Loss: 2.6263\n",
      "Validation loss improved from 2.6269 to 2.6263. Saving model...\n",
      "\n",
      "LOG: Epoch [681/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0464\n",
      "Epoch [681/2000], Avg Train Loss: 4.0464\n",
      "Epoch [681/2000], Avg Val Loss: 2.6258\n",
      "Validation loss improved from 2.6263 to 2.6258. Saving model...\n",
      "\n",
      "LOG: Epoch [682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9821\n",
      "Epoch [682/2000], Avg Train Loss: 3.9821\n",
      "Epoch [682/2000], Avg Val Loss: 2.6253\n",
      "Validation loss improved from 2.6258 to 2.6253. Saving model...\n",
      "\n",
      "LOG: Epoch [683/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0274\n",
      "Epoch [683/2000], Avg Train Loss: 4.0274\n",
      "Epoch [683/2000], Avg Val Loss: 2.6249\n",
      "Validation loss improved from 2.6253 to 2.6249. Saving model...\n",
      "\n",
      "LOG: Epoch [684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9952\n",
      "Epoch [684/2000], Avg Train Loss: 3.9952\n",
      "Epoch [684/2000], Avg Val Loss: 2.6245\n",
      "Validation loss improved from 2.6249 to 2.6245. Saving model...\n",
      "\n",
      "LOG: Epoch [685/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9974\n",
      "Epoch [685/2000], Avg Train Loss: 3.9974\n",
      "Epoch [685/2000], Avg Val Loss: 2.6240\n",
      "Validation loss improved from 2.6245 to 2.6240. Saving model...\n",
      "\n",
      "LOG: Epoch [686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0047\n",
      "Epoch [686/2000], Avg Train Loss: 4.0047\n",
      "Epoch [686/2000], Avg Val Loss: 2.6236\n",
      "Validation loss improved from 2.6240 to 2.6236. Saving model...\n",
      "\n",
      "LOG: Epoch [687/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0390\n",
      "Epoch [687/2000], Avg Train Loss: 4.0390\n",
      "Epoch [687/2000], Avg Val Loss: 2.6231\n",
      "Validation loss improved from 2.6236 to 2.6231. Saving model...\n",
      "\n",
      "LOG: Epoch [688/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0295\n",
      "Epoch [688/2000], Avg Train Loss: 4.0295\n",
      "Epoch [688/2000], Avg Val Loss: 2.6226\n",
      "Validation loss improved from 2.6231 to 2.6226. Saving model...\n",
      "\n",
      "LOG: Epoch [689/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9930\n",
      "Epoch [689/2000], Avg Train Loss: 3.9930\n",
      "Epoch [689/2000], Avg Val Loss: 2.6221\n",
      "Validation loss improved from 2.6226 to 2.6221. Saving model...\n",
      "\n",
      "LOG: Epoch [690/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0344\n",
      "Epoch [690/2000], Avg Train Loss: 4.0344\n",
      "Epoch [690/2000], Avg Val Loss: 2.6216\n",
      "Validation loss improved from 2.6221 to 2.6216. Saving model...\n",
      "\n",
      "LOG: Epoch [691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9992\n",
      "Epoch [691/2000], Avg Train Loss: 3.9992\n",
      "Epoch [691/2000], Avg Val Loss: 2.6211\n",
      "Validation loss improved from 2.6216 to 2.6211. Saving model...\n",
      "\n",
      "LOG: Epoch [692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9813\n",
      "Epoch [692/2000], Avg Train Loss: 3.9813\n",
      "Epoch [692/2000], Avg Val Loss: 2.6206\n",
      "Validation loss improved from 2.6211 to 2.6206. Saving model...\n",
      "\n",
      "LOG: Epoch [693/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0120\n",
      "Epoch [693/2000], Avg Train Loss: 4.0120\n",
      "Epoch [693/2000], Avg Val Loss: 2.6202\n",
      "Validation loss improved from 2.6206 to 2.6202. Saving model...\n",
      "\n",
      "LOG: Epoch [694/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9998\n",
      "Epoch [694/2000], Avg Train Loss: 3.9998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [694/2000], Avg Val Loss: 2.6198\n",
      "Validation loss improved from 2.6202 to 2.6198. Saving model...\n",
      "\n",
      "LOG: Epoch [695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9754\n",
      "Epoch [695/2000], Avg Train Loss: 3.9754\n",
      "Epoch [695/2000], Avg Val Loss: 2.6195\n",
      "Validation loss improved from 2.6198 to 2.6195. Saving model...\n",
      "\n",
      "LOG: Epoch [696/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0186\n",
      "Epoch [696/2000], Avg Train Loss: 4.0186\n",
      "Epoch [696/2000], Avg Val Loss: 2.6192\n",
      "Validation loss improved from 2.6195 to 2.6192. Saving model...\n",
      "\n",
      "LOG: Epoch [697/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9987\n",
      "Epoch [697/2000], Avg Train Loss: 3.9987\n",
      "Epoch [697/2000], Avg Val Loss: 2.6190\n",
      "Validation loss improved from 2.6192 to 2.6190. Saving model...\n",
      "\n",
      "LOG: Epoch [698/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0100\n",
      "Epoch [698/2000], Avg Train Loss: 4.0100\n",
      "Epoch [698/2000], Avg Val Loss: 2.6188\n",
      "Validation loss improved from 2.6190 to 2.6188. Saving model...\n",
      "\n",
      "LOG: Epoch [699/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0081\n",
      "Epoch [699/2000], Avg Train Loss: 4.0081\n",
      "Epoch [699/2000], Avg Val Loss: 2.6185\n",
      "Validation loss improved from 2.6188 to 2.6185. Saving model...\n",
      "\n",
      "LOG: Epoch [700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0224\n",
      "Epoch [700/2000], Avg Train Loss: 4.0224\n",
      "Epoch [700/2000], Avg Val Loss: 2.6182\n",
      "Validation loss improved from 2.6185 to 2.6182. Saving model...\n",
      "\n",
      "LOG: Epoch [701/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9957\n",
      "Epoch [701/2000], Avg Train Loss: 3.9957\n",
      "Epoch [701/2000], Avg Val Loss: 2.6179\n",
      "Validation loss improved from 2.6182 to 2.6179. Saving model...\n",
      "\n",
      "LOG: Epoch [702/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0126\n",
      "Epoch [702/2000], Avg Train Loss: 4.0126\n",
      "Epoch [702/2000], Avg Val Loss: 2.6176\n",
      "Validation loss improved from 2.6179 to 2.6176. Saving model...\n",
      "\n",
      "LOG: Epoch [703/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0391\n",
      "Epoch [703/2000], Avg Train Loss: 4.0391\n",
      "Epoch [703/2000], Avg Val Loss: 2.6171\n",
      "Validation loss improved from 2.6176 to 2.6171. Saving model...\n",
      "\n",
      "LOG: Epoch [704/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0426\n",
      "Epoch [704/2000], Avg Train Loss: 4.0426\n",
      "Epoch [704/2000], Avg Val Loss: 2.6167\n",
      "Validation loss improved from 2.6171 to 2.6167. Saving model...\n",
      "\n",
      "LOG: Epoch [705/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0161\n",
      "Epoch [705/2000], Avg Train Loss: 4.0161\n",
      "Epoch [705/2000], Avg Val Loss: 2.6163\n",
      "Validation loss improved from 2.6167 to 2.6163. Saving model...\n",
      "\n",
      "LOG: Epoch [706/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0020\n",
      "Epoch [706/2000], Avg Train Loss: 4.0020\n",
      "Epoch [706/2000], Avg Val Loss: 2.6158\n",
      "Validation loss improved from 2.6163 to 2.6158. Saving model...\n",
      "\n",
      "LOG: Epoch [707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0600\n",
      "Epoch [707/2000], Avg Train Loss: 4.0600\n",
      "Epoch [707/2000], Avg Val Loss: 2.6154\n",
      "Validation loss improved from 2.6158 to 2.6154. Saving model...\n",
      "\n",
      "LOG: Epoch [708/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0107\n",
      "Epoch [708/2000], Avg Train Loss: 4.0107\n",
      "Epoch [708/2000], Avg Val Loss: 2.6149\n",
      "Validation loss improved from 2.6154 to 2.6149. Saving model...\n",
      "\n",
      "LOG: Epoch [709/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0092\n",
      "Epoch [709/2000], Avg Train Loss: 4.0092\n",
      "Epoch [709/2000], Avg Val Loss: 2.6144\n",
      "Validation loss improved from 2.6149 to 2.6144. Saving model...\n",
      "\n",
      "LOG: Epoch [710/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9673\n",
      "Epoch [710/2000], Avg Train Loss: 3.9673\n",
      "Epoch [710/2000], Avg Val Loss: 2.6139\n",
      "Validation loss improved from 2.6144 to 2.6139. Saving model...\n",
      "\n",
      "LOG: Epoch [711/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9641\n",
      "Epoch [711/2000], Avg Train Loss: 3.9641\n",
      "Epoch [711/2000], Avg Val Loss: 2.6135\n",
      "Validation loss improved from 2.6139 to 2.6135. Saving model...\n",
      "\n",
      "LOG: Epoch [712/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0356\n",
      "Epoch [712/2000], Avg Train Loss: 4.0356\n",
      "Epoch [712/2000], Avg Val Loss: 2.6131\n",
      "Validation loss improved from 2.6135 to 2.6131. Saving model...\n",
      "\n",
      "LOG: Epoch [713/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9900\n",
      "Epoch [713/2000], Avg Train Loss: 3.9900\n",
      "Epoch [713/2000], Avg Val Loss: 2.6127\n",
      "Validation loss improved from 2.6131 to 2.6127. Saving model...\n",
      "\n",
      "LOG: Epoch [714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9717\n",
      "Epoch [714/2000], Avg Train Loss: 3.9717\n",
      "Epoch [714/2000], Avg Val Loss: 2.6124\n",
      "Validation loss improved from 2.6127 to 2.6124. Saving model...\n",
      "\n",
      "LOG: Epoch [715/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9985\n",
      "Epoch [715/2000], Avg Train Loss: 3.9985\n",
      "Epoch [715/2000], Avg Val Loss: 2.6122\n",
      "Validation loss improved from 2.6124 to 2.6122. Saving model...\n",
      "\n",
      "LOG: Epoch [716/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0056\n",
      "Epoch [716/2000], Avg Train Loss: 4.0056\n",
      "Epoch [716/2000], Avg Val Loss: 2.6120\n",
      "Validation loss improved from 2.6122 to 2.6120. Saving model...\n",
      "\n",
      "LOG: Epoch [717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9862\n",
      "Epoch [717/2000], Avg Train Loss: 3.9862\n",
      "Epoch [717/2000], Avg Val Loss: 2.6119\n",
      "Validation loss improved from 2.6120 to 2.6119. Saving model...\n",
      "\n",
      "LOG: Epoch [718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9889\n",
      "Epoch [718/2000], Avg Train Loss: 3.9889\n",
      "Epoch [718/2000], Avg Val Loss: 2.6118\n",
      "Validation loss improved from 2.6119 to 2.6118. Saving model...\n",
      "\n",
      "LOG: Epoch [719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9984\n",
      "Epoch [719/2000], Avg Train Loss: 3.9984\n",
      "Epoch [719/2000], Avg Val Loss: 2.6118\n",
      "Validation loss improved from 2.6118 to 2.6118. Saving model...\n",
      "\n",
      "LOG: Epoch [720/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0174\n",
      "Epoch [720/2000], Avg Train Loss: 4.0174\n",
      "Epoch [720/2000], Avg Val Loss: 2.6117\n",
      "Validation loss improved from 2.6118 to 2.6117. Saving model...\n",
      "\n",
      "LOG: Epoch [721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9629\n",
      "Epoch [721/2000], Avg Train Loss: 3.9629\n",
      "Epoch [721/2000], Avg Val Loss: 2.6116\n",
      "Validation loss improved from 2.6117 to 2.6116. Saving model...\n",
      "\n",
      "LOG: Epoch [722/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9885\n",
      "Epoch [722/2000], Avg Train Loss: 3.9885\n",
      "Epoch [722/2000], Avg Val Loss: 2.6115\n",
      "Validation loss improved from 2.6116 to 2.6115. Saving model...\n",
      "\n",
      "LOG: Epoch [723/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9999\n",
      "Epoch [723/2000], Avg Train Loss: 3.9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [723/2000], Avg Val Loss: 2.6114\n",
      "Validation loss improved from 2.6115 to 2.6114. Saving model...\n",
      "\n",
      "LOG: Epoch [724/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9547\n",
      "Epoch [724/2000], Avg Train Loss: 3.9547\n",
      "Epoch [724/2000], Avg Val Loss: 2.6113\n",
      "Validation loss improved from 2.6114 to 2.6113. Saving model...\n",
      "\n",
      "LOG: Epoch [725/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9815\n",
      "Epoch [725/2000], Avg Train Loss: 3.9815\n",
      "Epoch [725/2000], Avg Val Loss: 2.6112\n",
      "Validation loss improved from 2.6113 to 2.6112. Saving model...\n",
      "\n",
      "LOG: Epoch [726/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9832\n",
      "Epoch [726/2000], Avg Train Loss: 3.9832\n",
      "Epoch [726/2000], Avg Val Loss: 2.6111\n",
      "Validation loss improved from 2.6112 to 2.6111. Saving model...\n",
      "\n",
      "LOG: Epoch [727/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9977\n",
      "Epoch [727/2000], Avg Train Loss: 3.9977\n",
      "Epoch [727/2000], Avg Val Loss: 2.6110\n",
      "Validation loss improved from 2.6111 to 2.6110. Saving model...\n",
      "\n",
      "LOG: Epoch [728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9739\n",
      "Epoch [728/2000], Avg Train Loss: 3.9739\n",
      "Epoch [728/2000], Avg Val Loss: 2.6109\n",
      "Validation loss improved from 2.6110 to 2.6109. Saving model...\n",
      "\n",
      "LOG: Epoch [729/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9621\n",
      "Epoch [729/2000], Avg Train Loss: 3.9621\n",
      "Epoch [729/2000], Avg Val Loss: 2.6107\n",
      "Validation loss improved from 2.6109 to 2.6107. Saving model...\n",
      "\n",
      "LOG: Epoch [730/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9752\n",
      "Epoch [730/2000], Avg Train Loss: 3.9752\n",
      "Epoch [730/2000], Avg Val Loss: 2.6106\n",
      "Validation loss improved from 2.6107 to 2.6106. Saving model...\n",
      "\n",
      "LOG: Epoch [731/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9411\n",
      "Epoch [731/2000], Avg Train Loss: 3.9411\n",
      "Epoch [731/2000], Avg Val Loss: 2.6104\n",
      "Validation loss improved from 2.6106 to 2.6104. Saving model...\n",
      "\n",
      "LOG: Epoch [732/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0094\n",
      "Epoch [732/2000], Avg Train Loss: 4.0094\n",
      "Epoch [732/2000], Avg Val Loss: 2.6102\n",
      "Validation loss improved from 2.6104 to 2.6102. Saving model...\n",
      "\n",
      "LOG: Epoch [733/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9866\n",
      "Epoch [733/2000], Avg Train Loss: 3.9866\n",
      "Epoch [733/2000], Avg Val Loss: 2.6098\n",
      "Validation loss improved from 2.6102 to 2.6098. Saving model...\n",
      "\n",
      "LOG: Epoch [734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9924\n",
      "Epoch [734/2000], Avg Train Loss: 3.9924\n",
      "Epoch [734/2000], Avg Val Loss: 2.6094\n",
      "Validation loss improved from 2.6098 to 2.6094. Saving model...\n",
      "\n",
      "LOG: Epoch [735/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9265\n",
      "Epoch [735/2000], Avg Train Loss: 3.9265\n",
      "Epoch [735/2000], Avg Val Loss: 2.6090\n",
      "Validation loss improved from 2.6094 to 2.6090. Saving model...\n",
      "\n",
      "LOG: Epoch [736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9757\n",
      "Epoch [736/2000], Avg Train Loss: 3.9757\n",
      "Epoch [736/2000], Avg Val Loss: 2.6085\n",
      "Validation loss improved from 2.6090 to 2.6085. Saving model...\n",
      "\n",
      "LOG: Epoch [737/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9318\n",
      "Epoch [737/2000], Avg Train Loss: 3.9318\n",
      "Epoch [737/2000], Avg Val Loss: 2.6080\n",
      "Validation loss improved from 2.6085 to 2.6080. Saving model...\n",
      "\n",
      "LOG: Epoch [738/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9731\n",
      "Epoch [738/2000], Avg Train Loss: 3.9731\n",
      "Epoch [738/2000], Avg Val Loss: 2.6076\n",
      "Validation loss improved from 2.6080 to 2.6076. Saving model...\n",
      "\n",
      "LOG: Epoch [739/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9661\n",
      "Epoch [739/2000], Avg Train Loss: 3.9661\n",
      "Epoch [739/2000], Avg Val Loss: 2.6072\n",
      "Validation loss improved from 2.6076 to 2.6072. Saving model...\n",
      "\n",
      "LOG: Epoch [740/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9426\n",
      "Epoch [740/2000], Avg Train Loss: 3.9426\n",
      "Epoch [740/2000], Avg Val Loss: 2.6068\n",
      "Validation loss improved from 2.6072 to 2.6068. Saving model...\n",
      "\n",
      "LOG: Epoch [741/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9708\n",
      "Epoch [741/2000], Avg Train Loss: 3.9708\n",
      "Epoch [741/2000], Avg Val Loss: 2.6064\n",
      "Validation loss improved from 2.6068 to 2.6064. Saving model...\n",
      "\n",
      "LOG: Epoch [742/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9664\n",
      "Epoch [742/2000], Avg Train Loss: 3.9664\n",
      "Epoch [742/2000], Avg Val Loss: 2.6060\n",
      "Validation loss improved from 2.6064 to 2.6060. Saving model...\n",
      "\n",
      "LOG: Epoch [743/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9531\n",
      "Epoch [743/2000], Avg Train Loss: 3.9531\n",
      "Epoch [743/2000], Avg Val Loss: 2.6055\n",
      "Validation loss improved from 2.6060 to 2.6055. Saving model...\n",
      "\n",
      "LOG: Epoch [744/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0007\n",
      "Epoch [744/2000], Avg Train Loss: 4.0007\n",
      "Epoch [744/2000], Avg Val Loss: 2.6051\n",
      "Validation loss improved from 2.6055 to 2.6051. Saving model...\n",
      "\n",
      "LOG: Epoch [745/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9210\n",
      "Epoch [745/2000], Avg Train Loss: 3.9210\n",
      "Epoch [745/2000], Avg Val Loss: 2.6047\n",
      "Validation loss improved from 2.6051 to 2.6047. Saving model...\n",
      "\n",
      "LOG: Epoch [746/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0125\n",
      "Epoch [746/2000], Avg Train Loss: 4.0125\n",
      "Epoch [746/2000], Avg Val Loss: 2.6042\n",
      "Validation loss improved from 2.6047 to 2.6042. Saving model...\n",
      "\n",
      "LOG: Epoch [747/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9574\n",
      "Epoch [747/2000], Avg Train Loss: 3.9574\n",
      "Epoch [747/2000], Avg Val Loss: 2.6037\n",
      "Validation loss improved from 2.6042 to 2.6037. Saving model...\n",
      "\n",
      "LOG: Epoch [748/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9940\n",
      "Epoch [748/2000], Avg Train Loss: 3.9940\n",
      "Epoch [748/2000], Avg Val Loss: 2.6033\n",
      "Validation loss improved from 2.6037 to 2.6033. Saving model...\n",
      "\n",
      "LOG: Epoch [749/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9752\n",
      "Epoch [749/2000], Avg Train Loss: 3.9752\n",
      "Epoch [749/2000], Avg Val Loss: 2.6028\n",
      "Validation loss improved from 2.6033 to 2.6028. Saving model...\n",
      "\n",
      "LOG: Epoch [750/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9403\n",
      "Epoch [750/2000], Avg Train Loss: 3.9403\n",
      "Epoch [750/2000], Avg Val Loss: 2.6023\n",
      "Validation loss improved from 2.6028 to 2.6023. Saving model...\n",
      "\n",
      "LOG: Epoch [751/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9140\n",
      "Epoch [751/2000], Avg Train Loss: 3.9140\n",
      "Epoch [751/2000], Avg Val Loss: 2.6018\n",
      "Validation loss improved from 2.6023 to 2.6018. Saving model...\n",
      "\n",
      "LOG: Epoch [752/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9603\n",
      "Epoch [752/2000], Avg Train Loss: 3.9603\n",
      "Epoch [752/2000], Avg Val Loss: 2.6013\n",
      "Validation loss improved from 2.6018 to 2.6013. Saving model...\n",
      "\n",
      "LOG: Epoch [753/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9376\n",
      "Epoch [753/2000], Avg Train Loss: 3.9376\n",
      "Epoch [753/2000], Avg Val Loss: 2.6009\n",
      "Validation loss improved from 2.6013 to 2.6009. Saving model...\n",
      "\n",
      "LOG: Epoch [754/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9567\n",
      "Epoch [754/2000], Avg Train Loss: 3.9567\n",
      "Epoch [754/2000], Avg Val Loss: 2.6004\n",
      "Validation loss improved from 2.6009 to 2.6004. Saving model...\n",
      "\n",
      "LOG: Epoch [755/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9610\n",
      "Epoch [755/2000], Avg Train Loss: 3.9610\n",
      "Epoch [755/2000], Avg Val Loss: 2.6000\n",
      "Validation loss improved from 2.6004 to 2.6000. Saving model...\n",
      "\n",
      "LOG: Epoch [756/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9353\n",
      "Epoch [756/2000], Avg Train Loss: 3.9353\n",
      "Epoch [756/2000], Avg Val Loss: 2.5996\n",
      "Validation loss improved from 2.6000 to 2.5996. Saving model...\n",
      "\n",
      "LOG: Epoch [757/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9695\n",
      "Epoch [757/2000], Avg Train Loss: 3.9695\n",
      "Epoch [757/2000], Avg Val Loss: 2.5992\n",
      "Validation loss improved from 2.5996 to 2.5992. Saving model...\n",
      "\n",
      "LOG: Epoch [758/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9535\n",
      "Epoch [758/2000], Avg Train Loss: 3.9535\n",
      "Epoch [758/2000], Avg Val Loss: 2.5988\n",
      "Validation loss improved from 2.5992 to 2.5988. Saving model...\n",
      "\n",
      "LOG: Epoch [759/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9099\n",
      "Epoch [759/2000], Avg Train Loss: 3.9099\n",
      "Epoch [759/2000], Avg Val Loss: 2.5983\n",
      "Validation loss improved from 2.5988 to 2.5983. Saving model...\n",
      "\n",
      "LOG: Epoch [760/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9195\n",
      "Epoch [760/2000], Avg Train Loss: 3.9195\n",
      "Epoch [760/2000], Avg Val Loss: 2.5979\n",
      "Validation loss improved from 2.5983 to 2.5979. Saving model...\n",
      "\n",
      "LOG: Epoch [761/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9214\n",
      "Epoch [761/2000], Avg Train Loss: 3.9214\n",
      "Epoch [761/2000], Avg Val Loss: 2.5975\n",
      "Validation loss improved from 2.5979 to 2.5975. Saving model...\n",
      "\n",
      "LOG: Epoch [762/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9708\n",
      "Epoch [762/2000], Avg Train Loss: 3.9708\n",
      "Epoch [762/2000], Avg Val Loss: 2.5970\n",
      "Validation loss improved from 2.5975 to 2.5970. Saving model...\n",
      "\n",
      "LOG: Epoch [763/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9208\n",
      "Epoch [763/2000], Avg Train Loss: 3.9208\n",
      "Epoch [763/2000], Avg Val Loss: 2.5966\n",
      "Validation loss improved from 2.5970 to 2.5966. Saving model...\n",
      "\n",
      "LOG: Epoch [764/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9385\n",
      "Epoch [764/2000], Avg Train Loss: 3.9385\n",
      "Epoch [764/2000], Avg Val Loss: 2.5962\n",
      "Validation loss improved from 2.5966 to 2.5962. Saving model...\n",
      "\n",
      "LOG: Epoch [765/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8806\n",
      "Epoch [765/2000], Avg Train Loss: 3.8806\n",
      "Epoch [765/2000], Avg Val Loss: 2.5958\n",
      "Validation loss improved from 2.5962 to 2.5958. Saving model...\n",
      "\n",
      "LOG: Epoch [766/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8789\n",
      "Epoch [766/2000], Avg Train Loss: 3.8789\n",
      "Epoch [766/2000], Avg Val Loss: 2.5955\n",
      "Validation loss improved from 2.5958 to 2.5955. Saving model...\n",
      "\n",
      "LOG: Epoch [767/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9619\n",
      "Epoch [767/2000], Avg Train Loss: 3.9619\n",
      "Epoch [767/2000], Avg Val Loss: 2.5952\n",
      "Validation loss improved from 2.5955 to 2.5952. Saving model...\n",
      "\n",
      "LOG: Epoch [768/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9582\n",
      "Epoch [768/2000], Avg Train Loss: 3.9582\n",
      "Epoch [768/2000], Avg Val Loss: 2.5949\n",
      "Validation loss improved from 2.5952 to 2.5949. Saving model...\n",
      "\n",
      "LOG: Epoch [769/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9275\n",
      "Epoch [769/2000], Avg Train Loss: 3.9275\n",
      "Epoch [769/2000], Avg Val Loss: 2.5947\n",
      "Validation loss improved from 2.5949 to 2.5947. Saving model...\n",
      "\n",
      "LOG: Epoch [770/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9342\n",
      "Epoch [770/2000], Avg Train Loss: 3.9342\n",
      "Epoch [770/2000], Avg Val Loss: 2.5945\n",
      "Validation loss improved from 2.5947 to 2.5945. Saving model...\n",
      "\n",
      "LOG: Epoch [771/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9689\n",
      "Epoch [771/2000], Avg Train Loss: 3.9689\n",
      "Epoch [771/2000], Avg Val Loss: 2.5944\n",
      "Validation loss improved from 2.5945 to 2.5944. Saving model...\n",
      "\n",
      "LOG: Epoch [772/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9319\n",
      "Epoch [772/2000], Avg Train Loss: 3.9319\n",
      "Epoch [772/2000], Avg Val Loss: 2.5942\n",
      "Validation loss improved from 2.5944 to 2.5942. Saving model...\n",
      "\n",
      "LOG: Epoch [773/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8994\n",
      "Epoch [773/2000], Avg Train Loss: 3.8994\n",
      "Epoch [773/2000], Avg Val Loss: 2.5940\n",
      "Validation loss improved from 2.5942 to 2.5940. Saving model...\n",
      "\n",
      "LOG: Epoch [774/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9182\n",
      "Epoch [774/2000], Avg Train Loss: 3.9182\n",
      "Epoch [774/2000], Avg Val Loss: 2.5938\n",
      "Validation loss improved from 2.5940 to 2.5938. Saving model...\n",
      "\n",
      "LOG: Epoch [775/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8961\n",
      "Epoch [775/2000], Avg Train Loss: 3.8961\n",
      "Epoch [775/2000], Avg Val Loss: 2.5937\n",
      "Validation loss improved from 2.5938 to 2.5937. Saving model...\n",
      "\n",
      "LOG: Epoch [776/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9668\n",
      "Epoch [776/2000], Avg Train Loss: 3.9668\n",
      "Epoch [776/2000], Avg Val Loss: 2.5934\n",
      "Validation loss improved from 2.5937 to 2.5934. Saving model...\n",
      "\n",
      "LOG: Epoch [777/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9110\n",
      "Epoch [777/2000], Avg Train Loss: 3.9110\n",
      "Epoch [777/2000], Avg Val Loss: 2.5931\n",
      "Validation loss improved from 2.5934 to 2.5931. Saving model...\n",
      "\n",
      "LOG: Epoch [778/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9282\n",
      "Epoch [778/2000], Avg Train Loss: 3.9282\n",
      "Epoch [778/2000], Avg Val Loss: 2.5928\n",
      "Validation loss improved from 2.5931 to 2.5928. Saving model...\n",
      "\n",
      "LOG: Epoch [779/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9458\n",
      "Epoch [779/2000], Avg Train Loss: 3.9458\n",
      "Epoch [779/2000], Avg Val Loss: 2.5925\n",
      "Validation loss improved from 2.5928 to 2.5925. Saving model...\n",
      "\n",
      "LOG: Epoch [780/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9122\n",
      "Epoch [780/2000], Avg Train Loss: 3.9122\n",
      "Epoch [780/2000], Avg Val Loss: 2.5921\n",
      "Validation loss improved from 2.5925 to 2.5921. Saving model...\n",
      "\n",
      "LOG: Epoch [781/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9444\n",
      "Epoch [781/2000], Avg Train Loss: 3.9444\n",
      "Epoch [781/2000], Avg Val Loss: 2.5917\n",
      "Validation loss improved from 2.5921 to 2.5917. Saving model...\n",
      "\n",
      "LOG: Epoch [782/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9292\n",
      "Epoch [782/2000], Avg Train Loss: 3.9292\n",
      "Epoch [782/2000], Avg Val Loss: 2.5914\n",
      "Validation loss improved from 2.5917 to 2.5914. Saving model...\n",
      "\n",
      "LOG: Epoch [783/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9086\n",
      "Epoch [783/2000], Avg Train Loss: 3.9086\n",
      "Epoch [783/2000], Avg Val Loss: 2.5911\n",
      "Validation loss improved from 2.5914 to 2.5911. Saving model...\n",
      "\n",
      "LOG: Epoch [784/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9140\n",
      "Epoch [784/2000], Avg Train Loss: 3.9140\n",
      "Epoch [784/2000], Avg Val Loss: 2.5908\n",
      "Validation loss improved from 2.5911 to 2.5908. Saving model...\n",
      "\n",
      "LOG: Epoch [785/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9214\n",
      "Epoch [785/2000], Avg Train Loss: 3.9214\n",
      "Epoch [785/2000], Avg Val Loss: 2.5905\n",
      "Validation loss improved from 2.5908 to 2.5905. Saving model...\n",
      "\n",
      "LOG: Epoch [786/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9482\n",
      "Epoch [786/2000], Avg Train Loss: 3.9482\n",
      "Epoch [786/2000], Avg Val Loss: 2.5903\n",
      "Validation loss improved from 2.5905 to 2.5903. Saving model...\n",
      "\n",
      "LOG: Epoch [787/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9217\n",
      "Epoch [787/2000], Avg Train Loss: 3.9217\n",
      "Epoch [787/2000], Avg Val Loss: 2.5900\n",
      "Validation loss improved from 2.5903 to 2.5900. Saving model...\n",
      "\n",
      "LOG: Epoch [788/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9129\n",
      "Epoch [788/2000], Avg Train Loss: 3.9129\n",
      "Epoch [788/2000], Avg Val Loss: 2.5897\n",
      "Validation loss improved from 2.5900 to 2.5897. Saving model...\n",
      "\n",
      "LOG: Epoch [789/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9392\n",
      "Epoch [789/2000], Avg Train Loss: 3.9392\n",
      "Epoch [789/2000], Avg Val Loss: 2.5895\n",
      "Validation loss improved from 2.5897 to 2.5895. Saving model...\n",
      "\n",
      "LOG: Epoch [790/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9054\n",
      "Epoch [790/2000], Avg Train Loss: 3.9054\n",
      "Epoch [790/2000], Avg Val Loss: 2.5894\n",
      "Validation loss improved from 2.5895 to 2.5894. Saving model...\n",
      "\n",
      "LOG: Epoch [791/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9619\n",
      "Epoch [791/2000], Avg Train Loss: 3.9619\n",
      "Epoch [791/2000], Avg Val Loss: 2.5893\n",
      "Validation loss improved from 2.5894 to 2.5893. Saving model...\n",
      "\n",
      "LOG: Epoch [792/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9032\n",
      "Epoch [792/2000], Avg Train Loss: 3.9032\n",
      "Epoch [792/2000], Avg Val Loss: 2.5892\n",
      "Validation loss improved from 2.5893 to 2.5892. Saving model...\n",
      "\n",
      "LOG: Epoch [793/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8832\n",
      "Epoch [793/2000], Avg Train Loss: 3.8832\n",
      "Epoch [793/2000], Avg Val Loss: 2.5891\n",
      "Validation loss improved from 2.5892 to 2.5891. Saving model...\n",
      "\n",
      "LOG: Epoch [794/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9368\n",
      "Epoch [794/2000], Avg Train Loss: 3.9368\n",
      "Epoch [794/2000], Avg Val Loss: 2.5889\n",
      "Validation loss improved from 2.5891 to 2.5889. Saving model...\n",
      "\n",
      "LOG: Epoch [795/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8989\n",
      "Epoch [795/2000], Avg Train Loss: 3.8989\n",
      "Epoch [795/2000], Avg Val Loss: 2.5888\n",
      "Validation loss improved from 2.5889 to 2.5888. Saving model...\n",
      "\n",
      "LOG: Epoch [796/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9223\n",
      "Epoch [796/2000], Avg Train Loss: 3.9223\n",
      "Epoch [796/2000], Avg Val Loss: 2.5886\n",
      "Validation loss improved from 2.5888 to 2.5886. Saving model...\n",
      "\n",
      "LOG: Epoch [797/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9009\n",
      "Epoch [797/2000], Avg Train Loss: 3.9009\n",
      "Epoch [797/2000], Avg Val Loss: 2.5884\n",
      "Validation loss improved from 2.5886 to 2.5884. Saving model...\n",
      "\n",
      "LOG: Epoch [798/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9198\n",
      "Epoch [798/2000], Avg Train Loss: 3.9198\n",
      "Epoch [798/2000], Avg Val Loss: 2.5882\n",
      "Validation loss improved from 2.5884 to 2.5882. Saving model...\n",
      "\n",
      "LOG: Epoch [799/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9087\n",
      "Epoch [799/2000], Avg Train Loss: 3.9087\n",
      "Epoch [799/2000], Avg Val Loss: 2.5880\n",
      "Validation loss improved from 2.5882 to 2.5880. Saving model...\n",
      "\n",
      "LOG: Epoch [800/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8811\n",
      "Epoch [800/2000], Avg Train Loss: 3.8811\n",
      "Epoch [800/2000], Avg Val Loss: 2.5878\n",
      "Validation loss improved from 2.5880 to 2.5878. Saving model...\n",
      "\n",
      "LOG: Epoch [801/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9259\n",
      "Epoch [801/2000], Avg Train Loss: 3.9259\n",
      "Epoch [801/2000], Avg Val Loss: 2.5875\n",
      "Validation loss improved from 2.5878 to 2.5875. Saving model...\n",
      "\n",
      "LOG: Epoch [802/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9114\n",
      "Epoch [802/2000], Avg Train Loss: 3.9114\n",
      "Epoch [802/2000], Avg Val Loss: 2.5873\n",
      "Validation loss improved from 2.5875 to 2.5873. Saving model...\n",
      "\n",
      "LOG: Epoch [803/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8820\n",
      "Epoch [803/2000], Avg Train Loss: 3.8820\n",
      "Epoch [803/2000], Avg Val Loss: 2.5870\n",
      "Validation loss improved from 2.5873 to 2.5870. Saving model...\n",
      "\n",
      "LOG: Epoch [804/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8950\n",
      "Epoch [804/2000], Avg Train Loss: 3.8950\n",
      "Epoch [804/2000], Avg Val Loss: 2.5867\n",
      "Validation loss improved from 2.5870 to 2.5867. Saving model...\n",
      "\n",
      "LOG: Epoch [805/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9027\n",
      "Epoch [805/2000], Avg Train Loss: 3.9027\n",
      "Epoch [805/2000], Avg Val Loss: 2.5864\n",
      "Validation loss improved from 2.5867 to 2.5864. Saving model...\n",
      "\n",
      "LOG: Epoch [806/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9231\n",
      "Epoch [806/2000], Avg Train Loss: 3.9231\n",
      "Epoch [806/2000], Avg Val Loss: 2.5861\n",
      "Validation loss improved from 2.5864 to 2.5861. Saving model...\n",
      "\n",
      "LOG: Epoch [807/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9361\n",
      "Epoch [807/2000], Avg Train Loss: 3.9361\n",
      "Epoch [807/2000], Avg Val Loss: 2.5857\n",
      "Validation loss improved from 2.5861 to 2.5857. Saving model...\n",
      "\n",
      "LOG: Epoch [808/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9715\n",
      "Epoch [808/2000], Avg Train Loss: 3.9715\n",
      "Epoch [808/2000], Avg Val Loss: 2.5853\n",
      "Validation loss improved from 2.5857 to 2.5853. Saving model...\n",
      "\n",
      "LOG: Epoch [809/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8773\n",
      "Epoch [809/2000], Avg Train Loss: 3.8773\n",
      "Epoch [809/2000], Avg Val Loss: 2.5850\n",
      "Validation loss improved from 2.5853 to 2.5850. Saving model...\n",
      "\n",
      "LOG: Epoch [810/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8721\n",
      "Epoch [810/2000], Avg Train Loss: 3.8721\n",
      "Epoch [810/2000], Avg Val Loss: 2.5846\n",
      "Validation loss improved from 2.5850 to 2.5846. Saving model...\n",
      "\n",
      "LOG: Epoch [811/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8942\n",
      "Epoch [811/2000], Avg Train Loss: 3.8942\n",
      "Epoch [811/2000], Avg Val Loss: 2.5843\n",
      "Validation loss improved from 2.5846 to 2.5843. Saving model...\n",
      "\n",
      "LOG: Epoch [812/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9171\n",
      "Epoch [812/2000], Avg Train Loss: 3.9171\n",
      "Epoch [812/2000], Avg Val Loss: 2.5840\n",
      "Validation loss improved from 2.5843 to 2.5840. Saving model...\n",
      "\n",
      "LOG: Epoch [813/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8934\n",
      "Epoch [813/2000], Avg Train Loss: 3.8934\n",
      "Epoch [813/2000], Avg Val Loss: 2.5836\n",
      "Validation loss improved from 2.5840 to 2.5836. Saving model...\n",
      "\n",
      "LOG: Epoch [814/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8828\n",
      "Epoch [814/2000], Avg Train Loss: 3.8828\n",
      "Epoch [814/2000], Avg Val Loss: 2.5833\n",
      "Validation loss improved from 2.5836 to 2.5833. Saving model...\n",
      "\n",
      "LOG: Epoch [815/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8551\n",
      "Epoch [815/2000], Avg Train Loss: 3.8551\n",
      "Epoch [815/2000], Avg Val Loss: 2.5829\n",
      "Validation loss improved from 2.5833 to 2.5829. Saving model...\n",
      "\n",
      "LOG: Epoch [816/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9385\n",
      "Epoch [816/2000], Avg Train Loss: 3.9385\n",
      "Epoch [816/2000], Avg Val Loss: 2.5826\n",
      "Validation loss improved from 2.5829 to 2.5826. Saving model...\n",
      "\n",
      "LOG: Epoch [817/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9090\n",
      "Epoch [817/2000], Avg Train Loss: 3.9090\n",
      "Epoch [817/2000], Avg Val Loss: 2.5823\n",
      "Validation loss improved from 2.5826 to 2.5823. Saving model...\n",
      "\n",
      "LOG: Epoch [818/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8879\n",
      "Epoch [818/2000], Avg Train Loss: 3.8879\n",
      "Epoch [818/2000], Avg Val Loss: 2.5819\n",
      "Validation loss improved from 2.5823 to 2.5819. Saving model...\n",
      "\n",
      "LOG: Epoch [819/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9319\n",
      "Epoch [819/2000], Avg Train Loss: 3.9319\n",
      "Epoch [819/2000], Avg Val Loss: 2.5817\n",
      "Validation loss improved from 2.5819 to 2.5817. Saving model...\n",
      "\n",
      "LOG: Epoch [820/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9112\n",
      "Epoch [820/2000], Avg Train Loss: 3.9112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [820/2000], Avg Val Loss: 2.5814\n",
      "Validation loss improved from 2.5817 to 2.5814. Saving model...\n",
      "\n",
      "LOG: Epoch [821/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9081\n",
      "Epoch [821/2000], Avg Train Loss: 3.9081\n",
      "Epoch [821/2000], Avg Val Loss: 2.5810\n",
      "Validation loss improved from 2.5814 to 2.5810. Saving model...\n",
      "\n",
      "LOG: Epoch [822/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9446\n",
      "Epoch [822/2000], Avg Train Loss: 3.9446\n",
      "Epoch [822/2000], Avg Val Loss: 2.5808\n",
      "Validation loss improved from 2.5810 to 2.5808. Saving model...\n",
      "\n",
      "LOG: Epoch [823/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9093\n",
      "Epoch [823/2000], Avg Train Loss: 3.9093\n",
      "Epoch [823/2000], Avg Val Loss: 2.5805\n",
      "Validation loss improved from 2.5808 to 2.5805. Saving model...\n",
      "\n",
      "LOG: Epoch [824/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8883\n",
      "Epoch [824/2000], Avg Train Loss: 3.8883\n",
      "Epoch [824/2000], Avg Val Loss: 2.5802\n",
      "Validation loss improved from 2.5805 to 2.5802. Saving model...\n",
      "\n",
      "LOG: Epoch [825/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8788\n",
      "Epoch [825/2000], Avg Train Loss: 3.8788\n",
      "Epoch [825/2000], Avg Val Loss: 2.5799\n",
      "Validation loss improved from 2.5802 to 2.5799. Saving model...\n",
      "\n",
      "LOG: Epoch [826/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8831\n",
      "Epoch [826/2000], Avg Train Loss: 3.8831\n",
      "Epoch [826/2000], Avg Val Loss: 2.5797\n",
      "Validation loss improved from 2.5799 to 2.5797. Saving model...\n",
      "\n",
      "LOG: Epoch [827/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8807\n",
      "Epoch [827/2000], Avg Train Loss: 3.8807\n",
      "Epoch [827/2000], Avg Val Loss: 2.5794\n",
      "Validation loss improved from 2.5797 to 2.5794. Saving model...\n",
      "\n",
      "LOG: Epoch [828/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9179\n",
      "Epoch [828/2000], Avg Train Loss: 3.9179\n",
      "Epoch [828/2000], Avg Val Loss: 2.5791\n",
      "Validation loss improved from 2.5794 to 2.5791. Saving model...\n",
      "\n",
      "LOG: Epoch [829/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9394\n",
      "Epoch [829/2000], Avg Train Loss: 3.9394\n",
      "Epoch [829/2000], Avg Val Loss: 2.5788\n",
      "Validation loss improved from 2.5791 to 2.5788. Saving model...\n",
      "\n",
      "LOG: Epoch [830/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8785\n",
      "Epoch [830/2000], Avg Train Loss: 3.8785\n",
      "Epoch [830/2000], Avg Val Loss: 2.5787\n",
      "Validation loss improved from 2.5788 to 2.5787. Saving model...\n",
      "\n",
      "LOG: Epoch [831/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8766\n",
      "Epoch [831/2000], Avg Train Loss: 3.8766\n",
      "Epoch [831/2000], Avg Val Loss: 2.5785\n",
      "Validation loss improved from 2.5787 to 2.5785. Saving model...\n",
      "\n",
      "LOG: Epoch [832/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9088\n",
      "Epoch [832/2000], Avg Train Loss: 3.9088\n",
      "Epoch [832/2000], Avg Val Loss: 2.5784\n",
      "Validation loss improved from 2.5785 to 2.5784. Saving model...\n",
      "\n",
      "LOG: Epoch [833/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8755\n",
      "Epoch [833/2000], Avg Train Loss: 3.8755\n",
      "Epoch [833/2000], Avg Val Loss: 2.5782\n",
      "Validation loss improved from 2.5784 to 2.5782. Saving model...\n",
      "\n",
      "LOG: Epoch [834/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8979\n",
      "Epoch [834/2000], Avg Train Loss: 3.8979\n",
      "Epoch [834/2000], Avg Val Loss: 2.5780\n",
      "Validation loss improved from 2.5782 to 2.5780. Saving model...\n",
      "\n",
      "LOG: Epoch [835/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8726\n",
      "Epoch [835/2000], Avg Train Loss: 3.8726\n",
      "Epoch [835/2000], Avg Val Loss: 2.5778\n",
      "Validation loss improved from 2.5780 to 2.5778. Saving model...\n",
      "\n",
      "LOG: Epoch [836/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9292\n",
      "Epoch [836/2000], Avg Train Loss: 3.9292\n",
      "Epoch [836/2000], Avg Val Loss: 2.5777\n",
      "Validation loss improved from 2.5778 to 2.5777. Saving model...\n",
      "\n",
      "LOG: Epoch [837/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8742\n",
      "Epoch [837/2000], Avg Train Loss: 3.8742\n",
      "Epoch [837/2000], Avg Val Loss: 2.5775\n",
      "Validation loss improved from 2.5777 to 2.5775. Saving model...\n",
      "\n",
      "LOG: Epoch [838/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8859\n",
      "Epoch [838/2000], Avg Train Loss: 3.8859\n",
      "Epoch [838/2000], Avg Val Loss: 2.5774\n",
      "Validation loss improved from 2.5775 to 2.5774. Saving model...\n",
      "\n",
      "LOG: Epoch [839/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8579\n",
      "Epoch [839/2000], Avg Train Loss: 3.8579\n",
      "Epoch [839/2000], Avg Val Loss: 2.5771\n",
      "Validation loss improved from 2.5774 to 2.5771. Saving model...\n",
      "\n",
      "LOG: Epoch [840/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8684\n",
      "Epoch [840/2000], Avg Train Loss: 3.8684\n",
      "Epoch [840/2000], Avg Val Loss: 2.5769\n",
      "Validation loss improved from 2.5771 to 2.5769. Saving model...\n",
      "\n",
      "LOG: Epoch [841/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8612\n",
      "Epoch [841/2000], Avg Train Loss: 3.8612\n",
      "Epoch [841/2000], Avg Val Loss: 2.5767\n",
      "Validation loss improved from 2.5769 to 2.5767. Saving model...\n",
      "\n",
      "LOG: Epoch [842/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8799\n",
      "Epoch [842/2000], Avg Train Loss: 3.8799\n",
      "Epoch [842/2000], Avg Val Loss: 2.5764\n",
      "Validation loss improved from 2.5767 to 2.5764. Saving model...\n",
      "\n",
      "LOG: Epoch [843/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9173\n",
      "Epoch [843/2000], Avg Train Loss: 3.9173\n",
      "Epoch [843/2000], Avg Val Loss: 2.5762\n",
      "Validation loss improved from 2.5764 to 2.5762. Saving model...\n",
      "\n",
      "LOG: Epoch [844/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8843\n",
      "Epoch [844/2000], Avg Train Loss: 3.8843\n",
      "Epoch [844/2000], Avg Val Loss: 2.5759\n",
      "Validation loss improved from 2.5762 to 2.5759. Saving model...\n",
      "\n",
      "LOG: Epoch [845/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9246\n",
      "Epoch [845/2000], Avg Train Loss: 3.9246\n",
      "Epoch [845/2000], Avg Val Loss: 2.5757\n",
      "Validation loss improved from 2.5759 to 2.5757. Saving model...\n",
      "\n",
      "LOG: Epoch [846/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9067\n",
      "Epoch [846/2000], Avg Train Loss: 3.9067\n",
      "Epoch [846/2000], Avg Val Loss: 2.5756\n",
      "Validation loss improved from 2.5757 to 2.5756. Saving model...\n",
      "\n",
      "LOG: Epoch [847/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8462\n",
      "Epoch [847/2000], Avg Train Loss: 3.8462\n",
      "Epoch [847/2000], Avg Val Loss: 2.5755\n",
      "Validation loss improved from 2.5756 to 2.5755. Saving model...\n",
      "\n",
      "LOG: Epoch [848/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8691\n",
      "Epoch [848/2000], Avg Train Loss: 3.8691\n",
      "Epoch [848/2000], Avg Val Loss: 2.5754\n",
      "Validation loss improved from 2.5755 to 2.5754. Saving model...\n",
      "\n",
      "LOG: Epoch [849/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9416\n",
      "Epoch [849/2000], Avg Train Loss: 3.9416\n",
      "Epoch [849/2000], Avg Val Loss: 2.5753\n",
      "Validation loss improved from 2.5754 to 2.5753. Saving model...\n",
      "\n",
      "LOG: Epoch [850/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8629\n",
      "Epoch [850/2000], Avg Train Loss: 3.8629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [850/2000], Avg Val Loss: 2.5752\n",
      "Validation loss improved from 2.5753 to 2.5752. Saving model...\n",
      "\n",
      "LOG: Epoch [851/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8607\n",
      "Epoch [851/2000], Avg Train Loss: 3.8607\n",
      "Epoch [851/2000], Avg Val Loss: 2.5751\n",
      "Validation loss improved from 2.5752 to 2.5751. Saving model...\n",
      "\n",
      "LOG: Epoch [852/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8544\n",
      "Epoch [852/2000], Avg Train Loss: 3.8544\n",
      "Epoch [852/2000], Avg Val Loss: 2.5750\n",
      "Validation loss improved from 2.5751 to 2.5750. Saving model...\n",
      "\n",
      "LOG: Epoch [853/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8941\n",
      "Epoch [853/2000], Avg Train Loss: 3.8941\n",
      "Epoch [853/2000], Avg Val Loss: 2.5749\n",
      "Validation loss improved from 2.5750 to 2.5749. Saving model...\n",
      "\n",
      "LOG: Epoch [854/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8490\n",
      "Epoch [854/2000], Avg Train Loss: 3.8490\n",
      "Epoch [854/2000], Avg Val Loss: 2.5748\n",
      "Validation loss improved from 2.5749 to 2.5748. Saving model...\n",
      "\n",
      "LOG: Epoch [855/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8567\n",
      "Epoch [855/2000], Avg Train Loss: 3.8567\n",
      "Epoch [855/2000], Avg Val Loss: 2.5746\n",
      "Validation loss improved from 2.5748 to 2.5746. Saving model...\n",
      "\n",
      "LOG: Epoch [856/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8607\n",
      "Epoch [856/2000], Avg Train Loss: 3.8607\n",
      "Epoch [856/2000], Avg Val Loss: 2.5744\n",
      "Validation loss improved from 2.5746 to 2.5744. Saving model...\n",
      "\n",
      "LOG: Epoch [857/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8721\n",
      "Epoch [857/2000], Avg Train Loss: 3.8721\n",
      "Epoch [857/2000], Avg Val Loss: 2.5742\n",
      "Validation loss improved from 2.5744 to 2.5742. Saving model...\n",
      "\n",
      "LOG: Epoch [858/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8714\n",
      "Epoch [858/2000], Avg Train Loss: 3.8714\n",
      "Epoch [858/2000], Avg Val Loss: 2.5740\n",
      "Validation loss improved from 2.5742 to 2.5740. Saving model...\n",
      "\n",
      "LOG: Epoch [859/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8611\n",
      "Epoch [859/2000], Avg Train Loss: 3.8611\n",
      "Epoch [859/2000], Avg Val Loss: 2.5739\n",
      "Validation loss improved from 2.5740 to 2.5739. Saving model...\n",
      "\n",
      "LOG: Epoch [860/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8690\n",
      "Epoch [860/2000], Avg Train Loss: 3.8690\n",
      "Epoch [860/2000], Avg Val Loss: 2.5736\n",
      "Validation loss improved from 2.5739 to 2.5736. Saving model...\n",
      "\n",
      "LOG: Epoch [861/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8547\n",
      "Epoch [861/2000], Avg Train Loss: 3.8547\n",
      "Epoch [861/2000], Avg Val Loss: 2.5735\n",
      "Validation loss improved from 2.5736 to 2.5735. Saving model...\n",
      "\n",
      "LOG: Epoch [862/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9013\n",
      "Epoch [862/2000], Avg Train Loss: 3.9013\n",
      "Epoch [862/2000], Avg Val Loss: 2.5732\n",
      "Validation loss improved from 2.5735 to 2.5732. Saving model...\n",
      "\n",
      "LOG: Epoch [863/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8459\n",
      "Epoch [863/2000], Avg Train Loss: 3.8459\n",
      "Epoch [863/2000], Avg Val Loss: 2.5730\n",
      "Validation loss improved from 2.5732 to 2.5730. Saving model...\n",
      "\n",
      "LOG: Epoch [864/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8306\n",
      "Epoch [864/2000], Avg Train Loss: 3.8306\n",
      "Epoch [864/2000], Avg Val Loss: 2.5728\n",
      "Validation loss improved from 2.5730 to 2.5728. Saving model...\n",
      "\n",
      "LOG: Epoch [865/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8688\n",
      "Epoch [865/2000], Avg Train Loss: 3.8688\n",
      "Epoch [865/2000], Avg Val Loss: 2.5725\n",
      "Validation loss improved from 2.5728 to 2.5725. Saving model...\n",
      "\n",
      "LOG: Epoch [866/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8345\n",
      "Epoch [866/2000], Avg Train Loss: 3.8345\n",
      "Epoch [866/2000], Avg Val Loss: 2.5723\n",
      "Validation loss improved from 2.5725 to 2.5723. Saving model...\n",
      "\n",
      "LOG: Epoch [867/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8206\n",
      "Epoch [867/2000], Avg Train Loss: 3.8206\n",
      "Epoch [867/2000], Avg Val Loss: 2.5722\n",
      "Validation loss improved from 2.5723 to 2.5722. Saving model...\n",
      "\n",
      "LOG: Epoch [868/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8670\n",
      "Epoch [868/2000], Avg Train Loss: 3.8670\n",
      "Epoch [868/2000], Avg Val Loss: 2.5721\n",
      "Validation loss improved from 2.5722 to 2.5721. Saving model...\n",
      "\n",
      "LOG: Epoch [869/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8747\n",
      "Epoch [869/2000], Avg Train Loss: 3.8747\n",
      "Epoch [869/2000], Avg Val Loss: 2.5721\n",
      "Validation loss improved from 2.5721 to 2.5721. Saving model...\n",
      "\n",
      "LOG: Epoch [870/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8682\n",
      "Epoch [870/2000], Avg Train Loss: 3.8682\n",
      "Epoch [870/2000], Avg Val Loss: 2.5720\n",
      "Validation loss improved from 2.5721 to 2.5720. Saving model...\n",
      "\n",
      "LOG: Epoch [871/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8633\n",
      "Epoch [871/2000], Avg Train Loss: 3.8633\n",
      "Epoch [871/2000], Avg Val Loss: 2.5719\n",
      "Validation loss improved from 2.5720 to 2.5719. Saving model...\n",
      "\n",
      "LOG: Epoch [872/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8481\n",
      "Epoch [872/2000], Avg Train Loss: 3.8481\n",
      "Epoch [872/2000], Avg Val Loss: 2.5718\n",
      "Validation loss improved from 2.5719 to 2.5718. Saving model...\n",
      "\n",
      "LOG: Epoch [873/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8822\n",
      "Epoch [873/2000], Avg Train Loss: 3.8822\n",
      "Epoch [873/2000], Avg Val Loss: 2.5716\n",
      "Validation loss improved from 2.5718 to 2.5716. Saving model...\n",
      "\n",
      "LOG: Epoch [874/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8637\n",
      "Epoch [874/2000], Avg Train Loss: 3.8637\n",
      "Epoch [874/2000], Avg Val Loss: 2.5713\n",
      "Validation loss improved from 2.5716 to 2.5713. Saving model...\n",
      "\n",
      "LOG: Epoch [875/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9227\n",
      "Epoch [875/2000], Avg Train Loss: 3.9227\n",
      "Epoch [875/2000], Avg Val Loss: 2.5710\n",
      "Validation loss improved from 2.5713 to 2.5710. Saving model...\n",
      "\n",
      "LOG: Epoch [876/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8715\n",
      "Epoch [876/2000], Avg Train Loss: 3.8715\n",
      "Epoch [876/2000], Avg Val Loss: 2.5706\n",
      "Validation loss improved from 2.5710 to 2.5706. Saving model...\n",
      "\n",
      "LOG: Epoch [877/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8361\n",
      "Epoch [877/2000], Avg Train Loss: 3.8361\n",
      "Epoch [877/2000], Avg Val Loss: 2.5703\n",
      "Validation loss improved from 2.5706 to 2.5703. Saving model...\n",
      "\n",
      "LOG: Epoch [878/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8730\n",
      "Epoch [878/2000], Avg Train Loss: 3.8730\n",
      "Epoch [878/2000], Avg Val Loss: 2.5699\n",
      "Validation loss improved from 2.5703 to 2.5699. Saving model...\n",
      "\n",
      "LOG: Epoch [879/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8429\n",
      "Epoch [879/2000], Avg Train Loss: 3.8429\n",
      "Epoch [879/2000], Avg Val Loss: 2.5695\n",
      "Validation loss improved from 2.5699 to 2.5695. Saving model...\n",
      "\n",
      "LOG: Epoch [880/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8572\n",
      "Epoch [880/2000], Avg Train Loss: 3.8572\n",
      "Epoch [880/2000], Avg Val Loss: 2.5692\n",
      "Validation loss improved from 2.5695 to 2.5692. Saving model...\n",
      "\n",
      "LOG: Epoch [881/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8381\n",
      "Epoch [881/2000], Avg Train Loss: 3.8381\n",
      "Epoch [881/2000], Avg Val Loss: 2.5689\n",
      "Validation loss improved from 2.5692 to 2.5689. Saving model...\n",
      "\n",
      "LOG: Epoch [882/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8556\n",
      "Epoch [882/2000], Avg Train Loss: 3.8556\n",
      "Epoch [882/2000], Avg Val Loss: 2.5686\n",
      "Validation loss improved from 2.5689 to 2.5686. Saving model...\n",
      "\n",
      "LOG: Epoch [883/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8768\n",
      "Epoch [883/2000], Avg Train Loss: 3.8768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [883/2000], Avg Val Loss: 2.5682\n",
      "Validation loss improved from 2.5686 to 2.5682. Saving model...\n",
      "\n",
      "LOG: Epoch [884/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8327\n",
      "Epoch [884/2000], Avg Train Loss: 3.8327\n",
      "Epoch [884/2000], Avg Val Loss: 2.5678\n",
      "Validation loss improved from 2.5682 to 2.5678. Saving model...\n",
      "\n",
      "LOG: Epoch [885/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8614\n",
      "Epoch [885/2000], Avg Train Loss: 3.8614\n",
      "Epoch [885/2000], Avg Val Loss: 2.5674\n",
      "Validation loss improved from 2.5678 to 2.5674. Saving model...\n",
      "\n",
      "LOG: Epoch [886/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8709\n",
      "Epoch [886/2000], Avg Train Loss: 3.8709\n",
      "Epoch [886/2000], Avg Val Loss: 2.5670\n",
      "Validation loss improved from 2.5674 to 2.5670. Saving model...\n",
      "\n",
      "LOG: Epoch [887/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8630\n",
      "Epoch [887/2000], Avg Train Loss: 3.8630\n",
      "Epoch [887/2000], Avg Val Loss: 2.5667\n",
      "Validation loss improved from 2.5670 to 2.5667. Saving model...\n",
      "\n",
      "LOG: Epoch [888/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8351\n",
      "Epoch [888/2000], Avg Train Loss: 3.8351\n",
      "Epoch [888/2000], Avg Val Loss: 2.5663\n",
      "Validation loss improved from 2.5667 to 2.5663. Saving model...\n",
      "\n",
      "LOG: Epoch [889/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8234\n",
      "Epoch [889/2000], Avg Train Loss: 3.8234\n",
      "Epoch [889/2000], Avg Val Loss: 2.5661\n",
      "Validation loss improved from 2.5663 to 2.5661. Saving model...\n",
      "\n",
      "LOG: Epoch [890/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8260\n",
      "Epoch [890/2000], Avg Train Loss: 3.8260\n",
      "Epoch [890/2000], Avg Val Loss: 2.5660\n",
      "Validation loss improved from 2.5661 to 2.5660. Saving model...\n",
      "\n",
      "LOG: Epoch [891/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8424\n",
      "Epoch [891/2000], Avg Train Loss: 3.8424\n",
      "Epoch [891/2000], Avg Val Loss: 2.5659\n",
      "Validation loss improved from 2.5660 to 2.5659. Saving model...\n",
      "\n",
      "LOG: Epoch [892/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8306\n",
      "Epoch [892/2000], Avg Train Loss: 3.8306\n",
      "Epoch [892/2000], Avg Val Loss: 2.5657\n",
      "Validation loss improved from 2.5659 to 2.5657. Saving model...\n",
      "\n",
      "LOG: Epoch [893/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8396\n",
      "Epoch [893/2000], Avg Train Loss: 3.8396\n",
      "Epoch [893/2000], Avg Val Loss: 2.5655\n",
      "Validation loss improved from 2.5657 to 2.5655. Saving model...\n",
      "\n",
      "LOG: Epoch [894/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7896\n",
      "Epoch [894/2000], Avg Train Loss: 3.7896\n",
      "Epoch [894/2000], Avg Val Loss: 2.5654\n",
      "Validation loss improved from 2.5655 to 2.5654. Saving model...\n",
      "\n",
      "LOG: Epoch [895/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8135\n",
      "Epoch [895/2000], Avg Train Loss: 3.8135\n",
      "Epoch [895/2000], Avg Val Loss: 2.5654\n",
      "Validation loss improved from 2.5654 to 2.5654. Saving model...\n",
      "\n",
      "LOG: Epoch [896/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8324\n",
      "Epoch [896/2000], Avg Train Loss: 3.8324\n",
      "Epoch [896/2000], Avg Val Loss: 2.5653\n",
      "Validation loss improved from 2.5654 to 2.5653. Saving model...\n",
      "\n",
      "LOG: Epoch [897/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8519\n",
      "Epoch [897/2000], Avg Train Loss: 3.8519\n",
      "Epoch [897/2000], Avg Val Loss: 2.5652\n",
      "Validation loss improved from 2.5653 to 2.5652. Saving model...\n",
      "\n",
      "LOG: Epoch [898/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8295\n",
      "Epoch [898/2000], Avg Train Loss: 3.8295\n",
      "Epoch [898/2000], Avg Val Loss: 2.5652\n",
      "Validation loss improved from 2.5652 to 2.5652. Saving model...\n",
      "\n",
      "LOG: Epoch [899/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8186\n",
      "Epoch [899/2000], Avg Train Loss: 3.8186\n",
      "Epoch [899/2000], Avg Val Loss: 2.5651\n",
      "Validation loss improved from 2.5652 to 2.5651. Saving model...\n",
      "\n",
      "LOG: Epoch [900/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8442\n",
      "Epoch [900/2000], Avg Train Loss: 3.8442\n",
      "Epoch [900/2000], Avg Val Loss: 2.5649\n",
      "Validation loss improved from 2.5651 to 2.5649. Saving model...\n",
      "\n",
      "LOG: Epoch [901/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8621\n",
      "Epoch [901/2000], Avg Train Loss: 3.8621\n",
      "Epoch [901/2000], Avg Val Loss: 2.5647\n",
      "Validation loss improved from 2.5649 to 2.5647. Saving model...\n",
      "\n",
      "LOG: Epoch [902/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8329\n",
      "Epoch [902/2000], Avg Train Loss: 3.8329\n",
      "Epoch [902/2000], Avg Val Loss: 2.5645\n",
      "Validation loss improved from 2.5647 to 2.5645. Saving model...\n",
      "\n",
      "LOG: Epoch [903/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8768\n",
      "Epoch [903/2000], Avg Train Loss: 3.8768\n",
      "Epoch [903/2000], Avg Val Loss: 2.5644\n",
      "Validation loss improved from 2.5645 to 2.5644. Saving model...\n",
      "\n",
      "LOG: Epoch [904/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8512\n",
      "Epoch [904/2000], Avg Train Loss: 3.8512\n",
      "Epoch [904/2000], Avg Val Loss: 2.5642\n",
      "Validation loss improved from 2.5644 to 2.5642. Saving model...\n",
      "\n",
      "LOG: Epoch [905/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8470\n",
      "Epoch [905/2000], Avg Train Loss: 3.8470\n",
      "Epoch [905/2000], Avg Val Loss: 2.5641\n",
      "Validation loss improved from 2.5642 to 2.5641. Saving model...\n",
      "\n",
      "LOG: Epoch [906/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8501\n",
      "Epoch [906/2000], Avg Train Loss: 3.8501\n",
      "Epoch [906/2000], Avg Val Loss: 2.5639\n",
      "Validation loss improved from 2.5641 to 2.5639. Saving model...\n",
      "\n",
      "LOG: Epoch [907/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8361\n",
      "Epoch [907/2000], Avg Train Loss: 3.8361\n",
      "Epoch [907/2000], Avg Val Loss: 2.5637\n",
      "Validation loss improved from 2.5639 to 2.5637. Saving model...\n",
      "\n",
      "LOG: Epoch [908/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8408\n",
      "Epoch [908/2000], Avg Train Loss: 3.8408\n",
      "Epoch [908/2000], Avg Val Loss: 2.5636\n",
      "Validation loss improved from 2.5637 to 2.5636. Saving model...\n",
      "\n",
      "LOG: Epoch [909/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8533\n",
      "Epoch [909/2000], Avg Train Loss: 3.8533\n",
      "Epoch [909/2000], Avg Val Loss: 2.5635\n",
      "Validation loss improved from 2.5636 to 2.5635. Saving model...\n",
      "\n",
      "LOG: Epoch [910/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8635\n",
      "Epoch [910/2000], Avg Train Loss: 3.8635\n",
      "Epoch [910/2000], Avg Val Loss: 2.5634\n",
      "Validation loss improved from 2.5635 to 2.5634. Saving model...\n",
      "\n",
      "LOG: Epoch [911/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8819\n",
      "Epoch [911/2000], Avg Train Loss: 3.8819\n",
      "Epoch [911/2000], Avg Val Loss: 2.5633\n",
      "Validation loss improved from 2.5634 to 2.5633. Saving model...\n",
      "\n",
      "LOG: Epoch [912/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8255\n",
      "Epoch [912/2000], Avg Train Loss: 3.8255\n",
      "Epoch [912/2000], Avg Val Loss: 2.5633\n",
      "Validation loss improved from 2.5633 to 2.5633. Saving model...\n",
      "\n",
      "LOG: Epoch [913/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8036\n",
      "Epoch [913/2000], Avg Train Loss: 3.8036\n",
      "Epoch [913/2000], Avg Val Loss: 2.5631\n",
      "Validation loss improved from 2.5633 to 2.5631. Saving model...\n",
      "\n",
      "LOG: Epoch [914/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8711\n",
      "Epoch [914/2000], Avg Train Loss: 3.8711\n",
      "Epoch [914/2000], Avg Val Loss: 2.5629\n",
      "Validation loss improved from 2.5631 to 2.5629. Saving model...\n",
      "\n",
      "LOG: Epoch [915/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8099\n",
      "Epoch [915/2000], Avg Train Loss: 3.8099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [915/2000], Avg Val Loss: 2.5627\n",
      "Validation loss improved from 2.5629 to 2.5627. Saving model...\n",
      "\n",
      "LOG: Epoch [916/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8428\n",
      "Epoch [916/2000], Avg Train Loss: 3.8428\n",
      "Epoch [916/2000], Avg Val Loss: 2.5625\n",
      "Validation loss improved from 2.5627 to 2.5625. Saving model...\n",
      "\n",
      "LOG: Epoch [917/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7957\n",
      "Epoch [917/2000], Avg Train Loss: 3.7957\n",
      "Epoch [917/2000], Avg Val Loss: 2.5624\n",
      "Validation loss improved from 2.5625 to 2.5624. Saving model...\n",
      "\n",
      "LOG: Epoch [918/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8488\n",
      "Epoch [918/2000], Avg Train Loss: 3.8488\n",
      "Epoch [918/2000], Avg Val Loss: 2.5623\n",
      "Validation loss improved from 2.5624 to 2.5623. Saving model...\n",
      "\n",
      "LOG: Epoch [919/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8037\n",
      "Epoch [919/2000], Avg Train Loss: 3.8037\n",
      "Epoch [919/2000], Avg Val Loss: 2.5623\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [920/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8235\n",
      "Epoch [920/2000], Avg Train Loss: 3.8235\n",
      "Epoch [920/2000], Avg Val Loss: 2.5624\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [921/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7841\n",
      "Epoch [921/2000], Avg Train Loss: 3.7841\n",
      "Epoch [921/2000], Avg Val Loss: 2.5624\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [922/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8565\n",
      "Epoch [922/2000], Avg Train Loss: 3.8565\n",
      "Epoch [922/2000], Avg Val Loss: 2.5624\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [923/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8172\n",
      "Epoch [923/2000], Avg Train Loss: 3.8172\n",
      "Epoch [923/2000], Avg Val Loss: 2.5624\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [924/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8021\n",
      "Epoch [924/2000], Avg Train Loss: 3.8021\n",
      "Epoch [924/2000], Avg Val Loss: 2.5624\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [925/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8036\n",
      "Epoch [925/2000], Avg Train Loss: 3.8036\n",
      "Epoch [925/2000], Avg Val Loss: 2.5626\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [926/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8062\n",
      "Epoch [926/2000], Avg Train Loss: 3.8062\n",
      "Epoch [926/2000], Avg Val Loss: 2.5627\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [927/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7910\n",
      "Epoch [927/2000], Avg Train Loss: 3.7910\n",
      "Epoch [927/2000], Avg Val Loss: 2.5627\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [928/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7835\n",
      "Epoch [928/2000], Avg Train Loss: 3.7835\n",
      "Epoch [928/2000], Avg Val Loss: 2.5628\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [929/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8537\n",
      "Epoch [929/2000], Avg Train Loss: 3.8537\n",
      "Epoch [929/2000], Avg Val Loss: 2.5627\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [930/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8037\n",
      "Epoch [930/2000], Avg Train Loss: 3.8037\n",
      "Epoch [930/2000], Avg Val Loss: 2.5626\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [931/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8223\n",
      "Epoch [931/2000], Avg Train Loss: 3.8223\n",
      "Epoch [931/2000], Avg Val Loss: 2.5624\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [932/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8172\n",
      "Epoch [932/2000], Avg Train Loss: 3.8172\n",
      "Epoch [932/2000], Avg Val Loss: 2.5624\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [933/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7964\n",
      "Epoch [933/2000], Avg Train Loss: 3.7964\n",
      "Epoch [933/2000], Avg Val Loss: 2.5623\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [934/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8292\n",
      "Epoch [934/2000], Avg Train Loss: 3.8292\n",
      "Epoch [934/2000], Avg Val Loss: 2.5622\n",
      "Validation loss improved from 2.5623 to 2.5622. Saving model...\n",
      "\n",
      "LOG: Epoch [935/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7883\n",
      "Epoch [935/2000], Avg Train Loss: 3.7883\n",
      "Epoch [935/2000], Avg Val Loss: 2.5620\n",
      "Validation loss improved from 2.5622 to 2.5620. Saving model...\n",
      "\n",
      "LOG: Epoch [936/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8096\n",
      "Epoch [936/2000], Avg Train Loss: 3.8096\n",
      "Epoch [936/2000], Avg Val Loss: 2.5618\n",
      "Validation loss improved from 2.5620 to 2.5618. Saving model...\n",
      "\n",
      "LOG: Epoch [937/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8206\n",
      "Epoch [937/2000], Avg Train Loss: 3.8206\n",
      "Epoch [937/2000], Avg Val Loss: 2.5616\n",
      "Validation loss improved from 2.5618 to 2.5616. Saving model...\n",
      "\n",
      "LOG: Epoch [938/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8080\n",
      "Epoch [938/2000], Avg Train Loss: 3.8080\n",
      "Epoch [938/2000], Avg Val Loss: 2.5615\n",
      "Validation loss improved from 2.5616 to 2.5615. Saving model...\n",
      "\n",
      "LOG: Epoch [939/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7932\n",
      "Epoch [939/2000], Avg Train Loss: 3.7932\n",
      "Epoch [939/2000], Avg Val Loss: 2.5613\n",
      "Validation loss improved from 2.5615 to 2.5613. Saving model...\n",
      "\n",
      "LOG: Epoch [940/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8232\n",
      "Epoch [940/2000], Avg Train Loss: 3.8232\n",
      "Epoch [940/2000], Avg Val Loss: 2.5610\n",
      "Validation loss improved from 2.5613 to 2.5610. Saving model...\n",
      "\n",
      "LOG: Epoch [941/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8403\n",
      "Epoch [941/2000], Avg Train Loss: 3.8403\n",
      "Epoch [941/2000], Avg Val Loss: 2.5607\n",
      "Validation loss improved from 2.5610 to 2.5607. Saving model...\n",
      "\n",
      "LOG: Epoch [942/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8036\n",
      "Epoch [942/2000], Avg Train Loss: 3.8036\n",
      "Epoch [942/2000], Avg Val Loss: 2.5605\n",
      "Validation loss improved from 2.5607 to 2.5605. Saving model...\n",
      "\n",
      "LOG: Epoch [943/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8407\n",
      "Epoch [943/2000], Avg Train Loss: 3.8407\n",
      "Epoch [943/2000], Avg Val Loss: 2.5604\n",
      "Validation loss improved from 2.5605 to 2.5604. Saving model...\n",
      "\n",
      "LOG: Epoch [944/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7877\n",
      "Epoch [944/2000], Avg Train Loss: 3.7877\n",
      "Epoch [944/2000], Avg Val Loss: 2.5602\n",
      "Validation loss improved from 2.5604 to 2.5602. Saving model...\n",
      "\n",
      "LOG: Epoch [945/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8142\n",
      "Epoch [945/2000], Avg Train Loss: 3.8142\n",
      "Epoch [945/2000], Avg Val Loss: 2.5601\n",
      "Validation loss improved from 2.5602 to 2.5601. Saving model...\n",
      "\n",
      "LOG: Epoch [946/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8315\n",
      "Epoch [946/2000], Avg Train Loss: 3.8315\n",
      "Epoch [946/2000], Avg Val Loss: 2.5600\n",
      "Validation loss improved from 2.5601 to 2.5600. Saving model...\n",
      "\n",
      "LOG: Epoch [947/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8418\n",
      "Epoch [947/2000], Avg Train Loss: 3.8418\n",
      "Epoch [947/2000], Avg Val Loss: 2.5599\n",
      "Validation loss improved from 2.5600 to 2.5599. Saving model...\n",
      "\n",
      "LOG: Epoch [948/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8196\n",
      "Epoch [948/2000], Avg Train Loss: 3.8196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [948/2000], Avg Val Loss: 2.5599\n",
      "Validation loss improved from 2.5599 to 2.5599. Saving model...\n",
      "\n",
      "LOG: Epoch [949/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7996\n",
      "Epoch [949/2000], Avg Train Loss: 3.7996\n",
      "Epoch [949/2000], Avg Val Loss: 2.5597\n",
      "Validation loss improved from 2.5599 to 2.5597. Saving model...\n",
      "\n",
      "LOG: Epoch [950/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8309\n",
      "Epoch [950/2000], Avg Train Loss: 3.8309\n",
      "Epoch [950/2000], Avg Val Loss: 2.5596\n",
      "Validation loss improved from 2.5597 to 2.5596. Saving model...\n",
      "\n",
      "LOG: Epoch [951/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7762\n",
      "Epoch [951/2000], Avg Train Loss: 3.7762\n",
      "Epoch [951/2000], Avg Val Loss: 2.5594\n",
      "Validation loss improved from 2.5596 to 2.5594. Saving model...\n",
      "\n",
      "LOG: Epoch [952/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7728\n",
      "Epoch [952/2000], Avg Train Loss: 3.7728\n",
      "Epoch [952/2000], Avg Val Loss: 2.5593\n",
      "Validation loss improved from 2.5594 to 2.5593. Saving model...\n",
      "\n",
      "LOG: Epoch [953/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7860\n",
      "Epoch [953/2000], Avg Train Loss: 3.7860\n",
      "Epoch [953/2000], Avg Val Loss: 2.5592\n",
      "Validation loss improved from 2.5593 to 2.5592. Saving model...\n",
      "\n",
      "LOG: Epoch [954/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7631\n",
      "Epoch [954/2000], Avg Train Loss: 3.7631\n",
      "Epoch [954/2000], Avg Val Loss: 2.5590\n",
      "Validation loss improved from 2.5592 to 2.5590. Saving model...\n",
      "\n",
      "LOG: Epoch [955/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8169\n",
      "Epoch [955/2000], Avg Train Loss: 3.8169\n",
      "Epoch [955/2000], Avg Val Loss: 2.5589\n",
      "Validation loss improved from 2.5590 to 2.5589. Saving model...\n",
      "\n",
      "LOG: Epoch [956/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7816\n",
      "Epoch [956/2000], Avg Train Loss: 3.7816\n",
      "Epoch [956/2000], Avg Val Loss: 2.5587\n",
      "Validation loss improved from 2.5589 to 2.5587. Saving model...\n",
      "\n",
      "LOG: Epoch [957/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8278\n",
      "Epoch [957/2000], Avg Train Loss: 3.8278\n",
      "Epoch [957/2000], Avg Val Loss: 2.5586\n",
      "Validation loss improved from 2.5587 to 2.5586. Saving model...\n",
      "\n",
      "LOG: Epoch [958/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7931\n",
      "Epoch [958/2000], Avg Train Loss: 3.7931\n",
      "Epoch [958/2000], Avg Val Loss: 2.5585\n",
      "Validation loss improved from 2.5586 to 2.5585. Saving model...\n",
      "\n",
      "LOG: Epoch [959/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8230\n",
      "Epoch [959/2000], Avg Train Loss: 3.8230\n",
      "Epoch [959/2000], Avg Val Loss: 2.5583\n",
      "Validation loss improved from 2.5585 to 2.5583. Saving model...\n",
      "\n",
      "LOG: Epoch [960/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7960\n",
      "Epoch [960/2000], Avg Train Loss: 3.7960\n",
      "Epoch [960/2000], Avg Val Loss: 2.5582\n",
      "Validation loss improved from 2.5583 to 2.5582. Saving model...\n",
      "\n",
      "LOG: Epoch [961/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7925\n",
      "Epoch [961/2000], Avg Train Loss: 3.7925\n",
      "Epoch [961/2000], Avg Val Loss: 2.5582\n",
      "Validation loss improved from 2.5582 to 2.5582. Saving model...\n",
      "\n",
      "LOG: Epoch [962/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8299\n",
      "Epoch [962/2000], Avg Train Loss: 3.8299\n",
      "Epoch [962/2000], Avg Val Loss: 2.5582\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [963/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8473\n",
      "Epoch [963/2000], Avg Train Loss: 3.8473\n",
      "Epoch [963/2000], Avg Val Loss: 2.5583\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [964/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8239\n",
      "Epoch [964/2000], Avg Train Loss: 3.8239\n",
      "Epoch [964/2000], Avg Val Loss: 2.5584\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [965/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7842\n",
      "Epoch [965/2000], Avg Train Loss: 3.7842\n",
      "Epoch [965/2000], Avg Val Loss: 2.5584\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [966/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8361\n",
      "Epoch [966/2000], Avg Train Loss: 3.8361\n",
      "Epoch [966/2000], Avg Val Loss: 2.5585\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [967/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7672\n",
      "Epoch [967/2000], Avg Train Loss: 3.7672\n",
      "Epoch [967/2000], Avg Val Loss: 2.5585\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [968/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8049\n",
      "Epoch [968/2000], Avg Train Loss: 3.8049\n",
      "Epoch [968/2000], Avg Val Loss: 2.5585\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [969/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7566\n",
      "Epoch [969/2000], Avg Train Loss: 3.7566\n",
      "Epoch [969/2000], Avg Val Loss: 2.5585\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [970/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7976\n",
      "Epoch [970/2000], Avg Train Loss: 3.7976\n",
      "Epoch [970/2000], Avg Val Loss: 2.5584\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [971/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7981\n",
      "Epoch [971/2000], Avg Train Loss: 3.7981\n",
      "Epoch [971/2000], Avg Val Loss: 2.5584\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [972/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7882\n",
      "Epoch [972/2000], Avg Train Loss: 3.7882\n",
      "Epoch [972/2000], Avg Val Loss: 2.5583\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [973/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7589\n",
      "Epoch [973/2000], Avg Train Loss: 3.7589\n",
      "Epoch [973/2000], Avg Val Loss: 2.5583\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [974/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8238\n",
      "Epoch [974/2000], Avg Train Loss: 3.8238\n",
      "Epoch [974/2000], Avg Val Loss: 2.5581\n",
      "Validation loss improved from 2.5582 to 2.5581. Saving model...\n",
      "\n",
      "LOG: Epoch [975/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7978\n",
      "Epoch [975/2000], Avg Train Loss: 3.7978\n",
      "Epoch [975/2000], Avg Val Loss: 2.5579\n",
      "Validation loss improved from 2.5581 to 2.5579. Saving model...\n",
      "\n",
      "LOG: Epoch [976/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8097\n",
      "Epoch [976/2000], Avg Train Loss: 3.8097\n",
      "Epoch [976/2000], Avg Val Loss: 2.5577\n",
      "Validation loss improved from 2.5579 to 2.5577. Saving model...\n",
      "\n",
      "LOG: Epoch [977/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8130\n",
      "Epoch [977/2000], Avg Train Loss: 3.8130\n",
      "Epoch [977/2000], Avg Val Loss: 2.5575\n",
      "Validation loss improved from 2.5577 to 2.5575. Saving model...\n",
      "\n",
      "LOG: Epoch [978/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8106\n",
      "Epoch [978/2000], Avg Train Loss: 3.8106\n",
      "Epoch [978/2000], Avg Val Loss: 2.5574\n",
      "Validation loss improved from 2.5575 to 2.5574. Saving model...\n",
      "\n",
      "LOG: Epoch [979/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7436\n",
      "Epoch [979/2000], Avg Train Loss: 3.7436\n",
      "Epoch [979/2000], Avg Val Loss: 2.5572\n",
      "Validation loss improved from 2.5574 to 2.5572. Saving model...\n",
      "\n",
      "LOG: Epoch [980/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8312\n",
      "Epoch [980/2000], Avg Train Loss: 3.8312\n",
      "Epoch [980/2000], Avg Val Loss: 2.5570\n",
      "Validation loss improved from 2.5572 to 2.5570. Saving model...\n",
      "\n",
      "LOG: Epoch [981/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8264\n",
      "Epoch [981/2000], Avg Train Loss: 3.8264\n",
      "Epoch [981/2000], Avg Val Loss: 2.5568\n",
      "Validation loss improved from 2.5570 to 2.5568. Saving model...\n",
      "\n",
      "LOG: Epoch [982/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7488\n",
      "Epoch [982/2000], Avg Train Loss: 3.7488\n",
      "Epoch [982/2000], Avg Val Loss: 2.5566\n",
      "Validation loss improved from 2.5568 to 2.5566. Saving model...\n",
      "\n",
      "LOG: Epoch [983/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7721\n",
      "Epoch [983/2000], Avg Train Loss: 3.7721\n",
      "Epoch [983/2000], Avg Val Loss: 2.5564\n",
      "Validation loss improved from 2.5566 to 2.5564. Saving model...\n",
      "\n",
      "LOG: Epoch [984/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8096\n",
      "Epoch [984/2000], Avg Train Loss: 3.8096\n",
      "Epoch [984/2000], Avg Val Loss: 2.5563\n",
      "Validation loss improved from 2.5564 to 2.5563. Saving model...\n",
      "\n",
      "LOG: Epoch [985/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7675\n",
      "Epoch [985/2000], Avg Train Loss: 3.7675\n",
      "Epoch [985/2000], Avg Val Loss: 2.5561\n",
      "Validation loss improved from 2.5563 to 2.5561. Saving model...\n",
      "\n",
      "LOG: Epoch [986/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8102\n",
      "Epoch [986/2000], Avg Train Loss: 3.8102\n",
      "Epoch [986/2000], Avg Val Loss: 2.5559\n",
      "Validation loss improved from 2.5561 to 2.5559. Saving model...\n",
      "\n",
      "LOG: Epoch [987/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7556\n",
      "Epoch [987/2000], Avg Train Loss: 3.7556\n",
      "Epoch [987/2000], Avg Val Loss: 2.5557\n",
      "Validation loss improved from 2.5559 to 2.5557. Saving model...\n",
      "\n",
      "LOG: Epoch [988/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7783\n",
      "Epoch [988/2000], Avg Train Loss: 3.7783\n",
      "Epoch [988/2000], Avg Val Loss: 2.5556\n",
      "Validation loss improved from 2.5557 to 2.5556. Saving model...\n",
      "\n",
      "LOG: Epoch [989/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7531\n",
      "Epoch [989/2000], Avg Train Loss: 3.7531\n",
      "Epoch [989/2000], Avg Val Loss: 2.5555\n",
      "Validation loss improved from 2.5556 to 2.5555. Saving model...\n",
      "\n",
      "LOG: Epoch [990/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7699\n",
      "Epoch [990/2000], Avg Train Loss: 3.7699\n",
      "Epoch [990/2000], Avg Val Loss: 2.5555\n",
      "Validation loss improved from 2.5555 to 2.5555. Saving model...\n",
      "\n",
      "LOG: Epoch [991/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8065\n",
      "Epoch [991/2000], Avg Train Loss: 3.8065\n",
      "Epoch [991/2000], Avg Val Loss: 2.5554\n",
      "Validation loss improved from 2.5555 to 2.5554. Saving model...\n",
      "\n",
      "LOG: Epoch [992/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7582\n",
      "Epoch [992/2000], Avg Train Loss: 3.7582\n",
      "Epoch [992/2000], Avg Val Loss: 2.5553\n",
      "Validation loss improved from 2.5554 to 2.5553. Saving model...\n",
      "\n",
      "LOG: Epoch [993/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8220\n",
      "Epoch [993/2000], Avg Train Loss: 3.8220\n",
      "Epoch [993/2000], Avg Val Loss: 2.5551\n",
      "Validation loss improved from 2.5553 to 2.5551. Saving model...\n",
      "\n",
      "LOG: Epoch [994/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7827\n",
      "Epoch [994/2000], Avg Train Loss: 3.7827\n",
      "Epoch [994/2000], Avg Val Loss: 2.5550\n",
      "Validation loss improved from 2.5551 to 2.5550. Saving model...\n",
      "\n",
      "LOG: Epoch [995/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7513\n",
      "Epoch [995/2000], Avg Train Loss: 3.7513\n",
      "Epoch [995/2000], Avg Val Loss: 2.5549\n",
      "Validation loss improved from 2.5550 to 2.5549. Saving model...\n",
      "\n",
      "LOG: Epoch [996/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8104\n",
      "Epoch [996/2000], Avg Train Loss: 3.8104\n",
      "Epoch [996/2000], Avg Val Loss: 2.5547\n",
      "Validation loss improved from 2.5549 to 2.5547. Saving model...\n",
      "\n",
      "LOG: Epoch [997/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7459\n",
      "Epoch [997/2000], Avg Train Loss: 3.7459\n",
      "Epoch [997/2000], Avg Val Loss: 2.5545\n",
      "Validation loss improved from 2.5547 to 2.5545. Saving model...\n",
      "\n",
      "LOG: Epoch [998/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7882\n",
      "Epoch [998/2000], Avg Train Loss: 3.7882\n",
      "Epoch [998/2000], Avg Val Loss: 2.5543\n",
      "Validation loss improved from 2.5545 to 2.5543. Saving model...\n",
      "\n",
      "LOG: Epoch [999/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7626\n",
      "Epoch [999/2000], Avg Train Loss: 3.7626\n",
      "Epoch [999/2000], Avg Val Loss: 2.5540\n",
      "Validation loss improved from 2.5543 to 2.5540. Saving model...\n",
      "\n",
      "LOG: Epoch [1000/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7377\n",
      "Epoch [1000/2000], Avg Train Loss: 3.7377\n",
      "Epoch [1000/2000], Avg Val Loss: 2.5539\n",
      "Validation loss improved from 2.5540 to 2.5539. Saving model...\n",
      "\n",
      "LOG: Epoch [1001/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7764\n",
      "Epoch [1001/2000], Avg Train Loss: 3.7764\n",
      "Epoch [1001/2000], Avg Val Loss: 2.5537\n",
      "Validation loss improved from 2.5539 to 2.5537. Saving model...\n",
      "\n",
      "LOG: Epoch [1002/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7483\n",
      "Epoch [1002/2000], Avg Train Loss: 3.7483\n",
      "Epoch [1002/2000], Avg Val Loss: 2.5536\n",
      "Validation loss improved from 2.5537 to 2.5536. Saving model...\n",
      "\n",
      "LOG: Epoch [1003/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7894\n",
      "Epoch [1003/2000], Avg Train Loss: 3.7894\n",
      "Epoch [1003/2000], Avg Val Loss: 2.5535\n",
      "Validation loss improved from 2.5536 to 2.5535. Saving model...\n",
      "\n",
      "LOG: Epoch [1004/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7537\n",
      "Epoch [1004/2000], Avg Train Loss: 3.7537\n",
      "Epoch [1004/2000], Avg Val Loss: 2.5533\n",
      "Validation loss improved from 2.5535 to 2.5533. Saving model...\n",
      "\n",
      "LOG: Epoch [1005/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7720\n",
      "Epoch [1005/2000], Avg Train Loss: 3.7720\n",
      "Epoch [1005/2000], Avg Val Loss: 2.5531\n",
      "Validation loss improved from 2.5533 to 2.5531. Saving model...\n",
      "\n",
      "LOG: Epoch [1006/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7482\n",
      "Epoch [1006/2000], Avg Train Loss: 3.7482\n",
      "Epoch [1006/2000], Avg Val Loss: 2.5530\n",
      "Validation loss improved from 2.5531 to 2.5530. Saving model...\n",
      "\n",
      "LOG: Epoch [1007/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7551\n",
      "Epoch [1007/2000], Avg Train Loss: 3.7551\n",
      "Epoch [1007/2000], Avg Val Loss: 2.5528\n",
      "Validation loss improved from 2.5530 to 2.5528. Saving model...\n",
      "\n",
      "LOG: Epoch [1008/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7584\n",
      "Epoch [1008/2000], Avg Train Loss: 3.7584\n",
      "Epoch [1008/2000], Avg Val Loss: 2.5527\n",
      "Validation loss improved from 2.5528 to 2.5527. Saving model...\n",
      "\n",
      "LOG: Epoch [1009/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7399\n",
      "Epoch [1009/2000], Avg Train Loss: 3.7399\n",
      "Epoch [1009/2000], Avg Val Loss: 2.5527\n",
      "Validation loss improved from 2.5527 to 2.5527. Saving model...\n",
      "\n",
      "LOG: Epoch [1010/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7777\n",
      "Epoch [1010/2000], Avg Train Loss: 3.7777\n",
      "Epoch [1010/2000], Avg Val Loss: 2.5525\n",
      "Validation loss improved from 2.5527 to 2.5525. Saving model...\n",
      "\n",
      "LOG: Epoch [1011/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7657\n",
      "Epoch [1011/2000], Avg Train Loss: 3.7657\n",
      "Epoch [1011/2000], Avg Val Loss: 2.5524\n",
      "Validation loss improved from 2.5525 to 2.5524. Saving model...\n",
      "\n",
      "LOG: Epoch [1012/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7753\n",
      "Epoch [1012/2000], Avg Train Loss: 3.7753\n",
      "Epoch [1012/2000], Avg Val Loss: 2.5523\n",
      "Validation loss improved from 2.5524 to 2.5523. Saving model...\n",
      "\n",
      "LOG: Epoch [1013/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7446\n",
      "Epoch [1013/2000], Avg Train Loss: 3.7446\n",
      "Epoch [1013/2000], Avg Val Loss: 2.5523\n",
      "Validation loss improved from 2.5523 to 2.5523. Saving model...\n",
      "\n",
      "LOG: Epoch [1014/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7650\n",
      "Epoch [1014/2000], Avg Train Loss: 3.7650\n",
      "Epoch [1014/2000], Avg Val Loss: 2.5523\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1015/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7823\n",
      "Epoch [1015/2000], Avg Train Loss: 3.7823\n",
      "Epoch [1015/2000], Avg Val Loss: 2.5523\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1016/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7458\n",
      "Epoch [1016/2000], Avg Train Loss: 3.7458\n",
      "Epoch [1016/2000], Avg Val Loss: 2.5523\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1017/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7608\n",
      "Epoch [1017/2000], Avg Train Loss: 3.7608\n",
      "Epoch [1017/2000], Avg Val Loss: 2.5524\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1018/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7708\n",
      "Epoch [1018/2000], Avg Train Loss: 3.7708\n",
      "Epoch [1018/2000], Avg Val Loss: 2.5524\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1019/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7539\n",
      "Epoch [1019/2000], Avg Train Loss: 3.7539\n",
      "Epoch [1019/2000], Avg Val Loss: 2.5525\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1020/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7579\n",
      "Epoch [1020/2000], Avg Train Loss: 3.7579\n",
      "Epoch [1020/2000], Avg Val Loss: 2.5526\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1021/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7547\n",
      "Epoch [1021/2000], Avg Train Loss: 3.7547\n",
      "Epoch [1021/2000], Avg Val Loss: 2.5528\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1022/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7868\n",
      "Epoch [1022/2000], Avg Train Loss: 3.7868\n",
      "Epoch [1022/2000], Avg Val Loss: 2.5530\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1023/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7637\n",
      "Epoch [1023/2000], Avg Train Loss: 3.7637\n",
      "Epoch [1023/2000], Avg Val Loss: 2.5531\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1024/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7389\n",
      "Epoch [1024/2000], Avg Train Loss: 3.7389\n",
      "Epoch [1024/2000], Avg Val Loss: 2.5532\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1025/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7795\n",
      "Epoch [1025/2000], Avg Train Loss: 3.7795\n",
      "Epoch [1025/2000], Avg Val Loss: 2.5533\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1026/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7516\n",
      "Epoch [1026/2000], Avg Train Loss: 3.7516\n",
      "Epoch [1026/2000], Avg Val Loss: 2.5533\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1027/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7778\n",
      "Epoch [1027/2000], Avg Train Loss: 3.7778\n",
      "Epoch [1027/2000], Avg Val Loss: 2.5534\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1028/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7816\n",
      "Epoch [1028/2000], Avg Train Loss: 3.7816\n",
      "Epoch [1028/2000], Avg Val Loss: 2.5534\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1029/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7786\n",
      "Epoch [1029/2000], Avg Train Loss: 3.7786\n",
      "Epoch [1029/2000], Avg Val Loss: 2.5534\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1030/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7860\n",
      "Epoch [1030/2000], Avg Train Loss: 3.7860\n",
      "Epoch [1030/2000], Avg Val Loss: 2.5533\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1031/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7650\n",
      "Epoch [1031/2000], Avg Train Loss: 3.7650\n",
      "Epoch [1031/2000], Avg Val Loss: 2.5531\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1032/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7378\n",
      "Epoch [1032/2000], Avg Train Loss: 3.7378\n",
      "Epoch [1032/2000], Avg Val Loss: 2.5530\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1033/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7366\n",
      "Epoch [1033/2000], Avg Train Loss: 3.7366\n",
      "Epoch [1033/2000], Avg Val Loss: 2.5528\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1034/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7550\n",
      "Epoch [1034/2000], Avg Train Loss: 3.7550\n",
      "Epoch [1034/2000], Avg Val Loss: 2.5528\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1035/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7143\n",
      "Epoch [1035/2000], Avg Train Loss: 3.7143\n",
      "Epoch [1035/2000], Avg Val Loss: 2.5527\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1036/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7480\n",
      "Epoch [1036/2000], Avg Train Loss: 3.7480\n",
      "Epoch [1036/2000], Avg Val Loss: 2.5526\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1037/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7392\n",
      "Epoch [1037/2000], Avg Train Loss: 3.7392\n",
      "Epoch [1037/2000], Avg Val Loss: 2.5524\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1038/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7842\n",
      "Epoch [1038/2000], Avg Train Loss: 3.7842\n",
      "Epoch [1038/2000], Avg Val Loss: 2.5522\n",
      "Validation loss improved from 2.5523 to 2.5522. Saving model...\n",
      "\n",
      "LOG: Epoch [1039/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7535\n",
      "Epoch [1039/2000], Avg Train Loss: 3.7535\n",
      "Epoch [1039/2000], Avg Val Loss: 2.5520\n",
      "Validation loss improved from 2.5522 to 2.5520. Saving model...\n",
      "\n",
      "LOG: Epoch [1040/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7555\n",
      "Epoch [1040/2000], Avg Train Loss: 3.7555\n",
      "Epoch [1040/2000], Avg Val Loss: 2.5518\n",
      "Validation loss improved from 2.5520 to 2.5518. Saving model...\n",
      "\n",
      "LOG: Epoch [1041/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7827\n",
      "Epoch [1041/2000], Avg Train Loss: 3.7827\n",
      "Epoch [1041/2000], Avg Val Loss: 2.5517\n",
      "Validation loss improved from 2.5518 to 2.5517. Saving model...\n",
      "\n",
      "LOG: Epoch [1042/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7121\n",
      "Epoch [1042/2000], Avg Train Loss: 3.7121\n",
      "Epoch [1042/2000], Avg Val Loss: 2.5517\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1043/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7637\n",
      "Epoch [1043/2000], Avg Train Loss: 3.7637\n",
      "Epoch [1043/2000], Avg Val Loss: 2.5517\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1044/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8279\n",
      "Epoch [1044/2000], Avg Train Loss: 3.8279\n",
      "Epoch [1044/2000], Avg Val Loss: 2.5517\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1045/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7385\n",
      "Epoch [1045/2000], Avg Train Loss: 3.7385\n",
      "Epoch [1045/2000], Avg Val Loss: 2.5518\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1046/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7467\n",
      "Epoch [1046/2000], Avg Train Loss: 3.7467\n",
      "Epoch [1046/2000], Avg Val Loss: 2.5519\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1047/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7765\n",
      "Epoch [1047/2000], Avg Train Loss: 3.7765\n",
      "Epoch [1047/2000], Avg Val Loss: 2.5519\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1048/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7178\n",
      "Epoch [1048/2000], Avg Train Loss: 3.7178\n",
      "Epoch [1048/2000], Avg Val Loss: 2.5520\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1049/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7272\n",
      "Epoch [1049/2000], Avg Train Loss: 3.7272\n",
      "Epoch [1049/2000], Avg Val Loss: 2.5521\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1050/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7595\n",
      "Epoch [1050/2000], Avg Train Loss: 3.7595\n",
      "Epoch [1050/2000], Avg Val Loss: 2.5522\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1051/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7170\n",
      "Epoch [1051/2000], Avg Train Loss: 3.7170\n",
      "Epoch [1051/2000], Avg Val Loss: 2.5522\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1052/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7722\n",
      "Epoch [1052/2000], Avg Train Loss: 3.7722\n",
      "Epoch [1052/2000], Avg Val Loss: 2.5523\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1053/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7405\n",
      "Epoch [1053/2000], Avg Train Loss: 3.7405\n",
      "Epoch [1053/2000], Avg Val Loss: 2.5524\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1054/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7455\n",
      "Epoch [1054/2000], Avg Train Loss: 3.7455\n",
      "Epoch [1054/2000], Avg Val Loss: 2.5523\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1055/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7102\n",
      "Epoch [1055/2000], Avg Train Loss: 3.7102\n",
      "Epoch [1055/2000], Avg Val Loss: 2.5524\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1056/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7389\n",
      "Epoch [1056/2000], Avg Train Loss: 3.7389\n",
      "Epoch [1056/2000], Avg Val Loss: 2.5523\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1057/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7613\n",
      "Epoch [1057/2000], Avg Train Loss: 3.7613\n",
      "Epoch [1057/2000], Avg Val Loss: 2.5522\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1058/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7282\n",
      "Epoch [1058/2000], Avg Train Loss: 3.7282\n",
      "Epoch [1058/2000], Avg Val Loss: 2.5521\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1059/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7319\n",
      "Epoch [1059/2000], Avg Train Loss: 3.7319\n",
      "Epoch [1059/2000], Avg Val Loss: 2.5518\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1060/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7167\n",
      "Epoch [1060/2000], Avg Train Loss: 3.7167\n",
      "Epoch [1060/2000], Avg Val Loss: 2.5517\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1061/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7407\n",
      "Epoch [1061/2000], Avg Train Loss: 3.7407\n",
      "Epoch [1061/2000], Avg Val Loss: 2.5515\n",
      "Validation loss improved from 2.5517 to 2.5515. Saving model...\n",
      "\n",
      "LOG: Epoch [1062/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7249\n",
      "Epoch [1062/2000], Avg Train Loss: 3.7249\n",
      "Epoch [1062/2000], Avg Val Loss: 2.5513\n",
      "Validation loss improved from 2.5515 to 2.5513. Saving model...\n",
      "\n",
      "LOG: Epoch [1063/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7447\n",
      "Epoch [1063/2000], Avg Train Loss: 3.7447\n",
      "Epoch [1063/2000], Avg Val Loss: 2.5512\n",
      "Validation loss improved from 2.5513 to 2.5512. Saving model...\n",
      "\n",
      "LOG: Epoch [1064/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6980\n",
      "Epoch [1064/2000], Avg Train Loss: 3.6980\n",
      "Epoch [1064/2000], Avg Val Loss: 2.5512\n",
      "Validation loss improved from 2.5512 to 2.5512. Saving model...\n",
      "\n",
      "LOG: Epoch [1065/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7265\n",
      "Epoch [1065/2000], Avg Train Loss: 3.7265\n",
      "Epoch [1065/2000], Avg Val Loss: 2.5512\n",
      "Validation loss improved from 2.5512 to 2.5512. Saving model...\n",
      "\n",
      "LOG: Epoch [1066/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7614\n",
      "Epoch [1066/2000], Avg Train Loss: 3.7614\n",
      "Epoch [1066/2000], Avg Val Loss: 2.5511\n",
      "Validation loss improved from 2.5512 to 2.5511. Saving model...\n",
      "\n",
      "LOG: Epoch [1067/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7186\n",
      "Epoch [1067/2000], Avg Train Loss: 3.7186\n",
      "Epoch [1067/2000], Avg Val Loss: 2.5509\n",
      "Validation loss improved from 2.5511 to 2.5509. Saving model...\n",
      "\n",
      "LOG: Epoch [1068/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7452\n",
      "Epoch [1068/2000], Avg Train Loss: 3.7452\n",
      "Epoch [1068/2000], Avg Val Loss: 2.5506\n",
      "Validation loss improved from 2.5509 to 2.5506. Saving model...\n",
      "\n",
      "LOG: Epoch [1069/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7731\n",
      "Epoch [1069/2000], Avg Train Loss: 3.7731\n",
      "Epoch [1069/2000], Avg Val Loss: 2.5504\n",
      "Validation loss improved from 2.5506 to 2.5504. Saving model...\n",
      "\n",
      "LOG: Epoch [1070/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7210\n",
      "Epoch [1070/2000], Avg Train Loss: 3.7210\n",
      "Epoch [1070/2000], Avg Val Loss: 2.5501\n",
      "Validation loss improved from 2.5504 to 2.5501. Saving model...\n",
      "\n",
      "LOG: Epoch [1071/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7494\n",
      "Epoch [1071/2000], Avg Train Loss: 3.7494\n",
      "Epoch [1071/2000], Avg Val Loss: 2.5499\n",
      "Validation loss improved from 2.5501 to 2.5499. Saving model...\n",
      "\n",
      "LOG: Epoch [1072/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6909\n",
      "Epoch [1072/2000], Avg Train Loss: 3.6909\n",
      "Epoch [1072/2000], Avg Val Loss: 2.5497\n",
      "Validation loss improved from 2.5499 to 2.5497. Saving model...\n",
      "\n",
      "LOG: Epoch [1073/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7254\n",
      "Epoch [1073/2000], Avg Train Loss: 3.7254\n",
      "Epoch [1073/2000], Avg Val Loss: 2.5495\n",
      "Validation loss improved from 2.5497 to 2.5495. Saving model...\n",
      "\n",
      "LOG: Epoch [1074/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7205\n",
      "Epoch [1074/2000], Avg Train Loss: 3.7205\n",
      "Epoch [1074/2000], Avg Val Loss: 2.5493\n",
      "Validation loss improved from 2.5495 to 2.5493. Saving model...\n",
      "\n",
      "LOG: Epoch [1075/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7245\n",
      "Epoch [1075/2000], Avg Train Loss: 3.7245\n",
      "Epoch [1075/2000], Avg Val Loss: 2.5491\n",
      "Validation loss improved from 2.5493 to 2.5491. Saving model...\n",
      "\n",
      "LOG: Epoch [1076/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7496\n",
      "Epoch [1076/2000], Avg Train Loss: 3.7496\n",
      "Epoch [1076/2000], Avg Val Loss: 2.5490\n",
      "Validation loss improved from 2.5491 to 2.5490. Saving model...\n",
      "\n",
      "LOG: Epoch [1077/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7360\n",
      "Epoch [1077/2000], Avg Train Loss: 3.7360\n",
      "Epoch [1077/2000], Avg Val Loss: 2.5489\n",
      "Validation loss improved from 2.5490 to 2.5489. Saving model...\n",
      "\n",
      "LOG: Epoch [1078/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7358\n",
      "Epoch [1078/2000], Avg Train Loss: 3.7358\n",
      "Epoch [1078/2000], Avg Val Loss: 2.5488\n",
      "Validation loss improved from 2.5489 to 2.5488. Saving model...\n",
      "\n",
      "LOG: Epoch [1079/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7436\n",
      "Epoch [1079/2000], Avg Train Loss: 3.7436\n",
      "Epoch [1079/2000], Avg Val Loss: 2.5486\n",
      "Validation loss improved from 2.5488 to 2.5486. Saving model...\n",
      "\n",
      "LOG: Epoch [1080/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7045\n",
      "Epoch [1080/2000], Avg Train Loss: 3.7045\n",
      "Epoch [1080/2000], Avg Val Loss: 2.5485\n",
      "Validation loss improved from 2.5486 to 2.5485. Saving model...\n",
      "\n",
      "LOG: Epoch [1081/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6859\n",
      "Epoch [1081/2000], Avg Train Loss: 3.6859\n",
      "Epoch [1081/2000], Avg Val Loss: 2.5485\n",
      "Validation loss improved from 2.5485 to 2.5485. Saving model...\n",
      "\n",
      "LOG: Epoch [1082/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7011\n",
      "Epoch [1082/2000], Avg Train Loss: 3.7011\n",
      "Epoch [1082/2000], Avg Val Loss: 2.5486\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1083/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6805\n",
      "Epoch [1083/2000], Avg Train Loss: 3.6805\n",
      "Epoch [1083/2000], Avg Val Loss: 2.5487\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1084/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7184\n",
      "Epoch [1084/2000], Avg Train Loss: 3.7184\n",
      "Epoch [1084/2000], Avg Val Loss: 2.5488\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1085/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7630\n",
      "Epoch [1085/2000], Avg Train Loss: 3.7630\n",
      "Epoch [1085/2000], Avg Val Loss: 2.5489\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1086/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7407\n",
      "Epoch [1086/2000], Avg Train Loss: 3.7407\n",
      "Epoch [1086/2000], Avg Val Loss: 2.5489\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1087/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7122\n",
      "Epoch [1087/2000], Avg Train Loss: 3.7122\n",
      "Epoch [1087/2000], Avg Val Loss: 2.5490\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1088/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7293\n",
      "Epoch [1088/2000], Avg Train Loss: 3.7293\n",
      "Epoch [1088/2000], Avg Val Loss: 2.5491\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1089/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7420\n",
      "Epoch [1089/2000], Avg Train Loss: 3.7420\n",
      "Epoch [1089/2000], Avg Val Loss: 2.5492\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1090/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7463\n",
      "Epoch [1090/2000], Avg Train Loss: 3.7463\n",
      "Epoch [1090/2000], Avg Val Loss: 2.5494\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1091/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7358\n",
      "Epoch [1091/2000], Avg Train Loss: 3.7358\n",
      "Epoch [1091/2000], Avg Val Loss: 2.5495\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1092/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7449\n",
      "Epoch [1092/2000], Avg Train Loss: 3.7449\n",
      "Epoch [1092/2000], Avg Val Loss: 2.5497\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1093/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7094\n",
      "Epoch [1093/2000], Avg Train Loss: 3.7094\n",
      "Epoch [1093/2000], Avg Val Loss: 2.5498\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1094/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6858\n",
      "Epoch [1094/2000], Avg Train Loss: 3.6858\n",
      "Epoch [1094/2000], Avg Val Loss: 2.5499\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1095/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7271\n",
      "Epoch [1095/2000], Avg Train Loss: 3.7271\n",
      "Epoch [1095/2000], Avg Val Loss: 2.5500\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1096/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7088\n",
      "Epoch [1096/2000], Avg Train Loss: 3.7088\n",
      "Epoch [1096/2000], Avg Val Loss: 2.5501\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1097/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7365\n",
      "Epoch [1097/2000], Avg Train Loss: 3.7365\n",
      "Epoch [1097/2000], Avg Val Loss: 2.5502\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1098/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6984\n",
      "Epoch [1098/2000], Avg Train Loss: 3.6984\n",
      "Epoch [1098/2000], Avg Val Loss: 2.5504\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1099/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7158\n",
      "Epoch [1099/2000], Avg Train Loss: 3.7158\n",
      "Epoch [1099/2000], Avg Val Loss: 2.5505\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6982\n",
      "Epoch [1100/2000], Avg Train Loss: 3.6982\n",
      "Epoch [1100/2000], Avg Val Loss: 2.5507\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1101/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7180\n",
      "Epoch [1101/2000], Avg Train Loss: 3.7180\n",
      "Epoch [1101/2000], Avg Val Loss: 2.5508\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1102/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7171\n",
      "Epoch [1102/2000], Avg Train Loss: 3.7171\n",
      "Epoch [1102/2000], Avg Val Loss: 2.5510\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7062\n",
      "Epoch [1103/2000], Avg Train Loss: 3.7062\n",
      "Epoch [1103/2000], Avg Val Loss: 2.5511\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6846\n",
      "Epoch [1104/2000], Avg Train Loss: 3.6846\n",
      "Epoch [1104/2000], Avg Val Loss: 2.5511\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7195\n",
      "Epoch [1105/2000], Avg Train Loss: 3.7195\n",
      "Epoch [1105/2000], Avg Val Loss: 2.5513\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7153\n",
      "Epoch [1106/2000], Avg Train Loss: 3.7153\n",
      "Epoch [1106/2000], Avg Val Loss: 2.5514\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6725\n",
      "Epoch [1107/2000], Avg Train Loss: 3.6725\n",
      "Epoch [1107/2000], Avg Val Loss: 2.5515\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6947\n",
      "Epoch [1108/2000], Avg Train Loss: 3.6947\n",
      "Epoch [1108/2000], Avg Val Loss: 2.5516\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7161\n",
      "Epoch [1109/2000], Avg Train Loss: 3.7161\n",
      "Epoch [1109/2000], Avg Val Loss: 2.5517\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6897\n",
      "Epoch [1110/2000], Avg Train Loss: 3.6897\n",
      "Epoch [1110/2000], Avg Val Loss: 2.5517\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6859\n",
      "Epoch [1111/2000], Avg Train Loss: 3.6859\n",
      "Epoch [1111/2000], Avg Val Loss: 2.5516\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7298\n",
      "Epoch [1112/2000], Avg Train Loss: 3.7298\n",
      "Epoch [1112/2000], Avg Val Loss: 2.5516\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6996\n",
      "Epoch [1113/2000], Avg Train Loss: 3.6996\n",
      "Epoch [1113/2000], Avg Val Loss: 2.5517\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6884\n",
      "Epoch [1114/2000], Avg Train Loss: 3.6884\n",
      "Epoch [1114/2000], Avg Val Loss: 2.5518\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7192\n",
      "Epoch [1115/2000], Avg Train Loss: 3.7192\n",
      "Epoch [1115/2000], Avg Val Loss: 2.5518\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7401\n",
      "Epoch [1116/2000], Avg Train Loss: 3.7401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1116/2000], Avg Val Loss: 2.5518\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7317\n",
      "Epoch [1117/2000], Avg Train Loss: 3.7317\n",
      "Epoch [1117/2000], Avg Val Loss: 2.5519\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7339\n",
      "Epoch [1118/2000], Avg Train Loss: 3.7339\n",
      "Epoch [1118/2000], Avg Val Loss: 2.5520\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7195\n",
      "Epoch [1119/2000], Avg Train Loss: 3.7195\n",
      "Epoch [1119/2000], Avg Val Loss: 2.5520\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1120/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6966\n",
      "Epoch [1120/2000], Avg Train Loss: 3.6966\n",
      "Epoch [1120/2000], Avg Val Loss: 2.5520\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6793\n",
      "Epoch [1121/2000], Avg Train Loss: 3.6793\n",
      "Epoch [1121/2000], Avg Val Loss: 2.5519\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6612\n",
      "Epoch [1122/2000], Avg Train Loss: 3.6612\n",
      "Epoch [1122/2000], Avg Val Loss: 2.5518\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7172\n",
      "Epoch [1123/2000], Avg Train Loss: 3.7172\n",
      "Epoch [1123/2000], Avg Val Loss: 2.5518\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6823\n",
      "Epoch [1124/2000], Avg Train Loss: 3.6823\n",
      "Epoch [1124/2000], Avg Val Loss: 2.5517\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7107\n",
      "Epoch [1125/2000], Avg Train Loss: 3.7107\n",
      "Epoch [1125/2000], Avg Val Loss: 2.5517\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1126/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6948\n",
      "Epoch [1126/2000], Avg Train Loss: 3.6948\n",
      "Epoch [1126/2000], Avg Val Loss: 2.5516\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6922\n",
      "Epoch [1127/2000], Avg Train Loss: 3.6922\n",
      "Epoch [1127/2000], Avg Val Loss: 2.5515\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6892\n",
      "Epoch [1128/2000], Avg Train Loss: 3.6892\n",
      "Epoch [1128/2000], Avg Val Loss: 2.5513\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7131\n",
      "Epoch [1129/2000], Avg Train Loss: 3.7131\n",
      "Epoch [1129/2000], Avg Val Loss: 2.5512\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6966\n",
      "Epoch [1130/2000], Avg Train Loss: 3.6966\n",
      "Epoch [1130/2000], Avg Val Loss: 2.5509\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7452\n",
      "Epoch [1131/2000], Avg Train Loss: 3.7452\n",
      "Epoch [1131/2000], Avg Val Loss: 2.5506\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6970\n",
      "Epoch [1132/2000], Avg Train Loss: 3.6970\n",
      "Epoch [1132/2000], Avg Val Loss: 2.5503\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1133/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7046\n",
      "Epoch [1133/2000], Avg Train Loss: 3.7046\n",
      "Epoch [1133/2000], Avg Val Loss: 2.5500\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6635\n",
      "Epoch [1134/2000], Avg Train Loss: 3.6635\n",
      "Epoch [1134/2000], Avg Val Loss: 2.5499\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7476\n",
      "Epoch [1135/2000], Avg Train Loss: 3.7476\n",
      "Epoch [1135/2000], Avg Val Loss: 2.5497\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7053\n",
      "Epoch [1136/2000], Avg Train Loss: 3.7053\n",
      "Epoch [1136/2000], Avg Val Loss: 2.5496\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6755\n",
      "Epoch [1137/2000], Avg Train Loss: 3.6755\n",
      "Epoch [1137/2000], Avg Val Loss: 2.5495\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7268\n",
      "Epoch [1138/2000], Avg Train Loss: 3.7268\n",
      "Epoch [1138/2000], Avg Val Loss: 2.5493\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6854\n",
      "Epoch [1139/2000], Avg Train Loss: 3.6854\n",
      "Epoch [1139/2000], Avg Val Loss: 2.5490\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1140/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7188\n",
      "Epoch [1140/2000], Avg Train Loss: 3.7188\n",
      "Epoch [1140/2000], Avg Val Loss: 2.5487\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6611\n",
      "Epoch [1141/2000], Avg Train Loss: 3.6611\n",
      "Epoch [1141/2000], Avg Val Loss: 2.5486\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6713\n",
      "Epoch [1142/2000], Avg Train Loss: 3.6713\n",
      "Epoch [1142/2000], Avg Val Loss: 2.5485\n",
      "Validation loss improved from 2.5485 to 2.5485. Saving model...\n",
      "\n",
      "LOG: Epoch [1143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6870\n",
      "Epoch [1143/2000], Avg Train Loss: 3.6870\n",
      "Epoch [1143/2000], Avg Val Loss: 2.5483\n",
      "Validation loss improved from 2.5485 to 2.5483. Saving model...\n",
      "\n",
      "LOG: Epoch [1144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6948\n",
      "Epoch [1144/2000], Avg Train Loss: 3.6948\n",
      "Epoch [1144/2000], Avg Val Loss: 2.5482\n",
      "Validation loss improved from 2.5483 to 2.5482. Saving model...\n",
      "\n",
      "LOG: Epoch [1145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6939\n",
      "Epoch [1145/2000], Avg Train Loss: 3.6939\n",
      "Epoch [1145/2000], Avg Val Loss: 2.5482\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6727\n",
      "Epoch [1146/2000], Avg Train Loss: 3.6727\n",
      "Epoch [1146/2000], Avg Val Loss: 2.5482\n",
      "Validation loss improved from 2.5482 to 2.5482. Saving model...\n",
      "\n",
      "LOG: Epoch [1147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6675\n",
      "Epoch [1147/2000], Avg Train Loss: 3.6675\n",
      "Epoch [1147/2000], Avg Val Loss: 2.5482\n",
      "Validation loss improved from 2.5482 to 2.5482. Saving model...\n",
      "\n",
      "LOG: Epoch [1148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6701\n",
      "Epoch [1148/2000], Avg Train Loss: 3.6701\n",
      "Epoch [1148/2000], Avg Val Loss: 2.5481\n",
      "Validation loss improved from 2.5482 to 2.5481. Saving model...\n",
      "\n",
      "LOG: Epoch [1149/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6716\n",
      "Epoch [1149/2000], Avg Train Loss: 3.6716\n",
      "Epoch [1149/2000], Avg Val Loss: 2.5480\n",
      "Validation loss improved from 2.5481 to 2.5480. Saving model...\n",
      "\n",
      "LOG: Epoch [1150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6698\n",
      "Epoch [1150/2000], Avg Train Loss: 3.6698\n",
      "Epoch [1150/2000], Avg Val Loss: 2.5481\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6652\n",
      "Epoch [1151/2000], Avg Train Loss: 3.6652\n",
      "Epoch [1151/2000], Avg Val Loss: 2.5480\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6904\n",
      "Epoch [1152/2000], Avg Train Loss: 3.6904\n",
      "Epoch [1152/2000], Avg Val Loss: 2.5480\n",
      "Validation loss improved from 2.5480 to 2.5480. Saving model...\n",
      "\n",
      "LOG: Epoch [1153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6509\n",
      "Epoch [1153/2000], Avg Train Loss: 3.6509\n",
      "Epoch [1153/2000], Avg Val Loss: 2.5478\n",
      "Validation loss improved from 2.5480 to 2.5478. Saving model...\n",
      "\n",
      "LOG: Epoch [1154/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6605\n",
      "Epoch [1154/2000], Avg Train Loss: 3.6605\n",
      "Epoch [1154/2000], Avg Val Loss: 2.5476\n",
      "Validation loss improved from 2.5478 to 2.5476. Saving model...\n",
      "\n",
      "LOG: Epoch [1155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6892\n",
      "Epoch [1155/2000], Avg Train Loss: 3.6892\n",
      "Epoch [1155/2000], Avg Val Loss: 2.5474\n",
      "Validation loss improved from 2.5476 to 2.5474. Saving model...\n",
      "\n",
      "LOG: Epoch [1156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6825\n",
      "Epoch [1156/2000], Avg Train Loss: 3.6825\n",
      "Epoch [1156/2000], Avg Val Loss: 2.5471\n",
      "Validation loss improved from 2.5474 to 2.5471. Saving model...\n",
      "\n",
      "LOG: Epoch [1157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7089\n",
      "Epoch [1157/2000], Avg Train Loss: 3.7089\n",
      "Epoch [1157/2000], Avg Val Loss: 2.5469\n",
      "Validation loss improved from 2.5471 to 2.5469. Saving model...\n",
      "\n",
      "LOG: Epoch [1158/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6448\n",
      "Epoch [1158/2000], Avg Train Loss: 3.6448\n",
      "Epoch [1158/2000], Avg Val Loss: 2.5467\n",
      "Validation loss improved from 2.5469 to 2.5467. Saving model...\n",
      "\n",
      "LOG: Epoch [1159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6722\n",
      "Epoch [1159/2000], Avg Train Loss: 3.6722\n",
      "Epoch [1159/2000], Avg Val Loss: 2.5466\n",
      "Validation loss improved from 2.5467 to 2.5466. Saving model...\n",
      "\n",
      "LOG: Epoch [1160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6511\n",
      "Epoch [1160/2000], Avg Train Loss: 3.6511\n",
      "Epoch [1160/2000], Avg Val Loss: 2.5464\n",
      "Validation loss improved from 2.5466 to 2.5464. Saving model...\n",
      "\n",
      "LOG: Epoch [1161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6724\n",
      "Epoch [1161/2000], Avg Train Loss: 3.6724\n",
      "Epoch [1161/2000], Avg Val Loss: 2.5462\n",
      "Validation loss improved from 2.5464 to 2.5462. Saving model...\n",
      "\n",
      "LOG: Epoch [1162/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7045\n",
      "Epoch [1162/2000], Avg Train Loss: 3.7045\n",
      "Epoch [1162/2000], Avg Val Loss: 2.5460\n",
      "Validation loss improved from 2.5462 to 2.5460. Saving model...\n",
      "\n",
      "LOG: Epoch [1163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6969\n",
      "Epoch [1163/2000], Avg Train Loss: 3.6969\n",
      "Epoch [1163/2000], Avg Val Loss: 2.5458\n",
      "Validation loss improved from 2.5460 to 2.5458. Saving model...\n",
      "\n",
      "LOG: Epoch [1164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6602\n",
      "Epoch [1164/2000], Avg Train Loss: 3.6602\n",
      "Epoch [1164/2000], Avg Val Loss: 2.5455\n",
      "Validation loss improved from 2.5458 to 2.5455. Saving model...\n",
      "\n",
      "LOG: Epoch [1165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6703\n",
      "Epoch [1165/2000], Avg Train Loss: 3.6703\n",
      "Epoch [1165/2000], Avg Val Loss: 2.5455\n",
      "Validation loss improved from 2.5455 to 2.5455. Saving model...\n",
      "\n",
      "LOG: Epoch [1166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6646\n",
      "Epoch [1166/2000], Avg Train Loss: 3.6646\n",
      "Epoch [1166/2000], Avg Val Loss: 2.5454\n",
      "Validation loss improved from 2.5455 to 2.5454. Saving model...\n",
      "\n",
      "LOG: Epoch [1167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6628\n",
      "Epoch [1167/2000], Avg Train Loss: 3.6628\n",
      "Epoch [1167/2000], Avg Val Loss: 2.5453\n",
      "Validation loss improved from 2.5454 to 2.5453. Saving model...\n",
      "\n",
      "LOG: Epoch [1168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6980\n",
      "Epoch [1168/2000], Avg Train Loss: 3.6980\n",
      "Epoch [1168/2000], Avg Val Loss: 2.5453\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6715\n",
      "Epoch [1169/2000], Avg Train Loss: 3.6715\n",
      "Epoch [1169/2000], Avg Val Loss: 2.5454\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6740\n",
      "Epoch [1170/2000], Avg Train Loss: 3.6740\n",
      "Epoch [1170/2000], Avg Val Loss: 2.5454\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6522\n",
      "Epoch [1171/2000], Avg Train Loss: 3.6522\n",
      "Epoch [1171/2000], Avg Val Loss: 2.5453\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6713\n",
      "Epoch [1172/2000], Avg Train Loss: 3.6713\n",
      "Epoch [1172/2000], Avg Val Loss: 2.5453\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6780\n",
      "Epoch [1173/2000], Avg Train Loss: 3.6780\n",
      "Epoch [1173/2000], Avg Val Loss: 2.5453\n",
      "Validation loss improved from 2.5453 to 2.5453. Saving model...\n",
      "\n",
      "LOG: Epoch [1174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6442\n",
      "Epoch [1174/2000], Avg Train Loss: 3.6442\n",
      "Epoch [1174/2000], Avg Val Loss: 2.5451\n",
      "Validation loss improved from 2.5453 to 2.5451. Saving model...\n",
      "\n",
      "LOG: Epoch [1175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6983\n",
      "Epoch [1175/2000], Avg Train Loss: 3.6983\n",
      "Epoch [1175/2000], Avg Val Loss: 2.5450\n",
      "Validation loss improved from 2.5451 to 2.5450. Saving model...\n",
      "\n",
      "LOG: Epoch [1176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6670\n",
      "Epoch [1176/2000], Avg Train Loss: 3.6670\n",
      "Epoch [1176/2000], Avg Val Loss: 2.5449\n",
      "Validation loss improved from 2.5450 to 2.5449. Saving model...\n",
      "\n",
      "LOG: Epoch [1177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6687\n",
      "Epoch [1177/2000], Avg Train Loss: 3.6687\n",
      "Epoch [1177/2000], Avg Val Loss: 2.5450\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6404\n",
      "Epoch [1178/2000], Avg Train Loss: 3.6404\n",
      "Epoch [1178/2000], Avg Val Loss: 2.5450\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6171\n",
      "Epoch [1179/2000], Avg Train Loss: 3.6171\n",
      "Epoch [1179/2000], Avg Val Loss: 2.5451\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1180/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6812\n",
      "Epoch [1180/2000], Avg Train Loss: 3.6812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1180/2000], Avg Val Loss: 2.5449\n",
      "Validation loss improved from 2.5449 to 2.5449. Saving model...\n",
      "\n",
      "LOG: Epoch [1181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6685\n",
      "Epoch [1181/2000], Avg Train Loss: 3.6685\n",
      "Epoch [1181/2000], Avg Val Loss: 2.5448\n",
      "Validation loss improved from 2.5449 to 2.5448. Saving model...\n",
      "\n",
      "LOG: Epoch [1182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7077\n",
      "Epoch [1182/2000], Avg Train Loss: 3.7077\n",
      "Epoch [1182/2000], Avg Val Loss: 2.5447\n",
      "Validation loss improved from 2.5448 to 2.5447. Saving model...\n",
      "\n",
      "LOG: Epoch [1183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6746\n",
      "Epoch [1183/2000], Avg Train Loss: 3.6746\n",
      "Epoch [1183/2000], Avg Val Loss: 2.5447\n",
      "Validation loss improved from 2.5447 to 2.5447. Saving model...\n",
      "\n",
      "LOG: Epoch [1184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7015\n",
      "Epoch [1184/2000], Avg Train Loss: 3.7015\n",
      "Epoch [1184/2000], Avg Val Loss: 2.5447\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6296\n",
      "Epoch [1185/2000], Avg Train Loss: 3.6296\n",
      "Epoch [1185/2000], Avg Val Loss: 2.5449\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6855\n",
      "Epoch [1186/2000], Avg Train Loss: 3.6855\n",
      "Epoch [1186/2000], Avg Val Loss: 2.5450\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7008\n",
      "Epoch [1187/2000], Avg Train Loss: 3.7008\n",
      "Epoch [1187/2000], Avg Val Loss: 2.5451\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6973\n",
      "Epoch [1188/2000], Avg Train Loss: 3.6973\n",
      "Epoch [1188/2000], Avg Val Loss: 2.5451\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6838\n",
      "Epoch [1189/2000], Avg Train Loss: 3.6838\n",
      "Epoch [1189/2000], Avg Val Loss: 2.5452\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1190/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7133\n",
      "Epoch [1190/2000], Avg Train Loss: 3.7133\n",
      "Epoch [1190/2000], Avg Val Loss: 2.5452\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6772\n",
      "Epoch [1191/2000], Avg Train Loss: 3.6772\n",
      "Epoch [1191/2000], Avg Val Loss: 2.5451\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7033\n",
      "Epoch [1192/2000], Avg Train Loss: 3.7033\n",
      "Epoch [1192/2000], Avg Val Loss: 2.5451\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1193/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6603\n",
      "Epoch [1193/2000], Avg Train Loss: 3.6603\n",
      "Epoch [1193/2000], Avg Val Loss: 2.5452\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6760\n",
      "Epoch [1194/2000], Avg Train Loss: 3.6760\n",
      "Epoch [1194/2000], Avg Val Loss: 2.5452\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6876\n",
      "Epoch [1195/2000], Avg Train Loss: 3.6876\n",
      "Epoch [1195/2000], Avg Val Loss: 2.5452\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6231\n",
      "Epoch [1196/2000], Avg Train Loss: 3.6231\n",
      "Epoch [1196/2000], Avg Val Loss: 2.5453\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6671\n",
      "Epoch [1197/2000], Avg Train Loss: 3.6671\n",
      "Epoch [1197/2000], Avg Val Loss: 2.5454\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7061\n",
      "Epoch [1198/2000], Avg Train Loss: 3.7061\n",
      "Epoch [1198/2000], Avg Val Loss: 2.5456\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6297\n",
      "Epoch [1199/2000], Avg Train Loss: 3.6297\n",
      "Epoch [1199/2000], Avg Val Loss: 2.5457\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6689\n",
      "Epoch [1200/2000], Avg Train Loss: 3.6689\n",
      "Epoch [1200/2000], Avg Val Loss: 2.5456\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6575\n",
      "Epoch [1201/2000], Avg Train Loss: 3.6575\n",
      "Epoch [1201/2000], Avg Val Loss: 2.5454\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6882\n",
      "Epoch [1202/2000], Avg Train Loss: 3.6882\n",
      "Epoch [1202/2000], Avg Val Loss: 2.5452\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6687\n",
      "Epoch [1203/2000], Avg Train Loss: 3.6687\n",
      "Epoch [1203/2000], Avg Val Loss: 2.5451\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6535\n",
      "Epoch [1204/2000], Avg Train Loss: 3.6535\n",
      "Epoch [1204/2000], Avg Val Loss: 2.5450\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6737\n",
      "Epoch [1205/2000], Avg Train Loss: 3.6737\n",
      "Epoch [1205/2000], Avg Val Loss: 2.5450\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6411\n",
      "Epoch [1206/2000], Avg Train Loss: 3.6411\n",
      "Epoch [1206/2000], Avg Val Loss: 2.5450\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6593\n",
      "Epoch [1207/2000], Avg Train Loss: 3.6593\n",
      "Epoch [1207/2000], Avg Val Loss: 2.5449\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6642\n",
      "Epoch [1208/2000], Avg Train Loss: 3.6642\n",
      "Epoch [1208/2000], Avg Val Loss: 2.5449\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6835\n",
      "Epoch [1209/2000], Avg Train Loss: 3.6835\n",
      "Epoch [1209/2000], Avg Val Loss: 2.5448\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6715\n",
      "Epoch [1210/2000], Avg Train Loss: 3.6715\n",
      "Epoch [1210/2000], Avg Val Loss: 2.5447\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6686\n",
      "Epoch [1211/2000], Avg Train Loss: 3.6686\n",
      "Epoch [1211/2000], Avg Val Loss: 2.5446\n",
      "Validation loss improved from 2.5447 to 2.5446. Saving model...\n",
      "\n",
      "LOG: Epoch [1212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6784\n",
      "Epoch [1212/2000], Avg Train Loss: 3.6784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1212/2000], Avg Val Loss: 2.5445\n",
      "Validation loss improved from 2.5446 to 2.5445. Saving model...\n",
      "\n",
      "LOG: Epoch [1213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6276\n",
      "Epoch [1213/2000], Avg Train Loss: 3.6276\n",
      "Epoch [1213/2000], Avg Val Loss: 2.5443\n",
      "Validation loss improved from 2.5445 to 2.5443. Saving model...\n",
      "\n",
      "LOG: Epoch [1214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6557\n",
      "Epoch [1214/2000], Avg Train Loss: 3.6557\n",
      "Epoch [1214/2000], Avg Val Loss: 2.5443\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6525\n",
      "Epoch [1215/2000], Avg Train Loss: 3.6525\n",
      "Epoch [1215/2000], Avg Val Loss: 2.5443\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1216/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6787\n",
      "Epoch [1216/2000], Avg Train Loss: 3.6787\n",
      "Epoch [1216/2000], Avg Val Loss: 2.5443\n",
      "Validation loss improved from 2.5443 to 2.5443. Saving model...\n",
      "\n",
      "LOG: Epoch [1217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6686\n",
      "Epoch [1217/2000], Avg Train Loss: 3.6686\n",
      "Epoch [1217/2000], Avg Val Loss: 2.5441\n",
      "Validation loss improved from 2.5443 to 2.5441. Saving model...\n",
      "\n",
      "LOG: Epoch [1218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6304\n",
      "Epoch [1218/2000], Avg Train Loss: 3.6304\n",
      "Epoch [1218/2000], Avg Val Loss: 2.5439\n",
      "Validation loss improved from 2.5441 to 2.5439. Saving model...\n",
      "\n",
      "LOG: Epoch [1219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6222\n",
      "Epoch [1219/2000], Avg Train Loss: 3.6222\n",
      "Epoch [1219/2000], Avg Val Loss: 2.5437\n",
      "Validation loss improved from 2.5439 to 2.5437. Saving model...\n",
      "\n",
      "LOG: Epoch [1220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6326\n",
      "Epoch [1220/2000], Avg Train Loss: 3.6326\n",
      "Epoch [1220/2000], Avg Val Loss: 2.5436\n",
      "Validation loss improved from 2.5437 to 2.5436. Saving model...\n",
      "\n",
      "LOG: Epoch [1221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6466\n",
      "Epoch [1221/2000], Avg Train Loss: 3.6466\n",
      "Epoch [1221/2000], Avg Val Loss: 2.5436\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6789\n",
      "Epoch [1222/2000], Avg Train Loss: 3.6789\n",
      "Epoch [1222/2000], Avg Val Loss: 2.5435\n",
      "Validation loss improved from 2.5436 to 2.5435. Saving model...\n",
      "\n",
      "LOG: Epoch [1223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6926\n",
      "Epoch [1223/2000], Avg Train Loss: 3.6926\n",
      "Epoch [1223/2000], Avg Val Loss: 2.5436\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6507\n",
      "Epoch [1224/2000], Avg Train Loss: 3.6507\n",
      "Epoch [1224/2000], Avg Val Loss: 2.5437\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6819\n",
      "Epoch [1225/2000], Avg Train Loss: 3.6819\n",
      "Epoch [1225/2000], Avg Val Loss: 2.5437\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1226/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6867\n",
      "Epoch [1226/2000], Avg Train Loss: 3.6867\n",
      "Epoch [1226/2000], Avg Val Loss: 2.5440\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6044\n",
      "Epoch [1227/2000], Avg Train Loss: 3.6044\n",
      "Epoch [1227/2000], Avg Val Loss: 2.5442\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6025\n",
      "Epoch [1228/2000], Avg Train Loss: 3.6025\n",
      "Epoch [1228/2000], Avg Val Loss: 2.5443\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6702\n",
      "Epoch [1229/2000], Avg Train Loss: 3.6702\n",
      "Epoch [1229/2000], Avg Val Loss: 2.5444\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6543\n",
      "Epoch [1230/2000], Avg Train Loss: 3.6543\n",
      "Epoch [1230/2000], Avg Val Loss: 2.5444\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6285\n",
      "Epoch [1231/2000], Avg Train Loss: 3.6285\n",
      "Epoch [1231/2000], Avg Val Loss: 2.5446\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6462\n",
      "Epoch [1232/2000], Avg Train Loss: 3.6462\n",
      "Epoch [1232/2000], Avg Val Loss: 2.5444\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6369\n",
      "Epoch [1233/2000], Avg Train Loss: 3.6369\n",
      "Epoch [1233/2000], Avg Val Loss: 2.5445\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6474\n",
      "Epoch [1234/2000], Avg Train Loss: 3.6474\n",
      "Epoch [1234/2000], Avg Val Loss: 2.5445\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1235/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6675\n",
      "Epoch [1235/2000], Avg Train Loss: 3.6675\n",
      "Epoch [1235/2000], Avg Val Loss: 2.5443\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6875\n",
      "Epoch [1236/2000], Avg Train Loss: 3.6875\n",
      "Epoch [1236/2000], Avg Val Loss: 2.5441\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5891\n",
      "Epoch [1237/2000], Avg Train Loss: 3.5891\n",
      "Epoch [1237/2000], Avg Val Loss: 2.5440\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6415\n",
      "Epoch [1238/2000], Avg Train Loss: 3.6415\n",
      "Epoch [1238/2000], Avg Val Loss: 2.5438\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6527\n",
      "Epoch [1239/2000], Avg Train Loss: 3.6527\n",
      "Epoch [1239/2000], Avg Val Loss: 2.5436\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6387\n",
      "Epoch [1240/2000], Avg Train Loss: 3.6387\n",
      "Epoch [1240/2000], Avg Val Loss: 2.5435\n",
      "Validation loss improved from 2.5435 to 2.5435. Saving model...\n",
      "\n",
      "LOG: Epoch [1241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6523\n",
      "Epoch [1241/2000], Avg Train Loss: 3.6523\n",
      "Epoch [1241/2000], Avg Val Loss: 2.5435\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1242/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6259\n",
      "Epoch [1242/2000], Avg Train Loss: 3.6259\n",
      "Epoch [1242/2000], Avg Val Loss: 2.5436\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6387\n",
      "Epoch [1243/2000], Avg Train Loss: 3.6387\n",
      "Epoch [1243/2000], Avg Val Loss: 2.5437\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7030\n",
      "Epoch [1244/2000], Avg Train Loss: 3.7030\n",
      "Epoch [1244/2000], Avg Val Loss: 2.5438\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6568\n",
      "Epoch [1245/2000], Avg Train Loss: 3.6568\n",
      "Epoch [1245/2000], Avg Val Loss: 2.5440\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1246/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6334\n",
      "Epoch [1246/2000], Avg Train Loss: 3.6334\n",
      "Epoch [1246/2000], Avg Val Loss: 2.5442\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6141\n",
      "Epoch [1247/2000], Avg Train Loss: 3.6141\n",
      "Epoch [1247/2000], Avg Val Loss: 2.5443\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1248/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6412\n",
      "Epoch [1248/2000], Avg Train Loss: 3.6412\n",
      "Epoch [1248/2000], Avg Val Loss: 2.5443\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6818\n",
      "Epoch [1249/2000], Avg Train Loss: 3.6818\n",
      "Epoch [1249/2000], Avg Val Loss: 2.5443\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6966\n",
      "Epoch [1250/2000], Avg Train Loss: 3.6966\n",
      "Epoch [1250/2000], Avg Val Loss: 2.5441\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6563\n",
      "Epoch [1251/2000], Avg Train Loss: 3.6563\n",
      "Epoch [1251/2000], Avg Val Loss: 2.5440\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6160\n",
      "Epoch [1252/2000], Avg Train Loss: 3.6160\n",
      "Epoch [1252/2000], Avg Val Loss: 2.5438\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6346\n",
      "Epoch [1253/2000], Avg Train Loss: 3.6346\n",
      "Epoch [1253/2000], Avg Val Loss: 2.5437\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6456\n",
      "Epoch [1254/2000], Avg Train Loss: 3.6456\n",
      "Epoch [1254/2000], Avg Val Loss: 2.5436\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6334\n",
      "Epoch [1255/2000], Avg Train Loss: 3.6334\n",
      "Epoch [1255/2000], Avg Val Loss: 2.5436\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6437\n",
      "Epoch [1256/2000], Avg Train Loss: 3.6437\n",
      "Epoch [1256/2000], Avg Val Loss: 2.5436\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6327\n",
      "Epoch [1257/2000], Avg Train Loss: 3.6327\n",
      "Epoch [1257/2000], Avg Val Loss: 2.5435\n",
      "Validation loss improved from 2.5435 to 2.5435. Saving model...\n",
      "\n",
      "LOG: Epoch [1258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6681\n",
      "Epoch [1258/2000], Avg Train Loss: 3.6681\n",
      "Epoch [1258/2000], Avg Val Loss: 2.5435\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6248\n",
      "Epoch [1259/2000], Avg Train Loss: 3.6248\n",
      "Epoch [1259/2000], Avg Val Loss: 2.5436\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6354\n",
      "Epoch [1260/2000], Avg Train Loss: 3.6354\n",
      "Epoch [1260/2000], Avg Val Loss: 2.5438\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6584\n",
      "Epoch [1261/2000], Avg Train Loss: 3.6584\n",
      "Epoch [1261/2000], Avg Val Loss: 2.5438\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6490\n",
      "Epoch [1262/2000], Avg Train Loss: 3.6490\n",
      "Epoch [1262/2000], Avg Val Loss: 2.5439\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6215\n",
      "Epoch [1263/2000], Avg Train Loss: 3.6215\n",
      "Epoch [1263/2000], Avg Val Loss: 2.5440\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6463\n",
      "Epoch [1264/2000], Avg Train Loss: 3.6463\n",
      "Epoch [1264/2000], Avg Val Loss: 2.5441\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1265/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6359\n",
      "Epoch [1265/2000], Avg Train Loss: 3.6359\n",
      "Epoch [1265/2000], Avg Val Loss: 2.5441\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6203\n",
      "Epoch [1266/2000], Avg Train Loss: 3.6203\n",
      "Epoch [1266/2000], Avg Val Loss: 2.5441\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1267/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6065\n",
      "Epoch [1267/2000], Avg Train Loss: 3.6065\n",
      "Epoch [1267/2000], Avg Val Loss: 2.5443\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6300\n",
      "Epoch [1268/2000], Avg Train Loss: 3.6300\n",
      "Epoch [1268/2000], Avg Val Loss: 2.5445\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6549\n",
      "Epoch [1269/2000], Avg Train Loss: 3.6549\n",
      "Epoch [1269/2000], Avg Val Loss: 2.5448\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6476\n",
      "Epoch [1270/2000], Avg Train Loss: 3.6476\n",
      "Epoch [1270/2000], Avg Val Loss: 2.5453\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6035\n",
      "Epoch [1271/2000], Avg Train Loss: 3.6035\n",
      "Epoch [1271/2000], Avg Val Loss: 2.5456\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6267\n",
      "Epoch [1272/2000], Avg Train Loss: 3.6267\n",
      "Epoch [1272/2000], Avg Val Loss: 2.5459\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5967\n",
      "Epoch [1273/2000], Avg Train Loss: 3.5967\n",
      "Epoch [1273/2000], Avg Val Loss: 2.5462\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1274/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6289\n",
      "Epoch [1274/2000], Avg Train Loss: 3.6289\n",
      "Epoch [1274/2000], Avg Val Loss: 2.5464\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1275/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6180\n",
      "Epoch [1275/2000], Avg Train Loss: 3.6180\n",
      "Epoch [1275/2000], Avg Val Loss: 2.5465\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6263\n",
      "Epoch [1276/2000], Avg Train Loss: 3.6263\n",
      "Epoch [1276/2000], Avg Val Loss: 2.5467\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6170\n",
      "Epoch [1277/2000], Avg Train Loss: 3.6170\n",
      "Epoch [1277/2000], Avg Val Loss: 2.5467\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1278/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6086\n",
      "Epoch [1278/2000], Avg Train Loss: 3.6086\n",
      "Epoch [1278/2000], Avg Val Loss: 2.5468\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6413\n",
      "Epoch [1279/2000], Avg Train Loss: 3.6413\n",
      "Epoch [1279/2000], Avg Val Loss: 2.5469\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6403\n",
      "Epoch [1280/2000], Avg Train Loss: 3.6403\n",
      "Epoch [1280/2000], Avg Val Loss: 2.5468\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6318\n",
      "Epoch [1281/2000], Avg Train Loss: 3.6318\n",
      "Epoch [1281/2000], Avg Val Loss: 2.5468\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6177\n",
      "Epoch [1282/2000], Avg Train Loss: 3.6177\n",
      "Epoch [1282/2000], Avg Val Loss: 2.5469\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6214\n",
      "Epoch [1283/2000], Avg Train Loss: 3.6214\n",
      "Epoch [1283/2000], Avg Val Loss: 2.5470\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1284/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6047\n",
      "Epoch [1284/2000], Avg Train Loss: 3.6047\n",
      "Epoch [1284/2000], Avg Val Loss: 2.5470\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6509\n",
      "Epoch [1285/2000], Avg Train Loss: 3.6509\n",
      "Epoch [1285/2000], Avg Val Loss: 2.5470\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1286/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6631\n",
      "Epoch [1286/2000], Avg Train Loss: 3.6631\n",
      "Epoch [1286/2000], Avg Val Loss: 2.5469\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6248\n",
      "Epoch [1287/2000], Avg Train Loss: 3.6248\n",
      "Epoch [1287/2000], Avg Val Loss: 2.5468\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6094\n",
      "Epoch [1288/2000], Avg Train Loss: 3.6094\n",
      "Epoch [1288/2000], Avg Val Loss: 2.5468\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6317\n",
      "Epoch [1289/2000], Avg Train Loss: 3.6317\n",
      "Epoch [1289/2000], Avg Val Loss: 2.5467\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6294\n",
      "Epoch [1290/2000], Avg Train Loss: 3.6294\n",
      "Epoch [1290/2000], Avg Val Loss: 2.5466\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6307\n",
      "Epoch [1291/2000], Avg Train Loss: 3.6307\n",
      "Epoch [1291/2000], Avg Val Loss: 2.5466\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5898\n",
      "Epoch [1292/2000], Avg Train Loss: 3.5898\n",
      "Epoch [1292/2000], Avg Val Loss: 2.5465\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5881\n",
      "Epoch [1293/2000], Avg Train Loss: 3.5881\n",
      "Epoch [1293/2000], Avg Val Loss: 2.5464\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5866\n",
      "Epoch [1294/2000], Avg Train Loss: 3.5866\n",
      "Epoch [1294/2000], Avg Val Loss: 2.5462\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6216\n",
      "Epoch [1295/2000], Avg Train Loss: 3.6216\n",
      "Epoch [1295/2000], Avg Val Loss: 2.5461\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6349\n",
      "Epoch [1296/2000], Avg Train Loss: 3.6349\n",
      "Epoch [1296/2000], Avg Val Loss: 2.5461\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6229\n",
      "Epoch [1297/2000], Avg Train Loss: 3.6229\n",
      "Epoch [1297/2000], Avg Val Loss: 2.5461\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6335\n",
      "Epoch [1298/2000], Avg Train Loss: 3.6335\n",
      "Epoch [1298/2000], Avg Val Loss: 2.5461\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6040\n",
      "Epoch [1299/2000], Avg Train Loss: 3.6040\n",
      "Epoch [1299/2000], Avg Val Loss: 2.5459\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6628\n",
      "Epoch [1300/2000], Avg Train Loss: 3.6628\n",
      "Epoch [1300/2000], Avg Val Loss: 2.5457\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6708\n",
      "Epoch [1301/2000], Avg Train Loss: 3.6708\n",
      "Epoch [1301/2000], Avg Val Loss: 2.5456\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1302/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6226\n",
      "Epoch [1302/2000], Avg Train Loss: 3.6226\n",
      "Epoch [1302/2000], Avg Val Loss: 2.5453\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5921\n",
      "Epoch [1303/2000], Avg Train Loss: 3.5921\n",
      "Epoch [1303/2000], Avg Val Loss: 2.5452\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6554\n",
      "Epoch [1304/2000], Avg Train Loss: 3.6554\n",
      "Epoch [1304/2000], Avg Val Loss: 2.5451\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6136\n",
      "Epoch [1305/2000], Avg Train Loss: 3.6136\n",
      "Epoch [1305/2000], Avg Val Loss: 2.5449\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6500\n",
      "Epoch [1306/2000], Avg Train Loss: 3.6500\n",
      "Epoch [1306/2000], Avg Val Loss: 2.5449\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1307/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5842\n",
      "Epoch [1307/2000], Avg Train Loss: 3.5842\n",
      "Epoch [1307/2000], Avg Val Loss: 2.5448\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6098\n",
      "Epoch [1308/2000], Avg Train Loss: 3.6098\n",
      "Epoch [1308/2000], Avg Val Loss: 2.5447\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6301\n",
      "Epoch [1309/2000], Avg Train Loss: 3.6301\n",
      "Epoch [1309/2000], Avg Val Loss: 2.5446\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6072\n",
      "Epoch [1310/2000], Avg Train Loss: 3.6072\n",
      "Epoch [1310/2000], Avg Val Loss: 2.5447\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6335\n",
      "Epoch [1311/2000], Avg Train Loss: 3.6335\n",
      "Epoch [1311/2000], Avg Val Loss: 2.5448\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6041\n",
      "Epoch [1312/2000], Avg Train Loss: 3.6041\n",
      "Epoch [1312/2000], Avg Val Loss: 2.5449\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1313/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6101\n",
      "Epoch [1313/2000], Avg Train Loss: 3.6101\n",
      "Epoch [1313/2000], Avg Val Loss: 2.5449\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5688\n",
      "Epoch [1314/2000], Avg Train Loss: 3.5688\n",
      "Epoch [1314/2000], Avg Val Loss: 2.5448\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6303\n",
      "Epoch [1315/2000], Avg Train Loss: 3.6303\n",
      "Epoch [1315/2000], Avg Val Loss: 2.5446\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6001\n",
      "Epoch [1316/2000], Avg Train Loss: 3.6001\n",
      "Epoch [1316/2000], Avg Val Loss: 2.5444\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6227\n",
      "Epoch [1317/2000], Avg Train Loss: 3.6227\n",
      "Epoch [1317/2000], Avg Val Loss: 2.5441\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5617\n",
      "Epoch [1318/2000], Avg Train Loss: 3.5617\n",
      "Epoch [1318/2000], Avg Val Loss: 2.5438\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1319/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5640\n",
      "Epoch [1319/2000], Avg Train Loss: 3.5640\n",
      "Epoch [1319/2000], Avg Val Loss: 2.5436\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6213\n",
      "Epoch [1320/2000], Avg Train Loss: 3.6213\n",
      "Epoch [1320/2000], Avg Val Loss: 2.5434\n",
      "Validation loss improved from 2.5435 to 2.5434. Saving model...\n",
      "\n",
      "LOG: Epoch [1321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6287\n",
      "Epoch [1321/2000], Avg Train Loss: 3.6287\n",
      "Epoch [1321/2000], Avg Val Loss: 2.5429\n",
      "Validation loss improved from 2.5434 to 2.5429. Saving model...\n",
      "\n",
      "LOG: Epoch [1322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6013\n",
      "Epoch [1322/2000], Avg Train Loss: 3.6013\n",
      "Epoch [1322/2000], Avg Val Loss: 2.5424\n",
      "Validation loss improved from 2.5429 to 2.5424. Saving model...\n",
      "\n",
      "LOG: Epoch [1323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5746\n",
      "Epoch [1323/2000], Avg Train Loss: 3.5746\n",
      "Epoch [1323/2000], Avg Val Loss: 2.5419\n",
      "Validation loss improved from 2.5424 to 2.5419. Saving model...\n",
      "\n",
      "LOG: Epoch [1324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6081\n",
      "Epoch [1324/2000], Avg Train Loss: 3.6081\n",
      "Epoch [1324/2000], Avg Val Loss: 2.5414\n",
      "Validation loss improved from 2.5419 to 2.5414. Saving model...\n",
      "\n",
      "LOG: Epoch [1325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5854\n",
      "Epoch [1325/2000], Avg Train Loss: 3.5854\n",
      "Epoch [1325/2000], Avg Val Loss: 2.5411\n",
      "Validation loss improved from 2.5414 to 2.5411. Saving model...\n",
      "\n",
      "LOG: Epoch [1326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6283\n",
      "Epoch [1326/2000], Avg Train Loss: 3.6283\n",
      "Epoch [1326/2000], Avg Val Loss: 2.5408\n",
      "Validation loss improved from 2.5411 to 2.5408. Saving model...\n",
      "\n",
      "LOG: Epoch [1327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6194\n",
      "Epoch [1327/2000], Avg Train Loss: 3.6194\n",
      "Epoch [1327/2000], Avg Val Loss: 2.5405\n",
      "Validation loss improved from 2.5408 to 2.5405. Saving model...\n",
      "\n",
      "LOG: Epoch [1328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5910\n",
      "Epoch [1328/2000], Avg Train Loss: 3.5910\n",
      "Epoch [1328/2000], Avg Val Loss: 2.5401\n",
      "Validation loss improved from 2.5405 to 2.5401. Saving model...\n",
      "\n",
      "LOG: Epoch [1329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6100\n",
      "Epoch [1329/2000], Avg Train Loss: 3.6100\n",
      "Epoch [1329/2000], Avg Val Loss: 2.5398\n",
      "Validation loss improved from 2.5401 to 2.5398. Saving model...\n",
      "\n",
      "LOG: Epoch [1330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6119\n",
      "Epoch [1330/2000], Avg Train Loss: 3.6119\n",
      "Epoch [1330/2000], Avg Val Loss: 2.5395\n",
      "Validation loss improved from 2.5398 to 2.5395. Saving model...\n",
      "\n",
      "LOG: Epoch [1331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5793\n",
      "Epoch [1331/2000], Avg Train Loss: 3.5793\n",
      "Epoch [1331/2000], Avg Val Loss: 2.5392\n",
      "Validation loss improved from 2.5395 to 2.5392. Saving model...\n",
      "\n",
      "LOG: Epoch [1332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5917\n",
      "Epoch [1332/2000], Avg Train Loss: 3.5917\n",
      "Epoch [1332/2000], Avg Val Loss: 2.5390\n",
      "Validation loss improved from 2.5392 to 2.5390. Saving model...\n",
      "\n",
      "LOG: Epoch [1333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6157\n",
      "Epoch [1333/2000], Avg Train Loss: 3.6157\n",
      "Epoch [1333/2000], Avg Val Loss: 2.5387\n",
      "Validation loss improved from 2.5390 to 2.5387. Saving model...\n",
      "\n",
      "LOG: Epoch [1334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6436\n",
      "Epoch [1334/2000], Avg Train Loss: 3.6436\n",
      "Epoch [1334/2000], Avg Val Loss: 2.5385\n",
      "Validation loss improved from 2.5387 to 2.5385. Saving model...\n",
      "\n",
      "LOG: Epoch [1335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5697\n",
      "Epoch [1335/2000], Avg Train Loss: 3.5697\n",
      "Epoch [1335/2000], Avg Val Loss: 2.5384\n",
      "Validation loss improved from 2.5385 to 2.5384. Saving model...\n",
      "\n",
      "LOG: Epoch [1336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5808\n",
      "Epoch [1336/2000], Avg Train Loss: 3.5808\n",
      "Epoch [1336/2000], Avg Val Loss: 2.5384\n",
      "Validation loss improved from 2.5384 to 2.5384. Saving model...\n",
      "\n",
      "LOG: Epoch [1337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5788\n",
      "Epoch [1337/2000], Avg Train Loss: 3.5788\n",
      "Epoch [1337/2000], Avg Val Loss: 2.5383\n",
      "Validation loss improved from 2.5384 to 2.5383. Saving model...\n",
      "\n",
      "LOG: Epoch [1338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5622\n",
      "Epoch [1338/2000], Avg Train Loss: 3.5622\n",
      "Epoch [1338/2000], Avg Val Loss: 2.5383\n",
      "Validation loss improved from 2.5383 to 2.5383. Saving model...\n",
      "\n",
      "LOG: Epoch [1339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6188\n",
      "Epoch [1339/2000], Avg Train Loss: 3.6188\n",
      "Epoch [1339/2000], Avg Val Loss: 2.5383\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6204\n",
      "Epoch [1340/2000], Avg Train Loss: 3.6204\n",
      "Epoch [1340/2000], Avg Val Loss: 2.5384\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1341/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.6136\n",
      "Epoch [1341/2000], Avg Train Loss: 3.6136\n",
      "Epoch [1341/2000], Avg Val Loss: 2.5386\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6023\n",
      "Epoch [1342/2000], Avg Train Loss: 3.6023\n",
      "Epoch [1342/2000], Avg Val Loss: 2.5386\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1343/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5996\n",
      "Epoch [1343/2000], Avg Train Loss: 3.5996\n",
      "Epoch [1343/2000], Avg Val Loss: 2.5388\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5863\n",
      "Epoch [1344/2000], Avg Train Loss: 3.5863\n",
      "Epoch [1344/2000], Avg Val Loss: 2.5388\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5756\n",
      "Epoch [1345/2000], Avg Train Loss: 3.5756\n",
      "Epoch [1345/2000], Avg Val Loss: 2.5388\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5812\n",
      "Epoch [1346/2000], Avg Train Loss: 3.5812\n",
      "Epoch [1346/2000], Avg Val Loss: 2.5389\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6186\n",
      "Epoch [1347/2000], Avg Train Loss: 3.6186\n",
      "Epoch [1347/2000], Avg Val Loss: 2.5391\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5658\n",
      "Epoch [1348/2000], Avg Train Loss: 3.5658\n",
      "Epoch [1348/2000], Avg Val Loss: 2.5394\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5785\n",
      "Epoch [1349/2000], Avg Train Loss: 3.5785\n",
      "Epoch [1349/2000], Avg Val Loss: 2.5397\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6243\n",
      "Epoch [1350/2000], Avg Train Loss: 3.6243\n",
      "Epoch [1350/2000], Avg Val Loss: 2.5399\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5862\n",
      "Epoch [1351/2000], Avg Train Loss: 3.5862\n",
      "Epoch [1351/2000], Avg Val Loss: 2.5401\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6250\n",
      "Epoch [1352/2000], Avg Train Loss: 3.6250\n",
      "Epoch [1352/2000], Avg Val Loss: 2.5403\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5891\n",
      "Epoch [1353/2000], Avg Train Loss: 3.5891\n",
      "Epoch [1353/2000], Avg Val Loss: 2.5404\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1354/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5872\n",
      "Epoch [1354/2000], Avg Train Loss: 3.5872\n",
      "Epoch [1354/2000], Avg Val Loss: 2.5406\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5374\n",
      "Epoch [1355/2000], Avg Train Loss: 3.5374\n",
      "Epoch [1355/2000], Avg Val Loss: 2.5408\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6222\n",
      "Epoch [1356/2000], Avg Train Loss: 3.6222\n",
      "Epoch [1356/2000], Avg Val Loss: 2.5409\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6281\n",
      "Epoch [1357/2000], Avg Train Loss: 3.6281\n",
      "Epoch [1357/2000], Avg Val Loss: 2.5410\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6459\n",
      "Epoch [1358/2000], Avg Train Loss: 3.6459\n",
      "Epoch [1358/2000], Avg Val Loss: 2.5412\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5793\n",
      "Epoch [1359/2000], Avg Train Loss: 3.5793\n",
      "Epoch [1359/2000], Avg Val Loss: 2.5414\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5870\n",
      "Epoch [1360/2000], Avg Train Loss: 3.5870\n",
      "Epoch [1360/2000], Avg Val Loss: 2.5417\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5852\n",
      "Epoch [1361/2000], Avg Train Loss: 3.5852\n",
      "Epoch [1361/2000], Avg Val Loss: 2.5420\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1362/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5812\n",
      "Epoch [1362/2000], Avg Train Loss: 3.5812\n",
      "Epoch [1362/2000], Avg Val Loss: 2.5422\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6037\n",
      "Epoch [1363/2000], Avg Train Loss: 3.6037\n",
      "Epoch [1363/2000], Avg Val Loss: 2.5427\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1364/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5963\n",
      "Epoch [1364/2000], Avg Train Loss: 3.5963\n",
      "Epoch [1364/2000], Avg Val Loss: 2.5433\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6048\n",
      "Epoch [1365/2000], Avg Train Loss: 3.6048\n",
      "Epoch [1365/2000], Avg Val Loss: 2.5438\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5969\n",
      "Epoch [1366/2000], Avg Train Loss: 3.5969\n",
      "Epoch [1366/2000], Avg Val Loss: 2.5443\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6377\n",
      "Epoch [1367/2000], Avg Train Loss: 3.6377\n",
      "Epoch [1367/2000], Avg Val Loss: 2.5448\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5938\n",
      "Epoch [1368/2000], Avg Train Loss: 3.5938\n",
      "Epoch [1368/2000], Avg Val Loss: 2.5452\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5442\n",
      "Epoch [1369/2000], Avg Train Loss: 3.5442\n",
      "Epoch [1369/2000], Avg Val Loss: 2.5455\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6114\n",
      "Epoch [1370/2000], Avg Train Loss: 3.6114\n",
      "Epoch [1370/2000], Avg Val Loss: 2.5456\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6261\n",
      "Epoch [1371/2000], Avg Train Loss: 3.6261\n",
      "Epoch [1371/2000], Avg Val Loss: 2.5458\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5566\n",
      "Epoch [1372/2000], Avg Train Loss: 3.5566\n",
      "Epoch [1372/2000], Avg Val Loss: 2.5458\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1373/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5913\n",
      "Epoch [1373/2000], Avg Train Loss: 3.5913\n",
      "Epoch [1373/2000], Avg Val Loss: 2.5458\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5787\n",
      "Epoch [1374/2000], Avg Train Loss: 3.5787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1374/2000], Avg Val Loss: 2.5457\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6203\n",
      "Epoch [1375/2000], Avg Train Loss: 3.6203\n",
      "Epoch [1375/2000], Avg Val Loss: 2.5457\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5790\n",
      "Epoch [1376/2000], Avg Train Loss: 3.5790\n",
      "Epoch [1376/2000], Avg Val Loss: 2.5456\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5741\n",
      "Epoch [1377/2000], Avg Train Loss: 3.5741\n",
      "Epoch [1377/2000], Avg Val Loss: 2.5453\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5798\n",
      "Epoch [1378/2000], Avg Train Loss: 3.5798\n",
      "Epoch [1378/2000], Avg Val Loss: 2.5449\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5685\n",
      "Epoch [1379/2000], Avg Train Loss: 3.5685\n",
      "Epoch [1379/2000], Avg Val Loss: 2.5446\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5483\n",
      "Epoch [1380/2000], Avg Train Loss: 3.5483\n",
      "Epoch [1380/2000], Avg Val Loss: 2.5442\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5389\n",
      "Epoch [1381/2000], Avg Train Loss: 3.5389\n",
      "Epoch [1381/2000], Avg Val Loss: 2.5439\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5516\n",
      "Epoch [1382/2000], Avg Train Loss: 3.5516\n",
      "Epoch [1382/2000], Avg Val Loss: 2.5435\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5188\n",
      "Epoch [1383/2000], Avg Train Loss: 3.5188\n",
      "Epoch [1383/2000], Avg Val Loss: 2.5430\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5542\n",
      "Epoch [1384/2000], Avg Train Loss: 3.5542\n",
      "Epoch [1384/2000], Avg Val Loss: 2.5426\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6023\n",
      "Epoch [1385/2000], Avg Train Loss: 3.6023\n",
      "Epoch [1385/2000], Avg Val Loss: 2.5421\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5583\n",
      "Epoch [1386/2000], Avg Train Loss: 3.5583\n",
      "Epoch [1386/2000], Avg Val Loss: 2.5416\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5616\n",
      "Epoch [1387/2000], Avg Train Loss: 3.5616\n",
      "Epoch [1387/2000], Avg Val Loss: 2.5412\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6284\n",
      "Epoch [1388/2000], Avg Train Loss: 3.6284\n",
      "Epoch [1388/2000], Avg Val Loss: 2.5410\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5811\n",
      "Epoch [1389/2000], Avg Train Loss: 3.5811\n",
      "Epoch [1389/2000], Avg Val Loss: 2.5407\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5641\n",
      "Epoch [1390/2000], Avg Train Loss: 3.5641\n",
      "Epoch [1390/2000], Avg Val Loss: 2.5404\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6244\n",
      "Epoch [1391/2000], Avg Train Loss: 3.6244\n",
      "Epoch [1391/2000], Avg Val Loss: 2.5403\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5992\n",
      "Epoch [1392/2000], Avg Train Loss: 3.5992\n",
      "Epoch [1392/2000], Avg Val Loss: 2.5400\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5577\n",
      "Epoch [1393/2000], Avg Train Loss: 3.5577\n",
      "Epoch [1393/2000], Avg Val Loss: 2.5397\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5502\n",
      "Epoch [1394/2000], Avg Train Loss: 3.5502\n",
      "Epoch [1394/2000], Avg Val Loss: 2.5394\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5598\n",
      "Epoch [1395/2000], Avg Train Loss: 3.5598\n",
      "Epoch [1395/2000], Avg Val Loss: 2.5393\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5857\n",
      "Epoch [1396/2000], Avg Train Loss: 3.5857\n",
      "Epoch [1396/2000], Avg Val Loss: 2.5390\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1397/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5471\n",
      "Epoch [1397/2000], Avg Train Loss: 3.5471\n",
      "Epoch [1397/2000], Avg Val Loss: 2.5388\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1398/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5538\n",
      "Epoch [1398/2000], Avg Train Loss: 3.5538\n",
      "Epoch [1398/2000], Avg Val Loss: 2.5387\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5373\n",
      "Epoch [1399/2000], Avg Train Loss: 3.5373\n",
      "Epoch [1399/2000], Avg Val Loss: 2.5386\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5448\n",
      "Epoch [1400/2000], Avg Train Loss: 3.5448\n",
      "Epoch [1400/2000], Avg Val Loss: 2.5384\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5385\n",
      "Epoch [1401/2000], Avg Train Loss: 3.5385\n",
      "Epoch [1401/2000], Avg Val Loss: 2.5383\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5771\n",
      "Epoch [1402/2000], Avg Train Loss: 3.5771\n",
      "Epoch [1402/2000], Avg Val Loss: 2.5383\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6259\n",
      "Epoch [1403/2000], Avg Train Loss: 3.6259\n",
      "Epoch [1403/2000], Avg Val Loss: 2.5383\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5848\n",
      "Epoch [1404/2000], Avg Train Loss: 3.5848\n",
      "Epoch [1404/2000], Avg Val Loss: 2.5383\n",
      "Validation loss improved from 2.5383 to 2.5383. Saving model...\n",
      "\n",
      "LOG: Epoch [1405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5750\n",
      "Epoch [1405/2000], Avg Train Loss: 3.5750\n",
      "Epoch [1405/2000], Avg Val Loss: 2.5383\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5630\n",
      "Epoch [1406/2000], Avg Train Loss: 3.5630\n",
      "Epoch [1406/2000], Avg Val Loss: 2.5383\n",
      "Validation loss improved from 2.5383 to 2.5383. Saving model...\n",
      "\n",
      "LOG: Epoch [1407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6288\n",
      "Epoch [1407/2000], Avg Train Loss: 3.6288\n",
      "Epoch [1407/2000], Avg Val Loss: 2.5384\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5972\n",
      "Epoch [1408/2000], Avg Train Loss: 3.5972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1408/2000], Avg Val Loss: 2.5386\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1409/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5817\n",
      "Epoch [1409/2000], Avg Train Loss: 3.5817\n",
      "Epoch [1409/2000], Avg Val Loss: 2.5388\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5622\n",
      "Epoch [1410/2000], Avg Train Loss: 3.5622\n",
      "Epoch [1410/2000], Avg Val Loss: 2.5389\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5545\n",
      "Epoch [1411/2000], Avg Train Loss: 3.5545\n",
      "Epoch [1411/2000], Avg Val Loss: 2.5389\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5743\n",
      "Epoch [1412/2000], Avg Train Loss: 3.5743\n",
      "Epoch [1412/2000], Avg Val Loss: 2.5390\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5531\n",
      "Epoch [1413/2000], Avg Train Loss: 3.5531\n",
      "Epoch [1413/2000], Avg Val Loss: 2.5389\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5396\n",
      "Epoch [1414/2000], Avg Train Loss: 3.5396\n",
      "Epoch [1414/2000], Avg Val Loss: 2.5388\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6032\n",
      "Epoch [1415/2000], Avg Train Loss: 3.6032\n",
      "Epoch [1415/2000], Avg Val Loss: 2.5388\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1416/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5403\n",
      "Epoch [1416/2000], Avg Train Loss: 3.5403\n",
      "Epoch [1416/2000], Avg Val Loss: 2.5387\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5722\n",
      "Epoch [1417/2000], Avg Train Loss: 3.5722\n",
      "Epoch [1417/2000], Avg Val Loss: 2.5387\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1418/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5638\n",
      "Epoch [1418/2000], Avg Train Loss: 3.5638\n",
      "Epoch [1418/2000], Avg Val Loss: 2.5387\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5455\n",
      "Epoch [1419/2000], Avg Train Loss: 3.5455\n",
      "Epoch [1419/2000], Avg Val Loss: 2.5387\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5718\n",
      "Epoch [1420/2000], Avg Train Loss: 3.5718\n",
      "Epoch [1420/2000], Avg Val Loss: 2.5385\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5964\n",
      "Epoch [1421/2000], Avg Train Loss: 3.5964\n",
      "Epoch [1421/2000], Avg Val Loss: 2.5381\n",
      "Validation loss improved from 2.5383 to 2.5381. Saving model...\n",
      "\n",
      "LOG: Epoch [1422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5377\n",
      "Epoch [1422/2000], Avg Train Loss: 3.5377\n",
      "Epoch [1422/2000], Avg Val Loss: 2.5377\n",
      "Validation loss improved from 2.5381 to 2.5377. Saving model...\n",
      "\n",
      "LOG: Epoch [1423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5765\n",
      "Epoch [1423/2000], Avg Train Loss: 3.5765\n",
      "Epoch [1423/2000], Avg Val Loss: 2.5374\n",
      "Validation loss improved from 2.5377 to 2.5374. Saving model...\n",
      "\n",
      "LOG: Epoch [1424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6135\n",
      "Epoch [1424/2000], Avg Train Loss: 3.6135\n",
      "Epoch [1424/2000], Avg Val Loss: 2.5373\n",
      "Validation loss improved from 2.5374 to 2.5373. Saving model...\n",
      "\n",
      "LOG: Epoch [1425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5844\n",
      "Epoch [1425/2000], Avg Train Loss: 3.5844\n",
      "Epoch [1425/2000], Avg Val Loss: 2.5371\n",
      "Validation loss improved from 2.5373 to 2.5371. Saving model...\n",
      "\n",
      "LOG: Epoch [1426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5345\n",
      "Epoch [1426/2000], Avg Train Loss: 3.5345\n",
      "Epoch [1426/2000], Avg Val Loss: 2.5370\n",
      "Validation loss improved from 2.5371 to 2.5370. Saving model...\n",
      "\n",
      "LOG: Epoch [1427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5727\n",
      "Epoch [1427/2000], Avg Train Loss: 3.5727\n",
      "Epoch [1427/2000], Avg Val Loss: 2.5370\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5394\n",
      "Epoch [1428/2000], Avg Train Loss: 3.5394\n",
      "Epoch [1428/2000], Avg Val Loss: 2.5370\n",
      "Validation loss improved from 2.5370 to 2.5370. Saving model...\n",
      "\n",
      "LOG: Epoch [1429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5514\n",
      "Epoch [1429/2000], Avg Train Loss: 3.5514\n",
      "Epoch [1429/2000], Avg Val Loss: 2.5369\n",
      "Validation loss improved from 2.5370 to 2.5369. Saving model...\n",
      "\n",
      "LOG: Epoch [1430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5719\n",
      "Epoch [1430/2000], Avg Train Loss: 3.5719\n",
      "Epoch [1430/2000], Avg Val Loss: 2.5367\n",
      "Validation loss improved from 2.5369 to 2.5367. Saving model...\n",
      "\n",
      "LOG: Epoch [1431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5824\n",
      "Epoch [1431/2000], Avg Train Loss: 3.5824\n",
      "Epoch [1431/2000], Avg Val Loss: 2.5367\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5327\n",
      "Epoch [1432/2000], Avg Train Loss: 3.5327\n",
      "Epoch [1432/2000], Avg Val Loss: 2.5367\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5736\n",
      "Epoch [1433/2000], Avg Train Loss: 3.5736\n",
      "Epoch [1433/2000], Avg Val Loss: 2.5365\n",
      "Validation loss improved from 2.5367 to 2.5365. Saving model...\n",
      "\n",
      "LOG: Epoch [1434/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5408\n",
      "Epoch [1434/2000], Avg Train Loss: 3.5408\n",
      "Epoch [1434/2000], Avg Val Loss: 2.5363\n",
      "Validation loss improved from 2.5365 to 2.5363. Saving model...\n",
      "\n",
      "LOG: Epoch [1435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5660\n",
      "Epoch [1435/2000], Avg Train Loss: 3.5660\n",
      "Epoch [1435/2000], Avg Val Loss: 2.5362\n",
      "Validation loss improved from 2.5363 to 2.5362. Saving model...\n",
      "\n",
      "LOG: Epoch [1436/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5761\n",
      "Epoch [1436/2000], Avg Train Loss: 3.5761\n",
      "Epoch [1436/2000], Avg Val Loss: 2.5361\n",
      "Validation loss improved from 2.5362 to 2.5361. Saving model...\n",
      "\n",
      "LOG: Epoch [1437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5637\n",
      "Epoch [1437/2000], Avg Train Loss: 3.5637\n",
      "Epoch [1437/2000], Avg Val Loss: 2.5361\n",
      "Validation loss improved from 2.5361 to 2.5361. Saving model...\n",
      "\n",
      "LOG: Epoch [1438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5880\n",
      "Epoch [1438/2000], Avg Train Loss: 3.5880\n",
      "Epoch [1438/2000], Avg Val Loss: 2.5360\n",
      "Validation loss improved from 2.5361 to 2.5360. Saving model...\n",
      "\n",
      "LOG: Epoch [1439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5683\n",
      "Epoch [1439/2000], Avg Train Loss: 3.5683\n",
      "Epoch [1439/2000], Avg Val Loss: 2.5361\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5603\n",
      "Epoch [1440/2000], Avg Train Loss: 3.5603\n",
      "Epoch [1440/2000], Avg Val Loss: 2.5363\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5523\n",
      "Epoch [1441/2000], Avg Train Loss: 3.5523\n",
      "Epoch [1441/2000], Avg Val Loss: 2.5366\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1442/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5721\n",
      "Epoch [1442/2000], Avg Train Loss: 3.5721\n",
      "Epoch [1442/2000], Avg Val Loss: 2.5369\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5668\n",
      "Epoch [1443/2000], Avg Train Loss: 3.5668\n",
      "Epoch [1443/2000], Avg Val Loss: 2.5373\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5668\n",
      "Epoch [1444/2000], Avg Train Loss: 3.5668\n",
      "Epoch [1444/2000], Avg Val Loss: 2.5376\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5570\n",
      "Epoch [1445/2000], Avg Train Loss: 3.5570\n",
      "Epoch [1445/2000], Avg Val Loss: 2.5378\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5778\n",
      "Epoch [1446/2000], Avg Train Loss: 3.5778\n",
      "Epoch [1446/2000], Avg Val Loss: 2.5381\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5175\n",
      "Epoch [1447/2000], Avg Train Loss: 3.5175\n",
      "Epoch [1447/2000], Avg Val Loss: 2.5383\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5581\n",
      "Epoch [1448/2000], Avg Train Loss: 3.5581\n",
      "Epoch [1448/2000], Avg Val Loss: 2.5388\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5492\n",
      "Epoch [1449/2000], Avg Train Loss: 3.5492\n",
      "Epoch [1449/2000], Avg Val Loss: 2.5391\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5178\n",
      "Epoch [1450/2000], Avg Train Loss: 3.5178\n",
      "Epoch [1450/2000], Avg Val Loss: 2.5394\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1451/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5657\n",
      "Epoch [1451/2000], Avg Train Loss: 3.5657\n",
      "Epoch [1451/2000], Avg Val Loss: 2.5396\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5083\n",
      "Epoch [1452/2000], Avg Train Loss: 3.5083\n",
      "Epoch [1452/2000], Avg Val Loss: 2.5397\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5180\n",
      "Epoch [1453/2000], Avg Train Loss: 3.5180\n",
      "Epoch [1453/2000], Avg Val Loss: 2.5398\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1454/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5803\n",
      "Epoch [1454/2000], Avg Train Loss: 3.5803\n",
      "Epoch [1454/2000], Avg Val Loss: 2.5398\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5636\n",
      "Epoch [1455/2000], Avg Train Loss: 3.5636\n",
      "Epoch [1455/2000], Avg Val Loss: 2.5398\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5330\n",
      "Epoch [1456/2000], Avg Train Loss: 3.5330\n",
      "Epoch [1456/2000], Avg Val Loss: 2.5399\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5295\n",
      "Epoch [1457/2000], Avg Train Loss: 3.5295\n",
      "Epoch [1457/2000], Avg Val Loss: 2.5402\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5411\n",
      "Epoch [1458/2000], Avg Train Loss: 3.5411\n",
      "Epoch [1458/2000], Avg Val Loss: 2.5404\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5553\n",
      "Epoch [1459/2000], Avg Train Loss: 3.5553\n",
      "Epoch [1459/2000], Avg Val Loss: 2.5404\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5519\n",
      "Epoch [1460/2000], Avg Train Loss: 3.5519\n",
      "Epoch [1460/2000], Avg Val Loss: 2.5404\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5079\n",
      "Epoch [1461/2000], Avg Train Loss: 3.5079\n",
      "Epoch [1461/2000], Avg Val Loss: 2.5403\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5154\n",
      "Epoch [1462/2000], Avg Train Loss: 3.5154\n",
      "Epoch [1462/2000], Avg Val Loss: 2.5403\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5337\n",
      "Epoch [1463/2000], Avg Train Loss: 3.5337\n",
      "Epoch [1463/2000], Avg Val Loss: 2.5402\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5157\n",
      "Epoch [1464/2000], Avg Train Loss: 3.5157\n",
      "Epoch [1464/2000], Avg Val Loss: 2.5401\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5422\n",
      "Epoch [1465/2000], Avg Train Loss: 3.5422\n",
      "Epoch [1465/2000], Avg Val Loss: 2.5400\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5295\n",
      "Epoch [1466/2000], Avg Train Loss: 3.5295\n",
      "Epoch [1466/2000], Avg Val Loss: 2.5398\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5624\n",
      "Epoch [1467/2000], Avg Train Loss: 3.5624\n",
      "Epoch [1467/2000], Avg Val Loss: 2.5396\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5236\n",
      "Epoch [1468/2000], Avg Train Loss: 3.5236\n",
      "Epoch [1468/2000], Avg Val Loss: 2.5393\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5075\n",
      "Epoch [1469/2000], Avg Train Loss: 3.5075\n",
      "Epoch [1469/2000], Avg Val Loss: 2.5391\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5711\n",
      "Epoch [1470/2000], Avg Train Loss: 3.5711\n",
      "Epoch [1470/2000], Avg Val Loss: 2.5388\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5719\n",
      "Epoch [1471/2000], Avg Train Loss: 3.5719\n",
      "Epoch [1471/2000], Avg Val Loss: 2.5385\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5358\n",
      "Epoch [1472/2000], Avg Train Loss: 3.5358\n",
      "Epoch [1472/2000], Avg Val Loss: 2.5381\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5269\n",
      "Epoch [1473/2000], Avg Train Loss: 3.5269\n",
      "Epoch [1473/2000], Avg Val Loss: 2.5377\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5241\n",
      "Epoch [1474/2000], Avg Train Loss: 3.5241\n",
      "Epoch [1474/2000], Avg Val Loss: 2.5373\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1475/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4986\n",
      "Epoch [1475/2000], Avg Train Loss: 3.4986\n",
      "Epoch [1475/2000], Avg Val Loss: 2.5369\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5519\n",
      "Epoch [1476/2000], Avg Train Loss: 3.5519\n",
      "Epoch [1476/2000], Avg Val Loss: 2.5365\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5595\n",
      "Epoch [1477/2000], Avg Train Loss: 3.5595\n",
      "Epoch [1477/2000], Avg Val Loss: 2.5361\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1478/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5110\n",
      "Epoch [1478/2000], Avg Train Loss: 3.5110\n",
      "Epoch [1478/2000], Avg Val Loss: 2.5357\n",
      "Validation loss improved from 2.5360 to 2.5357. Saving model...\n",
      "\n",
      "LOG: Epoch [1479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5498\n",
      "Epoch [1479/2000], Avg Train Loss: 3.5498\n",
      "Epoch [1479/2000], Avg Val Loss: 2.5354\n",
      "Validation loss improved from 2.5357 to 2.5354. Saving model...\n",
      "\n",
      "LOG: Epoch [1480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5228\n",
      "Epoch [1480/2000], Avg Train Loss: 3.5228\n",
      "Epoch [1480/2000], Avg Val Loss: 2.5351\n",
      "Validation loss improved from 2.5354 to 2.5351. Saving model...\n",
      "\n",
      "LOG: Epoch [1481/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5294\n",
      "Epoch [1481/2000], Avg Train Loss: 3.5294\n",
      "Epoch [1481/2000], Avg Val Loss: 2.5349\n",
      "Validation loss improved from 2.5351 to 2.5349. Saving model...\n",
      "\n",
      "LOG: Epoch [1482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5379\n",
      "Epoch [1482/2000], Avg Train Loss: 3.5379\n",
      "Epoch [1482/2000], Avg Val Loss: 2.5348\n",
      "Validation loss improved from 2.5349 to 2.5348. Saving model...\n",
      "\n",
      "LOG: Epoch [1483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5297\n",
      "Epoch [1483/2000], Avg Train Loss: 3.5297\n",
      "Epoch [1483/2000], Avg Val Loss: 2.5347\n",
      "Validation loss improved from 2.5348 to 2.5347. Saving model...\n",
      "\n",
      "LOG: Epoch [1484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5427\n",
      "Epoch [1484/2000], Avg Train Loss: 3.5427\n",
      "Epoch [1484/2000], Avg Val Loss: 2.5347\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5558\n",
      "Epoch [1485/2000], Avg Train Loss: 3.5558\n",
      "Epoch [1485/2000], Avg Val Loss: 2.5349\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5150\n",
      "Epoch [1486/2000], Avg Train Loss: 3.5150\n",
      "Epoch [1486/2000], Avg Val Loss: 2.5351\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4987\n",
      "Epoch [1487/2000], Avg Train Loss: 3.4987\n",
      "Epoch [1487/2000], Avg Val Loss: 2.5355\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4998\n",
      "Epoch [1488/2000], Avg Train Loss: 3.4998\n",
      "Epoch [1488/2000], Avg Val Loss: 2.5359\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5321\n",
      "Epoch [1489/2000], Avg Train Loss: 3.5321\n",
      "Epoch [1489/2000], Avg Val Loss: 2.5364\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5181\n",
      "Epoch [1490/2000], Avg Train Loss: 3.5181\n",
      "Epoch [1490/2000], Avg Val Loss: 2.5368\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5210\n",
      "Epoch [1491/2000], Avg Train Loss: 3.5210\n",
      "Epoch [1491/2000], Avg Val Loss: 2.5373\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5410\n",
      "Epoch [1492/2000], Avg Train Loss: 3.5410\n",
      "Epoch [1492/2000], Avg Val Loss: 2.5379\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4961\n",
      "Epoch [1493/2000], Avg Train Loss: 3.4961\n",
      "Epoch [1493/2000], Avg Val Loss: 2.5385\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5194\n",
      "Epoch [1494/2000], Avg Train Loss: 3.5194\n",
      "Epoch [1494/2000], Avg Val Loss: 2.5390\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4938\n",
      "Epoch [1495/2000], Avg Train Loss: 3.4938\n",
      "Epoch [1495/2000], Avg Val Loss: 2.5396\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1496/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5823\n",
      "Epoch [1496/2000], Avg Train Loss: 3.5823\n",
      "Epoch [1496/2000], Avg Val Loss: 2.5400\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1497/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5290\n",
      "Epoch [1497/2000], Avg Train Loss: 3.5290\n",
      "Epoch [1497/2000], Avg Val Loss: 2.5406\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1498/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5763\n",
      "Epoch [1498/2000], Avg Train Loss: 3.5763\n",
      "Epoch [1498/2000], Avg Val Loss: 2.5410\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5300\n",
      "Epoch [1499/2000], Avg Train Loss: 3.5300\n",
      "Epoch [1499/2000], Avg Val Loss: 2.5413\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5073\n",
      "Epoch [1500/2000], Avg Train Loss: 3.5073\n",
      "Epoch [1500/2000], Avg Val Loss: 2.5416\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5695\n",
      "Epoch [1501/2000], Avg Train Loss: 3.5695\n",
      "Epoch [1501/2000], Avg Val Loss: 2.5418\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1502/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5837\n",
      "Epoch [1502/2000], Avg Train Loss: 3.5837\n",
      "Epoch [1502/2000], Avg Val Loss: 2.5419\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1503/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5335\n",
      "Epoch [1503/2000], Avg Train Loss: 3.5335\n",
      "Epoch [1503/2000], Avg Val Loss: 2.5421\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1504/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5195\n",
      "Epoch [1504/2000], Avg Train Loss: 3.5195\n",
      "Epoch [1504/2000], Avg Val Loss: 2.5421\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1505/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5336\n",
      "Epoch [1505/2000], Avg Train Loss: 3.5336\n",
      "Epoch [1505/2000], Avg Val Loss: 2.5418\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6027\n",
      "Epoch [1506/2000], Avg Train Loss: 3.6027\n",
      "Epoch [1506/2000], Avg Val Loss: 2.5415\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5349\n",
      "Epoch [1507/2000], Avg Train Loss: 3.5349\n",
      "Epoch [1507/2000], Avg Val Loss: 2.5413\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1508/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5237\n",
      "Epoch [1508/2000], Avg Train Loss: 3.5237\n",
      "Epoch [1508/2000], Avg Val Loss: 2.5411\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1509/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5077\n",
      "Epoch [1509/2000], Avg Train Loss: 3.5077\n",
      "Epoch [1509/2000], Avg Val Loss: 2.5409\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5072\n",
      "Epoch [1510/2000], Avg Train Loss: 3.5072\n",
      "Epoch [1510/2000], Avg Val Loss: 2.5406\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5186\n",
      "Epoch [1511/2000], Avg Train Loss: 3.5186\n",
      "Epoch [1511/2000], Avg Val Loss: 2.5404\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1512/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5094\n",
      "Epoch [1512/2000], Avg Train Loss: 3.5094\n",
      "Epoch [1512/2000], Avg Val Loss: 2.5399\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1513/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5496\n",
      "Epoch [1513/2000], Avg Train Loss: 3.5496\n",
      "Epoch [1513/2000], Avg Val Loss: 2.5395\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5160\n",
      "Epoch [1514/2000], Avg Train Loss: 3.5160\n",
      "Epoch [1514/2000], Avg Val Loss: 2.5391\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5133\n",
      "Epoch [1515/2000], Avg Train Loss: 3.5133\n",
      "Epoch [1515/2000], Avg Val Loss: 2.5387\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5257\n",
      "Epoch [1516/2000], Avg Train Loss: 3.5257\n",
      "Epoch [1516/2000], Avg Val Loss: 2.5383\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1517/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5452\n",
      "Epoch [1517/2000], Avg Train Loss: 3.5452\n",
      "Epoch [1517/2000], Avg Val Loss: 2.5379\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5475\n",
      "Epoch [1518/2000], Avg Train Loss: 3.5475\n",
      "Epoch [1518/2000], Avg Val Loss: 2.5374\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5186\n",
      "Epoch [1519/2000], Avg Train Loss: 3.5186\n",
      "Epoch [1519/2000], Avg Val Loss: 2.5371\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5570\n",
      "Epoch [1520/2000], Avg Train Loss: 3.5570\n",
      "Epoch [1520/2000], Avg Val Loss: 2.5367\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5140\n",
      "Epoch [1521/2000], Avg Train Loss: 3.5140\n",
      "Epoch [1521/2000], Avg Val Loss: 2.5365\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5121\n",
      "Epoch [1522/2000], Avg Train Loss: 3.5121\n",
      "Epoch [1522/2000], Avg Val Loss: 2.5362\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5513\n",
      "Epoch [1523/2000], Avg Train Loss: 3.5513\n",
      "Epoch [1523/2000], Avg Val Loss: 2.5358\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5237\n",
      "Epoch [1524/2000], Avg Train Loss: 3.5237\n",
      "Epoch [1524/2000], Avg Val Loss: 2.5353\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4722\n",
      "Epoch [1525/2000], Avg Train Loss: 3.4722\n",
      "Epoch [1525/2000], Avg Val Loss: 2.5348\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5126\n",
      "Epoch [1526/2000], Avg Train Loss: 3.5126\n",
      "Epoch [1526/2000], Avg Val Loss: 2.5342\n",
      "Validation loss improved from 2.5347 to 2.5342. Saving model...\n",
      "\n",
      "LOG: Epoch [1527/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5190\n",
      "Epoch [1527/2000], Avg Train Loss: 3.5190\n",
      "Epoch [1527/2000], Avg Val Loss: 2.5338\n",
      "Validation loss improved from 2.5342 to 2.5338. Saving model...\n",
      "\n",
      "LOG: Epoch [1528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4746\n",
      "Epoch [1528/2000], Avg Train Loss: 3.4746\n",
      "Epoch [1528/2000], Avg Val Loss: 2.5334\n",
      "Validation loss improved from 2.5338 to 2.5334. Saving model...\n",
      "\n",
      "LOG: Epoch [1529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5212\n",
      "Epoch [1529/2000], Avg Train Loss: 3.5212\n",
      "Epoch [1529/2000], Avg Val Loss: 2.5329\n",
      "Validation loss improved from 2.5334 to 2.5329. Saving model...\n",
      "\n",
      "LOG: Epoch [1530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4834\n",
      "Epoch [1530/2000], Avg Train Loss: 3.4834\n",
      "Epoch [1530/2000], Avg Val Loss: 2.5325\n",
      "Validation loss improved from 2.5329 to 2.5325. Saving model...\n",
      "\n",
      "LOG: Epoch [1531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5032\n",
      "Epoch [1531/2000], Avg Train Loss: 3.5032\n",
      "Epoch [1531/2000], Avg Val Loss: 2.5320\n",
      "Validation loss improved from 2.5325 to 2.5320. Saving model...\n",
      "\n",
      "LOG: Epoch [1532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4976\n",
      "Epoch [1532/2000], Avg Train Loss: 3.4976\n",
      "Epoch [1532/2000], Avg Val Loss: 2.5314\n",
      "Validation loss improved from 2.5320 to 2.5314. Saving model...\n",
      "\n",
      "LOG: Epoch [1533/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5137\n",
      "Epoch [1533/2000], Avg Train Loss: 3.5137\n",
      "Epoch [1533/2000], Avg Val Loss: 2.5311\n",
      "Validation loss improved from 2.5314 to 2.5311. Saving model...\n",
      "\n",
      "LOG: Epoch [1534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5288\n",
      "Epoch [1534/2000], Avg Train Loss: 3.5288\n",
      "Epoch [1534/2000], Avg Val Loss: 2.5308\n",
      "Validation loss improved from 2.5311 to 2.5308. Saving model...\n",
      "\n",
      "LOG: Epoch [1535/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5383\n",
      "Epoch [1535/2000], Avg Train Loss: 3.5383\n",
      "Epoch [1535/2000], Avg Val Loss: 2.5305\n",
      "Validation loss improved from 2.5308 to 2.5305. Saving model...\n",
      "\n",
      "LOG: Epoch [1536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5047\n",
      "Epoch [1536/2000], Avg Train Loss: 3.5047\n",
      "Epoch [1536/2000], Avg Val Loss: 2.5305\n",
      "Validation loss improved from 2.5305 to 2.5305. Saving model...\n",
      "\n",
      "LOG: Epoch [1537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5059\n",
      "Epoch [1537/2000], Avg Train Loss: 3.5059\n",
      "Epoch [1537/2000], Avg Val Loss: 2.5305\n",
      "Validation loss improved from 2.5305 to 2.5305. Saving model...\n",
      "\n",
      "LOG: Epoch [1538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4729\n",
      "Epoch [1538/2000], Avg Train Loss: 3.4729\n",
      "Epoch [1538/2000], Avg Val Loss: 2.5304\n",
      "Validation loss improved from 2.5305 to 2.5304. Saving model...\n",
      "\n",
      "LOG: Epoch [1539/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4795\n",
      "Epoch [1539/2000], Avg Train Loss: 3.4795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1539/2000], Avg Val Loss: 2.5302\n",
      "Validation loss improved from 2.5304 to 2.5302. Saving model...\n",
      "\n",
      "LOG: Epoch [1540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5048\n",
      "Epoch [1540/2000], Avg Train Loss: 3.5048\n",
      "Epoch [1540/2000], Avg Val Loss: 2.5301\n",
      "Validation loss improved from 2.5302 to 2.5301. Saving model...\n",
      "\n",
      "LOG: Epoch [1541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5034\n",
      "Epoch [1541/2000], Avg Train Loss: 3.5034\n",
      "Epoch [1541/2000], Avg Val Loss: 2.5302\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1542/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5154\n",
      "Epoch [1542/2000], Avg Train Loss: 3.5154\n",
      "Epoch [1542/2000], Avg Val Loss: 2.5305\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1543/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4957\n",
      "Epoch [1543/2000], Avg Train Loss: 3.4957\n",
      "Epoch [1543/2000], Avg Val Loss: 2.5307\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4750\n",
      "Epoch [1544/2000], Avg Train Loss: 3.4750\n",
      "Epoch [1544/2000], Avg Val Loss: 2.5309\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1545/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4678\n",
      "Epoch [1545/2000], Avg Train Loss: 3.4678\n",
      "Epoch [1545/2000], Avg Val Loss: 2.5310\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4920\n",
      "Epoch [1546/2000], Avg Train Loss: 3.4920\n",
      "Epoch [1546/2000], Avg Val Loss: 2.5313\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1547/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5234\n",
      "Epoch [1547/2000], Avg Train Loss: 3.5234\n",
      "Epoch [1547/2000], Avg Val Loss: 2.5317\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1548/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4941\n",
      "Epoch [1548/2000], Avg Train Loss: 3.4941\n",
      "Epoch [1548/2000], Avg Val Loss: 2.5319\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1549/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5083\n",
      "Epoch [1549/2000], Avg Train Loss: 3.5083\n",
      "Epoch [1549/2000], Avg Val Loss: 2.5320\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5102\n",
      "Epoch [1550/2000], Avg Train Loss: 3.5102\n",
      "Epoch [1550/2000], Avg Val Loss: 2.5321\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1551/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5027\n",
      "Epoch [1551/2000], Avg Train Loss: 3.5027\n",
      "Epoch [1551/2000], Avg Val Loss: 2.5321\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5065\n",
      "Epoch [1552/2000], Avg Train Loss: 3.5065\n",
      "Epoch [1552/2000], Avg Val Loss: 2.5321\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1553/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5077\n",
      "Epoch [1553/2000], Avg Train Loss: 3.5077\n",
      "Epoch [1553/2000], Avg Val Loss: 2.5320\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5216\n",
      "Epoch [1554/2000], Avg Train Loss: 3.5216\n",
      "Epoch [1554/2000], Avg Val Loss: 2.5321\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4809\n",
      "Epoch [1555/2000], Avg Train Loss: 3.4809\n",
      "Epoch [1555/2000], Avg Val Loss: 2.5321\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5179\n",
      "Epoch [1556/2000], Avg Train Loss: 3.5179\n",
      "Epoch [1556/2000], Avg Val Loss: 2.5321\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5233\n",
      "Epoch [1557/2000], Avg Train Loss: 3.5233\n",
      "Epoch [1557/2000], Avg Val Loss: 2.5321\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5248\n",
      "Epoch [1558/2000], Avg Train Loss: 3.5248\n",
      "Epoch [1558/2000], Avg Val Loss: 2.5324\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4822\n",
      "Epoch [1559/2000], Avg Train Loss: 3.4822\n",
      "Epoch [1559/2000], Avg Val Loss: 2.5326\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1560/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4782\n",
      "Epoch [1560/2000], Avg Train Loss: 3.4782\n",
      "Epoch [1560/2000], Avg Val Loss: 2.5329\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5316\n",
      "Epoch [1561/2000], Avg Train Loss: 3.5316\n",
      "Epoch [1561/2000], Avg Val Loss: 2.5330\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1562/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5047\n",
      "Epoch [1562/2000], Avg Train Loss: 3.5047\n",
      "Epoch [1562/2000], Avg Val Loss: 2.5332\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5132\n",
      "Epoch [1563/2000], Avg Train Loss: 3.5132\n",
      "Epoch [1563/2000], Avg Val Loss: 2.5335\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1564/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5004\n",
      "Epoch [1564/2000], Avg Train Loss: 3.5004\n",
      "Epoch [1564/2000], Avg Val Loss: 2.5337\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4817\n",
      "Epoch [1565/2000], Avg Train Loss: 3.4817\n",
      "Epoch [1565/2000], Avg Val Loss: 2.5340\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4748\n",
      "Epoch [1566/2000], Avg Train Loss: 3.4748\n",
      "Epoch [1566/2000], Avg Val Loss: 2.5343\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5029\n",
      "Epoch [1567/2000], Avg Train Loss: 3.5029\n",
      "Epoch [1567/2000], Avg Val Loss: 2.5346\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5157\n",
      "Epoch [1568/2000], Avg Train Loss: 3.5157\n",
      "Epoch [1568/2000], Avg Val Loss: 2.5349\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1569/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4880\n",
      "Epoch [1569/2000], Avg Train Loss: 3.4880\n",
      "Epoch [1569/2000], Avg Val Loss: 2.5353\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5325\n",
      "Epoch [1570/2000], Avg Train Loss: 3.5325\n",
      "Epoch [1570/2000], Avg Val Loss: 2.5356\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1571/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5163\n",
      "Epoch [1571/2000], Avg Train Loss: 3.5163\n",
      "Epoch [1571/2000], Avg Val Loss: 2.5358\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4962\n",
      "Epoch [1572/2000], Avg Train Loss: 3.4962\n",
      "Epoch [1572/2000], Avg Val Loss: 2.5360\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1573/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4951\n",
      "Epoch [1573/2000], Avg Train Loss: 3.4951\n",
      "Epoch [1573/2000], Avg Val Loss: 2.5361\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4671\n",
      "Epoch [1574/2000], Avg Train Loss: 3.4671\n",
      "Epoch [1574/2000], Avg Val Loss: 2.5362\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4945\n",
      "Epoch [1575/2000], Avg Train Loss: 3.4945\n",
      "Epoch [1575/2000], Avg Val Loss: 2.5363\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4665\n",
      "Epoch [1576/2000], Avg Train Loss: 3.4665\n",
      "Epoch [1576/2000], Avg Val Loss: 2.5363\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1577/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4797\n",
      "Epoch [1577/2000], Avg Train Loss: 3.4797\n",
      "Epoch [1577/2000], Avg Val Loss: 2.5363\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1578/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4726\n",
      "Epoch [1578/2000], Avg Train Loss: 3.4726\n",
      "Epoch [1578/2000], Avg Val Loss: 2.5362\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5084\n",
      "Epoch [1579/2000], Avg Train Loss: 3.5084\n",
      "Epoch [1579/2000], Avg Val Loss: 2.5361\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1580/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4873\n",
      "Epoch [1580/2000], Avg Train Loss: 3.4873\n",
      "Epoch [1580/2000], Avg Val Loss: 2.5361\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5197\n",
      "Epoch [1581/2000], Avg Train Loss: 3.5197\n",
      "Epoch [1581/2000], Avg Val Loss: 2.5359\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1582/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4912\n",
      "Epoch [1582/2000], Avg Train Loss: 3.4912\n",
      "Epoch [1582/2000], Avg Val Loss: 2.5356\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4965\n",
      "Epoch [1583/2000], Avg Train Loss: 3.4965\n",
      "Epoch [1583/2000], Avg Val Loss: 2.5355\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1584/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4899\n",
      "Epoch [1584/2000], Avg Train Loss: 3.4899\n",
      "Epoch [1584/2000], Avg Val Loss: 2.5354\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4596\n",
      "Epoch [1585/2000], Avg Train Loss: 3.4596\n",
      "Epoch [1585/2000], Avg Val Loss: 2.5355\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1586/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5268\n",
      "Epoch [1586/2000], Avg Train Loss: 3.5268\n",
      "Epoch [1586/2000], Avg Val Loss: 2.5355\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5143\n",
      "Epoch [1587/2000], Avg Train Loss: 3.5143\n",
      "Epoch [1587/2000], Avg Val Loss: 2.5355\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1588/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5120\n",
      "Epoch [1588/2000], Avg Train Loss: 3.5120\n",
      "Epoch [1588/2000], Avg Val Loss: 2.5354\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5216\n",
      "Epoch [1589/2000], Avg Train Loss: 3.5216\n",
      "Epoch [1589/2000], Avg Val Loss: 2.5352\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4891\n",
      "Epoch [1590/2000], Avg Train Loss: 3.4891\n",
      "Epoch [1590/2000], Avg Val Loss: 2.5351\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4976\n",
      "Epoch [1591/2000], Avg Train Loss: 3.4976\n",
      "Epoch [1591/2000], Avg Val Loss: 2.5350\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5056\n",
      "Epoch [1592/2000], Avg Train Loss: 3.5056\n",
      "Epoch [1592/2000], Avg Val Loss: 2.5348\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1593/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4772\n",
      "Epoch [1593/2000], Avg Train Loss: 3.4772\n",
      "Epoch [1593/2000], Avg Val Loss: 2.5345\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1594/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4702\n",
      "Epoch [1594/2000], Avg Train Loss: 3.4702\n",
      "Epoch [1594/2000], Avg Val Loss: 2.5342\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5351\n",
      "Epoch [1595/2000], Avg Train Loss: 3.5351\n",
      "Epoch [1595/2000], Avg Val Loss: 2.5341\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4767\n",
      "Epoch [1596/2000], Avg Train Loss: 3.4767\n",
      "Epoch [1596/2000], Avg Val Loss: 2.5340\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4803\n",
      "Epoch [1597/2000], Avg Train Loss: 3.4803\n",
      "Epoch [1597/2000], Avg Val Loss: 2.5340\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1598/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4710\n",
      "Epoch [1598/2000], Avg Train Loss: 3.4710\n",
      "Epoch [1598/2000], Avg Val Loss: 2.5339\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1599/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4662\n",
      "Epoch [1599/2000], Avg Train Loss: 3.4662\n",
      "Epoch [1599/2000], Avg Val Loss: 2.5340\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1600/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5039\n",
      "Epoch [1600/2000], Avg Train Loss: 3.5039\n",
      "Epoch [1600/2000], Avg Val Loss: 2.5340\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1601/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4781\n",
      "Epoch [1601/2000], Avg Train Loss: 3.4781\n",
      "Epoch [1601/2000], Avg Val Loss: 2.5341\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4895\n",
      "Epoch [1602/2000], Avg Train Loss: 3.4895\n",
      "Epoch [1602/2000], Avg Val Loss: 2.5343\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1603/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4976\n",
      "Epoch [1603/2000], Avg Train Loss: 3.4976\n",
      "Epoch [1603/2000], Avg Val Loss: 2.5343\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1604/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5188\n",
      "Epoch [1604/2000], Avg Train Loss: 3.5188\n",
      "Epoch [1604/2000], Avg Val Loss: 2.5341\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1605/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4756\n",
      "Epoch [1605/2000], Avg Train Loss: 3.4756\n",
      "Epoch [1605/2000], Avg Val Loss: 2.5339\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1606/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4512\n",
      "Epoch [1606/2000], Avg Train Loss: 3.4512\n",
      "Epoch [1606/2000], Avg Val Loss: 2.5338\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1607/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4915\n",
      "Epoch [1607/2000], Avg Train Loss: 3.4915\n",
      "Epoch [1607/2000], Avg Val Loss: 2.5337\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1608/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5105\n",
      "Epoch [1608/2000], Avg Train Loss: 3.5105\n",
      "Epoch [1608/2000], Avg Val Loss: 2.5338\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [1609/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4672\n",
      "Epoch [1609/2000], Avg Train Loss: 3.4672\n",
      "Epoch [1609/2000], Avg Val Loss: 2.5338\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [1610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4658\n",
      "Epoch [1610/2000], Avg Train Loss: 3.4658\n",
      "Epoch [1610/2000], Avg Val Loss: 2.5337\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [1611/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4754\n",
      "Epoch [1611/2000], Avg Train Loss: 3.4754\n",
      "Epoch [1611/2000], Avg Val Loss: 2.5337\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [1612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5050\n",
      "Epoch [1612/2000], Avg Train Loss: 3.5050\n",
      "Epoch [1612/2000], Avg Val Loss: 2.5337\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [1613/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5106\n",
      "Epoch [1613/2000], Avg Train Loss: 3.5106\n",
      "Epoch [1613/2000], Avg Val Loss: 2.5337\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [1614/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5362\n",
      "Epoch [1614/2000], Avg Train Loss: 3.5362\n",
      "Epoch [1614/2000], Avg Val Loss: 2.5336\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [1615/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4799\n",
      "Epoch [1615/2000], Avg Train Loss: 3.4799\n",
      "Epoch [1615/2000], Avg Val Loss: 2.5335\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [1616/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5006\n",
      "Epoch [1616/2000], Avg Train Loss: 3.5006\n",
      "Epoch [1616/2000], Avg Val Loss: 2.5334\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [1617/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4755\n",
      "Epoch [1617/2000], Avg Train Loss: 3.4755\n",
      "Epoch [1617/2000], Avg Val Loss: 2.5334\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [1618/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4992\n",
      "Epoch [1618/2000], Avg Train Loss: 3.4992\n",
      "Epoch [1618/2000], Avg Val Loss: 2.5333\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [1619/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4481\n",
      "Epoch [1619/2000], Avg Train Loss: 3.4481\n",
      "Epoch [1619/2000], Avg Val Loss: 2.5332\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [1620/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5162\n",
      "Epoch [1620/2000], Avg Train Loss: 3.5162\n",
      "Epoch [1620/2000], Avg Val Loss: 2.5327\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [1621/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4811\n",
      "Epoch [1621/2000], Avg Train Loss: 3.4811\n",
      "Epoch [1621/2000], Avg Val Loss: 2.5322\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [1622/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5031\n",
      "Epoch [1622/2000], Avg Train Loss: 3.5031\n",
      "Epoch [1622/2000], Avg Val Loss: 2.5315\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [1623/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4996\n",
      "Epoch [1623/2000], Avg Train Loss: 3.4996\n",
      "Epoch [1623/2000], Avg Val Loss: 2.5309\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [1624/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4946\n",
      "Epoch [1624/2000], Avg Train Loss: 3.4946\n",
      "Epoch [1624/2000], Avg Val Loss: 2.5304\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [1625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4616\n",
      "Epoch [1625/2000], Avg Train Loss: 3.4616\n",
      "Epoch [1625/2000], Avg Val Loss: 2.5299\n",
      "Validation loss improved from 2.5301 to 2.5299. Saving model...\n",
      "\n",
      "LOG: Epoch [1626/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4661\n",
      "Epoch [1626/2000], Avg Train Loss: 3.4661\n",
      "Epoch [1626/2000], Avg Val Loss: 2.5295\n",
      "Validation loss improved from 2.5299 to 2.5295. Saving model...\n",
      "\n",
      "LOG: Epoch [1627/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4677\n",
      "Epoch [1627/2000], Avg Train Loss: 3.4677\n",
      "Epoch [1627/2000], Avg Val Loss: 2.5291\n",
      "Validation loss improved from 2.5295 to 2.5291. Saving model...\n",
      "\n",
      "LOG: Epoch [1628/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4864\n",
      "Epoch [1628/2000], Avg Train Loss: 3.4864\n",
      "Epoch [1628/2000], Avg Val Loss: 2.5287\n",
      "Validation loss improved from 2.5291 to 2.5287. Saving model...\n",
      "\n",
      "LOG: Epoch [1629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4808\n",
      "Epoch [1629/2000], Avg Train Loss: 3.4808\n",
      "Epoch [1629/2000], Avg Val Loss: 2.5283\n",
      "Validation loss improved from 2.5287 to 2.5283. Saving model...\n",
      "\n",
      "LOG: Epoch [1630/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4818\n",
      "Epoch [1630/2000], Avg Train Loss: 3.4818\n",
      "Epoch [1630/2000], Avg Val Loss: 2.5281\n",
      "Validation loss improved from 2.5283 to 2.5281. Saving model...\n",
      "\n",
      "LOG: Epoch [1631/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5120\n",
      "Epoch [1631/2000], Avg Train Loss: 3.5120\n",
      "Epoch [1631/2000], Avg Val Loss: 2.5279\n",
      "Validation loss improved from 2.5281 to 2.5279. Saving model...\n",
      "\n",
      "LOG: Epoch [1632/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4883\n",
      "Epoch [1632/2000], Avg Train Loss: 3.4883\n",
      "Epoch [1632/2000], Avg Val Loss: 2.5278\n",
      "Validation loss improved from 2.5279 to 2.5278. Saving model...\n",
      "\n",
      "LOG: Epoch [1633/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4513\n",
      "Epoch [1633/2000], Avg Train Loss: 3.4513\n",
      "Epoch [1633/2000], Avg Val Loss: 2.5277\n",
      "Validation loss improved from 2.5278 to 2.5277. Saving model...\n",
      "\n",
      "LOG: Epoch [1634/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4380\n",
      "Epoch [1634/2000], Avg Train Loss: 3.4380\n",
      "Epoch [1634/2000], Avg Val Loss: 2.5274\n",
      "Validation loss improved from 2.5277 to 2.5274. Saving model...\n",
      "\n",
      "LOG: Epoch [1635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5122\n",
      "Epoch [1635/2000], Avg Train Loss: 3.5122\n",
      "Epoch [1635/2000], Avg Val Loss: 2.5269\n",
      "Validation loss improved from 2.5274 to 2.5269. Saving model...\n",
      "\n",
      "LOG: Epoch [1636/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5129\n",
      "Epoch [1636/2000], Avg Train Loss: 3.5129\n",
      "Epoch [1636/2000], Avg Val Loss: 2.5264\n",
      "Validation loss improved from 2.5269 to 2.5264. Saving model...\n",
      "\n",
      "LOG: Epoch [1637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4672\n",
      "Epoch [1637/2000], Avg Train Loss: 3.4672\n",
      "Epoch [1637/2000], Avg Val Loss: 2.5261\n",
      "Validation loss improved from 2.5264 to 2.5261. Saving model...\n",
      "\n",
      "LOG: Epoch [1638/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4354\n",
      "Epoch [1638/2000], Avg Train Loss: 3.4354\n",
      "Epoch [1638/2000], Avg Val Loss: 2.5259\n",
      "Validation loss improved from 2.5261 to 2.5259. Saving model...\n",
      "\n",
      "LOG: Epoch [1639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4470\n",
      "Epoch [1639/2000], Avg Train Loss: 3.4470\n",
      "Epoch [1639/2000], Avg Val Loss: 2.5257\n",
      "Validation loss improved from 2.5259 to 2.5257. Saving model...\n",
      "\n",
      "LOG: Epoch [1640/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4721\n",
      "Epoch [1640/2000], Avg Train Loss: 3.4721\n",
      "Epoch [1640/2000], Avg Val Loss: 2.5257\n",
      "Validation loss improved from 2.5257 to 2.5257. Saving model...\n",
      "\n",
      "LOG: Epoch [1641/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4485\n",
      "Epoch [1641/2000], Avg Train Loss: 3.4485\n",
      "Epoch [1641/2000], Avg Val Loss: 2.5256\n",
      "Validation loss improved from 2.5257 to 2.5256. Saving model...\n",
      "\n",
      "LOG: Epoch [1642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4480\n",
      "Epoch [1642/2000], Avg Train Loss: 3.4480\n",
      "Epoch [1642/2000], Avg Val Loss: 2.5254\n",
      "Validation loss improved from 2.5256 to 2.5254. Saving model...\n",
      "\n",
      "LOG: Epoch [1643/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4490\n",
      "Epoch [1643/2000], Avg Train Loss: 3.4490\n",
      "Epoch [1643/2000], Avg Val Loss: 2.5252\n",
      "Validation loss improved from 2.5254 to 2.5252. Saving model...\n",
      "\n",
      "LOG: Epoch [1644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4812\n",
      "Epoch [1644/2000], Avg Train Loss: 3.4812\n",
      "Epoch [1644/2000], Avg Val Loss: 2.5251\n",
      "Validation loss improved from 2.5252 to 2.5251. Saving model...\n",
      "\n",
      "LOG: Epoch [1645/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4875\n",
      "Epoch [1645/2000], Avg Train Loss: 3.4875\n",
      "Epoch [1645/2000], Avg Val Loss: 2.5251\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1646/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4781\n",
      "Epoch [1646/2000], Avg Train Loss: 3.4781\n",
      "Epoch [1646/2000], Avg Val Loss: 2.5251\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4687\n",
      "Epoch [1647/2000], Avg Train Loss: 3.4687\n",
      "Epoch [1647/2000], Avg Val Loss: 2.5252\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4775\n",
      "Epoch [1648/2000], Avg Train Loss: 3.4775\n",
      "Epoch [1648/2000], Avg Val Loss: 2.5253\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1649/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4580\n",
      "Epoch [1649/2000], Avg Train Loss: 3.4580\n",
      "Epoch [1649/2000], Avg Val Loss: 2.5254\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1650/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4645\n",
      "Epoch [1650/2000], Avg Train Loss: 3.4645\n",
      "Epoch [1650/2000], Avg Val Loss: 2.5254\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4630\n",
      "Epoch [1651/2000], Avg Train Loss: 3.4630\n",
      "Epoch [1651/2000], Avg Val Loss: 2.5253\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1652/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4931\n",
      "Epoch [1652/2000], Avg Train Loss: 3.4931\n",
      "Epoch [1652/2000], Avg Val Loss: 2.5253\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4695\n",
      "Epoch [1653/2000], Avg Train Loss: 3.4695\n",
      "Epoch [1653/2000], Avg Val Loss: 2.5254\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1654/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4836\n",
      "Epoch [1654/2000], Avg Train Loss: 3.4836\n",
      "Epoch [1654/2000], Avg Val Loss: 2.5253\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4525\n",
      "Epoch [1655/2000], Avg Train Loss: 3.4525\n",
      "Epoch [1655/2000], Avg Val Loss: 2.5251\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1656/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4838\n",
      "Epoch [1656/2000], Avg Train Loss: 3.4838\n",
      "Epoch [1656/2000], Avg Val Loss: 2.5250\n",
      "Validation loss improved from 2.5251 to 2.5250. Saving model...\n",
      "\n",
      "LOG: Epoch [1657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4829\n",
      "Epoch [1657/2000], Avg Train Loss: 3.4829\n",
      "Epoch [1657/2000], Avg Val Loss: 2.5248\n",
      "Validation loss improved from 2.5250 to 2.5248. Saving model...\n",
      "\n",
      "LOG: Epoch [1658/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4648\n",
      "Epoch [1658/2000], Avg Train Loss: 3.4648\n",
      "Epoch [1658/2000], Avg Val Loss: 2.5248\n",
      "Validation loss improved from 2.5248 to 2.5248. Saving model...\n",
      "\n",
      "LOG: Epoch [1659/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4710\n",
      "Epoch [1659/2000], Avg Train Loss: 3.4710\n",
      "Epoch [1659/2000], Avg Val Loss: 2.5248\n",
      "Validation loss improved from 2.5248 to 2.5248. Saving model...\n",
      "\n",
      "LOG: Epoch [1660/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4409\n",
      "Epoch [1660/2000], Avg Train Loss: 3.4409\n",
      "Epoch [1660/2000], Avg Val Loss: 2.5247\n",
      "Validation loss improved from 2.5248 to 2.5247. Saving model...\n",
      "\n",
      "LOG: Epoch [1661/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4734\n",
      "Epoch [1661/2000], Avg Train Loss: 3.4734\n",
      "Epoch [1661/2000], Avg Val Loss: 2.5249\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1662/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4580\n",
      "Epoch [1662/2000], Avg Train Loss: 3.4580\n",
      "Epoch [1662/2000], Avg Val Loss: 2.5251\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1663/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4194\n",
      "Epoch [1663/2000], Avg Train Loss: 3.4194\n",
      "Epoch [1663/2000], Avg Val Loss: 2.5253\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4519\n",
      "Epoch [1664/2000], Avg Train Loss: 3.4519\n",
      "Epoch [1664/2000], Avg Val Loss: 2.5255\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1665/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4793\n",
      "Epoch [1665/2000], Avg Train Loss: 3.4793\n",
      "Epoch [1665/2000], Avg Val Loss: 2.5258\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1666/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4565\n",
      "Epoch [1666/2000], Avg Train Loss: 3.4565\n",
      "Epoch [1666/2000], Avg Val Loss: 2.5262\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1667/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5032\n",
      "Epoch [1667/2000], Avg Train Loss: 3.5032\n",
      "Epoch [1667/2000], Avg Val Loss: 2.5265\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1668/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4411\n",
      "Epoch [1668/2000], Avg Train Loss: 3.4411\n",
      "Epoch [1668/2000], Avg Val Loss: 2.5268\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1669/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4564\n",
      "Epoch [1669/2000], Avg Train Loss: 3.4564\n",
      "Epoch [1669/2000], Avg Val Loss: 2.5269\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1670/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4580\n",
      "Epoch [1670/2000], Avg Train Loss: 3.4580\n",
      "Epoch [1670/2000], Avg Val Loss: 2.5273\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1671/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4870\n",
      "Epoch [1671/2000], Avg Train Loss: 3.4870\n",
      "Epoch [1671/2000], Avg Val Loss: 2.5274\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5046\n",
      "Epoch [1672/2000], Avg Train Loss: 3.5046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1672/2000], Avg Val Loss: 2.5274\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1673/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4722\n",
      "Epoch [1673/2000], Avg Train Loss: 3.4722\n",
      "Epoch [1673/2000], Avg Val Loss: 2.5274\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4631\n",
      "Epoch [1674/2000], Avg Train Loss: 3.4631\n",
      "Epoch [1674/2000], Avg Val Loss: 2.5273\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4746\n",
      "Epoch [1675/2000], Avg Train Loss: 3.4746\n",
      "Epoch [1675/2000], Avg Val Loss: 2.5270\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1676/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4731\n",
      "Epoch [1676/2000], Avg Train Loss: 3.4731\n",
      "Epoch [1676/2000], Avg Val Loss: 2.5266\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4908\n",
      "Epoch [1677/2000], Avg Train Loss: 3.4908\n",
      "Epoch [1677/2000], Avg Val Loss: 2.5264\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1678/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4270\n",
      "Epoch [1678/2000], Avg Train Loss: 3.4270\n",
      "Epoch [1678/2000], Avg Val Loss: 2.5264\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1679/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4364\n",
      "Epoch [1679/2000], Avg Train Loss: 3.4364\n",
      "Epoch [1679/2000], Avg Val Loss: 2.5264\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4266\n",
      "Epoch [1680/2000], Avg Train Loss: 3.4266\n",
      "Epoch [1680/2000], Avg Val Loss: 2.5265\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1681/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4655\n",
      "Epoch [1681/2000], Avg Train Loss: 3.4655\n",
      "Epoch [1681/2000], Avg Val Loss: 2.5265\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4818\n",
      "Epoch [1682/2000], Avg Train Loss: 3.4818\n",
      "Epoch [1682/2000], Avg Val Loss: 2.5263\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1683/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4715\n",
      "Epoch [1683/2000], Avg Train Loss: 3.4715\n",
      "Epoch [1683/2000], Avg Val Loss: 2.5263\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4694\n",
      "Epoch [1684/2000], Avg Train Loss: 3.4694\n",
      "Epoch [1684/2000], Avg Val Loss: 2.5262\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1685/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4407\n",
      "Epoch [1685/2000], Avg Train Loss: 3.4407\n",
      "Epoch [1685/2000], Avg Val Loss: 2.5262\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4604\n",
      "Epoch [1686/2000], Avg Train Loss: 3.4604\n",
      "Epoch [1686/2000], Avg Val Loss: 2.5260\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1687/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4371\n",
      "Epoch [1687/2000], Avg Train Loss: 3.4371\n",
      "Epoch [1687/2000], Avg Val Loss: 2.5257\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1688/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5008\n",
      "Epoch [1688/2000], Avg Train Loss: 3.5008\n",
      "Epoch [1688/2000], Avg Val Loss: 2.5254\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1689/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4598\n",
      "Epoch [1689/2000], Avg Train Loss: 3.4598\n",
      "Epoch [1689/2000], Avg Val Loss: 2.5251\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1690/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4378\n",
      "Epoch [1690/2000], Avg Train Loss: 3.4378\n",
      "Epoch [1690/2000], Avg Val Loss: 2.5249\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4853\n",
      "Epoch [1691/2000], Avg Train Loss: 3.4853\n",
      "Epoch [1691/2000], Avg Val Loss: 2.5247\n",
      "Validation loss improved from 2.5247 to 2.5247. Saving model...\n",
      "\n",
      "LOG: Epoch [1692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4667\n",
      "Epoch [1692/2000], Avg Train Loss: 3.4667\n",
      "Epoch [1692/2000], Avg Val Loss: 2.5246\n",
      "Validation loss improved from 2.5247 to 2.5246. Saving model...\n",
      "\n",
      "LOG: Epoch [1693/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4583\n",
      "Epoch [1693/2000], Avg Train Loss: 3.4583\n",
      "Epoch [1693/2000], Avg Val Loss: 2.5246\n",
      "Validation loss improved from 2.5246 to 2.5246. Saving model...\n",
      "\n",
      "LOG: Epoch [1694/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4843\n",
      "Epoch [1694/2000], Avg Train Loss: 3.4843\n",
      "Epoch [1694/2000], Avg Val Loss: 2.5245\n",
      "Validation loss improved from 2.5246 to 2.5245. Saving model...\n",
      "\n",
      "LOG: Epoch [1695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4601\n",
      "Epoch [1695/2000], Avg Train Loss: 3.4601\n",
      "Epoch [1695/2000], Avg Val Loss: 2.5246\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1696/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4663\n",
      "Epoch [1696/2000], Avg Train Loss: 3.4663\n",
      "Epoch [1696/2000], Avg Val Loss: 2.5247\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1697/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4681\n",
      "Epoch [1697/2000], Avg Train Loss: 3.4681\n",
      "Epoch [1697/2000], Avg Val Loss: 2.5248\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1698/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4753\n",
      "Epoch [1698/2000], Avg Train Loss: 3.4753\n",
      "Epoch [1698/2000], Avg Val Loss: 2.5251\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1699/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4617\n",
      "Epoch [1699/2000], Avg Train Loss: 3.4617\n",
      "Epoch [1699/2000], Avg Val Loss: 2.5254\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4382\n",
      "Epoch [1700/2000], Avg Train Loss: 3.4382\n",
      "Epoch [1700/2000], Avg Val Loss: 2.5254\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1701/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4684\n",
      "Epoch [1701/2000], Avg Train Loss: 3.4684\n",
      "Epoch [1701/2000], Avg Val Loss: 2.5256\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1702/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4835\n",
      "Epoch [1702/2000], Avg Train Loss: 3.4835\n",
      "Epoch [1702/2000], Avg Val Loss: 2.5257\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1703/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4403\n",
      "Epoch [1703/2000], Avg Train Loss: 3.4403\n",
      "Epoch [1703/2000], Avg Val Loss: 2.5258\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1704/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4504\n",
      "Epoch [1704/2000], Avg Train Loss: 3.4504\n",
      "Epoch [1704/2000], Avg Val Loss: 2.5258\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1705/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4575\n",
      "Epoch [1705/2000], Avg Train Loss: 3.4575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1705/2000], Avg Val Loss: 2.5257\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1706/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4531\n",
      "Epoch [1706/2000], Avg Train Loss: 3.4531\n",
      "Epoch [1706/2000], Avg Val Loss: 2.5254\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4522\n",
      "Epoch [1707/2000], Avg Train Loss: 3.4522\n",
      "Epoch [1707/2000], Avg Val Loss: 2.5251\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1708/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4644\n",
      "Epoch [1708/2000], Avg Train Loss: 3.4644\n",
      "Epoch [1708/2000], Avg Val Loss: 2.5246\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1709/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4466\n",
      "Epoch [1709/2000], Avg Train Loss: 3.4466\n",
      "Epoch [1709/2000], Avg Val Loss: 2.5242\n",
      "Validation loss improved from 2.5245 to 2.5242. Saving model...\n",
      "\n",
      "LOG: Epoch [1710/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4508\n",
      "Epoch [1710/2000], Avg Train Loss: 3.4508\n",
      "Epoch [1710/2000], Avg Val Loss: 2.5237\n",
      "Validation loss improved from 2.5242 to 2.5237. Saving model...\n",
      "\n",
      "LOG: Epoch [1711/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4490\n",
      "Epoch [1711/2000], Avg Train Loss: 3.4490\n",
      "Epoch [1711/2000], Avg Val Loss: 2.5233\n",
      "Validation loss improved from 2.5237 to 2.5233. Saving model...\n",
      "\n",
      "LOG: Epoch [1712/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4500\n",
      "Epoch [1712/2000], Avg Train Loss: 3.4500\n",
      "Epoch [1712/2000], Avg Val Loss: 2.5229\n",
      "Validation loss improved from 2.5233 to 2.5229. Saving model...\n",
      "\n",
      "LOG: Epoch [1713/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4980\n",
      "Epoch [1713/2000], Avg Train Loss: 3.4980\n",
      "Epoch [1713/2000], Avg Val Loss: 2.5224\n",
      "Validation loss improved from 2.5229 to 2.5224. Saving model...\n",
      "\n",
      "LOG: Epoch [1714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4532\n",
      "Epoch [1714/2000], Avg Train Loss: 3.4532\n",
      "Epoch [1714/2000], Avg Val Loss: 2.5219\n",
      "Validation loss improved from 2.5224 to 2.5219. Saving model...\n",
      "\n",
      "LOG: Epoch [1715/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4942\n",
      "Epoch [1715/2000], Avg Train Loss: 3.4942\n",
      "Epoch [1715/2000], Avg Val Loss: 2.5214\n",
      "Validation loss improved from 2.5219 to 2.5214. Saving model...\n",
      "\n",
      "LOG: Epoch [1716/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4387\n",
      "Epoch [1716/2000], Avg Train Loss: 3.4387\n",
      "Epoch [1716/2000], Avg Val Loss: 2.5211\n",
      "Validation loss improved from 2.5214 to 2.5211. Saving model...\n",
      "\n",
      "LOG: Epoch [1717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4598\n",
      "Epoch [1717/2000], Avg Train Loss: 3.4598\n",
      "Epoch [1717/2000], Avg Val Loss: 2.5207\n",
      "Validation loss improved from 2.5211 to 2.5207. Saving model...\n",
      "\n",
      "LOG: Epoch [1718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4512\n",
      "Epoch [1718/2000], Avg Train Loss: 3.4512\n",
      "Epoch [1718/2000], Avg Val Loss: 2.5203\n",
      "Validation loss improved from 2.5207 to 2.5203. Saving model...\n",
      "\n",
      "LOG: Epoch [1719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4618\n",
      "Epoch [1719/2000], Avg Train Loss: 3.4618\n",
      "Epoch [1719/2000], Avg Val Loss: 2.5201\n",
      "Validation loss improved from 2.5203 to 2.5201. Saving model...\n",
      "\n",
      "LOG: Epoch [1720/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4601\n",
      "Epoch [1720/2000], Avg Train Loss: 3.4601\n",
      "Epoch [1720/2000], Avg Val Loss: 2.5200\n",
      "Validation loss improved from 2.5201 to 2.5200. Saving model...\n",
      "\n",
      "LOG: Epoch [1721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4599\n",
      "Epoch [1721/2000], Avg Train Loss: 3.4599\n",
      "Epoch [1721/2000], Avg Val Loss: 2.5199\n",
      "Validation loss improved from 2.5200 to 2.5199. Saving model...\n",
      "\n",
      "LOG: Epoch [1722/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3964\n",
      "Epoch [1722/2000], Avg Train Loss: 3.3964\n",
      "Epoch [1722/2000], Avg Val Loss: 2.5199\n",
      "Validation loss improved from 2.5199 to 2.5199. Saving model...\n",
      "\n",
      "LOG: Epoch [1723/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4322\n",
      "Epoch [1723/2000], Avg Train Loss: 3.4322\n",
      "Epoch [1723/2000], Avg Val Loss: 2.5199\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1724/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4311\n",
      "Epoch [1724/2000], Avg Train Loss: 3.4311\n",
      "Epoch [1724/2000], Avg Val Loss: 2.5197\n",
      "Validation loss improved from 2.5199 to 2.5197. Saving model...\n",
      "\n",
      "LOG: Epoch [1725/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4550\n",
      "Epoch [1725/2000], Avg Train Loss: 3.4550\n",
      "Epoch [1725/2000], Avg Val Loss: 2.5197\n",
      "Validation loss improved from 2.5197 to 2.5197. Saving model...\n",
      "\n",
      "LOG: Epoch [1726/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4264\n",
      "Epoch [1726/2000], Avg Train Loss: 3.4264\n",
      "Epoch [1726/2000], Avg Val Loss: 2.5196\n",
      "Validation loss improved from 2.5197 to 2.5196. Saving model...\n",
      "\n",
      "LOG: Epoch [1727/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4326\n",
      "Epoch [1727/2000], Avg Train Loss: 3.4326\n",
      "Epoch [1727/2000], Avg Val Loss: 2.5197\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4730\n",
      "Epoch [1728/2000], Avg Train Loss: 3.4730\n",
      "Epoch [1728/2000], Avg Val Loss: 2.5198\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1729/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4892\n",
      "Epoch [1729/2000], Avg Train Loss: 3.4892\n",
      "Epoch [1729/2000], Avg Val Loss: 2.5200\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1730/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4567\n",
      "Epoch [1730/2000], Avg Train Loss: 3.4567\n",
      "Epoch [1730/2000], Avg Val Loss: 2.5200\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1731/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4658\n",
      "Epoch [1731/2000], Avg Train Loss: 3.4658\n",
      "Epoch [1731/2000], Avg Val Loss: 2.5197\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1732/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4756\n",
      "Epoch [1732/2000], Avg Train Loss: 3.4756\n",
      "Epoch [1732/2000], Avg Val Loss: 2.5195\n",
      "Validation loss improved from 2.5196 to 2.5195. Saving model...\n",
      "\n",
      "LOG: Epoch [1733/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4352\n",
      "Epoch [1733/2000], Avg Train Loss: 3.4352\n",
      "Epoch [1733/2000], Avg Val Loss: 2.5192\n",
      "Validation loss improved from 2.5195 to 2.5192. Saving model...\n",
      "\n",
      "LOG: Epoch [1734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4520\n",
      "Epoch [1734/2000], Avg Train Loss: 3.4520\n",
      "Epoch [1734/2000], Avg Val Loss: 2.5191\n",
      "Validation loss improved from 2.5192 to 2.5191. Saving model...\n",
      "\n",
      "LOG: Epoch [1735/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4203\n",
      "Epoch [1735/2000], Avg Train Loss: 3.4203\n",
      "Epoch [1735/2000], Avg Val Loss: 2.5189\n",
      "Validation loss improved from 2.5191 to 2.5189. Saving model...\n",
      "\n",
      "LOG: Epoch [1736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4583\n",
      "Epoch [1736/2000], Avg Train Loss: 3.4583\n",
      "Epoch [1736/2000], Avg Val Loss: 2.5187\n",
      "Validation loss improved from 2.5189 to 2.5187. Saving model...\n",
      "\n",
      "LOG: Epoch [1737/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4008\n",
      "Epoch [1737/2000], Avg Train Loss: 3.4008\n",
      "Epoch [1737/2000], Avg Val Loss: 2.5186\n",
      "Validation loss improved from 2.5187 to 2.5186. Saving model...\n",
      "\n",
      "LOG: Epoch [1738/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4476\n",
      "Epoch [1738/2000], Avg Train Loss: 3.4476\n",
      "Epoch [1738/2000], Avg Val Loss: 2.5182\n",
      "Validation loss improved from 2.5186 to 2.5182. Saving model...\n",
      "\n",
      "LOG: Epoch [1739/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4540\n",
      "Epoch [1739/2000], Avg Train Loss: 3.4540\n",
      "Epoch [1739/2000], Avg Val Loss: 2.5179\n",
      "Validation loss improved from 2.5182 to 2.5179. Saving model...\n",
      "\n",
      "LOG: Epoch [1740/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4616\n",
      "Epoch [1740/2000], Avg Train Loss: 3.4616\n",
      "Epoch [1740/2000], Avg Val Loss: 2.5175\n",
      "Validation loss improved from 2.5179 to 2.5175. Saving model...\n",
      "\n",
      "LOG: Epoch [1741/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4374\n",
      "Epoch [1741/2000], Avg Train Loss: 3.4374\n",
      "Epoch [1741/2000], Avg Val Loss: 2.5170\n",
      "Validation loss improved from 2.5175 to 2.5170. Saving model...\n",
      "\n",
      "LOG: Epoch [1742/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4212\n",
      "Epoch [1742/2000], Avg Train Loss: 3.4212\n",
      "Epoch [1742/2000], Avg Val Loss: 2.5165\n",
      "Validation loss improved from 2.5170 to 2.5165. Saving model...\n",
      "\n",
      "LOG: Epoch [1743/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4094\n",
      "Epoch [1743/2000], Avg Train Loss: 3.4094\n",
      "Epoch [1743/2000], Avg Val Loss: 2.5162\n",
      "Validation loss improved from 2.5165 to 2.5162. Saving model...\n",
      "\n",
      "LOG: Epoch [1744/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4227\n",
      "Epoch [1744/2000], Avg Train Loss: 3.4227\n",
      "Epoch [1744/2000], Avg Val Loss: 2.5156\n",
      "Validation loss improved from 2.5162 to 2.5156. Saving model...\n",
      "\n",
      "LOG: Epoch [1745/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4385\n",
      "Epoch [1745/2000], Avg Train Loss: 3.4385\n",
      "Epoch [1745/2000], Avg Val Loss: 2.5151\n",
      "Validation loss improved from 2.5156 to 2.5151. Saving model...\n",
      "\n",
      "LOG: Epoch [1746/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4268\n",
      "Epoch [1746/2000], Avg Train Loss: 3.4268\n",
      "Epoch [1746/2000], Avg Val Loss: 2.5145\n",
      "Validation loss improved from 2.5151 to 2.5145. Saving model...\n",
      "\n",
      "LOG: Epoch [1747/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4457\n",
      "Epoch [1747/2000], Avg Train Loss: 3.4457\n",
      "Epoch [1747/2000], Avg Val Loss: 2.5141\n",
      "Validation loss improved from 2.5145 to 2.5141. Saving model...\n",
      "\n",
      "LOG: Epoch [1748/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4359\n",
      "Epoch [1748/2000], Avg Train Loss: 3.4359\n",
      "Epoch [1748/2000], Avg Val Loss: 2.5140\n",
      "Validation loss improved from 2.5141 to 2.5140. Saving model...\n",
      "\n",
      "LOG: Epoch [1749/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4424\n",
      "Epoch [1749/2000], Avg Train Loss: 3.4424\n",
      "Epoch [1749/2000], Avg Val Loss: 2.5139\n",
      "Validation loss improved from 2.5140 to 2.5139. Saving model...\n",
      "\n",
      "LOG: Epoch [1750/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4346\n",
      "Epoch [1750/2000], Avg Train Loss: 3.4346\n",
      "Epoch [1750/2000], Avg Val Loss: 2.5138\n",
      "Validation loss improved from 2.5139 to 2.5138. Saving model...\n",
      "\n",
      "LOG: Epoch [1751/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4597\n",
      "Epoch [1751/2000], Avg Train Loss: 3.4597\n",
      "Epoch [1751/2000], Avg Val Loss: 2.5138\n",
      "Validation loss improved from 2.5138 to 2.5138. Saving model...\n",
      "\n",
      "LOG: Epoch [1752/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4638\n",
      "Epoch [1752/2000], Avg Train Loss: 3.4638\n",
      "Epoch [1752/2000], Avg Val Loss: 2.5138\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1753/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4198\n",
      "Epoch [1753/2000], Avg Train Loss: 3.4198\n",
      "Epoch [1753/2000], Avg Val Loss: 2.5139\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1754/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4483\n",
      "Epoch [1754/2000], Avg Train Loss: 3.4483\n",
      "Epoch [1754/2000], Avg Val Loss: 2.5139\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1755/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4151\n",
      "Epoch [1755/2000], Avg Train Loss: 3.4151\n",
      "Epoch [1755/2000], Avg Val Loss: 2.5140\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1756/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4552\n",
      "Epoch [1756/2000], Avg Train Loss: 3.4552\n",
      "Epoch [1756/2000], Avg Val Loss: 2.5142\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1757/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4503\n",
      "Epoch [1757/2000], Avg Train Loss: 3.4503\n",
      "Epoch [1757/2000], Avg Val Loss: 2.5144\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1758/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4622\n",
      "Epoch [1758/2000], Avg Train Loss: 3.4622\n",
      "Epoch [1758/2000], Avg Val Loss: 2.5147\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1759/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4371\n",
      "Epoch [1759/2000], Avg Train Loss: 3.4371\n",
      "Epoch [1759/2000], Avg Val Loss: 2.5149\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1760/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4510\n",
      "Epoch [1760/2000], Avg Train Loss: 3.4510\n",
      "Epoch [1760/2000], Avg Val Loss: 2.5149\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1761/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4377\n",
      "Epoch [1761/2000], Avg Train Loss: 3.4377\n",
      "Epoch [1761/2000], Avg Val Loss: 2.5149\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1762/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4229\n",
      "Epoch [1762/2000], Avg Train Loss: 3.4229\n",
      "Epoch [1762/2000], Avg Val Loss: 2.5147\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1763/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4467\n",
      "Epoch [1763/2000], Avg Train Loss: 3.4467\n",
      "Epoch [1763/2000], Avg Val Loss: 2.5144\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1764/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4219\n",
      "Epoch [1764/2000], Avg Train Loss: 3.4219\n",
      "Epoch [1764/2000], Avg Val Loss: 2.5142\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1765/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4166\n",
      "Epoch [1765/2000], Avg Train Loss: 3.4166\n",
      "Epoch [1765/2000], Avg Val Loss: 2.5139\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1766/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4441\n",
      "Epoch [1766/2000], Avg Train Loss: 3.4441\n",
      "Epoch [1766/2000], Avg Val Loss: 2.5137\n",
      "Validation loss improved from 2.5138 to 2.5137. Saving model...\n",
      "\n",
      "LOG: Epoch [1767/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4116\n",
      "Epoch [1767/2000], Avg Train Loss: 3.4116\n",
      "Epoch [1767/2000], Avg Val Loss: 2.5136\n",
      "Validation loss improved from 2.5137 to 2.5136. Saving model...\n",
      "\n",
      "LOG: Epoch [1768/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4335\n",
      "Epoch [1768/2000], Avg Train Loss: 3.4335\n",
      "Epoch [1768/2000], Avg Val Loss: 2.5137\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1769/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4419\n",
      "Epoch [1769/2000], Avg Train Loss: 3.4419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1769/2000], Avg Val Loss: 2.5136\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1770/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3946\n",
      "Epoch [1770/2000], Avg Train Loss: 3.3946\n",
      "Epoch [1770/2000], Avg Val Loss: 2.5138\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1771/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4238\n",
      "Epoch [1771/2000], Avg Train Loss: 3.4238\n",
      "Epoch [1771/2000], Avg Val Loss: 2.5140\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1772/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4861\n",
      "Epoch [1772/2000], Avg Train Loss: 3.4861\n",
      "Epoch [1772/2000], Avg Val Loss: 2.5141\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1773/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4070\n",
      "Epoch [1773/2000], Avg Train Loss: 3.4070\n",
      "Epoch [1773/2000], Avg Val Loss: 2.5143\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1774/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4426\n",
      "Epoch [1774/2000], Avg Train Loss: 3.4426\n",
      "Epoch [1774/2000], Avg Val Loss: 2.5142\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1775/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4514\n",
      "Epoch [1775/2000], Avg Train Loss: 3.4514\n",
      "Epoch [1775/2000], Avg Val Loss: 2.5140\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1776/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4051\n",
      "Epoch [1776/2000], Avg Train Loss: 3.4051\n",
      "Epoch [1776/2000], Avg Val Loss: 2.5139\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1777/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4461\n",
      "Epoch [1777/2000], Avg Train Loss: 3.4461\n",
      "Epoch [1777/2000], Avg Val Loss: 2.5138\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1778/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3921\n",
      "Epoch [1778/2000], Avg Train Loss: 3.3921\n",
      "Epoch [1778/2000], Avg Val Loss: 2.5135\n",
      "Validation loss improved from 2.5136 to 2.5135. Saving model...\n",
      "\n",
      "LOG: Epoch [1779/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4600\n",
      "Epoch [1779/2000], Avg Train Loss: 3.4600\n",
      "Epoch [1779/2000], Avg Val Loss: 2.5129\n",
      "Validation loss improved from 2.5135 to 2.5129. Saving model...\n",
      "\n",
      "LOG: Epoch [1780/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4070\n",
      "Epoch [1780/2000], Avg Train Loss: 3.4070\n",
      "Epoch [1780/2000], Avg Val Loss: 2.5125\n",
      "Validation loss improved from 2.5129 to 2.5125. Saving model...\n",
      "\n",
      "LOG: Epoch [1781/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3866\n",
      "Epoch [1781/2000], Avg Train Loss: 3.3866\n",
      "Epoch [1781/2000], Avg Val Loss: 2.5121\n",
      "Validation loss improved from 2.5125 to 2.5121. Saving model...\n",
      "\n",
      "LOG: Epoch [1782/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4689\n",
      "Epoch [1782/2000], Avg Train Loss: 3.4689\n",
      "Epoch [1782/2000], Avg Val Loss: 2.5114\n",
      "Validation loss improved from 2.5121 to 2.5114. Saving model...\n",
      "\n",
      "LOG: Epoch [1783/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4269\n",
      "Epoch [1783/2000], Avg Train Loss: 3.4269\n",
      "Epoch [1783/2000], Avg Val Loss: 2.5111\n",
      "Validation loss improved from 2.5114 to 2.5111. Saving model...\n",
      "\n",
      "LOG: Epoch [1784/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4035\n",
      "Epoch [1784/2000], Avg Train Loss: 3.4035\n",
      "Epoch [1784/2000], Avg Val Loss: 2.5108\n",
      "Validation loss improved from 2.5111 to 2.5108. Saving model...\n",
      "\n",
      "LOG: Epoch [1785/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4288\n",
      "Epoch [1785/2000], Avg Train Loss: 3.4288\n",
      "Epoch [1785/2000], Avg Val Loss: 2.5105\n",
      "Validation loss improved from 2.5108 to 2.5105. Saving model...\n",
      "\n",
      "LOG: Epoch [1786/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4574\n",
      "Epoch [1786/2000], Avg Train Loss: 3.4574\n",
      "Epoch [1786/2000], Avg Val Loss: 2.5100\n",
      "Validation loss improved from 2.5105 to 2.5100. Saving model...\n",
      "\n",
      "LOG: Epoch [1787/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4665\n",
      "Epoch [1787/2000], Avg Train Loss: 3.4665\n",
      "Epoch [1787/2000], Avg Val Loss: 2.5092\n",
      "Validation loss improved from 2.5100 to 2.5092. Saving model...\n",
      "\n",
      "LOG: Epoch [1788/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4548\n",
      "Epoch [1788/2000], Avg Train Loss: 3.4548\n",
      "Epoch [1788/2000], Avg Val Loss: 2.5085\n",
      "Validation loss improved from 2.5092 to 2.5085. Saving model...\n",
      "\n",
      "LOG: Epoch [1789/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4307\n",
      "Epoch [1789/2000], Avg Train Loss: 3.4307\n",
      "Epoch [1789/2000], Avg Val Loss: 2.5079\n",
      "Validation loss improved from 2.5085 to 2.5079. Saving model...\n",
      "\n",
      "LOG: Epoch [1790/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4024\n",
      "Epoch [1790/2000], Avg Train Loss: 3.4024\n",
      "Epoch [1790/2000], Avg Val Loss: 2.5075\n",
      "Validation loss improved from 2.5079 to 2.5075. Saving model...\n",
      "\n",
      "LOG: Epoch [1791/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4246\n",
      "Epoch [1791/2000], Avg Train Loss: 3.4246\n",
      "Epoch [1791/2000], Avg Val Loss: 2.5073\n",
      "Validation loss improved from 2.5075 to 2.5073. Saving model...\n",
      "\n",
      "LOG: Epoch [1792/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4344\n",
      "Epoch [1792/2000], Avg Train Loss: 3.4344\n",
      "Epoch [1792/2000], Avg Val Loss: 2.5071\n",
      "Validation loss improved from 2.5073 to 2.5071. Saving model...\n",
      "\n",
      "LOG: Epoch [1793/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4117\n",
      "Epoch [1793/2000], Avg Train Loss: 3.4117\n",
      "Epoch [1793/2000], Avg Val Loss: 2.5070\n",
      "Validation loss improved from 2.5071 to 2.5070. Saving model...\n",
      "\n",
      "LOG: Epoch [1794/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4233\n",
      "Epoch [1794/2000], Avg Train Loss: 3.4233\n",
      "Epoch [1794/2000], Avg Val Loss: 2.5069\n",
      "Validation loss improved from 2.5070 to 2.5069. Saving model...\n",
      "\n",
      "LOG: Epoch [1795/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4399\n",
      "Epoch [1795/2000], Avg Train Loss: 3.4399\n",
      "Epoch [1795/2000], Avg Val Loss: 2.5067\n",
      "Validation loss improved from 2.5069 to 2.5067. Saving model...\n",
      "\n",
      "LOG: Epoch [1796/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4144\n",
      "Epoch [1796/2000], Avg Train Loss: 3.4144\n",
      "Epoch [1796/2000], Avg Val Loss: 2.5065\n",
      "Validation loss improved from 2.5067 to 2.5065. Saving model...\n",
      "\n",
      "LOG: Epoch [1797/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4620\n",
      "Epoch [1797/2000], Avg Train Loss: 3.4620\n",
      "Epoch [1797/2000], Avg Val Loss: 2.5066\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1798/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4019\n",
      "Epoch [1798/2000], Avg Train Loss: 3.4019\n",
      "Epoch [1798/2000], Avg Val Loss: 2.5069\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1799/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4485\n",
      "Epoch [1799/2000], Avg Train Loss: 3.4485\n",
      "Epoch [1799/2000], Avg Val Loss: 2.5069\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1800/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3971\n",
      "Epoch [1800/2000], Avg Train Loss: 3.3971\n",
      "Epoch [1800/2000], Avg Val Loss: 2.5072\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1801/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3815\n",
      "Epoch [1801/2000], Avg Train Loss: 3.3815\n",
      "Epoch [1801/2000], Avg Val Loss: 2.5075\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1802/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3975\n",
      "Epoch [1802/2000], Avg Train Loss: 3.3975\n",
      "Epoch [1802/2000], Avg Val Loss: 2.5078\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1803/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4425\n",
      "Epoch [1803/2000], Avg Train Loss: 3.4425\n",
      "Epoch [1803/2000], Avg Val Loss: 2.5082\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1804/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4326\n",
      "Epoch [1804/2000], Avg Train Loss: 3.4326\n",
      "Epoch [1804/2000], Avg Val Loss: 2.5085\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1805/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3975\n",
      "Epoch [1805/2000], Avg Train Loss: 3.3975\n",
      "Epoch [1805/2000], Avg Val Loss: 2.5090\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1806/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4365\n",
      "Epoch [1806/2000], Avg Train Loss: 3.4365\n",
      "Epoch [1806/2000], Avg Val Loss: 2.5096\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1807/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4104\n",
      "Epoch [1807/2000], Avg Train Loss: 3.4104\n",
      "Epoch [1807/2000], Avg Val Loss: 2.5103\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1808/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4516\n",
      "Epoch [1808/2000], Avg Train Loss: 3.4516\n",
      "Epoch [1808/2000], Avg Val Loss: 2.5109\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1809/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4459\n",
      "Epoch [1809/2000], Avg Train Loss: 3.4459\n",
      "Epoch [1809/2000], Avg Val Loss: 2.5114\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1810/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4071\n",
      "Epoch [1810/2000], Avg Train Loss: 3.4071\n",
      "Epoch [1810/2000], Avg Val Loss: 2.5118\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1811/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3876\n",
      "Epoch [1811/2000], Avg Train Loss: 3.3876\n",
      "Epoch [1811/2000], Avg Val Loss: 2.5122\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1812/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4205\n",
      "Epoch [1812/2000], Avg Train Loss: 3.4205\n",
      "Epoch [1812/2000], Avg Val Loss: 2.5125\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1813/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4472\n",
      "Epoch [1813/2000], Avg Train Loss: 3.4472\n",
      "Epoch [1813/2000], Avg Val Loss: 2.5128\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1814/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3950\n",
      "Epoch [1814/2000], Avg Train Loss: 3.3950\n",
      "Epoch [1814/2000], Avg Val Loss: 2.5131\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1815/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3978\n",
      "Epoch [1815/2000], Avg Train Loss: 3.3978\n",
      "Epoch [1815/2000], Avg Val Loss: 2.5132\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1816/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4182\n",
      "Epoch [1816/2000], Avg Train Loss: 3.4182\n",
      "Epoch [1816/2000], Avg Val Loss: 2.5132\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1817/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4310\n",
      "Epoch [1817/2000], Avg Train Loss: 3.4310\n",
      "Epoch [1817/2000], Avg Val Loss: 2.5132\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1818/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4297\n",
      "Epoch [1818/2000], Avg Train Loss: 3.4297\n",
      "Epoch [1818/2000], Avg Val Loss: 2.5132\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1819/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4307\n",
      "Epoch [1819/2000], Avg Train Loss: 3.4307\n",
      "Epoch [1819/2000], Avg Val Loss: 2.5129\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1820/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4127\n",
      "Epoch [1820/2000], Avg Train Loss: 3.4127\n",
      "Epoch [1820/2000], Avg Val Loss: 2.5128\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1821/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4411\n",
      "Epoch [1821/2000], Avg Train Loss: 3.4411\n",
      "Epoch [1821/2000], Avg Val Loss: 2.5127\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1822/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4424\n",
      "Epoch [1822/2000], Avg Train Loss: 3.4424\n",
      "Epoch [1822/2000], Avg Val Loss: 2.5127\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1823/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4578\n",
      "Epoch [1823/2000], Avg Train Loss: 3.4578\n",
      "Epoch [1823/2000], Avg Val Loss: 2.5128\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1824/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4264\n",
      "Epoch [1824/2000], Avg Train Loss: 3.4264\n",
      "Epoch [1824/2000], Avg Val Loss: 2.5128\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1825/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4149\n",
      "Epoch [1825/2000], Avg Train Loss: 3.4149\n",
      "Epoch [1825/2000], Avg Val Loss: 2.5131\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1826/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4079\n",
      "Epoch [1826/2000], Avg Train Loss: 3.4079\n",
      "Epoch [1826/2000], Avg Val Loss: 2.5134\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1827/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3994\n",
      "Epoch [1827/2000], Avg Train Loss: 3.3994\n",
      "Epoch [1827/2000], Avg Val Loss: 2.5138\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1828/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3868\n",
      "Epoch [1828/2000], Avg Train Loss: 3.3868\n",
      "Epoch [1828/2000], Avg Val Loss: 2.5140\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1829/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4192\n",
      "Epoch [1829/2000], Avg Train Loss: 3.4192\n",
      "Epoch [1829/2000], Avg Val Loss: 2.5144\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1830/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4080\n",
      "Epoch [1830/2000], Avg Train Loss: 3.4080\n",
      "Epoch [1830/2000], Avg Val Loss: 2.5149\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1831/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3727\n",
      "Epoch [1831/2000], Avg Train Loss: 3.3727\n",
      "Epoch [1831/2000], Avg Val Loss: 2.5153\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1832/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4102\n",
      "Epoch [1832/2000], Avg Train Loss: 3.4102\n",
      "Epoch [1832/2000], Avg Val Loss: 2.5155\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1833/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4261\n",
      "Epoch [1833/2000], Avg Train Loss: 3.4261\n",
      "Epoch [1833/2000], Avg Val Loss: 2.5154\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1834/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4133\n",
      "Epoch [1834/2000], Avg Train Loss: 3.4133\n",
      "Epoch [1834/2000], Avg Val Loss: 2.5152\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1835/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4004\n",
      "Epoch [1835/2000], Avg Train Loss: 3.4004\n",
      "Epoch [1835/2000], Avg Val Loss: 2.5149\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1836/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4311\n",
      "Epoch [1836/2000], Avg Train Loss: 3.4311\n",
      "Epoch [1836/2000], Avg Val Loss: 2.5146\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1837/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4128\n",
      "Epoch [1837/2000], Avg Train Loss: 3.4128\n",
      "Epoch [1837/2000], Avg Val Loss: 2.5144\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1838/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4273\n",
      "Epoch [1838/2000], Avg Train Loss: 3.4273\n",
      "Epoch [1838/2000], Avg Val Loss: 2.5144\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1839/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4346\n",
      "Epoch [1839/2000], Avg Train Loss: 3.4346\n",
      "Epoch [1839/2000], Avg Val Loss: 2.5146\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1840/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4097\n",
      "Epoch [1840/2000], Avg Train Loss: 3.4097\n",
      "Epoch [1840/2000], Avg Val Loss: 2.5149\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1841/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4173\n",
      "Epoch [1841/2000], Avg Train Loss: 3.4173\n",
      "Epoch [1841/2000], Avg Val Loss: 2.5151\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1842/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4273\n",
      "Epoch [1842/2000], Avg Train Loss: 3.4273\n",
      "Epoch [1842/2000], Avg Val Loss: 2.5149\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1843/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4116\n",
      "Epoch [1843/2000], Avg Train Loss: 3.4116\n",
      "Epoch [1843/2000], Avg Val Loss: 2.5149\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1844/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3995\n",
      "Epoch [1844/2000], Avg Train Loss: 3.3995\n",
      "Epoch [1844/2000], Avg Val Loss: 2.5150\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1845/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4210\n",
      "Epoch [1845/2000], Avg Train Loss: 3.4210\n",
      "Epoch [1845/2000], Avg Val Loss: 2.5151\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1846/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4436\n",
      "Epoch [1846/2000], Avg Train Loss: 3.4436\n",
      "Epoch [1846/2000], Avg Val Loss: 2.5152\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1847/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4358\n",
      "Epoch [1847/2000], Avg Train Loss: 3.4358\n",
      "Epoch [1847/2000], Avg Val Loss: 2.5152\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1848/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4063\n",
      "Epoch [1848/2000], Avg Train Loss: 3.4063\n",
      "Epoch [1848/2000], Avg Val Loss: 2.5152\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1849/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3752\n",
      "Epoch [1849/2000], Avg Train Loss: 3.3752\n",
      "Epoch [1849/2000], Avg Val Loss: 2.5151\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1850/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4139\n",
      "Epoch [1850/2000], Avg Train Loss: 3.4139\n",
      "Epoch [1850/2000], Avg Val Loss: 2.5149\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1851/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4266\n",
      "Epoch [1851/2000], Avg Train Loss: 3.4266\n",
      "Epoch [1851/2000], Avg Val Loss: 2.5147\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1852/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4677\n",
      "Epoch [1852/2000], Avg Train Loss: 3.4677\n",
      "Epoch [1852/2000], Avg Val Loss: 2.5144\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1853/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3834\n",
      "Epoch [1853/2000], Avg Train Loss: 3.3834\n",
      "Epoch [1853/2000], Avg Val Loss: 2.5141\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1854/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4235\n",
      "Epoch [1854/2000], Avg Train Loss: 3.4235\n",
      "Epoch [1854/2000], Avg Val Loss: 2.5137\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1855/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4117\n",
      "Epoch [1855/2000], Avg Train Loss: 3.4117\n",
      "Epoch [1855/2000], Avg Val Loss: 2.5132\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1856/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3805\n",
      "Epoch [1856/2000], Avg Train Loss: 3.3805\n",
      "Epoch [1856/2000], Avg Val Loss: 2.5126\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1857/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4167\n",
      "Epoch [1857/2000], Avg Train Loss: 3.4167\n",
      "Epoch [1857/2000], Avg Val Loss: 2.5122\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1858/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3836\n",
      "Epoch [1858/2000], Avg Train Loss: 3.3836\n",
      "Epoch [1858/2000], Avg Val Loss: 2.5117\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1859/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4243\n",
      "Epoch [1859/2000], Avg Train Loss: 3.4243\n",
      "Epoch [1859/2000], Avg Val Loss: 2.5111\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1860/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3781\n",
      "Epoch [1860/2000], Avg Train Loss: 3.3781\n",
      "Epoch [1860/2000], Avg Val Loss: 2.5105\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1861/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4141\n",
      "Epoch [1861/2000], Avg Train Loss: 3.4141\n",
      "Epoch [1861/2000], Avg Val Loss: 2.5100\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1862/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3937\n",
      "Epoch [1862/2000], Avg Train Loss: 3.3937\n",
      "Epoch [1862/2000], Avg Val Loss: 2.5095\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1863/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4103\n",
      "Epoch [1863/2000], Avg Train Loss: 3.4103\n",
      "Epoch [1863/2000], Avg Val Loss: 2.5089\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1864/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4167\n",
      "Epoch [1864/2000], Avg Train Loss: 3.4167\n",
      "Epoch [1864/2000], Avg Val Loss: 2.5084\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [1865/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4162\n",
      "Epoch [1865/2000], Avg Train Loss: 3.4162\n",
      "Epoch [1865/2000], Avg Val Loss: 2.5079\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [1866/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4350\n",
      "Epoch [1866/2000], Avg Train Loss: 3.4350\n",
      "Epoch [1866/2000], Avg Val Loss: 2.5074\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [1867/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3923\n",
      "Epoch [1867/2000], Avg Train Loss: 3.3923\n",
      "Epoch [1867/2000], Avg Val Loss: 2.5069\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [1868/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3622\n",
      "Epoch [1868/2000], Avg Train Loss: 3.3622\n",
      "Epoch [1868/2000], Avg Val Loss: 2.5065\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [1869/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3928\n",
      "Epoch [1869/2000], Avg Train Loss: 3.3928\n",
      "Epoch [1869/2000], Avg Val Loss: 2.5062\n",
      "Validation loss improved from 2.5065 to 2.5062. Saving model...\n",
      "\n",
      "LOG: Epoch [1870/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3605\n",
      "Epoch [1870/2000], Avg Train Loss: 3.3605\n",
      "Epoch [1870/2000], Avg Val Loss: 2.5058\n",
      "Validation loss improved from 2.5062 to 2.5058. Saving model...\n",
      "\n",
      "LOG: Epoch [1871/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3614\n",
      "Epoch [1871/2000], Avg Train Loss: 3.3614\n",
      "Epoch [1871/2000], Avg Val Loss: 2.5054\n",
      "Validation loss improved from 2.5058 to 2.5054. Saving model...\n",
      "\n",
      "LOG: Epoch [1872/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4409\n",
      "Epoch [1872/2000], Avg Train Loss: 3.4409\n",
      "Epoch [1872/2000], Avg Val Loss: 2.5052\n",
      "Validation loss improved from 2.5054 to 2.5052. Saving model...\n",
      "\n",
      "LOG: Epoch [1873/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4341\n",
      "Epoch [1873/2000], Avg Train Loss: 3.4341\n",
      "Epoch [1873/2000], Avg Val Loss: 2.5051\n",
      "Validation loss improved from 2.5052 to 2.5051. Saving model...\n",
      "\n",
      "LOG: Epoch [1874/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3895\n",
      "Epoch [1874/2000], Avg Train Loss: 3.3895\n",
      "Epoch [1874/2000], Avg Val Loss: 2.5049\n",
      "Validation loss improved from 2.5051 to 2.5049. Saving model...\n",
      "\n",
      "LOG: Epoch [1875/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4115\n",
      "Epoch [1875/2000], Avg Train Loss: 3.4115\n",
      "Epoch [1875/2000], Avg Val Loss: 2.5047\n",
      "Validation loss improved from 2.5049 to 2.5047. Saving model...\n",
      "\n",
      "LOG: Epoch [1876/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3999\n",
      "Epoch [1876/2000], Avg Train Loss: 3.3999\n",
      "Epoch [1876/2000], Avg Val Loss: 2.5045\n",
      "Validation loss improved from 2.5047 to 2.5045. Saving model...\n",
      "\n",
      "LOG: Epoch [1877/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4196\n",
      "Epoch [1877/2000], Avg Train Loss: 3.4196\n",
      "Epoch [1877/2000], Avg Val Loss: 2.5041\n",
      "Validation loss improved from 2.5045 to 2.5041. Saving model...\n",
      "\n",
      "LOG: Epoch [1878/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3869\n",
      "Epoch [1878/2000], Avg Train Loss: 3.3869\n",
      "Epoch [1878/2000], Avg Val Loss: 2.5039\n",
      "Validation loss improved from 2.5041 to 2.5039. Saving model...\n",
      "\n",
      "LOG: Epoch [1879/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3635\n",
      "Epoch [1879/2000], Avg Train Loss: 3.3635\n",
      "Epoch [1879/2000], Avg Val Loss: 2.5038\n",
      "Validation loss improved from 2.5039 to 2.5038. Saving model...\n",
      "\n",
      "LOG: Epoch [1880/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4115\n",
      "Epoch [1880/2000], Avg Train Loss: 3.4115\n",
      "Epoch [1880/2000], Avg Val Loss: 2.5036\n",
      "Validation loss improved from 2.5038 to 2.5036. Saving model...\n",
      "\n",
      "LOG: Epoch [1881/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3914\n",
      "Epoch [1881/2000], Avg Train Loss: 3.3914\n",
      "Epoch [1881/2000], Avg Val Loss: 2.5033\n",
      "Validation loss improved from 2.5036 to 2.5033. Saving model...\n",
      "\n",
      "LOG: Epoch [1882/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3557\n",
      "Epoch [1882/2000], Avg Train Loss: 3.3557\n",
      "Epoch [1882/2000], Avg Val Loss: 2.5032\n",
      "Validation loss improved from 2.5033 to 2.5032. Saving model...\n",
      "\n",
      "LOG: Epoch [1883/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3979\n",
      "Epoch [1883/2000], Avg Train Loss: 3.3979\n",
      "Epoch [1883/2000], Avg Val Loss: 2.5031\n",
      "Validation loss improved from 2.5032 to 2.5031. Saving model...\n",
      "\n",
      "LOG: Epoch [1884/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4542\n",
      "Epoch [1884/2000], Avg Train Loss: 3.4542\n",
      "Epoch [1884/2000], Avg Val Loss: 2.5030\n",
      "Validation loss improved from 2.5031 to 2.5030. Saving model...\n",
      "\n",
      "LOG: Epoch [1885/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3906\n",
      "Epoch [1885/2000], Avg Train Loss: 3.3906\n",
      "Epoch [1885/2000], Avg Val Loss: 2.5032\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1886/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4014\n",
      "Epoch [1886/2000], Avg Train Loss: 3.4014\n",
      "Epoch [1886/2000], Avg Val Loss: 2.5034\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1887/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4214\n",
      "Epoch [1887/2000], Avg Train Loss: 3.4214\n",
      "Epoch [1887/2000], Avg Val Loss: 2.5037\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1888/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4255\n",
      "Epoch [1888/2000], Avg Train Loss: 3.4255\n",
      "Epoch [1888/2000], Avg Val Loss: 2.5041\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1889/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3901\n",
      "Epoch [1889/2000], Avg Train Loss: 3.3901\n",
      "Epoch [1889/2000], Avg Val Loss: 2.5045\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1890/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4169\n",
      "Epoch [1890/2000], Avg Train Loss: 3.4169\n",
      "Epoch [1890/2000], Avg Val Loss: 2.5050\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1891/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3857\n",
      "Epoch [1891/2000], Avg Train Loss: 3.3857\n",
      "Epoch [1891/2000], Avg Val Loss: 2.5054\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1892/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4054\n",
      "Epoch [1892/2000], Avg Train Loss: 3.4054\n",
      "Epoch [1892/2000], Avg Val Loss: 2.5058\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1893/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4311\n",
      "Epoch [1893/2000], Avg Train Loss: 3.4311\n",
      "Epoch [1893/2000], Avg Val Loss: 2.5061\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1894/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3954\n",
      "Epoch [1894/2000], Avg Train Loss: 3.3954\n",
      "Epoch [1894/2000], Avg Val Loss: 2.5064\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1895/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3992\n",
      "Epoch [1895/2000], Avg Train Loss: 3.3992\n",
      "Epoch [1895/2000], Avg Val Loss: 2.5069\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1896/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4171\n",
      "Epoch [1896/2000], Avg Train Loss: 3.4171\n",
      "Epoch [1896/2000], Avg Val Loss: 2.5072\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1897/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4202\n",
      "Epoch [1897/2000], Avg Train Loss: 3.4202\n",
      "Epoch [1897/2000], Avg Val Loss: 2.5077\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1898/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4172\n",
      "Epoch [1898/2000], Avg Train Loss: 3.4172\n",
      "Epoch [1898/2000], Avg Val Loss: 2.5080\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1899/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3951\n",
      "Epoch [1899/2000], Avg Train Loss: 3.3951\n",
      "Epoch [1899/2000], Avg Val Loss: 2.5083\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1900/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3813\n",
      "Epoch [1900/2000], Avg Train Loss: 3.3813\n",
      "Epoch [1900/2000], Avg Val Loss: 2.5086\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1901/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3865\n",
      "Epoch [1901/2000], Avg Train Loss: 3.3865\n",
      "Epoch [1901/2000], Avg Val Loss: 2.5090\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1902/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4116\n",
      "Epoch [1902/2000], Avg Train Loss: 3.4116\n",
      "Epoch [1902/2000], Avg Val Loss: 2.5093\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1903/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3903\n",
      "Epoch [1903/2000], Avg Train Loss: 3.3903\n",
      "Epoch [1903/2000], Avg Val Loss: 2.5095\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1904/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3967\n",
      "Epoch [1904/2000], Avg Train Loss: 3.3967\n",
      "Epoch [1904/2000], Avg Val Loss: 2.5096\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1905/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3865\n",
      "Epoch [1905/2000], Avg Train Loss: 3.3865\n",
      "Epoch [1905/2000], Avg Val Loss: 2.5096\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1906/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4232\n",
      "Epoch [1906/2000], Avg Train Loss: 3.4232\n",
      "Epoch [1906/2000], Avg Val Loss: 2.5097\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1907/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3963\n",
      "Epoch [1907/2000], Avg Train Loss: 3.3963\n",
      "Epoch [1907/2000], Avg Val Loss: 2.5098\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1908/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4051\n",
      "Epoch [1908/2000], Avg Train Loss: 3.4051\n",
      "Epoch [1908/2000], Avg Val Loss: 2.5098\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1909/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4168\n",
      "Epoch [1909/2000], Avg Train Loss: 3.4168\n",
      "Epoch [1909/2000], Avg Val Loss: 2.5100\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1910/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3756\n",
      "Epoch [1910/2000], Avg Train Loss: 3.3756\n",
      "Epoch [1910/2000], Avg Val Loss: 2.5100\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1911/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3979\n",
      "Epoch [1911/2000], Avg Train Loss: 3.3979\n",
      "Epoch [1911/2000], Avg Val Loss: 2.5099\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1912/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3861\n",
      "Epoch [1912/2000], Avg Train Loss: 3.3861\n",
      "Epoch [1912/2000], Avg Val Loss: 2.5099\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1913/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4102\n",
      "Epoch [1913/2000], Avg Train Loss: 3.4102\n",
      "Epoch [1913/2000], Avg Val Loss: 2.5099\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1914/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3958\n",
      "Epoch [1914/2000], Avg Train Loss: 3.3958\n",
      "Epoch [1914/2000], Avg Val Loss: 2.5099\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1915/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3776\n",
      "Epoch [1915/2000], Avg Train Loss: 3.3776\n",
      "Epoch [1915/2000], Avg Val Loss: 2.5101\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1916/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4242\n",
      "Epoch [1916/2000], Avg Train Loss: 3.4242\n",
      "Epoch [1916/2000], Avg Val Loss: 2.5099\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1917/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3958\n",
      "Epoch [1917/2000], Avg Train Loss: 3.3958\n",
      "Epoch [1917/2000], Avg Val Loss: 2.5096\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1918/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3916\n",
      "Epoch [1918/2000], Avg Train Loss: 3.3916\n",
      "Epoch [1918/2000], Avg Val Loss: 2.5092\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1919/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4268\n",
      "Epoch [1919/2000], Avg Train Loss: 3.4268\n",
      "Epoch [1919/2000], Avg Val Loss: 2.5089\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1920/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3861\n",
      "Epoch [1920/2000], Avg Train Loss: 3.3861\n",
      "Epoch [1920/2000], Avg Val Loss: 2.5085\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1921/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3938\n",
      "Epoch [1921/2000], Avg Train Loss: 3.3938\n",
      "Epoch [1921/2000], Avg Val Loss: 2.5082\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1922/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3922\n",
      "Epoch [1922/2000], Avg Train Loss: 3.3922\n",
      "Epoch [1922/2000], Avg Val Loss: 2.5079\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1923/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3759\n",
      "Epoch [1923/2000], Avg Train Loss: 3.3759\n",
      "Epoch [1923/2000], Avg Val Loss: 2.5075\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1924/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3759\n",
      "Epoch [1924/2000], Avg Train Loss: 3.3759\n",
      "Epoch [1924/2000], Avg Val Loss: 2.5072\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1925/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3919\n",
      "Epoch [1925/2000], Avg Train Loss: 3.3919\n",
      "Epoch [1925/2000], Avg Val Loss: 2.5069\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1926/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3783\n",
      "Epoch [1926/2000], Avg Train Loss: 3.3783\n",
      "Epoch [1926/2000], Avg Val Loss: 2.5071\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1927/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4164\n",
      "Epoch [1927/2000], Avg Train Loss: 3.4164\n",
      "Epoch [1927/2000], Avg Val Loss: 2.5070\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1928/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3514\n",
      "Epoch [1928/2000], Avg Train Loss: 3.3514\n",
      "Epoch [1928/2000], Avg Val Loss: 2.5071\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1929/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4078\n",
      "Epoch [1929/2000], Avg Train Loss: 3.4078\n",
      "Epoch [1929/2000], Avg Val Loss: 2.5072\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1930/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4064\n",
      "Epoch [1930/2000], Avg Train Loss: 3.4064\n",
      "Epoch [1930/2000], Avg Val Loss: 2.5074\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1931/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3895\n",
      "Epoch [1931/2000], Avg Train Loss: 3.3895\n",
      "Epoch [1931/2000], Avg Val Loss: 2.5077\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1932/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3635\n",
      "Epoch [1932/2000], Avg Train Loss: 3.3635\n",
      "Epoch [1932/2000], Avg Val Loss: 2.5079\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1933/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3538\n",
      "Epoch [1933/2000], Avg Train Loss: 3.3538\n",
      "Epoch [1933/2000], Avg Val Loss: 2.5081\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1934/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3805\n",
      "Epoch [1934/2000], Avg Train Loss: 3.3805\n",
      "Epoch [1934/2000], Avg Val Loss: 2.5083\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1935/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4134\n",
      "Epoch [1935/2000], Avg Train Loss: 3.4134\n",
      "Epoch [1935/2000], Avg Val Loss: 2.5085\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1936/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4010\n",
      "Epoch [1936/2000], Avg Train Loss: 3.4010\n",
      "Epoch [1936/2000], Avg Val Loss: 2.5087\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1937/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3851\n",
      "Epoch [1937/2000], Avg Train Loss: 3.3851\n",
      "Epoch [1937/2000], Avg Val Loss: 2.5087\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1938/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3851\n",
      "Epoch [1938/2000], Avg Train Loss: 3.3851\n",
      "Epoch [1938/2000], Avg Val Loss: 2.5087\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1939/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3861\n",
      "Epoch [1939/2000], Avg Train Loss: 3.3861\n",
      "Epoch [1939/2000], Avg Val Loss: 2.5089\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1940/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3873\n",
      "Epoch [1940/2000], Avg Train Loss: 3.3873\n",
      "Epoch [1940/2000], Avg Val Loss: 2.5090\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1941/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4313\n",
      "Epoch [1941/2000], Avg Train Loss: 3.4313\n",
      "Epoch [1941/2000], Avg Val Loss: 2.5093\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1942/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3749\n",
      "Epoch [1942/2000], Avg Train Loss: 3.3749\n",
      "Epoch [1942/2000], Avg Val Loss: 2.5094\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1943/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3579\n",
      "Epoch [1943/2000], Avg Train Loss: 3.3579\n",
      "Epoch [1943/2000], Avg Val Loss: 2.5094\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1944/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3636\n",
      "Epoch [1944/2000], Avg Train Loss: 3.3636\n",
      "Epoch [1944/2000], Avg Val Loss: 2.5094\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1945/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4020\n",
      "Epoch [1945/2000], Avg Train Loss: 3.4020\n",
      "Epoch [1945/2000], Avg Val Loss: 2.5093\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1946/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3905\n",
      "Epoch [1946/2000], Avg Train Loss: 3.3905\n",
      "Epoch [1946/2000], Avg Val Loss: 2.5091\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1947/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3831\n",
      "Epoch [1947/2000], Avg Train Loss: 3.3831\n",
      "Epoch [1947/2000], Avg Val Loss: 2.5090\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1948/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3616\n",
      "Epoch [1948/2000], Avg Train Loss: 3.3616\n",
      "Epoch [1948/2000], Avg Val Loss: 2.5088\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1949/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3688\n",
      "Epoch [1949/2000], Avg Train Loss: 3.3688\n",
      "Epoch [1949/2000], Avg Val Loss: 2.5089\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1950/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3766\n",
      "Epoch [1950/2000], Avg Train Loss: 3.3766\n",
      "Epoch [1950/2000], Avg Val Loss: 2.5088\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1951/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3836\n",
      "Epoch [1951/2000], Avg Train Loss: 3.3836\n",
      "Epoch [1951/2000], Avg Val Loss: 2.5084\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1952/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3831\n",
      "Epoch [1952/2000], Avg Train Loss: 3.3831\n",
      "Epoch [1952/2000], Avg Val Loss: 2.5079\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [1953/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3536\n",
      "Epoch [1953/2000], Avg Train Loss: 3.3536\n",
      "Epoch [1953/2000], Avg Val Loss: 2.5074\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [1954/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4115\n",
      "Epoch [1954/2000], Avg Train Loss: 3.4115\n",
      "Epoch [1954/2000], Avg Val Loss: 2.5068\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [1955/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3733\n",
      "Epoch [1955/2000], Avg Train Loss: 3.3733\n",
      "Epoch [1955/2000], Avg Val Loss: 2.5064\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [1956/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3640\n",
      "Epoch [1956/2000], Avg Train Loss: 3.3640\n",
      "Epoch [1956/2000], Avg Val Loss: 2.5060\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [1957/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3942\n",
      "Epoch [1957/2000], Avg Train Loss: 3.3942\n",
      "Epoch [1957/2000], Avg Val Loss: 2.5058\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [1958/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3639\n",
      "Epoch [1958/2000], Avg Train Loss: 3.3639\n",
      "Epoch [1958/2000], Avg Val Loss: 2.5057\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [1959/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4013\n",
      "Epoch [1959/2000], Avg Train Loss: 3.4013\n",
      "Epoch [1959/2000], Avg Val Loss: 2.5056\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [1960/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4139\n",
      "Epoch [1960/2000], Avg Train Loss: 3.4139\n",
      "Epoch [1960/2000], Avg Val Loss: 2.5057\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [1961/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3778\n",
      "Epoch [1961/2000], Avg Train Loss: 3.3778\n",
      "Epoch [1961/2000], Avg Val Loss: 2.5057\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [1962/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3847\n",
      "Epoch [1962/2000], Avg Train Loss: 3.3847\n",
      "Epoch [1962/2000], Avg Val Loss: 2.5057\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [1963/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3676\n",
      "Epoch [1963/2000], Avg Train Loss: 3.3676\n",
      "Epoch [1963/2000], Avg Val Loss: 2.5056\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [1964/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4178\n",
      "Epoch [1964/2000], Avg Train Loss: 3.4178\n",
      "Epoch [1964/2000], Avg Val Loss: 2.5055\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [1965/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3752\n",
      "Epoch [1965/2000], Avg Train Loss: 3.3752\n",
      "Epoch [1965/2000], Avg Val Loss: 2.5053\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [1966/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3783\n",
      "Epoch [1966/2000], Avg Train Loss: 3.3783\n",
      "Epoch [1966/2000], Avg Val Loss: 2.5048\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [1967/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3661\n",
      "Epoch [1967/2000], Avg Train Loss: 3.3661\n",
      "Epoch [1967/2000], Avg Val Loss: 2.5044\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [1968/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4232\n",
      "Epoch [1968/2000], Avg Train Loss: 3.4232\n",
      "Epoch [1968/2000], Avg Val Loss: 2.5040\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [1969/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3773\n",
      "Epoch [1969/2000], Avg Train Loss: 3.3773\n",
      "Epoch [1969/2000], Avg Val Loss: 2.5037\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [1970/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3497\n",
      "Epoch [1970/2000], Avg Train Loss: 3.3497\n",
      "Epoch [1970/2000], Avg Val Loss: 2.5038\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [1971/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4176\n",
      "Epoch [1971/2000], Avg Train Loss: 3.4176\n",
      "Epoch [1971/2000], Avg Val Loss: 2.5040\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [1972/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3548\n",
      "Epoch [1972/2000], Avg Train Loss: 3.3548\n",
      "Epoch [1972/2000], Avg Val Loss: 2.5042\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [1973/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4257\n",
      "Epoch [1973/2000], Avg Train Loss: 3.4257\n",
      "Epoch [1973/2000], Avg Val Loss: 2.5045\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [1974/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3976\n",
      "Epoch [1974/2000], Avg Train Loss: 3.3976\n",
      "Epoch [1974/2000], Avg Val Loss: 2.5050\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [1975/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3679\n",
      "Epoch [1975/2000], Avg Train Loss: 3.3679\n",
      "Epoch [1975/2000], Avg Val Loss: 2.5056\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [1976/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3586\n",
      "Epoch [1976/2000], Avg Train Loss: 3.3586\n",
      "Epoch [1976/2000], Avg Val Loss: 2.5062\n",
      "Validation loss did not improve. Patience: 92/100\n",
      "\n",
      "LOG: Epoch [1977/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4027\n",
      "Epoch [1977/2000], Avg Train Loss: 3.4027\n",
      "Epoch [1977/2000], Avg Val Loss: 2.5065\n",
      "Validation loss did not improve. Patience: 93/100\n",
      "\n",
      "LOG: Epoch [1978/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3659\n",
      "Epoch [1978/2000], Avg Train Loss: 3.3659\n",
      "Epoch [1978/2000], Avg Val Loss: 2.5068\n",
      "Validation loss did not improve. Patience: 94/100\n",
      "\n",
      "LOG: Epoch [1979/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3688\n",
      "Epoch [1979/2000], Avg Train Loss: 3.3688\n",
      "Epoch [1979/2000], Avg Val Loss: 2.5070\n",
      "Validation loss did not improve. Patience: 95/100\n",
      "\n",
      "LOG: Epoch [1980/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3523\n",
      "Epoch [1980/2000], Avg Train Loss: 3.3523\n",
      "Epoch [1980/2000], Avg Val Loss: 2.5075\n",
      "Validation loss did not improve. Patience: 96/100\n",
      "\n",
      "LOG: Epoch [1981/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3854\n",
      "Epoch [1981/2000], Avg Train Loss: 3.3854\n",
      "Epoch [1981/2000], Avg Val Loss: 2.5079\n",
      "Validation loss did not improve. Patience: 97/100\n",
      "\n",
      "LOG: Epoch [1982/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3664\n",
      "Epoch [1982/2000], Avg Train Loss: 3.3664\n",
      "Epoch [1982/2000], Avg Val Loss: 2.5083\n",
      "Validation loss did not improve. Patience: 98/100\n",
      "\n",
      "LOG: Epoch [1983/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3667\n",
      "Epoch [1983/2000], Avg Train Loss: 3.3667\n",
      "Epoch [1983/2000], Avg Val Loss: 2.5087\n",
      "Validation loss did not improve. Patience: 99/100\n",
      "\n",
      "LOG: Epoch [1984/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3909\n",
      "Epoch [1984/2000], Avg Train Loss: 3.3909\n",
      "Epoch [1984/2000], Avg Val Loss: 2.5089\n",
      "Validation loss did not improve. Patience: 100/100\n",
      "Early stopping triggered at epoch 1984. No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_model = SupConNet().to(device)\n",
    "tscl_criterion = SupConLoss(temperature=0.07).to(device)\n",
    "tscl_optimizer = optim.Adam(tscl_model.parameters(), lr=1e-4, weight_decay=1e-5)  # Increased learning rate\n",
    "\n",
    "tscl_patience = 100\n",
    "tscl_best_val_loss = float('inf')\n",
    "tscl_epochs_without_improvement = 0\n",
    "\n",
    "tscl_num_epochs = 2000\n",
    "tscl_train_losses = []\n",
    "tscl_val_losses = []\n",
    "\n",
    "# TRAINING\n",
    "for tscl_epoch in range(tscl_num_epochs):\n",
    "    print(f\"\\nLOG: Epoch [{tscl_epoch + 1}/{tscl_num_epochs}] - Training\")\n",
    "    tscl_model.train()\n",
    "    tscl_total_loss = 0\n",
    "\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_train_loader):\n",
    "        vectors = vectors.to(device).float()  # moving input tensors to GPU\n",
    "        labels = labels.to(device)  # moving labels to GPU\n",
    "\n",
    "        # forward pass to get projections\n",
    "        projections = tscl_model(vectors)\n",
    "\n",
    "        # calc contrastive loss\n",
    "        loss = tscl_criterion(projections, labels)\n",
    "\n",
    "        # backprop and optimization\n",
    "        tscl_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        tscl_optimizer.step()\n",
    "\n",
    "        tscl_total_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 1 == 0:\n",
    "            print(f\"    Batch [{batch_idx + 1}/{len(tscl_train_loader)}], \"\n",
    "                  f\"Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc avg training loss for the epoch\n",
    "    tscl_avg_train_loss = tscl_total_loss / len(tscl_train_loader)\n",
    "    tscl_train_losses.append(tscl_avg_train_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {tscl_avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    tscl_model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (vectors, labels) in enumerate(tscl_val_loader):\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            projections = tscl_model(vectors)\n",
    "\n",
    "            loss = tscl_criterion(projections, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Batch [{batch_idx + 1}/{len(tscl_val_loader)}], \"\n",
    "                      f\"Val Loss: {loss.item():.4f}\")\n",
    "\n",
    "    tscl_avg_val_loss = total_val_loss / len(tscl_val_loader)\n",
    "    tscl_val_losses.append(tscl_avg_val_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Val Loss: {tscl_avg_val_loss:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if tscl_avg_val_loss < tscl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_best_val_loss:.4f} to {tscl_avg_val_loss:.4f}. Saving model...\")\n",
    "        tscl_best_val_loss = tscl_avg_val_loss\n",
    "        tscl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        tscl_epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {tscl_epochs_without_improvement}/{tscl_patience}\")\n",
    "\n",
    "    # stopping training if validation loss hasn't improved for patience amount of epochs\n",
    "    if tscl_epochs_without_improvement >= tscl_patience:\n",
    "        print(f\"Early stopping triggered at epoch {tscl_epoch + 1}. No improvement for {tscl_patience} epochs.\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(tscl_train_losses) + 1), tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, len(tscl_val_losses) + 1), tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:35.410187Z",
     "iopub.status.busy": "2025-05-08T19:08:35.409182Z",
     "iopub.status.idle": "2025-05-08T19:08:35.559435Z",
     "shell.execute_reply": "2025-05-08T19:08:35.559435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/12], Loss: 6.4508\n",
      "\n",
      "Test Loss: 5.5464\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "tscl_model.eval()\n",
    "total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = tscl_model(vectors)\n",
    "        loss = criterion(projections, labels)\n",
    "        total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(tscl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "avg_test_loss = total_test_loss / len(tscl_test_loader)\n",
    "print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs = range(1, len(tscl_train_losses) + 1)\n",
    "plt.plot(epochs, tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(epochs, tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving representations learnt by Typical SCL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:35.562440Z",
     "iopub.status.busy": "2025-05-08T19:08:35.561440Z",
     "iopub.status.idle": "2025-05-08T19:08:35.637989Z",
     "shell.execute_reply": "2025-05-08T19:08:35.637989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'tscl_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'tscl_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/12 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'tscl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "tscl_rep_dir = \"tscl_representations\"\n",
    "os.makedirs(tscl_rep_dir, exist_ok=True)\n",
    "\n",
    "tscl_loaders = {\n",
    "    'train': tscl_train_loader,\n",
    "    'val': tscl_val_loader,\n",
    "    'test': tscl_test_loader\n",
    "}\n",
    "\n",
    "tscl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_split_name, tscl_loader in tscl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {tscl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        tscl_split_dir = os.path.join(tscl_rep_dir, tscl_split_name)\n",
    "        os.makedirs(tscl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for tscl_batch_idx, (tscl_vectors, tscl_labels) in enumerate(tscl_loader):\n",
    "            tscl_vectors = tscl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            tscl_projections = tscl_model(tscl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            tscl_projections_np = tscl_projections.cpu().numpy()\n",
    "            tscl_labels_np = tscl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_encoded_batch_{tscl_batch_idx}.npy\"), tscl_projections_np)\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_labels_batch_{tscl_batch_idx}.npy\"), tscl_labels_np)\n",
    "            \n",
    "            if (tscl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {tscl_batch_idx + 1}/{len(tscl_loader)} for {tscl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {tscl_split_name} dataset. Representations saved in '{tscl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying representations learnt by SCL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:35.641267Z",
     "iopub.status.busy": "2025-05-08T19:08:35.641267Z",
     "iopub.status.idle": "2025-05-08T19:08:35.645267Z",
     "shell.execute_reply": "2025-05-08T19:08:35.645267Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_tscl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    tscl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    tscl_all_reps = []\n",
    "    tscl_all_labels = []\n",
    "\n",
    "    for tscl_rep_file in tscl_rep_files:\n",
    "        #deriving label filenames\n",
    "        tscl_label_file = tscl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        tscl_reps = np.load(tscl_rep_file)\n",
    "        tscl_labels = np.load(tscl_label_file)\n",
    "\n",
    "        tscl_all_reps.append(tscl_reps)\n",
    "        tscl_all_labels.append(tscl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    tscl_all_reps = np.concatenate(tscl_all_reps, axis = 0)\n",
    "    tscl_all_labels = np.concatenate(tscl_all_labels, axis = 0)\n",
    "\n",
    "    return tscl_all_reps, tscl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:35.648308Z",
     "iopub.status.busy": "2025-05-08T19:08:35.648308Z",
     "iopub.status.idle": "2025-05-08T19:08:35.813272Z",
     "shell.execute_reply": "2025-05-08T19:08:35.813272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (280, 128)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 128)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "tscl_lrm_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_lrm_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_lrm_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_lrm_train_reps, tscl_lrm_train_labels = load_tscl_reps_and_labels(tscl_lrm_train_dir)\n",
    "tscl_lrm_val_reps, tscl_lrm_val_labels = load_tscl_reps_and_labels(tscl_lrm_val_dir)\n",
    "tscl_lrm_test_reps, tscl_lrm_test_labels = load_tscl_reps_and_labels(tscl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", tscl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:35.817001Z",
     "iopub.status.busy": "2025-05-08T19:08:35.815992Z",
     "iopub.status.idle": "2025-05-08T19:08:35.868005Z",
     "shell.execute_reply": "2025-05-08T19:08:35.868005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 81.43%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       0.71      1.00      0.83         5\n",
      "           2       1.00      0.80      0.89         5\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       1.00      0.40      0.57         5\n",
      "           5       0.75      0.60      0.67         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      0.60      0.75         5\n",
      "           8       0.60      0.60      0.60         5\n",
      "           9       0.71      1.00      0.83         5\n",
      "          10       0.62      1.00      0.77         5\n",
      "          11       0.67      0.80      0.73         5\n",
      "          12       0.75      0.60      0.67         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.81        70\n",
      "   macro avg       0.84      0.81      0.81        70\n",
      "weighted avg       0.84      0.81      0.81        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 88.58%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       245\n",
      "           1       0.75      0.95      0.84        76\n",
      "           2       0.95      0.96      0.95       226\n",
      "           3       0.81      0.97      0.89       190\n",
      "           4       0.92      0.66      0.77       244\n",
      "           5       0.77      0.70      0.73       244\n",
      "           6       0.98      0.96      0.97       234\n",
      "           7       0.97      0.95      0.96       178\n",
      "           8       0.80      0.82      0.81       289\n",
      "           9       0.77      0.96      0.85       223\n",
      "          10       0.95      0.93      0.94       280\n",
      "          11       0.94      0.99      0.96       156\n",
      "          12       0.86      0.81      0.83       243\n",
      "          13       1.00      0.96      0.98        70\n",
      "\n",
      "    accuracy                           0.89      2898\n",
      "   macro avg       0.89      0.90      0.89      2898\n",
      "weighted avg       0.89      0.89      0.88      2898\n",
      "\n",
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# training LRM on the tscl representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "tscl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "tscl_logistic_clf.fit(tscl_lrm_train_reps, tscl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# eval on val set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "tscl_lrm_val_predictions = tscl_logistic_clf.predict(tscl_lrm_val_reps)\n",
    "tscl_lrm_val_accuracy = accuracy_score(tscl_lrm_val_labels, tscl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {tscl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(tscl_lrm_val_labels, tscl_lrm_val_predictions))\n",
    "\n",
    "# eval on test\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "tscl_lrm_test_predictions = tscl_logistic_clf.predict(tscl_lrm_test_reps)\n",
    "tscl_lrm_test_accuracy = accuracy_score(tscl_lrm_test_labels, tscl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {tscl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(tscl_lrm_test_labels, tscl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_predictions.npy'), tscl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_true_labels.npy'), tscl_lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by Typical SCL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:35.870520Z",
     "iopub.status.busy": "2025-05-08T19:08:35.870520Z",
     "iopub.status.idle": "2025-05-08T19:08:35.874484Z",
     "shell.execute_reply": "2025-05-08T19:08:35.874484Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:35.877079Z",
     "iopub.status.busy": "2025-05-08T19:08:35.877079Z",
     "iopub.status.idle": "2025-05-08T19:08:35.886556Z",
     "shell.execute_reply": "2025-05-08T19:08:35.886556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (280, 128)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 128)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "tscl_mlp_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_mlp_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_mlp_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_mlp_train_reps, tscl_mlp_train_labels = load_tscl_reps_and_labels(tscl_mlp_train_dir)\n",
    "tscl_mlp_val_reps, tscl_mlp_val_labels = load_tscl_reps_and_labels(tscl_mlp_val_dir)\n",
    "tscl_mlp_test_reps, tscl_mlp_test_labels = load_tscl_reps_and_labels(tscl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",tscl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:35.889069Z",
     "iopub.status.busy": "2025-05-08T19:08:35.889069Z",
     "iopub.status.idle": "2025-05-08T19:08:35.893555Z",
     "shell.execute_reply": "2025-05-08T19:08:35.893555Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "tscl_mlp_train_embeddings_torch = torch.tensor(tscl_mlp_train_reps, dtype=torch.float32)\n",
    "tscl_mlp_train_labels_torch = torch.tensor(tscl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_val_embeddings_torch = torch.tensor(tscl_mlp_val_reps, dtype=torch.float32)\n",
    "tscl_mlp_val_labels_torch = torch.tensor(tscl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_test_embeddings_torch = torch.tensor(tscl_mlp_test_reps, dtype=torch.float32)\n",
    "tscl_mlp_test_labels_torch = torch.tensor(tscl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "tscl_mlp_train_dataset = TensorDataset(tscl_mlp_train_embeddings_torch, tscl_mlp_train_labels_torch)\n",
    "tscl_mlp_val_dataset = TensorDataset(tscl_mlp_val_embeddings_torch, tscl_mlp_val_labels_torch)\n",
    "tscl_mlp_test_dataset = TensorDataset(tscl_mlp_test_embeddings_torch, tscl_mlp_test_labels_torch)\n",
    "\n",
    "tscl_mlp_batch_size = 64\n",
    "tscl_mlp_train_loader = DataLoader(tscl_mlp_train_dataset, batch_size=tscl_mlp_batch_size, shuffle=True)\n",
    "tscl_mlp_val_loader = DataLoader(tscl_mlp_val_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n",
    "tscl_mlp_test_loader = DataLoader(tscl_mlp_test_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:35.896560Z",
     "iopub.status.busy": "2025-05-08T19:08:35.896560Z",
     "iopub.status.idle": "2025-05-08T19:08:40.221509Z",
     "shell.execute_reply": "2025-05-08T19:08:40.221509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.8501  |  Val Loss: 2.8211\n",
      "Validation loss improved from inf to 2.8211.\n",
      "[Epoch 2/1000] Train Loss: 2.8106  |  Val Loss: 2.7861\n",
      "Validation loss improved from 2.8211 to 2.7861.\n",
      "[Epoch 3/1000] Train Loss: 2.7752  |  Val Loss: 2.7517\n",
      "Validation loss improved from 2.7861 to 2.7517.\n",
      "[Epoch 4/1000] Train Loss: 2.7406  |  Val Loss: 2.7184\n",
      "Validation loss improved from 2.7517 to 2.7184.\n",
      "[Epoch 5/1000] Train Loss: 2.7054  |  Val Loss: 2.6895\n",
      "Validation loss improved from 2.7184 to 2.6895.\n",
      "[Epoch 6/1000] Train Loss: 2.6761  |  Val Loss: 2.6623\n",
      "Validation loss improved from 2.6895 to 2.6623.\n",
      "[Epoch 7/1000] Train Loss: 2.6473  |  Val Loss: 2.6376\n",
      "Validation loss improved from 2.6623 to 2.6376.\n",
      "[Epoch 8/1000] Train Loss: 2.6210  |  Val Loss: 2.6145\n",
      "Validation loss improved from 2.6376 to 2.6145.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/1000] Train Loss: 2.5960  |  Val Loss: 2.5933\n",
      "Validation loss improved from 2.6145 to 2.5933.\n",
      "[Epoch 10/1000] Train Loss: 2.5740  |  Val Loss: 2.5729\n",
      "Validation loss improved from 2.5933 to 2.5729.\n",
      "[Epoch 11/1000] Train Loss: 2.5529  |  Val Loss: 2.5529\n",
      "Validation loss improved from 2.5729 to 2.5529.\n",
      "[Epoch 12/1000] Train Loss: 2.5316  |  Val Loss: 2.5341\n",
      "Validation loss improved from 2.5529 to 2.5341.\n",
      "[Epoch 13/1000] Train Loss: 2.5102  |  Val Loss: 2.5165\n",
      "Validation loss improved from 2.5341 to 2.5165.\n",
      "[Epoch 14/1000] Train Loss: 2.4913  |  Val Loss: 2.4990\n",
      "Validation loss improved from 2.5165 to 2.4990.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/1000] Train Loss: 2.4720  |  Val Loss: 2.4825\n",
      "Validation loss improved from 2.4990 to 2.4825.\n",
      "[Epoch 16/1000] Train Loss: 2.4544  |  Val Loss: 2.4644\n",
      "Validation loss improved from 2.4825 to 2.4644.\n",
      "[Epoch 17/1000] Train Loss: 2.4353  |  Val Loss: 2.4446\n",
      "Validation loss improved from 2.4644 to 2.4446.\n",
      "[Epoch 18/1000] Train Loss: 2.4152  |  Val Loss: 2.4263\n",
      "Validation loss improved from 2.4446 to 2.4263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/1000] Train Loss: 2.3946  |  Val Loss: 2.4095\n",
      "Validation loss improved from 2.4263 to 2.4095.\n",
      "[Epoch 20/1000] Train Loss: 2.3765  |  Val Loss: 2.3925\n",
      "Validation loss improved from 2.4095 to 2.3925.\n",
      "[Epoch 21/1000] Train Loss: 2.3575  |  Val Loss: 2.3763\n",
      "Validation loss improved from 2.3925 to 2.3763.\n",
      "[Epoch 22/1000] Train Loss: 2.3399  |  Val Loss: 2.3603\n",
      "Validation loss improved from 2.3763 to 2.3603.\n",
      "[Epoch 23/1000] Train Loss: 2.3225  |  Val Loss: 2.3451\n",
      "Validation loss improved from 2.3603 to 2.3451.\n",
      "[Epoch 24/1000] Train Loss: 2.3059  |  Val Loss: 2.3305\n",
      "Validation loss improved from 2.3451 to 2.3305.\n",
      "[Epoch 25/1000] Train Loss: 2.2896  |  Val Loss: 2.3159\n",
      "Validation loss improved from 2.3305 to 2.3159.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26/1000] Train Loss: 2.2725  |  Val Loss: 2.3016\n",
      "Validation loss improved from 2.3159 to 2.3016.\n",
      "[Epoch 27/1000] Train Loss: 2.2564  |  Val Loss: 2.2873\n",
      "Validation loss improved from 2.3016 to 2.2873.\n",
      "[Epoch 28/1000] Train Loss: 2.2395  |  Val Loss: 2.2732\n",
      "Validation loss improved from 2.2873 to 2.2732.\n",
      "[Epoch 29/1000] Train Loss: 2.2233  |  Val Loss: 2.2593\n",
      "Validation loss improved from 2.2732 to 2.2593.\n",
      "[Epoch 30/1000] Train Loss: 2.2064  |  Val Loss: 2.2453\n",
      "Validation loss improved from 2.2593 to 2.2453.\n",
      "[Epoch 31/1000] Train Loss: 2.1899  |  Val Loss: 2.2311\n",
      "Validation loss improved from 2.2453 to 2.2311.\n",
      "[Epoch 32/1000] Train Loss: 2.1736  |  Val Loss: 2.2169\n",
      "Validation loss improved from 2.2311 to 2.2169.\n",
      "[Epoch 33/1000] Train Loss: 2.1567  |  Val Loss: 2.2028\n",
      "Validation loss improved from 2.2169 to 2.2028.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/1000] Train Loss: 2.1399  |  Val Loss: 2.1886\n",
      "Validation loss improved from 2.2028 to 2.1886.\n",
      "[Epoch 35/1000] Train Loss: 2.1229  |  Val Loss: 2.1740\n",
      "Validation loss improved from 2.1886 to 2.1740.\n",
      "[Epoch 36/1000] Train Loss: 2.1057  |  Val Loss: 2.1590\n",
      "Validation loss improved from 2.1740 to 2.1590.\n",
      "[Epoch 37/1000] Train Loss: 2.0878  |  Val Loss: 2.1437\n",
      "Validation loss improved from 2.1590 to 2.1437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/1000] Train Loss: 2.0700  |  Val Loss: 2.1279\n",
      "Validation loss improved from 2.1437 to 2.1279.\n",
      "[Epoch 39/1000] Train Loss: 2.0518  |  Val Loss: 2.1120\n",
      "Validation loss improved from 2.1279 to 2.1120.\n",
      "[Epoch 40/1000] Train Loss: 2.0331  |  Val Loss: 2.0961\n",
      "Validation loss improved from 2.1120 to 2.0961.\n",
      "[Epoch 41/1000] Train Loss: 2.0146  |  Val Loss: 2.0799\n",
      "Validation loss improved from 2.0961 to 2.0799.\n",
      "[Epoch 42/1000] Train Loss: 1.9959  |  Val Loss: 2.0635\n",
      "Validation loss improved from 2.0799 to 2.0635.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43/1000] Train Loss: 1.9773  |  Val Loss: 2.0468\n",
      "Validation loss improved from 2.0635 to 2.0468.\n",
      "[Epoch 44/1000] Train Loss: 1.9582  |  Val Loss: 2.0302\n",
      "Validation loss improved from 2.0468 to 2.0302.\n",
      "[Epoch 45/1000] Train Loss: 1.9392  |  Val Loss: 2.0137\n",
      "Validation loss improved from 2.0302 to 2.0137.\n",
      "[Epoch 46/1000] Train Loss: 1.9203  |  Val Loss: 1.9967\n",
      "Validation loss improved from 2.0137 to 1.9967.\n",
      "[Epoch 47/1000] Train Loss: 1.9010  |  Val Loss: 1.9793\n",
      "Validation loss improved from 1.9967 to 1.9793.\n",
      "[Epoch 48/1000] Train Loss: 1.8813  |  Val Loss: 1.9622\n",
      "Validation loss improved from 1.9793 to 1.9622.\n",
      "[Epoch 49/1000] Train Loss: 1.8617  |  Val Loss: 1.9449\n",
      "Validation loss improved from 1.9622 to 1.9449.\n",
      "[Epoch 50/1000] Train Loss: 1.8422  |  Val Loss: 1.9275\n",
      "Validation loss improved from 1.9449 to 1.9275.\n",
      "[Epoch 51/1000] Train Loss: 1.8226  |  Val Loss: 1.9102\n",
      "Validation loss improved from 1.9275 to 1.9102.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 52/1000] Train Loss: 1.8026  |  Val Loss: 1.8929\n",
      "Validation loss improved from 1.9102 to 1.8929.\n",
      "[Epoch 53/1000] Train Loss: 1.7830  |  Val Loss: 1.8758\n",
      "Validation loss improved from 1.8929 to 1.8758.\n",
      "[Epoch 54/1000] Train Loss: 1.7630  |  Val Loss: 1.8585\n",
      "Validation loss improved from 1.8758 to 1.8585.\n",
      "[Epoch 55/1000] Train Loss: 1.7434  |  Val Loss: 1.8408\n",
      "Validation loss improved from 1.8585 to 1.8408.\n",
      "[Epoch 56/1000] Train Loss: 1.7230  |  Val Loss: 1.8232\n",
      "Validation loss improved from 1.8408 to 1.8232.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 57/1000] Train Loss: 1.7026  |  Val Loss: 1.8057\n",
      "Validation loss improved from 1.8232 to 1.8057.\n",
      "[Epoch 58/1000] Train Loss: 1.6822  |  Val Loss: 1.7882\n",
      "Validation loss improved from 1.8057 to 1.7882.\n",
      "[Epoch 59/1000] Train Loss: 1.6615  |  Val Loss: 1.7708\n",
      "Validation loss improved from 1.7882 to 1.7708.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 60/1000] Train Loss: 1.6405  |  Val Loss: 1.7535\n",
      "Validation loss improved from 1.7708 to 1.7535.\n",
      "[Epoch 61/1000] Train Loss: 1.6202  |  Val Loss: 1.7358\n",
      "Validation loss improved from 1.7535 to 1.7358.\n",
      "[Epoch 62/1000] Train Loss: 1.5987  |  Val Loss: 1.7176\n",
      "Validation loss improved from 1.7358 to 1.7176.\n",
      "[Epoch 63/1000] Train Loss: 1.5774  |  Val Loss: 1.6994\n",
      "Validation loss improved from 1.7176 to 1.6994.\n",
      "[Epoch 64/1000] Train Loss: 1.5565  |  Val Loss: 1.6810\n",
      "Validation loss improved from 1.6994 to 1.6810.\n",
      "[Epoch 65/1000] Train Loss: 1.5349  |  Val Loss: 1.6628\n",
      "Validation loss improved from 1.6810 to 1.6628.\n",
      "[Epoch 66/1000] Train Loss: 1.5138  |  Val Loss: 1.6443\n",
      "Validation loss improved from 1.6628 to 1.6443.\n",
      "[Epoch 67/1000] Train Loss: 1.4927  |  Val Loss: 1.6259\n",
      "Validation loss improved from 1.6443 to 1.6259.\n",
      "[Epoch 68/1000] Train Loss: 1.4713  |  Val Loss: 1.6076\n",
      "Validation loss improved from 1.6259 to 1.6076.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 69/1000] Train Loss: 1.4502  |  Val Loss: 1.5893\n",
      "Validation loss improved from 1.6076 to 1.5893.\n",
      "[Epoch 70/1000] Train Loss: 1.4291  |  Val Loss: 1.5710\n",
      "Validation loss improved from 1.5893 to 1.5710.\n",
      "[Epoch 71/1000] Train Loss: 1.4079  |  Val Loss: 1.5525\n",
      "Validation loss improved from 1.5710 to 1.5525.\n",
      "[Epoch 72/1000] Train Loss: 1.3862  |  Val Loss: 1.5344\n",
      "Validation loss improved from 1.5525 to 1.5344.\n",
      "[Epoch 73/1000] Train Loss: 1.3650  |  Val Loss: 1.5164\n",
      "Validation loss improved from 1.5344 to 1.5164.\n",
      "[Epoch 74/1000] Train Loss: 1.3437  |  Val Loss: 1.4981\n",
      "Validation loss improved from 1.5164 to 1.4981.\n",
      "[Epoch 75/1000] Train Loss: 1.3228  |  Val Loss: 1.4800\n",
      "Validation loss improved from 1.4981 to 1.4800.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 76/1000] Train Loss: 1.3017  |  Val Loss: 1.4623\n",
      "Validation loss improved from 1.4800 to 1.4623.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 77/1000] Train Loss: 1.2810  |  Val Loss: 1.4444\n",
      "Validation loss improved from 1.4623 to 1.4444.\n",
      "[Epoch 78/1000] Train Loss: 1.2607  |  Val Loss: 1.4267\n",
      "Validation loss improved from 1.4444 to 1.4267.\n",
      "[Epoch 79/1000] Train Loss: 1.2402  |  Val Loss: 1.4094\n",
      "Validation loss improved from 1.4267 to 1.4094.\n",
      "[Epoch 80/1000] Train Loss: 1.2202  |  Val Loss: 1.3920\n",
      "Validation loss improved from 1.4094 to 1.3920.\n",
      "[Epoch 81/1000] Train Loss: 1.2003  |  Val Loss: 1.3748\n",
      "Validation loss improved from 1.3920 to 1.3748.\n",
      "[Epoch 82/1000] Train Loss: 1.1805  |  Val Loss: 1.3580\n",
      "Validation loss improved from 1.3748 to 1.3580.\n",
      "[Epoch 83/1000] Train Loss: 1.1610  |  Val Loss: 1.3414\n",
      "Validation loss improved from 1.3580 to 1.3414.\n",
      "[Epoch 84/1000] Train Loss: 1.1423  |  Val Loss: 1.3249\n",
      "Validation loss improved from 1.3414 to 1.3249.\n",
      "[Epoch 85/1000] Train Loss: 1.1228  |  Val Loss: 1.3090\n",
      "Validation loss improved from 1.3249 to 1.3090.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 86/1000] Train Loss: 1.1038  |  Val Loss: 1.2934\n",
      "Validation loss improved from 1.3090 to 1.2934.\n",
      "[Epoch 87/1000] Train Loss: 1.0856  |  Val Loss: 1.2775\n",
      "Validation loss improved from 1.2934 to 1.2775.\n",
      "[Epoch 88/1000] Train Loss: 1.0673  |  Val Loss: 1.2624\n",
      "Validation loss improved from 1.2775 to 1.2624.\n",
      "[Epoch 89/1000] Train Loss: 1.0490  |  Val Loss: 1.2479\n",
      "Validation loss improved from 1.2624 to 1.2479.\n",
      "[Epoch 90/1000] Train Loss: 1.0312  |  Val Loss: 1.2335\n",
      "Validation loss improved from 1.2479 to 1.2335.\n",
      "[Epoch 91/1000] Train Loss: 1.0139  |  Val Loss: 1.2192\n",
      "Validation loss improved from 1.2335 to 1.2192.\n",
      "[Epoch 92/1000] Train Loss: 0.9968  |  Val Loss: 1.2048\n",
      "Validation loss improved from 1.2192 to 1.2048.\n",
      "[Epoch 93/1000] Train Loss: 0.9797  |  Val Loss: 1.1907\n",
      "Validation loss improved from 1.2048 to 1.1907.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 94/1000] Train Loss: 0.9629  |  Val Loss: 1.1768\n",
      "Validation loss improved from 1.1907 to 1.1768.\n",
      "[Epoch 95/1000] Train Loss: 0.9464  |  Val Loss: 1.1635\n",
      "Validation loss improved from 1.1768 to 1.1635.\n",
      "[Epoch 96/1000] Train Loss: 0.9303  |  Val Loss: 1.1503\n",
      "Validation loss improved from 1.1635 to 1.1503.\n",
      "[Epoch 97/1000] Train Loss: 0.9144  |  Val Loss: 1.1377\n",
      "Validation loss improved from 1.1503 to 1.1377.\n",
      "[Epoch 98/1000] Train Loss: 0.8987  |  Val Loss: 1.1256\n",
      "Validation loss improved from 1.1377 to 1.1256.\n",
      "[Epoch 99/1000] Train Loss: 0.8834  |  Val Loss: 1.1132\n",
      "Validation loss improved from 1.1256 to 1.1132.\n",
      "[Epoch 100/1000] Train Loss: 0.8677  |  Val Loss: 1.1016\n",
      "Validation loss improved from 1.1132 to 1.1016.\n",
      "[Epoch 101/1000] Train Loss: 0.8529  |  Val Loss: 1.0898\n",
      "Validation loss improved from 1.1016 to 1.0898.\n",
      "[Epoch 102/1000] Train Loss: 0.8381  |  Val Loss: 1.0783\n",
      "Validation loss improved from 1.0898 to 1.0783.\n",
      "[Epoch 103/1000] Train Loss: 0.8238  |  Val Loss: 1.0666\n",
      "Validation loss improved from 1.0783 to 1.0666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 104/1000] Train Loss: 0.8094  |  Val Loss: 1.0553\n",
      "Validation loss improved from 1.0666 to 1.0553.\n",
      "[Epoch 105/1000] Train Loss: 0.7954  |  Val Loss: 1.0443\n",
      "Validation loss improved from 1.0553 to 1.0443.\n",
      "[Epoch 106/1000] Train Loss: 0.7815  |  Val Loss: 1.0336\n",
      "Validation loss improved from 1.0443 to 1.0336.\n",
      "[Epoch 107/1000] Train Loss: 0.7679  |  Val Loss: 1.0231\n",
      "Validation loss improved from 1.0336 to 1.0231.\n",
      "[Epoch 108/1000] Train Loss: 0.7547  |  Val Loss: 1.0132\n",
      "Validation loss improved from 1.0231 to 1.0132.\n",
      "[Epoch 109/1000] Train Loss: 0.7417  |  Val Loss: 1.0037\n",
      "Validation loss improved from 1.0132 to 1.0037.\n",
      "[Epoch 110/1000] Train Loss: 0.7290  |  Val Loss: 0.9946\n",
      "Validation loss improved from 1.0037 to 0.9946.\n",
      "[Epoch 111/1000] Train Loss: 0.7163  |  Val Loss: 0.9852\n",
      "Validation loss improved from 0.9946 to 0.9852.\n",
      "[Epoch 112/1000] Train Loss: 0.7037  |  Val Loss: 0.9770\n",
      "Validation loss improved from 0.9852 to 0.9770.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 113/1000] Train Loss: 0.6917  |  Val Loss: 0.9687\n",
      "Validation loss improved from 0.9770 to 0.9687.\n",
      "[Epoch 114/1000] Train Loss: 0.6800  |  Val Loss: 0.9593\n",
      "Validation loss improved from 0.9687 to 0.9593.\n",
      "[Epoch 115/1000] Train Loss: 0.6681  |  Val Loss: 0.9498\n",
      "Validation loss improved from 0.9593 to 0.9498.\n",
      "[Epoch 116/1000] Train Loss: 0.6564  |  Val Loss: 0.9408\n",
      "Validation loss improved from 0.9498 to 0.9408.\n",
      "[Epoch 117/1000] Train Loss: 0.6453  |  Val Loss: 0.9319\n",
      "Validation loss improved from 0.9408 to 0.9319.\n",
      "[Epoch 118/1000] Train Loss: 0.6343  |  Val Loss: 0.9225\n",
      "Validation loss improved from 0.9319 to 0.9225.\n",
      "[Epoch 119/1000] Train Loss: 0.6233  |  Val Loss: 0.9140\n",
      "Validation loss improved from 0.9225 to 0.9140.\n",
      "[Epoch 120/1000] Train Loss: 0.6126  |  Val Loss: 0.9063\n",
      "Validation loss improved from 0.9140 to 0.9063.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 121/1000] Train Loss: 0.6021  |  Val Loss: 0.8987\n",
      "Validation loss improved from 0.9063 to 0.8987.\n",
      "[Epoch 122/1000] Train Loss: 0.5917  |  Val Loss: 0.8912\n",
      "Validation loss improved from 0.8987 to 0.8912.\n",
      "[Epoch 123/1000] Train Loss: 0.5816  |  Val Loss: 0.8842\n",
      "Validation loss improved from 0.8912 to 0.8842.\n",
      "[Epoch 124/1000] Train Loss: 0.5717  |  Val Loss: 0.8776\n",
      "Validation loss improved from 0.8842 to 0.8776.\n",
      "[Epoch 125/1000] Train Loss: 0.5619  |  Val Loss: 0.8710\n",
      "Validation loss improved from 0.8776 to 0.8710.\n",
      "[Epoch 126/1000] Train Loss: 0.5524  |  Val Loss: 0.8638\n",
      "Validation loss improved from 0.8710 to 0.8638.\n",
      "[Epoch 127/1000] Train Loss: 0.5427  |  Val Loss: 0.8570\n",
      "Validation loss improved from 0.8638 to 0.8570.\n",
      "[Epoch 128/1000] Train Loss: 0.5336  |  Val Loss: 0.8507\n",
      "Validation loss improved from 0.8570 to 0.8507.\n",
      "[Epoch 129/1000] Train Loss: 0.5243  |  Val Loss: 0.8444\n",
      "Validation loss improved from 0.8507 to 0.8444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 130/1000] Train Loss: 0.5156  |  Val Loss: 0.8380\n",
      "Validation loss improved from 0.8444 to 0.8380.\n",
      "[Epoch 131/1000] Train Loss: 0.5067  |  Val Loss: 0.8323\n",
      "Validation loss improved from 0.8380 to 0.8323.\n",
      "[Epoch 132/1000] Train Loss: 0.4982  |  Val Loss: 0.8265\n",
      "Validation loss improved from 0.8323 to 0.8265.\n",
      "[Epoch 133/1000] Train Loss: 0.4899  |  Val Loss: 0.8206\n",
      "Validation loss improved from 0.8265 to 0.8206.\n",
      "[Epoch 134/1000] Train Loss: 0.4813  |  Val Loss: 0.8155\n",
      "Validation loss improved from 0.8206 to 0.8155.\n",
      "[Epoch 135/1000] Train Loss: 0.4735  |  Val Loss: 0.8102\n",
      "Validation loss improved from 0.8155 to 0.8102.\n",
      "[Epoch 136/1000] Train Loss: 0.4656  |  Val Loss: 0.8056\n",
      "Validation loss improved from 0.8102 to 0.8056.\n",
      "[Epoch 137/1000] Train Loss: 0.4579  |  Val Loss: 0.8003\n",
      "Validation loss improved from 0.8056 to 0.8003.\n",
      "[Epoch 138/1000] Train Loss: 0.4501  |  Val Loss: 0.7950\n",
      "Validation loss improved from 0.8003 to 0.7950.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 139/1000] Train Loss: 0.4423  |  Val Loss: 0.7900\n",
      "Validation loss improved from 0.7950 to 0.7900.\n",
      "[Epoch 140/1000] Train Loss: 0.4350  |  Val Loss: 0.7847\n",
      "Validation loss improved from 0.7900 to 0.7847.\n",
      "[Epoch 141/1000] Train Loss: 0.4274  |  Val Loss: 0.7795\n",
      "Validation loss improved from 0.7847 to 0.7795.\n",
      "[Epoch 142/1000] Train Loss: 0.4202  |  Val Loss: 0.7739\n",
      "Validation loss improved from 0.7795 to 0.7739.\n",
      "[Epoch 143/1000] Train Loss: 0.4131  |  Val Loss: 0.7685\n",
      "Validation loss improved from 0.7739 to 0.7685.\n",
      "[Epoch 144/1000] Train Loss: 0.4062  |  Val Loss: 0.7633\n",
      "Validation loss improved from 0.7685 to 0.7633.\n",
      "[Epoch 145/1000] Train Loss: 0.3991  |  Val Loss: 0.7600\n",
      "Validation loss improved from 0.7633 to 0.7600.\n",
      "[Epoch 146/1000] Train Loss: 0.3924  |  Val Loss: 0.7563\n",
      "Validation loss improved from 0.7600 to 0.7563.\n",
      "[Epoch 147/1000] Train Loss: 0.3857  |  Val Loss: 0.7523\n",
      "Validation loss improved from 0.7563 to 0.7523.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 148/1000] Train Loss: 0.3792  |  Val Loss: 0.7477\n",
      "Validation loss improved from 0.7523 to 0.7477.\n",
      "[Epoch 149/1000] Train Loss: 0.3726  |  Val Loss: 0.7427\n",
      "Validation loss improved from 0.7477 to 0.7427.\n",
      "[Epoch 150/1000] Train Loss: 0.3663  |  Val Loss: 0.7377\n",
      "Validation loss improved from 0.7427 to 0.7377.\n",
      "[Epoch 151/1000] Train Loss: 0.3602  |  Val Loss: 0.7324\n",
      "Validation loss improved from 0.7377 to 0.7324.\n",
      "[Epoch 152/1000] Train Loss: 0.3543  |  Val Loss: 0.7266\n",
      "Validation loss improved from 0.7324 to 0.7266.\n",
      "[Epoch 153/1000] Train Loss: 0.3482  |  Val Loss: 0.7222\n",
      "Validation loss improved from 0.7266 to 0.7222.\n",
      "[Epoch 154/1000] Train Loss: 0.3426  |  Val Loss: 0.7186\n",
      "Validation loss improved from 0.7222 to 0.7186.\n",
      "[Epoch 155/1000] Train Loss: 0.3368  |  Val Loss: 0.7149\n",
      "Validation loss improved from 0.7186 to 0.7149.\n",
      "[Epoch 156/1000] Train Loss: 0.3314  |  Val Loss: 0.7101\n",
      "Validation loss improved from 0.7149 to 0.7101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 157/1000] Train Loss: 0.3261  |  Val Loss: 0.7062\n",
      "Validation loss improved from 0.7101 to 0.7062.\n",
      "[Epoch 158/1000] Train Loss: 0.3204  |  Val Loss: 0.7028\n",
      "Validation loss improved from 0.7062 to 0.7028.\n",
      "[Epoch 159/1000] Train Loss: 0.3153  |  Val Loss: 0.6998\n",
      "Validation loss improved from 0.7028 to 0.6998.\n",
      "[Epoch 160/1000] Train Loss: 0.3098  |  Val Loss: 0.6979\n",
      "Validation loss improved from 0.6998 to 0.6979.\n",
      "[Epoch 161/1000] Train Loss: 0.3049  |  Val Loss: 0.6948\n",
      "Validation loss improved from 0.6979 to 0.6948.\n",
      "[Epoch 162/1000] Train Loss: 0.2998  |  Val Loss: 0.6915\n",
      "Validation loss improved from 0.6948 to 0.6915.\n",
      "[Epoch 163/1000] Train Loss: 0.2948  |  Val Loss: 0.6866\n",
      "Validation loss improved from 0.6915 to 0.6866.\n",
      "[Epoch 164/1000] Train Loss: 0.2899  |  Val Loss: 0.6829\n",
      "Validation loss improved from 0.6866 to 0.6829.\n",
      "[Epoch 165/1000] Train Loss: 0.2852  |  Val Loss: 0.6789\n",
      "Validation loss improved from 0.6829 to 0.6789.\n",
      "[Epoch 166/1000] Train Loss: 0.2806  |  Val Loss: 0.6755\n",
      "Validation loss improved from 0.6789 to 0.6755.\n",
      "[Epoch 167/1000] Train Loss: 0.2760  |  Val Loss: 0.6724\n",
      "Validation loss improved from 0.6755 to 0.6724.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 168/1000] Train Loss: 0.2715  |  Val Loss: 0.6688\n",
      "Validation loss improved from 0.6724 to 0.6688.\n",
      "[Epoch 169/1000] Train Loss: 0.2672  |  Val Loss: 0.6669\n",
      "Validation loss improved from 0.6688 to 0.6669.\n",
      "[Epoch 170/1000] Train Loss: 0.2629  |  Val Loss: 0.6639\n",
      "Validation loss improved from 0.6669 to 0.6639.\n",
      "[Epoch 171/1000] Train Loss: 0.2585  |  Val Loss: 0.6620\n",
      "Validation loss improved from 0.6639 to 0.6620.\n",
      "[Epoch 172/1000] Train Loss: 0.2543  |  Val Loss: 0.6599\n",
      "Validation loss improved from 0.6620 to 0.6599.\n",
      "[Epoch 173/1000] Train Loss: 0.2503  |  Val Loss: 0.6580\n",
      "Validation loss improved from 0.6599 to 0.6580.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 174/1000] Train Loss: 0.2465  |  Val Loss: 0.6549\n",
      "Validation loss improved from 0.6580 to 0.6549.\n",
      "[Epoch 175/1000] Train Loss: 0.2424  |  Val Loss: 0.6528\n",
      "Validation loss improved from 0.6549 to 0.6528.\n",
      "[Epoch 176/1000] Train Loss: 0.2386  |  Val Loss: 0.6511\n",
      "Validation loss improved from 0.6528 to 0.6511.\n",
      "[Epoch 177/1000] Train Loss: 0.2349  |  Val Loss: 0.6486\n",
      "Validation loss improved from 0.6511 to 0.6486.\n",
      "[Epoch 178/1000] Train Loss: 0.2309  |  Val Loss: 0.6467\n",
      "Validation loss improved from 0.6486 to 0.6467.\n",
      "[Epoch 179/1000] Train Loss: 0.2275  |  Val Loss: 0.6449\n",
      "Validation loss improved from 0.6467 to 0.6449.\n",
      "[Epoch 180/1000] Train Loss: 0.2236  |  Val Loss: 0.6432\n",
      "Validation loss improved from 0.6449 to 0.6432.\n",
      "[Epoch 181/1000] Train Loss: 0.2201  |  Val Loss: 0.6406\n",
      "Validation loss improved from 0.6432 to 0.6406.\n",
      "[Epoch 182/1000] Train Loss: 0.2167  |  Val Loss: 0.6378\n",
      "Validation loss improved from 0.6406 to 0.6378.\n",
      "[Epoch 183/1000] Train Loss: 0.2133  |  Val Loss: 0.6352\n",
      "Validation loss improved from 0.6378 to 0.6352.\n",
      "[Epoch 184/1000] Train Loss: 0.2099  |  Val Loss: 0.6330\n",
      "Validation loss improved from 0.6352 to 0.6330.\n",
      "[Epoch 185/1000] Train Loss: 0.2064  |  Val Loss: 0.6308\n",
      "Validation loss improved from 0.6330 to 0.6308.\n",
      "[Epoch 186/1000] Train Loss: 0.2030  |  Val Loss: 0.6287\n",
      "Validation loss improved from 0.6308 to 0.6287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 187/1000] Train Loss: 0.1999  |  Val Loss: 0.6264\n",
      "Validation loss improved from 0.6287 to 0.6264.\n",
      "[Epoch 188/1000] Train Loss: 0.1966  |  Val Loss: 0.6251\n",
      "Validation loss improved from 0.6264 to 0.6251.\n",
      "[Epoch 189/1000] Train Loss: 0.1935  |  Val Loss: 0.6247\n",
      "Validation loss improved from 0.6251 to 0.6247.\n",
      "[Epoch 190/1000] Train Loss: 0.1901  |  Val Loss: 0.6227\n",
      "Validation loss improved from 0.6247 to 0.6227.\n",
      "[Epoch 191/1000] Train Loss: 0.1869  |  Val Loss: 0.6208\n",
      "Validation loss improved from 0.6227 to 0.6208.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 192/1000] Train Loss: 0.1837  |  Val Loss: 0.6191\n",
      "Validation loss improved from 0.6208 to 0.6191.\n",
      "[Epoch 193/1000] Train Loss: 0.1805  |  Val Loss: 0.6182\n",
      "Validation loss improved from 0.6191 to 0.6182.\n",
      "[Epoch 194/1000] Train Loss: 0.1774  |  Val Loss: 0.6166\n",
      "Validation loss improved from 0.6182 to 0.6166.\n",
      "[Epoch 195/1000] Train Loss: 0.1744  |  Val Loss: 0.6154\n",
      "Validation loss improved from 0.6166 to 0.6154.\n",
      "[Epoch 196/1000] Train Loss: 0.1712  |  Val Loss: 0.6157\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 197/1000] Train Loss: 0.1681  |  Val Loss: 0.6153\n",
      "Validation loss improved from 0.6154 to 0.6153.\n",
      "[Epoch 198/1000] Train Loss: 0.1652  |  Val Loss: 0.6144\n",
      "Validation loss improved from 0.6153 to 0.6144.\n",
      "[Epoch 199/1000] Train Loss: 0.1622  |  Val Loss: 0.6129\n",
      "Validation loss improved from 0.6144 to 0.6129.\n",
      "[Epoch 200/1000] Train Loss: 0.1593  |  Val Loss: 0.6111\n",
      "Validation loss improved from 0.6129 to 0.6111.\n",
      "[Epoch 201/1000] Train Loss: 0.1564  |  Val Loss: 0.6092\n",
      "Validation loss improved from 0.6111 to 0.6092.\n",
      "[Epoch 202/1000] Train Loss: 0.1536  |  Val Loss: 0.6068\n",
      "Validation loss improved from 0.6092 to 0.6068.\n",
      "[Epoch 203/1000] Train Loss: 0.1510  |  Val Loss: 0.6045\n",
      "Validation loss improved from 0.6068 to 0.6045.\n",
      "[Epoch 204/1000] Train Loss: 0.1486  |  Val Loss: 0.6023\n",
      "Validation loss improved from 0.6045 to 0.6023.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 205/1000] Train Loss: 0.1460  |  Val Loss: 0.6016\n",
      "Validation loss improved from 0.6023 to 0.6016.\n",
      "[Epoch 206/1000] Train Loss: 0.1437  |  Val Loss: 0.6038\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 207/1000] Train Loss: 0.1409  |  Val Loss: 0.6032\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 208/1000] Train Loss: 0.1387  |  Val Loss: 0.6017\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 209/1000] Train Loss: 0.1366  |  Val Loss: 0.6001\n",
      "Validation loss improved from 0.6016 to 0.6001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 210/1000] Train Loss: 0.1343  |  Val Loss: 0.5980\n",
      "Validation loss improved from 0.6001 to 0.5980.\n",
      "[Epoch 211/1000] Train Loss: 0.1321  |  Val Loss: 0.5968\n",
      "Validation loss improved from 0.5980 to 0.5968.\n",
      "[Epoch 212/1000] Train Loss: 0.1300  |  Val Loss: 0.5953\n",
      "Validation loss improved from 0.5968 to 0.5953.\n",
      "[Epoch 213/1000] Train Loss: 0.1279  |  Val Loss: 0.5937\n",
      "Validation loss improved from 0.5953 to 0.5937.\n",
      "[Epoch 214/1000] Train Loss: 0.1260  |  Val Loss: 0.5918\n",
      "Validation loss improved from 0.5937 to 0.5918.\n",
      "[Epoch 215/1000] Train Loss: 0.1242  |  Val Loss: 0.5912\n",
      "Validation loss improved from 0.5918 to 0.5912.\n",
      "[Epoch 216/1000] Train Loss: 0.1223  |  Val Loss: 0.5910\n",
      "Validation loss improved from 0.5912 to 0.5910.\n",
      "[Epoch 217/1000] Train Loss: 0.1204  |  Val Loss: 0.5913\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 218/1000] Train Loss: 0.1186  |  Val Loss: 0.5913\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 219/1000] Train Loss: 0.1167  |  Val Loss: 0.5933\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 220/1000] Train Loss: 0.1151  |  Val Loss: 0.5932\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 221/1000] Train Loss: 0.1134  |  Val Loss: 0.5924\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 222/1000] Train Loss: 0.1120  |  Val Loss: 0.5917\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 223/1000] Train Loss: 0.1102  |  Val Loss: 0.5896\n",
      "Validation loss improved from 0.5910 to 0.5896.\n",
      "[Epoch 224/1000] Train Loss: 0.1086  |  Val Loss: 0.5877\n",
      "Validation loss improved from 0.5896 to 0.5877.\n",
      "[Epoch 225/1000] Train Loss: 0.1071  |  Val Loss: 0.5862\n",
      "Validation loss improved from 0.5877 to 0.5862.\n",
      "[Epoch 226/1000] Train Loss: 0.1055  |  Val Loss: 0.5846\n",
      "Validation loss improved from 0.5862 to 0.5846.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 227/1000] Train Loss: 0.1041  |  Val Loss: 0.5832\n",
      "Validation loss improved from 0.5846 to 0.5832.\n",
      "[Epoch 228/1000] Train Loss: 0.1026  |  Val Loss: 0.5830\n",
      "Validation loss improved from 0.5832 to 0.5830.\n",
      "[Epoch 229/1000] Train Loss: 0.1011  |  Val Loss: 0.5823\n",
      "Validation loss improved from 0.5830 to 0.5823.\n",
      "[Epoch 230/1000] Train Loss: 0.0998  |  Val Loss: 0.5823\n",
      "Validation loss improved from 0.5823 to 0.5823.\n",
      "[Epoch 231/1000] Train Loss: 0.0986  |  Val Loss: 0.5794\n",
      "Validation loss improved from 0.5823 to 0.5794.\n",
      "[Epoch 232/1000] Train Loss: 0.0973  |  Val Loss: 0.5790\n",
      "Validation loss improved from 0.5794 to 0.5790.\n",
      "[Epoch 233/1000] Train Loss: 0.0959  |  Val Loss: 0.5785\n",
      "Validation loss improved from 0.5790 to 0.5785.\n",
      "[Epoch 234/1000] Train Loss: 0.0945  |  Val Loss: 0.5784\n",
      "Validation loss improved from 0.5785 to 0.5784.\n",
      "[Epoch 235/1000] Train Loss: 0.0933  |  Val Loss: 0.5799\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 236/1000] Train Loss: 0.0921  |  Val Loss: 0.5810\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 237/1000] Train Loss: 0.0909  |  Val Loss: 0.5808\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 238/1000] Train Loss: 0.0898  |  Val Loss: 0.5827\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 239/1000] Train Loss: 0.0886  |  Val Loss: 0.5830\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 240/1000] Train Loss: 0.0875  |  Val Loss: 0.5818\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 241/1000] Train Loss: 0.0864  |  Val Loss: 0.5799\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 242/1000] Train Loss: 0.0852  |  Val Loss: 0.5783\n",
      "Validation loss improved from 0.5784 to 0.5783.\n",
      "[Epoch 243/1000] Train Loss: 0.0841  |  Val Loss: 0.5760\n",
      "Validation loss improved from 0.5783 to 0.5760.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 244/1000] Train Loss: 0.0831  |  Val Loss: 0.5755\n",
      "Validation loss improved from 0.5760 to 0.5755.\n",
      "[Epoch 245/1000] Train Loss: 0.0821  |  Val Loss: 0.5755\n",
      "Validation loss improved from 0.5755 to 0.5755.\n",
      "[Epoch 246/1000] Train Loss: 0.0810  |  Val Loss: 0.5763\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 247/1000] Train Loss: 0.0801  |  Val Loss: 0.5773\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 248/1000] Train Loss: 0.0791  |  Val Loss: 0.5754\n",
      "Validation loss improved from 0.5755 to 0.5754.\n",
      "[Epoch 249/1000] Train Loss: 0.0781  |  Val Loss: 0.5749\n",
      "Validation loss improved from 0.5754 to 0.5749.\n",
      "[Epoch 250/1000] Train Loss: 0.0775  |  Val Loss: 0.5747\n",
      "Validation loss improved from 0.5749 to 0.5747.\n",
      "[Epoch 251/1000] Train Loss: 0.0764  |  Val Loss: 0.5760\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 252/1000] Train Loss: 0.0755  |  Val Loss: 0.5769\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 253/1000] Train Loss: 0.0745  |  Val Loss: 0.5792\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 254/1000] Train Loss: 0.0735  |  Val Loss: 0.5805\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 255/1000] Train Loss: 0.0727  |  Val Loss: 0.5802\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 256/1000] Train Loss: 0.0719  |  Val Loss: 0.5805\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 257/1000] Train Loss: 0.0710  |  Val Loss: 0.5811\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 258/1000] Train Loss: 0.0703  |  Val Loss: 0.5802\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 259/1000] Train Loss: 0.0694  |  Val Loss: 0.5801\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 260/1000] Train Loss: 0.0688  |  Val Loss: 0.5825\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 261/1000] Train Loss: 0.0679  |  Val Loss: 0.5801\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 262/1000] Train Loss: 0.0673  |  Val Loss: 0.5788\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 263/1000] Train Loss: 0.0665  |  Val Loss: 0.5828\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 264/1000] Train Loss: 0.0657  |  Val Loss: 0.5846\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 265/1000] Train Loss: 0.0650  |  Val Loss: 0.5842\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 266/1000] Train Loss: 0.0642  |  Val Loss: 0.5839\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 267/1000] Train Loss: 0.0635  |  Val Loss: 0.5838\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 268/1000] Train Loss: 0.0627  |  Val Loss: 0.5827\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 269/1000] Train Loss: 0.0621  |  Val Loss: 0.5807\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 270/1000] Train Loss: 0.0614  |  Val Loss: 0.5804\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 271/1000] Train Loss: 0.0607  |  Val Loss: 0.5808\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 272/1000] Train Loss: 0.0601  |  Val Loss: 0.5815\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 273/1000] Train Loss: 0.0594  |  Val Loss: 0.5815\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 274/1000] Train Loss: 0.0588  |  Val Loss: 0.5804\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 275/1000] Train Loss: 0.0582  |  Val Loss: 0.5799\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 276/1000] Train Loss: 0.0576  |  Val Loss: 0.5807\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 277/1000] Train Loss: 0.0570  |  Val Loss: 0.5807\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 278/1000] Train Loss: 0.0563  |  Val Loss: 0.5839\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 279/1000] Train Loss: 0.0558  |  Val Loss: 0.5849\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 280/1000] Train Loss: 0.0553  |  Val Loss: 0.5852\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 281/1000] Train Loss: 0.0547  |  Val Loss: 0.5847\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 282/1000] Train Loss: 0.0541  |  Val Loss: 0.5829\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 283/1000] Train Loss: 0.0540  |  Val Loss: 0.5795\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 284/1000] Train Loss: 0.0530  |  Val Loss: 0.5814\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 285/1000] Train Loss: 0.0526  |  Val Loss: 0.5838\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 286/1000] Train Loss: 0.0520  |  Val Loss: 0.5846\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 287/1000] Train Loss: 0.0515  |  Val Loss: 0.5853\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 288/1000] Train Loss: 0.0510  |  Val Loss: 0.5850\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 289/1000] Train Loss: 0.0504  |  Val Loss: 0.5846\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 290/1000] Train Loss: 0.0499  |  Val Loss: 0.5847\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 291/1000] Train Loss: 0.0494  |  Val Loss: 0.5842\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 292/1000] Train Loss: 0.0490  |  Val Loss: 0.5833\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 293/1000] Train Loss: 0.0486  |  Val Loss: 0.5843\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 294/1000] Train Loss: 0.0481  |  Val Loss: 0.5848\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 295/1000] Train Loss: 0.0476  |  Val Loss: 0.5819\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 296/1000] Train Loss: 0.0473  |  Val Loss: 0.5822\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 297/1000] Train Loss: 0.0468  |  Val Loss: 0.5831\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 298/1000] Train Loss: 0.0463  |  Val Loss: 0.5842\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 299/1000] Train Loss: 0.0458  |  Val Loss: 0.5852\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 300/1000] Train Loss: 0.0454  |  Val Loss: 0.5859\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 301/1000] Train Loss: 0.0450  |  Val Loss: 0.5873\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 302/1000] Train Loss: 0.0446  |  Val Loss: 0.5883\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 303/1000] Train Loss: 0.0443  |  Val Loss: 0.5894\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 304/1000] Train Loss: 0.0438  |  Val Loss: 0.5895\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 305/1000] Train Loss: 0.0434  |  Val Loss: 0.5890\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 306/1000] Train Loss: 0.0430  |  Val Loss: 0.5884\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 307/1000] Train Loss: 0.0426  |  Val Loss: 0.5879\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 308/1000] Train Loss: 0.0423  |  Val Loss: 0.5895\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 309/1000] Train Loss: 0.0419  |  Val Loss: 0.5901\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 310/1000] Train Loss: 0.0415  |  Val Loss: 0.5905\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 311/1000] Train Loss: 0.0411  |  Val Loss: 0.5905\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 312/1000] Train Loss: 0.0408  |  Val Loss: 0.5901\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 313/1000] Train Loss: 0.0404  |  Val Loss: 0.5897\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 314/1000] Train Loss: 0.0401  |  Val Loss: 0.5892\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 315/1000] Train Loss: 0.0398  |  Val Loss: 0.5899\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 316/1000] Train Loss: 0.0395  |  Val Loss: 0.5895\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 317/1000] Train Loss: 0.0392  |  Val Loss: 0.5913\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 318/1000] Train Loss: 0.0387  |  Val Loss: 0.5925\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 319/1000] Train Loss: 0.0384  |  Val Loss: 0.5927\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 320/1000] Train Loss: 0.0383  |  Val Loss: 0.5900\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 321/1000] Train Loss: 0.0377  |  Val Loss: 0.5926\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 322/1000] Train Loss: 0.0374  |  Val Loss: 0.5938\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 323/1000] Train Loss: 0.0372  |  Val Loss: 0.5965\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 324/1000] Train Loss: 0.0369  |  Val Loss: 0.5971\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 325/1000] Train Loss: 0.0367  |  Val Loss: 0.5935\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 326/1000] Train Loss: 0.0363  |  Val Loss: 0.5923\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 327/1000] Train Loss: 0.0361  |  Val Loss: 0.5933\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 328/1000] Train Loss: 0.0357  |  Val Loss: 0.5928\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 329/1000] Train Loss: 0.0356  |  Val Loss: 0.5934\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 330/1000] Train Loss: 0.0352  |  Val Loss: 0.5921\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 331/1000] Train Loss: 0.0351  |  Val Loss: 0.5912\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 332/1000] Train Loss: 0.0349  |  Val Loss: 0.5926\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 333/1000] Train Loss: 0.0345  |  Val Loss: 0.5952\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 334/1000] Train Loss: 0.0342  |  Val Loss: 0.5988\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 335/1000] Train Loss: 0.0337  |  Val Loss: 0.6007\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 336/1000] Train Loss: 0.0334  |  Val Loss: 0.6010\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 337/1000] Train Loss: 0.0332  |  Val Loss: 0.6009\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 338/1000] Train Loss: 0.0329  |  Val Loss: 0.6049\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 339/1000] Train Loss: 0.0328  |  Val Loss: 0.6082\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 340/1000] Train Loss: 0.0327  |  Val Loss: 0.6098\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 341/1000] Train Loss: 0.0326  |  Val Loss: 0.6104\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 342/1000] Train Loss: 0.0323  |  Val Loss: 0.6090\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 343/1000] Train Loss: 0.0319  |  Val Loss: 0.6062\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 344/1000] Train Loss: 0.0314  |  Val Loss: 0.6041\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 345/1000] Train Loss: 0.0313  |  Val Loss: 0.6020\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 346/1000] Train Loss: 0.0310  |  Val Loss: 0.6012\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 347/1000] Train Loss: 0.0309  |  Val Loss: 0.5982\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 348/1000] Train Loss: 0.0306  |  Val Loss: 0.5988\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 349/1000] Train Loss: 0.0304  |  Val Loss: 0.5991\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 350/1000] Train Loss: 0.0301  |  Val Loss: 0.6008\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 350 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_input_dim = tscl_mlp_train_reps.shape[1]\n",
    "tscl_mlp_num_classes = len(torch.unique(tscl_mlp_train_labels_torch))\n",
    "tscl_mlp_model = MLPClassifier(tscl_mlp_input_dim, tscl_mlp_num_classes).to(device)\n",
    "\n",
    "tscl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "tscl_mlp_optimizer = optim.Adam(tscl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "tscl_mlp_num_epochs = 1000\n",
    "tscl_mlp_patience = 100\n",
    "\n",
    "tscl_mlp_train_losses = []\n",
    "tscl_mlp_val_losses = []\n",
    "\n",
    "tscl_mlp_best_val_loss = float('inf')\n",
    "tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for tscl_mlp_epoch in range(tscl_mlp_num_epochs):\n",
    "    # Training\n",
    "    tscl_mlp_model.train()\n",
    "    tscl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for tscl_mlp_embeddings_batch, tscl_mlp_labels_batch in tscl_mlp_train_loader:\n",
    "        tscl_mlp_embeddings_batch = tscl_mlp_embeddings_batch.to(device)\n",
    "        tscl_mlp_labels_batch = tscl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        tscl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        tscl_mlp_outputs = tscl_mlp_model(tscl_mlp_embeddings_batch)\n",
    "        tscl_mlp_loss = tscl_mlp_criterion(tscl_mlp_outputs, tscl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        tscl_mlp_loss.backward()\n",
    "        tscl_mlp_optimizer.step()\n",
    "        \n",
    "        tscl_mlp_train_running_loss += tscl_mlp_loss.item() * tscl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    tscl_mlp_epoch_train_loss = tscl_mlp_train_running_loss / len(tscl_mlp_train_loader.dataset)\n",
    "    tscl_mlp_train_losses.append(tscl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    tscl_mlp_model.eval()\n",
    "    tscl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for tscl_mlp_val_embeddings_batch, tscl_mlp_val_labels_batch in tscl_mlp_val_loader:\n",
    "            tscl_mlp_val_embeddings_batch = tscl_mlp_val_embeddings_batch.to(device)\n",
    "            tscl_mlp_val_labels_batch = tscl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            tscl_mlp_val_outputs = tscl_mlp_model(tscl_mlp_val_embeddings_batch)\n",
    "            tscl_mlp_val_loss = tscl_mlp_criterion(tscl_mlp_val_outputs, tscl_mlp_val_labels_batch)\n",
    "\n",
    "            tscl_mlp_val_running_loss += tscl_mlp_val_loss.item() * tscl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    tscl_mlp_epoch_val_loss = tscl_mlp_val_running_loss / len(tscl_mlp_val_loader.dataset)\n",
    "    tscl_mlp_val_losses.append(tscl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {tscl_mlp_epoch+1}/{tscl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {tscl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {tscl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if tscl_mlp_epoch_val_loss < tscl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_mlp_best_val_loss:.4f} to {tscl_mlp_epoch_val_loss:.4f}.\")\n",
    "        tscl_mlp_best_val_loss = tscl_mlp_epoch_val_loss\n",
    "        tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        tscl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {tscl_mlp_epochs_without_improvement}/{tscl_mlp_patience}\")\n",
    "        \n",
    "        if tscl_mlp_epochs_without_improvement >= tscl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {tscl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {tscl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(tscl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(tscl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:40.224787Z",
     "iopub.status.busy": "2025-05-08T19:08:40.224787Z",
     "iopub.status.idle": "2025-05-08T19:08:40.377029Z",
     "shell.execute_reply": "2025-05-08T19:08:40.377029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TSCL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.4024 | Test Accuracy: 88.68%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_model.eval()\n",
    "\n",
    "tscl_mlp_test_running_loss = 0.0\n",
    "tscl_mlp_test_correct = 0\n",
    "tscl_mlp_all_predictions = []\n",
    "tscl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_mlp_test_embeddings_batch, tscl_mlp_test_labels_batch in tscl_mlp_test_loader:\n",
    "        tscl_mlp_test_embeddings_batch = tscl_mlp_test_embeddings_batch.to(device)\n",
    "        tscl_mlp_test_labels_batch = tscl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        tscl_mlp_test_outputs = tscl_mlp_model(tscl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        tscl_mlp_test_loss_batch = tscl_mlp_criterion(tscl_mlp_test_outputs, tscl_mlp_test_labels_batch)\n",
    "        tscl_mlp_test_running_loss += tscl_mlp_test_loss_batch.item() * tscl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, tscl_mlp_test_predicted = torch.max(tscl_mlp_test_outputs, dim=1)\n",
    "        tscl_mlp_test_correct += (tscl_mlp_test_predicted == tscl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        tscl_mlp_all_predictions.extend(tscl_mlp_test_predicted.cpu().numpy())\n",
    "        tscl_mlp_all_true_labels.extend(tscl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_predictions.npy'), np.array(tscl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_true_labels.npy'), np.array(tscl_mlp_all_true_labels))\n",
    "print(f\"Saved TSCL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "tscl_mlp_epoch_test_loss = tscl_mlp_test_running_loss / len(tscl_mlp_test_loader.dataset)\n",
    "tscl_mlp_test_accuracy = tscl_mlp_test_correct / len(tscl_mlp_test_loader.dataset)\n",
    "\n",
    "tscl_mlp_test_accuracy_pct = tscl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {tscl_mlp_epoch_test_loss:.4f} | Test Accuracy: {tscl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "tscl_mlp_num_epochs_run = len(tscl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         [tscl_mlp_epoch_test_loss]*tscl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Supervised Contrastive Learning with Silhouette Distance Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:40.379566Z",
     "iopub.status.busy": "2025-05-08T19:08:40.379566Z",
     "iopub.status.idle": "2025-05-08T19:08:40.388638Z",
     "shell.execute_reply": "2025-05-08T19:08:40.388638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 280 samples with 64 features each\n",
      "LOG: Labels shape: (280,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 2898 samples with 64 features each\n",
      "LOG: Labels shape: (2898,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (280, 64), \n",
      "Train labels shape: (280,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (70, 64), \n",
      "Val labels shape: (70,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (2898, 64), \n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "sclsdl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "sclsdl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "sclsdl_train_embeddings, sclsdl_train_labels = load_encoded_data(sclsdl_encoded_train_dir)\n",
    "sclsdl_val_embeddings, sclsdl_val_labels = load_encoded_data(sclsdl_encoded_val_dir)\n",
    "sclsdl_test_embeddings, sclsdl_test_labels = load_encoded_data(sclsdl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {sclsdl_train_embeddings.shape}, \\nTrain labels shape: {sclsdl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {sclsdl_val_embeddings.shape}, \\nVal labels shape: {sclsdl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {sclsdl_test_embeddings.shape}, \\nTest labels shape: {sclsdl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:40.391745Z",
     "iopub.status.busy": "2025-05-08T19:08:40.390646Z",
     "iopub.status.idle": "2025-05-08T19:08:40.402292Z",
     "shell.execute_reply": "2025-05-08T19:08:40.402292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 20, 8: 20, 9: 20, 10: 20, 11: 20, 12: 20, 13: 20}\n",
      "Training batch size: 280\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "sclsdl_train_embeddings = sclsdl_train_embeddings.reshape(sclsdl_train_embeddings.shape[0], -1)\n",
    "sclsdl_val_embeddings = sclsdl_val_embeddings.reshape(sclsdl_val_embeddings.shape[0], -1)\n",
    "sclsdl_test_embeddings = sclsdl_test_embeddings.reshape(sclsdl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "sclsdl_train_mean = np.mean(sclsdl_train_embeddings, axis=0)\n",
    "sclsdl_train_std = np.std(sclsdl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "#sclsdl_train_embeddings = (sclsdl_train_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_val_embeddings = (sclsdl_val_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_test_embeddings = (sclsdl_test_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "\n",
    "sclsdl_train_dataset = TensorDataset(torch.tensor(sclsdl_train_embeddings, dtype=torch.float32), torch.tensor(sclsdl_train_labels, dtype=torch.long))\n",
    "sclsdl_val_dataset = TensorDataset(torch.tensor(sclsdl_val_embeddings, dtype=torch.float32), torch.tensor(sclsdl_val_labels, dtype=torch.long))\n",
    "sclsdl_test_dataset = TensorDataset(torch.tensor(sclsdl_test_embeddings, dtype=torch.float32), torch.tensor(sclsdl_test_labels, dtype=torch.long))\n",
    "\n",
    "\n",
    "sclsdl_m = 20\n",
    "sclsdl_num_classes = len(np.unique(sclsdl_train_labels))\n",
    "\n",
    "# calc theoretical required batch size\n",
    "sclsdl_required_batch_size = sclsdl_m * sclsdl_num_classes\n",
    "\n",
    "if sclsdl_required_batch_size > len(sclsdl_train_dataset):\n",
    "    sclsdl_max_possible_m = len(sclsdl_train_dataset) // sclsdl_num_classes\n",
    "    sclsdl_m = max(1, sclsdl_max_possible_m)\n",
    "    sclsdl_batch_size_train = sclsdl_m * sclsdl_num_classes\n",
    "else:\n",
    "    sclsdl_batch_size_train = sclsdl_required_batch_size\n",
    "\n",
    "sclsdl_sampler = MPerClassSampler(labels = sclsdl_train_labels, m = sclsdl_m, batch_size = sclsdl_batch_size_train, length_before_new_iter=len(sclsdl_train_dataset))\n",
    "sclsdl_train_loader = DataLoader(sclsdl_train_dataset, batch_size=sclsdl_batch_size_train, sampler=sclsdl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "sclsdl_dataloader_bs = 64\n",
    "sclsdl_val_loader = DataLoader(sclsdl_val_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "sclsdl_test_loader = DataLoader(sclsdl_test_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for sclsdl_X_batch, sclsdl_y_batch in sclsdl_train_loader:\n",
    "    sclsdl_unique, sclsdl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(sclsdl_unique, sclsdl_counts)))\n",
    "    print(f\"Training batch size: {sclsdl_batch_size_train}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:40.405300Z",
     "iopub.status.busy": "2025-05-08T19:08:40.405300Z",
     "iopub.status.idle": "2025-05-08T19:08:40.409803Z",
     "shell.execute_reply": "2025-05-08T19:08:40.409300Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.projection_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:40.412319Z",
     "iopub.status.busy": "2025-05-08T19:08:40.412319Z",
     "iopub.status.idle": "2025-05-08T19:08:40.420335Z",
     "shell.execute_reply": "2025-05-08T19:08:40.419825Z"
    }
   },
   "outputs": [],
   "source": [
    "class SilhouetteDistanceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SilhouetteDistanceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        return self.score(features, labels, True,True)\n",
    "\n",
    "    def score(self,X, labels,feature_norm=True, loss=False):\n",
    "        unique_labels = torch.unique(labels)\n",
    "        if feature_norm:\n",
    "            X= F.normalize(X, p=2, dim=1)\n",
    "\n",
    "\n",
    "        A, B = self._compute_distances(X, labels, unique_labels)\n",
    "\n",
    "        # A= scale*A\n",
    "        # B = (1-scale)*B\n",
    "        sil_samples = (B - A) / torch.clamp(torch.maximum(A, B), min=0.0001)\n",
    "\n",
    "        # nan values are for clusters of size 1, and should be 0\n",
    "        mean_sil_score = torch.mean(torch.nan_to_num(sil_samples))\n",
    "        if loss:\n",
    "            return (1 - mean_sil_score) / 2\n",
    "        else:\n",
    "            return mean_sil_score.item()\n",
    "\n",
    "\n",
    "    def _compute_distances(self,X, labels, unique_labels):\n",
    "        intra_dist = torch.zeros_like(labels, dtype=torch.float32)\n",
    "        inter_dist = torch.full_like(labels, torch.inf, dtype=torch.float32)\n",
    "\n",
    "        for i, label_a in enumerate(unique_labels):\n",
    "            cluster_indices_a = (labels == label_a)\n",
    "            subX_a = X[cluster_indices_a]\n",
    "\n",
    "\n",
    "            intra_distances_a = torch.cdist(subX_a, subX_a)\n",
    "            div = (subX_a.size(0) - 1) if subX_a.shape[0]>1 else 1\n",
    "            intra_dist[cluster_indices_a] = intra_distances_a.sum(dim=1) / div\n",
    "\n",
    "            for label_b in unique_labels[i + 1:]:\n",
    "                cluster_indices_b = (labels == label_b)\n",
    "                subX_b = X[cluster_indices_b]\n",
    "                inter_distances_ab = torch.cdist(subX_a, subX_b)\n",
    "                inter_distances_ba = torch.cdist(subX_b, subX_a)\n",
    "\n",
    "                inter_dist[cluster_indices_a] = torch.minimum(inter_distances_ab.mean(dim=1), inter_dist[cluster_indices_a])\n",
    "                inter_dist[cluster_indices_b] = torch.minimum(inter_distances_ba.mean(dim=1), inter_dist[cluster_indices_b])\n",
    "\n",
    "        return intra_dist, inter_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:08:40.422340Z",
     "iopub.status.busy": "2025-05-08T19:08:40.422340Z",
     "iopub.status.idle": "2025-05-08T19:16:59.103953Z",
     "shell.execute_reply": "2025-05-08T19:16:59.103953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Epoch [1/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4872\n",
      "LOG: Epoch [1/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4724\n",
      "    Batch [2/2], Val Loss: 0.1759\n",
      "Epoch [1/2000], Avg Train Loss: 0.4872, Avg Val Loss: 0.3241\n",
      "\n",
      "Validation loss improved from inf to 0.3241. Saving model...\n",
      "LOG: Epoch [2/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4894\n",
      "LOG: Epoch [2/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4717\n",
      "    Batch [2/2], Val Loss: 0.1772\n",
      "Epoch [2/2000], Avg Train Loss: 0.4894, Avg Val Loss: 0.3245\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [3/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4858\n",
      "LOG: Epoch [3/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4711\n",
      "    Batch [2/2], Val Loss: 0.1784\n",
      "Epoch [3/2000], Avg Train Loss: 0.4858, Avg Val Loss: 0.3248\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [4/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4855\n",
      "LOG: Epoch [4/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4705\n",
      "    Batch [2/2], Val Loss: 0.1793\n",
      "Epoch [4/2000], Avg Train Loss: 0.4855, Avg Val Loss: 0.3249\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [5/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4838\n",
      "LOG: Epoch [5/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4705\n",
      "    Batch [2/2], Val Loss: 0.1791\n",
      "Epoch [5/2000], Avg Train Loss: 0.4838, Avg Val Loss: 0.3248\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [6/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4855\n",
      "LOG: Epoch [6/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4703\n",
      "    Batch [2/2], Val Loss: 0.1787\n",
      "Epoch [6/2000], Avg Train Loss: 0.4855, Avg Val Loss: 0.3245\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [7/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4828\n",
      "LOG: Epoch [7/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4699\n",
      "    Batch [2/2], Val Loss: 0.1787\n",
      "Epoch [7/2000], Avg Train Loss: 0.4828, Avg Val Loss: 0.3243\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [8/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4818\n",
      "LOG: Epoch [8/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4693\n",
      "    Batch [2/2], Val Loss: 0.1786\n",
      "Epoch [8/2000], Avg Train Loss: 0.4818, Avg Val Loss: 0.3240\n",
      "\n",
      "Validation loss improved from 0.3241 to 0.3240. Saving model...\n",
      "LOG: Epoch [9/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4825\n",
      "LOG: Epoch [9/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4687\n",
      "    Batch [2/2], Val Loss: 0.1782\n",
      "Epoch [9/2000], Avg Train Loss: 0.4825, Avg Val Loss: 0.3234\n",
      "\n",
      "Validation loss improved from 0.3240 to 0.3234. Saving model...\n",
      "LOG: Epoch [10/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4789\n",
      "LOG: Epoch [10/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4681\n",
      "    Batch [2/2], Val Loss: 0.1766\n",
      "Epoch [10/2000], Avg Train Loss: 0.4789, Avg Val Loss: 0.3223\n",
      "\n",
      "Validation loss improved from 0.3234 to 0.3223. Saving model...\n",
      "LOG: Epoch [11/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4796\n",
      "LOG: Epoch [11/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4675\n",
      "    Batch [2/2], Val Loss: 0.1745\n",
      "Epoch [11/2000], Avg Train Loss: 0.4796, Avg Val Loss: 0.3210\n",
      "\n",
      "Validation loss improved from 0.3223 to 0.3210. Saving model...\n",
      "LOG: Epoch [12/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4774\n",
      "LOG: Epoch [12/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4671\n",
      "    Batch [2/2], Val Loss: 0.1705\n",
      "Epoch [12/2000], Avg Train Loss: 0.4774, Avg Val Loss: 0.3188\n",
      "\n",
      "Validation loss improved from 0.3210 to 0.3188. Saving model...\n",
      "LOG: Epoch [13/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4781\n",
      "LOG: Epoch [13/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4669\n",
      "    Batch [2/2], Val Loss: 0.1684\n",
      "Epoch [13/2000], Avg Train Loss: 0.4781, Avg Val Loss: 0.3177\n",
      "\n",
      "Validation loss improved from 0.3188 to 0.3177. Saving model...\n",
      "LOG: Epoch [14/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4769\n",
      "LOG: Epoch [14/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4666\n",
      "    Batch [2/2], Val Loss: 0.1690\n",
      "Epoch [14/2000], Avg Train Loss: 0.4769, Avg Val Loss: 0.3178\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [15/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4762\n",
      "LOG: Epoch [15/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4663\n",
      "    Batch [2/2], Val Loss: 0.1671\n",
      "Epoch [15/2000], Avg Train Loss: 0.4762, Avg Val Loss: 0.3167\n",
      "\n",
      "Validation loss improved from 0.3177 to 0.3167. Saving model...\n",
      "LOG: Epoch [16/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4754\n",
      "LOG: Epoch [16/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4656\n",
      "    Batch [2/2], Val Loss: 0.1634\n",
      "Epoch [16/2000], Avg Train Loss: 0.4754, Avg Val Loss: 0.3145\n",
      "\n",
      "Validation loss improved from 0.3167 to 0.3145. Saving model...\n",
      "LOG: Epoch [17/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4770\n",
      "LOG: Epoch [17/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4650\n",
      "    Batch [2/2], Val Loss: 0.1608\n",
      "Epoch [17/2000], Avg Train Loss: 0.4770, Avg Val Loss: 0.3129\n",
      "\n",
      "Validation loss improved from 0.3145 to 0.3129. Saving model...\n",
      "LOG: Epoch [18/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4721\n",
      "LOG: Epoch [18/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4639\n",
      "    Batch [2/2], Val Loss: 0.1571\n",
      "Epoch [18/2000], Avg Train Loss: 0.4721, Avg Val Loss: 0.3105\n",
      "\n",
      "Validation loss improved from 0.3129 to 0.3105. Saving model...\n",
      "LOG: Epoch [19/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4724\n",
      "LOG: Epoch [19/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4631\n",
      "    Batch [2/2], Val Loss: 0.1516\n",
      "Epoch [19/2000], Avg Train Loss: 0.4724, Avg Val Loss: 0.3073\n",
      "\n",
      "Validation loss improved from 0.3105 to 0.3073. Saving model...\n",
      "LOG: Epoch [20/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4732\n",
      "LOG: Epoch [20/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4613\n",
      "    Batch [2/2], Val Loss: 0.1461\n",
      "Epoch [20/2000], Avg Train Loss: 0.4732, Avg Val Loss: 0.3037\n",
      "\n",
      "Validation loss improved from 0.3073 to 0.3037. Saving model...\n",
      "LOG: Epoch [21/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4668\n",
      "LOG: Epoch [21/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4581\n",
      "    Batch [2/2], Val Loss: 0.1405\n",
      "Epoch [21/2000], Avg Train Loss: 0.4668, Avg Val Loss: 0.2993\n",
      "\n",
      "Validation loss improved from 0.3037 to 0.2993. Saving model...\n",
      "LOG: Epoch [22/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4683\n",
      "LOG: Epoch [22/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4559\n",
      "    Batch [2/2], Val Loss: 0.1348\n",
      "Epoch [22/2000], Avg Train Loss: 0.4683, Avg Val Loss: 0.2954\n",
      "\n",
      "Validation loss improved from 0.2993 to 0.2954. Saving model...\n",
      "LOG: Epoch [23/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4702\n",
      "LOG: Epoch [23/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4537\n",
      "    Batch [2/2], Val Loss: 0.1296\n",
      "Epoch [23/2000], Avg Train Loss: 0.4702, Avg Val Loss: 0.2916\n",
      "\n",
      "Validation loss improved from 0.2954 to 0.2916. Saving model...\n",
      "LOG: Epoch [24/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4681\n",
      "LOG: Epoch [24/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4523\n",
      "    Batch [2/2], Val Loss: 0.1249\n",
      "Epoch [24/2000], Avg Train Loss: 0.4681, Avg Val Loss: 0.2886\n",
      "\n",
      "Validation loss improved from 0.2916 to 0.2886. Saving model...\n",
      "LOG: Epoch [25/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4650\n",
      "LOG: Epoch [25/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4510\n",
      "    Batch [2/2], Val Loss: 0.1213\n",
      "Epoch [25/2000], Avg Train Loss: 0.4650, Avg Val Loss: 0.2862\n",
      "\n",
      "Validation loss improved from 0.2886 to 0.2862. Saving model...\n",
      "LOG: Epoch [26/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4640\n",
      "LOG: Epoch [26/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4505\n",
      "    Batch [2/2], Val Loss: 0.1193\n",
      "Epoch [26/2000], Avg Train Loss: 0.4640, Avg Val Loss: 0.2849\n",
      "\n",
      "Validation loss improved from 0.2862 to 0.2849. Saving model...\n",
      "LOG: Epoch [27/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4643\n",
      "LOG: Epoch [27/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4500\n",
      "    Batch [2/2], Val Loss: 0.1178\n",
      "Epoch [27/2000], Avg Train Loss: 0.4643, Avg Val Loss: 0.2839\n",
      "\n",
      "Validation loss improved from 0.2849 to 0.2839. Saving model...\n",
      "LOG: Epoch [28/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4676\n",
      "LOG: Epoch [28/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4493\n",
      "    Batch [2/2], Val Loss: 0.1166\n",
      "Epoch [28/2000], Avg Train Loss: 0.4676, Avg Val Loss: 0.2830\n",
      "\n",
      "Validation loss improved from 0.2839 to 0.2830. Saving model...\n",
      "LOG: Epoch [29/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4636\n",
      "LOG: Epoch [29/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4489\n",
      "    Batch [2/2], Val Loss: 0.1159\n",
      "Epoch [29/2000], Avg Train Loss: 0.4636, Avg Val Loss: 0.2824\n",
      "\n",
      "Validation loss improved from 0.2830 to 0.2824. Saving model...\n",
      "LOG: Epoch [30/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4635\n",
      "LOG: Epoch [30/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4490\n",
      "    Batch [2/2], Val Loss: 0.1154\n",
      "Epoch [30/2000], Avg Train Loss: 0.4635, Avg Val Loss: 0.2822\n",
      "\n",
      "Validation loss improved from 0.2824 to 0.2822. Saving model...\n",
      "LOG: Epoch [31/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4629\n",
      "LOG: Epoch [31/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4495\n",
      "    Batch [2/2], Val Loss: 0.1150\n",
      "Epoch [31/2000], Avg Train Loss: 0.4629, Avg Val Loss: 0.2822\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [32/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4620\n",
      "LOG: Epoch [32/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4497\n",
      "    Batch [2/2], Val Loss: 0.1146\n",
      "Epoch [32/2000], Avg Train Loss: 0.4620, Avg Val Loss: 0.2822\n",
      "\n",
      "Validation loss improved from 0.2822 to 0.2822. Saving model...\n",
      "LOG: Epoch [33/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4595\n",
      "LOG: Epoch [33/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4498\n",
      "    Batch [2/2], Val Loss: 0.1144\n",
      "Epoch [33/2000], Avg Train Loss: 0.4595, Avg Val Loss: 0.2821\n",
      "\n",
      "Validation loss improved from 0.2822 to 0.2821. Saving model...\n",
      "LOG: Epoch [34/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4611\n",
      "LOG: Epoch [34/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4501\n",
      "    Batch [2/2], Val Loss: 0.1143\n",
      "Epoch [34/2000], Avg Train Loss: 0.4611, Avg Val Loss: 0.2822\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [35/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4602\n",
      "LOG: Epoch [35/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4502\n",
      "    Batch [2/2], Val Loss: 0.1145\n",
      "Epoch [35/2000], Avg Train Loss: 0.4602, Avg Val Loss: 0.2824\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [36/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4589\n",
      "LOG: Epoch [36/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4503\n",
      "    Batch [2/2], Val Loss: 0.1147\n",
      "Epoch [36/2000], Avg Train Loss: 0.4589, Avg Val Loss: 0.2825\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [37/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4579\n",
      "LOG: Epoch [37/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4502\n",
      "    Batch [2/2], Val Loss: 0.1148\n",
      "Epoch [37/2000], Avg Train Loss: 0.4579, Avg Val Loss: 0.2825\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [38/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4610\n",
      "LOG: Epoch [38/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4498\n",
      "    Batch [2/2], Val Loss: 0.1150\n",
      "Epoch [38/2000], Avg Train Loss: 0.4610, Avg Val Loss: 0.2824\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [39/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4550\n",
      "LOG: Epoch [39/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4494\n",
      "    Batch [2/2], Val Loss: 0.1151\n",
      "Epoch [39/2000], Avg Train Loss: 0.4550, Avg Val Loss: 0.2823\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [40/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4579\n",
      "LOG: Epoch [40/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4491\n",
      "    Batch [2/2], Val Loss: 0.1153\n",
      "Epoch [40/2000], Avg Train Loss: 0.4579, Avg Val Loss: 0.2822\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [41/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4572\n",
      "LOG: Epoch [41/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4487\n",
      "    Batch [2/2], Val Loss: 0.1153\n",
      "Epoch [41/2000], Avg Train Loss: 0.4572, Avg Val Loss: 0.2820\n",
      "\n",
      "Validation loss improved from 0.2821 to 0.2820. Saving model...\n",
      "LOG: Epoch [42/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4566\n",
      "LOG: Epoch [42/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4483\n",
      "    Batch [2/2], Val Loss: 0.1153\n",
      "Epoch [42/2000], Avg Train Loss: 0.4566, Avg Val Loss: 0.2818\n",
      "\n",
      "Validation loss improved from 0.2820 to 0.2818. Saving model...\n",
      "LOG: Epoch [43/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4524\n",
      "LOG: Epoch [43/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4478\n",
      "    Batch [2/2], Val Loss: 0.1154\n",
      "Epoch [43/2000], Avg Train Loss: 0.4524, Avg Val Loss: 0.2816\n",
      "\n",
      "Validation loss improved from 0.2818 to 0.2816. Saving model...\n",
      "LOG: Epoch [44/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4564\n",
      "LOG: Epoch [44/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4473\n",
      "    Batch [2/2], Val Loss: 0.1156\n",
      "Epoch [44/2000], Avg Train Loss: 0.4564, Avg Val Loss: 0.2815\n",
      "\n",
      "Validation loss improved from 0.2816 to 0.2815. Saving model...\n",
      "LOG: Epoch [45/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4549\n",
      "LOG: Epoch [45/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4468\n",
      "    Batch [2/2], Val Loss: 0.1158\n",
      "Epoch [45/2000], Avg Train Loss: 0.4549, Avg Val Loss: 0.2813\n",
      "\n",
      "Validation loss improved from 0.2815 to 0.2813. Saving model...\n",
      "LOG: Epoch [46/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4554\n",
      "LOG: Epoch [46/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4462\n",
      "    Batch [2/2], Val Loss: 0.1159\n",
      "Epoch [46/2000], Avg Train Loss: 0.4554, Avg Val Loss: 0.2811\n",
      "\n",
      "Validation loss improved from 0.2813 to 0.2811. Saving model...\n",
      "LOG: Epoch [47/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4526\n",
      "LOG: Epoch [47/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4456\n",
      "    Batch [2/2], Val Loss: 0.1161\n",
      "Epoch [47/2000], Avg Train Loss: 0.4526, Avg Val Loss: 0.2809\n",
      "\n",
      "Validation loss improved from 0.2811 to 0.2809. Saving model...\n",
      "LOG: Epoch [48/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4510\n",
      "LOG: Epoch [48/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4450\n",
      "    Batch [2/2], Val Loss: 0.1163\n",
      "Epoch [48/2000], Avg Train Loss: 0.4510, Avg Val Loss: 0.2806\n",
      "\n",
      "Validation loss improved from 0.2809 to 0.2806. Saving model...\n",
      "LOG: Epoch [49/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4517\n",
      "LOG: Epoch [49/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4443\n",
      "    Batch [2/2], Val Loss: 0.1165\n",
      "Epoch [49/2000], Avg Train Loss: 0.4517, Avg Val Loss: 0.2804\n",
      "\n",
      "Validation loss improved from 0.2806 to 0.2804. Saving model...\n",
      "LOG: Epoch [50/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4492\n",
      "LOG: Epoch [50/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4436\n",
      "    Batch [2/2], Val Loss: 0.1165\n",
      "Epoch [50/2000], Avg Train Loss: 0.4492, Avg Val Loss: 0.2801\n",
      "\n",
      "Validation loss improved from 0.2804 to 0.2801. Saving model...\n",
      "LOG: Epoch [51/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4522\n",
      "LOG: Epoch [51/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4430\n",
      "    Batch [2/2], Val Loss: 0.1165\n",
      "Epoch [51/2000], Avg Train Loss: 0.4522, Avg Val Loss: 0.2798\n",
      "\n",
      "Validation loss improved from 0.2801 to 0.2798. Saving model...\n",
      "LOG: Epoch [52/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4481\n",
      "LOG: Epoch [52/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4424\n",
      "    Batch [2/2], Val Loss: 0.1166\n",
      "Epoch [52/2000], Avg Train Loss: 0.4481, Avg Val Loss: 0.2795\n",
      "\n",
      "Validation loss improved from 0.2798 to 0.2795. Saving model...\n",
      "LOG: Epoch [53/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4468\n",
      "LOG: Epoch [53/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4419\n",
      "    Batch [2/2], Val Loss: 0.1166\n",
      "Epoch [53/2000], Avg Train Loss: 0.4468, Avg Val Loss: 0.2793\n",
      "\n",
      "Validation loss improved from 0.2795 to 0.2793. Saving model...\n",
      "LOG: Epoch [54/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4505\n",
      "LOG: Epoch [54/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4415\n",
      "    Batch [2/2], Val Loss: 0.1167\n",
      "Epoch [54/2000], Avg Train Loss: 0.4505, Avg Val Loss: 0.2791\n",
      "\n",
      "Validation loss improved from 0.2793 to 0.2791. Saving model...\n",
      "LOG: Epoch [55/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4495\n",
      "LOG: Epoch [55/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4412\n",
      "    Batch [2/2], Val Loss: 0.1168\n",
      "Epoch [55/2000], Avg Train Loss: 0.4495, Avg Val Loss: 0.2790\n",
      "\n",
      "Validation loss improved from 0.2791 to 0.2790. Saving model...\n",
      "LOG: Epoch [56/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4471\n",
      "LOG: Epoch [56/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4409\n",
      "    Batch [2/2], Val Loss: 0.1168\n",
      "Epoch [56/2000], Avg Train Loss: 0.4471, Avg Val Loss: 0.2788\n",
      "\n",
      "Validation loss improved from 0.2790 to 0.2788. Saving model...\n",
      "LOG: Epoch [57/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4468\n",
      "LOG: Epoch [57/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4406\n",
      "    Batch [2/2], Val Loss: 0.1168\n",
      "Epoch [57/2000], Avg Train Loss: 0.4468, Avg Val Loss: 0.2787\n",
      "\n",
      "Validation loss improved from 0.2788 to 0.2787. Saving model...\n",
      "LOG: Epoch [58/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4444\n",
      "LOG: Epoch [58/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4402\n",
      "    Batch [2/2], Val Loss: 0.1170\n",
      "Epoch [58/2000], Avg Train Loss: 0.4444, Avg Val Loss: 0.2786\n",
      "\n",
      "Validation loss improved from 0.2787 to 0.2786. Saving model...\n",
      "LOG: Epoch [59/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4441\n",
      "LOG: Epoch [59/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4399\n",
      "    Batch [2/2], Val Loss: 0.1171\n",
      "Epoch [59/2000], Avg Train Loss: 0.4441, Avg Val Loss: 0.2785\n",
      "\n",
      "Validation loss improved from 0.2786 to 0.2785. Saving model...\n",
      "LOG: Epoch [60/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4437\n",
      "LOG: Epoch [60/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4395\n",
      "    Batch [2/2], Val Loss: 0.1171\n",
      "Epoch [60/2000], Avg Train Loss: 0.4437, Avg Val Loss: 0.2783\n",
      "\n",
      "Validation loss improved from 0.2785 to 0.2783. Saving model...\n",
      "LOG: Epoch [61/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4430\n",
      "LOG: Epoch [61/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4391\n",
      "    Batch [2/2], Val Loss: 0.1171\n",
      "Epoch [61/2000], Avg Train Loss: 0.4430, Avg Val Loss: 0.2781\n",
      "\n",
      "Validation loss improved from 0.2783 to 0.2781. Saving model...\n",
      "LOG: Epoch [62/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4428\n",
      "LOG: Epoch [62/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4385\n",
      "    Batch [2/2], Val Loss: 0.1171\n",
      "Epoch [62/2000], Avg Train Loss: 0.4428, Avg Val Loss: 0.2778\n",
      "\n",
      "Validation loss improved from 0.2781 to 0.2778. Saving model...\n",
      "LOG: Epoch [63/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4414\n",
      "LOG: Epoch [63/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4375\n",
      "    Batch [2/2], Val Loss: 0.1172\n",
      "Epoch [63/2000], Avg Train Loss: 0.4414, Avg Val Loss: 0.2773\n",
      "\n",
      "Validation loss improved from 0.2778 to 0.2773. Saving model...\n",
      "LOG: Epoch [64/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4419\n",
      "LOG: Epoch [64/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4366\n",
      "    Batch [2/2], Val Loss: 0.1171\n",
      "Epoch [64/2000], Avg Train Loss: 0.4419, Avg Val Loss: 0.2769\n",
      "\n",
      "Validation loss improved from 0.2773 to 0.2769. Saving model...\n",
      "LOG: Epoch [65/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4397\n",
      "LOG: Epoch [65/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4356\n",
      "    Batch [2/2], Val Loss: 0.1171\n",
      "Epoch [65/2000], Avg Train Loss: 0.4397, Avg Val Loss: 0.2764\n",
      "\n",
      "Validation loss improved from 0.2769 to 0.2764. Saving model...\n",
      "LOG: Epoch [66/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4418\n",
      "LOG: Epoch [66/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4347\n",
      "    Batch [2/2], Val Loss: 0.1174\n",
      "Epoch [66/2000], Avg Train Loss: 0.4418, Avg Val Loss: 0.2760\n",
      "\n",
      "Validation loss improved from 0.2764 to 0.2760. Saving model...\n",
      "LOG: Epoch [67/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4373\n",
      "LOG: Epoch [67/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4341\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [67/2000], Avg Train Loss: 0.4373, Avg Val Loss: 0.2760\n",
      "\n",
      "Validation loss improved from 0.2760 to 0.2760. Saving model...\n",
      "LOG: Epoch [68/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4380\n",
      "LOG: Epoch [68/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4334\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [68/2000], Avg Train Loss: 0.4380, Avg Val Loss: 0.2760\n",
      "\n",
      "Validation loss improved from 0.2760 to 0.2760. Saving model...\n",
      "LOG: Epoch [69/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4395\n",
      "LOG: Epoch [69/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4330\n",
      "    Batch [2/2], Val Loss: 0.1192\n",
      "Epoch [69/2000], Avg Train Loss: 0.4395, Avg Val Loss: 0.2761\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [70/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4390\n",
      "LOG: Epoch [70/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4328\n",
      "    Batch [2/2], Val Loss: 0.1199\n",
      "Epoch [70/2000], Avg Train Loss: 0.4390, Avg Val Loss: 0.2763\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [71/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4387\n",
      "LOG: Epoch [71/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4326\n",
      "    Batch [2/2], Val Loss: 0.1205\n",
      "Epoch [71/2000], Avg Train Loss: 0.4387, Avg Val Loss: 0.2765\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [72/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4352\n",
      "LOG: Epoch [72/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4325\n",
      "    Batch [2/2], Val Loss: 0.1211\n",
      "Epoch [72/2000], Avg Train Loss: 0.4352, Avg Val Loss: 0.2768\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [73/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4368\n",
      "LOG: Epoch [73/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4325\n",
      "    Batch [2/2], Val Loss: 0.1218\n",
      "Epoch [73/2000], Avg Train Loss: 0.4368, Avg Val Loss: 0.2771\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [74/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4359\n",
      "LOG: Epoch [74/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4322\n",
      "    Batch [2/2], Val Loss: 0.1224\n",
      "Epoch [74/2000], Avg Train Loss: 0.4359, Avg Val Loss: 0.2773\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [75/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4349\n",
      "LOG: Epoch [75/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4321\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [75/2000], Avg Train Loss: 0.4349, Avg Val Loss: 0.2775\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [76/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4394\n",
      "LOG: Epoch [76/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4321\n",
      "    Batch [2/2], Val Loss: 0.1232\n",
      "Epoch [76/2000], Avg Train Loss: 0.4394, Avg Val Loss: 0.2777\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [77/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4341\n",
      "LOG: Epoch [77/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4321\n",
      "    Batch [2/2], Val Loss: 0.1234\n",
      "Epoch [77/2000], Avg Train Loss: 0.4341, Avg Val Loss: 0.2777\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [78/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4369\n",
      "LOG: Epoch [78/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4323\n",
      "    Batch [2/2], Val Loss: 0.1235\n",
      "Epoch [78/2000], Avg Train Loss: 0.4369, Avg Val Loss: 0.2779\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [79/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4320\n",
      "LOG: Epoch [79/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4326\n",
      "    Batch [2/2], Val Loss: 0.1237\n",
      "Epoch [79/2000], Avg Train Loss: 0.4320, Avg Val Loss: 0.2781\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [80/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4313\n",
      "LOG: Epoch [80/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4327\n",
      "    Batch [2/2], Val Loss: 0.1238\n",
      "Epoch [80/2000], Avg Train Loss: 0.4313, Avg Val Loss: 0.2782\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [81/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4344\n",
      "LOG: Epoch [81/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4326\n",
      "    Batch [2/2], Val Loss: 0.1237\n",
      "Epoch [81/2000], Avg Train Loss: 0.4344, Avg Val Loss: 0.2782\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [82/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4290\n",
      "LOG: Epoch [82/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4324\n",
      "    Batch [2/2], Val Loss: 0.1233\n",
      "Epoch [82/2000], Avg Train Loss: 0.4290, Avg Val Loss: 0.2779\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [83/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4317\n",
      "LOG: Epoch [83/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4322\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [83/2000], Avg Train Loss: 0.4317, Avg Val Loss: 0.2776\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [84/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4319\n",
      "LOG: Epoch [84/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4318\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [84/2000], Avg Train Loss: 0.4319, Avg Val Loss: 0.2772\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [85/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4318\n",
      "LOG: Epoch [85/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4312\n",
      "    Batch [2/2], Val Loss: 0.1218\n",
      "Epoch [85/2000], Avg Train Loss: 0.4318, Avg Val Loss: 0.2765\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [86/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4337\n",
      "LOG: Epoch [86/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4307\n",
      "    Batch [2/2], Val Loss: 0.1210\n",
      "Epoch [86/2000], Avg Train Loss: 0.4337, Avg Val Loss: 0.2758\n",
      "\n",
      "Validation loss improved from 0.2760 to 0.2758. Saving model...\n",
      "LOG: Epoch [87/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4293\n",
      "LOG: Epoch [87/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4299\n",
      "    Batch [2/2], Val Loss: 0.1202\n",
      "Epoch [87/2000], Avg Train Loss: 0.4293, Avg Val Loss: 0.2751\n",
      "\n",
      "Validation loss improved from 0.2758 to 0.2751. Saving model...\n",
      "LOG: Epoch [88/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4316\n",
      "LOG: Epoch [88/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4291\n",
      "    Batch [2/2], Val Loss: 0.1193\n",
      "Epoch [88/2000], Avg Train Loss: 0.4316, Avg Val Loss: 0.2742\n",
      "\n",
      "Validation loss improved from 0.2751 to 0.2742. Saving model...\n",
      "LOG: Epoch [89/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4294\n",
      "LOG: Epoch [89/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4284\n",
      "    Batch [2/2], Val Loss: 0.1187\n",
      "Epoch [89/2000], Avg Train Loss: 0.4294, Avg Val Loss: 0.2735\n",
      "\n",
      "Validation loss improved from 0.2742 to 0.2735. Saving model...\n",
      "LOG: Epoch [90/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4278\n",
      "LOG: Epoch [90/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4276\n",
      "    Batch [2/2], Val Loss: 0.1178\n",
      "Epoch [90/2000], Avg Train Loss: 0.4278, Avg Val Loss: 0.2727\n",
      "\n",
      "Validation loss improved from 0.2735 to 0.2727. Saving model...\n",
      "LOG: Epoch [91/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4289\n",
      "LOG: Epoch [91/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4269\n",
      "    Batch [2/2], Val Loss: 0.1168\n",
      "Epoch [91/2000], Avg Train Loss: 0.4289, Avg Val Loss: 0.2719\n",
      "\n",
      "Validation loss improved from 0.2727 to 0.2719. Saving model...\n",
      "LOG: Epoch [92/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4271\n",
      "LOG: Epoch [92/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4264\n",
      "    Batch [2/2], Val Loss: 0.1158\n",
      "Epoch [92/2000], Avg Train Loss: 0.4271, Avg Val Loss: 0.2711\n",
      "\n",
      "Validation loss improved from 0.2719 to 0.2711. Saving model...\n",
      "LOG: Epoch [93/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4238\n",
      "LOG: Epoch [93/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4258\n",
      "    Batch [2/2], Val Loss: 0.1151\n",
      "Epoch [93/2000], Avg Train Loss: 0.4238, Avg Val Loss: 0.2705\n",
      "\n",
      "Validation loss improved from 0.2711 to 0.2705. Saving model...\n",
      "LOG: Epoch [94/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4267\n",
      "LOG: Epoch [94/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4249\n",
      "    Batch [2/2], Val Loss: 0.1144\n",
      "Epoch [94/2000], Avg Train Loss: 0.4267, Avg Val Loss: 0.2697\n",
      "\n",
      "Validation loss improved from 0.2705 to 0.2697. Saving model...\n",
      "LOG: Epoch [95/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4274\n",
      "LOG: Epoch [95/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4243\n",
      "    Batch [2/2], Val Loss: 0.1136\n",
      "Epoch [95/2000], Avg Train Loss: 0.4274, Avg Val Loss: 0.2689\n",
      "\n",
      "Validation loss improved from 0.2697 to 0.2689. Saving model...\n",
      "LOG: Epoch [96/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4251\n",
      "LOG: Epoch [96/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4236\n",
      "    Batch [2/2], Val Loss: 0.1130\n",
      "Epoch [96/2000], Avg Train Loss: 0.4251, Avg Val Loss: 0.2683\n",
      "\n",
      "Validation loss improved from 0.2689 to 0.2683. Saving model...\n",
      "LOG: Epoch [97/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4244\n",
      "LOG: Epoch [97/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4230\n",
      "    Batch [2/2], Val Loss: 0.1124\n",
      "Epoch [97/2000], Avg Train Loss: 0.4244, Avg Val Loss: 0.2677\n",
      "\n",
      "Validation loss improved from 0.2683 to 0.2677. Saving model...\n",
      "LOG: Epoch [98/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4242\n",
      "LOG: Epoch [98/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4221\n",
      "    Batch [2/2], Val Loss: 0.1119\n",
      "Epoch [98/2000], Avg Train Loss: 0.4242, Avg Val Loss: 0.2670\n",
      "\n",
      "Validation loss improved from 0.2677 to 0.2670. Saving model...\n",
      "LOG: Epoch [99/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4221\n",
      "LOG: Epoch [99/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4208\n",
      "    Batch [2/2], Val Loss: 0.1112\n",
      "Epoch [99/2000], Avg Train Loss: 0.4221, Avg Val Loss: 0.2660\n",
      "\n",
      "Validation loss improved from 0.2670 to 0.2660. Saving model...\n",
      "LOG: Epoch [100/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4225\n",
      "LOG: Epoch [100/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4197\n",
      "    Batch [2/2], Val Loss: 0.1108\n",
      "Epoch [100/2000], Avg Train Loss: 0.4225, Avg Val Loss: 0.2653\n",
      "\n",
      "Validation loss improved from 0.2660 to 0.2653. Saving model...\n",
      "LOG: Epoch [101/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4236\n",
      "LOG: Epoch [101/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4187\n",
      "    Batch [2/2], Val Loss: 0.1102\n",
      "Epoch [101/2000], Avg Train Loss: 0.4236, Avg Val Loss: 0.2644\n",
      "\n",
      "Validation loss improved from 0.2653 to 0.2644. Saving model...\n",
      "LOG: Epoch [102/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4200\n",
      "LOG: Epoch [102/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4179\n",
      "    Batch [2/2], Val Loss: 0.1096\n",
      "Epoch [102/2000], Avg Train Loss: 0.4200, Avg Val Loss: 0.2637\n",
      "\n",
      "Validation loss improved from 0.2644 to 0.2637. Saving model...\n",
      "LOG: Epoch [103/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4191\n",
      "LOG: Epoch [103/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4171\n",
      "    Batch [2/2], Val Loss: 0.1089\n",
      "Epoch [103/2000], Avg Train Loss: 0.4191, Avg Val Loss: 0.2630\n",
      "\n",
      "Validation loss improved from 0.2637 to 0.2630. Saving model...\n",
      "LOG: Epoch [104/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4221\n",
      "LOG: Epoch [104/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4164\n",
      "    Batch [2/2], Val Loss: 0.1083\n",
      "Epoch [104/2000], Avg Train Loss: 0.4221, Avg Val Loss: 0.2624\n",
      "\n",
      "Validation loss improved from 0.2630 to 0.2624. Saving model...\n",
      "LOG: Epoch [105/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4210\n",
      "LOG: Epoch [105/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4160\n",
      "    Batch [2/2], Val Loss: 0.1081\n",
      "Epoch [105/2000], Avg Train Loss: 0.4210, Avg Val Loss: 0.2620\n",
      "\n",
      "Validation loss improved from 0.2624 to 0.2620. Saving model...\n",
      "LOG: Epoch [106/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4174\n",
      "LOG: Epoch [106/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4153\n",
      "    Batch [2/2], Val Loss: 0.1080\n",
      "Epoch [106/2000], Avg Train Loss: 0.4174, Avg Val Loss: 0.2617\n",
      "\n",
      "Validation loss improved from 0.2620 to 0.2617. Saving model...\n",
      "LOG: Epoch [107/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4215\n",
      "LOG: Epoch [107/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4151\n",
      "    Batch [2/2], Val Loss: 0.1081\n",
      "Epoch [107/2000], Avg Train Loss: 0.4215, Avg Val Loss: 0.2616\n",
      "\n",
      "Validation loss improved from 0.2617 to 0.2616. Saving model...\n",
      "LOG: Epoch [108/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4192\n",
      "LOG: Epoch [108/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4151\n",
      "    Batch [2/2], Val Loss: 0.1083\n",
      "Epoch [108/2000], Avg Train Loss: 0.4192, Avg Val Loss: 0.2617\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [109/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4202\n",
      "LOG: Epoch [109/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4152\n",
      "    Batch [2/2], Val Loss: 0.1085\n",
      "Epoch [109/2000], Avg Train Loss: 0.4202, Avg Val Loss: 0.2618\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [110/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4192\n",
      "LOG: Epoch [110/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4151\n",
      "    Batch [2/2], Val Loss: 0.1084\n",
      "Epoch [110/2000], Avg Train Loss: 0.4192, Avg Val Loss: 0.2618\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [111/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4168\n",
      "LOG: Epoch [111/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4146\n",
      "    Batch [2/2], Val Loss: 0.1082\n",
      "Epoch [111/2000], Avg Train Loss: 0.4168, Avg Val Loss: 0.2614\n",
      "\n",
      "Validation loss improved from 0.2616 to 0.2614. Saving model...\n",
      "LOG: Epoch [112/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4165\n",
      "LOG: Epoch [112/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4142\n",
      "    Batch [2/2], Val Loss: 0.1080\n",
      "Epoch [112/2000], Avg Train Loss: 0.4165, Avg Val Loss: 0.2611\n",
      "\n",
      "Validation loss improved from 0.2614 to 0.2611. Saving model...\n",
      "LOG: Epoch [113/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4173\n",
      "LOG: Epoch [113/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4137\n",
      "    Batch [2/2], Val Loss: 0.1079\n",
      "Epoch [113/2000], Avg Train Loss: 0.4173, Avg Val Loss: 0.2608\n",
      "\n",
      "Validation loss improved from 0.2611 to 0.2608. Saving model...\n",
      "LOG: Epoch [114/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4184\n",
      "LOG: Epoch [114/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4133\n",
      "    Batch [2/2], Val Loss: 0.1074\n",
      "Epoch [114/2000], Avg Train Loss: 0.4184, Avg Val Loss: 0.2604\n",
      "\n",
      "Validation loss improved from 0.2608 to 0.2604. Saving model...\n",
      "LOG: Epoch [115/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4213\n",
      "LOG: Epoch [115/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4132\n",
      "    Batch [2/2], Val Loss: 0.1069\n",
      "Epoch [115/2000], Avg Train Loss: 0.4213, Avg Val Loss: 0.2600\n",
      "\n",
      "Validation loss improved from 0.2604 to 0.2600. Saving model...\n",
      "LOG: Epoch [116/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4130\n",
      "LOG: Epoch [116/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4130\n",
      "    Batch [2/2], Val Loss: 0.1063\n",
      "Epoch [116/2000], Avg Train Loss: 0.4130, Avg Val Loss: 0.2597\n",
      "\n",
      "Validation loss improved from 0.2600 to 0.2597. Saving model...\n",
      "LOG: Epoch [117/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4116\n",
      "LOG: Epoch [117/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4128\n",
      "    Batch [2/2], Val Loss: 0.1057\n",
      "Epoch [117/2000], Avg Train Loss: 0.4116, Avg Val Loss: 0.2592\n",
      "\n",
      "Validation loss improved from 0.2597 to 0.2592. Saving model...\n",
      "LOG: Epoch [118/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4135\n",
      "LOG: Epoch [118/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4127\n",
      "    Batch [2/2], Val Loss: 0.1053\n",
      "Epoch [118/2000], Avg Train Loss: 0.4135, Avg Val Loss: 0.2590\n",
      "\n",
      "Validation loss improved from 0.2592 to 0.2590. Saving model...\n",
      "LOG: Epoch [119/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4129\n",
      "LOG: Epoch [119/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4122\n",
      "    Batch [2/2], Val Loss: 0.1048\n",
      "Epoch [119/2000], Avg Train Loss: 0.4129, Avg Val Loss: 0.2585\n",
      "\n",
      "Validation loss improved from 0.2590 to 0.2585. Saving model...\n",
      "LOG: Epoch [120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4097\n",
      "LOG: Epoch [120/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4117\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [120/2000], Avg Train Loss: 0.4097, Avg Val Loss: 0.2579\n",
      "\n",
      "Validation loss improved from 0.2585 to 0.2579. Saving model...\n",
      "LOG: Epoch [121/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4113\n",
      "LOG: Epoch [121/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4112\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [121/2000], Avg Train Loss: 0.4113, Avg Val Loss: 0.2573\n",
      "\n",
      "Validation loss improved from 0.2579 to 0.2573. Saving model...\n",
      "LOG: Epoch [122/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4144\n",
      "LOG: Epoch [122/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4109\n",
      "    Batch [2/2], Val Loss: 0.1027\n",
      "Epoch [122/2000], Avg Train Loss: 0.4144, Avg Val Loss: 0.2568\n",
      "\n",
      "Validation loss improved from 0.2573 to 0.2568. Saving model...\n",
      "LOG: Epoch [123/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4126\n",
      "LOG: Epoch [123/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4108\n",
      "    Batch [2/2], Val Loss: 0.1022\n",
      "Epoch [123/2000], Avg Train Loss: 0.4126, Avg Val Loss: 0.2565\n",
      "\n",
      "Validation loss improved from 0.2568 to 0.2565. Saving model...\n",
      "LOG: Epoch [124/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4109\n",
      "LOG: Epoch [124/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4107\n",
      "    Batch [2/2], Val Loss: 0.1016\n",
      "Epoch [124/2000], Avg Train Loss: 0.4109, Avg Val Loss: 0.2562\n",
      "\n",
      "Validation loss improved from 0.2565 to 0.2562. Saving model...\n",
      "LOG: Epoch [125/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4122\n",
      "LOG: Epoch [125/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4108\n",
      "    Batch [2/2], Val Loss: 0.1014\n",
      "Epoch [125/2000], Avg Train Loss: 0.4122, Avg Val Loss: 0.2561\n",
      "\n",
      "Validation loss improved from 0.2562 to 0.2561. Saving model...\n",
      "LOG: Epoch [126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4109\n",
      "LOG: Epoch [126/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4110\n",
      "    Batch [2/2], Val Loss: 0.1013\n",
      "Epoch [126/2000], Avg Train Loss: 0.4109, Avg Val Loss: 0.2561\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [127/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4060\n",
      "LOG: Epoch [127/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4108\n",
      "    Batch [2/2], Val Loss: 0.1009\n",
      "Epoch [127/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.2559\n",
      "\n",
      "Validation loss improved from 0.2561 to 0.2559. Saving model...\n",
      "LOG: Epoch [128/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4116\n",
      "LOG: Epoch [128/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4104\n",
      "    Batch [2/2], Val Loss: 0.1007\n",
      "Epoch [128/2000], Avg Train Loss: 0.4116, Avg Val Loss: 0.2556\n",
      "\n",
      "Validation loss improved from 0.2559 to 0.2556. Saving model...\n",
      "LOG: Epoch [129/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4093\n",
      "LOG: Epoch [129/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4102\n",
      "    Batch [2/2], Val Loss: 0.1005\n",
      "Epoch [129/2000], Avg Train Loss: 0.4093, Avg Val Loss: 0.2554\n",
      "\n",
      "Validation loss improved from 0.2556 to 0.2554. Saving model...\n",
      "LOG: Epoch [130/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4074\n",
      "LOG: Epoch [130/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4100\n",
      "    Batch [2/2], Val Loss: 0.1008\n",
      "Epoch [130/2000], Avg Train Loss: 0.4074, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [131/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [131/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4099\n",
      "    Batch [2/2], Val Loss: 0.1009\n",
      "Epoch [131/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [132/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4054\n",
      "LOG: Epoch [132/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4098\n",
      "    Batch [2/2], Val Loss: 0.1011\n",
      "Epoch [132/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [133/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [133/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4096\n",
      "    Batch [2/2], Val Loss: 0.1013\n",
      "Epoch [133/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [134/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [134/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4093\n",
      "    Batch [2/2], Val Loss: 0.1014\n",
      "Epoch [134/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [135/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [135/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4086\n",
      "    Batch [2/2], Val Loss: 0.1016\n",
      "Epoch [135/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2554 to 0.2551. Saving model...\n",
      "LOG: Epoch [136/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4075\n",
      "LOG: Epoch [136/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4080\n",
      "    Batch [2/2], Val Loss: 0.1017\n",
      "Epoch [136/2000], Avg Train Loss: 0.4075, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2548. Saving model...\n",
      "LOG: Epoch [137/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [137/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4074\n",
      "    Batch [2/2], Val Loss: 0.1020\n",
      "Epoch [137/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2547. Saving model...\n",
      "LOG: Epoch [138/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [138/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1023\n",
      "Epoch [138/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2543. Saving model...\n",
      "LOG: Epoch [139/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [139/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1024\n",
      "Epoch [139/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2539\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2539. Saving model...\n",
      "LOG: Epoch [140/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [140/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4045\n",
      "    Batch [2/2], Val Loss: 0.1026\n",
      "Epoch [140/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2535\n",
      "\n",
      "Validation loss improved from 0.2539 to 0.2535. Saving model...\n",
      "LOG: Epoch [141/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [141/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4037\n",
      "    Batch [2/2], Val Loss: 0.1027\n",
      "Epoch [141/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2532\n",
      "\n",
      "Validation loss improved from 0.2535 to 0.2532. Saving model...\n",
      "LOG: Epoch [142/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [142/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4033\n",
      "    Batch [2/2], Val Loss: 0.1027\n",
      "Epoch [142/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2530\n",
      "\n",
      "Validation loss improved from 0.2532 to 0.2530. Saving model...\n",
      "LOG: Epoch [143/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [143/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4029\n",
      "    Batch [2/2], Val Loss: 0.1028\n",
      "Epoch [143/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2529\n",
      "\n",
      "Validation loss improved from 0.2530 to 0.2529. Saving model...\n",
      "LOG: Epoch [144/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3990\n",
      "LOG: Epoch [144/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4026\n",
      "    Batch [2/2], Val Loss: 0.1029\n",
      "Epoch [144/2000], Avg Train Loss: 0.3990, Avg Val Loss: 0.2527\n",
      "\n",
      "Validation loss improved from 0.2529 to 0.2527. Saving model...\n",
      "LOG: Epoch [145/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3995\n",
      "LOG: Epoch [145/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4020\n",
      "    Batch [2/2], Val Loss: 0.1029\n",
      "Epoch [145/2000], Avg Train Loss: 0.3995, Avg Val Loss: 0.2525\n",
      "\n",
      "Validation loss improved from 0.2527 to 0.2525. Saving model...\n",
      "LOG: Epoch [146/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3953\n",
      "LOG: Epoch [146/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4016\n",
      "    Batch [2/2], Val Loss: 0.1027\n",
      "Epoch [146/2000], Avg Train Loss: 0.3953, Avg Val Loss: 0.2522\n",
      "\n",
      "Validation loss improved from 0.2525 to 0.2522. Saving model...\n",
      "LOG: Epoch [147/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [147/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4011\n",
      "    Batch [2/2], Val Loss: 0.1026\n",
      "Epoch [147/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2519\n",
      "\n",
      "Validation loss improved from 0.2522 to 0.2519. Saving model...\n",
      "LOG: Epoch [148/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3960\n",
      "LOG: Epoch [148/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4008\n",
      "    Batch [2/2], Val Loss: 0.1023\n",
      "Epoch [148/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2515\n",
      "\n",
      "Validation loss improved from 0.2519 to 0.2515. Saving model...\n",
      "LOG: Epoch [149/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3964\n",
      "LOG: Epoch [149/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4007\n",
      "    Batch [2/2], Val Loss: 0.1019\n",
      "Epoch [149/2000], Avg Train Loss: 0.3964, Avg Val Loss: 0.2513\n",
      "\n",
      "Validation loss improved from 0.2515 to 0.2513. Saving model...\n",
      "LOG: Epoch [150/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3982\n",
      "LOG: Epoch [150/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4007\n",
      "    Batch [2/2], Val Loss: 0.1014\n",
      "Epoch [150/2000], Avg Train Loss: 0.3982, Avg Val Loss: 0.2511\n",
      "\n",
      "Validation loss improved from 0.2513 to 0.2511. Saving model...\n",
      "LOG: Epoch [151/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3965\n",
      "LOG: Epoch [151/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4007\n",
      "    Batch [2/2], Val Loss: 0.1008\n",
      "Epoch [151/2000], Avg Train Loss: 0.3965, Avg Val Loss: 0.2507\n",
      "\n",
      "Validation loss improved from 0.2511 to 0.2507. Saving model...\n",
      "LOG: Epoch [152/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3968\n",
      "LOG: Epoch [152/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4011\n",
      "    Batch [2/2], Val Loss: 0.1000\n",
      "Epoch [152/2000], Avg Train Loss: 0.3968, Avg Val Loss: 0.2505\n",
      "\n",
      "Validation loss improved from 0.2507 to 0.2505. Saving model...\n",
      "LOG: Epoch [153/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3980\n",
      "LOG: Epoch [153/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4009\n",
      "    Batch [2/2], Val Loss: 0.0989\n",
      "Epoch [153/2000], Avg Train Loss: 0.3980, Avg Val Loss: 0.2499\n",
      "\n",
      "Validation loss improved from 0.2505 to 0.2499. Saving model...\n",
      "LOG: Epoch [154/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3961\n",
      "LOG: Epoch [154/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4005\n",
      "    Batch [2/2], Val Loss: 0.0979\n",
      "Epoch [154/2000], Avg Train Loss: 0.3961, Avg Val Loss: 0.2492\n",
      "\n",
      "Validation loss improved from 0.2499 to 0.2492. Saving model...\n",
      "LOG: Epoch [155/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3945\n",
      "LOG: Epoch [155/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3998\n",
      "    Batch [2/2], Val Loss: 0.0973\n",
      "Epoch [155/2000], Avg Train Loss: 0.3945, Avg Val Loss: 0.2486\n",
      "\n",
      "Validation loss improved from 0.2492 to 0.2486. Saving model...\n",
      "LOG: Epoch [156/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3953\n",
      "LOG: Epoch [156/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3990\n",
      "    Batch [2/2], Val Loss: 0.0968\n",
      "Epoch [156/2000], Avg Train Loss: 0.3953, Avg Val Loss: 0.2479\n",
      "\n",
      "Validation loss improved from 0.2486 to 0.2479. Saving model...\n",
      "LOG: Epoch [157/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3915\n",
      "LOG: Epoch [157/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3981\n",
      "    Batch [2/2], Val Loss: 0.0963\n",
      "Epoch [157/2000], Avg Train Loss: 0.3915, Avg Val Loss: 0.2472\n",
      "\n",
      "Validation loss improved from 0.2479 to 0.2472. Saving model...\n",
      "LOG: Epoch [158/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [158/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3974\n",
      "    Batch [2/2], Val Loss: 0.0959\n",
      "Epoch [158/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2467\n",
      "\n",
      "Validation loss improved from 0.2472 to 0.2467. Saving model...\n",
      "LOG: Epoch [159/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3929\n",
      "LOG: Epoch [159/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3968\n",
      "    Batch [2/2], Val Loss: 0.0953\n",
      "Epoch [159/2000], Avg Train Loss: 0.3929, Avg Val Loss: 0.2461\n",
      "\n",
      "Validation loss improved from 0.2467 to 0.2461. Saving model...\n",
      "LOG: Epoch [160/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3885\n",
      "LOG: Epoch [160/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3963\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [160/2000], Avg Train Loss: 0.3885, Avg Val Loss: 0.2457\n",
      "\n",
      "Validation loss improved from 0.2461 to 0.2457. Saving model...\n",
      "LOG: Epoch [161/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3980\n",
      "LOG: Epoch [161/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3962\n",
      "    Batch [2/2], Val Loss: 0.0947\n",
      "Epoch [161/2000], Avg Train Loss: 0.3980, Avg Val Loss: 0.2454\n",
      "\n",
      "Validation loss improved from 0.2457 to 0.2454. Saving model...\n",
      "LOG: Epoch [162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3879\n",
      "LOG: Epoch [162/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3962\n",
      "    Batch [2/2], Val Loss: 0.0943\n",
      "Epoch [162/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2452\n",
      "\n",
      "Validation loss improved from 0.2454 to 0.2452. Saving model...\n",
      "LOG: Epoch [163/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3868\n",
      "LOG: Epoch [163/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3962\n",
      "    Batch [2/2], Val Loss: 0.0939\n",
      "Epoch [163/2000], Avg Train Loss: 0.3868, Avg Val Loss: 0.2450\n",
      "\n",
      "Validation loss improved from 0.2452 to 0.2450. Saving model...\n",
      "LOG: Epoch [164/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3863\n",
      "LOG: Epoch [164/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3960\n",
      "    Batch [2/2], Val Loss: 0.0936\n",
      "Epoch [164/2000], Avg Train Loss: 0.3863, Avg Val Loss: 0.2448\n",
      "\n",
      "Validation loss improved from 0.2450 to 0.2448. Saving model...\n",
      "LOG: Epoch [165/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3922\n",
      "LOG: Epoch [165/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3957\n",
      "    Batch [2/2], Val Loss: 0.0938\n",
      "Epoch [165/2000], Avg Train Loss: 0.3922, Avg Val Loss: 0.2448\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [166/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3906\n",
      "LOG: Epoch [166/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3953\n",
      "    Batch [2/2], Val Loss: 0.0943\n",
      "Epoch [166/2000], Avg Train Loss: 0.3906, Avg Val Loss: 0.2448\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [167/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3940\n",
      "LOG: Epoch [167/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3949\n",
      "    Batch [2/2], Val Loss: 0.0950\n",
      "Epoch [167/2000], Avg Train Loss: 0.3940, Avg Val Loss: 0.2450\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [168/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3852\n",
      "LOG: Epoch [168/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3948\n",
      "    Batch [2/2], Val Loss: 0.0953\n",
      "Epoch [168/2000], Avg Train Loss: 0.3852, Avg Val Loss: 0.2450\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [169/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3879\n",
      "LOG: Epoch [169/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3946\n",
      "    Batch [2/2], Val Loss: 0.0953\n",
      "Epoch [169/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2450\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [170/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3866\n",
      "LOG: Epoch [170/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3945\n",
      "    Batch [2/2], Val Loss: 0.0952\n",
      "Epoch [170/2000], Avg Train Loss: 0.3866, Avg Val Loss: 0.2448\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [171/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3879\n",
      "LOG: Epoch [171/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3943\n",
      "    Batch [2/2], Val Loss: 0.0951\n",
      "Epoch [171/2000], Avg Train Loss: 0.3879, Avg Val Loss: 0.2447\n",
      "\n",
      "Validation loss improved from 0.2448 to 0.2447. Saving model...\n",
      "LOG: Epoch [172/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3837\n",
      "LOG: Epoch [172/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3939\n",
      "    Batch [2/2], Val Loss: 0.0946\n",
      "Epoch [172/2000], Avg Train Loss: 0.3837, Avg Val Loss: 0.2443\n",
      "\n",
      "Validation loss improved from 0.2447 to 0.2443. Saving model...\n",
      "LOG: Epoch [173/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3804\n",
      "LOG: Epoch [173/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3929\n",
      "    Batch [2/2], Val Loss: 0.0939\n",
      "Epoch [173/2000], Avg Train Loss: 0.3804, Avg Val Loss: 0.2434\n",
      "\n",
      "Validation loss improved from 0.2443 to 0.2434. Saving model...\n",
      "LOG: Epoch [174/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3815\n",
      "LOG: Epoch [174/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3918\n",
      "    Batch [2/2], Val Loss: 0.0933\n",
      "Epoch [174/2000], Avg Train Loss: 0.3815, Avg Val Loss: 0.2426\n",
      "\n",
      "Validation loss improved from 0.2434 to 0.2426. Saving model...\n",
      "LOG: Epoch [175/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3831\n",
      "LOG: Epoch [175/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3910\n",
      "    Batch [2/2], Val Loss: 0.0930\n",
      "Epoch [175/2000], Avg Train Loss: 0.3831, Avg Val Loss: 0.2420\n",
      "\n",
      "Validation loss improved from 0.2426 to 0.2420. Saving model...\n",
      "LOG: Epoch [176/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3816\n",
      "LOG: Epoch [176/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3901\n",
      "    Batch [2/2], Val Loss: 0.0928\n",
      "Epoch [176/2000], Avg Train Loss: 0.3816, Avg Val Loss: 0.2414\n",
      "\n",
      "Validation loss improved from 0.2420 to 0.2414. Saving model...\n",
      "LOG: Epoch [177/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3825\n",
      "LOG: Epoch [177/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3892\n",
      "    Batch [2/2], Val Loss: 0.0925\n",
      "Epoch [177/2000], Avg Train Loss: 0.3825, Avg Val Loss: 0.2409\n",
      "\n",
      "Validation loss improved from 0.2414 to 0.2409. Saving model...\n",
      "LOG: Epoch [178/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3864\n",
      "LOG: Epoch [178/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3883\n",
      "    Batch [2/2], Val Loss: 0.0921\n",
      "Epoch [178/2000], Avg Train Loss: 0.3864, Avg Val Loss: 0.2402\n",
      "\n",
      "Validation loss improved from 0.2409 to 0.2402. Saving model...\n",
      "LOG: Epoch [179/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3829\n",
      "LOG: Epoch [179/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3876\n",
      "    Batch [2/2], Val Loss: 0.0915\n",
      "Epoch [179/2000], Avg Train Loss: 0.3829, Avg Val Loss: 0.2395\n",
      "\n",
      "Validation loss improved from 0.2402 to 0.2395. Saving model...\n",
      "LOG: Epoch [180/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3851\n",
      "LOG: Epoch [180/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3872\n",
      "    Batch [2/2], Val Loss: 0.0910\n",
      "Epoch [180/2000], Avg Train Loss: 0.3851, Avg Val Loss: 0.2391\n",
      "\n",
      "Validation loss improved from 0.2395 to 0.2391. Saving model...\n",
      "LOG: Epoch [181/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3817\n",
      "LOG: Epoch [181/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3869\n",
      "    Batch [2/2], Val Loss: 0.0907\n",
      "Epoch [181/2000], Avg Train Loss: 0.3817, Avg Val Loss: 0.2388\n",
      "\n",
      "Validation loss improved from 0.2391 to 0.2388. Saving model...\n",
      "LOG: Epoch [182/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3822\n",
      "LOG: Epoch [182/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3869\n",
      "    Batch [2/2], Val Loss: 0.0901\n",
      "Epoch [182/2000], Avg Train Loss: 0.3822, Avg Val Loss: 0.2385\n",
      "\n",
      "Validation loss improved from 0.2388 to 0.2385. Saving model...\n",
      "LOG: Epoch [183/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3829\n",
      "LOG: Epoch [183/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3868\n",
      "    Batch [2/2], Val Loss: 0.0899\n",
      "Epoch [183/2000], Avg Train Loss: 0.3829, Avg Val Loss: 0.2384\n",
      "\n",
      "Validation loss improved from 0.2385 to 0.2384. Saving model...\n",
      "LOG: Epoch [184/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3768\n",
      "LOG: Epoch [184/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3866\n",
      "    Batch [2/2], Val Loss: 0.0898\n",
      "Epoch [184/2000], Avg Train Loss: 0.3768, Avg Val Loss: 0.2382\n",
      "\n",
      "Validation loss improved from 0.2384 to 0.2382. Saving model...\n",
      "LOG: Epoch [185/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3797\n",
      "LOG: Epoch [185/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3864\n",
      "    Batch [2/2], Val Loss: 0.0897\n",
      "Epoch [185/2000], Avg Train Loss: 0.3797, Avg Val Loss: 0.2381\n",
      "\n",
      "Validation loss improved from 0.2382 to 0.2381. Saving model...\n",
      "LOG: Epoch [186/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3826\n",
      "LOG: Epoch [186/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3866\n",
      "    Batch [2/2], Val Loss: 0.0897\n",
      "Epoch [186/2000], Avg Train Loss: 0.3826, Avg Val Loss: 0.2381\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [187/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3773\n",
      "LOG: Epoch [187/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3869\n",
      "    Batch [2/2], Val Loss: 0.0896\n",
      "Epoch [187/2000], Avg Train Loss: 0.3773, Avg Val Loss: 0.2383\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [188/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3771\n",
      "LOG: Epoch [188/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3872\n",
      "    Batch [2/2], Val Loss: 0.0898\n",
      "Epoch [188/2000], Avg Train Loss: 0.3771, Avg Val Loss: 0.2385\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [189/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3726\n",
      "LOG: Epoch [189/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3872\n",
      "    Batch [2/2], Val Loss: 0.0898\n",
      "Epoch [189/2000], Avg Train Loss: 0.3726, Avg Val Loss: 0.2385\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [190/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3786\n",
      "LOG: Epoch [190/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3873\n",
      "    Batch [2/2], Val Loss: 0.0902\n",
      "Epoch [190/2000], Avg Train Loss: 0.3786, Avg Val Loss: 0.2388\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [191/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3816\n",
      "LOG: Epoch [191/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3876\n",
      "    Batch [2/2], Val Loss: 0.0906\n",
      "Epoch [191/2000], Avg Train Loss: 0.3816, Avg Val Loss: 0.2391\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [192/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3795\n",
      "LOG: Epoch [192/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3872\n",
      "    Batch [2/2], Val Loss: 0.0909\n",
      "Epoch [192/2000], Avg Train Loss: 0.3795, Avg Val Loss: 0.2390\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3740\n",
      "LOG: Epoch [193/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3872\n",
      "    Batch [2/2], Val Loss: 0.0912\n",
      "Epoch [193/2000], Avg Train Loss: 0.3740, Avg Val Loss: 0.2392\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [194/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3774\n",
      "LOG: Epoch [194/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3875\n",
      "    Batch [2/2], Val Loss: 0.0915\n",
      "Epoch [194/2000], Avg Train Loss: 0.3774, Avg Val Loss: 0.2395\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [195/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3740\n",
      "LOG: Epoch [195/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3874\n",
      "    Batch [2/2], Val Loss: 0.0914\n",
      "Epoch [195/2000], Avg Train Loss: 0.3740, Avg Val Loss: 0.2394\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [196/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3728\n",
      "LOG: Epoch [196/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3874\n",
      "    Batch [2/2], Val Loss: 0.0914\n",
      "Epoch [196/2000], Avg Train Loss: 0.3728, Avg Val Loss: 0.2394\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [197/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3704\n",
      "LOG: Epoch [197/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3872\n",
      "    Batch [2/2], Val Loss: 0.0915\n",
      "Epoch [197/2000], Avg Train Loss: 0.3704, Avg Val Loss: 0.2393\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [198/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3754\n",
      "LOG: Epoch [198/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3873\n",
      "    Batch [2/2], Val Loss: 0.0916\n",
      "Epoch [198/2000], Avg Train Loss: 0.3754, Avg Val Loss: 0.2394\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [199/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3743\n",
      "LOG: Epoch [199/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3876\n",
      "    Batch [2/2], Val Loss: 0.0918\n",
      "Epoch [199/2000], Avg Train Loss: 0.3743, Avg Val Loss: 0.2397\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [200/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3723\n",
      "LOG: Epoch [200/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3877\n",
      "    Batch [2/2], Val Loss: 0.0918\n",
      "Epoch [200/2000], Avg Train Loss: 0.3723, Avg Val Loss: 0.2398\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [201/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3738\n",
      "LOG: Epoch [201/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3882\n",
      "    Batch [2/2], Val Loss: 0.0922\n",
      "Epoch [201/2000], Avg Train Loss: 0.3738, Avg Val Loss: 0.2402\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [202/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3740\n",
      "LOG: Epoch [202/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3885\n",
      "    Batch [2/2], Val Loss: 0.0924\n",
      "Epoch [202/2000], Avg Train Loss: 0.3740, Avg Val Loss: 0.2404\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [203/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3701\n",
      "LOG: Epoch [203/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3884\n",
      "    Batch [2/2], Val Loss: 0.0923\n",
      "Epoch [203/2000], Avg Train Loss: 0.3701, Avg Val Loss: 0.2404\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [204/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3708\n",
      "LOG: Epoch [204/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3885\n",
      "    Batch [2/2], Val Loss: 0.0920\n",
      "Epoch [204/2000], Avg Train Loss: 0.3708, Avg Val Loss: 0.2402\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [205/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3676\n",
      "LOG: Epoch [205/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3879\n",
      "    Batch [2/2], Val Loss: 0.0913\n",
      "Epoch [205/2000], Avg Train Loss: 0.3676, Avg Val Loss: 0.2396\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [206/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3673\n",
      "LOG: Epoch [206/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3876\n",
      "    Batch [2/2], Val Loss: 0.0907\n",
      "Epoch [206/2000], Avg Train Loss: 0.3673, Avg Val Loss: 0.2391\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [207/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3694\n",
      "LOG: Epoch [207/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3875\n",
      "    Batch [2/2], Val Loss: 0.0897\n",
      "Epoch [207/2000], Avg Train Loss: 0.3694, Avg Val Loss: 0.2386\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [208/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3710\n",
      "LOG: Epoch [208/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3874\n",
      "    Batch [2/2], Val Loss: 0.0889\n",
      "Epoch [208/2000], Avg Train Loss: 0.3710, Avg Val Loss: 0.2381\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [209/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3712\n",
      "LOG: Epoch [209/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3867\n",
      "    Batch [2/2], Val Loss: 0.0881\n",
      "Epoch [209/2000], Avg Train Loss: 0.3712, Avg Val Loss: 0.2374\n",
      "\n",
      "Validation loss improved from 0.2381 to 0.2374. Saving model...\n",
      "LOG: Epoch [210/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3628\n",
      "LOG: Epoch [210/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3854\n",
      "    Batch [2/2], Val Loss: 0.0870\n",
      "Epoch [210/2000], Avg Train Loss: 0.3628, Avg Val Loss: 0.2362\n",
      "\n",
      "Validation loss improved from 0.2374 to 0.2362. Saving model...\n",
      "LOG: Epoch [211/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3651\n",
      "LOG: Epoch [211/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3840\n",
      "    Batch [2/2], Val Loss: 0.0861\n",
      "Epoch [211/2000], Avg Train Loss: 0.3651, Avg Val Loss: 0.2351\n",
      "\n",
      "Validation loss improved from 0.2362 to 0.2351. Saving model...\n",
      "LOG: Epoch [212/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3672\n",
      "LOG: Epoch [212/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3828\n",
      "    Batch [2/2], Val Loss: 0.0853\n",
      "Epoch [212/2000], Avg Train Loss: 0.3672, Avg Val Loss: 0.2341\n",
      "\n",
      "Validation loss improved from 0.2351 to 0.2341. Saving model...\n",
      "LOG: Epoch [213/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3640\n",
      "LOG: Epoch [213/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3811\n",
      "    Batch [2/2], Val Loss: 0.0844\n",
      "Epoch [213/2000], Avg Train Loss: 0.3640, Avg Val Loss: 0.2328\n",
      "\n",
      "Validation loss improved from 0.2341 to 0.2328. Saving model...\n",
      "LOG: Epoch [214/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3649\n",
      "LOG: Epoch [214/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3797\n",
      "    Batch [2/2], Val Loss: 0.0839\n",
      "Epoch [214/2000], Avg Train Loss: 0.3649, Avg Val Loss: 0.2318\n",
      "\n",
      "Validation loss improved from 0.2328 to 0.2318. Saving model...\n",
      "LOG: Epoch [215/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3686\n",
      "LOG: Epoch [215/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3787\n",
      "    Batch [2/2], Val Loss: 0.0834\n",
      "Epoch [215/2000], Avg Train Loss: 0.3686, Avg Val Loss: 0.2311\n",
      "\n",
      "Validation loss improved from 0.2318 to 0.2311. Saving model...\n",
      "LOG: Epoch [216/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3638\n",
      "LOG: Epoch [216/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3788\n",
      "    Batch [2/2], Val Loss: 0.0832\n",
      "Epoch [216/2000], Avg Train Loss: 0.3638, Avg Val Loss: 0.2310\n",
      "\n",
      "Validation loss improved from 0.2311 to 0.2310. Saving model...\n",
      "LOG: Epoch [217/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3670\n",
      "LOG: Epoch [217/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3788\n",
      "    Batch [2/2], Val Loss: 0.0831\n",
      "Epoch [217/2000], Avg Train Loss: 0.3670, Avg Val Loss: 0.2310\n",
      "\n",
      "Validation loss improved from 0.2310 to 0.2310. Saving model...\n",
      "LOG: Epoch [218/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3665\n",
      "LOG: Epoch [218/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3787\n",
      "    Batch [2/2], Val Loss: 0.0832\n",
      "Epoch [218/2000], Avg Train Loss: 0.3665, Avg Val Loss: 0.2309\n",
      "\n",
      "Validation loss improved from 0.2310 to 0.2309. Saving model...\n",
      "LOG: Epoch [219/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3633\n",
      "LOG: Epoch [219/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3785\n",
      "    Batch [2/2], Val Loss: 0.0835\n",
      "Epoch [219/2000], Avg Train Loss: 0.3633, Avg Val Loss: 0.2310\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [220/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3667\n",
      "LOG: Epoch [220/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3785\n",
      "    Batch [2/2], Val Loss: 0.0839\n",
      "Epoch [220/2000], Avg Train Loss: 0.3667, Avg Val Loss: 0.2312\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [221/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3639\n",
      "LOG: Epoch [221/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3790\n",
      "    Batch [2/2], Val Loss: 0.0844\n",
      "Epoch [221/2000], Avg Train Loss: 0.3639, Avg Val Loss: 0.2317\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [222/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3625\n",
      "LOG: Epoch [222/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3795\n",
      "    Batch [2/2], Val Loss: 0.0848\n",
      "Epoch [222/2000], Avg Train Loss: 0.3625, Avg Val Loss: 0.2322\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [223/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3630\n",
      "LOG: Epoch [223/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3799\n",
      "    Batch [2/2], Val Loss: 0.0849\n",
      "Epoch [223/2000], Avg Train Loss: 0.3630, Avg Val Loss: 0.2324\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [224/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3632\n",
      "LOG: Epoch [224/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3808\n",
      "    Batch [2/2], Val Loss: 0.0851\n",
      "Epoch [224/2000], Avg Train Loss: 0.3632, Avg Val Loss: 0.2330\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [225/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3578\n",
      "LOG: Epoch [225/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3819\n",
      "    Batch [2/2], Val Loss: 0.0853\n",
      "Epoch [225/2000], Avg Train Loss: 0.3578, Avg Val Loss: 0.2336\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [226/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3649\n",
      "LOG: Epoch [226/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3832\n",
      "    Batch [2/2], Val Loss: 0.0855\n",
      "Epoch [226/2000], Avg Train Loss: 0.3649, Avg Val Loss: 0.2343\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [227/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3610\n",
      "LOG: Epoch [227/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3844\n",
      "    Batch [2/2], Val Loss: 0.0857\n",
      "Epoch [227/2000], Avg Train Loss: 0.3610, Avg Val Loss: 0.2350\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [228/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3560\n",
      "LOG: Epoch [228/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3856\n",
      "    Batch [2/2], Val Loss: 0.0860\n",
      "Epoch [228/2000], Avg Train Loss: 0.3560, Avg Val Loss: 0.2358\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [229/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3583\n",
      "LOG: Epoch [229/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3860\n",
      "    Batch [2/2], Val Loss: 0.0861\n",
      "Epoch [229/2000], Avg Train Loss: 0.3583, Avg Val Loss: 0.2360\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [230/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3562\n",
      "LOG: Epoch [230/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3858\n",
      "    Batch [2/2], Val Loss: 0.0857\n",
      "Epoch [230/2000], Avg Train Loss: 0.3562, Avg Val Loss: 0.2357\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [231/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3544\n",
      "LOG: Epoch [231/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3857\n",
      "    Batch [2/2], Val Loss: 0.0853\n",
      "Epoch [231/2000], Avg Train Loss: 0.3544, Avg Val Loss: 0.2355\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [232/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3526\n",
      "LOG: Epoch [232/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3850\n",
      "    Batch [2/2], Val Loss: 0.0849\n",
      "Epoch [232/2000], Avg Train Loss: 0.3526, Avg Val Loss: 0.2350\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [233/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3545\n",
      "LOG: Epoch [233/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3837\n",
      "    Batch [2/2], Val Loss: 0.0843\n",
      "Epoch [233/2000], Avg Train Loss: 0.3545, Avg Val Loss: 0.2340\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [234/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3593\n",
      "LOG: Epoch [234/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3823\n",
      "    Batch [2/2], Val Loss: 0.0839\n",
      "Epoch [234/2000], Avg Train Loss: 0.3593, Avg Val Loss: 0.2331\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3513\n",
      "LOG: Epoch [235/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3815\n",
      "    Batch [2/2], Val Loss: 0.0836\n",
      "Epoch [235/2000], Avg Train Loss: 0.3513, Avg Val Loss: 0.2325\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [236/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3524\n",
      "LOG: Epoch [236/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3809\n",
      "    Batch [2/2], Val Loss: 0.0834\n",
      "Epoch [236/2000], Avg Train Loss: 0.3524, Avg Val Loss: 0.2321\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [237/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3584\n",
      "LOG: Epoch [237/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3803\n",
      "    Batch [2/2], Val Loss: 0.0833\n",
      "Epoch [237/2000], Avg Train Loss: 0.3584, Avg Val Loss: 0.2318\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [238/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3527\n",
      "LOG: Epoch [238/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3797\n",
      "    Batch [2/2], Val Loss: 0.0830\n",
      "Epoch [238/2000], Avg Train Loss: 0.3527, Avg Val Loss: 0.2314\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [239/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3558\n",
      "LOG: Epoch [239/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3794\n",
      "    Batch [2/2], Val Loss: 0.0830\n",
      "Epoch [239/2000], Avg Train Loss: 0.3558, Avg Val Loss: 0.2312\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [240/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3524\n",
      "LOG: Epoch [240/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3798\n",
      "    Batch [2/2], Val Loss: 0.0832\n",
      "Epoch [240/2000], Avg Train Loss: 0.3524, Avg Val Loss: 0.2315\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [241/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3501\n",
      "LOG: Epoch [241/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3807\n",
      "    Batch [2/2], Val Loss: 0.0836\n",
      "Epoch [241/2000], Avg Train Loss: 0.3501, Avg Val Loss: 0.2321\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [242/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3515\n",
      "LOG: Epoch [242/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3812\n",
      "    Batch [2/2], Val Loss: 0.0838\n",
      "Epoch [242/2000], Avg Train Loss: 0.3515, Avg Val Loss: 0.2325\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [243/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3516\n",
      "LOG: Epoch [243/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3793\n",
      "    Batch [2/2], Val Loss: 0.0834\n",
      "Epoch [243/2000], Avg Train Loss: 0.3516, Avg Val Loss: 0.2314\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [244/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3531\n",
      "LOG: Epoch [244/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3775\n",
      "    Batch [2/2], Val Loss: 0.0831\n",
      "Epoch [244/2000], Avg Train Loss: 0.3531, Avg Val Loss: 0.2303\n",
      "\n",
      "Validation loss improved from 0.2309 to 0.2303. Saving model...\n",
      "LOG: Epoch [245/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3483\n",
      "LOG: Epoch [245/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3759\n",
      "    Batch [2/2], Val Loss: 0.0828\n",
      "Epoch [245/2000], Avg Train Loss: 0.3483, Avg Val Loss: 0.2293\n",
      "\n",
      "Validation loss improved from 0.2303 to 0.2293. Saving model...\n",
      "LOG: Epoch [246/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3507\n",
      "LOG: Epoch [246/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3744\n",
      "    Batch [2/2], Val Loss: 0.0825\n",
      "Epoch [246/2000], Avg Train Loss: 0.3507, Avg Val Loss: 0.2284\n",
      "\n",
      "Validation loss improved from 0.2293 to 0.2284. Saving model...\n",
      "LOG: Epoch [247/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3498\n",
      "LOG: Epoch [247/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3729\n",
      "    Batch [2/2], Val Loss: 0.0823\n",
      "Epoch [247/2000], Avg Train Loss: 0.3498, Avg Val Loss: 0.2276\n",
      "\n",
      "Validation loss improved from 0.2284 to 0.2276. Saving model...\n",
      "LOG: Epoch [248/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3546\n",
      "LOG: Epoch [248/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3716\n",
      "    Batch [2/2], Val Loss: 0.0822\n",
      "Epoch [248/2000], Avg Train Loss: 0.3546, Avg Val Loss: 0.2269\n",
      "\n",
      "Validation loss improved from 0.2276 to 0.2269. Saving model...\n",
      "LOG: Epoch [249/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3535\n",
      "LOG: Epoch [249/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3704\n",
      "    Batch [2/2], Val Loss: 0.0821\n",
      "Epoch [249/2000], Avg Train Loss: 0.3535, Avg Val Loss: 0.2263\n",
      "\n",
      "Validation loss improved from 0.2269 to 0.2263. Saving model...\n",
      "LOG: Epoch [250/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3500\n",
      "LOG: Epoch [250/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3694\n",
      "    Batch [2/2], Val Loss: 0.0820\n",
      "Epoch [250/2000], Avg Train Loss: 0.3500, Avg Val Loss: 0.2257\n",
      "\n",
      "Validation loss improved from 0.2263 to 0.2257. Saving model...\n",
      "LOG: Epoch [251/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3539\n",
      "LOG: Epoch [251/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3686\n",
      "    Batch [2/2], Val Loss: 0.0819\n",
      "Epoch [251/2000], Avg Train Loss: 0.3539, Avg Val Loss: 0.2252\n",
      "\n",
      "Validation loss improved from 0.2257 to 0.2252. Saving model...\n",
      "LOG: Epoch [252/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3535\n",
      "LOG: Epoch [252/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3679\n",
      "    Batch [2/2], Val Loss: 0.0818\n",
      "Epoch [252/2000], Avg Train Loss: 0.3535, Avg Val Loss: 0.2248\n",
      "\n",
      "Validation loss improved from 0.2252 to 0.2248. Saving model...\n",
      "LOG: Epoch [253/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3504\n",
      "LOG: Epoch [253/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3673\n",
      "    Batch [2/2], Val Loss: 0.0816\n",
      "Epoch [253/2000], Avg Train Loss: 0.3504, Avg Val Loss: 0.2245\n",
      "\n",
      "Validation loss improved from 0.2248 to 0.2245. Saving model...\n",
      "LOG: Epoch [254/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3493\n",
      "LOG: Epoch [254/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3668\n",
      "    Batch [2/2], Val Loss: 0.0815\n",
      "Epoch [254/2000], Avg Train Loss: 0.3493, Avg Val Loss: 0.2242\n",
      "\n",
      "Validation loss improved from 0.2245 to 0.2242. Saving model...\n",
      "LOG: Epoch [255/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3527\n",
      "LOG: Epoch [255/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3664\n",
      "    Batch [2/2], Val Loss: 0.0814\n",
      "Epoch [255/2000], Avg Train Loss: 0.3527, Avg Val Loss: 0.2239\n",
      "\n",
      "Validation loss improved from 0.2242 to 0.2239. Saving model...\n",
      "LOG: Epoch [256/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [256/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3659\n",
      "    Batch [2/2], Val Loss: 0.0813\n",
      "Epoch [256/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2236\n",
      "\n",
      "Validation loss improved from 0.2239 to 0.2236. Saving model...\n",
      "LOG: Epoch [257/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3505\n",
      "LOG: Epoch [257/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3655\n",
      "    Batch [2/2], Val Loss: 0.0812\n",
      "Epoch [257/2000], Avg Train Loss: 0.3505, Avg Val Loss: 0.2234\n",
      "\n",
      "Validation loss improved from 0.2236 to 0.2234. Saving model...\n",
      "LOG: Epoch [258/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3515\n",
      "LOG: Epoch [258/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3652\n",
      "    Batch [2/2], Val Loss: 0.0811\n",
      "Epoch [258/2000], Avg Train Loss: 0.3515, Avg Val Loss: 0.2231\n",
      "\n",
      "Validation loss improved from 0.2234 to 0.2231. Saving model...\n",
      "LOG: Epoch [259/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3556\n",
      "LOG: Epoch [259/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3648\n",
      "    Batch [2/2], Val Loss: 0.0810\n",
      "Epoch [259/2000], Avg Train Loss: 0.3556, Avg Val Loss: 0.2229\n",
      "\n",
      "Validation loss improved from 0.2231 to 0.2229. Saving model...\n",
      "LOG: Epoch [260/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [260/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3646\n",
      "    Batch [2/2], Val Loss: 0.0809\n",
      "Epoch [260/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.2227\n",
      "\n",
      "Validation loss improved from 0.2229 to 0.2227. Saving model...\n",
      "LOG: Epoch [261/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3518\n",
      "LOG: Epoch [261/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3644\n",
      "    Batch [2/2], Val Loss: 0.0808\n",
      "Epoch [261/2000], Avg Train Loss: 0.3518, Avg Val Loss: 0.2226\n",
      "\n",
      "Validation loss improved from 0.2227 to 0.2226. Saving model...\n",
      "LOG: Epoch [262/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3503\n",
      "LOG: Epoch [262/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3643\n",
      "    Batch [2/2], Val Loss: 0.0808\n",
      "Epoch [262/2000], Avg Train Loss: 0.3503, Avg Val Loss: 0.2225\n",
      "\n",
      "Validation loss improved from 0.2226 to 0.2225. Saving model...\n",
      "LOG: Epoch [263/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [263/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3642\n",
      "    Batch [2/2], Val Loss: 0.0807\n",
      "Epoch [263/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2225\n",
      "\n",
      "Validation loss improved from 0.2225 to 0.2225. Saving model...\n",
      "LOG: Epoch [264/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3539\n",
      "LOG: Epoch [264/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3642\n",
      "    Batch [2/2], Val Loss: 0.0807\n",
      "Epoch [264/2000], Avg Train Loss: 0.3539, Avg Val Loss: 0.2224\n",
      "\n",
      "Validation loss improved from 0.2225 to 0.2224. Saving model...\n",
      "LOG: Epoch [265/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3494\n",
      "LOG: Epoch [265/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3641\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [265/2000], Avg Train Loss: 0.3494, Avg Val Loss: 0.2224\n",
      "\n",
      "Validation loss improved from 0.2224 to 0.2224. Saving model...\n",
      "LOG: Epoch [266/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3545\n",
      "LOG: Epoch [266/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3641\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [266/2000], Avg Train Loss: 0.3545, Avg Val Loss: 0.2223\n",
      "\n",
      "Validation loss improved from 0.2224 to 0.2223. Saving model...\n",
      "LOG: Epoch [267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3591\n",
      "LOG: Epoch [267/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3641\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [267/2000], Avg Train Loss: 0.3591, Avg Val Loss: 0.2223\n",
      "\n",
      "Validation loss improved from 0.2223 to 0.2223. Saving model...\n",
      "LOG: Epoch [268/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3519\n",
      "LOG: Epoch [268/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3640\n",
      "    Batch [2/2], Val Loss: 0.0805\n",
      "Epoch [268/2000], Avg Train Loss: 0.3519, Avg Val Loss: 0.2223\n",
      "\n",
      "Validation loss improved from 0.2223 to 0.2223. Saving model...\n",
      "LOG: Epoch [269/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [269/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3640\n",
      "    Batch [2/2], Val Loss: 0.0805\n",
      "Epoch [269/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2222\n",
      "\n",
      "Validation loss improved from 0.2223 to 0.2222. Saving model...\n",
      "LOG: Epoch [270/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [270/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3640\n",
      "    Batch [2/2], Val Loss: 0.0805\n",
      "Epoch [270/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.2222\n",
      "\n",
      "Validation loss improved from 0.2222 to 0.2222. Saving model...\n",
      "LOG: Epoch [271/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [271/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3640\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [271/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2222\n",
      "\n",
      "Validation loss improved from 0.2222 to 0.2222. Saving model...\n",
      "LOG: Epoch [272/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3562\n",
      "LOG: Epoch [272/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3639\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [272/2000], Avg Train Loss: 0.3562, Avg Val Loss: 0.2222\n",
      "\n",
      "Validation loss improved from 0.2222 to 0.2222. Saving model...\n",
      "LOG: Epoch [273/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3510\n",
      "LOG: Epoch [273/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3639\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [273/2000], Avg Train Loss: 0.3510, Avg Val Loss: 0.2221\n",
      "\n",
      "Validation loss improved from 0.2222 to 0.2221. Saving model...\n",
      "LOG: Epoch [274/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [274/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3638\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [274/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2221\n",
      "\n",
      "Validation loss improved from 0.2221 to 0.2221. Saving model...\n",
      "LOG: Epoch [275/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3533\n",
      "LOG: Epoch [275/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3638\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [275/2000], Avg Train Loss: 0.3533, Avg Val Loss: 0.2221\n",
      "\n",
      "Validation loss improved from 0.2221 to 0.2221. Saving model...\n",
      "LOG: Epoch [276/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [276/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3637\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [276/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2220\n",
      "\n",
      "Validation loss improved from 0.2221 to 0.2220. Saving model...\n",
      "LOG: Epoch [277/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3510\n",
      "LOG: Epoch [277/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3637\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [277/2000], Avg Train Loss: 0.3510, Avg Val Loss: 0.2220\n",
      "\n",
      "Validation loss improved from 0.2220 to 0.2220. Saving model...\n",
      "LOG: Epoch [278/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3530\n",
      "LOG: Epoch [278/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3636\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [278/2000], Avg Train Loss: 0.3530, Avg Val Loss: 0.2220\n",
      "\n",
      "Validation loss improved from 0.2220 to 0.2220. Saving model...\n",
      "LOG: Epoch [279/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3524\n",
      "LOG: Epoch [279/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3636\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [279/2000], Avg Train Loss: 0.3524, Avg Val Loss: 0.2219\n",
      "\n",
      "Validation loss improved from 0.2220 to 0.2219. Saving model...\n",
      "LOG: Epoch [280/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3506\n",
      "LOG: Epoch [280/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3636\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [280/2000], Avg Train Loss: 0.3506, Avg Val Loss: 0.2219\n",
      "\n",
      "Validation loss improved from 0.2219 to 0.2219. Saving model...\n",
      "LOG: Epoch [281/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3507\n",
      "LOG: Epoch [281/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3635\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [281/2000], Avg Train Loss: 0.3507, Avg Val Loss: 0.2219\n",
      "\n",
      "Validation loss improved from 0.2219 to 0.2219. Saving model...\n",
      "LOG: Epoch [282/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [282/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3635\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [282/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2219\n",
      "\n",
      "Validation loss improved from 0.2219 to 0.2219. Saving model...\n",
      "LOG: Epoch [283/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [283/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3634\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [283/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2218\n",
      "\n",
      "Validation loss improved from 0.2219 to 0.2218. Saving model...\n",
      "LOG: Epoch [284/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3520\n",
      "LOG: Epoch [284/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3633\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [284/2000], Avg Train Loss: 0.3520, Avg Val Loss: 0.2218\n",
      "\n",
      "Validation loss improved from 0.2218 to 0.2218. Saving model...\n",
      "LOG: Epoch [285/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3507\n",
      "LOG: Epoch [285/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3633\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [285/2000], Avg Train Loss: 0.3507, Avg Val Loss: 0.2218\n",
      "\n",
      "Validation loss improved from 0.2218 to 0.2218. Saving model...\n",
      "LOG: Epoch [286/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3509\n",
      "LOG: Epoch [286/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3633\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [286/2000], Avg Train Loss: 0.3509, Avg Val Loss: 0.2218\n",
      "\n",
      "Validation loss improved from 0.2218 to 0.2218. Saving model...\n",
      "LOG: Epoch [287/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3510\n",
      "LOG: Epoch [287/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3632\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [287/2000], Avg Train Loss: 0.3510, Avg Val Loss: 0.2217\n",
      "\n",
      "Validation loss improved from 0.2218 to 0.2217. Saving model...\n",
      "LOG: Epoch [288/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3492\n",
      "LOG: Epoch [288/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3631\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [288/2000], Avg Train Loss: 0.3492, Avg Val Loss: 0.2217\n",
      "\n",
      "Validation loss improved from 0.2217 to 0.2217. Saving model...\n",
      "LOG: Epoch [289/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3502\n",
      "LOG: Epoch [289/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [289/2000], Avg Train Loss: 0.3502, Avg Val Loss: 0.2217\n",
      "\n",
      "Validation loss improved from 0.2217 to 0.2217. Saving model...\n",
      "LOG: Epoch [290/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [290/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3629\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [290/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2216\n",
      "\n",
      "Validation loss improved from 0.2217 to 0.2216. Saving model...\n",
      "LOG: Epoch [291/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3510\n",
      "LOG: Epoch [291/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3629\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [291/2000], Avg Train Loss: 0.3510, Avg Val Loss: 0.2216\n",
      "\n",
      "Validation loss improved from 0.2216 to 0.2216. Saving model...\n",
      "LOG: Epoch [292/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3494\n",
      "LOG: Epoch [292/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3628\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [292/2000], Avg Train Loss: 0.3494, Avg Val Loss: 0.2216\n",
      "\n",
      "Validation loss improved from 0.2216 to 0.2216. Saving model...\n",
      "LOG: Epoch [293/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3518\n",
      "LOG: Epoch [293/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3628\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [293/2000], Avg Train Loss: 0.3518, Avg Val Loss: 0.2216\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [294/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3509\n",
      "LOG: Epoch [294/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3628\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [294/2000], Avg Train Loss: 0.3509, Avg Val Loss: 0.2216\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [295/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3509\n",
      "LOG: Epoch [295/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3629\n",
      "    Batch [2/2], Val Loss: 0.0805\n",
      "Epoch [295/2000], Avg Train Loss: 0.3509, Avg Val Loss: 0.2217\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [296/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3514\n",
      "LOG: Epoch [296/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3628\n",
      "    Batch [2/2], Val Loss: 0.0805\n",
      "Epoch [296/2000], Avg Train Loss: 0.3514, Avg Val Loss: 0.2217\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [297/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3531\n",
      "LOG: Epoch [297/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3628\n",
      "    Batch [2/2], Val Loss: 0.0805\n",
      "Epoch [297/2000], Avg Train Loss: 0.3531, Avg Val Loss: 0.2217\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [298/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3556\n",
      "LOG: Epoch [298/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3627\n",
      "    Batch [2/2], Val Loss: 0.0805\n",
      "Epoch [298/2000], Avg Train Loss: 0.3556, Avg Val Loss: 0.2216\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [299/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3485\n",
      "LOG: Epoch [299/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3627\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [299/2000], Avg Train Loss: 0.3485, Avg Val Loss: 0.2216\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [300/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3503\n",
      "LOG: Epoch [300/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3626\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [300/2000], Avg Train Loss: 0.3503, Avg Val Loss: 0.2216\n",
      "\n",
      "Validation loss improved from 0.2216 to 0.2216. Saving model...\n",
      "LOG: Epoch [301/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3557\n",
      "LOG: Epoch [301/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3625\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [301/2000], Avg Train Loss: 0.3557, Avg Val Loss: 0.2215\n",
      "\n",
      "Validation loss improved from 0.2216 to 0.2215. Saving model...\n",
      "LOG: Epoch [302/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [302/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [302/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2215\n",
      "\n",
      "Validation loss improved from 0.2215 to 0.2215. Saving model...\n",
      "LOG: Epoch [303/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [303/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [303/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.2215\n",
      "\n",
      "Validation loss improved from 0.2215 to 0.2215. Saving model...\n",
      "LOG: Epoch [304/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [304/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [304/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2215\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [305/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [305/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [305/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2215\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [306/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3506\n",
      "LOG: Epoch [306/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [306/2000], Avg Train Loss: 0.3506, Avg Val Loss: 0.2215\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [307/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [307/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [307/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2215\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [308/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3529\n",
      "LOG: Epoch [308/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [308/2000], Avg Train Loss: 0.3529, Avg Val Loss: 0.2215\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [309/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [309/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0807\n",
      "Epoch [309/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2215\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [310/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3487\n",
      "LOG: Epoch [310/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [310/2000], Avg Train Loss: 0.3487, Avg Val Loss: 0.2215\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [311/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3533\n",
      "LOG: Epoch [311/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [311/2000], Avg Train Loss: 0.3533, Avg Val Loss: 0.2215\n",
      "\n",
      "Validation loss improved from 0.2215 to 0.2215. Saving model...\n",
      "LOG: Epoch [312/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3530\n",
      "LOG: Epoch [312/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [312/2000], Avg Train Loss: 0.3530, Avg Val Loss: 0.2215\n",
      "\n",
      "Validation loss improved from 0.2215 to 0.2215. Saving model...\n",
      "LOG: Epoch [313/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3495\n",
      "LOG: Epoch [313/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [313/2000], Avg Train Loss: 0.3495, Avg Val Loss: 0.2214\n",
      "\n",
      "Validation loss improved from 0.2215 to 0.2214. Saving model...\n",
      "LOG: Epoch [314/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [314/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0806\n",
      "Epoch [314/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2214\n",
      "\n",
      "Validation loss improved from 0.2214 to 0.2214. Saving model...\n",
      "LOG: Epoch [315/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3497\n",
      "LOG: Epoch [315/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0805\n",
      "Epoch [315/2000], Avg Train Loss: 0.3497, Avg Val Loss: 0.2214\n",
      "\n",
      "Validation loss improved from 0.2214 to 0.2214. Saving model...\n",
      "LOG: Epoch [316/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [316/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0805\n",
      "Epoch [316/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2214\n",
      "\n",
      "Validation loss improved from 0.2214 to 0.2214. Saving model...\n",
      "LOG: Epoch [317/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [317/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3622\n",
      "    Batch [2/2], Val Loss: 0.0805\n",
      "Epoch [317/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2214\n",
      "\n",
      "Validation loss improved from 0.2214 to 0.2214. Saving model...\n",
      "LOG: Epoch [318/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3506\n",
      "LOG: Epoch [318/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3622\n",
      "    Batch [2/2], Val Loss: 0.0805\n",
      "Epoch [318/2000], Avg Train Loss: 0.3506, Avg Val Loss: 0.2213\n",
      "\n",
      "Validation loss improved from 0.2214 to 0.2213. Saving model...\n",
      "LOG: Epoch [319/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [319/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3622\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [319/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2213\n",
      "\n",
      "Validation loss improved from 0.2213 to 0.2213. Saving model...\n",
      "LOG: Epoch [320/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3516\n",
      "LOG: Epoch [320/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [320/2000], Avg Train Loss: 0.3516, Avg Val Loss: 0.2213\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [321/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [321/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [321/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2213\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [322/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [322/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [322/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2214\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [323/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3517\n",
      "LOG: Epoch [323/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [323/2000], Avg Train Loss: 0.3517, Avg Val Loss: 0.2214\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [324/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [324/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [324/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2214\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [325/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [325/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0805\n",
      "Epoch [325/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.2214\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [326/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3520\n",
      "LOG: Epoch [326/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3625\n",
      "    Batch [2/2], Val Loss: 0.0805\n",
      "Epoch [326/2000], Avg Train Loss: 0.3520, Avg Val Loss: 0.2215\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [327/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [327/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3625\n",
      "    Batch [2/2], Val Loss: 0.0805\n",
      "Epoch [327/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2215\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [328/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3431\n",
      "LOG: Epoch [328/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3626\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [328/2000], Avg Train Loss: 0.3431, Avg Val Loss: 0.2215\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [329/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [329/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3627\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [329/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.2215\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [330/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [330/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3628\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [330/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2216\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [331/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3505\n",
      "LOG: Epoch [331/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3628\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [331/2000], Avg Train Loss: 0.3505, Avg Val Loss: 0.2216\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [332/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [332/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [332/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2216\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [333/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3515\n",
      "LOG: Epoch [333/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [333/2000], Avg Train Loss: 0.3515, Avg Val Loss: 0.2217\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [334/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3500\n",
      "LOG: Epoch [334/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [334/2000], Avg Train Loss: 0.3500, Avg Val Loss: 0.2217\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [335/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [335/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [335/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2217\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [336/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3507\n",
      "LOG: Epoch [336/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [336/2000], Avg Train Loss: 0.3507, Avg Val Loss: 0.2217\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [337/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [337/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [337/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2216\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [338/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3510\n",
      "LOG: Epoch [338/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3630\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [338/2000], Avg Train Loss: 0.3510, Avg Val Loss: 0.2216\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [339/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [339/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3629\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [339/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2216\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [340/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [340/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3629\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [340/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2216\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [341/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [341/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3628\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [341/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2215\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [342/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [342/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3626\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [342/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2214\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [343/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3519\n",
      "LOG: Epoch [343/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3625\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [343/2000], Avg Train Loss: 0.3519, Avg Val Loss: 0.2214\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [344/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [344/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3624\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [344/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2213\n",
      "\n",
      "Validation loss improved from 0.2213 to 0.2213. Saving model...\n",
      "LOG: Epoch [345/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [345/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3623\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [345/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2212\n",
      "\n",
      "Validation loss improved from 0.2213 to 0.2212. Saving model...\n",
      "LOG: Epoch [346/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [346/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3622\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [346/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2212\n",
      "\n",
      "Validation loss improved from 0.2212 to 0.2212. Saving model...\n",
      "LOG: Epoch [347/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3511\n",
      "LOG: Epoch [347/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3621\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [347/2000], Avg Train Loss: 0.3511, Avg Val Loss: 0.2211\n",
      "\n",
      "Validation loss improved from 0.2212 to 0.2211. Saving model...\n",
      "LOG: Epoch [348/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3526\n",
      "LOG: Epoch [348/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3620\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [348/2000], Avg Train Loss: 0.3526, Avg Val Loss: 0.2211\n",
      "\n",
      "Validation loss improved from 0.2211 to 0.2211. Saving model...\n",
      "LOG: Epoch [349/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [349/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3619\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [349/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2210\n",
      "\n",
      "Validation loss improved from 0.2211 to 0.2210. Saving model...\n",
      "LOG: Epoch [350/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [350/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3618\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [350/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2210\n",
      "\n",
      "Validation loss improved from 0.2210 to 0.2210. Saving model...\n",
      "LOG: Epoch [351/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [351/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3618\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [351/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2210\n",
      "\n",
      "Validation loss improved from 0.2210 to 0.2210. Saving model...\n",
      "LOG: Epoch [352/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3515\n",
      "LOG: Epoch [352/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3617\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [352/2000], Avg Train Loss: 0.3515, Avg Val Loss: 0.2210\n",
      "\n",
      "Validation loss improved from 0.2210 to 0.2210. Saving model...\n",
      "LOG: Epoch [353/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [353/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3616\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [353/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2209\n",
      "\n",
      "Validation loss improved from 0.2210 to 0.2209. Saving model...\n",
      "LOG: Epoch [354/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [354/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3616\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [354/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2209\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [355/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [355/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3616\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [355/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2210\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [356/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3508\n",
      "LOG: Epoch [356/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3616\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [356/2000], Avg Train Loss: 0.3508, Avg Val Loss: 0.2210\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [357/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3504\n",
      "LOG: Epoch [357/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3616\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [357/2000], Avg Train Loss: 0.3504, Avg Val Loss: 0.2210\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [358/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [358/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3616\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [358/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2209\n",
      "\n",
      "Validation loss improved from 0.2209 to 0.2209. Saving model...\n",
      "LOG: Epoch [359/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3527\n",
      "LOG: Epoch [359/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3616\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [359/2000], Avg Train Loss: 0.3527, Avg Val Loss: 0.2209\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [360/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3530\n",
      "LOG: Epoch [360/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3616\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [360/2000], Avg Train Loss: 0.3530, Avg Val Loss: 0.2210\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [361/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [361/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3616\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [361/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2209\n",
      "\n",
      "Validation loss improved from 0.2209 to 0.2209. Saving model...\n",
      "LOG: Epoch [362/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [362/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3615\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [362/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2209\n",
      "\n",
      "Validation loss improved from 0.2209 to 0.2209. Saving model...\n",
      "LOG: Epoch [363/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3505\n",
      "LOG: Epoch [363/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3615\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [363/2000], Avg Train Loss: 0.3505, Avg Val Loss: 0.2209\n",
      "\n",
      "Validation loss improved from 0.2209 to 0.2209. Saving model...\n",
      "LOG: Epoch [364/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [364/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3615\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [364/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2209\n",
      "\n",
      "Validation loss improved from 0.2209 to 0.2209. Saving model...\n",
      "LOG: Epoch [365/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [365/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3615\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [365/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2208\n",
      "\n",
      "Validation loss improved from 0.2209 to 0.2208. Saving model...\n",
      "LOG: Epoch [366/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [366/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3615\n",
      "    Batch [2/2], Val Loss: 0.0801\n",
      "Epoch [366/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2208\n",
      "\n",
      "Validation loss improved from 0.2208 to 0.2208. Saving model...\n",
      "LOG: Epoch [367/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3500\n",
      "LOG: Epoch [367/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3615\n",
      "    Batch [2/2], Val Loss: 0.0801\n",
      "Epoch [367/2000], Avg Train Loss: 0.3500, Avg Val Loss: 0.2208\n",
      "\n",
      "Validation loss improved from 0.2208 to 0.2208. Saving model...\n",
      "LOG: Epoch [368/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3505\n",
      "LOG: Epoch [368/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3615\n",
      "    Batch [2/2], Val Loss: 0.0801\n",
      "Epoch [368/2000], Avg Train Loss: 0.3505, Avg Val Loss: 0.2208\n",
      "\n",
      "Validation loss improved from 0.2208 to 0.2208. Saving model...\n",
      "LOG: Epoch [369/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3491\n",
      "LOG: Epoch [369/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3615\n",
      "    Batch [2/2], Val Loss: 0.0801\n",
      "Epoch [369/2000], Avg Train Loss: 0.3491, Avg Val Loss: 0.2208\n",
      "\n",
      "Validation loss improved from 0.2208 to 0.2208. Saving model...\n",
      "LOG: Epoch [370/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3507\n",
      "LOG: Epoch [370/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0800\n",
      "Epoch [370/2000], Avg Train Loss: 0.3507, Avg Val Loss: 0.2207\n",
      "\n",
      "Validation loss improved from 0.2208 to 0.2207. Saving model...\n",
      "LOG: Epoch [371/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [371/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0799\n",
      "Epoch [371/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2207\n",
      "\n",
      "Validation loss improved from 0.2207 to 0.2207. Saving model...\n",
      "LOG: Epoch [372/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3426\n",
      "LOG: Epoch [372/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3614\n",
      "    Batch [2/2], Val Loss: 0.0799\n",
      "Epoch [372/2000], Avg Train Loss: 0.3426, Avg Val Loss: 0.2206\n",
      "\n",
      "Validation loss improved from 0.2207 to 0.2206. Saving model...\n",
      "LOG: Epoch [373/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [373/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0798\n",
      "Epoch [373/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2206\n",
      "\n",
      "Validation loss improved from 0.2206 to 0.2206. Saving model...\n",
      "LOG: Epoch [374/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3494\n",
      "LOG: Epoch [374/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3613\n",
      "    Batch [2/2], Val Loss: 0.0798\n",
      "Epoch [374/2000], Avg Train Loss: 0.3494, Avg Val Loss: 0.2205\n",
      "\n",
      "Validation loss improved from 0.2206 to 0.2205. Saving model...\n",
      "LOG: Epoch [375/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3492\n",
      "LOG: Epoch [375/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.0798\n",
      "Epoch [375/2000], Avg Train Loss: 0.3492, Avg Val Loss: 0.2205\n",
      "\n",
      "Validation loss improved from 0.2205 to 0.2205. Saving model...\n",
      "LOG: Epoch [376/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [376/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3612\n",
      "    Batch [2/2], Val Loss: 0.0798\n",
      "Epoch [376/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2205\n",
      "\n",
      "Validation loss improved from 0.2205 to 0.2205. Saving model...\n",
      "LOG: Epoch [377/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3418\n",
      "LOG: Epoch [377/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0798\n",
      "Epoch [377/2000], Avg Train Loss: 0.3418, Avg Val Loss: 0.2205\n",
      "\n",
      "Validation loss improved from 0.2205 to 0.2205. Saving model...\n",
      "LOG: Epoch [378/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [378/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3611\n",
      "    Batch [2/2], Val Loss: 0.0798\n",
      "Epoch [378/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2205 to 0.2204. Saving model...\n",
      "LOG: Epoch [379/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [379/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0798\n",
      "Epoch [379/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2204. Saving model...\n",
      "LOG: Epoch [380/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [380/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0799\n",
      "Epoch [380/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2204\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [381/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [381/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0799\n",
      "Epoch [381/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2205\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [382/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3412\n",
      "LOG: Epoch [382/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0800\n",
      "Epoch [382/2000], Avg Train Loss: 0.3412, Avg Val Loss: 0.2205\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [383/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [383/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0801\n",
      "Epoch [383/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2205\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [384/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [384/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [384/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.2205\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [385/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [385/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [385/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2206\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [386/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [386/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [386/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.2206\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [387/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [387/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [387/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2207\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [388/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3421\n",
      "LOG: Epoch [388/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3610\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [388/2000], Avg Train Loss: 0.3421, Avg Val Loss: 0.2207\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [389/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3422\n",
      "LOG: Epoch [389/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [389/2000], Avg Train Loss: 0.3422, Avg Val Loss: 0.2207\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [390/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [390/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [390/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2207\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [391/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3486\n",
      "LOG: Epoch [391/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3609\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [391/2000], Avg Train Loss: 0.3486, Avg Val Loss: 0.2207\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [392/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [392/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [392/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2206\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [393/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [393/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [393/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2206\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [394/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [394/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [394/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2206\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [395/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [395/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [395/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2206\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [396/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [396/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [396/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2206\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [397/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3518\n",
      "LOG: Epoch [397/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [397/2000], Avg Train Loss: 0.3518, Avg Val Loss: 0.2206\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [398/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [398/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [398/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2206\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [399/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3486\n",
      "LOG: Epoch [399/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [399/2000], Avg Train Loss: 0.3486, Avg Val Loss: 0.2206\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [400/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [400/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0804\n",
      "Epoch [400/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2206\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [401/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [401/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [401/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2206\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [402/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [402/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [402/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2205\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [403/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [403/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [403/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2205\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [404/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [404/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [404/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2206\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [405/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [405/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [405/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2206\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [406/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3405\n",
      "LOG: Epoch [406/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3608\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [406/2000], Avg Train Loss: 0.3405, Avg Val Loss: 0.2205\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [407/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3482\n",
      "LOG: Epoch [407/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [407/2000], Avg Train Loss: 0.3482, Avg Val Loss: 0.2205\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [408/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [408/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [408/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2205\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [409/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [409/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [409/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2205\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [410/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [410/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3607\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [410/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2205\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [411/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3473\n",
      "LOG: Epoch [411/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [411/2000], Avg Train Loss: 0.3473, Avg Val Loss: 0.2205\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [412/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3489\n",
      "LOG: Epoch [412/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [412/2000], Avg Train Loss: 0.3489, Avg Val Loss: 0.2205\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [413/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [413/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [413/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2205\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [414/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3422\n",
      "LOG: Epoch [414/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [414/2000], Avg Train Loss: 0.3422, Avg Val Loss: 0.2204\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [415/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [415/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3606\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [415/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2204\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [416/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [416/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [416/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2204. Saving model...\n",
      "LOG: Epoch [417/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3417\n",
      "LOG: Epoch [417/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [417/2000], Avg Train Loss: 0.3417, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2204. Saving model...\n",
      "LOG: Epoch [418/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [418/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [418/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2204. Saving model...\n",
      "LOG: Epoch [419/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [419/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [419/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2204. Saving model...\n",
      "LOG: Epoch [420/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3503\n",
      "LOG: Epoch [420/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [420/2000], Avg Train Loss: 0.3503, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2204. Saving model...\n",
      "LOG: Epoch [421/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [421/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [421/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2204. Saving model...\n",
      "LOG: Epoch [422/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [422/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [422/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2204. Saving model...\n",
      "LOG: Epoch [423/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [423/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3605\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [423/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2204. Saving model...\n",
      "LOG: Epoch [424/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [424/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [424/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2204. Saving model...\n",
      "LOG: Epoch [425/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3414\n",
      "LOG: Epoch [425/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [425/2000], Avg Train Loss: 0.3414, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2204. Saving model...\n",
      "LOG: Epoch [426/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [426/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [426/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2204. Saving model...\n",
      "LOG: Epoch [427/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [427/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [427/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2204. Saving model...\n",
      "LOG: Epoch [428/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3486\n",
      "LOG: Epoch [428/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [428/2000], Avg Train Loss: 0.3486, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2204. Saving model...\n",
      "LOG: Epoch [429/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [429/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [429/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2204\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2204. Saving model...\n",
      "LOG: Epoch [430/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [430/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [430/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2204 to 0.2203. Saving model...\n",
      "LOG: Epoch [431/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [431/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [431/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [432/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [432/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [432/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [433/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [433/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [433/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [434/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [434/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [434/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [435/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3401\n",
      "LOG: Epoch [435/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3604\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [435/2000], Avg Train Loss: 0.3401, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [436/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [436/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [437/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3406\n",
      "LOG: Epoch [437/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [437/2000], Avg Train Loss: 0.3406, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [438/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3510\n",
      "LOG: Epoch [438/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [438/2000], Avg Train Loss: 0.3510, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [439/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [439/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [439/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [440/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3511\n",
      "LOG: Epoch [440/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [440/2000], Avg Train Loss: 0.3511, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [441/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [441/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [441/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [442/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3473\n",
      "LOG: Epoch [442/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [442/2000], Avg Train Loss: 0.3473, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [443/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3482\n",
      "LOG: Epoch [443/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [443/2000], Avg Train Loss: 0.3482, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [444/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [444/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [444/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [445/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [445/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [445/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [446/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [446/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [446/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [447/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [447/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [447/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [448/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [448/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [448/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [449/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [449/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [449/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [450/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [450/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [450/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [451/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3603\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [451/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [452/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [452/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [452/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [453/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [453/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [453/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [454/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3391\n",
      "LOG: Epoch [454/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [454/2000], Avg Train Loss: 0.3391, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [455/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [455/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [455/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [456/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [456/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [456/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [457/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3397\n",
      "LOG: Epoch [457/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [457/2000], Avg Train Loss: 0.3397, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [458/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [458/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [458/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [459/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [459/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [459/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [460/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [460/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [460/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [461/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [461/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [461/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [462/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3393\n",
      "LOG: Epoch [462/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [462/2000], Avg Train Loss: 0.3393, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [463/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [463/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [463/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [464/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3419\n",
      "LOG: Epoch [464/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [464/2000], Avg Train Loss: 0.3419, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [465/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [465/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [465/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [466/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3426\n",
      "LOG: Epoch [466/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [466/2000], Avg Train Loss: 0.3426, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [467/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [467/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [467/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2203\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2203. Saving model...\n",
      "LOG: Epoch [468/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [468/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [468/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2203 to 0.2202. Saving model...\n",
      "LOG: Epoch [469/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [469/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [469/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [470/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3401\n",
      "LOG: Epoch [470/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [470/2000], Avg Train Loss: 0.3401, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [471/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [471/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [471/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [472/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [472/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [472/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [473/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [473/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [473/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [474/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3417\n",
      "LOG: Epoch [474/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [474/2000], Avg Train Loss: 0.3417, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [475/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [475/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [475/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [476/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [476/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [476/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [477/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3505\n",
      "LOG: Epoch [477/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [477/2000], Avg Train Loss: 0.3505, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [478/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3448\n",
      "LOG: Epoch [478/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [478/2000], Avg Train Loss: 0.3448, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [479/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [479/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [479/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [480/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [480/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [480/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [481/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [481/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [481/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2203\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [482/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [482/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [482/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [483/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3485\n",
      "LOG: Epoch [483/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [483/2000], Avg Train Loss: 0.3485, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [484/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [484/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [484/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [485/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [485/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [485/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [486/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3367\n",
      "LOG: Epoch [486/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [486/2000], Avg Train Loss: 0.3367, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [487/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [487/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [487/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [488/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3411\n",
      "LOG: Epoch [488/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [488/2000], Avg Train Loss: 0.3411, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [489/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [489/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0803\n",
      "Epoch [489/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [490/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [490/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [490/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [491/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [491/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [491/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [492/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [492/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [492/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [493/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [493/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [493/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [494/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3388\n",
      "LOG: Epoch [494/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [494/2000], Avg Train Loss: 0.3388, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [495/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3489\n",
      "LOG: Epoch [495/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [495/2000], Avg Train Loss: 0.3489, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [496/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3500\n",
      "LOG: Epoch [496/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [496/2000], Avg Train Loss: 0.3500, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [497/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [497/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [497/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [498/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [498/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [498/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [499/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [499/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [499/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [500/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [500/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [500/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [501/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3412\n",
      "LOG: Epoch [501/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [501/2000], Avg Train Loss: 0.3412, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [502/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [502/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [502/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [503/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3503\n",
      "LOG: Epoch [503/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [503/2000], Avg Train Loss: 0.3503, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [504/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [504/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [504/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [505/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [505/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [505/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [506/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [506/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [506/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [507/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [507/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [507/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [508/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3519\n",
      "LOG: Epoch [508/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [508/2000], Avg Train Loss: 0.3519, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [509/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3485\n",
      "LOG: Epoch [509/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [509/2000], Avg Train Loss: 0.3485, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [510/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3418\n",
      "LOG: Epoch [510/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [510/2000], Avg Train Loss: 0.3418, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [511/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3487\n",
      "LOG: Epoch [511/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [511/2000], Avg Train Loss: 0.3487, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [512/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [512/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [512/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [513/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [513/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [513/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [514/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3486\n",
      "LOG: Epoch [514/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [514/2000], Avg Train Loss: 0.3486, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [515/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3482\n",
      "LOG: Epoch [515/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [515/2000], Avg Train Loss: 0.3482, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [516/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [516/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [516/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [517/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [517/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [517/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [518/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [518/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [518/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [519/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [519/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [519/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [520/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3460\n",
      "LOG: Epoch [520/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [520/2000], Avg Train Loss: 0.3460, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [521/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [521/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [521/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [522/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [522/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [522/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [523/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [523/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [523/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [524/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [524/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [524/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [525/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [525/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [525/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [526/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [526/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [526/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [527/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3496\n",
      "LOG: Epoch [527/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [527/2000], Avg Train Loss: 0.3496, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [528/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [528/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [528/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [529/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [529/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [529/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [530/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [530/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [530/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [531/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [531/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [531/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [532/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3502\n",
      "LOG: Epoch [532/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [532/2000], Avg Train Loss: 0.3502, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [533/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [533/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [533/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [534/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3422\n",
      "LOG: Epoch [534/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [534/2000], Avg Train Loss: 0.3422, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [535/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [535/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [535/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [536/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3417\n",
      "LOG: Epoch [536/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [536/2000], Avg Train Loss: 0.3417, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [537/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [537/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [537/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [538/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [538/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [538/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [539/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3499\n",
      "LOG: Epoch [539/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [539/2000], Avg Train Loss: 0.3499, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [540/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [540/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [540/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [541/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [541/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [541/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [542/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [542/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [542/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [543/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3426\n",
      "LOG: Epoch [543/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [543/2000], Avg Train Loss: 0.3426, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [544/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3494\n",
      "LOG: Epoch [544/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [544/2000], Avg Train Loss: 0.3494, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [545/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [545/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [545/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [546/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [546/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [546/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [547/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [547/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [547/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [548/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [548/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [548/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [549/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [549/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [549/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [550/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [550/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [550/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [551/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [551/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [551/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [552/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [552/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [552/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [553/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [553/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [553/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [554/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3486\n",
      "LOG: Epoch [554/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [554/2000], Avg Train Loss: 0.3486, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [555/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3482\n",
      "LOG: Epoch [555/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [555/2000], Avg Train Loss: 0.3482, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [556/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [556/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [556/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [557/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [557/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [557/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [558/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [558/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [558/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [559/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [559/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [559/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [560/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [560/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [560/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [561/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3425\n",
      "LOG: Epoch [561/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [561/2000], Avg Train Loss: 0.3425, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [562/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3416\n",
      "LOG: Epoch [562/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [562/2000], Avg Train Loss: 0.3416, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [563/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3514\n",
      "LOG: Epoch [563/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [563/2000], Avg Train Loss: 0.3514, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [564/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3460\n",
      "LOG: Epoch [564/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [564/2000], Avg Train Loss: 0.3460, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [565/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [565/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [565/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [566/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [566/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [566/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [567/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [567/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [567/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [568/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [568/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [568/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [569/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [569/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [569/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [570/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3412\n",
      "LOG: Epoch [570/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [570/2000], Avg Train Loss: 0.3412, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [571/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [571/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [571/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [572/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [572/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [572/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [573/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3417\n",
      "LOG: Epoch [573/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [573/2000], Avg Train Loss: 0.3417, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [574/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [574/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [574/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [575/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [575/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [575/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [576/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3482\n",
      "LOG: Epoch [576/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [576/2000], Avg Train Loss: 0.3482, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [577/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [577/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [577/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [578/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [578/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [579/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [579/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [579/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [580/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3416\n",
      "LOG: Epoch [580/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [580/2000], Avg Train Loss: 0.3416, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [581/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3508\n",
      "LOG: Epoch [581/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [581/2000], Avg Train Loss: 0.3508, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [582/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [582/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [582/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [583/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3412\n",
      "LOG: Epoch [583/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [583/2000], Avg Train Loss: 0.3412, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [584/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [584/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [584/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [585/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3495\n",
      "LOG: Epoch [585/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [585/2000], Avg Train Loss: 0.3495, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [586/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3482\n",
      "LOG: Epoch [586/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [586/2000], Avg Train Loss: 0.3482, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [587/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [587/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [587/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [588/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3417\n",
      "LOG: Epoch [588/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [588/2000], Avg Train Loss: 0.3417, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [589/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3502\n",
      "LOG: Epoch [589/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [589/2000], Avg Train Loss: 0.3502, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [590/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [590/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [590/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [591/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [591/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [591/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [592/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [592/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [592/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [593/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [593/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [593/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [594/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [594/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [594/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [595/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3419\n",
      "LOG: Epoch [595/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [595/2000], Avg Train Loss: 0.3419, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [596/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3377\n",
      "LOG: Epoch [596/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [596/2000], Avg Train Loss: 0.3377, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [597/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [597/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [597/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [598/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3498\n",
      "LOG: Epoch [598/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [598/2000], Avg Train Loss: 0.3498, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [599/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [599/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [599/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [600/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [600/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [600/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [601/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3504\n",
      "LOG: Epoch [601/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [601/2000], Avg Train Loss: 0.3504, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [602/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [602/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [602/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [603/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [603/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [603/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [604/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [604/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [604/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [605/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [605/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [605/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [606/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [606/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [606/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [607/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [607/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [607/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [608/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [608/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [608/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [609/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [609/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [609/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [610/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3485\n",
      "LOG: Epoch [610/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [610/2000], Avg Train Loss: 0.3485, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [611/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3512\n",
      "LOG: Epoch [611/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [611/2000], Avg Train Loss: 0.3512, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [612/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [612/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [612/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [613/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3425\n",
      "LOG: Epoch [613/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [613/2000], Avg Train Loss: 0.3425, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [614/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [614/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [615/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [615/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [615/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [616/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [616/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [617/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3486\n",
      "LOG: Epoch [617/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [617/2000], Avg Train Loss: 0.3486, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [618/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [618/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [618/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [619/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3448\n",
      "LOG: Epoch [619/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [619/2000], Avg Train Loss: 0.3448, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [620/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [620/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [620/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [621/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [621/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [621/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [622/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [622/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [622/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [623/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [623/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [623/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [624/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [624/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [624/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [625/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [625/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [625/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [626/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [626/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [626/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [627/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3403\n",
      "LOG: Epoch [627/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [627/2000], Avg Train Loss: 0.3403, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [628/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3416\n",
      "LOG: Epoch [628/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [628/2000], Avg Train Loss: 0.3416, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [629/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [629/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [629/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [630/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [630/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [630/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [631/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [631/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [631/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [632/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [632/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [632/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [633/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3515\n",
      "LOG: Epoch [633/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [633/2000], Avg Train Loss: 0.3515, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [634/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [634/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [634/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [635/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [635/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [635/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [636/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3489\n",
      "LOG: Epoch [636/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [636/2000], Avg Train Loss: 0.3489, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [637/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [637/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [637/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [638/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3416\n",
      "LOG: Epoch [638/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [638/2000], Avg Train Loss: 0.3416, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [639/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [639/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [639/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [640/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [640/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [640/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [641/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [641/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [641/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [642/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [642/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [642/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [643/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3399\n",
      "LOG: Epoch [643/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [643/2000], Avg Train Loss: 0.3399, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [644/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [644/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [644/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [645/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [645/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [645/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [646/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [646/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [646/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [647/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [647/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [647/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [648/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [648/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [648/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [649/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [649/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [649/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [650/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3410\n",
      "LOG: Epoch [650/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [650/2000], Avg Train Loss: 0.3410, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [651/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [651/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [651/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [652/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [652/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [652/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [653/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [653/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [653/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [654/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [654/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [654/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [655/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [655/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [655/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [656/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [656/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [656/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [657/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3460\n",
      "LOG: Epoch [657/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [657/2000], Avg Train Loss: 0.3460, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [658/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [658/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [658/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [659/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [659/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [659/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [660/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [660/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [660/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [661/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [661/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [661/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [662/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [662/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [662/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [663/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [663/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [663/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [664/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3511\n",
      "LOG: Epoch [664/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [664/2000], Avg Train Loss: 0.3511, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [665/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3483\n",
      "LOG: Epoch [665/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [665/2000], Avg Train Loss: 0.3483, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [666/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [666/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [666/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [667/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [667/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [667/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [668/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3495\n",
      "LOG: Epoch [668/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [668/2000], Avg Train Loss: 0.3495, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [669/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [669/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [669/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [670/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [670/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [670/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [671/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [671/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [671/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [672/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [672/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [672/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [673/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [673/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [673/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [674/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3489\n",
      "LOG: Epoch [674/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [674/2000], Avg Train Loss: 0.3489, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [675/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [675/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [675/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [676/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [676/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [676/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [677/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [677/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [677/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [678/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [678/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [678/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [679/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3426\n",
      "LOG: Epoch [679/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [679/2000], Avg Train Loss: 0.3426, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [680/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3373\n",
      "LOG: Epoch [680/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [680/2000], Avg Train Loss: 0.3373, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [681/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [681/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [681/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [682/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [682/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [682/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [683/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3421\n",
      "LOG: Epoch [683/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [683/2000], Avg Train Loss: 0.3421, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [684/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [684/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [684/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [685/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [685/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [685/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [686/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [686/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [686/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [687/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3492\n",
      "LOG: Epoch [687/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [687/2000], Avg Train Loss: 0.3492, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [688/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [688/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [688/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [689/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [689/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [689/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [690/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [690/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [690/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [691/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [691/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [691/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [692/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [692/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [692/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [693/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [693/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [693/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [694/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3489\n",
      "LOG: Epoch [694/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [694/2000], Avg Train Loss: 0.3489, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [695/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [695/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [695/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [696/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3496\n",
      "LOG: Epoch [696/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [696/2000], Avg Train Loss: 0.3496, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [697/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [697/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [697/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [698/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [698/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [698/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [699/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [699/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [699/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [700/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [700/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [700/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [701/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3408\n",
      "LOG: Epoch [701/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [701/2000], Avg Train Loss: 0.3408, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [702/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [702/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [702/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [703/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3409\n",
      "LOG: Epoch [703/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [703/2000], Avg Train Loss: 0.3409, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [704/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3494\n",
      "LOG: Epoch [704/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [704/2000], Avg Train Loss: 0.3494, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [705/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3506\n",
      "LOG: Epoch [705/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [705/2000], Avg Train Loss: 0.3506, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [706/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3398\n",
      "LOG: Epoch [706/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [706/2000], Avg Train Loss: 0.3398, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [707/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [707/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [707/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [708/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3505\n",
      "LOG: Epoch [708/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [708/2000], Avg Train Loss: 0.3505, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [709/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [709/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [709/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [710/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3406\n",
      "LOG: Epoch [710/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [710/2000], Avg Train Loss: 0.3406, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [711/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3516\n",
      "LOG: Epoch [711/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [711/2000], Avg Train Loss: 0.3516, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [712/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [712/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [712/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [713/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3460\n",
      "LOG: Epoch [713/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [713/2000], Avg Train Loss: 0.3460, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [714/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [714/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [714/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [715/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [715/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [715/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [716/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [716/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [716/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [717/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3539\n",
      "LOG: Epoch [717/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [717/2000], Avg Train Loss: 0.3539, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [718/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [718/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [718/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [719/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [719/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [719/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [720/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3483\n",
      "LOG: Epoch [720/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [720/2000], Avg Train Loss: 0.3483, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [721/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [721/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [721/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [722/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [722/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [722/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [723/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [723/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [723/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [724/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [724/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [724/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [725/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3415\n",
      "LOG: Epoch [725/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [725/2000], Avg Train Loss: 0.3415, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [726/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3448\n",
      "LOG: Epoch [726/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [726/2000], Avg Train Loss: 0.3448, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [727/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3473\n",
      "LOG: Epoch [727/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [727/2000], Avg Train Loss: 0.3473, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [728/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [728/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [728/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [729/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3425\n",
      "LOG: Epoch [729/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [729/2000], Avg Train Loss: 0.3425, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [730/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3419\n",
      "LOG: Epoch [730/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [730/2000], Avg Train Loss: 0.3419, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [731/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [731/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [731/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [732/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [732/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [732/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [733/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3405\n",
      "LOG: Epoch [733/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [733/2000], Avg Train Loss: 0.3405, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [734/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [734/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [734/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [735/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [735/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [735/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [736/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [736/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [736/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [737/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3397\n",
      "LOG: Epoch [737/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [737/2000], Avg Train Loss: 0.3397, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [738/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3431\n",
      "LOG: Epoch [738/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [738/2000], Avg Train Loss: 0.3431, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [739/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3419\n",
      "LOG: Epoch [739/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [739/2000], Avg Train Loss: 0.3419, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [740/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [740/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [740/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [741/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3509\n",
      "LOG: Epoch [741/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [741/2000], Avg Train Loss: 0.3509, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [742/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [742/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [742/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [743/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [743/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [743/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [744/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3417\n",
      "LOG: Epoch [744/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [744/2000], Avg Train Loss: 0.3417, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [745/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [745/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [745/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [746/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [746/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [746/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [747/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [747/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [747/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [748/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [748/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [748/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [749/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [749/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [749/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [750/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [750/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [750/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [751/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [751/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [751/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [752/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [752/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [752/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [753/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3403\n",
      "LOG: Epoch [753/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [753/2000], Avg Train Loss: 0.3403, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [754/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [754/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [754/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [755/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [755/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [755/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [756/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3493\n",
      "LOG: Epoch [756/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [756/2000], Avg Train Loss: 0.3493, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [757/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3414\n",
      "LOG: Epoch [757/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [757/2000], Avg Train Loss: 0.3414, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [758/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3422\n",
      "LOG: Epoch [758/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [758/2000], Avg Train Loss: 0.3422, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [759/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [759/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [759/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [760/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3415\n",
      "LOG: Epoch [760/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [760/2000], Avg Train Loss: 0.3415, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [761/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [761/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [761/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [762/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [762/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [762/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [763/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [763/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [763/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [764/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [764/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [764/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [765/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [765/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [765/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [766/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3486\n",
      "LOG: Epoch [766/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [766/2000], Avg Train Loss: 0.3486, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [767/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3393\n",
      "LOG: Epoch [767/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [767/2000], Avg Train Loss: 0.3393, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [768/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3409\n",
      "LOG: Epoch [768/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [768/2000], Avg Train Loss: 0.3409, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [769/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3492\n",
      "LOG: Epoch [769/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [769/2000], Avg Train Loss: 0.3492, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [770/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3511\n",
      "LOG: Epoch [770/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [770/2000], Avg Train Loss: 0.3511, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [771/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [771/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [771/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [772/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3501\n",
      "LOG: Epoch [772/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [772/2000], Avg Train Loss: 0.3501, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [773/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [773/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [773/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [774/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [774/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [774/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [775/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3387\n",
      "LOG: Epoch [775/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [775/2000], Avg Train Loss: 0.3387, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [776/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [776/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [776/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [777/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [777/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [777/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [778/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [778/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [778/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [779/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [779/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [779/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [780/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [780/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [780/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [781/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [781/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [781/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [782/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [782/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [782/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [783/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [783/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [783/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [784/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [784/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [784/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [785/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [785/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [785/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [786/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [786/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [786/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [787/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3489\n",
      "LOG: Epoch [787/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [787/2000], Avg Train Loss: 0.3489, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [788/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [788/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [788/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [789/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [789/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [789/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [790/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3422\n",
      "LOG: Epoch [790/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [790/2000], Avg Train Loss: 0.3422, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [791/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [791/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [791/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [792/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3521\n",
      "LOG: Epoch [792/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [792/2000], Avg Train Loss: 0.3521, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [793/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [793/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [793/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [794/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [794/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [794/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [795/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [795/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [795/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [796/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3394\n",
      "LOG: Epoch [796/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [796/2000], Avg Train Loss: 0.3394, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [797/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [797/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [797/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [798/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [798/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [798/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [799/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [799/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [799/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [800/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3421\n",
      "LOG: Epoch [800/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [800/2000], Avg Train Loss: 0.3421, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [801/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [801/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [801/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [802/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [802/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [802/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [803/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [803/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [803/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [804/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3448\n",
      "LOG: Epoch [804/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [804/2000], Avg Train Loss: 0.3448, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [805/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [805/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [805/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [806/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [806/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [806/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [807/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [807/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [807/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [808/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [808/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [808/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [809/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [809/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [809/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [810/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3396\n",
      "LOG: Epoch [810/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [810/2000], Avg Train Loss: 0.3396, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [811/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3388\n",
      "LOG: Epoch [811/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [811/2000], Avg Train Loss: 0.3388, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [812/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [812/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [812/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [813/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [813/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [813/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [814/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [814/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [814/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [815/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3515\n",
      "LOG: Epoch [815/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [815/2000], Avg Train Loss: 0.3515, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [816/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [816/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [816/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [817/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [817/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [817/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [818/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3502\n",
      "LOG: Epoch [818/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [818/2000], Avg Train Loss: 0.3502, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [819/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [819/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [819/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [820/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3448\n",
      "LOG: Epoch [820/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [820/2000], Avg Train Loss: 0.3448, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [821/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [821/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [821/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [822/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3516\n",
      "LOG: Epoch [822/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [822/2000], Avg Train Loss: 0.3516, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [823/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [823/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [823/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [824/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [824/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [824/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [825/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [825/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [825/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [826/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [826/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [826/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [827/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [827/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [827/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [828/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3411\n",
      "LOG: Epoch [828/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [828/2000], Avg Train Loss: 0.3411, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [829/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3414\n",
      "LOG: Epoch [829/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [829/2000], Avg Train Loss: 0.3414, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [830/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3405\n",
      "LOG: Epoch [830/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [830/2000], Avg Train Loss: 0.3405, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [831/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [831/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [831/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [832/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [832/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [832/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [833/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [833/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [833/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [834/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [834/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [834/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [835/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3400\n",
      "LOG: Epoch [835/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [835/2000], Avg Train Loss: 0.3400, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [836/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [836/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [836/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [837/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3390\n",
      "LOG: Epoch [837/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [837/2000], Avg Train Loss: 0.3390, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [838/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3387\n",
      "LOG: Epoch [838/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [838/2000], Avg Train Loss: 0.3387, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [839/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [839/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [839/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [840/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [840/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [840/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [841/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3412\n",
      "LOG: Epoch [841/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [841/2000], Avg Train Loss: 0.3412, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [842/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [842/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [842/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [843/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [843/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [843/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [844/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3398\n",
      "LOG: Epoch [844/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [844/2000], Avg Train Loss: 0.3398, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [845/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [845/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [845/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [846/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [846/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [846/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [847/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3425\n",
      "LOG: Epoch [847/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [847/2000], Avg Train Loss: 0.3425, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [848/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [848/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [848/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [849/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [849/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [849/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [850/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [850/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [850/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [851/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [851/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [851/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [852/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [852/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [852/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [853/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [853/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [853/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [854/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [854/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [854/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [855/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [855/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [855/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [856/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [856/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [856/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [857/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [857/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [857/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [858/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3425\n",
      "LOG: Epoch [858/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [858/2000], Avg Train Loss: 0.3425, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [859/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [859/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [859/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [860/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [860/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [860/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [861/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [861/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [861/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [862/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3414\n",
      "LOG: Epoch [862/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [862/2000], Avg Train Loss: 0.3414, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [863/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [863/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [863/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [864/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [864/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [864/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [865/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [865/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [865/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [866/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [866/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [866/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [867/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [867/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [867/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [868/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3393\n",
      "LOG: Epoch [868/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [868/2000], Avg Train Loss: 0.3393, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [869/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3495\n",
      "LOG: Epoch [869/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [869/2000], Avg Train Loss: 0.3495, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [870/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3482\n",
      "LOG: Epoch [870/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [870/2000], Avg Train Loss: 0.3482, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [871/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3417\n",
      "LOG: Epoch [871/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [871/2000], Avg Train Loss: 0.3417, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [872/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3491\n",
      "LOG: Epoch [872/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [872/2000], Avg Train Loss: 0.3491, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [873/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [873/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [873/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [874/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [874/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [874/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [875/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [875/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [875/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [876/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [876/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [876/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [877/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3414\n",
      "LOG: Epoch [877/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [877/2000], Avg Train Loss: 0.3414, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [878/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [878/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [878/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [879/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [879/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [879/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [880/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [880/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [880/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [881/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [881/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [881/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [882/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [882/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [882/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [883/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [883/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [883/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [884/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [884/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [884/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [885/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3421\n",
      "LOG: Epoch [885/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [885/2000], Avg Train Loss: 0.3421, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [886/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [886/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [886/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [887/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [887/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [887/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [888/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3413\n",
      "LOG: Epoch [888/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [888/2000], Avg Train Loss: 0.3413, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [889/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [889/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [889/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [890/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [890/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [890/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [891/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [891/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [891/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [892/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [892/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [892/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [893/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [893/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [893/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [894/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3414\n",
      "LOG: Epoch [894/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [894/2000], Avg Train Loss: 0.3414, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [895/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [895/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [895/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [896/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [896/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [896/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [897/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3460\n",
      "LOG: Epoch [897/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [897/2000], Avg Train Loss: 0.3460, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [898/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [898/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [898/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [899/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [899/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [899/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [900/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3491\n",
      "LOG: Epoch [900/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [900/2000], Avg Train Loss: 0.3491, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [901/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [901/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [901/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [902/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [902/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [902/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [903/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3499\n",
      "LOG: Epoch [903/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [903/2000], Avg Train Loss: 0.3499, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [904/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [904/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [904/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [905/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [905/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [905/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [906/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [906/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [906/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [907/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [907/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [907/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [908/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [908/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [908/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [909/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [909/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [909/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [910/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [910/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [910/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [911/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3418\n",
      "LOG: Epoch [911/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [911/2000], Avg Train Loss: 0.3418, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [912/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3519\n",
      "LOG: Epoch [912/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [912/2000], Avg Train Loss: 0.3519, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [913/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [913/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [913/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [914/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [914/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [914/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [915/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [915/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [915/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [916/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3411\n",
      "LOG: Epoch [916/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [916/2000], Avg Train Loss: 0.3411, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [917/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [917/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [917/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [918/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [918/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [918/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [919/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [919/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [919/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [920/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3425\n",
      "LOG: Epoch [920/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [920/2000], Avg Train Loss: 0.3425, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [921/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [921/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [921/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [922/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [922/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [922/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [923/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [923/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [923/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [924/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [924/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [924/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [925/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3407\n",
      "LOG: Epoch [925/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [925/2000], Avg Train Loss: 0.3407, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [926/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3485\n",
      "LOG: Epoch [926/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [926/2000], Avg Train Loss: 0.3485, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [927/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [927/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [927/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [928/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [928/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [928/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [929/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3487\n",
      "LOG: Epoch [929/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [929/2000], Avg Train Loss: 0.3487, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [930/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3418\n",
      "LOG: Epoch [930/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [930/2000], Avg Train Loss: 0.3418, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [931/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3505\n",
      "LOG: Epoch [931/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [931/2000], Avg Train Loss: 0.3505, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [932/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [932/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [932/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [933/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3404\n",
      "LOG: Epoch [933/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [933/2000], Avg Train Loss: 0.3404, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [934/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [934/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [934/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [935/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3534\n",
      "LOG: Epoch [935/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [935/2000], Avg Train Loss: 0.3534, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [936/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3422\n",
      "LOG: Epoch [936/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [936/2000], Avg Train Loss: 0.3422, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [937/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [937/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [937/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [938/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [938/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [938/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [939/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [939/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [939/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [940/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [940/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [940/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [941/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [941/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [941/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [942/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [942/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [942/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [943/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3495\n",
      "LOG: Epoch [943/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [943/2000], Avg Train Loss: 0.3495, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [944/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3392\n",
      "LOG: Epoch [944/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [944/2000], Avg Train Loss: 0.3392, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [945/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3415\n",
      "LOG: Epoch [945/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [945/2000], Avg Train Loss: 0.3415, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [946/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [946/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [946/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [947/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [947/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [947/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [948/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [948/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [948/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [949/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3494\n",
      "LOG: Epoch [949/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [949/2000], Avg Train Loss: 0.3494, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [950/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [950/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [950/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [951/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [951/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [951/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [952/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3389\n",
      "LOG: Epoch [952/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [952/2000], Avg Train Loss: 0.3389, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [953/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [953/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [953/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [954/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [954/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [954/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [955/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3493\n",
      "LOG: Epoch [955/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [955/2000], Avg Train Loss: 0.3493, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [956/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [956/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [956/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [957/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [957/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [957/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [958/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [958/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [958/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [959/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [959/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [959/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [960/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [960/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [960/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [961/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [961/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [961/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [962/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [962/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [962/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [963/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3512\n",
      "LOG: Epoch [963/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [963/2000], Avg Train Loss: 0.3512, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [964/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [964/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [964/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [965/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [965/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [965/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [966/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [966/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [966/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [967/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3405\n",
      "LOG: Epoch [967/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [967/2000], Avg Train Loss: 0.3405, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [968/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3460\n",
      "LOG: Epoch [968/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [968/2000], Avg Train Loss: 0.3460, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [969/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3418\n",
      "LOG: Epoch [969/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [969/2000], Avg Train Loss: 0.3418, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [970/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [970/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [970/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [971/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [971/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [971/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [972/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [972/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [972/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [973/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [973/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [973/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [974/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [974/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [974/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [975/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [975/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [975/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [976/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3473\n",
      "LOG: Epoch [976/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [976/2000], Avg Train Loss: 0.3473, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [977/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [977/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [977/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [978/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [978/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [978/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [979/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [979/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [979/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [980/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [980/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [980/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [981/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [981/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [981/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [982/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3407\n",
      "LOG: Epoch [982/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [982/2000], Avg Train Loss: 0.3407, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [983/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [983/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [983/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [984/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [984/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [984/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [985/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [985/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [985/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [986/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [986/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [986/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [987/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [987/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [987/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [988/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [988/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [988/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [989/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [989/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [989/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [990/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [990/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [990/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [991/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [991/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [991/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [992/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [992/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [992/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [993/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [993/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [993/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [994/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [994/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [994/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [995/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [995/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [995/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [996/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3487\n",
      "LOG: Epoch [996/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [996/2000], Avg Train Loss: 0.3487, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [997/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [997/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [997/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [998/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [998/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [998/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [999/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [999/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [999/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1000/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1000/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1000/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1001/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1001/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1001/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1002/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1002/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1002/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1003/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [1003/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1003/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1004/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [1004/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1004/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1005/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1005/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1005/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1006/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3510\n",
      "LOG: Epoch [1006/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1006/2000], Avg Train Loss: 0.3510, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1007/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [1007/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1007/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1008/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1008/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1008/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1009/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [1009/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1009/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1010/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3425\n",
      "LOG: Epoch [1010/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1010/2000], Avg Train Loss: 0.3425, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1011/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [1011/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1011/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1012/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [1012/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1012/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1013/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1013/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1013/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1014/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [1014/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1014/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1015/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1015/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1015/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1016/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3408\n",
      "LOG: Epoch [1016/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1016/2000], Avg Train Loss: 0.3408, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1017/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1017/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1017/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1018/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1018/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1018/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1019/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1019/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1019/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1020/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1020/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1020/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1021/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3418\n",
      "LOG: Epoch [1021/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1021/2000], Avg Train Loss: 0.3418, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1022/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [1022/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1022/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1023/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [1023/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1023/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1024/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3422\n",
      "LOG: Epoch [1024/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1024/2000], Avg Train Loss: 0.3422, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1025/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [1025/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1025/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1026/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [1026/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1026/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1027/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3409\n",
      "LOG: Epoch [1027/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1027/2000], Avg Train Loss: 0.3409, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1028/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3495\n",
      "LOG: Epoch [1028/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1028/2000], Avg Train Loss: 0.3495, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1029/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [1029/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1029/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1030/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1030/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1030/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1031/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1031/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1031/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1032/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [1032/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1032/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1033/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1033/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1033/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1034/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1034/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1034/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1035/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [1035/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1035/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1036/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [1036/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1036/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1037/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [1037/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1037/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1038/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3494\n",
      "LOG: Epoch [1038/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1038/2000], Avg Train Loss: 0.3494, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1039/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [1039/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1039/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1040/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [1040/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1040/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1041/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [1041/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1041/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1042/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1042/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1042/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1043/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [1043/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1043/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1044/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [1044/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1044/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1045/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1045/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1045/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1046/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1046/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1046/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1047/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3448\n",
      "LOG: Epoch [1047/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1047/2000], Avg Train Loss: 0.3448, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1048/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1048/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1048/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1049/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1049/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1049/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1050/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1050/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1050/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1051/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [1051/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1051/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1052/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [1052/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1052/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1053/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3448\n",
      "LOG: Epoch [1053/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1053/2000], Avg Train Loss: 0.3448, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1054/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1054/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1054/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1055/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1055/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1055/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1056/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1056/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1056/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1057/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [1057/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1057/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1058/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [1058/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1058/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1059/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3501\n",
      "LOG: Epoch [1059/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1059/2000], Avg Train Loss: 0.3501, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1060/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1060/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1060/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1061/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3495\n",
      "LOG: Epoch [1061/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1061/2000], Avg Train Loss: 0.3495, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1062/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1062/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1062/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1063/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1063/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1063/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1064/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [1064/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1064/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1065/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [1065/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1065/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1066/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1066/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1066/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1067/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1067/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1067/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1068/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1068/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1068/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1069/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [1069/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1069/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1070/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [1070/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1070/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1071/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [1071/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1071/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1072/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [1072/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1072/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1073/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1073/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1073/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1074/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1074/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1074/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1075/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1075/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1075/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1076/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [1076/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1076/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1077/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [1077/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1077/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1078/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1078/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1078/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1079/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1079/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1079/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1080/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1080/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1080/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1081/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [1081/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1081/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1082/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1082/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1082/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1083/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1083/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1083/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1084/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1084/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1084/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1085/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [1085/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1085/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1086/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [1086/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1086/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1087/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [1087/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1087/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1088/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3483\n",
      "LOG: Epoch [1088/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1088/2000], Avg Train Loss: 0.3483, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1089/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3400\n",
      "LOG: Epoch [1089/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1089/2000], Avg Train Loss: 0.3400, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1090/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1090/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1090/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1091/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3410\n",
      "LOG: Epoch [1091/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1091/2000], Avg Train Loss: 0.3410, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1092/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1092/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1092/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1093/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [1093/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1093/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1094/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1094/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1094/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1095/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3493\n",
      "LOG: Epoch [1095/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1095/2000], Avg Train Loss: 0.3493, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1096/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [1096/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1096/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1097/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3422\n",
      "LOG: Epoch [1097/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1097/2000], Avg Train Loss: 0.3422, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1098/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [1098/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1098/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1099/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1099/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1099/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1100/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1100/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1100/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1101/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [1101/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1101/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1102/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1102/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1102/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1103/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3507\n",
      "LOG: Epoch [1103/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1103/2000], Avg Train Loss: 0.3507, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1104/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3409\n",
      "LOG: Epoch [1104/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1104/2000], Avg Train Loss: 0.3409, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1105/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3495\n",
      "LOG: Epoch [1105/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1105/2000], Avg Train Loss: 0.3495, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1106/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [1106/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1106/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1107/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [1107/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1107/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1108/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3515\n",
      "LOG: Epoch [1108/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1108/2000], Avg Train Loss: 0.3515, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1109/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [1109/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1109/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1110/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [1110/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1110/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1111/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [1111/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1111/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1112/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [1112/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1112/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1113/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3492\n",
      "LOG: Epoch [1113/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1113/2000], Avg Train Loss: 0.3492, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1114/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [1114/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1114/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1115/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [1115/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1115/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1116/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [1116/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1116/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1117/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1117/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1117/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1118/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [1118/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1118/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1119/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [1119/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1119/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1120/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1120/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1121/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1121/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1121/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1122/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [1122/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1122/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1123/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [1123/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1123/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1124/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3496\n",
      "LOG: Epoch [1124/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1124/2000], Avg Train Loss: 0.3496, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1125/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [1125/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1125/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3419\n",
      "LOG: Epoch [1126/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1126/2000], Avg Train Loss: 0.3419, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1127/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3419\n",
      "LOG: Epoch [1127/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1127/2000], Avg Train Loss: 0.3419, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1128/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1128/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1128/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1129/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [1129/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1129/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1130/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3473\n",
      "LOG: Epoch [1130/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1130/2000], Avg Train Loss: 0.3473, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1131/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [1131/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1131/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1132/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1132/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1132/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1133/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [1133/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1133/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1134/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1134/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1134/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1135/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [1135/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1135/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1136/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [1136/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1136/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1137/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3426\n",
      "LOG: Epoch [1137/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1137/2000], Avg Train Loss: 0.3426, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1138/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1138/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1138/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1139/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1139/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1139/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1140/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [1140/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1140/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1141/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1141/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1141/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1142/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1142/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1142/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1143/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [1143/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1143/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1144/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [1144/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1144/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1145/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1145/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1145/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1146/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3498\n",
      "LOG: Epoch [1146/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1146/2000], Avg Train Loss: 0.3498, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1147/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [1147/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1147/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1148/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [1148/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1148/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1149/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3416\n",
      "LOG: Epoch [1149/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1149/2000], Avg Train Loss: 0.3416, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1150/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [1150/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1150/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1151/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [1151/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1151/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1152/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [1152/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1152/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1153/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3395\n",
      "LOG: Epoch [1153/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1153/2000], Avg Train Loss: 0.3395, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1154/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1154/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1154/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1155/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3397\n",
      "LOG: Epoch [1155/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1155/2000], Avg Train Loss: 0.3397, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1156/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1156/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1156/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1157/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1157/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1157/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1158/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1158/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1158/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1159/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1159/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1159/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1160/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [1160/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1160/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1161/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3489\n",
      "LOG: Epoch [1161/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1161/2000], Avg Train Loss: 0.3489, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1162/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1162/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1163/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3473\n",
      "LOG: Epoch [1163/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1163/2000], Avg Train Loss: 0.3473, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1164/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [1164/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1164/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1165/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [1165/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1165/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1166/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3362\n",
      "LOG: Epoch [1166/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1166/2000], Avg Train Loss: 0.3362, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1167/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1167/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1167/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1168/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1168/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1168/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1169/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1169/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1169/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1170/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1170/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1170/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1171/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [1171/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1171/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1172/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3422\n",
      "LOG: Epoch [1172/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1172/2000], Avg Train Loss: 0.3422, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1173/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1173/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1173/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1174/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1174/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1174/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1175/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1175/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1175/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1176/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3384\n",
      "LOG: Epoch [1176/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1176/2000], Avg Train Loss: 0.3384, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1177/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3422\n",
      "LOG: Epoch [1177/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1177/2000], Avg Train Loss: 0.3422, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1178/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [1178/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1178/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1179/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1179/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1179/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1180/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3412\n",
      "LOG: Epoch [1180/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1180/2000], Avg Train Loss: 0.3412, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1181/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3388\n",
      "LOG: Epoch [1181/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1181/2000], Avg Train Loss: 0.3388, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1182/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [1182/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1182/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1183/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1183/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1183/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1184/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3425\n",
      "LOG: Epoch [1184/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1184/2000], Avg Train Loss: 0.3425, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1185/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3504\n",
      "LOG: Epoch [1185/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1185/2000], Avg Train Loss: 0.3504, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1186/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3489\n",
      "LOG: Epoch [1186/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1186/2000], Avg Train Loss: 0.3489, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1187/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3425\n",
      "LOG: Epoch [1187/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1187/2000], Avg Train Loss: 0.3425, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1188/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3422\n",
      "LOG: Epoch [1188/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1188/2000], Avg Train Loss: 0.3422, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1189/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [1189/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1189/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1190/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [1190/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1190/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1191/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3401\n",
      "LOG: Epoch [1191/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1191/2000], Avg Train Loss: 0.3401, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1192/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [1192/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1192/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [1193/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1193/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1194/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3422\n",
      "LOG: Epoch [1194/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1194/2000], Avg Train Loss: 0.3422, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1195/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1195/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1195/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1196/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3489\n",
      "LOG: Epoch [1196/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1196/2000], Avg Train Loss: 0.3489, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1197/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3403\n",
      "LOG: Epoch [1197/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1197/2000], Avg Train Loss: 0.3403, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1198/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [1198/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1198/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1199/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1199/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1199/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1200/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1200/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1200/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1201/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1201/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1201/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1202/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3421\n",
      "LOG: Epoch [1202/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1202/2000], Avg Train Loss: 0.3421, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1203/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3514\n",
      "LOG: Epoch [1203/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1203/2000], Avg Train Loss: 0.3514, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1204/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1204/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1204/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1205/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3415\n",
      "LOG: Epoch [1205/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1205/2000], Avg Train Loss: 0.3415, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1206/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [1206/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1206/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1207/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [1207/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1207/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1208/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [1208/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1208/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1209/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1209/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1209/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1210/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1210/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1210/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1211/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3460\n",
      "LOG: Epoch [1211/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1211/2000], Avg Train Loss: 0.3460, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1212/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1212/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1212/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1213/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3415\n",
      "LOG: Epoch [1213/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1213/2000], Avg Train Loss: 0.3415, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1214/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3426\n",
      "LOG: Epoch [1214/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1214/2000], Avg Train Loss: 0.3426, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1215/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [1215/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1215/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1216/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1216/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1216/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1217/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3521\n",
      "LOG: Epoch [1217/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1217/2000], Avg Train Loss: 0.3521, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1218/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [1218/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1218/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1219/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3403\n",
      "LOG: Epoch [1219/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1219/2000], Avg Train Loss: 0.3403, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1220/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3460\n",
      "LOG: Epoch [1220/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1220/2000], Avg Train Loss: 0.3460, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1221/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1221/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1221/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1222/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [1222/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1222/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1223/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1223/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1223/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1224/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [1224/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1224/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1225/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3404\n",
      "LOG: Epoch [1225/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1225/2000], Avg Train Loss: 0.3404, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1226/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3378\n",
      "LOG: Epoch [1226/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1226/2000], Avg Train Loss: 0.3378, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1227/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3529\n",
      "LOG: Epoch [1227/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1227/2000], Avg Train Loss: 0.3529, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1228/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [1228/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1228/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1229/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3431\n",
      "LOG: Epoch [1229/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1229/2000], Avg Train Loss: 0.3431, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1230/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3492\n",
      "LOG: Epoch [1230/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1230/2000], Avg Train Loss: 0.3492, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1231/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [1231/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1231/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1232/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1232/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1232/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1233/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3473\n",
      "LOG: Epoch [1233/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1233/2000], Avg Train Loss: 0.3473, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1234/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [1234/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1234/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [1235/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1235/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1236/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1236/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1236/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1237/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [1237/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1237/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1238/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3417\n",
      "LOG: Epoch [1238/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1238/2000], Avg Train Loss: 0.3417, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1239/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3398\n",
      "LOG: Epoch [1239/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1239/2000], Avg Train Loss: 0.3398, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1240/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3483\n",
      "LOG: Epoch [1240/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1240/2000], Avg Train Loss: 0.3483, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1241/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3421\n",
      "LOG: Epoch [1241/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1241/2000], Avg Train Loss: 0.3421, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1242/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3518\n",
      "LOG: Epoch [1242/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1242/2000], Avg Train Loss: 0.3518, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1243/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1243/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1243/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1244/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1244/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1244/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1245/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1245/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1245/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1246/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [1246/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1246/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1247/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [1247/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1247/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1248/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [1248/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1248/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1249/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3460\n",
      "LOG: Epoch [1249/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1249/2000], Avg Train Loss: 0.3460, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1250/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1250/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1250/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1251/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [1251/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1251/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1252/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3412\n",
      "LOG: Epoch [1252/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1252/2000], Avg Train Loss: 0.3412, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1253/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3492\n",
      "LOG: Epoch [1253/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1253/2000], Avg Train Loss: 0.3492, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1254/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [1254/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1254/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1255/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [1255/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1255/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1256/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [1256/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1256/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1257/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1257/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1257/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1258/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [1258/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1258/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1259/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3487\n",
      "LOG: Epoch [1259/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1259/2000], Avg Train Loss: 0.3487, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1260/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [1260/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1260/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1261/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [1261/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1261/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1262/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [1262/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1262/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1263/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1263/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1263/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1264/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1264/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1264/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1265/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3421\n",
      "LOG: Epoch [1265/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1265/2000], Avg Train Loss: 0.3421, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "LOG: Epoch [1266/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3393\n",
      "LOG: Epoch [1266/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1266/2000], Avg Train Loss: 0.3393, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "LOG: Epoch [1267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [1267/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1267/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "LOG: Epoch [1268/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3413\n",
      "LOG: Epoch [1268/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1268/2000], Avg Train Loss: 0.3413, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "LOG: Epoch [1269/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1269/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1269/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "LOG: Epoch [1270/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1270/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1270/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "LOG: Epoch [1271/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3499\n",
      "LOG: Epoch [1271/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1271/2000], Avg Train Loss: 0.3499, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "LOG: Epoch [1272/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [1272/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1272/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "LOG: Epoch [1273/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1273/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1273/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "LOG: Epoch [1274/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [1274/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1274/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "LOG: Epoch [1275/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [1275/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1275/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "LOG: Epoch [1276/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3492\n",
      "LOG: Epoch [1276/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1276/2000], Avg Train Loss: 0.3492, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "LOG: Epoch [1277/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [1277/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1277/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "LOG: Epoch [1278/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [1278/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1278/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "LOG: Epoch [1279/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3491\n",
      "LOG: Epoch [1279/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1279/2000], Avg Train Loss: 0.3491, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "LOG: Epoch [1280/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [1280/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1280/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "LOG: Epoch [1281/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [1281/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1281/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "LOG: Epoch [1282/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3492\n",
      "LOG: Epoch [1282/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1282/2000], Avg Train Loss: 0.3492, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "LOG: Epoch [1283/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [1283/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1283/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "LOG: Epoch [1284/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3493\n",
      "LOG: Epoch [1284/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1284/2000], Avg Train Loss: 0.3493, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "LOG: Epoch [1285/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3405\n",
      "LOG: Epoch [1285/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1285/2000], Avg Train Loss: 0.3405, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "LOG: Epoch [1286/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [1286/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1286/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1287/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [1287/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1287/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1288/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [1288/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1288/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1289/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3410\n",
      "LOG: Epoch [1289/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1289/2000], Avg Train Loss: 0.3410, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1290/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [1290/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1290/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1291/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [1291/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1291/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1292/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3425\n",
      "LOG: Epoch [1292/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1292/2000], Avg Train Loss: 0.3425, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1293/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1293/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1293/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1294/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1294/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1294/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1295/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3489\n",
      "LOG: Epoch [1295/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1295/2000], Avg Train Loss: 0.3489, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1296/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1296/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1296/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1297/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1297/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1297/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1298/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1298/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1298/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1299/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1299/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1299/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1300/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [1300/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1300/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1301/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3404\n",
      "LOG: Epoch [1301/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1301/2000], Avg Train Loss: 0.3404, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1302/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3494\n",
      "LOG: Epoch [1302/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1302/2000], Avg Train Loss: 0.3494, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1303/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3421\n",
      "LOG: Epoch [1303/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1303/2000], Avg Train Loss: 0.3421, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1304/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [1304/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1304/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1305/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [1305/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1305/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1306/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3460\n",
      "LOG: Epoch [1306/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1306/2000], Avg Train Loss: 0.3460, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1307/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [1307/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1307/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1308/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1308/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1308/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1309/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [1309/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1309/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1310/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3407\n",
      "LOG: Epoch [1310/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1310/2000], Avg Train Loss: 0.3407, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1311/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [1311/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1311/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1312/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1312/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1312/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1313/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3507\n",
      "LOG: Epoch [1313/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1313/2000], Avg Train Loss: 0.3507, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1314/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3413\n",
      "LOG: Epoch [1314/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1314/2000], Avg Train Loss: 0.3413, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1315/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1315/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1315/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1316/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3400\n",
      "LOG: Epoch [1316/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1316/2000], Avg Train Loss: 0.3400, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1317/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [1317/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1317/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1318/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [1318/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1318/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1319/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1319/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1319/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1320/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [1320/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1320/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1321/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1321/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1321/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1322/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3460\n",
      "LOG: Epoch [1322/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1322/2000], Avg Train Loss: 0.3460, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1323/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [1323/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1323/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1324/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3401\n",
      "LOG: Epoch [1324/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1324/2000], Avg Train Loss: 0.3401, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1325/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3482\n",
      "LOG: Epoch [1325/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1325/2000], Avg Train Loss: 0.3482, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1326/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [1326/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1326/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1327/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [1327/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1327/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1328/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [1328/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1328/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1329/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3401\n",
      "LOG: Epoch [1329/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1329/2000], Avg Train Loss: 0.3401, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1330/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1330/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1330/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1331/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [1331/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1331/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1332/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1332/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1332/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1333/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [1333/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1333/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1334/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [1334/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1334/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1335/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [1335/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1335/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1336/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3375\n",
      "LOG: Epoch [1336/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1336/2000], Avg Train Loss: 0.3375, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1337/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1337/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1337/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1338/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1338/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1338/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1339/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3491\n",
      "LOG: Epoch [1339/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1339/2000], Avg Train Loss: 0.3491, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1340/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1340/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1340/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1341/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3425\n",
      "LOG: Epoch [1341/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1341/2000], Avg Train Loss: 0.3425, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1342/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3448\n",
      "LOG: Epoch [1342/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1342/2000], Avg Train Loss: 0.3448, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1343/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1343/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1343/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1344/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3421\n",
      "LOG: Epoch [1344/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1344/2000], Avg Train Loss: 0.3421, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1345/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [1345/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1345/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1346/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3431\n",
      "LOG: Epoch [1346/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1346/2000], Avg Train Loss: 0.3431, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1347/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [1347/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1347/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1348/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [1348/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1348/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1349/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1349/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1349/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1350/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [1350/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1350/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1351/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [1351/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1351/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1352/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [1352/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1352/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1353/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [1353/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1353/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1354/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [1354/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1354/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1355/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [1355/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1355/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1356/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1356/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1356/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1357/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3503\n",
      "LOG: Epoch [1357/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1357/2000], Avg Train Loss: 0.3503, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1358/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [1358/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1358/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1359/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1359/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1359/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1360/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3515\n",
      "LOG: Epoch [1360/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1360/2000], Avg Train Loss: 0.3515, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1361/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1361/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1361/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1362/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3425\n",
      "LOG: Epoch [1362/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1362/2000], Avg Train Loss: 0.3425, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1363/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [1363/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1363/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1364/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [1364/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1364/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1365/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [1365/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1365/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1366/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3405\n",
      "LOG: Epoch [1366/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1366/2000], Avg Train Loss: 0.3405, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1367/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [1367/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1367/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1368/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1368/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1368/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1369/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3495\n",
      "LOG: Epoch [1369/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1369/2000], Avg Train Loss: 0.3495, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1370/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [1370/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1370/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1371/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [1371/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1371/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1372/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3473\n",
      "LOG: Epoch [1372/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1372/2000], Avg Train Loss: 0.3473, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1373/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [1373/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1373/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1374/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [1374/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1374/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1375/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1375/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1375/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1376/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3412\n",
      "LOG: Epoch [1376/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1376/2000], Avg Train Loss: 0.3412, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1377/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1377/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1377/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1378/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1378/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1378/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1379/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3409\n",
      "LOG: Epoch [1379/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1379/2000], Avg Train Loss: 0.3409, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1380/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [1380/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1380/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1381/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [1381/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1381/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1382/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3421\n",
      "LOG: Epoch [1382/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1382/2000], Avg Train Loss: 0.3421, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1383/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3405\n",
      "LOG: Epoch [1383/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1383/2000], Avg Train Loss: 0.3405, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1384/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [1384/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1384/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1385/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [1385/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1385/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1386/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1386/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1386/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1387/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3486\n",
      "LOG: Epoch [1387/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1387/2000], Avg Train Loss: 0.3486, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1388/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [1388/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1388/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1389/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3400\n",
      "LOG: Epoch [1389/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1389/2000], Avg Train Loss: 0.3400, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1390/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [1390/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1390/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1391/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [1391/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1391/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1392/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3489\n",
      "LOG: Epoch [1392/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1392/2000], Avg Train Loss: 0.3489, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1393/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [1393/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1393/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1394/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3460\n",
      "LOG: Epoch [1394/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1394/2000], Avg Train Loss: 0.3460, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1395/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3415\n",
      "LOG: Epoch [1395/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1395/2000], Avg Train Loss: 0.3415, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1396/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1396/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1396/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1397/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [1397/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1397/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1398/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1398/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1398/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1399/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3408\n",
      "LOG: Epoch [1399/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1399/2000], Avg Train Loss: 0.3408, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1400/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3497\n",
      "LOG: Epoch [1400/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1400/2000], Avg Train Loss: 0.3497, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1401/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3496\n",
      "LOG: Epoch [1401/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1401/2000], Avg Train Loss: 0.3496, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1402/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1402/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1402/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1403/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1403/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1403/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1404/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3490\n",
      "LOG: Epoch [1404/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1404/2000], Avg Train Loss: 0.3490, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1405/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [1405/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1405/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1406/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [1406/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1406/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1407/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1407/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1407/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1408/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3415\n",
      "LOG: Epoch [1408/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1408/2000], Avg Train Loss: 0.3415, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1409/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1409/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1409/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1410/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [1410/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1410/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1411/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [1411/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1411/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1412/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3496\n",
      "LOG: Epoch [1412/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1412/2000], Avg Train Loss: 0.3496, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1413/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3412\n",
      "LOG: Epoch [1413/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1413/2000], Avg Train Loss: 0.3412, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1414/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [1414/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1414/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1415/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [1415/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1415/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1416/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3522\n",
      "LOG: Epoch [1416/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1416/2000], Avg Train Loss: 0.3522, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1417/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [1417/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1417/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1418/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1418/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1418/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1419/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [1419/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1419/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1420/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3410\n",
      "LOG: Epoch [1420/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1420/2000], Avg Train Loss: 0.3410, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1421/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [1421/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1421/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1422/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3500\n",
      "LOG: Epoch [1422/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1422/2000], Avg Train Loss: 0.3500, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1423/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [1423/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1423/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1424/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3491\n",
      "LOG: Epoch [1424/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1424/2000], Avg Train Loss: 0.3491, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1425/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3413\n",
      "LOG: Epoch [1425/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1425/2000], Avg Train Loss: 0.3413, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1426/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [1426/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1426/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1427/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [1427/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1427/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1428/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1428/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1428/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1429/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [1429/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1429/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1430/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1430/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1430/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1431/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1431/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1431/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1432/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3399\n",
      "LOG: Epoch [1432/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1432/2000], Avg Train Loss: 0.3399, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1433/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1433/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1433/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1434/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3425\n",
      "LOG: Epoch [1434/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1434/2000], Avg Train Loss: 0.3425, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1435/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1435/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1435/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [1436/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1436/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1437/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [1437/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1437/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1438/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1438/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1438/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1439/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3415\n",
      "LOG: Epoch [1439/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1439/2000], Avg Train Loss: 0.3415, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1440/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [1440/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1440/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1441/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1441/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1441/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1442/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [1442/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1442/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1443/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3485\n",
      "LOG: Epoch [1443/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1443/2000], Avg Train Loss: 0.3485, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1444/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1444/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1444/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1445/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3517\n",
      "LOG: Epoch [1445/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1445/2000], Avg Train Loss: 0.3517, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1446/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3499\n",
      "LOG: Epoch [1446/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1446/2000], Avg Train Loss: 0.3499, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1447/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1447/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1447/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1448/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3496\n",
      "LOG: Epoch [1448/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1448/2000], Avg Train Loss: 0.3496, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1449/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [1449/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1449/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1450/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3417\n",
      "LOG: Epoch [1450/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1450/2000], Avg Train Loss: 0.3417, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3460\n",
      "LOG: Epoch [1451/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1451/2000], Avg Train Loss: 0.3460, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1452/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3416\n",
      "LOG: Epoch [1452/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1452/2000], Avg Train Loss: 0.3416, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1453/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1453/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1453/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1454/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3413\n",
      "LOG: Epoch [1454/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1454/2000], Avg Train Loss: 0.3413, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1455/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [1455/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1455/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1456/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [1456/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1456/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1457/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1457/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1457/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1458/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3406\n",
      "LOG: Epoch [1458/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1458/2000], Avg Train Loss: 0.3406, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1459/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [1459/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1459/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1460/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1460/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1460/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1461/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [1461/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1461/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1462/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [1462/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1462/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1463/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [1463/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1463/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1464/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [1464/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1464/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1465/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1465/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1465/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1466/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [1466/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1466/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1467/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [1467/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1467/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1468/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1468/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1468/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1469/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [1469/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1469/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1470/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3403\n",
      "LOG: Epoch [1470/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1470/2000], Avg Train Loss: 0.3403, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1471/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1471/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1471/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1472/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1472/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1472/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1473/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [1473/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1473/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1474/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1474/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1474/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1475/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [1475/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1475/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1476/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1476/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1476/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1477/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1477/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1477/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1478/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1478/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1478/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1479/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [1479/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1479/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1480/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3415\n",
      "LOG: Epoch [1480/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1480/2000], Avg Train Loss: 0.3415, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1481/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [1481/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1481/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1482/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1482/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1482/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1483/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [1483/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1483/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1484/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [1484/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1484/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1485/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [1485/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1485/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1486/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1486/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1486/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1487/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1487/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1487/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1488/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3416\n",
      "LOG: Epoch [1488/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1488/2000], Avg Train Loss: 0.3416, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1489/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1489/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1489/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1490/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [1490/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1490/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1491/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1491/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1491/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1492/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1492/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1492/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1493/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3400\n",
      "LOG: Epoch [1493/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1493/2000], Avg Train Loss: 0.3400, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1494/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [1494/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1494/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1495/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3494\n",
      "LOG: Epoch [1495/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1495/2000], Avg Train Loss: 0.3494, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1496/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [1496/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1496/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1497/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [1497/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1497/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1498/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [1498/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1498/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1499/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1499/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1499/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1500/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [1500/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1500/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1501/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1501/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1501/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1502/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [1502/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1502/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1503/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [1503/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1503/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1504/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1504/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1504/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1505/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [1505/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1505/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1506/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1506/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1506/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1507/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1507/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1507/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1508/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [1508/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1508/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1509/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3530\n",
      "LOG: Epoch [1509/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1509/2000], Avg Train Loss: 0.3530, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1510/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [1510/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1510/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1511/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [1511/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1511/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1512/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [1512/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1512/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1513/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [1513/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1513/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1514/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [1514/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1514/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1515/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [1515/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1515/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1516/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3486\n",
      "LOG: Epoch [1516/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1516/2000], Avg Train Loss: 0.3486, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1517/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1517/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1517/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1518/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [1518/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1518/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1519/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [1519/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1519/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1520/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [1520/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1520/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1521/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [1521/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1521/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1522/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1522/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1522/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1523/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3418\n",
      "LOG: Epoch [1523/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1523/2000], Avg Train Loss: 0.3418, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1524/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1524/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1524/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1525/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [1525/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1525/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1526/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1526/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1526/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1527/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1527/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1527/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1528/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1528/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1528/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1529/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [1529/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1529/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1530/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3500\n",
      "LOG: Epoch [1530/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1530/2000], Avg Train Loss: 0.3500, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1531/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1531/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1531/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1532/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1532/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1532/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1533/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1533/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1533/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1534/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1534/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1534/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1535/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [1535/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1535/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1536/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1536/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1536/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1537/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3384\n",
      "LOG: Epoch [1537/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1537/2000], Avg Train Loss: 0.3384, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1538/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3504\n",
      "LOG: Epoch [1538/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1538/2000], Avg Train Loss: 0.3504, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1539/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [1539/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1539/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1540/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1540/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1540/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1541/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1541/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1541/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1542/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3410\n",
      "LOG: Epoch [1542/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1542/2000], Avg Train Loss: 0.3410, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1543/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [1543/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1543/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1544/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1544/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1544/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1545/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3416\n",
      "LOG: Epoch [1545/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1545/2000], Avg Train Loss: 0.3416, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1546/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1546/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1546/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1547/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3523\n",
      "LOG: Epoch [1547/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1547/2000], Avg Train Loss: 0.3523, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1548/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [1548/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1548/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1549/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1549/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1549/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1550/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [1550/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1550/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1551/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3425\n",
      "LOG: Epoch [1551/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1551/2000], Avg Train Loss: 0.3425, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1552/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [1552/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1552/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1553/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1553/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1553/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1554/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [1554/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1554/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1555/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [1555/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1555/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1556/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3415\n",
      "LOG: Epoch [1556/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1556/2000], Avg Train Loss: 0.3415, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1557/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [1557/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1557/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1558/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3408\n",
      "LOG: Epoch [1558/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1558/2000], Avg Train Loss: 0.3408, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1559/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [1559/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1559/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1560/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [1560/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1560/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1561/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1561/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1561/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1562/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [1562/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1562/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1563/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [1563/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1563/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1564/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1564/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1564/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1565/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [1565/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1565/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1566/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1566/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1566/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1567/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3414\n",
      "LOG: Epoch [1567/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1567/2000], Avg Train Loss: 0.3414, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1568/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3387\n",
      "LOG: Epoch [1568/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1568/2000], Avg Train Loss: 0.3387, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1569/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3398\n",
      "LOG: Epoch [1569/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1569/2000], Avg Train Loss: 0.3398, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1570/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1570/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1570/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1571/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3414\n",
      "LOG: Epoch [1571/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1571/2000], Avg Train Loss: 0.3414, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1572/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1572/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1572/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1573/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1573/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1573/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1574/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [1574/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1574/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1575/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3398\n",
      "LOG: Epoch [1575/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1575/2000], Avg Train Loss: 0.3398, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1576/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3418\n",
      "LOG: Epoch [1576/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1576/2000], Avg Train Loss: 0.3418, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1577/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1577/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1577/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1578/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1578/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1579/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3402\n",
      "LOG: Epoch [1579/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1579/2000], Avg Train Loss: 0.3402, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1580/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1580/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1580/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1581/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [1581/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1581/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1582/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1582/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1582/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1583/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [1583/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1583/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1584/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3448\n",
      "LOG: Epoch [1584/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1584/2000], Avg Train Loss: 0.3448, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1585/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [1585/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1585/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1586/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3493\n",
      "LOG: Epoch [1586/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1586/2000], Avg Train Loss: 0.3493, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1587/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1587/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1587/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1588/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3421\n",
      "LOG: Epoch [1588/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1588/2000], Avg Train Loss: 0.3421, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1589/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1589/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1589/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1590/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1590/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1590/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1591/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3374\n",
      "LOG: Epoch [1591/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1591/2000], Avg Train Loss: 0.3374, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1592/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [1592/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1592/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1593/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3409\n",
      "LOG: Epoch [1593/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1593/2000], Avg Train Loss: 0.3409, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1594/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3417\n",
      "LOG: Epoch [1594/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1594/2000], Avg Train Loss: 0.3417, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1595/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [1595/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1595/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1596/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1596/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1596/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1597/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1597/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1597/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1598/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1598/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1598/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1599/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1599/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1599/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1600/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [1600/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1600/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1601/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [1601/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1601/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1602/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3513\n",
      "LOG: Epoch [1602/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1602/2000], Avg Train Loss: 0.3513, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1603/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3411\n",
      "LOG: Epoch [1603/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1603/2000], Avg Train Loss: 0.3411, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1604/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1604/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1604/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1605/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [1605/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1605/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1606/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3510\n",
      "LOG: Epoch [1606/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1606/2000], Avg Train Loss: 0.3510, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1607/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3402\n",
      "LOG: Epoch [1607/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1607/2000], Avg Train Loss: 0.3402, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1608/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3421\n",
      "LOG: Epoch [1608/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1608/2000], Avg Train Loss: 0.3421, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1609/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1609/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1609/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1610/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1610/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1610/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1611/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [1611/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1611/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1612/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [1612/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1612/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1613/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [1613/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1613/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [1614/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1614/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1615/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [1615/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1615/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1616/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1616/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1617/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [1617/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1617/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1618/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3368\n",
      "LOG: Epoch [1618/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1618/2000], Avg Train Loss: 0.3368, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1619/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3511\n",
      "LOG: Epoch [1619/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1619/2000], Avg Train Loss: 0.3511, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1620/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [1620/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1620/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1621/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1621/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1621/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1622/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1622/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1622/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1623/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1623/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1623/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1624/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [1624/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1624/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1625/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3473\n",
      "LOG: Epoch [1625/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1625/2000], Avg Train Loss: 0.3473, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1626/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1626/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1626/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1627/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3407\n",
      "LOG: Epoch [1627/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1627/2000], Avg Train Loss: 0.3407, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1628/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [1628/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1628/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1629/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [1629/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1629/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1630/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [1630/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1630/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1631/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [1631/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1631/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1632/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [1632/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1632/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1633/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1633/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1633/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1634/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [1634/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1634/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1635/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [1635/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1635/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1636/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3491\n",
      "LOG: Epoch [1636/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1636/2000], Avg Train Loss: 0.3491, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1637/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1637/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1637/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1638/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3473\n",
      "LOG: Epoch [1638/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1638/2000], Avg Train Loss: 0.3473, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1639/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3431\n",
      "LOG: Epoch [1639/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1639/2000], Avg Train Loss: 0.3431, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1640/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [1640/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1640/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1641/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [1641/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1641/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1642/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1642/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1642/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1643/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1643/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1643/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1644/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [1644/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1644/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1645/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3483\n",
      "LOG: Epoch [1645/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1645/2000], Avg Train Loss: 0.3483, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1646/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1646/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1646/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1647/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3493\n",
      "LOG: Epoch [1647/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1647/2000], Avg Train Loss: 0.3493, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1648/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3518\n",
      "LOG: Epoch [1648/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1648/2000], Avg Train Loss: 0.3518, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1649/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1649/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1649/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1650/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3482\n",
      "LOG: Epoch [1650/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1650/2000], Avg Train Loss: 0.3482, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1651/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3483\n",
      "LOG: Epoch [1651/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1651/2000], Avg Train Loss: 0.3483, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1652/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3387\n",
      "LOG: Epoch [1652/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1652/2000], Avg Train Loss: 0.3387, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1653/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1653/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1653/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1654/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1654/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1654/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1655/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3418\n",
      "LOG: Epoch [1655/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1655/2000], Avg Train Loss: 0.3418, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1656/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1656/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1656/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1657/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1657/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1657/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1658/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1658/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1658/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1659/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [1659/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1659/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1660/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1660/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1660/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1661/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [1661/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1661/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1662/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3405\n",
      "LOG: Epoch [1662/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1662/2000], Avg Train Loss: 0.3405, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1663/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [1663/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1663/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1664/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [1664/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1664/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1665/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1665/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1665/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1666/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [1666/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1666/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1667/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1667/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1667/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1668/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1668/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1668/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1669/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3500\n",
      "LOG: Epoch [1669/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1669/2000], Avg Train Loss: 0.3500, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1670/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1670/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1670/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1671/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [1671/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1671/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1672/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1672/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1672/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1673/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [1673/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1673/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1674/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3482\n",
      "LOG: Epoch [1674/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1674/2000], Avg Train Loss: 0.3482, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1675/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [1675/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1675/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1676/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1676/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1676/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1677/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3403\n",
      "LOG: Epoch [1677/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1677/2000], Avg Train Loss: 0.3403, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1678/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [1678/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1678/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1679/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3400\n",
      "LOG: Epoch [1679/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1679/2000], Avg Train Loss: 0.3400, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1680/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1680/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1680/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1681/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3510\n",
      "LOG: Epoch [1681/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1681/2000], Avg Train Loss: 0.3510, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1682/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [1682/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1682/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1683/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [1683/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1683/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1684/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1684/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1684/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1685/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1685/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1685/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1686/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1686/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1686/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1687/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [1687/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1687/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1688/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3407\n",
      "LOG: Epoch [1688/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1688/2000], Avg Train Loss: 0.3407, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1689/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3487\n",
      "LOG: Epoch [1689/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1689/2000], Avg Train Loss: 0.3487, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1690/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1690/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1690/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1691/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1691/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1691/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1692/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [1692/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1692/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1693/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [1693/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1693/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1694/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [1694/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1694/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1695/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3391\n",
      "LOG: Epoch [1695/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1695/2000], Avg Train Loss: 0.3391, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1696/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1696/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1696/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1697/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [1697/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1697/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1698/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3491\n",
      "LOG: Epoch [1698/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1698/2000], Avg Train Loss: 0.3491, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1699/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1699/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1699/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1700/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1700/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1700/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1701/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [1701/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1701/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1702/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1702/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1702/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1703/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3460\n",
      "LOG: Epoch [1703/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1703/2000], Avg Train Loss: 0.3460, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1704/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [1704/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1704/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1705/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3421\n",
      "LOG: Epoch [1705/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1705/2000], Avg Train Loss: 0.3421, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1706/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [1706/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1706/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1707/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [1707/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1707/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1708/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1708/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1708/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1709/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1709/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1709/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1710/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1710/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1710/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1711/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1711/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1711/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1712/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3482\n",
      "LOG: Epoch [1712/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1712/2000], Avg Train Loss: 0.3482, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1713/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3414\n",
      "LOG: Epoch [1713/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1713/2000], Avg Train Loss: 0.3414, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1714/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3473\n",
      "LOG: Epoch [1714/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1714/2000], Avg Train Loss: 0.3473, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1715/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [1715/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1715/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1716/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3498\n",
      "LOG: Epoch [1716/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1716/2000], Avg Train Loss: 0.3498, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1717/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3448\n",
      "LOG: Epoch [1717/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1717/2000], Avg Train Loss: 0.3448, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1718/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1718/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1718/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1719/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3506\n",
      "LOG: Epoch [1719/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1719/2000], Avg Train Loss: 0.3506, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1720/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [1720/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1720/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1721/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1721/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1721/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1722/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3500\n",
      "LOG: Epoch [1722/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1722/2000], Avg Train Loss: 0.3500, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1723/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1723/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1723/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1724/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3410\n",
      "LOG: Epoch [1724/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1724/2000], Avg Train Loss: 0.3410, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1725/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1725/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1725/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1726/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3523\n",
      "LOG: Epoch [1726/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1726/2000], Avg Train Loss: 0.3523, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1727/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1727/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1727/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1728/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1728/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1728/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1729/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1729/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1729/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1730/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [1730/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1730/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1731/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3409\n",
      "LOG: Epoch [1731/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1731/2000], Avg Train Loss: 0.3409, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1732/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [1732/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1732/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1733/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1733/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1733/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1734/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1734/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1734/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1735/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3368\n",
      "LOG: Epoch [1735/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1735/2000], Avg Train Loss: 0.3368, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1736/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1736/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1736/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1737/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [1737/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1737/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1738/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1738/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1738/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1739/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1739/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1739/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1740/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [1740/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1740/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1741/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1741/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1741/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1742/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1742/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1742/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1743/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [1743/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1743/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1744/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3404\n",
      "LOG: Epoch [1744/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1744/2000], Avg Train Loss: 0.3404, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1745/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [1745/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1745/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1746/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3473\n",
      "LOG: Epoch [1746/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1746/2000], Avg Train Loss: 0.3473, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1747/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1747/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1747/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1748/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [1748/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1748/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1749/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3493\n",
      "LOG: Epoch [1749/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1749/2000], Avg Train Loss: 0.3493, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1750/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [1750/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1750/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1751/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1751/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1751/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1752/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1752/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1752/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1753/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [1753/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1753/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1754/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3483\n",
      "LOG: Epoch [1754/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1754/2000], Avg Train Loss: 0.3483, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1755/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [1755/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1755/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1756/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [1756/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1756/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1757/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [1757/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1757/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1758/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3500\n",
      "LOG: Epoch [1758/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1758/2000], Avg Train Loss: 0.3500, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1759/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3416\n",
      "LOG: Epoch [1759/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1759/2000], Avg Train Loss: 0.3416, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1760/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1760/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1760/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1761/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1761/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1761/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1762/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3419\n",
      "LOG: Epoch [1762/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1762/2000], Avg Train Loss: 0.3419, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1763/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1763/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1763/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1764/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1764/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1764/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1765/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [1765/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1765/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1766/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1766/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1766/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1767/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [1767/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1767/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1768/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [1768/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1768/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1769/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1769/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1769/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1770/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1770/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1770/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1771/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [1771/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1771/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1772/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [1772/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1772/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1773/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1773/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1773/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1774/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [1774/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1774/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1775/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [1775/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1775/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1776/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3399\n",
      "LOG: Epoch [1776/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1776/2000], Avg Train Loss: 0.3399, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1777/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1777/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1777/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1778/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1778/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1778/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1779/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [1779/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1779/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1780/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3486\n",
      "LOG: Epoch [1780/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1780/2000], Avg Train Loss: 0.3486, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1781/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [1781/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1781/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1782/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1782/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1782/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1783/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1783/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1783/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1784/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1784/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1784/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1785/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [1785/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1785/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1786/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1786/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1786/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1787/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1787/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1787/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1788/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1788/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1788/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1789/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3492\n",
      "LOG: Epoch [1789/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1789/2000], Avg Train Loss: 0.3492, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1790/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3486\n",
      "LOG: Epoch [1790/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1790/2000], Avg Train Loss: 0.3486, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1791/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1791/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1791/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1792/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3452\n",
      "LOG: Epoch [1792/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1792/2000], Avg Train Loss: 0.3452, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1793/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1793/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1793/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1794/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [1794/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1794/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1795/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [1795/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1795/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1796/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1796/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1796/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1797/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3418\n",
      "LOG: Epoch [1797/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1797/2000], Avg Train Loss: 0.3418, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1798/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3413\n",
      "LOG: Epoch [1798/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1798/2000], Avg Train Loss: 0.3413, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1799/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1799/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1799/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1800/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [1800/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1800/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1801/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [1801/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1801/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1802/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3468\n",
      "LOG: Epoch [1802/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1802/2000], Avg Train Loss: 0.3468, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1803/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [1803/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1803/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1804/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [1804/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1804/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1805/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3487\n",
      "LOG: Epoch [1805/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1805/2000], Avg Train Loss: 0.3487, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1806/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3416\n",
      "LOG: Epoch [1806/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1806/2000], Avg Train Loss: 0.3416, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1807/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1807/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1807/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1808/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3497\n",
      "LOG: Epoch [1808/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1808/2000], Avg Train Loss: 0.3497, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1809/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3477\n",
      "LOG: Epoch [1809/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1809/2000], Avg Train Loss: 0.3477, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1810/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3448\n",
      "LOG: Epoch [1810/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1810/2000], Avg Train Loss: 0.3448, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1811/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1811/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1811/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1812/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3492\n",
      "LOG: Epoch [1812/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1812/2000], Avg Train Loss: 0.3492, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1813/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1813/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1813/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1814/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3443\n",
      "LOG: Epoch [1814/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1814/2000], Avg Train Loss: 0.3443, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1815/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3542\n",
      "LOG: Epoch [1815/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1815/2000], Avg Train Loss: 0.3542, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1816/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1816/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1816/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1817/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3394\n",
      "LOG: Epoch [1817/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1817/2000], Avg Train Loss: 0.3394, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1818/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1818/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1818/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1819/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [1819/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1819/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1820/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1820/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1820/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1821/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [1821/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1821/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1822/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [1822/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1822/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1823/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3418\n",
      "LOG: Epoch [1823/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1823/2000], Avg Train Loss: 0.3418, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1824/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1824/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1824/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1825/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3408\n",
      "LOG: Epoch [1825/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1825/2000], Avg Train Loss: 0.3408, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1826/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3473\n",
      "LOG: Epoch [1826/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1826/2000], Avg Train Loss: 0.3473, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1827/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3482\n",
      "LOG: Epoch [1827/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1827/2000], Avg Train Loss: 0.3482, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1828/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3446\n",
      "LOG: Epoch [1828/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1828/2000], Avg Train Loss: 0.3446, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1829/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3457\n",
      "LOG: Epoch [1829/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1829/2000], Avg Train Loss: 0.3457, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1830/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [1830/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1830/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1831/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1831/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1831/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1832/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1832/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1832/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1833/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3385\n",
      "LOG: Epoch [1833/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1833/2000], Avg Train Loss: 0.3385, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1834/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3402\n",
      "LOG: Epoch [1834/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1834/2000], Avg Train Loss: 0.3402, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1835/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [1835/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1835/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1836/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [1836/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1836/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1837/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3406\n",
      "LOG: Epoch [1837/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1837/2000], Avg Train Loss: 0.3406, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1838/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3431\n",
      "LOG: Epoch [1838/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1838/2000], Avg Train Loss: 0.3431, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1839/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3480\n",
      "LOG: Epoch [1839/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1839/2000], Avg Train Loss: 0.3480, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1840/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [1840/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1840/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1841/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [1841/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1841/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1842/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3521\n",
      "LOG: Epoch [1842/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1842/2000], Avg Train Loss: 0.3521, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1843/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3476\n",
      "LOG: Epoch [1843/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1843/2000], Avg Train Loss: 0.3476, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1844/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1844/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1844/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1845/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [1845/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1845/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1846/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [1846/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1846/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1847/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1847/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1847/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1848/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [1848/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1848/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1849/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3475\n",
      "LOG: Epoch [1849/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1849/2000], Avg Train Loss: 0.3475, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1850/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3418\n",
      "LOG: Epoch [1850/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1850/2000], Avg Train Loss: 0.3418, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1851/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3514\n",
      "LOG: Epoch [1851/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1851/2000], Avg Train Loss: 0.3514, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1852/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [1852/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1852/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1853/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1853/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1853/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1854/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [1854/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1854/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1855/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3442\n",
      "LOG: Epoch [1855/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1855/2000], Avg Train Loss: 0.3442, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1856/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [1856/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1856/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1857/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3447\n",
      "LOG: Epoch [1857/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1857/2000], Avg Train Loss: 0.3447, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1858/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1858/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1858/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1859/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [1859/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1859/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1860/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3449\n",
      "LOG: Epoch [1860/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1860/2000], Avg Train Loss: 0.3449, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1861/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1861/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1861/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1862/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1862/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1862/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1863/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3486\n",
      "LOG: Epoch [1863/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1863/2000], Avg Train Loss: 0.3486, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1864/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [1864/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1864/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1865/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1865/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1865/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1866/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3426\n",
      "LOG: Epoch [1866/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1866/2000], Avg Train Loss: 0.3426, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1867/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3431\n",
      "LOG: Epoch [1867/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1867/2000], Avg Train Loss: 0.3431, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1868/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1868/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1868/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1869/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [1869/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1869/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1870/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [1870/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1870/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1871/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3397\n",
      "LOG: Epoch [1871/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1871/2000], Avg Train Loss: 0.3397, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1872/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [1872/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1872/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1873/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [1873/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1873/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1874/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1874/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1874/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1875/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1875/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1875/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1876/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1876/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1876/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1877/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1877/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1877/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1878/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1878/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1878/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1879/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1879/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1879/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1880/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1880/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1880/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1881/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [1881/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1881/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1882/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [1882/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1882/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1883/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3428\n",
      "LOG: Epoch [1883/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1883/2000], Avg Train Loss: 0.3428, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1884/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1884/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1884/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1885/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3502\n",
      "LOG: Epoch [1885/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1885/2000], Avg Train Loss: 0.3502, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1886/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1886/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1886/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1887/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1887/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1887/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1888/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1888/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1888/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1889/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1889/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1889/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1890/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3438\n",
      "LOG: Epoch [1890/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1890/2000], Avg Train Loss: 0.3438, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1891/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1891/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1891/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1892/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1892/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1892/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1893/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3471\n",
      "LOG: Epoch [1893/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1893/2000], Avg Train Loss: 0.3471, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1894/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [1894/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1894/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1895/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3478\n",
      "LOG: Epoch [1895/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1895/2000], Avg Train Loss: 0.3478, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1896/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3463\n",
      "LOG: Epoch [1896/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1896/2000], Avg Train Loss: 0.3463, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1897/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3412\n",
      "LOG: Epoch [1897/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1897/2000], Avg Train Loss: 0.3412, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1898/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3432\n",
      "LOG: Epoch [1898/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1898/2000], Avg Train Loss: 0.3432, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1899/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3483\n",
      "LOG: Epoch [1899/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1899/2000], Avg Train Loss: 0.3483, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1900/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1900/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1900/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1901/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [1901/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1901/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1902/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3431\n",
      "LOG: Epoch [1902/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1902/2000], Avg Train Loss: 0.3431, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1903/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1903/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1903/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1904/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1904/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1904/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1905/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3393\n",
      "LOG: Epoch [1905/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1905/2000], Avg Train Loss: 0.3393, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1906/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1906/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1906/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1907/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [1907/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1907/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1908/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1908/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1908/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1909/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [1909/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1909/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1910/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1910/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1910/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1911/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1911/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1911/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1912/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3474\n",
      "LOG: Epoch [1912/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1912/2000], Avg Train Loss: 0.3474, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1913/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1913/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1913/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1914/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1914/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1914/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1915/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3453\n",
      "LOG: Epoch [1915/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1915/2000], Avg Train Loss: 0.3453, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1916/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3472\n",
      "LOG: Epoch [1916/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1916/2000], Avg Train Loss: 0.3472, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1917/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1917/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1917/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1918/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3429\n",
      "LOG: Epoch [1918/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1918/2000], Avg Train Loss: 0.3429, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1919/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3487\n",
      "LOG: Epoch [1919/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1919/2000], Avg Train Loss: 0.3487, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1920/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3435\n",
      "LOG: Epoch [1920/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1920/2000], Avg Train Loss: 0.3435, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1921/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3426\n",
      "LOG: Epoch [1921/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1921/2000], Avg Train Loss: 0.3426, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1922/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1922/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1922/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1923/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [1923/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1923/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1924/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3411\n",
      "LOG: Epoch [1924/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1924/2000], Avg Train Loss: 0.3411, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1925/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3393\n",
      "LOG: Epoch [1925/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1925/2000], Avg Train Loss: 0.3393, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1926/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [1926/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1926/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1927/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1927/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1927/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1928/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3527\n",
      "LOG: Epoch [1928/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1928/2000], Avg Train Loss: 0.3527, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1929/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3441\n",
      "LOG: Epoch [1929/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1929/2000], Avg Train Loss: 0.3441, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1930/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1930/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1930/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1931/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3496\n",
      "LOG: Epoch [1931/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1931/2000], Avg Train Loss: 0.3496, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1932/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3448\n",
      "LOG: Epoch [1932/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1932/2000], Avg Train Loss: 0.3448, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1933/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3419\n",
      "LOG: Epoch [1933/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1933/2000], Avg Train Loss: 0.3419, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1934/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3470\n",
      "LOG: Epoch [1934/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1934/2000], Avg Train Loss: 0.3470, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1935/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3420\n",
      "LOG: Epoch [1935/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1935/2000], Avg Train Loss: 0.3420, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1936/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1936/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1936/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1937/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3454\n",
      "LOG: Epoch [1937/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1937/2000], Avg Train Loss: 0.3454, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1938/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1938/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1938/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1939/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [1939/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1939/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1940/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1940/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1940/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1941/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3439\n",
      "LOG: Epoch [1941/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1941/2000], Avg Train Loss: 0.3439, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1942/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1942/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1942/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1943/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3434\n",
      "LOG: Epoch [1943/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1943/2000], Avg Train Loss: 0.3434, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1944/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1944/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1944/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1945/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3465\n",
      "LOG: Epoch [1945/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1945/2000], Avg Train Loss: 0.3465, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1946/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3374\n",
      "LOG: Epoch [1946/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1946/2000], Avg Train Loss: 0.3374, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1947/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [1947/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1947/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1948/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3466\n",
      "LOG: Epoch [1948/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1948/2000], Avg Train Loss: 0.3466, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1949/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3491\n",
      "LOG: Epoch [1949/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1949/2000], Avg Train Loss: 0.3491, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1950/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1950/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1950/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1951/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1951/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1951/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1952/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3502\n",
      "LOG: Epoch [1952/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1952/2000], Avg Train Loss: 0.3502, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1953/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1953/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1953/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1954/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3424\n",
      "LOG: Epoch [1954/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1954/2000], Avg Train Loss: 0.3424, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1955/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1955/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1955/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1956/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3501\n",
      "LOG: Epoch [1956/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1956/2000], Avg Train Loss: 0.3501, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1957/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3385\n",
      "LOG: Epoch [1957/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1957/2000], Avg Train Loss: 0.3385, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1958/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1958/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1958/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1959/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3451\n",
      "LOG: Epoch [1959/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1959/2000], Avg Train Loss: 0.3451, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1960/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1960/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1960/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1961/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3436\n",
      "LOG: Epoch [1961/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1961/2000], Avg Train Loss: 0.3436, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1962/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3483\n",
      "LOG: Epoch [1962/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1962/2000], Avg Train Loss: 0.3483, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1963/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3433\n",
      "LOG: Epoch [1963/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1963/2000], Avg Train Loss: 0.3433, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1964/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3461\n",
      "LOG: Epoch [1964/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1964/2000], Avg Train Loss: 0.3461, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1965/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3458\n",
      "LOG: Epoch [1965/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1965/2000], Avg Train Loss: 0.3458, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1966/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3426\n",
      "LOG: Epoch [1966/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1966/2000], Avg Train Loss: 0.3426, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1967/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3462\n",
      "LOG: Epoch [1967/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1967/2000], Avg Train Loss: 0.3462, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1968/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3419\n",
      "LOG: Epoch [1968/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1968/2000], Avg Train Loss: 0.3419, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1969/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [1969/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1969/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1970/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3464\n",
      "LOG: Epoch [1970/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1970/2000], Avg Train Loss: 0.3464, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1971/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3448\n",
      "LOG: Epoch [1971/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1971/2000], Avg Train Loss: 0.3448, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1972/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3493\n",
      "LOG: Epoch [1972/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1972/2000], Avg Train Loss: 0.3493, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1973/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3489\n",
      "LOG: Epoch [1973/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1973/2000], Avg Train Loss: 0.3489, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1974/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3415\n",
      "LOG: Epoch [1974/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1974/2000], Avg Train Loss: 0.3415, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1975/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3484\n",
      "LOG: Epoch [1975/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1975/2000], Avg Train Loss: 0.3484, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1976/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3481\n",
      "LOG: Epoch [1976/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1976/2000], Avg Train Loss: 0.3481, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1977/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3409\n",
      "LOG: Epoch [1977/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1977/2000], Avg Train Loss: 0.3409, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1978/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3479\n",
      "LOG: Epoch [1978/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1978/2000], Avg Train Loss: 0.3479, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1979/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3487\n",
      "LOG: Epoch [1979/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1979/2000], Avg Train Loss: 0.3487, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1980/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3440\n",
      "LOG: Epoch [1980/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1980/2000], Avg Train Loss: 0.3440, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1981/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [1981/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1981/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1982/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3497\n",
      "LOG: Epoch [1982/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1982/2000], Avg Train Loss: 0.3497, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1983/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3386\n",
      "LOG: Epoch [1983/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1983/2000], Avg Train Loss: 0.3386, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1984/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3423\n",
      "LOG: Epoch [1984/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1984/2000], Avg Train Loss: 0.3423, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1985/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3450\n",
      "LOG: Epoch [1985/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1985/2000], Avg Train Loss: 0.3450, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1986/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3469\n",
      "LOG: Epoch [1986/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1986/2000], Avg Train Loss: 0.3469, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1987/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3425\n",
      "LOG: Epoch [1987/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1987/2000], Avg Train Loss: 0.3425, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1988/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3459\n",
      "LOG: Epoch [1988/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1988/2000], Avg Train Loss: 0.3459, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1989/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3488\n",
      "LOG: Epoch [1989/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1989/2000], Avg Train Loss: 0.3488, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1990/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3467\n",
      "LOG: Epoch [1990/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1990/2000], Avg Train Loss: 0.3467, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1991/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3407\n",
      "LOG: Epoch [1991/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1991/2000], Avg Train Loss: 0.3407, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1992/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3418\n",
      "LOG: Epoch [1992/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1992/2000], Avg Train Loss: 0.3418, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1993/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3456\n",
      "LOG: Epoch [1993/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1993/2000], Avg Train Loss: 0.3456, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1994/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3455\n",
      "LOG: Epoch [1994/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1994/2000], Avg Train Loss: 0.3455, Avg Val Loss: 0.2202\n",
      "\n",
      "Validation loss improved from 0.2202 to 0.2202. Saving model...\n",
      "LOG: Epoch [1995/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3427\n",
      "LOG: Epoch [1995/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1995/2000], Avg Train Loss: 0.3427, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1996/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3437\n",
      "LOG: Epoch [1996/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1996/2000], Avg Train Loss: 0.3437, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1997/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3445\n",
      "LOG: Epoch [1997/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1997/2000], Avg Train Loss: 0.3445, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1998/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3430\n",
      "LOG: Epoch [1998/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1998/2000], Avg Train Loss: 0.3430, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1999/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3444\n",
      "LOG: Epoch [1999/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [1999/2000], Avg Train Loss: 0.3444, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [2000/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3409\n",
      "LOG: Epoch [2000/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.3602\n",
      "    Batch [2/2], Val Loss: 0.0802\n",
      "Epoch [2000/2000], Avg Train Loss: 0.3409, Avg Val Loss: 0.2202\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_model = SupConNet().to(device)\n",
    "sclsdl_criterion = SilhouetteDistanceLoss()\n",
    "sclsdl_optimizer = optim.AdamW(sclsdl_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "sclsdl_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    sclsdl_optimizer, \n",
    "    mode='min',\n",
    "    patience=25,\n",
    "    factor=0.1\n",
    ")\n",
    "\n",
    "sclsdl_num_epochs = 2000\n",
    "\n",
    "sclsdl_patience = 100\n",
    "sclsdl_best_val_loss = float('inf')\n",
    "sclsdl_epochs_without_improvement = 0\n",
    "\n",
    "sclsdl_train_loss_history = []\n",
    "sclsdl_val_loss_history = []\n",
    "\n",
    "for sclsdl_epoch in range(sclsdl_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_model.train()\n",
    "    sclsdl_running_train_loss = 0.0\n",
    "    \n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Training\")\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_train_loader):\n",
    "\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_train_projections = sclsdl_model(vectors)\n",
    "\n",
    "        sclsdl_loss = sclsdl_criterion(sclsdl_train_projections, labels)\n",
    "\n",
    "        # Backprop and optimize\n",
    "        sclsdl_optimizer.zero_grad()\n",
    "        sclsdl_loss.backward()\n",
    "        sclsdl_optimizer.step()\n",
    "\n",
    "        sclsdl_running_train_loss += sclsdl_loss.item()\n",
    "        print(f\"    Batch [{batch_idx+1}/{len(sclsdl_train_loader)}], Train Loss: {sclsdl_loss.item():.4f}\")\n",
    "\n",
    "    sclsdl_train_epoch_loss = sclsdl_running_train_loss / len(sclsdl_train_loader)\n",
    "    sclsdl_train_loss_history.append(sclsdl_train_epoch_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_model.eval()\n",
    "    sclsdl_running_val_loss = 0.0\n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Validation\")\n",
    "    with torch.no_grad():\n",
    "        for val_batch_idx, (vectors, labels) in enumerate(sclsdl_val_loader):\n",
    "\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            sclsdl_val_projections = sclsdl_model(vectors)\n",
    "            sclsdl_val_batch_loss = sclsdl_criterion(sclsdl_val_projections, labels).item()\n",
    "            sclsdl_running_val_loss += sclsdl_val_batch_loss\n",
    "            print(f\"    Batch [{val_batch_idx+1}/{len(sclsdl_val_loader)}], Val Loss: {sclsdl_val_batch_loss:.4f}\")\n",
    "\n",
    "    sclsdl_val_epoch_loss = sclsdl_running_val_loss / len(sclsdl_val_loader)\n",
    "    sclsdl_val_loss_history.append(sclsdl_val_epoch_loss)\n",
    "    \n",
    "    sclsdl_scheduler.step(sclsdl_val_epoch_loss)\n",
    "\n",
    "    print(f\"Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {sclsdl_train_epoch_loss:.4f}, \"\n",
    "          f\"Avg Val Loss: {sclsdl_val_epoch_loss:.4f}\\n\")\n",
    "    \n",
    "    #early stopping logic\n",
    "    if sclsdl_val_epoch_loss < sclsdl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_best_val_loss:.4f} to {sclsdl_val_epoch_loss:.4f}. Saving model...\")\n",
    "        sclsdl_best_val_loss = sclsdl_val_epoch_loss\n",
    "        sclsdl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        sclsdl_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! Patience: {sclsdl_epochs_without_improvement}/{sclsdl_patience}\")\n",
    "\n",
    "    #stop training if val loss not improving\n",
    "    if sclsdl_epochs_without_improvement >= sclsdl_patience:\n",
    "        print(f\"!! Early stopping triggered at epoch {sclsdl_epoch + 1}!!\\nNo improvement for {sclsdl_patience} epochs\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Silhouette Distance Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:16:59.106962Z",
     "iopub.status.busy": "2025-05-08T19:16:59.106962Z",
     "iopub.status.idle": "2025-05-08T19:16:59.353177Z",
     "shell.execute_reply": "2025-05-08T19:16:59.353177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/46], Loss: 0.1832\n",
      "Test Batch [20/46], Loss: 0.2159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [30/46], Loss: 0.2961\n",
      "Test Batch [40/46], Loss: 0.2399\n",
      "\n",
      "Test Loss: 0.2394\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "sclsdl_model.eval()\n",
    "sclsdl_total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = sclsdl_model(vectors)\n",
    "        loss = sclsdl_criterion(projections, labels)\n",
    "        sclsdl_total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(sclsdl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "sclsdl_avg_test_loss = sclsdl_total_test_loss / len(sclsdl_test_loader)\n",
    "print(f\"\\nTest Loss: {sclsdl_avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=sclsdl_avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the representations learnt by SCL w/ SDL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:16:59.355184Z",
     "iopub.status.busy": "2025-05-08T19:16:59.355184Z",
     "iopub.status.idle": "2025-05-08T19:16:59.767974Z",
     "shell.execute_reply": "2025-05-08T19:16:59.767974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL_SDL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'sclsdl_representations\\train'.\n",
      "\n",
      "Extracting SCL_SDL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'sclsdl_representations\\val'.\n",
      "\n",
      "Extracting SCL_SDL representations for the test dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 10/46 for test dataset.\n",
      "  Processed batch 20/46 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 30/46 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 40/46 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'sclsdl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "sclsdl_rep_dir = \"sclsdl_representations\"\n",
    "os.makedirs(sclsdl_rep_dir, exist_ok=True)\n",
    "\n",
    "sclsdl_loaders = {\n",
    "    'train': sclsdl_train_loader,\n",
    "    'val': sclsdl_val_loader,\n",
    "    'test': sclsdl_test_loader\n",
    "}\n",
    "\n",
    "sclsdl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_split_name, sclsdl_loader in sclsdl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL_SDL representations for the {sclsdl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        sclsdl_split_dir = os.path.join(sclsdl_rep_dir, sclsdl_split_name)\n",
    "        os.makedirs(sclsdl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for sclsdl_batch_idx, (sclsdl_vectors, sclsdl_labels) in enumerate(sclsdl_loader):\n",
    "            sclsdl_vectors = sclsdl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            sclsdl_projections = sclsdl_model(sclsdl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            sclsdl_projections_np = sclsdl_projections.cpu().numpy()\n",
    "            sclsdl_labels_np = sclsdl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_encoded_batch_{sclsdl_batch_idx}.npy\"), sclsdl_projections_np)\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_labels_batch_{sclsdl_batch_idx}.npy\"), sclsdl_labels_np)\n",
    "            \n",
    "            if (sclsdl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {sclsdl_batch_idx + 1}/{len(sclsdl_loader)} for {sclsdl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {sclsdl_split_name} dataset. Representations saved in '{sclsdl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by SCL w/ SDL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:16:59.769979Z",
     "iopub.status.busy": "2025-05-08T19:16:59.769979Z",
     "iopub.status.idle": "2025-05-08T19:16:59.774361Z",
     "shell.execute_reply": "2025-05-08T19:16:59.774361Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_sclsdl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    sclsdl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    sclsdl_all_reps = []\n",
    "    sclsdl_all_labels = []\n",
    "\n",
    "    for sclsdl_rep_file in sclsdl_rep_files:\n",
    "        #deriving label filenames\n",
    "        sclsdl_label_file = sclsdl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        sclsdl_reps = np.load(sclsdl_rep_file)\n",
    "        sclsdl_labels = np.load(sclsdl_label_file)\n",
    "\n",
    "        sclsdl_all_reps.append(sclsdl_reps)\n",
    "        sclsdl_all_labels.append(sclsdl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    sclsdl_all_reps = np.concatenate(sclsdl_all_reps, axis = 0)\n",
    "    sclsdl_all_labels = np.concatenate(sclsdl_all_labels, axis = 0)\n",
    "\n",
    "    return sclsdl_all_reps, sclsdl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:16:59.778367Z",
     "iopub.status.busy": "2025-05-08T19:16:59.777367Z",
     "iopub.status.idle": "2025-05-08T19:17:00.253653Z",
     "shell.execute_reply": "2025-05-08T19:17:00.253653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (280, 128)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 128)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_lrm_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_lrm_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_lrm_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_lrm_train_reps, sclsdl_lrm_train_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_train_dir)\n",
    "sclsdl_lrm_val_reps, sclsdl_lrm_val_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_val_dir)\n",
    "sclsdl_lrm_test_reps, sclsdl_lrm_test_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:00.256087Z",
     "iopub.status.busy": "2025-05-08T19:17:00.256087Z",
     "iopub.status.idle": "2025-05-08T19:17:00.306114Z",
     "shell.execute_reply": "2025-05-08T19:17:00.306114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 84.29%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       0.67      0.80      0.73         5\n",
      "           2       1.00      0.80      0.89         5\n",
      "           3       0.83      1.00      0.91         5\n",
      "           4       1.00      0.60      0.75         5\n",
      "           5       0.50      0.40      0.44         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.80      0.80      0.80         5\n",
      "           8       0.60      0.60      0.60         5\n",
      "           9       0.80      0.80      0.80         5\n",
      "          10       0.83      1.00      0.91         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       0.83      1.00      0.91         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.84        70\n",
      "   macro avg       0.85      0.84      0.84        70\n",
      "weighted avg       0.85      0.84      0.84        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 88.72%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       245\n",
      "           1       0.76      0.92      0.83        76\n",
      "           2       0.95      0.97      0.96       226\n",
      "           3       0.86      0.96      0.91       190\n",
      "           4       0.92      0.78      0.85       244\n",
      "           5       0.67      0.68      0.68       244\n",
      "           6       1.00      1.00      1.00       234\n",
      "           7       0.82      0.99      0.90       178\n",
      "           8       0.78      0.75      0.77       289\n",
      "           9       0.88      0.88      0.88       223\n",
      "          10       0.95      0.88      0.91       280\n",
      "          11       0.97      0.99      0.98       156\n",
      "          12       0.90      0.85      0.87       243\n",
      "          13       1.00      1.00      1.00        70\n",
      "\n",
      "    accuracy                           0.89      2898\n",
      "   macro avg       0.89      0.90      0.89      2898\n",
      "weighted avg       0.89      0.89      0.89      2898\n",
      "\n",
      "Saved SCL_SDL+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression Model on the SCLSDL representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "sclsdl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "sclsdl_logistic_clf.fit(sclsdl_lrm_train_reps, sclsdl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "sclsdl_lrm_val_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_val_reps)\n",
    "sclsdl_lrm_val_accuracy = accuracy_score(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {sclsdl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions))\n",
    "\n",
    "# Evaluate on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "sclsdl_lrm_test_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_test_reps)\n",
    "sclsdl_lrm_test_accuracy = accuracy_score(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {sclsdl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_predictions.npy'), sclsdl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_true_labels.npy'), sclsdl_lrm_test_labels)\n",
    "print(f\"Saved SCL_SDL+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the representations learnt by SCL w/ SDL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:00.309124Z",
     "iopub.status.busy": "2025-05-08T19:17:00.309124Z",
     "iopub.status.idle": "2025-05-08T19:17:00.328194Z",
     "shell.execute_reply": "2025-05-08T19:17:00.328194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (280, 128)\n",
      "Train labels shape: (280,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (2898, 128)\n",
      "Test labels shape: (2898,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_mlp_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_mlp_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_mlp_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_mlp_train_reps, sclsdl_mlp_train_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_train_dir)\n",
    "sclsdl_mlp_val_reps, sclsdl_mlp_val_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_val_dir)\n",
    "sclsdl_mlp_test_reps, sclsdl_mlp_test_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:00.332320Z",
     "iopub.status.busy": "2025-05-08T19:17:00.332320Z",
     "iopub.status.idle": "2025-05-08T19:17:00.337396Z",
     "shell.execute_reply": "2025-05-08T19:17:00.337396Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "sclsdl_mlp_train_embeddings_torch = torch.tensor(sclsdl_mlp_train_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_train_labels_torch = torch.tensor(sclsdl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_val_embeddings_torch = torch.tensor(sclsdl_mlp_val_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_val_labels_torch = torch.tensor(sclsdl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_test_embeddings_torch = torch.tensor(sclsdl_mlp_test_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_test_labels_torch = torch.tensor(sclsdl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "sclsdl_mlp_train_dataset = TensorDataset(sclsdl_mlp_train_embeddings_torch, sclsdl_mlp_train_labels_torch)\n",
    "sclsdl_mlp_val_dataset = TensorDataset(sclsdl_mlp_val_embeddings_torch, sclsdl_mlp_val_labels_torch)\n",
    "sclsdl_mlp_test_dataset = TensorDataset(sclsdl_mlp_test_embeddings_torch, sclsdl_mlp_test_labels_torch)\n",
    "\n",
    "sclsdl_mlp_batch_size = 64\n",
    "sclsdl_mlp_train_loader = DataLoader(sclsdl_mlp_train_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=True)\n",
    "sclsdl_mlp_val_loader = DataLoader(sclsdl_mlp_val_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n",
    "sclsdl_mlp_test_loader = DataLoader(sclsdl_mlp_test_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:00.340404Z",
     "iopub.status.busy": "2025-05-08T19:17:00.339402Z",
     "iopub.status.idle": "2025-05-08T19:17:05.246414Z",
     "shell.execute_reply": "2025-05-08T19:17:05.245409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.7068  |  Val Loss: 2.6826\n",
      "Validation loss improved from inf to 2.6826.\n",
      "[Epoch 2/1000] Train Loss: 2.6695  |  Val Loss: 2.6465\n",
      "Validation loss improved from 2.6826 to 2.6465.\n",
      "[Epoch 3/1000] Train Loss: 2.6339  |  Val Loss: 2.6130\n",
      "Validation loss improved from 2.6465 to 2.6130.\n",
      "[Epoch 4/1000] Train Loss: 2.6014  |  Val Loss: 2.5818\n",
      "Validation loss improved from 2.6130 to 2.5818.\n",
      "[Epoch 5/1000] Train Loss: 2.5726  |  Val Loss: 2.5546\n",
      "Validation loss improved from 2.5818 to 2.5546.\n",
      "[Epoch 6/1000] Train Loss: 2.5465  |  Val Loss: 2.5301\n",
      "Validation loss improved from 2.5546 to 2.5301.\n",
      "[Epoch 7/1000] Train Loss: 2.5209  |  Val Loss: 2.5067\n",
      "Validation loss improved from 2.5301 to 2.5067.\n",
      "[Epoch 8/1000] Train Loss: 2.4979  |  Val Loss: 2.4848\n",
      "Validation loss improved from 2.5067 to 2.4848.\n",
      "[Epoch 9/1000] Train Loss: 2.4757  |  Val Loss: 2.4639\n",
      "Validation loss improved from 2.4848 to 2.4639.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/1000] Train Loss: 2.4524  |  Val Loss: 2.4426\n",
      "Validation loss improved from 2.4639 to 2.4426.\n",
      "[Epoch 11/1000] Train Loss: 2.4302  |  Val Loss: 2.4208\n",
      "Validation loss improved from 2.4426 to 2.4208.\n",
      "[Epoch 12/1000] Train Loss: 2.4079  |  Val Loss: 2.4005\n",
      "Validation loss improved from 2.4208 to 2.4005.\n",
      "[Epoch 13/1000] Train Loss: 2.3858  |  Val Loss: 2.3808\n",
      "Validation loss improved from 2.4005 to 2.3808.\n",
      "[Epoch 14/1000] Train Loss: 2.3652  |  Val Loss: 2.3607\n",
      "Validation loss improved from 2.3808 to 2.3607.\n",
      "[Epoch 15/1000] Train Loss: 2.3436  |  Val Loss: 2.3411\n",
      "Validation loss improved from 2.3607 to 2.3411.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/1000] Train Loss: 2.3234  |  Val Loss: 2.3217\n",
      "Validation loss improved from 2.3411 to 2.3217.\n",
      "[Epoch 17/1000] Train Loss: 2.3026  |  Val Loss: 2.3027\n",
      "Validation loss improved from 2.3217 to 2.3027.\n",
      "[Epoch 18/1000] Train Loss: 2.2819  |  Val Loss: 2.2839\n",
      "Validation loss improved from 2.3027 to 2.2839.\n",
      "[Epoch 19/1000] Train Loss: 2.2614  |  Val Loss: 2.2653\n",
      "Validation loss improved from 2.2839 to 2.2653.\n",
      "[Epoch 20/1000] Train Loss: 2.2411  |  Val Loss: 2.2466\n",
      "Validation loss improved from 2.2653 to 2.2466.\n",
      "[Epoch 21/1000] Train Loss: 2.2214  |  Val Loss: 2.2281\n",
      "Validation loss improved from 2.2466 to 2.2281.\n",
      "[Epoch 22/1000] Train Loss: 2.2003  |  Val Loss: 2.2098\n",
      "Validation loss improved from 2.2281 to 2.2098.\n",
      "[Epoch 23/1000] Train Loss: 2.1803  |  Val Loss: 2.1911\n",
      "Validation loss improved from 2.2098 to 2.1911.\n",
      "[Epoch 24/1000] Train Loss: 2.1603  |  Val Loss: 2.1723\n",
      "Validation loss improved from 2.1911 to 2.1723.\n",
      "[Epoch 25/1000] Train Loss: 2.1395  |  Val Loss: 2.1539\n",
      "Validation loss improved from 2.1723 to 2.1539.\n",
      "[Epoch 26/1000] Train Loss: 2.1192  |  Val Loss: 2.1357\n",
      "Validation loss improved from 2.1539 to 2.1357.\n",
      "[Epoch 27/1000] Train Loss: 2.0987  |  Val Loss: 2.1173\n",
      "Validation loss improved from 2.1357 to 2.1173.\n",
      "[Epoch 28/1000] Train Loss: 2.0783  |  Val Loss: 2.0985\n",
      "Validation loss improved from 2.1173 to 2.0985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29/1000] Train Loss: 2.0576  |  Val Loss: 2.0796\n",
      "Validation loss improved from 2.0985 to 2.0796.\n",
      "[Epoch 30/1000] Train Loss: 2.0368  |  Val Loss: 2.0606\n",
      "Validation loss improved from 2.0796 to 2.0606.\n",
      "[Epoch 31/1000] Train Loss: 2.0157  |  Val Loss: 2.0415\n",
      "Validation loss improved from 2.0606 to 2.0415.\n",
      "[Epoch 32/1000] Train Loss: 1.9945  |  Val Loss: 2.0222\n",
      "Validation loss improved from 2.0415 to 2.0222.\n",
      "[Epoch 33/1000] Train Loss: 1.9734  |  Val Loss: 2.0027\n",
      "Validation loss improved from 2.0222 to 2.0027.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/1000] Train Loss: 1.9518  |  Val Loss: 1.9829\n",
      "Validation loss improved from 2.0027 to 1.9829.\n",
      "[Epoch 35/1000] Train Loss: 1.9298  |  Val Loss: 1.9630\n",
      "Validation loss improved from 1.9829 to 1.9630.\n",
      "[Epoch 36/1000] Train Loss: 1.9078  |  Val Loss: 1.9429\n",
      "Validation loss improved from 1.9630 to 1.9429.\n",
      "[Epoch 37/1000] Train Loss: 1.8854  |  Val Loss: 1.9223\n",
      "Validation loss improved from 1.9429 to 1.9223.\n",
      "[Epoch 38/1000] Train Loss: 1.8629  |  Val Loss: 1.9015\n",
      "Validation loss improved from 1.9223 to 1.9015.\n",
      "[Epoch 39/1000] Train Loss: 1.8401  |  Val Loss: 1.8806\n",
      "Validation loss improved from 1.9015 to 1.8806.\n",
      "[Epoch 40/1000] Train Loss: 1.8169  |  Val Loss: 1.8597\n",
      "Validation loss improved from 1.8806 to 1.8597.\n",
      "[Epoch 41/1000] Train Loss: 1.7936  |  Val Loss: 1.8387\n",
      "Validation loss improved from 1.8597 to 1.8387.\n",
      "[Epoch 42/1000] Train Loss: 1.7700  |  Val Loss: 1.8176\n",
      "Validation loss improved from 1.8387 to 1.8176.\n",
      "[Epoch 43/1000] Train Loss: 1.7465  |  Val Loss: 1.7964\n",
      "Validation loss improved from 1.8176 to 1.7964.\n",
      "[Epoch 44/1000] Train Loss: 1.7225  |  Val Loss: 1.7752\n",
      "Validation loss improved from 1.7964 to 1.7752.\n",
      "[Epoch 45/1000] Train Loss: 1.6990  |  Val Loss: 1.7538\n",
      "Validation loss improved from 1.7752 to 1.7538.\n",
      "[Epoch 46/1000] Train Loss: 1.6747  |  Val Loss: 1.7323\n",
      "Validation loss improved from 1.7538 to 1.7323.\n",
      "[Epoch 47/1000] Train Loss: 1.6503  |  Val Loss: 1.7109\n",
      "Validation loss improved from 1.7323 to 1.7109.\n",
      "[Epoch 48/1000] Train Loss: 1.6264  |  Val Loss: 1.6891\n",
      "Validation loss improved from 1.7109 to 1.6891.\n",
      "[Epoch 49/1000] Train Loss: 1.6018  |  Val Loss: 1.6674\n",
      "Validation loss improved from 1.6891 to 1.6674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 50/1000] Train Loss: 1.5774  |  Val Loss: 1.6454\n",
      "Validation loss improved from 1.6674 to 1.6454.\n",
      "[Epoch 51/1000] Train Loss: 1.5523  |  Val Loss: 1.6234\n",
      "Validation loss improved from 1.6454 to 1.6234.\n",
      "[Epoch 52/1000] Train Loss: 1.5276  |  Val Loss: 1.6015\n",
      "Validation loss improved from 1.6234 to 1.6015.\n",
      "[Epoch 53/1000] Train Loss: 1.5032  |  Val Loss: 1.5795\n",
      "Validation loss improved from 1.6015 to 1.5795.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 54/1000] Train Loss: 1.4787  |  Val Loss: 1.5573\n",
      "Validation loss improved from 1.5795 to 1.5573.\n",
      "[Epoch 55/1000] Train Loss: 1.4542  |  Val Loss: 1.5351\n",
      "Validation loss improved from 1.5573 to 1.5351.\n",
      "[Epoch 56/1000] Train Loss: 1.4294  |  Val Loss: 1.5128\n",
      "Validation loss improved from 1.5351 to 1.5128.\n",
      "[Epoch 57/1000] Train Loss: 1.4050  |  Val Loss: 1.4903\n",
      "Validation loss improved from 1.5128 to 1.4903.\n",
      "[Epoch 58/1000] Train Loss: 1.3800  |  Val Loss: 1.4678\n",
      "Validation loss improved from 1.4903 to 1.4678.\n",
      "[Epoch 59/1000] Train Loss: 1.3552  |  Val Loss: 1.4450\n",
      "Validation loss improved from 1.4678 to 1.4450.\n",
      "[Epoch 60/1000] Train Loss: 1.3299  |  Val Loss: 1.4224\n",
      "Validation loss improved from 1.4450 to 1.4224.\n",
      "[Epoch 61/1000] Train Loss: 1.3048  |  Val Loss: 1.4001\n",
      "Validation loss improved from 1.4224 to 1.4001.\n",
      "[Epoch 62/1000] Train Loss: 1.2798  |  Val Loss: 1.3781\n",
      "Validation loss improved from 1.4001 to 1.3781.\n",
      "[Epoch 63/1000] Train Loss: 1.2551  |  Val Loss: 1.3561\n",
      "Validation loss improved from 1.3781 to 1.3561.\n",
      "[Epoch 64/1000] Train Loss: 1.2310  |  Val Loss: 1.3340\n",
      "Validation loss improved from 1.3561 to 1.3340.\n",
      "[Epoch 65/1000] Train Loss: 1.2064  |  Val Loss: 1.3122\n",
      "Validation loss improved from 1.3340 to 1.3122.\n",
      "[Epoch 66/1000] Train Loss: 1.1821  |  Val Loss: 1.2907\n",
      "Validation loss improved from 1.3122 to 1.2907.\n",
      "[Epoch 67/1000] Train Loss: 1.1577  |  Val Loss: 1.2699\n",
      "Validation loss improved from 1.2907 to 1.2699.\n",
      "[Epoch 68/1000] Train Loss: 1.1341  |  Val Loss: 1.2492\n",
      "Validation loss improved from 1.2699 to 1.2492.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 69/1000] Train Loss: 1.1106  |  Val Loss: 1.2291\n",
      "Validation loss improved from 1.2492 to 1.2291.\n",
      "[Epoch 70/1000] Train Loss: 1.0874  |  Val Loss: 1.2090\n",
      "Validation loss improved from 1.2291 to 1.2090.\n",
      "[Epoch 71/1000] Train Loss: 1.0644  |  Val Loss: 1.1891\n",
      "Validation loss improved from 1.2090 to 1.1891.\n",
      "[Epoch 72/1000] Train Loss: 1.0413  |  Val Loss: 1.1692\n",
      "Validation loss improved from 1.1891 to 1.1692.\n",
      "[Epoch 73/1000] Train Loss: 1.0190  |  Val Loss: 1.1494\n",
      "Validation loss improved from 1.1692 to 1.1494.\n",
      "[Epoch 74/1000] Train Loss: 0.9965  |  Val Loss: 1.1299\n",
      "Validation loss improved from 1.1494 to 1.1299.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 75/1000] Train Loss: 0.9740  |  Val Loss: 1.1106\n",
      "Validation loss improved from 1.1299 to 1.1106.\n",
      "[Epoch 76/1000] Train Loss: 0.9520  |  Val Loss: 1.0919\n",
      "Validation loss improved from 1.1106 to 1.0919.\n",
      "[Epoch 77/1000] Train Loss: 0.9307  |  Val Loss: 1.0741\n",
      "Validation loss improved from 1.0919 to 1.0741.\n",
      "[Epoch 78/1000] Train Loss: 0.9098  |  Val Loss: 1.0560\n",
      "Validation loss improved from 1.0741 to 1.0560.\n",
      "[Epoch 79/1000] Train Loss: 0.8889  |  Val Loss: 1.0386\n",
      "Validation loss improved from 1.0560 to 1.0386.\n",
      "[Epoch 80/1000] Train Loss: 0.8678  |  Val Loss: 1.0217\n",
      "Validation loss improved from 1.0386 to 1.0217.\n",
      "[Epoch 81/1000] Train Loss: 0.8478  |  Val Loss: 1.0049\n",
      "Validation loss improved from 1.0217 to 1.0049.\n",
      "[Epoch 82/1000] Train Loss: 0.8276  |  Val Loss: 0.9876\n",
      "Validation loss improved from 1.0049 to 0.9876.\n",
      "[Epoch 83/1000] Train Loss: 0.8077  |  Val Loss: 0.9704\n",
      "Validation loss improved from 0.9876 to 0.9704.\n",
      "[Epoch 84/1000] Train Loss: 0.7884  |  Val Loss: 0.9537\n",
      "Validation loss improved from 0.9704 to 0.9537.\n",
      "[Epoch 85/1000] Train Loss: 0.7688  |  Val Loss: 0.9369\n",
      "Validation loss improved from 0.9537 to 0.9369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 86/1000] Train Loss: 0.7499  |  Val Loss: 0.9206\n",
      "Validation loss improved from 0.9369 to 0.9206.\n",
      "[Epoch 87/1000] Train Loss: 0.7312  |  Val Loss: 0.9048\n",
      "Validation loss improved from 0.9206 to 0.9048.\n",
      "[Epoch 88/1000] Train Loss: 0.7131  |  Val Loss: 0.8891\n",
      "Validation loss improved from 0.9048 to 0.8891.\n",
      "[Epoch 89/1000] Train Loss: 0.6952  |  Val Loss: 0.8739\n",
      "Validation loss improved from 0.8891 to 0.8739.\n",
      "[Epoch 90/1000] Train Loss: 0.6776  |  Val Loss: 0.8591\n",
      "Validation loss improved from 0.8739 to 0.8591.\n",
      "[Epoch 91/1000] Train Loss: 0.6601  |  Val Loss: 0.8447\n",
      "Validation loss improved from 0.8591 to 0.8447.\n",
      "[Epoch 92/1000] Train Loss: 0.6432  |  Val Loss: 0.8307\n",
      "Validation loss improved from 0.8447 to 0.8307.\n",
      "[Epoch 93/1000] Train Loss: 0.6272  |  Val Loss: 0.8170\n",
      "Validation loss improved from 0.8307 to 0.8170.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 94/1000] Train Loss: 0.6114  |  Val Loss: 0.8038\n",
      "Validation loss improved from 0.8170 to 0.8038.\n",
      "[Epoch 95/1000] Train Loss: 0.5963  |  Val Loss: 0.7912\n",
      "Validation loss improved from 0.8038 to 0.7912.\n",
      "[Epoch 96/1000] Train Loss: 0.5813  |  Val Loss: 0.7788\n",
      "Validation loss improved from 0.7912 to 0.7788.\n",
      "[Epoch 97/1000] Train Loss: 0.5669  |  Val Loss: 0.7669\n",
      "Validation loss improved from 0.7788 to 0.7669.\n",
      "[Epoch 98/1000] Train Loss: 0.5529  |  Val Loss: 0.7557\n",
      "Validation loss improved from 0.7669 to 0.7557.\n",
      "[Epoch 99/1000] Train Loss: 0.5392  |  Val Loss: 0.7449\n",
      "Validation loss improved from 0.7557 to 0.7449.\n",
      "[Epoch 100/1000] Train Loss: 0.5257  |  Val Loss: 0.7346\n",
      "Validation loss improved from 0.7449 to 0.7346.\n",
      "[Epoch 101/1000] Train Loss: 0.5130  |  Val Loss: 0.7244\n",
      "Validation loss improved from 0.7346 to 0.7244.\n",
      "[Epoch 102/1000] Train Loss: 0.5009  |  Val Loss: 0.7148\n",
      "Validation loss improved from 0.7244 to 0.7148.\n",
      "[Epoch 103/1000] Train Loss: 0.4886  |  Val Loss: 0.7054\n",
      "Validation loss improved from 0.7148 to 0.7054.\n",
      "[Epoch 104/1000] Train Loss: 0.4772  |  Val Loss: 0.6969\n",
      "Validation loss improved from 0.7054 to 0.6969.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 105/1000] Train Loss: 0.4661  |  Val Loss: 0.6879\n",
      "Validation loss improved from 0.6969 to 0.6879.\n",
      "[Epoch 106/1000] Train Loss: 0.4552  |  Val Loss: 0.6788\n",
      "Validation loss improved from 0.6879 to 0.6788.\n",
      "[Epoch 107/1000] Train Loss: 0.4451  |  Val Loss: 0.6700\n",
      "Validation loss improved from 0.6788 to 0.6700.\n",
      "[Epoch 108/1000] Train Loss: 0.4346  |  Val Loss: 0.6614\n",
      "Validation loss improved from 0.6700 to 0.6614.\n",
      "[Epoch 109/1000] Train Loss: 0.4252  |  Val Loss: 0.6534\n",
      "Validation loss improved from 0.6614 to 0.6534.\n",
      "[Epoch 110/1000] Train Loss: 0.4158  |  Val Loss: 0.6455\n",
      "Validation loss improved from 0.6534 to 0.6455.\n",
      "[Epoch 111/1000] Train Loss: 0.4069  |  Val Loss: 0.6379\n",
      "Validation loss improved from 0.6455 to 0.6379.\n",
      "[Epoch 112/1000] Train Loss: 0.3980  |  Val Loss: 0.6312\n",
      "Validation loss improved from 0.6379 to 0.6312.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 113/1000] Train Loss: 0.3897  |  Val Loss: 0.6248\n",
      "Validation loss improved from 0.6312 to 0.6248.\n",
      "[Epoch 114/1000] Train Loss: 0.3817  |  Val Loss: 0.6191\n",
      "Validation loss improved from 0.6248 to 0.6191.\n",
      "[Epoch 115/1000] Train Loss: 0.3737  |  Val Loss: 0.6136\n",
      "Validation loss improved from 0.6191 to 0.6136.\n",
      "[Epoch 116/1000] Train Loss: 0.3665  |  Val Loss: 0.6083\n",
      "Validation loss improved from 0.6136 to 0.6083.\n",
      "[Epoch 117/1000] Train Loss: 0.3591  |  Val Loss: 0.6029\n",
      "Validation loss improved from 0.6083 to 0.6029.\n",
      "[Epoch 118/1000] Train Loss: 0.3521  |  Val Loss: 0.5978\n",
      "Validation loss improved from 0.6029 to 0.5978.\n",
      "[Epoch 119/1000] Train Loss: 0.3458  |  Val Loss: 0.5922\n",
      "Validation loss improved from 0.5978 to 0.5922.\n",
      "[Epoch 120/1000] Train Loss: 0.3390  |  Val Loss: 0.5867\n",
      "Validation loss improved from 0.5922 to 0.5867.\n",
      "[Epoch 121/1000] Train Loss: 0.3327  |  Val Loss: 0.5818\n",
      "Validation loss improved from 0.5867 to 0.5818.\n",
      "[Epoch 122/1000] Train Loss: 0.3263  |  Val Loss: 0.5766\n",
      "Validation loss improved from 0.5818 to 0.5766.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 123/1000] Train Loss: 0.3206  |  Val Loss: 0.5721\n",
      "Validation loss improved from 0.5766 to 0.5721.\n",
      "[Epoch 124/1000] Train Loss: 0.3147  |  Val Loss: 0.5681\n",
      "Validation loss improved from 0.5721 to 0.5681.\n",
      "[Epoch 125/1000] Train Loss: 0.3092  |  Val Loss: 0.5638\n",
      "Validation loss improved from 0.5681 to 0.5638.\n",
      "[Epoch 126/1000] Train Loss: 0.3037  |  Val Loss: 0.5593\n",
      "Validation loss improved from 0.5638 to 0.5593.\n",
      "[Epoch 127/1000] Train Loss: 0.2983  |  Val Loss: 0.5549\n",
      "Validation loss improved from 0.5593 to 0.5549.\n",
      "[Epoch 128/1000] Train Loss: 0.2934  |  Val Loss: 0.5505\n",
      "Validation loss improved from 0.5549 to 0.5505.\n",
      "[Epoch 129/1000] Train Loss: 0.2886  |  Val Loss: 0.5464\n",
      "Validation loss improved from 0.5505 to 0.5464.\n",
      "[Epoch 130/1000] Train Loss: 0.2836  |  Val Loss: 0.5430\n",
      "Validation loss improved from 0.5464 to 0.5430.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 131/1000] Train Loss: 0.2790  |  Val Loss: 0.5397\n",
      "Validation loss improved from 0.5430 to 0.5397.\n",
      "[Epoch 132/1000] Train Loss: 0.2744  |  Val Loss: 0.5368\n",
      "Validation loss improved from 0.5397 to 0.5368.\n",
      "[Epoch 133/1000] Train Loss: 0.2702  |  Val Loss: 0.5341\n",
      "Validation loss improved from 0.5368 to 0.5341.\n",
      "[Epoch 134/1000] Train Loss: 0.2657  |  Val Loss: 0.5309\n",
      "Validation loss improved from 0.5341 to 0.5309.\n",
      "[Epoch 135/1000] Train Loss: 0.2616  |  Val Loss: 0.5278\n",
      "Validation loss improved from 0.5309 to 0.5278.\n",
      "[Epoch 136/1000] Train Loss: 0.2577  |  Val Loss: 0.5251\n",
      "Validation loss improved from 0.5278 to 0.5251.\n",
      "[Epoch 137/1000] Train Loss: 0.2539  |  Val Loss: 0.5216\n",
      "Validation loss improved from 0.5251 to 0.5216.\n",
      "[Epoch 138/1000] Train Loss: 0.2501  |  Val Loss: 0.5192\n",
      "Validation loss improved from 0.5216 to 0.5192.\n",
      "[Epoch 139/1000] Train Loss: 0.2464  |  Val Loss: 0.5170\n",
      "Validation loss improved from 0.5192 to 0.5170.\n",
      "[Epoch 140/1000] Train Loss: 0.2428  |  Val Loss: 0.5142\n",
      "Validation loss improved from 0.5170 to 0.5142.\n",
      "[Epoch 141/1000] Train Loss: 0.2395  |  Val Loss: 0.5117\n",
      "Validation loss improved from 0.5142 to 0.5117.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 142/1000] Train Loss: 0.2361  |  Val Loss: 0.5097\n",
      "Validation loss improved from 0.5117 to 0.5097.\n",
      "[Epoch 143/1000] Train Loss: 0.2329  |  Val Loss: 0.5084\n",
      "Validation loss improved from 0.5097 to 0.5084.\n",
      "[Epoch 144/1000] Train Loss: 0.2296  |  Val Loss: 0.5067\n",
      "Validation loss improved from 0.5084 to 0.5067.\n",
      "[Epoch 145/1000] Train Loss: 0.2267  |  Val Loss: 0.5050\n",
      "Validation loss improved from 0.5067 to 0.5050.\n",
      "[Epoch 146/1000] Train Loss: 0.2236  |  Val Loss: 0.5025\n",
      "Validation loss improved from 0.5050 to 0.5025.\n",
      "[Epoch 147/1000] Train Loss: 0.2206  |  Val Loss: 0.5007\n",
      "Validation loss improved from 0.5025 to 0.5007.\n",
      "[Epoch 148/1000] Train Loss: 0.2177  |  Val Loss: 0.4989\n",
      "Validation loss improved from 0.5007 to 0.4989.\n",
      "[Epoch 149/1000] Train Loss: 0.2150  |  Val Loss: 0.4972\n",
      "Validation loss improved from 0.4989 to 0.4972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 150/1000] Train Loss: 0.2122  |  Val Loss: 0.4958\n",
      "Validation loss improved from 0.4972 to 0.4958.\n",
      "[Epoch 151/1000] Train Loss: 0.2094  |  Val Loss: 0.4943\n",
      "Validation loss improved from 0.4958 to 0.4943.\n",
      "[Epoch 152/1000] Train Loss: 0.2066  |  Val Loss: 0.4914\n",
      "Validation loss improved from 0.4943 to 0.4914.\n",
      "[Epoch 153/1000] Train Loss: 0.2041  |  Val Loss: 0.4891\n",
      "Validation loss improved from 0.4914 to 0.4891.\n",
      "[Epoch 154/1000] Train Loss: 0.2015  |  Val Loss: 0.4870\n",
      "Validation loss improved from 0.4891 to 0.4870.\n",
      "[Epoch 155/1000] Train Loss: 0.1991  |  Val Loss: 0.4855\n",
      "Validation loss improved from 0.4870 to 0.4855.\n",
      "[Epoch 156/1000] Train Loss: 0.1965  |  Val Loss: 0.4836\n",
      "Validation loss improved from 0.4855 to 0.4836.\n",
      "[Epoch 157/1000] Train Loss: 0.1942  |  Val Loss: 0.4822\n",
      "Validation loss improved from 0.4836 to 0.4822.\n",
      "[Epoch 158/1000] Train Loss: 0.1918  |  Val Loss: 0.4812\n",
      "Validation loss improved from 0.4822 to 0.4812.\n",
      "[Epoch 159/1000] Train Loss: 0.1896  |  Val Loss: 0.4798\n",
      "Validation loss improved from 0.4812 to 0.4798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 160/1000] Train Loss: 0.1876  |  Val Loss: 0.4777\n",
      "Validation loss improved from 0.4798 to 0.4777.\n",
      "[Epoch 161/1000] Train Loss: 0.1853  |  Val Loss: 0.4767\n",
      "Validation loss improved from 0.4777 to 0.4767.\n",
      "[Epoch 162/1000] Train Loss: 0.1833  |  Val Loss: 0.4761\n",
      "Validation loss improved from 0.4767 to 0.4761.\n",
      "[Epoch 163/1000] Train Loss: 0.1812  |  Val Loss: 0.4749\n",
      "Validation loss improved from 0.4761 to 0.4749.\n",
      "[Epoch 164/1000] Train Loss: 0.1792  |  Val Loss: 0.4737\n",
      "Validation loss improved from 0.4749 to 0.4737.\n",
      "[Epoch 165/1000] Train Loss: 0.1771  |  Val Loss: 0.4728\n",
      "Validation loss improved from 0.4737 to 0.4728.\n",
      "[Epoch 166/1000] Train Loss: 0.1753  |  Val Loss: 0.4725\n",
      "Validation loss improved from 0.4728 to 0.4725.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 167/1000] Train Loss: 0.1735  |  Val Loss: 0.4711\n",
      "Validation loss improved from 0.4725 to 0.4711.\n",
      "[Epoch 168/1000] Train Loss: 0.1718  |  Val Loss: 0.4699\n",
      "Validation loss improved from 0.4711 to 0.4699.\n",
      "[Epoch 169/1000] Train Loss: 0.1700  |  Val Loss: 0.4681\n",
      "Validation loss improved from 0.4699 to 0.4681.\n",
      "[Epoch 170/1000] Train Loss: 0.1681  |  Val Loss: 0.4668\n",
      "Validation loss improved from 0.4681 to 0.4668.\n",
      "[Epoch 171/1000] Train Loss: 0.1666  |  Val Loss: 0.4655\n",
      "Validation loss improved from 0.4668 to 0.4655.\n",
      "[Epoch 172/1000] Train Loss: 0.1648  |  Val Loss: 0.4650\n",
      "Validation loss improved from 0.4655 to 0.4650.\n",
      "[Epoch 173/1000] Train Loss: 0.1632  |  Val Loss: 0.4644\n",
      "Validation loss improved from 0.4650 to 0.4644.\n",
      "[Epoch 174/1000] Train Loss: 0.1615  |  Val Loss: 0.4624\n",
      "Validation loss improved from 0.4644 to 0.4624.\n",
      "[Epoch 175/1000] Train Loss: 0.1600  |  Val Loss: 0.4599\n",
      "Validation loss improved from 0.4624 to 0.4599.\n",
      "[Epoch 176/1000] Train Loss: 0.1584  |  Val Loss: 0.4583\n",
      "Validation loss improved from 0.4599 to 0.4583.\n",
      "[Epoch 177/1000] Train Loss: 0.1570  |  Val Loss: 0.4566\n",
      "Validation loss improved from 0.4583 to 0.4566.\n",
      "[Epoch 178/1000] Train Loss: 0.1554  |  Val Loss: 0.4560\n",
      "Validation loss improved from 0.4566 to 0.4560.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 179/1000] Train Loss: 0.1537  |  Val Loss: 0.4558\n",
      "Validation loss improved from 0.4560 to 0.4558.\n",
      "[Epoch 180/1000] Train Loss: 0.1523  |  Val Loss: 0.4553\n",
      "Validation loss improved from 0.4558 to 0.4553.\n",
      "[Epoch 181/1000] Train Loss: 0.1510  |  Val Loss: 0.4548\n",
      "Validation loss improved from 0.4553 to 0.4548.\n",
      "[Epoch 182/1000] Train Loss: 0.1494  |  Val Loss: 0.4535\n",
      "Validation loss improved from 0.4548 to 0.4535.\n",
      "[Epoch 183/1000] Train Loss: 0.1481  |  Val Loss: 0.4527\n",
      "Validation loss improved from 0.4535 to 0.4527.\n",
      "[Epoch 184/1000] Train Loss: 0.1471  |  Val Loss: 0.4515\n",
      "Validation loss improved from 0.4527 to 0.4515.\n",
      "[Epoch 185/1000] Train Loss: 0.1455  |  Val Loss: 0.4513\n",
      "Validation loss improved from 0.4515 to 0.4513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 186/1000] Train Loss: 0.1441  |  Val Loss: 0.4512\n",
      "Validation loss improved from 0.4513 to 0.4512.\n",
      "[Epoch 187/1000] Train Loss: 0.1430  |  Val Loss: 0.4504\n",
      "Validation loss improved from 0.4512 to 0.4504.\n",
      "[Epoch 188/1000] Train Loss: 0.1417  |  Val Loss: 0.4502\n",
      "Validation loss improved from 0.4504 to 0.4502.\n",
      "[Epoch 189/1000] Train Loss: 0.1404  |  Val Loss: 0.4497\n",
      "Validation loss improved from 0.4502 to 0.4497.\n",
      "[Epoch 190/1000] Train Loss: 0.1392  |  Val Loss: 0.4486\n",
      "Validation loss improved from 0.4497 to 0.4486.\n",
      "[Epoch 191/1000] Train Loss: 0.1379  |  Val Loss: 0.4471\n",
      "Validation loss improved from 0.4486 to 0.4471.\n",
      "[Epoch 192/1000] Train Loss: 0.1367  |  Val Loss: 0.4466\n",
      "Validation loss improved from 0.4471 to 0.4466.\n",
      "[Epoch 193/1000] Train Loss: 0.1356  |  Val Loss: 0.4463\n",
      "Validation loss improved from 0.4466 to 0.4463.\n",
      "[Epoch 194/1000] Train Loss: 0.1345  |  Val Loss: 0.4460\n",
      "Validation loss improved from 0.4463 to 0.4460.\n",
      "[Epoch 195/1000] Train Loss: 0.1333  |  Val Loss: 0.4453\n",
      "Validation loss improved from 0.4460 to 0.4453.\n",
      "[Epoch 196/1000] Train Loss: 0.1323  |  Val Loss: 0.4437\n",
      "Validation loss improved from 0.4453 to 0.4437.\n",
      "[Epoch 197/1000] Train Loss: 0.1312  |  Val Loss: 0.4431\n",
      "Validation loss improved from 0.4437 to 0.4431.\n",
      "[Epoch 198/1000] Train Loss: 0.1301  |  Val Loss: 0.4417\n",
      "Validation loss improved from 0.4431 to 0.4417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 199/1000] Train Loss: 0.1290  |  Val Loss: 0.4412\n",
      "Validation loss improved from 0.4417 to 0.4412.\n",
      "[Epoch 200/1000] Train Loss: 0.1279  |  Val Loss: 0.4409\n",
      "Validation loss improved from 0.4412 to 0.4409.\n",
      "[Epoch 201/1000] Train Loss: 0.1269  |  Val Loss: 0.4411\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 202/1000] Train Loss: 0.1260  |  Val Loss: 0.4414\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 203/1000] Train Loss: 0.1248  |  Val Loss: 0.4417\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 204/1000] Train Loss: 0.1239  |  Val Loss: 0.4412\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 205/1000] Train Loss: 0.1229  |  Val Loss: 0.4404\n",
      "Validation loss improved from 0.4409 to 0.4404.\n",
      "[Epoch 206/1000] Train Loss: 0.1220  |  Val Loss: 0.4392\n",
      "Validation loss improved from 0.4404 to 0.4392.\n",
      "[Epoch 207/1000] Train Loss: 0.1209  |  Val Loss: 0.4388\n",
      "Validation loss improved from 0.4392 to 0.4388.\n",
      "[Epoch 208/1000] Train Loss: 0.1199  |  Val Loss: 0.4379\n",
      "Validation loss improved from 0.4388 to 0.4379.\n",
      "[Epoch 209/1000] Train Loss: 0.1190  |  Val Loss: 0.4371\n",
      "Validation loss improved from 0.4379 to 0.4371.\n",
      "[Epoch 210/1000] Train Loss: 0.1180  |  Val Loss: 0.4370\n",
      "Validation loss improved from 0.4371 to 0.4370.\n",
      "[Epoch 211/1000] Train Loss: 0.1172  |  Val Loss: 0.4367\n",
      "Validation loss improved from 0.4370 to 0.4367.\n",
      "[Epoch 212/1000] Train Loss: 0.1162  |  Val Loss: 0.4353\n",
      "Validation loss improved from 0.4367 to 0.4353.\n",
      "[Epoch 213/1000] Train Loss: 0.1154  |  Val Loss: 0.4349\n",
      "Validation loss improved from 0.4353 to 0.4349.\n",
      "[Epoch 214/1000] Train Loss: 0.1147  |  Val Loss: 0.4344\n",
      "Validation loss improved from 0.4349 to 0.4344.\n",
      "[Epoch 215/1000] Train Loss: 0.1136  |  Val Loss: 0.4327\n",
      "Validation loss improved from 0.4344 to 0.4327.\n",
      "[Epoch 216/1000] Train Loss: 0.1130  |  Val Loss: 0.4315\n",
      "Validation loss improved from 0.4327 to 0.4315.\n",
      "[Epoch 217/1000] Train Loss: 0.1120  |  Val Loss: 0.4309\n",
      "Validation loss improved from 0.4315 to 0.4309.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 218/1000] Train Loss: 0.1110  |  Val Loss: 0.4310\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 219/1000] Train Loss: 0.1102  |  Val Loss: 0.4304\n",
      "Validation loss improved from 0.4309 to 0.4304.\n",
      "[Epoch 220/1000] Train Loss: 0.1094  |  Val Loss: 0.4299\n",
      "Validation loss improved from 0.4304 to 0.4299.\n",
      "[Epoch 221/1000] Train Loss: 0.1085  |  Val Loss: 0.4300\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 222/1000] Train Loss: 0.1078  |  Val Loss: 0.4302\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 223/1000] Train Loss: 0.1069  |  Val Loss: 0.4295\n",
      "Validation loss improved from 0.4299 to 0.4295.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 224/1000] Train Loss: 0.1063  |  Val Loss: 0.4295\n",
      "Validation loss improved from 0.4295 to 0.4295.\n",
      "[Epoch 225/1000] Train Loss: 0.1053  |  Val Loss: 0.4292\n",
      "Validation loss improved from 0.4295 to 0.4292.\n",
      "[Epoch 226/1000] Train Loss: 0.1047  |  Val Loss: 0.4281\n",
      "Validation loss improved from 0.4292 to 0.4281.\n",
      "[Epoch 227/1000] Train Loss: 0.1040  |  Val Loss: 0.4272\n",
      "Validation loss improved from 0.4281 to 0.4272.\n",
      "[Epoch 228/1000] Train Loss: 0.1032  |  Val Loss: 0.4269\n",
      "Validation loss improved from 0.4272 to 0.4269.\n",
      "[Epoch 229/1000] Train Loss: 0.1025  |  Val Loss: 0.4270\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 230/1000] Train Loss: 0.1019  |  Val Loss: 0.4271\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 231/1000] Train Loss: 0.1011  |  Val Loss: 0.4272\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 232/1000] Train Loss: 0.1005  |  Val Loss: 0.4278\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 233/1000] Train Loss: 0.0998  |  Val Loss: 0.4283\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 234/1000] Train Loss: 0.0992  |  Val Loss: 0.4281\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 235/1000] Train Loss: 0.0987  |  Val Loss: 0.4271\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 236/1000] Train Loss: 0.0979  |  Val Loss: 0.4256\n",
      "Validation loss improved from 0.4269 to 0.4256.\n",
      "[Epoch 237/1000] Train Loss: 0.0973  |  Val Loss: 0.4249\n",
      "Validation loss improved from 0.4256 to 0.4249.\n",
      "[Epoch 238/1000] Train Loss: 0.0966  |  Val Loss: 0.4242\n",
      "Validation loss improved from 0.4249 to 0.4242.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 239/1000] Train Loss: 0.0959  |  Val Loss: 0.4241\n",
      "Validation loss improved from 0.4242 to 0.4241.\n",
      "[Epoch 240/1000] Train Loss: 0.0951  |  Val Loss: 0.4235\n",
      "Validation loss improved from 0.4241 to 0.4235.\n",
      "[Epoch 241/1000] Train Loss: 0.0945  |  Val Loss: 0.4235\n",
      "Validation loss improved from 0.4235 to 0.4235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 242/1000] Train Loss: 0.0939  |  Val Loss: 0.4237\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 243/1000] Train Loss: 0.0933  |  Val Loss: 0.4221\n",
      "Validation loss improved from 0.4235 to 0.4221.\n",
      "[Epoch 244/1000] Train Loss: 0.0927  |  Val Loss: 0.4218\n",
      "Validation loss improved from 0.4221 to 0.4218.\n",
      "[Epoch 245/1000] Train Loss: 0.0921  |  Val Loss: 0.4225\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 246/1000] Train Loss: 0.0914  |  Val Loss: 0.4223\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 247/1000] Train Loss: 0.0908  |  Val Loss: 0.4224\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 248/1000] Train Loss: 0.0901  |  Val Loss: 0.4227\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 249/1000] Train Loss: 0.0898  |  Val Loss: 0.4237\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 250/1000] Train Loss: 0.0890  |  Val Loss: 0.4232\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 251/1000] Train Loss: 0.0886  |  Val Loss: 0.4215\n",
      "Validation loss improved from 0.4218 to 0.4215.\n",
      "[Epoch 252/1000] Train Loss: 0.0878  |  Val Loss: 0.4225\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 253/1000] Train Loss: 0.0872  |  Val Loss: 0.4227\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 254/1000] Train Loss: 0.0867  |  Val Loss: 0.4228\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 255/1000] Train Loss: 0.0861  |  Val Loss: 0.4230\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 256/1000] Train Loss: 0.0856  |  Val Loss: 0.4233\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 257/1000] Train Loss: 0.0851  |  Val Loss: 0.4231\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 258/1000] Train Loss: 0.0847  |  Val Loss: 0.4230\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 259/1000] Train Loss: 0.0842  |  Val Loss: 0.4235\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 260/1000] Train Loss: 0.0836  |  Val Loss: 0.4214\n",
      "Validation loss improved from 0.4215 to 0.4214.\n",
      "[Epoch 261/1000] Train Loss: 0.0828  |  Val Loss: 0.4206\n",
      "Validation loss improved from 0.4214 to 0.4206.\n",
      "[Epoch 262/1000] Train Loss: 0.0823  |  Val Loss: 0.4199\n",
      "Validation loss improved from 0.4206 to 0.4199.\n",
      "[Epoch 263/1000] Train Loss: 0.0819  |  Val Loss: 0.4200\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 264/1000] Train Loss: 0.0812  |  Val Loss: 0.4193\n",
      "Validation loss improved from 0.4199 to 0.4193.\n",
      "[Epoch 265/1000] Train Loss: 0.0808  |  Val Loss: 0.4184\n",
      "Validation loss improved from 0.4193 to 0.4184.\n",
      "[Epoch 266/1000] Train Loss: 0.0804  |  Val Loss: 0.4188\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 267/1000] Train Loss: 0.0798  |  Val Loss: 0.4189\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 268/1000] Train Loss: 0.0793  |  Val Loss: 0.4187\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 269/1000] Train Loss: 0.0790  |  Val Loss: 0.4180\n",
      "Validation loss improved from 0.4184 to 0.4180.\n",
      "[Epoch 270/1000] Train Loss: 0.0783  |  Val Loss: 0.4179\n",
      "Validation loss improved from 0.4180 to 0.4179.\n",
      "[Epoch 271/1000] Train Loss: 0.0780  |  Val Loss: 0.4175\n",
      "Validation loss improved from 0.4179 to 0.4175.\n",
      "[Epoch 272/1000] Train Loss: 0.0774  |  Val Loss: 0.4171\n",
      "Validation loss improved from 0.4175 to 0.4171.\n",
      "[Epoch 273/1000] Train Loss: 0.0771  |  Val Loss: 0.4178\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 274/1000] Train Loss: 0.0765  |  Val Loss: 0.4182\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 275/1000] Train Loss: 0.0759  |  Val Loss: 0.4189\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 276/1000] Train Loss: 0.0755  |  Val Loss: 0.4201\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 277/1000] Train Loss: 0.0749  |  Val Loss: 0.4197\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 278/1000] Train Loss: 0.0749  |  Val Loss: 0.4189\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 279/1000] Train Loss: 0.0741  |  Val Loss: 0.4187\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 280/1000] Train Loss: 0.0735  |  Val Loss: 0.4197\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 281/1000] Train Loss: 0.0735  |  Val Loss: 0.4208\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 282/1000] Train Loss: 0.0729  |  Val Loss: 0.4212\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 283/1000] Train Loss: 0.0725  |  Val Loss: 0.4211\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 284/1000] Train Loss: 0.0719  |  Val Loss: 0.4195\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 285/1000] Train Loss: 0.0713  |  Val Loss: 0.4178\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 286/1000] Train Loss: 0.0714  |  Val Loss: 0.4163\n",
      "Validation loss improved from 0.4171 to 0.4163.\n",
      "[Epoch 287/1000] Train Loss: 0.0706  |  Val Loss: 0.4162\n",
      "Validation loss improved from 0.4163 to 0.4162.\n",
      "[Epoch 288/1000] Train Loss: 0.0703  |  Val Loss: 0.4169\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 289/1000] Train Loss: 0.0699  |  Val Loss: 0.4168\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 290/1000] Train Loss: 0.0694  |  Val Loss: 0.4170\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 291/1000] Train Loss: 0.0694  |  Val Loss: 0.4156\n",
      "Validation loss improved from 0.4162 to 0.4156.\n",
      "[Epoch 292/1000] Train Loss: 0.0689  |  Val Loss: 0.4156\n",
      "Validation loss improved from 0.4156 to 0.4156.\n",
      "[Epoch 293/1000] Train Loss: 0.0682  |  Val Loss: 0.4161\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 294/1000] Train Loss: 0.0678  |  Val Loss: 0.4152\n",
      "Validation loss improved from 0.4156 to 0.4152.\n",
      "[Epoch 295/1000] Train Loss: 0.0675  |  Val Loss: 0.4156\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 296/1000] Train Loss: 0.0670  |  Val Loss: 0.4156\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 297/1000] Train Loss: 0.0668  |  Val Loss: 0.4151\n",
      "Validation loss improved from 0.4152 to 0.4151.\n",
      "[Epoch 298/1000] Train Loss: 0.0663  |  Val Loss: 0.4154\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 299/1000] Train Loss: 0.0661  |  Val Loss: 0.4162\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 300/1000] Train Loss: 0.0657  |  Val Loss: 0.4160\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 301/1000] Train Loss: 0.0652  |  Val Loss: 0.4159\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 302/1000] Train Loss: 0.0648  |  Val Loss: 0.4152\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 303/1000] Train Loss: 0.0643  |  Val Loss: 0.4147\n",
      "Validation loss improved from 0.4151 to 0.4147.\n",
      "[Epoch 304/1000] Train Loss: 0.0640  |  Val Loss: 0.4145\n",
      "Validation loss improved from 0.4147 to 0.4145.\n",
      "[Epoch 305/1000] Train Loss: 0.0636  |  Val Loss: 0.4147\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 306/1000] Train Loss: 0.0633  |  Val Loss: 0.4144\n",
      "Validation loss improved from 0.4145 to 0.4144.\n",
      "[Epoch 307/1000] Train Loss: 0.0629  |  Val Loss: 0.4150\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 308/1000] Train Loss: 0.0626  |  Val Loss: 0.4138\n",
      "Validation loss improved from 0.4144 to 0.4138.\n",
      "[Epoch 309/1000] Train Loss: 0.0624  |  Val Loss: 0.4129\n",
      "Validation loss improved from 0.4138 to 0.4129.\n",
      "[Epoch 310/1000] Train Loss: 0.0619  |  Val Loss: 0.4130\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 311/1000] Train Loss: 0.0615  |  Val Loss: 0.4144\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 312/1000] Train Loss: 0.0616  |  Val Loss: 0.4163\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 313/1000] Train Loss: 0.0609  |  Val Loss: 0.4162\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 314/1000] Train Loss: 0.0606  |  Val Loss: 0.4168\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 315/1000] Train Loss: 0.0602  |  Val Loss: 0.4164\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 316/1000] Train Loss: 0.0598  |  Val Loss: 0.4157\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 317/1000] Train Loss: 0.0595  |  Val Loss: 0.4147\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 318/1000] Train Loss: 0.0591  |  Val Loss: 0.4141\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 319/1000] Train Loss: 0.0589  |  Val Loss: 0.4127\n",
      "Validation loss improved from 0.4129 to 0.4127.\n",
      "[Epoch 320/1000] Train Loss: 0.0586  |  Val Loss: 0.4116\n",
      "Validation loss improved from 0.4127 to 0.4116.\n",
      "[Epoch 321/1000] Train Loss: 0.0583  |  Val Loss: 0.4118\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 322/1000] Train Loss: 0.0581  |  Val Loss: 0.4123\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 323/1000] Train Loss: 0.0577  |  Val Loss: 0.4138\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 324/1000] Train Loss: 0.0572  |  Val Loss: 0.4138\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 325/1000] Train Loss: 0.0569  |  Val Loss: 0.4141\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 326/1000] Train Loss: 0.0566  |  Val Loss: 0.4148\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 327/1000] Train Loss: 0.0563  |  Val Loss: 0.4153\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 328/1000] Train Loss: 0.0560  |  Val Loss: 0.4155\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 329/1000] Train Loss: 0.0556  |  Val Loss: 0.4156\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 330/1000] Train Loss: 0.0552  |  Val Loss: 0.4157\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 331/1000] Train Loss: 0.0549  |  Val Loss: 0.4161\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 332/1000] Train Loss: 0.0546  |  Val Loss: 0.4161\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 333/1000] Train Loss: 0.0542  |  Val Loss: 0.4159\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 334/1000] Train Loss: 0.0540  |  Val Loss: 0.4164\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 335/1000] Train Loss: 0.0537  |  Val Loss: 0.4156\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 336/1000] Train Loss: 0.0534  |  Val Loss: 0.4135\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 337/1000] Train Loss: 0.0531  |  Val Loss: 0.4123\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 338/1000] Train Loss: 0.0529  |  Val Loss: 0.4120\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 339/1000] Train Loss: 0.0526  |  Val Loss: 0.4118\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 340/1000] Train Loss: 0.0522  |  Val Loss: 0.4134\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 341/1000] Train Loss: 0.0520  |  Val Loss: 0.4149\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 342/1000] Train Loss: 0.0518  |  Val Loss: 0.4137\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 343/1000] Train Loss: 0.0512  |  Val Loss: 0.4131\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 344/1000] Train Loss: 0.0510  |  Val Loss: 0.4128\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 345/1000] Train Loss: 0.0506  |  Val Loss: 0.4133\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 346/1000] Train Loss: 0.0503  |  Val Loss: 0.4140\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 347/1000] Train Loss: 0.0500  |  Val Loss: 0.4146\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 348/1000] Train Loss: 0.0496  |  Val Loss: 0.4143\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 349/1000] Train Loss: 0.0493  |  Val Loss: 0.4145\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 350/1000] Train Loss: 0.0491  |  Val Loss: 0.4144\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 351/1000] Train Loss: 0.0487  |  Val Loss: 0.4142\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 352/1000] Train Loss: 0.0485  |  Val Loss: 0.4138\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 353/1000] Train Loss: 0.0482  |  Val Loss: 0.4143\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 354/1000] Train Loss: 0.0479  |  Val Loss: 0.4145\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 355/1000] Train Loss: 0.0475  |  Val Loss: 0.4146\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 356/1000] Train Loss: 0.0473  |  Val Loss: 0.4138\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 357/1000] Train Loss: 0.0470  |  Val Loss: 0.4144\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 358/1000] Train Loss: 0.0467  |  Val Loss: 0.4145\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 359/1000] Train Loss: 0.0465  |  Val Loss: 0.4151\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 360/1000] Train Loss: 0.0463  |  Val Loss: 0.4158\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 361/1000] Train Loss: 0.0460  |  Val Loss: 0.4157\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 362/1000] Train Loss: 0.0457  |  Val Loss: 0.4147\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 363/1000] Train Loss: 0.0454  |  Val Loss: 0.4142\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 364/1000] Train Loss: 0.0451  |  Val Loss: 0.4142\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 365/1000] Train Loss: 0.0448  |  Val Loss: 0.4129\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 366/1000] Train Loss: 0.0445  |  Val Loss: 0.4129\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 367/1000] Train Loss: 0.0443  |  Val Loss: 0.4136\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 368/1000] Train Loss: 0.0442  |  Val Loss: 0.4138\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 369/1000] Train Loss: 0.0438  |  Val Loss: 0.4148\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 370/1000] Train Loss: 0.0436  |  Val Loss: 0.4148\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 371/1000] Train Loss: 0.0432  |  Val Loss: 0.4140\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 372/1000] Train Loss: 0.0429  |  Val Loss: 0.4141\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 373/1000] Train Loss: 0.0428  |  Val Loss: 0.4133\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 374/1000] Train Loss: 0.0426  |  Val Loss: 0.4140\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 375/1000] Train Loss: 0.0423  |  Val Loss: 0.4129\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 376/1000] Train Loss: 0.0419  |  Val Loss: 0.4122\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 377/1000] Train Loss: 0.0417  |  Val Loss: 0.4127\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 378/1000] Train Loss: 0.0415  |  Val Loss: 0.4127\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 379/1000] Train Loss: 0.0412  |  Val Loss: 0.4130\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 380/1000] Train Loss: 0.0410  |  Val Loss: 0.4131\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 381/1000] Train Loss: 0.0407  |  Val Loss: 0.4133\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 382/1000] Train Loss: 0.0406  |  Val Loss: 0.4138\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 383/1000] Train Loss: 0.0404  |  Val Loss: 0.4137\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 384/1000] Train Loss: 0.0402  |  Val Loss: 0.4131\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 385/1000] Train Loss: 0.0399  |  Val Loss: 0.4136\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 386/1000] Train Loss: 0.0396  |  Val Loss: 0.4133\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 387/1000] Train Loss: 0.0393  |  Val Loss: 0.4134\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 388/1000] Train Loss: 0.0391  |  Val Loss: 0.4137\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 389/1000] Train Loss: 0.0389  |  Val Loss: 0.4139\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 390/1000] Train Loss: 0.0387  |  Val Loss: 0.4135\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 391/1000] Train Loss: 0.0384  |  Val Loss: 0.4142\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 392/1000] Train Loss: 0.0383  |  Val Loss: 0.4157\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 393/1000] Train Loss: 0.0380  |  Val Loss: 0.4170\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 394/1000] Train Loss: 0.0379  |  Val Loss: 0.4182\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 395/1000] Train Loss: 0.0377  |  Val Loss: 0.4187\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 396/1000] Train Loss: 0.0375  |  Val Loss: 0.4182\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 397/1000] Train Loss: 0.0373  |  Val Loss: 0.4185\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 398/1000] Train Loss: 0.0370  |  Val Loss: 0.4183\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 399/1000] Train Loss: 0.0367  |  Val Loss: 0.4176\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 400/1000] Train Loss: 0.0365  |  Val Loss: 0.4174\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 401/1000] Train Loss: 0.0363  |  Val Loss: 0.4162\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 402/1000] Train Loss: 0.0360  |  Val Loss: 0.4156\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 403/1000] Train Loss: 0.0359  |  Val Loss: 0.4154\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 404/1000] Train Loss: 0.0357  |  Val Loss: 0.4158\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 405/1000] Train Loss: 0.0356  |  Val Loss: 0.4163\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 406/1000] Train Loss: 0.0353  |  Val Loss: 0.4173\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 407/1000] Train Loss: 0.0351  |  Val Loss: 0.4169\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 408/1000] Train Loss: 0.0349  |  Val Loss: 0.4162\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 409/1000] Train Loss: 0.0347  |  Val Loss: 0.4157\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 410/1000] Train Loss: 0.0344  |  Val Loss: 0.4157\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 411/1000] Train Loss: 0.0341  |  Val Loss: 0.4160\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 412/1000] Train Loss: 0.0341  |  Val Loss: 0.4172\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 413/1000] Train Loss: 0.0340  |  Val Loss: 0.4175\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 414/1000] Train Loss: 0.0338  |  Val Loss: 0.4177\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 415/1000] Train Loss: 0.0336  |  Val Loss: 0.4169\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 416/1000] Train Loss: 0.0334  |  Val Loss: 0.4168\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 417/1000] Train Loss: 0.0332  |  Val Loss: 0.4158\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 418/1000] Train Loss: 0.0329  |  Val Loss: 0.4163\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 419/1000] Train Loss: 0.0328  |  Val Loss: 0.4166\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 420/1000] Train Loss: 0.0325  |  Val Loss: 0.4158\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 420 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_input_dim = sclsdl_mlp_train_reps.shape[1]\n",
    "sclsdl_mlp_num_classes = len(torch.unique(sclsdl_mlp_train_labels_torch))\n",
    "sclsdl_mlp_model = MLPClassifier(sclsdl_mlp_input_dim, sclsdl_mlp_num_classes).to(device)\n",
    "\n",
    "sclsdl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "sclsdl_mlp_optimizer = optim.Adam(sclsdl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "sclsdl_mlp_num_epochs = 1000\n",
    "sclsdl_mlp_patience = 100\n",
    "\n",
    "sclsdl_mlp_train_losses = []\n",
    "sclsdl_mlp_val_losses = []\n",
    "\n",
    "sclsdl_mlp_best_val_loss = float('inf')\n",
    "sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for sclsdl_mlp_epoch in range(sclsdl_mlp_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_mlp_model.train()\n",
    "    sclsdl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for sclsdl_mlp_embeddings_batch, sclsdl_mlp_labels_batch in sclsdl_mlp_train_loader:\n",
    "        sclsdl_mlp_embeddings_batch = sclsdl_mlp_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_labels_batch = sclsdl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        sclsdl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        sclsdl_mlp_outputs = sclsdl_mlp_model(sclsdl_mlp_embeddings_batch)\n",
    "        sclsdl_mlp_loss = sclsdl_mlp_criterion(sclsdl_mlp_outputs, sclsdl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        sclsdl_mlp_loss.backward()\n",
    "        sclsdl_mlp_optimizer.step()\n",
    "        \n",
    "        sclsdl_mlp_train_running_loss += sclsdl_mlp_loss.item() * sclsdl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    sclsdl_mlp_epoch_train_loss = sclsdl_mlp_train_running_loss / len(sclsdl_mlp_train_loader.dataset)\n",
    "    sclsdl_mlp_train_losses.append(sclsdl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_mlp_model.eval()\n",
    "    sclsdl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sclsdl_mlp_val_embeddings_batch, sclsdl_mlp_val_labels_batch in sclsdl_mlp_val_loader:\n",
    "            sclsdl_mlp_val_embeddings_batch = sclsdl_mlp_val_embeddings_batch.to(device)\n",
    "            sclsdl_mlp_val_labels_batch = sclsdl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            sclsdl_mlp_val_outputs = sclsdl_mlp_model(sclsdl_mlp_val_embeddings_batch)\n",
    "            sclsdl_mlp_val_loss = sclsdl_mlp_criterion(sclsdl_mlp_val_outputs, sclsdl_mlp_val_labels_batch)\n",
    "\n",
    "            sclsdl_mlp_val_running_loss += sclsdl_mlp_val_loss.item() * sclsdl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    sclsdl_mlp_epoch_val_loss = sclsdl_mlp_val_running_loss / len(sclsdl_mlp_val_loader.dataset)\n",
    "    sclsdl_mlp_val_losses.append(sclsdl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {sclsdl_mlp_epoch+1}/{sclsdl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {sclsdl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {sclsdl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if sclsdl_mlp_epoch_val_loss < sclsdl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_mlp_best_val_loss:.4f} to {sclsdl_mlp_epoch_val_loss:.4f}.\")\n",
    "        sclsdl_mlp_best_val_loss = sclsdl_mlp_epoch_val_loss\n",
    "        sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "\n",
    "    else:\n",
    "        sclsdl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {sclsdl_mlp_epochs_without_improvement}/{sclsdl_mlp_patience}\")\n",
    "        \n",
    "        if sclsdl_mlp_epochs_without_improvement >= sclsdl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {sclsdl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {sclsdl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(sclsdl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(sclsdl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:05.248415Z",
     "iopub.status.busy": "2025-05-08T19:17:05.248415Z",
     "iopub.status.idle": "2025-05-08T19:17:05.387339Z",
     "shell.execute_reply": "2025-05-08T19:17:05.387339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SCL_SDL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.3262 | Test Accuracy: 88.82%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_model.eval()\n",
    "\n",
    "sclsdl_mlp_test_running_loss = 0.0\n",
    "sclsdl_mlp_test_correct = 0\n",
    "sclsdl_mlp_all_predictions = []\n",
    "sclsdl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_mlp_test_embeddings_batch, sclsdl_mlp_test_labels_batch in sclsdl_mlp_test_loader:\n",
    "        sclsdl_mlp_test_embeddings_batch = sclsdl_mlp_test_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_test_labels_batch = sclsdl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_mlp_test_outputs = sclsdl_mlp_model(sclsdl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        sclsdl_mlp_test_loss_batch = sclsdl_mlp_criterion(sclsdl_mlp_test_outputs, sclsdl_mlp_test_labels_batch)\n",
    "        sclsdl_mlp_test_running_loss += sclsdl_mlp_test_loss_batch.item() * sclsdl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, sclsdl_mlp_test_predicted = torch.max(sclsdl_mlp_test_outputs, dim=1)\n",
    "        sclsdl_mlp_test_correct += (sclsdl_mlp_test_predicted == sclsdl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        sclsdl_mlp_all_predictions.extend(sclsdl_mlp_test_predicted.cpu().numpy())\n",
    "        sclsdl_mlp_all_true_labels.extend(sclsdl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_predictions.npy'), np.array(sclsdl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_true_labels.npy'), np.array(sclsdl_mlp_all_true_labels))\n",
    "print(f\"Saved SCL_SDL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "sclsdl_mlp_epoch_test_loss = sclsdl_mlp_test_running_loss / len(sclsdl_mlp_test_loader.dataset)\n",
    "sclsdl_mlp_test_accuracy = sclsdl_mlp_test_correct / len(sclsdl_mlp_test_loader.dataset)\n",
    "\n",
    "sclsdl_mlp_test_accuracy_pct = sclsdl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {sclsdl_mlp_epoch_test_loss:.4f} | Test Accuracy: {sclsdl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "sclsdl_mlp_num_epochs_run = len(sclsdl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         [sclsdl_mlp_epoch_test_loss]*sclsdl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Results and Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:05.389954Z",
     "iopub.status.busy": "2025-05-08T19:17:05.388947Z",
     "iopub.status.idle": "2025-05-08T19:17:05.394480Z",
     "shell.execute_reply": "2025-05-08T19:17:05.394480Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_conf_matrix(model_name, class_names = None, cm_save_dir='confusion_matrices'):\n",
    "    os.makedirs(cm_save_dir, exist_ok = True)\n",
    "\n",
    "    #loading predictions and true labels\n",
    "    predictions_path = os.path.join(predictions_dir, f'{model_name}_predictions.npy')\n",
    "    true_labels_path = os.path.join(predictions_dir, f'{model_name}_true_labels.npy')\n",
    "\n",
    "    if not os.path.exists(predictions_path) or not os.path.exists(true_labels_path):\n",
    "        print(f\"Error: Files not found for model {model_name}\")\n",
    "        return\n",
    "    \n",
    "    cm_predictions = np.load(predictions_path)\n",
    "    cm_true_labels = np.load(true_labels_path)\n",
    "\n",
    "    conf_matrix = confusion_matrix(cm_true_labels, cm_predictions)\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    conf_matrix_normalised = conf_matrix.astype('float') / conf_matrix.sum(axis = 1)[:, np.newaxis]\n",
    "    sns.heatmap(conf_matrix_normalised, annot=conf_matrix, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "    plt.title(f\"{model_name.upper()} Confusion Matrix\", fontsize=16)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    cm_save_path = os.path.join(cm_save_dir, f'{model_name}_confusion_matrix.png')\n",
    "    plt.savefig(cm_save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved confusion matrix to: {cm_save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "    print(f\"Classification Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:05.396499Z",
     "iopub.status.busy": "2025-05-08T19:17:05.396499Z",
     "iopub.status.idle": "2025-05-08T19:17:10.280330Z",
     "shell.execute_reply": "2025-05-08T19:17:10.280330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving confusion matrices to: confusion_matrices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\e2e_cnn_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 96.58%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 78.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 52.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 88.58%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 88.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 88.72%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAMWCAYAAABIgshOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADEPUlEQVR4nOzdd1RUR8MG8GdZaaIigqKoCBZQxIBiB3uJGrsSja8lauzGFhtiN4q9xBaNNWqMLSbGqLH3Enss2AsWkI4FBFnu94cfG1eWsrLsvaPP75x7jtz6MPcuzs7OzKokSZJARERERESKYyZ3ACIiIiIi0o+VdSIiIiIihWJlnYiIiIhIoVhZJyIiIiJSKFbWiYiIiIgUipV1IiIiIiKFYmWdiIiIiEihWFknIiIiIlIoVtaJiIiIiBSKlXUioo9AVFQUevXqhaJFi0KtVkOlUmHixIkmu/6DBw+gUqng4uJismt+ytasWQOVSoWvv/5a7ihElMNYWaePSkhICIYNGwZPT0/Y2NjA2toazs7OqFmzJkaMGIG///47w+OvXLmCwYMH47PPPoOdnR0sLCzg6OiIRo0aYd68eYiKitLZ//Dhw1CpVFCpVAblvH79Ovr06QM3NzdYW1vDxsYGrq6uqFu3LsaNG4eTJ0+mOcbFxUV7LZVKBTMzM+TLlw/FixdHo0aNMHbsWFy/fj3D69atWzfHKnETJ07UZnN0dERycnK6+0ZFRcHCwkK7/5o1a3S2p1ZEslrxS60ovr/kzZsXXl5eGDNmDCIjIz/4dzP0uZBDq1atsGLFCrx69QqVK1eGr68vnJ2d5Y6lKO8/J3/++WeG+7dp00a7b926dY2S4dKlS5g4cSJ+//13o5yPiD4BEtFH4sCBA1LevHklAJJarZZcXFykqlWrSqVLl5ZUKpUEQLK3t9d7bHJysvTtt99KZmZmEgApV65cUtmyZaUqVapIzs7OEgAJgGRrayvt27dPe9yhQ4e027Jq/fr1koWFhQRAMjc3l0qVKiVVqVJFKlGihPZcPj4+aY5L3V6mTBnJ19dX8vX1lXx8fHSOAyC1a9dOioyM1HvtOnXqSACkCRMmZDlvVk2YMEEnx19//ZXuvosWLdLZd/Xq1TrbV69eLQGQSpQokaVr379/X3uuypUra8vHxcVFe++LFi0q3bt3z6Df6UOfC1O7fPmy9neMjY2VJcPjx48ld3d3qX79+rJcPyvefU4ASP7+/unuGx0drX2dApDq1KljlAypz3a3bt2ydZ7ffvtNcnd3l0aPHm2UXESkXGxZp4/C8+fP0aFDB7x48QJffPEF7t69i/v37+PMmTO4ffs2oqOjsWbNGlSrVk3v8Z06dcLChQthY2ODBQsWICoqCsHBwfjnn3/w8OFD3L9/H6NHj8abN29w9erVD8754MED9OzZE0lJSejRowceP36MO3fu4J9//sGDBw8QGhqKRYsWwcPDI91zjBkzBsePH8fx48dx7tw5PHjwABEREZg/fz4cHBywbds2+Pn5IS4u7oNzZoe7uzsAYN26denus27dOqhUKpQpU8bo19+yZYu2fO7fv49z586hRIkSePLkCfr162fQuUz1XGTXjRs3AAC+vr6wtbWVJUPRokVx48YNHDhwQJbrG0KtVqNUqVL4888/032dbNq0CUlJSdrnWWnatGmDGzduICgoSO4oRJTDWFmnj8KuXbsQGRmJfPnyYfPmzShRooTO9vz586Nbt27466+/0hy7YsUKbN68GdbW1jh06BAGDRqEfPny6ezj4uKCoKAgnD17FqVLl/7gnL/++isSExPh7u6On376CYUKFdLZXrhwYQwYMAA///yzQed1cHDA4MGDce7cORQpUgQ3btzAkCFDPjhndvj6+sLFxQV//PEHXrx4kWb7nTt3cObMGdSpU8ck3TQqVaqEefPmAQD27t2b5S4rpnwusishIQEAYG1tLVsG0XTu3BmvX7/G1q1b9W5fv349VCoV/ve//5k4GRGRLlbW6aNw7949AICbmxty586d5eM0Gg2mTp0KABg/fjx8fHwy3N/DwwPNmzfPds4KFSrAzMz4L78SJUpgyZIlAN5WNh49emT0a2QmtYKTkJCAbdu2pdme2uLeuXNnk2WqXbs2AECSJNy9ezfT/Y31XJw8eRJt27aFo6MjLCwsUKxYMXTt2hXBwcF6z5M6puDw4cO4ceMG/P394eDgAGtra/j4+GDz5s06+6eOmUgdZLh27VqdPtmpMhtXkToe4sGDBzrro6KiMHz4cJQtWxZWVlawsbGBi4sLmjRpon3OUmU2wDQqKgojR46Eu7s7rK2tYWdnh7p162LDhg2QJCnN/u8OoExMTMTEiRNRunRpWFlZoXjx4hg2bBhevXqV7u+UmdTnT98nQPfv38eJEyfg6+sLV1fXdM9x+vRpjBw5EpUrV0ahQoVgaWmJ4sWLo0uXLrh27Vqa/V1cXNC9e3cAae/Vu33i330OLl26hPbt28PR0RFmZmba8R36BpgmJiaiQoUKUKlUmDJlSprrS5KEevXqQaVSoXfv3lkpJiJSAFbW6aOQ2uJ5+/ZtxMbGZvm4M2fO4MGDB8iVK5dJ/vNKzXnp0iW8efMmR67RsmVLODk5ITk5GXv37s2Ra2SmS5cuAN6+YXjfhg0bYGVlhfbt25ssj77KYEaM8VwsXboUfn5+2L59OwDAy8sLr169wrp161CpUiW9n/KkOn/+PKpUqYK///4bLi4uyJs3Ly5cuIAOHTrolKmtrS18fX213YkKFSoEX19f7ZIdcXFxqFatGubMmYP79++jVKlSKFu2LBISErB3716MGTMmy+e6c+cOKlasiFmzZuHBgwfw8PBAgQIFcOTIEXTu3Blff/11uvfozZs3aNy4MSZPngwrKyu4uLjg6dOnmDdvHtq0afPBv1/p0qVRvXp1HD16FCEhITrbUss49TlOT+fOnbW/k6OjI8qVK4cXL15g/fr1qFKlCg4fPqyzf5UqVdK9VxUqVEhz/qNHj6J69er4+++/Ubx48QzfOACApaUl1q1bBwsLC0yePBlnz57V2T5nzhwcPnwYpUqVwty5czM8FxEpiKw95omM5ObNm9pBgD4+PtLWrVuzNNBu1qxZEgDJ29v7g65r6ADTffv2afdv0KCBtGvXLunVq1dZOjZ1IOn7gzH1adeunQRA6tOnj856Uwww7dmzpyRJklSlShXJzMxMevz4sXafEydOSACkL7/8UpIkSWrQoIHRB5jev38/zfbffvtNAiCpVCopIiIi0/Nl97m4ePGilCtXLgmANHPmTEmj0UiSJEmvX7+W+vfvrx2U+vTpU53jUu+Pubm5NHDgQCkhIUGSJElKSUmRRo0aJQGQnJycpOTkZJ3jMhu0mNkzmvpsvVt2s2fPlgBIjRs3lqKionT2f/jwoTRv3jyddan34P17lpKSIlWuXFk7SDMsLEy7bffu3ZKNjY0EQFqyZIne38nc3Fzy8PCQbt68qd126tQpKV++fBIAaffu3en+Xu9LzahWqyVJkqTFixdLAKRp06bp7Ofm5iZZWlpK0dHR0rp169IdYLp27Vrp7t27OuvevHkjrVixQsqVK5dUsmRJ7b1///fKaIBp6nOgVqul3r176/yNiI+Pz/Q8QUFBEgDJzc1Ne+yVK1ckS0tLSa1WSydPnkz32kSkPGxZp4+Cm5ub9mPf8+fPo3379rCzs0PZsmXRvXt3bNq0CYmJiWmOe/LkCQBk2mJlLA0bNtS21B44cADNmjWDra0tvLy80LdvX+zcuRMajSbb1ylevDgAIDw8PNvn+lCdO3dGSkoKNmzYoF0nRxeYixcvYujQoQCA+vXrw8HBIdNjsvtczJ49G8nJyWjVqhVGjBih7fJkaWmJRYsWoXz58oiLi8PSpUv1Hu/h4YEFCxbAysoKALTdGgoXLoynT5/i33///aBchrh9+zYAYMCAAShQoIDONmdn5yyPiThw4ADOnTsHS0tL/Prrr3B0dNRua9KkCSZMmAAAmDFjht7W9eTkZKxduxZubm7addWrV8c333wDANi9e7dBv9e7OnToAHNzc52uMGfOnMGtW7fwxRdfwM7OLsPju3btipIlS+qsy5UrF3r27ImOHTvi3r17OH369Afn8/T0xNKlS3W69mVlXMLIkSPh5+eHW7duYfjw4UhKSkLnzp2RmJiIgIAA1KhR44MzEZHpsbJOH40xY8bg4MGDaNasGSwsLCBJEm7evIk1a9agY8eOcHNzS/OxdOoASBsbG5PlXLZsGbZt24Y6depArVYjOTkZ//77L5YtW4YWLVrAy8sLV65cydY1Un8ffQM8TeWrr75Crly5tF0KkpKSsHnzZjg4OKBJkyY5dl1/f3/4+fnBz88PJUuWhI+PDx4+fAhHR8d0K8fvy+5zkdr96Ntvv02zTaVSYdCgQTr7va9Hjx5pxjSYm5vDy8sLwH9jH3JS6hu+7du3ZzhnfmZSf0d/f38ULlw4zfa+ffvC0tISDx8+xM2bN9Ns9/b2RuXKldOsr1KlCoDslYW9vT2aNm2K4OBgXLhwAUDWu8CkunHjBiZMmIC2bduibt262mfvyJEjAIDLly9/cL7OnTt/0NgWMzMz/Pzzz8ibNy+WLl2KL774ApcvX4aPjw/Gjx//wXmISB6srNNHpV69evjrr78QGxuLo0ePYtasWdoBVSEhIWjWrJl2mjsAyJs3LwBka6Dah2jbti0OHz6M6Oho7Nu3D1OmTEHVqlUBANeuXUPDhg0RERHxwed/+fIlAKSZvcSUChYsiMaNG+PKlSu4fPkydu3ahejoaG1rZk45d+4cTpw4gRMnTiAsLAzlypXD8OHDcfny5SxPFZmd5yI2NlZ779KbgrN8+fIAgFu3bundXqpUKb3rU2cPSr2/Oal79+6wtbXFmjVrUKxYMXz99ddYuXKlwZXj1N8xvbLImzev9o2BvvLI6bJ4d6BpcnIyNm3ahAIFCqBZs2aZHhsUFITy5ctj8uTJ2L59O44cOaJ99lIHd0dHR39wtnLlyn3wsa6urpg/fz4AYP/+/bC2tsb69etz9LVHRDmDlXX6KFlbW6NWrVoYPnw4Dh48iKNHj8LGxgYJCQmYM2eOdr+iRYsCeDv7gxzy5cuHhg0bYuzYsThz5gy2bNkCMzMzhIeHY/ny5R983tQBc+9PDWlq7w40NbTF8kPdv38fkiRBkiTEx8fj2rVrmDVrlk73i8xk57l4t/KYXvmnZknvk4/0WvRTW1n1dRcxNicnJ5w6dQrt2rVDXFwc1q5di2+++QalSpVCjRo1cOrUqSydJ7U8MnoWMyqPnC6LFi1awNbWFhs3bsTOnTsRERGBL7/8EhYWFhked/ToUYwZMwYqlQpBQUG4du0aXr58iZSUFEiShMDAQADI1kDy7H7iV7t2beTKlQsAUKNGDZQtWzZb5yMiebCyTp8EPz8/9O/fHwDwzz//aNfXrFkTAHD16tVstYAZS/v27dGuXTsAujkNkZKSoq1IpbbWy6VVq1bIly8f1q1bh507d6JMmTLpfjGVkmTnuciTJ4/23+mNGXj27BmA/1rwTSW9im16nyCUK1cOW7duRWxsLA4dOoSJEyeibNmyOH36NBo3bpxmqkd9Ussjo/ETcpUHAFhZWcHf3x/Pnj3D4MGDAWTtDWXqWIwRI0Zg9OjR8PDwgI2NjXaKTDmmTX2XRqNB165dkZycDDMzMxw8eFBn/AgRiYOVdfpkpA4ES0pK0q6rVq0aXFxckJycnK2WbGPSl9MQv//+O8LCwmBubo7GjRsbM5rBrK2t0bZtWzx79gyJiYkmHViaHdl5LvLnz4+CBQsCAK5fv653n9Q5uN8dNJmTUlto9XWtiouLQ2RkZIbHW1paom7dupgwYQKuXr0KX19fvHz5Ehs3bsz02qm/Y3pl8eLFC23F1lTl8b7U5zIkJAQlS5bUvlnLSOoblfT2Ta+vekbz3RvTtGnTcOrUKZQvXx6bNm0CAAwcOFD2NxFEZDhW1umjEBkZmenH4SdPngQAnX7LarUaAQEBAIApU6ZoB5mlJzg4GDt37vzgnFmZnUVfzqx6+PAhBg4cCODtTBWp3Tnk1Lt3bzRo0AANGjTI8S4wxpLd5+Lzzz8HACxcuDDNvpIkaden7pfTUt8Avj/vNvD2m1oNoVartYM7nz59mun+qb/jli1bEBYWlmb7smXLkJiYiBIlSsDd3d2gLMZSu3ZttG3bFg0aNMCIESOydEzqrCypnwq8a+/evelW1lOPS/3W2Zxw/vx5TJkyBebm5li/fj3at2+PXr16ITY2NsM57YlImVhZp4/C+vXr4e3tjZ9++inN18nHxsZi/Pjx2j7Tqd8gmKp3795o164d4uPjUa9ePSxcuDBN39lHjx5h7NixqFy5Mu7cufPBOadNm4ZatWph48aNaa4RGhqKvn374tixY1CpVOjWrVuWzxsZGYkffvgBlStXRmhoKDw8PBTzpSc1atTA/v37sX//fpNNkWkM2XkuvvvuO+TKlQt//PEH5syZg5SUFABvPy0ZPHgwrl69CltbW/Tr188kv0vTpk0BAGPHjtWpXO7ZsweTJ0/W9mt+V2BgIFauXJnmS8auXr2q/SbVSpUqZXrt+vXro0qVKkhMTMRXX32l84Z17969mDRpEgBg9OjRJmt1fp9KpcK2bduwf/9+9O3bN0vH+Pn5AQCmT5+uM7bh7Nmz6NGjh3bazfe9+8YpPj4+m8nTSkhIQJcuXfDmzRtMmjQJ3t7eAIC5c+eiVKlSOHjwIBYsWGD06xJRDpJpfncio5o/f772i18ASK6urlLVqlWlMmXKSBYWFtr1w4cP13v8mzdvpP79+0sqlUr7RSzlypWTqlatKrm4uGiPL1CggHTgwAHtce9+KZK9vX26S926dSVJkqQhQ4Zo9zczM5PKlCkjVa1aVXJ1ddV+iY5arZYWLFiQJmPqF9eUKVNG8vX1lXx9faXKlSvr5AMg+fv7p/kSm1SpX7ZibW2dYd5du3YZfA/e/1KkrMjsS5HMzMwyzNmlSxdJkjL/UqQP9aHPhSRJ0pIlS7THOTo6SlWqVJHy588vAZAsLS2lnTt3prle6v05dOiQ3jzdunXLsLzS+6Kd8PBwqXDhwtpre3t7a/OPHj1a75citWrVSnsPSpcuLVWtWlUqXbq09neuV6+e9ObNG+3+6X0pkiRJ0u3bt6VixYppr1+pUiWdc3Xp0kVKSUkx6HdKfe3p+7Ki9Lz/pUhZkd6XIsXFxUklS5aUAEgWFhZShQoVJHd3dwmA5OHhIQ0bNkzvF5BpNBqpTJky2r8ZNWrUkOrUqSMNHjxYu09mz4EkpV8+3377rQRAqlmzZpovzzpx4oSkVqslKysr6fr161kuAyKSF1vW6aPQv39/HDx4ECNGjEDNmjWh0Whw6dIlPHnyBCVKlEDXrl1x7NgxzJo1S+/xuXLlwuLFi3Hp0iUMHDgQbm5uePr0KS5evIj4+Hg0aNAACxYswN27d1G/fn2954iKikp3iYmJAfC2Zf2vv/7CwIED4ePjg1evXuHixYuIiIiAm5sb+vbtiwsXLmjn4dbn9u3b2unhbty4geTkZDRs2BCBgYG4fv06Nm/enOZLbN6XkJCQYV59XyAlh5SUlAxzPn/+PEevn53nol+/fjh27Bhat26NlJQUXLp0Cblz50bnzp1x4cIFfPHFFzma/V0FCxbEiRMn4O/vj9y5c+PmzZuws7PD6tWrERQUpPeYsWPHYvTo0ahSpQpevnyJS5cuISEhAXXq1MHPP/+MvXv36m2R16d06dK4ePEihg8fDmdnZ1y7dg3h4eGoXbs21q1bh7Vr18rWqv6h8uXLh+PHj6Nr167Ily8fbt68iaSkJAwbNgynTp1Kd7CsmZkZ/vrrL7Rv3x5qtRr//PMPjhw5gkuXLmU70/79+7Fo0SLY2Njg559/hlqt1tles2ZNjBo1Cq9fv0bnzp2zNVMNEZmOSpLYeY2IiIiISInYsk5EREREpFCsrBMRERERKVTWOhwS0SfF398foaGhWdq3WbNmGDNmTA4nIiIi+jSxsk5EaZw9exYPHz7M0r6lS5fO4TRERETyO3r0KGbNmoXz588jNDQU27dvR+vWrTM85siRIxg2bBiuXbsGJycnjBw5MstTxKZiNxgiSuPBgweQJClLy5o1a+SOS0RElONevXoFLy8vLFq0KEv7379/H82aNUOtWrVw8eJFjBkzBoMGDcK2bdsMui5ngyEiIiIiMoBKpcq0ZX3UqFHYsWMHgoODtev69u2Ly5cv49SpU1m+FlvWiYiIiOiTlJiYiOfPn+ssxvqukVOnTqFx48Y66z7//HOcO3fOoO85+Gj7rFv7DJY7QpbEnOHXPn9KUgT5IMtMsC+oISKi9FkprLZnXXGg3BG0RrVywKRJk3TWTZgwARMnTsz2ucPCwuDo6KizztHREcnJyYiMjESRIkWydB6F3T4iIiIiItMICAjAsGHDdNZZWloa7fzvfztzau9zQ761mZV1IiIiIvokWVpaGrVy/q7ChQsjLCxMZ114eDhy5coFe3v7LJ+HlXUiIiIiMh3VpzFkskaNGvjzzz911u3duxeVK1eGubl5ls/zaZQWEREREVE2vHz5EpcuXcKlS5cAvJ2a8dKlSwgJCQHwtktN165dtfv37dsXDx8+xLBhwxAcHIxVq1Zh5cqVGD58uEHXZcs6EREREVEmzp07h3r16ml/Tu3r3q1bN6xZswahoaHaijsAuLq6YteuXRg6dCgWL14MJycn/PDDD2jXrp1B1/1o51nnbDCkRJwNhoiITE1xs8EoqI6WcF759TB2gyEiIiIiUihW1omIiIiIFEphH4wQERER0UftE5kNxlhYWkRERERECsWWdSIiIiIyHU5iYBC2rBMRERERKRQr60RERERECsVuMERERERkOhxgahCWFhERERGRQrGyTkRERESkUOwGQ0RERESmw9lgDMKWdSIiIiIihfqkK+vDuzfE8Z+/Q/jRGXi473tsntMTZUoUSnf/hWO+RML5BRj4VZ0066/9MQ7RJ2YhZP9UbJ7zDdxc0j9PTtm0cQOaNq6PKhUroKN/W1w4f87kGTIjQkZA2TlX/rQM/+vQHr5VK6F+7ZoYOmgAHty/J3esdCm5LFOJkBEQI6cIGQExcoqQERAjpwgZAXFyZpvKTDmLAMRImUNqVSqNH7ccQ52v56F5/yVQq9XYubgfcltZpNm3Rd0KqOJZAk/DY9Nsuxj8CL0n/gLv9kFoOXApVCpg5+L+MDMz3cc8e3bvwszpQejVux82bf0dlSr5oH+fXgh9+tRkGTIjQkZA+TkvnDuLDl91ws+/bMLS5augSU5Gv97fICE+Xu5oaSi9LAExMgJi5BQhIyBGThEyAmLkFCEjIE5OMj2VJEmS3CFygrXPYIOPcchvg0cHpqHhNz/gxMW72vVOBW1xdO0wtBi4FNsX9MaiX45g0cYj6Z7Hs7QTzm4aBY9Wk3H/cVSG14w5s8DgnPr8r6M/ynl4YOz4Sdp1rVs0Rb36DTF46HdGuUZ2iZARyNmcKTnwcouOjkaD2jWxYs06+FSuYpRzmhmpP6EI91yEjIAYOUXICIiRU4SMgBg5RcgI5GxOK4WNULSuPkruCFoJp2fIHSFTn3TL+vvy5bEGAMQ8/6+FUqVSYeWUzpi37iCC74Vleo7cVhbo2rIa7j+OxOOw2JyKquNNUhKCr19DjZp+Outr1PTF5UsXTZIhMyJkBMTJ+a6XL18AAGxtbWVOokuEshQhIyBGThEyAmLkFCEjIEZOETIC4uQ0GpVKOYsAFPZeS14zhrXGiYt3cf1uqHbdd183QLImBYszaEkHgN7+fpg6qCXy5LbEjfth+GLAErxJ1uR0ZABATGwMNBoN7O3tddbb2zsgMjLCJBkyI0JGQJycqSRJwpyZ01Gxkg9Kl3GTO44OEcpShIyAGDlFyAiIkVOEjIAYOUXICIiTk+Sh+Jb1R48eoUePHhnuk5iYiOfPn+ssUkqyQdeZN6o9KpRxQrcxa7XrKpYthgEd66D3hA2ZHv/r7nOo3mkWGn7zA+6ERGD99O6wtDDteyHVe+8QJUlKs05uImQExMk5feoU3L51E0Ez58gdJV0ilKUIGQExcoqQERAjpwgZATFyipARECcnmZbiK+vR0dFYu3ZthvsEBQXB1tZWZ0kOy/oI6rkj2qF5bU983mcRnoTHadf7ViyFQgXy4NZfE/HizFy8ODMXJZzsMX1oa9z4c7zOOZ6/fI27jyJw4uJddBq5Gu4uhdCq3meG/bIfyC6/HdRqNSIjI3XWR0dHwd7ewSQZMiNCRkCcnAAwfdoUHDl0ED+t+hmOhQvLHScNEcpShIyAGDlFyAiIkVOEjIAYOUXICIiT02jkngGGs8EYZseOHRkuhw4dyvQcAQEBiIuL01lyFa6cpevPG9kOrep/hiZ9F+Ph02idbb/sOosqHWeiWqdZ2uVpeCzmrTuIFgN/zPC8KpUKFiZqWTe3sEA5j/I4ffKEzvrTJ0/Cy7uiSTJkRoSMgBg5JUnC9KmTcXD/PixbtQZFixWTO5JeIpSlCBkBMXKKkBEQI6cIGQExcoqQERAnJ8lD9j7rrVu3hkqlQkaT0mT2EZClpSUsLS11jzHL/FebP9ofHZpUgv+wFXgZ/xqO9nkBAHEvX+N14htEx8UjOk53Orw3yRo8i3yO2w/DAQAuRe3RvnFFHDh1A5Gxr+BU0Bbffd0ACa/f4O/j1zPNYCxdunVH4OiR8PD0hJdXRWzbsgmhoaHw79DRZBkyI0JGQPk5g76fjN27dmLeD4thY2Oj7c+YJ09eWFlZyZxOl9LLEhAjIyBGThEyAmLkFCEjIEZOETIC4uQk05O9sl6kSBEsXrwYrVu31rv90qVL8PHxyZFr9/F/O+p630+DdNb3mrgB6//8J0vnSEx8A1/vUhj4VV3Y5bNGeNQLHL94F/V6zEdEzEujZ05Pk6bNEBcbg+VLlyAiIhyly7hh8Y/L4eRU1GQZMiNCRkD5Obds2ggA6NW9q876Sd9PQ8vWbeWIlC6llyUgRkZAjJwiZATEyClCRkCMnCJkBMTJaRTsh28Q2edZb9myJby9vTF58mS92y9fvoyKFSsiJSXFoPN+yDzrcjDWPOskhpyYZz0nGGuedSIikp/i5ln3DZQ7glbCialyR8iU7LdvxIgRePXqVbrbS5cunaV+60REREQkAEEGdiqF7JX1WrVqZbjdxsYGderUMVEaIiIiIiLl4FsbIiIiIiKFkr1lnYiIiIg+IRwXZRC2rBMRERERKRQr60RERERECsVuMERERERkOpwNxiAsLSIiIiIihWJlnYiIiIhIodgNhoiIiIhMh91gDMLSIiIiIiJSKLasExEREZHpmHGedUOwZZ2IiIiISKFYWSciIiIiUih2gyEiIiIi0+EAU4OwtIiIiIiIFIqVdSIiIiIihWI3GCIiIiIyHRVngzEEW9aJiIiIiBSKlXUiIiIiIoX6aLvBxJxZIHeELLFrPFXuCJmK2Rsod4SPxqtEjdwRsiSv1Uf7p4GIiOTG2WAMwtIiIiIiIlIoNp8RERERkelwgKlB2LJORERERKRQrKwTERERESkUu8EQERERkelwgKlBWFpERERERArFyjoRERERkUKxGwwRERERmQ5ngzEIW9aJiIiIiBSKLetEREREZDocYGoQlhYRERERkUKxsk5EREREpFDsBkNEREREpsMBpgZhyzoRERERkUKxsk5EREREpFDsBkNEREREpsPZYAzC0iIiIiIiUihW1omIiIiIFIqV9SzYtHEDmjaujyoVK6Cjf1tcOH9O1jw3fhmAhIOBaZZ5gz4HALSq5Y4dMzri0fahSDgYiM9KOcqa911KK8v0KD3nymWL4edTXmdp2bi23LH0UnpZAmJkBMTIKUJGQIycImQExMgpQkZAnJzZplIpZxEAK+uZ2LN7F2ZOD0Kv3v2waevvqFTJB/379ELo06eyZfLrtxou7eZrl2bDNwAAfjsSDADIbWWOU1cfY9xPh2TLqI8Sy1IfUXK6liqNP/4+rF3Wbvpd7khpiFCWImQExMgpQkZAjJwiZATEyClCRkCcnGR6rKxnYt3a1WjTrh3atvdHyVKlMDIgEIWLFMbmTRtlyxQZF49nMa+0S7MaZXD3STSOXQ4BAGzcdxVB647j4Pn7smXUR4llqY8oOdVqNewdCmoXO7sCckdKQ4SyFCEjIEZOETICYuQUISMgRk4RMgLi5DQKlZlyFgGIkVImb5KSEHz9GmrU9NNZX6OmLy5fuihTKl3muczQsaEn1u6+LHeUDIlQloA4OQHgcUgIWn1eF/4tGmNCwHA8efxI7kg6RChLETICYuQUISMgRk4RMgJi5BQhIyBOTpIHp27MQExsDDQaDezt7XXW29s7IDIyQqZUulr6uiN/Hius//tfuaNkSISyBMTJ6eH5GcZOnobizi6Ijo7C2pXL0K/H/7Bu8w7Y5s8vdzwAYpSlCBkBMXKKkBEQI6cIGQExcoqQERAnJ8lDEZX1hIQEnD9/HgUKFICHh4fOttevX2Pz5s3o2rVruscnJiYiMTFRZ52ktoSlpaVR8qneG4AgSVKadXLp1swLf/9zF6FRL+WOkiVKLst3KT1nDd9a2n+XAuD5mRc6tGqC3Tt/R8fOX8uWSx+llyUgRkZAjJwiZATEyClCRkCMnCJkBMTJmW2CdD9RCtlL69atWyhXrhxq166NChUqoG7duggNDdVuj4uLQ/fu3TM8R1BQEGxtbXWWWTOCsp3NLr8d1Go1IiMjddZHR0fB3t4h2+fPLmfHfKhfyRVr/rokd5RMKb0sU4mS833W1rlRsrQbHoeEyB1FS4SyFCEjIEZOETICYuQUISMgRk4RMgLi5CR5yF5ZHzVqFCpUqIDw8HDcvHkT+fLlg6+vL0IMqHQEBAQgLi5OZxkxKiDb2cwtLFDOozxOnzyhs/70yZPw8q6Y7fNnV5cmXgiPjcfu07fljpIppZdlKlFyvi8pKQkP79+DvYNy/qiLUJYiZATEyClCRkCMnCJkBMTIKUJGQJycJA/Zu8GcPHkS+/fvh4ODAxwcHLBjxw4MGDAAtWrVwqFDh2BjY5PpOSwt03Z5eZ1snHxdunVH4OiR8PD0hJdXRWzbsgmhoaHw79DROBf4QCoV0LWJFzbs/ReaFElnm11eKxQvZIsiDnkAAG7F384S8iz6JZ7FvDJ51lRKLcv3iZBz0bxZ8K1dF46FiyAmOhprV/6IV69eommL1nJH0yFCWYqQERAjpwgZATFyipARECOnCBkBcXIaxcfYtScHyV5ZT0hIQK5cujEWL14MMzMz1KlTB7/88otMyd5q0rQZ4mJjsHzpEkREhKN0GTcs/nE5nJyKypqrvo8rnB1t9c4C80VNN/w0qoX253Xj2wIAvl97FFPXHjNZxvcptSzfJ0LOiPBnmDhmBOJiY5DfrgDKV/gMy9b8gsJFnOSOpkOEshQhIyBGThEyAmLkFCEjIEZOETIC4uQk01NJkiRlvlvOqVq1Kr799lt06dIlzbaBAwdiw4YNeP78OTQajUHnNVbLek6zazxV7giZitkbKHeEj8YLQR7MvFayv48nIiIjUdqfdOuWS+WOoJWwo5/cETIle5/1Nm3aYONG/RP+L1q0CF999RVkfj9BRERERMYi9xchCfalSLK3rOcUQRow2bL+iWHLOhERmZrS/qRbt1omdwSthD/6yB0hUwq7fURERET0UeMAU4OI0f5PRERERPQJYmWdiIiIiEih2A2GiIiIiExHkIGdSsHSIiIiIiJSKFbWiYiIiIgUit1giIiIiMh0OBuMQdiyTkRERESkUGxZJyIiIiKTUbFl3SBsWSciIiIiUihW1omIiIiIFIrdYIiIiIjIZNgNxjBsWSciIiIiUihW1omIiIiIFIrdYIiIiIjIdNgLxiBsWSciIiIiUihW1omIiIiIFIrdYIiIiIjIZDgbjGFYWZdZzN5AuSNkyq7+RJkTZM3TPePkjpCpvFZ8yRF9KEmSO0HmWAchImNjzYGIiIiITIYt64Zhn3UiIiIiIoViZZ2IiIiISKHYDYaIiIiITIbdYAzDlnUiIiIiIoViZZ2IiIiISKHYDYaIiIiITIbdYAzDlnUiIiIiIoViZZ2IiIiISKHYDYaIiIiITIe9YAzClnUiIiIiIoViyzoRERERmQwHmBqGLetERERERArFyjoRERERkUKxGwwRERERmQy7wRiGLetERERERArFyjoRERERkUKxGwwRERERmQy7wRiGLetZsGnjBjRtXB9VKlZAR/+2uHD+nNyR9JIz5/D/+eH4sl4I3xOAh3+MwOapHVGmuL3OPq1ql8OO2Z3xaMdIJBydiM9KF87wnL/P/B8Sjk5EC7+yOZb74vlz+G5wfzRvVAfVK3rgyKH9OtsPHdiHwf174fN6NVG9ogdu3QzOsSyG4nNpPCJkBMTIqfSM58+dxaABfdGonh+8Pd1x8MD+zA+SidLLMpUIOUXICIiTk0yLlfVM7Nm9CzOnB6FX737YtPV3VKrkg/59eiH06VO5o+mQO2ctbxf8uP0s6vRdgebDfoZabYadc7ogt5W5dp/cVuY4deURxi3L/D/Hb/2rQ8rJwP8vISEeZdzc8d3osXq3v05IwGdeFdH/22EmSJN1ct/vrBIhpwgZATFyipAxISEebu7uGD1mvNxRMiRCWQJi5BQhIyBOTjI9VtYzsW7tarRp1w5t2/ujZKlSGBkQiMJFCmPzpo1yR9Mhd85WI9Zj/Z5LCH4QgSt3n6FP0O9wLpwfFd2dtPts3PsvgtYewcHz9zI8V4VSjhjUoQb6Tv8jp2Ojpl9t9B0wGPUaNNK7vWnzlujZpz+qVK+R41kMIff9zioRcoqQERAjpwgZ/WrVwcBBQ9GgUWO5o2RIhLIExMgpQkZAnJzGoFKpFLOIgJX1DLxJSkLw9WuoUdNPZ32Nmr64fOmiTKnSUmLOfHmsAAAxzxMMOs7a0hxrJ7TH0Pm78Cz6ZU5EE54S77c+IuQUISMgRk4RMopClLIUIacIGQFxcpI8OMA0AzGxMdBoNLC31+17bW/vgMjICJlSpaXEnDMGfo4Tlx/i+v1wg46b+e3nOH31EXYev5lDycSnxPutjwg5RcgIiJFThIyiEKUsRcgpQkZAnJxGI0aDtmIoorIeHByM06dPo0aNGihbtixu3LiBBQsWIDExEZ07d0b9+vUzPD4xMRGJiYk66yS1JSwtLY2S7/2PSSRJUuRHJ0rJOW9oM1Qo6YgGA1cZdNwXvu6oW8kV1Xsuy6FkHxel3O/MiJBThIyAGDlFyCgKUcpShJwiZATEyUmmJXs3mD179sDb2xvDhw9HxYoVsWfPHtSuXRt37txBSEgIPv/8cxw8eDDDcwQFBcHW1lZnmTUjKNvZ7PLbQa1WIzIyUmd9dHQU7O0dsn1+Y1FSzrmDm6K5rzs+H7IGTyKeG3Rs3UquKOlUAGF/jcaLg+Px4uDbAWAbp3yJvxd8nQNpxaSk+50REXKKkBEQI6cIGUUhSlmKkFOEjIA4OUkeslfWJ0+ejBEjRiAqKgqrV69Gp06d0KtXL+zbtw/79+/HyJEjMX369AzPERAQgLi4OJ1lxKiAbGczt7BAOY/yOH3yhM760ydPwsu7YrbPbyxKyTlvSDO0ql0OTYasxcPQWIOPn73hOKp0X4pqPX/ULgAwctHf6D39d+OGFZhS7ndmRMgpQkZAjJwiZBSFKGUpQk4RMgLi5DQWuQeVijbAVPZuMNeuXcPPP/8MAPjyyy/RpUsXtGvXTrv9q6++wsqVKzM8h6Vl2i4vr5ONk69Lt+4IHD0SHp6e8PKqiG1bNiE0NBT+HToa5wJGInfO+UO/QIeGFeA/ZiNexifBsUAeAEDcy9d4nfT2ZtjltUZxR1sUccgLAHBzfts371n0S53lfY+exX1Q5T8r4uNf4fGjEO3PT588wa2bwciXzxaFizghLi4Wz8JCERn+tu/9wwcPALztR2jvUDBHMmWF3Pc7q0TIKUJGQIycImSMj3+FkJD/XvNPnjzGjRvBsLW1RZEiThkcaVoilCUgRk4RMgLi5CTTk72y/i4zMzNYWVkhf/782nV58+ZFXFycbJmaNG2GuNgYLF+6BBER4Shdxg2Lf1wOJ6eismXSR+6cfdpUAQDsW9hdZ32vab9j/Z5LAN72Sf9pTGvttnUT/QEA368+jKmrD5siZhrB169hQK+vtT8vmDMDANCsRWuMnzwNx44cwvcTArXbx43+DgDQs09/9Oo70KRZ3yX3/c4qEXKKkBEQI6cIGa9dvYpePbpqf54z822XyRat2mDK1Iw/xTUlEcoSECOnCBkBcXKS6akkSTLFd8+ky8vLCzNmzECTJk0AAFevXkXZsmWRK9fb9xHHjx9H165dce9exnNzv89YLesE2NWfKHOCrHm6Z5zcETJlbaGWOwKRsOT93yprBPlUnT4xVopqmgUKdt8kdwStiNUd5I6QKdlvX79+/aDRaLQ/e3p66mzfvXt3prPBEBERERF9jGSvrPft2zfD7VOnTjVREiIiIiLKaaIM7FQK2WeDISIiIiIi/VhZJyIiIiJSKNm7wRARERHRJ4S9YAzClnUiIiIiIoViZZ2IiIiIKIuWLFkCV1dXWFlZwcfHB8eOHctw/w0bNsDLywu5c+dGkSJF0L17d0RFRWX5eqysExEREZHJqFQqxSyG2rRpE4YMGYLAwEBcvHgRtWrVQtOmTXW+Gfldqd8X1LNnT1y7dg1btmzB2bNn8c0332T5mqysExERERFlwdy5c9GzZ0988803KFeuHObPn4/ixYtj6dKlevc/ffo0XFxcMGjQILi6usLPzw99+vTBuXPnsnxNVtaJiIiI6JOUmJiI58+f6yyJiYl6901KSsL58+fRuHFjnfWNGzfGyZMn9R5Ts2ZNPH78GLt27YIkSXj27Bm2bt2KL774IssZWVknIiIiIpORu+vLu0tQUBBsbW11lqCgIL25IyMjodFo4OjoqLPe0dERYWFheo+pWbMmNmzYgA4dOsDCwgKFCxdG/vz5sXDhwiyXFyvrRERERPRJCggIQFxcnM4SEBCQ4THv93WXJCnd/u/Xr1/HoEGDMH78eJw/fx579uzB/fv30bdv3yxn5DzrRERERGQyHzKwM6dYWlrC0tIyS/s6ODhArVanaUUPDw9P09qeKigoCL6+vhgxYgQA4LPPPoONjQ1q1aqF77//HkWKFMn0umxZJyIiIiLKhIWFBXx8fLBv3z6d9fv27UPNmjX1HhMfHw8zM93qtlqtBvC2RT4rWFknIiIiIsqCYcOGYcWKFVi1ahWCg4MxdOhQhISEaLu1BAQEoGvXrtr9W7Rogd9++w1Lly7FvXv3cOLECQwaNAhVq1aFk5NTlq7JbjBEREREZDJK6gZjqA4dOiAqKgqTJ09GaGgoPD09sWvXLpQoUQIAEBoaqjPn+tdff40XL15g0aJF+O6775A/f37Ur18fM2bMyPI1VVJW2+AF8zpZ7gQfD7v6E2VOkDVP94yTO0KmrC3UckcgEpYI/1sJXAehj5iVwppmnfr8JncErafL2sodIVPsBkNEREREpFAKe69FRERERB81fgJlELasExEREREpFFvWKVPRBybKHSFLCtQeLXeETMUcmy53hCzRpCi/c7DajE0zxiJCX3CA/cE/NSI8l3wmyRRYWSciIiIikxF5Nhg5sBsMEREREZFCsWWdiIiIiEyGLeuGYcs6EREREZFCsbJORERERKRQ7AZDRERERCbDbjCGYcs6EREREZFCsbJORERERKRQ7AZDRERERKbDXjAGYcs6EREREZFCsbJORERERKRQ7AZDRERERCbD2WAMw5Z1IiIiIiKFYss6EREREZkMW9YNw5Z1IiIiIiKFYmWdiIiIiEih2A2GiIiIiEyG3WAMw5Z1IiIiIiKFYmU9CzZt3ICmjeujSsUK6OjfFhfOn5M7kl5Kz3n+3FkMGtAXjer5wdvTHQcP7Dd5Bl9vV2yd1Q33doxBwqnpaFHbQ2e7jbUF5n3XEnf+CED04Sm4uHEYerWplu75fp/bXe95TEHp93vLpo34sm1L1Krug1rVfdDtfx1w4thRuWPppfSyTKX0nEp4jWeV0ssSECMjoPycfC5JdKysZ2LP7l2YOT0IvXr3w6atv6NSJR/079MLoU+fyh1Nhwg5ExLi4ebujtFjxsuWwcbKHFduh2LonD/0bp85uDkaVXdD94mb4N1xLhb+ehxzh7VE81ppK+PfdvSDJEk5HVkvEe53IUdHDBryHdb/uhXrf92KKtWqY+igAbh757bc0XSIUJaAGDmV8BrPChHKUoSMgBg5+Vwqj0qlUswiAlbWM7Fu7Wq0adcObdv7o2SpUhgZEIjCRQpj86aNckfTIUJOv1p1MHDQUDRo1Fi2DHtP38Kk5Xvxx5FrerdX83TG+l0XcOziPYSExWDVH//g3zuhqFSuqM5+FUoXwaCOfug7daspYqchwv2uU7c+/GrXQQkXV5RwccXAQUORO3duXPn3stzRdIhQloAYOZXwGs8KEcpShIyAGDn5XJLoFFlZl6u18n1vkpIQfP0aatT001lfo6YvLl+6KFOqtETJKYKT/z5Ac79ycCqYDwBQu1JJlCleEPtP39LuY21pjrWTO2LonB14Fv3S5BlFvN8ajQZ/7/4LCQnx+MzLW+44WqKUpSg5RSBCWYqQERAnpwg+ubJUKWgRgCJng7G0tMTly5dRrlw5WXPExMZAo9HA3t5eZ729vQMiIyNkSpWWKDlF8N3cP7EkoC3u7hiDN8kapKRI6Be0DSf/fajdZ+aQ5jh9JQQ7j12XJaNI9/v2rZv4uvNXSEpKhHXu3JgzfxFKliotdywtUcpSlJwiEKEsRcgIiJNTBCxLyoislfVhw4bpXa/RaDB9+nTtQzt37twMz5OYmIjExESddZLaEpaWlkbJ+X6fJkmSFNnPSZScSjbgy5qoWt4Z7UasRUhoDPwqumLB8NYIi3qBQ2fv4Au/cqjrUwrVu/0gd1Qh7reLqys2bt2Oly+e48C+vRg/djRWrF6nqAo7IEZZAuLkFIEIZSlCRkCcnCJgWZI+slbW58+fDy8vL+TPn19nvSRJCA4Oho2NTZYe0qCgIEyaNElnXeC4CRg7fmK28tnlt4NarUZkZKTO+ujoKNjbO2Tr3MYkSk6ls7LMhUl9P0eH0euw5+RNAMDVu2H4rIwThnSqhUNn76Bu5VIoWbQAwvZO0Dl247TOOHH5AT4fsDzHc4p0v83NLeDsXAIA4FG+Aq5dvYpf1v+MsRMmy5zsLVHKUpScIhChLEXICIiTUwSfWlnyDYhhZO2zPnXqVMTFxWHcuHE4dOiQdlGr1VizZg0OHTqEgwcPZnqegIAAxMXF6SwjRgVkO5+5hQXKeZTH6ZMndNafPnkSXt4Vs31+YxElp9KZq9WwMM+FlBTdMROalBSY/f8fltk/H0aVLgtQrdsP2gUARi7Yid7fbzFNToHvtwQJb5KS5I6hJUpZipJTBCKUpQgZAXFyioBlSRmRtWU9ICAADRs2ROfOndGiRQsEBQXB3Nzc4PNYWqbt8vI62TgZu3TrjsDRI+Hh6Qkvr4rYtmUTQkND4d+ho3EuYCQi5IyPf4WQkBDtz0+ePMaNG8GwtbVFkSJOJslgY22BUsX+6xPo4lQAn5Upgpjn8Xj0LA5HL9zDtIHNkJCYjJCwGNSqWBL/a1oJoxbsBAA8i36pd1Dpo2exeBgaY5LfARDjfi9cMBe+frVRuHBhvHr1Cn/v2YXzZ//BoqU/yR1NhwhlCYiRUwmv8awQoSxFyAiIkZPPJYlO9gGmVapUwfnz5zFgwABUrlwZ69evV9THI02aNkNcbAyWL12CiIhwlC7jhsU/LoeTU9HMDzYhEXJeu3oVvXp01f48Z2YQAKBFqzaYMnW6STJUKlsMe5f01v48c3BzAMC6v86j9/db0HXcL5jcrwnWTOoAu3y5ERIWg4k//o2ftp8xSb6sEuF+R0dFYdyYkYiMiECevHlRpow7Fi39CdVr+sodTYcIZQmIkVMJr/GsEKEsRcgIiJGTz6XyKKmeJwKVpJR5EgH8+uuvGDJkCCIiInDlyhV4eHz4t0Iaq2WdAOU8IRkrUHu03BEyFXNMOf8xZESTovybrjbjH3tjEeU1zv/fPy0iPJeiPJNWsjfN6ir13W65I2jdndNU7giZUtTt69ixI/z8/HD+/HmUKFFC7jhERERERLJSVGUdAIoVK4ZixYrJHYOIiIiIcoAon0gohSK/wZSIiIiIiBTYsk5EREREHy8OMDUMW9aJiIiIiBSKlXUiIiIiIoViNxgiIiIiMhn2gjEMW9aJiIiIiBSKlXUiIiIiIoViNxgiIiIiMhnOBmMYtqwTERERESkUK+tERERERArFbjBEREREZDLsBWMYtqwTERERESkUW9aJiIiIyGTMzNi0bgi2rBMRERERKRQr60RERERECsVuMERERERkMhxgahi2rBMRERERKRQr60RERERECsVuMDJ7/UYjd4RMWZmr5Y6QJWEHp8kdIVOu/bfJHSFLzs5oLneETDnktZQ7QpZIktwJiMSUIsCLR83+HB9ExXIzCFvWiYiIiIgUipV1IiIiIiKFYjcYIiIiIjIZ9oIxDFvWiYiIiIgUii3rRERERGQyHGBqGLasExEREREpFCvrREREREQKxW4wRERERGQy7AZjGLasExEREREpFCvrREREREQKxW4wRERERGQy7AVjGLasExEREREpFFvWiYiIiMhkOMDUMGxZJyIiIiJSKFbWiYiIiIgUit1giIiIiMhk2AvGMGxZJyIiIiJSKFbWiYiIiIgUipX1LNi0cQOaNq6PKhUroKN/W1w4f07WPBfPn8N3g/rji0Z1UM3bA0cO7tfZLkkSflq6CF80qoPa1SqiX89uuHfntkxpdSmtLPV59eoV5s6chpZN66NWNW/07PoVrl+9YrLrVy/jgLUDauLizGYIXd4OTbyddLY75LXE/K99cHFmM9xb1Aq/DPKFa6E86Z5vwyBfvecxpl/WrkD/7l+hef3qaNe0DsaNHIxHD+/r7DNj8lg0qP6ZzjKw5/9yLJMhlP5cnj93FoMG9EWjen7w9nTHwQP7Mz9IBqLkBJR/zwExMgLi5ASAVSuWoVKFspg1Y5rcUfQSqSyzQ6VSKWYRASvrmdizexdmTg9Cr979sGnr76hUyQf9+/RC6NOnsmVKSIhHGTd3DB89Vu/2dWtW4pf1azF89Fis3rAZBRwc8G2/b/Dq1SsTJ9WlxLLUZ+qksThz+iQmfj8Dv2z5A9Vq+GJA3x4If/bMJNfPbanG9cexCNx4Se/21f1roISDDb5efAqNphzA4+h4bB7qB2sLdZp9ezcsDUnK4cAA/r14Di3bdcSiFesx84fl0Gg0GDm4LxIS4nX2q1LdF1v+Oqhdps1dkvPhMiHCc5mQEA83d3eMHjNe7igZEiWnCPdchIyAODkB4NrVK/ht62aUcXOXO4peIpUlmRYr65lYt3Y12rRrh7bt/VGyVCmMDAhE4SKFsXnTRtky1fSrjb4DB6Neg0ZptkmShF83/Izu3/RBvQaNUKp0GUyYEoTXCa/x9+6dMqT9jxLL8n2vX7/GoQP78O2Q4ajkUwXFnUugd7+BcHIqhm1bTJPz4NVnmPHHdey6mPYPdMlCeVC5lD1GbbiIyw9jcPfZS4zecBG5LXOhTdXiOvt6FLNF74ZlMHRtzrfMTJ//I5o0bwWXkqVRqow7Ro6djPCwUNy+cV1nP3MLCxSwd9Au+WxtczxbZkR4Lv1q1cHAQUPRoFFjuaNkSJScItxzETIC4uSMj3+FwNHDMW7CFOTLl0/uOHqJUpZkeqysZ+BNUhKCr19DjZp+Outr1PTF5UsXZUqVsadPHiMqMhLVatTUrrOwsEDFypVx5dIl2XKJUpYajQYajQYWlpY66y2tLHH54gWZUv3HwvztSzYxOUW7LkUC3mhSULW0vXadtYUaS7+pisCNlxDxPNHkOV+9fAkAyJtPtzJ++cI5tGtaB139W2DOtImIiY4yebZ3ifJckvGIcM9FyAiIkxMApk+dDL9adXX+b1QSkcrSGFQq5SwiYGU9AzGxMdBoNLC3t9dZb2/vgMjICJlSZSwqMhIAUKCAg876AgUcEBUVKUckAOKUpY2NDSp85o1Vy5ciIjwcGo0Gu//agWtX/lVEzjthL/Ao8hXGtPGEbW5zmKtVGNjEDY621nC0tdbuN+nLz3D2bhT+vhxq8oySJGHpglnw9KoI11JltOur1vDDmElBmL1oBfoO+g43g69h+MBvkJSUZPKMqUR5Lsl4RLjnImQExMn59+6/cOP6dXw7ZJjcUdIlSlmSPBQ3z3pMTAzWrl2L27dvo0iRIujWrRuKFy+e4TGJiYlITNRtPZTUlrB8r3X0Q70/AEGSJMUPSkiTTyGZRSjLSVNnYMrEQHzRuA7UajXcy3rg86bNcfO9Lh1ySNZI+ObH05jTzQc35rdEsiYFx4LDceBKmHafxl5F4OteCI2+l2dw3w+zp+HendtYsHyNzvp6jZpo/+1aqgzcy5VHp9af48yJo6hVr6GJU+oS4bkk4xLhnouQEVB2zrCwUMyaPg1Llq80Wp0gJym5LI3pY/ydcpLslXUnJydcuXIF9vb2uH//PmrWfPsRVYUKFbBjxw7Mnj0bp0+fRtmyZdM9R1BQECZNmqSzLnDcBIwdPzFb2ezy20GtViMyUrdFOjo6Cvb2DukcJS97h7e5oqIi4FCwoHZ9dEwUChSwT++wHCdSWRYr7oxlK9chISEer16+hEPBQhgzciicnIrKHQ0A8G9ILBpNOYC81rlgoTZD1Msk/BVQD5cfxAAA/NwLwqWgDW7Ob6lz3Iq+1XHmdiTazTmaY9kWzg7CqWOHMe/H1ShYqHCG+9o7FIRjYSc8fhSSY3kyI9JzScYhwj0XISMgRs7ga9cQHR2F/3Vop12n0Whw4fw5bN64AafP/wu1Ou3gfFMToSxJPrJ3gwkLC4NGowEAjBkzBmXLlsXdu3exd+9e3LlzB7Vq1cK4ceMyPEdAQADi4uJ0lhGjArKdzdzCAuU8yuP0yRM660+fPAkv74rZPn9OcCpaDPYODvjn1CntujdvknDx3DlU8PaWLZeIZWltnRsOBQvh+fM4nD55ArXrNpA7ko4XCcmIepkE10J54FXCDn9ffjsgdeGem6g/eT8aTjmgXQBgwubLGLImZwabSpKEH2ZPw7EjBzB70QoUcSqW6TFxcbEIDw/TvsGUg4jPJWWPCPdchIyAGDmrVq+Ozb/twMYt27WLR3lPNP2iBTZu2a6IijogRlmSfGRvWX/XmTNnsGLFCuTOnRsAYGlpibFjx6J9+/YZHmdpmbbLy+tk42Tq0q07AkePhIenJ7y8KmLblk0IDQ2Ff4eOxrnAB4iPf4XHIf+1Rj598gS3bgQjn60tChdxQsf/dcWalctRvEQJFHcugTUrlsPK2gqfN20uW2ZAmWWpz6mTxwFJgrOLKx6HPMQP82ajhIsrWrRqY5Lr57ZUw7Xgf/OmOzvkRvlitoiNT8KT6AQ09ymKqBeJeBKdgHJF82FKBy/sufQUR66HAwAinifqHVT6JDoBj6Li06w3hh9mTcWBvbsxZeYC5LaxQfT/j4+wsckDSysrJMTHY+2KJahVrxHs7R0QFvoUK3/8Aba2+eFXR943QSI8l/HxrxDyzmv+yZPHuHEjGLa2tihSJOfmzzeUKDlFuOciZASUn9PGJg9Kl3HTWWdtbQ3b/PnTrJeb0svSmNgLxjCKqKyn9l1KTEyEo6OjzjZHR0dERMg3uKJJ02aIi43B8qVLEBERjtJl3LD4x+WydokIvnYN/Xt9rf15/pwZAIAvWrTG+CnT0OXrnkh8/Rozp03Gi+fPUb7CZ/hh6QrY2NjIlPgtJZalPi9fvMCShfMQ/iwM+WxtUb9BY/QbOAS5zM1Ncn2vEnb4bXgd7c+TvvQCAGw6+QBD1pyHo60VJvp/hoL5rBAel4Atp0Iw769gk2RLz47fNgMAhvXvobN+xNgpaNK8FczMzHD/7h3s2/0nXr54gQIOBeFdqQrGfT8LuflcZura1avo1aOr9uc5M4MAAC1atcGUqdPlipWGKDlFuOciZATEySkCliWlRyVJpvjKlPSZmZnB09MTuXLlwu3bt/Hzzz+jTZv/WjCPHj2KTp064fHjxwad11gt6znt9RuN3BEyZWWujI8JM5P4JiXznWRWdvB2uSNkydkZ8n4KkxUOeZU/WAyASb6U6lPB1rhPiyZF+S8etZkYD6WVIppm/1N12mG5I2j9M6au3BEyJfvtmzBhgs7PqV1gUv3555+oVauWKSMRERERUQ7hbDCGUVxl/X2zZs0yURIiIiIiImWRfTYYIiIiIiLST/aWdSIiIiL6dLAXjGHYsk5EREREpFBsWSciIiIik+EAU8OwZZ2IiIiISKFYWSciIiIiUih2gyEiIiIik2EvGMOwZZ2IiIiISKFYWSciIiIiUih2gyEiIiIik+FsMIZhyzoRERERkUKxZZ2IiIiITIYN64ZhyzoRERERkUKxsk5EREREpFDsBkNEREREJsMBpoZhyzoRERERkUKxsk5EREREpFDsBkNEREREJsNuMIZhZV1mKvCBNRYzAYry1sI2ckfIEr9ph+SOkKkz4xrIHSFLRPg/KfjJC7kjZEm5onnljkAmpBbhjzqRCbAbDBERERGRQrFlnYiIiIhMRoRPHJWELetERERERArFlnUiIiIiMhkOMDUMW9aJiIiIiBSKlXUiIiIiIoViNxgiIiIiMhn2gjEMW9aJiIiIiBSKlXUiIiIiIoViNxgiIiIiMhnOBmMYtqwTERERESkUK+tERERERArFbjBEREREZDLsBWMYtqwTERERESkUW9aJiIiIyGTM2LRuELasExEREREpFCvrREREREQKxW4wRERERGQy7AVjGFbWs2DTxg1Ys3olIiMiUKp0GYwcPQaVfCrLHUvHq1evsGzxAhw+tB8x0dFwcy+H70aOgYdnBbmj6VB6WbZo2gChT5+mWe/f4SuMGjNehkT6hT97hoXz5+Dk8aN4nZiIEiVcMG7S9yjnUd5kGSqVyI+vfZ1Rrkg+FMpniSEbL+PQjUjt9suTGug9bu7e21h7IgQA0M7HCU0rFEa5InmRxyoX/IKO4MXrZJPkf5fSn8tUSsq55edl2Lb+J511tnb2WLbpbwDAP8cPYv9fv+H+7WC8eB6H6Us3wKWUuxxR9VJSWaZHhIyAGDlFyAiIk5NMi91gMrFn9y7MnB6EXr37YdPW31Gpkg/69+mlt0Inp6mTxuLM6ZOY+P0M/LLlD1Sr4YsBfXsg/NkzuaNpiVCWP2/Ygj0HjmqXxctWAgAaNGoic7L/PH8eh57dOiFXrlxYsGQ5tmzfiSHfjUTevHlNmsPaXI2bYS8xfddNvdvrzzqms4zffh0pKRL2Xw/X7mNlrsbJO1FYeeyBiVKnJcJzCSgzZ7ESJfHjr3u0y6xlv2q3vX6dAPfyXviq57ey5UuPEsvyfSJkBMTIKUJGQJycZHqsrGdi3drVaNOuHdq290fJUqUwMiAQhYsUxuZNG+WOpvX69WscOrAP3w4Zjko+VVDcuQR69xsIJ6di2LZFOTlFKEu7AgXg4FBQuxw/ehjFijvDp3IVuaNprV21Ao6ORTBhyjR4VvgMTkWLomr1GihW3NmkOU7cicLig/dwIDhC7/aol0k6S92yBXH2QQyexLzW7rPh9COsOv4Q/z6OM1XsNER4LgFl5lSrcyF/AQftki+/nXZb7YZfoF3nXvCsWFW2fOlRYlm+T4SMgBg5RcgIiJPTGFQqlWIWEbCynoE3SUkIvn4NNWr66ayvUdMXly9dlClVWhqNBhqNBhaWljrrLa0scfniBZlS6RKlLN/15k0Sdv31J1q2bquoF/TRw4dQrnx5jPpuCBrV8UWnL9ti+9bNcsfKUAEbC9Rys8f2C8pqIRLluVRqzrAnIejXsQm+7dISC6YG4FnoY9myZJVSy/JdImQExMgpQkZAnJwkD1bWMxATGwONRgN7e3ud9fb2DoiM1N+aKAcbGxtU+Mwbq5YvRUR4ODQaDXb/tQPXrvyrmJyilOW7Dh88gJcvXqBFyzZyR9Hx5PEjbNv8K5ydS2Dhjz+hnX8HzJ4xDTt3/C53tHS19C6M+ERNuq3wchHluVRiztJlPdF/5CQEBC1C76GBiI2JwvghPfHieawsebJKiWX5PhEyAmLkFCEjIE5OkofslfWLFy/i/v372p/Xr18PX19fFC9eHH5+fvj1118zOPqtxMREPH/+XGdJTEw0Wsb3W1UlSVJUSysATJo6AxIkfNG4DvyqemHTL+vxedPmUKvVckfTIUJZpvpj+zbU9K2FgoUKyR1FR0qKhLLlPDBg8FCULeeBdv4d0LqdP7Ztzvy1IpfWFZ2w60oYkpJT5I6ilyjPpZJyVqzqi2q1GsDZtTQqVKqGUVMWAACO7t0pSx5DKaks0yNCRkCMnCJkBMTJmV1mKuUsIpC9st6zZ088ePAAALBixQr07t0blStXRmBgIKpUqYJevXph1apVGZ4jKCgItra2OsusGUHZzmaX3w5qtRqRkZE666Ojo2Bv75Dt8xtTseLOWLZyHY6cOo8/9xzEmg2bkZz8Bk5OReWOBkCssgSA0KdP8M+ZU2jVtr3cUdJwKOgA15KldNa5upZEWFioTIkyVtE5P1wL2uC388rqAgOI81yKkNPK2hrOLqUQ+vSR3FEyJEJZipARECOnCBkBcXKSPGSvrN+8eROlSr2teCxZsgTz58/HggUL0LdvX8ybNw/Lli3DnDlzMjxHQEAA4uLidJYRowKync3cwgLlPMrj9MkTOutPnzwJL++K2T5/TrC2zg2HgoXw/HkcTp88gdp19U+fZ2qileWOP7bDrkAB+NWqI3eUNLy8K+Hh/7/BTfXw4QMUKeIkT6BMtKlUBNeePMetZy/ljpKGKM+lCDnfJCXhyaMHsCug7IqFCGUpQkZAjJwiZATEyWkscg8qze4A0yVLlsDV1RVWVlbw8fHBsWPHMtw/MTERgYGBKFGiBCwtLVGqVKlMG6LfJfs869bW1oiIiICzszOePHmCatWq6WyvVq2aTjcZfSwtLWH53uBKY03V3KVbdwSOHgkPT094eVXEti2bEBoaCv8OHY1zASM5dfI4IElwdnHF45CH+GHebJRwcUWLVsrpby1KWaakpODPP35D8xatkSuX7C+RNDp16YYeXTth1U/L0OjzJrh25Qq2b92CwAmTTJrD2kIN5wLW2p+L2lnDvXAexCW8QVjc225oNpZqNC7viDl/39Z7Dvs8FnDIY4HiBXIDAEoXyoP4pGSExr3G8wTTzLcuynOptJzrls+HT/VacChYGHGxMdj+y0okxL9C7UbNAQAvn8chMiIMMVFv+9s+ffQQAJDfzh75Za7QK60s9REhIyBGThEyAuLk/NRt2rQJQ4YMwZIlS+Dr64tly5ahadOmuH79Opyd9c/K9uWXX+LZs2dYuXIlSpcujfDwcCQnZ/3/ONlrIk2bNsXSpUuxYsUK1KlTB1u3boWXl5d2++bNm1G6dGnZ8jVp2gxxsTFYvnQJIiLCUbqMGxb/uFwx3UtSvXzxAksWzkP4szDks7VF/QaN0W/gEOQyN5c7mpYoZfnP6VMICw1Fy9Zt5Y6iV3nPCpg97wcsWjAPK5YtgVPRYvhu5Gg0/aKFaXM45cXK7j7an0c0cQMA/HHxKcb/HgwAaOLpCADYfSVM7zn8KxdFv3oltT+v6fn2fOO2X8eOS6bp1iPKc6m0nNERz7BwWiCeP49FPls7lCnniSkLVqOgYxEAwLnTR/Hj7P/eQP4wbQwAoF3nXvDv2keWzKmUVpb6iJARECOnCBkBcXJ+6ubOnYuePXvim2++AQDMnz8ff//9N5YuXYqgoLRdsPfs2YMjR47g3r17KFCgAADAxcXFoGuqJEmSsp08G54+fQpfX184OzujcuXKWLp0KXx8fFCuXDncvHkTp0+fxvbt29GsWTODzivDlyB+kMQ3yhxw9y5Lc9l7S2XJG4UOXtQhyGAWv2mH5I6QqTPjlNHF62MQ/OSF3BGypFxR037xF9HHwkr2plldXyz7R+4IWr997ZVmUhJ9PTYAICkpCblz58aWLVvQps1/PRcGDx6MS5cu4ciRI2mO6d+/P27duoXKlStj3bp1sLGxQcuWLTFlyhRYW1un2V8f2WthTk5OuHjxImrUqIE9e/ZAkiT8888/2Lt3L4oVK4YTJ04YXFEnIiIiIsqMvklK9LWQA0BkZCQ0Gg0cHR111js6OiIsTP8nyPfu3cPx48dx9epVbN++HfPnz8fWrVsxYMCALGdUxHut/PnzY/r06Zg+fbrcUYiIiIjoExEQEIBhw4bprNPXqv4uQ6bYTElJgUqlwoYNG2BrawvgbVea9u3bY/HixVlqXVdEZZ2IiIiIPg0qBfUJTa/Liz4ODg5Qq9VpWtHDw8PTtLanKlKkCIoWLaqtqANAuXLlIEkSHj9+jDJlymR6Xdm7wRARERERKZ2FhQV8fHywb98+nfX79u1DzZo19R7j6+uLp0+f4uXL/6YvvnXrFszMzFCsWLEsXZeVdSIiIiIyGbm/tTQ732A6bNgwrFixAqtWrUJwcDCGDh2KkJAQ9O3bF8DbbjVdu3bV7t+pUyfY29uje/fuuH79Oo4ePYoRI0agR48eWR5gym4wRERERERZ0KFDB0RFRWHy5MkIDQ2Fp6cndu3ahRIlSgAAQkNDERISot0/T5482LdvH7799ltUrlwZ9vb2+PLLL/H9999n+ZqyT92YUzh1o/Fw6kYjUk43vQxx6sZPC6duJPq4KW3qxpbLz8odQWtH7ypyR8iUwm4fEREREX3M0ps5hfQTo8mUiIiIiOgTxMo6EREREZFCsRsMEREREZkMe8EYhi3rREREREQKxco6EREREZFCsRsMEREREZmMGfvBGIQt60RERERECsWWdSIiIiIyGTasG4Yt60RERERECsXKOhERERGRQrEbDBERERGZjIr9YAzClnUiIiIiIoViy7rMLM35fslYcqmVX5aiNCacGddA7giZsqs6SO4IWRLzzw9yR8hUuaJ55Y5ARETpYGWdiIiIiExGlIYrpVB+UyQRERER0SeKlXUiIiIiIoViNxgiIiIiMhkz9oMxCFvWiYiIiIgUii3rRERERGQybFc3DFvWiYiIiIgUipV1IiIiIiKFylI3mJCQEINO6uzs/EFhiIiIiOjjpuIAU4NkqbLu4uJiUMFqNJoPDkRERERERG9lqbK+atUqvgsiIiIiIjKxLFXWv/766xyOQURERESfAjO2/xokWwNMExIS8OTJEyQnJxsrDxERERER/b8PqqwfOnQINWrUQN68eVGiRAn8+++/AIABAwbgt99+M2pAIiIiIqJPlcGV9YMHD6Jx48Z4/fo1hg8fjpSUFO02BwcHrFmzxpj5iIiIiOgjolKpFLOIwODK+vjx49GsWTNcvHgR33//vc42Ly8vXLp0yVjZiIiIiIg+aVkaYPquixcvYsuWLQDSzpNZsGBBhIeHGycZEREREX10BGnQVgyDW9Zz5cqFN2/e6N0WHh6OvHnzZjsUERERERF9QGW9SpUqWLdund5tW7duRY0aNbIdSmk2bdyApo3ro0rFCujo3xYXzp+TO5JeIuQUIeP5c2cxaEBfNKrnB29Pdxw8sF/uSHqJUJaAvDmHd2+E4+u+Q/ixmXi4fyo2z/kGZUoU0tknsE9TXNoWiMgTs/D08HT8tXQAqniW0NlnYWAHXPtjPKJPzkbIgWnYPLcX3Fx0z2MKItxzETICYuQUISMgRk4RMgLi5CTTMriyPnr0aGzfvh1t2rTBjh07oFKpcObMGQwcOBBbt27FyJEjcyKnbPbs3oWZ04PQq3c/bNr6OypV8kH/Pr0Q+vSp3NF0iJBThIwAkJAQDzd3d4weM17uKOkSpSzlzlnLpzR+3HwMdbrNRfN+i6HOZYadS/ojt5WFdp87D8MxdMYWVP5yOhr0mI+HT6Px5+L+cMifR7vPxeBH6D1pA7zbTUPLAUugUgE7F/eHmQknC5a7LLNChIyAGDlFyAiIkVOEjIA4OY1B7kGlog0wVUmSJBl60Pr16zFkyBBER0dr1+XPnx8LFy7E//73P6MG/FCvjTT1+/86+qOchwfGjp+kXde6RVPUq98Qg4d+Z5yLGIEIOXM6o+FPcua8Pd0xd8Fi1G/Q0CjnM9bfBRHuN5CzOe2qDjL4GIf8efDo4DQ0/GYBTly4q3efvDZWCD82E037LsLhf27p3cezjBPObhoNj5aTcf9xZIbXjPnnB4Nz6iPCPRchIyBGThEyAmLkFCEjkLM5rQweoZizuv7yr9wRtH7u9JncETL1QfOsd+7cGY8ePcLevXuxfv167NmzB48ePVJMRd1Y3iQlIfj6NdSo6aezvkZNX1y+dFGmVGmJkFOEjKIQpSyVmDNfXisAQExcvN7t5rnU6Nm2JmJfxOPKrSd698ltZYGuLavh/uNIPA6LybGs71JiWb5PhIyAGDlFyAiIkVOEjIA4OUkeH/xey9raGg0bZr+18dtvv8WXX36JWrVqZftcxhYTGwONRgN7e3ud9fb2DoiMjJApVVoi5BQhoyhEKUsl5pwxrA1OXLyL63dDddY3rVUePwd9jdxW5giLfI7m/ZYgKvaVzj69/f0wdXAr5MltiRv3w/BF/yV4k6wxSW4lluX7RMgIiJFThIyAGDlFyAiIk9NYTNiD8KPwQS3rz58/R1BQEBo3bgwfHx80btwYQUFBiI2NNfhcixcvRt26deHm5oYZM2YgLCzM4HMkJibi+fPnOktiYqLB50nP+32aJElSZD8nEXKKkFEUopSlUnLOG+2PCmWc0C1gbZptR87eRrWvZqBe9/nYezIY62d0R0G7PDr7/Lr7HKp/NRMNv1mAOyERWD+jOywtTPvZslLKMiMiZATEyClCRkCMnCJkBMTJSaZlcGX9/v37+OyzzxAYGIjbt2/DwsICt2/fRmBgILy8vHDv3j2DQ+zduxfNmjXD7Nmz4ezsjFatWmHnzp06346akaCgINja2uoss2YEGZzjfXb57aBWqxEZqdsnNTo6Cvb2Dtk+v7GIkFOEjKIQpSyVlHPuyHZoXtsTn/deiCfhsWm2x79Owr1HkfjnygP0m7wRyRoNurXWndnq+cvXuPsoAicu3EWnEavg7lIIreqZpq+jksoyPSJkBMTIKUJGQIycImQExMlpLHIPKhVtgKnBlfXBgwfj9evXOHHiBO7fv49Tp07h/v37OH78OBITEzFkyBCDQ1SoUAHz58/H06dPsX79eiQmJqJ169YoXrw4AgMDcefOnQyPDwgIQFxcnM4yYlSAwTneZ25hgXIe5XH65Amd9adPnoSXd8Vsn99YRMgpQkZRiFKWSsk5b1R7tKrvhSZ9FuHh0+jMD8Db/0gyazVXQQULE7WsK6UsMyJCRkCMnCJkBMTIKUJGQJycJA+D/6c5ePAgFixYkGY+9Zo1a+L777//oMp6KnNzc3z55Zf48ssvERISglWrVmHNmjWYPn06NJr0+4ZaWlrC0tJSZ52xZoPp0q07AkePhIenJ7y8KmLblk0IDQ2Ff4eOxrmAkYiQU4SMABAf/wohISHan588eYwbN4Jha2uLIkWcZEz2H1HKUu6c80f7o0NTH/gPXYGX8a/haP/2S9viXr7G68Q3yG1lgVHfNMZfR64iLDIOBWxt0Nu/FooWyo/f9r0d1OVS1B7tG1fCgdM3EBnzEk6FbPFdt4ZISHyDv49fN8nvAchfllkhQkZAjJwiZATEyClCRkCcnGR6BlfWLS0tUbx4cb3bnJ2d01SaP5SzszMmTpyICRMmYP9++b6UpknTZoiLjcHypUsQERGO0mXcsPjH5XByKipbJn1EyClCRgC4dvUqevXoqv15zsy3XapatGqDKVOnyxVLhyhlKXfOPl++Hbi+b4XuNI+9JqzH+j//gSYlBe4ujujcvCrs8+dBdNwrnLsWgoY9FyD43tvxM4mJb+BbsSQGdqoDu3y5ER71Ascv3EW97vMQEfPSJL8HIH9ZZoUIGQExcoqQERAjpwgZAXFyGoMYnU+Uw+B51nv06AG1Wo2ffvopzbZevXohKSkJa9emHcCVHldXV5w7dy7NCOjsMlbLOokjJ+ZZNzZBuscJ4UPmWZeDseZZJyL6UEqbZ73Hr1fkjqC1qmMFuSNkKku378KFC9p/d+rUCT179oS/vz86deqEwoULIywsDBs2bMC5c+ewcuVKgwLcv3/fsMRERERERJ+ILFXWK1eurDNiVpIkPHr0CL/99pvOOgBo3Lhxhv3LiYiIiOjTZcaPmQ2Spcr66tWrczoHERERERG9J0uV9W7duuV0DiIiIiIieo/ChhwQERER0ceMvWAM80GV9ejoaPzyyy8IDg5GQkKCzjaVSmXwIFMiIiIiIkrL4Mp6SEgIqlSpgvj4eMTHx8PBwQHR0dHQaDSws7ODra1tTuQkIiIioo+Aik3rBjEz9IDRo0ejfPnyePbsGSRJwu7du/Hq1SssXLgQVlZW+Ouvv3IiJxERERHRJ8fgyvqpU6fQr18/WFlZAXg7ZaOFhQUGDBiAnj17YsSIEUYPSURERET0KTK4sv7s2TMUKVIEZmZmUKvVeP78uXZbnTp1cPz4caMGJCIiIqKPh0qlnEUEBlfWHR0dER0dDQBwcXHBuXPntNsePHiAXLk4wQwRERERkTEYXLOuXr06Ll68iJYtW6Jt27aYPHkyEhMTYWFhgVmzZqF+/fo5kZOIiIiI6JNjcGV9+PDhePDgAQBg/PjxCA4OxoQJEyBJEmrXro358+cbOSIRERERfSzMROl/ohAGV9Z9fHzg4+MDALCxscGOHTvw/PlzqFQq5M2b1+gBiYiIiIg+VQb3WdcnX758yJs3L44ePcpuMERERERERmLU0aARERE4cuSIMU9JRERERB8R9oIxjFFa1omIiIiIyPg4zyIRERERmYyKTesGYcs6EREREZFCsbJORERERKRQWeoG89lnn2XpZM+fP89WGKLs4Kdqn5aYf36QO0KW2FUdJHeETIlSliKQJLkTZI5/K0lubCk2TJYq6wUKFMhS/yJ7e3u4urpmOxQREREREWWxsn748OEcjkFERERERO/jbDBEREREZDKcDcYw7DZERERERKRQbFknIiIiIpMxY8O6QdiyTkRERESkUKysExEREREpFLvBEBEREZHJsBuMYT64sn7jxg0cOXIEkZGR6NmzJwoXLoynT5/Czs4O1tbWxsxIRERERPRJMriyrtFo0Lt3b6xZswaSJEGlUqFp06YoXLgw+vTpg4oVK2Ly5Mk5kZWIiIiI6JNicJ/1qVOn4pdffsGsWbNw9epVSO98t3LTpk2xZ88eowYkIiIioo+HSqVSzCICg1vW16xZg3HjxmHYsGHQaDQ621xdXXH//n2jhSMiIiIi+pQZ3LL+5MkT1KhRQ+82KysrvHjxItuhiIiIiIjoAyrrhQoVwr179/Ruu3nzJooVK5btUERERET0cTJTKWcRgcGV9WbNmmHq1Kl48uSJdp1KpUJcXBx++OEHtGjRwqgBiYiIiIg+VQZX1idPnozk5GR4eHigXbt2UKlUGDNmDDw9PfH69WuMGzcuJ3ISERER0UdApVLOIgKDK+uOjo44e/YsvvrqK5w/fx5qtRqXL19G06ZNcfLkSRQoUCAnchIRERERfXI+6EuRHB0d8eOPPxo7CxERERERvcPglvVP0aaNG9C0cX1UqVgBHf3b4sL5c3JH0kuEnCJkBMTIKUJGQIyccmf0rVQKW+f3xr2/pyDhwg9oUbeCzvaECz/oXYZ2rQ8AcC5SIN192jb0NunvIndZZpXSc54/dxaDBvRFo3p+8PZ0x8ED++WOlC6llyUgRkZAnJzZZaZSKWYRgcGV9R49emS49OzZMydyymbP7l2YOT0IvXr3w6atv6NSJR/079MLoU+fyh1Nhwg5RcgIiJFThIyAGDmVkNHGygJXbj3B0Blb9G53aRSos/SeuAEpKSnYfuAyAODxs5g0+0xeugsv4xPx94nrJvs9lFCWWSFCzoSEeLi5u2P0mPFyR8mQCGUpQkZAnJxkeirp3a8gzQIXF5c03/gUFRWFly9fIn/+/MifP3+6Uzua0utk45znfx39Uc7DA2PHT9Kua92iKerVb4jBQ78zzkWMQIScImQExMgpQkZAjJw5ndGu6iCD9k+48AO+HPYT/jx8Jd19Ns/5BnlsLNGs7+J09zn1y0hcuvEI/SZvzPSaMf/8YFDG9Ihwv4GczWnY/6hZ4+3pjrkLFqN+g4ZGOZ8xGxNFuOciZARyNqfVB3V6zjmjd92SO4LW9GZuckfIlMEt6w8ePMD9+/d1lufPn2P//v0oVKgQ/vjjj5zIKYs3SUkIvn4NNWr66ayvUdMXly9dlClVWiLkFCEjIEZOETICYuQUIeP7ChXIiyZ+5bH299Pp7lOxXHF4ly2W4T7GJkpZipJTBCKUpQgZAXFyGouZghYRGC1n/fr1MXDgQAwePNjgYxcuXIhu3bph8+bNAIB169bBw8MDZcuWxZgxY5CcbKRmcgPFxMZAo9HA3t5eZ729vQMiIyNkyaSPCDlFyAiIkVOEjIAYOUXI+L7OLariRfxr/H7wcrr7dGtVHcH3wnD63/smyyVKWYqSUwQilKUIGQFxcpI8jPrBiIeHB0aPHm3QMVOmTMGsWbPQuHFjDB48GPfv38esWbMwdOhQmJmZYd68eTA3N8ekSZPSPUdiYiISExN11klqS1haWn7Q7/G+97v9SJKUZp0SiJBThIyAGDlFyAiIkVOEjKm6tqyOTbvPITFJfyOGlaU5OjT1wfSf/jZxsrdEKUtRcopAhLIUISMgTk4yLaN+AnDkyBE4ODgYdMyaNWuwZs0abN26FXv27EFgYCAWLFiAwMBABAQEYNmyZfjll18yPEdQUBBsbW11llkzgrLzqwAA7PLbQa1WIzIyUmd9dHQU7O0N+z1zkgg5RcgIiJFThIyAGDlFyPgu34ol4e7qiNXbT6W7T5uG3shtZYENO8+aMJk4ZSlKThGIUJYiZATEyWkscn8R0kf/pUiTJ09OswQGBqJFixaYOnUqvvrqK4POFxoaisqVKwMAvLy8YGZmBm9vb+32SpUq4WkmI6EDAgIQFxens4wYFWDor5aGuYUFynmUx+mTJ3TWnz55El7eFbN9fmMRIacIGQExcoqQERAjpwgZ39WtVQ2cvx6CK7fT/5v4davq+OvIVUTGvjRhMnHKUpScIhChLEXICIiTk+RhcDeYiRMnpllnaWkJFxcXTJ48GSNGjDDofIULF8b169fh7OyM27dvQ6PR4Pr16yhfvjwA4Nq1ayhUqFCG57C0TNvlxVizwXTp1h2Bo0fCw9MTXl4VsW3LJoSGhsK/Q0fjXMBIRMgpQkZAjJwiZATEyKmEjDbWFihVvKD2Z5ei9vjMrShinsfjUVgMACCvjRXaNvLG6Lm/p3ueksUd4FepFFoPWpbTkfVSQllmhQg54+NfISQkRPvzkyePceNGMGxtbVGkiJOMyXSJUJYiZATEyWkMosxvrhQGV9ZTUlKMGqBTp07o2rUrWrVqhQMHDmDUqFEYPnw4oqKioFKpMHXqVLRv396o1zREk6bNEBcbg+VLlyAiIhyly7hh8Y/L4eRUVLZM+oiQU4SMgBg5RcgIiJFTCRkreThj70//TfE487u2AIB1O86g98QNAAD/zytBBRU2/30+3fN0a1UdT8PjsP/UjZwNnA4llGVWiJDz2tWr6NWjq/bnOTPfdu1s0aoNpkydLlesNEQoSxEyAuLkJNMzaJ71hIQE9OzZE/3794efn1/mB2SBRqPB9OnTcfr0afj5+WHUqFH49ddfMXLkSMTHx6NFixZYtGgRbGxsDDqvsVrWiYiyw9B51uVgrHnWKWfmWTc2Nmp+epQ2z/q4PbfljqA1pUkZuSNkyuAvRbKxscHu3btRu3btnMpkFKysE5ESsLL+aWFlnZRIaZX18X8rp7I++XPlV9YNHmDq7e2Nq1ev5kQWIiIiIiJ6h8GV9enTp2PmzJk4cuRITuQhIiIiIqL/l6UPRo4ePYpKlSohT5486N+/P16+fIn69evDzs4ORYoU0ZmwX6VS4fLl9L9Zj4iIiIg+XWbsimWQLFXW69Wrh1OnTqFq1aqwt7c3+IuPiIiIiIjIcFmqrL87BvXw4cM5lYWIiIiIiN6hsPHBRERERPQx45ciGSbLA0xVLFgiIiIiIpPKcst6vXr1YGaWed1epVIhLi4uW6GIiIiI6OPE9l/DZLmyXrduXRQsWDAnsxARERER0TuyXFkfP348qlatmpNZiIiIiIjoHRxgSkREREQmw3nWDWPwN5gSEREREZFpsLJORERERKRQWeoGk5KSktM5iIiIiOgToAL7wRiCLetERERERArFAaZEREREZDIcYGoYtqwTERERESkUK+tERERERArFbjBEREREZDLsBmMYVtYpU5oUSe4IWZKsUX5OS3MxPsy6FfpS7giZciuSR+4IWRLzzw9yR8iUV+DfckfIkstTP5c7QqZUrIQYTYoA//eYsdZJJiBGzYGIiIiI6BPElnUiIiIiMhkVP4IyCFvWiYiIiIgUipV1IiIiIiKFYjcYIiIiIjIZjss1DFvWiYiIiIgUii3rRERERGQyHF9qGLasExEREREpFCvrREREREQKxW4wRERERGQyZuwHYxC2rBMRERERKRQr60RERERECsVuMERERERkMpxn3TBsWSciIiIiUihW1omIiIiIsmjJkiVwdXWFlZUVfHx8cOzYsSwdd+LECeTKlQve3t4GXY+VdSIiIiIyGZVKOYuhNm3ahCFDhiAwMBAXL15ErVq10LRpU4SEhGR4XFxcHLp27YoGDRoYfE1W1omIiIiIsmDu3Lno2bMnvvnmG5QrVw7z589H8eLFsXTp0gyP69OnDzp16oQaNWoYfE1W1omIiIjIZMygUsxiiKSkJJw/fx6NGzfWWd+4cWOcPHky3eNWr16Nu3fvYsKECR9YXpSpTRs3oGnj+qhSsQI6+rfFhfPn5I6UxvlzZ/Ft/75oWNcPXuXdcfDAfrkjpfHjkoWoVKGsztKorp+smS6cP4thg/qhWaPaqOpdDocP6pbboQN78W2/b9Cobg1U9S6HWzeCZUqqS4n3e/PaZfBv6KOzfOOv+wft8cP7mD5uKLq2rI0uLWphzMBuiHgWKlPi/4jwGgfky9m7riu2DqyOC5Mb4OS4uljc1RuuDrl19mlUvhBW9PTB6fH1cHPG5yhbJG+a83xZtRh+7l0F5yc1wM0ZnyOvlXwTkolwz0XICIiTEwBWrliGihXKYtaMaXJH0UuksvxYJCYm4vnz5zpLYmKi3n0jIyOh0Wjg6Oios97R0RFhYWF6j7l9+zZGjx6NDRs2IFeuD/ubx8p6Jvbs3oWZ04PQq3c/bNr6OypV8kH/Pr0Q+vSp3NF0JCTEw93dHaMDx8sdJUOlSpfB3kPHtMvm33bImud1QgLKuLljxOixercnJCTAy7siBgwaZuJkGVPq/S7uUgrLN/+tXeb8tEm7LezpI4wb0hNFi7tg0pzlmL1sI9p1/gYWFpYyJhbnNS5nzqolC2DDqRB8ufg0uq84D7WZCiu/qQxrc7V2n9wWalx8EIvZu2+lex5rCzWO3YrEj4fu5XjmjIhwz0XICIiTEwCuXb2C37ZuRhk3d7mj6CVSWX5MgoKCYGtrq7MEBQVleIzqvc7ukiSlWQcAGo0GnTp1wqRJk+Dm5vbBGTnPeibWrV2NNu3aoW17fwDAyIBAnDx5HJs3bcTgod/JnO4/frXqwK9WHbljZEqtVsPBoaDcMbRq+tVGTb/a6W5v1rwVAODpkyemipQlSr3fZmo17Ao46N22cdUSVKzmiy69B2vXOToVM1W0dInyGpcz5zerzuv8HLDlKk6Pr4/yxfLh3P0YAMAfF99+QlLUzird86w9/hAAULWkXQ4lzRoR7rkIGQFxcsbHv8KY0cMxbsIUrFiecd9iuYhSlsbwIQM7c0pAQACGDdNtkLO01N+I5ODgALVanaYVPTw8PE1rOwC8ePEC586dw8WLFzFw4EAAQEpKCiRJQq5cubB3717Ur18/04yyt6yHhoZi/PjxqF+/PsqVKwdPT0+0aNECK1euhEajkTXbm6QkBF+/hho1dbtq1Kjpi8uXLsqUSmwhIQ/RuH4tNG/SAKNHDMPjR4/kjkRGFPYkBL07fI7+nVtg3vcBePb0MYC3f5wunDkOp2LO+H7UAPRs3xABA7vinxOHZM0rymtcaTnzWpkDAOLi35j82tmltLLUR4SMgDg5ASBo6mTUqlUX1WvUlDuKXiKV5cfG0tIS+fLl01nSq6xbWFjAx8cH+/bt01m/b98+1KyZ9tnKly8frly5gkuXLmmXvn37wt3dHZcuXUK1atWylFHWyvq5c+dQrlw5/Pnnn3j9+jVu3bqFSpUqwcbGBsOHD0etWrXw4sUL2fLFxMZAo9HA3t5eZ729vQMiIyNkSiWuChW8MGXqdCz+cQXGTZiCqMgIdO/yFWJjY+SORkZQppwnBo6cjMCgReg7dCxio6MQOLgHXsTFIi42Gq8T4vH7r2vgXaUmxk5fjKq+9TB74ghcu3w+85PnEFFe40rLGdDcHefux+D2s5cmv3Z2Ka0s9REhIyBOzj27/8KN69fx7RBldWd8lyhlScCwYcOwYsUKrFq1CsHBwRg6dChCQkLQt29fAG9b6rt27QoAMDMzg6enp85SqFAhWFlZwdPTEzY2Nlm6pqzdYIYMGYKhQ4dqR8euX78eixYtwunTpxETE4P69etj7NixWLBgQYbnSUxMTDMYQFJbpvvOyFBZ7ZtEGfOtpdvd5DMvb7Rs1hg7//gdnbt1lykVGUvFqr46P7t5fIaBXVvh8L6d8K37OQCgco06aN7+fwAA19LuuHn9X+zbuQ3lvXxMnvddorzGlZBzfKtycCucF51+PGPS6xqbEsoyMyJkBJSdMywsFLOmT8OS5SuNVifISUouS2MyE/hX6tChA6KiojB58mSEhobC09MTu3btQokSJQC87TGS2ZzrhpK1Zf3ChQvo0qWL9udOnTrhwoULePbsGezs7DBz5kxs3bo10/PoGxwwa0bGgwOywi6/HdRqNSIjI3XWR0dHwd5ef79cyjrr3LlRuowbQkIeyh2FcoCVtTWcXUsj9HEI8trmh1qtRvESJXX2Kebsishw/SPoTUGU17hSco5tWRb1PQqi2/KzeBanf7YEpVNKWWZEhIyAGDmDr11DdHQU/tehHSp7l0dl7/I4f+4sNm5Yh8re5WXvbptKhLKk//Tv3x8PHjxAYmIizp8/j9q1/2uMXLNmDQ4fPpzusRMnTsSlS5cMup6slfVChQohNPS/aduePXuG5ORk5MuXDwBQpkwZREdHZ3qegIAAxMXF6SwjRgVkO5+5hQXKeZTH6ZMndNafPnkSXt4Vs33+T11SUhLu37urqAGnZDxvkpLwJOQ+7OwdYG5ujlLu5fHkse4bs6ePH8KhUGGZEorzGldCznGtyqGxpyO6LT+HxzEJJrlmTlBCWWZGhIyAGDmrVq+OLb/twK9btmsXj/KeaPZFC/y6ZTvUanXmJzEBEcqS5CNrN5jWrVujb9++mDVrFiwtLTFlyhTUqVMH1tbWAICbN2+iaNGimZ7H0jJtl5fXycbJ2KVbdwSOHgkPT094eVXEti2bEBoaCv8OHY1zASOJf/VK52OXJ48f40ZwMGxtbVHEyUnGZP+ZN3sGateph8JFnBAdHYUVy5fi1auXaN6qtWyZ4uNf4fE75fb0yWPcuhGMfLa2KFzECXFxsXgWGoqIiHAAwMOH9wEABRwcZH2TocT7/fOyefCpXhsOhQrjeWw0tm1YiYT4V6jbuAUAoOWXXTDv+wB4VKiI8t5VcOnsSZw/dQwT5yyTJW8qUV7jcuac0LocmnsXQf+1F/EqMRkOeSwAAC9eJyMxOQUAYGttjiL5rVAo39u/xa4F3/bFjHyRiMiXSQAAhzwWcMhrCWf7t3O0uxXOg1eJGoTGvkZcgukGq4pwz0XICCg/p41NHpQuoztlnrW1NWzz50+zXm5KL0tjMvsIu/bkJFkr699//z1CQ0PRokULaDQa1KhRA+vXr9duV6lUmc51mdOaNG2GuNgYLF+6BBER4Shdxg2Lf1wOJ6fM30SY0rVrV/FN967an2fPfFtuLVu1wZRp0+WKpePZs2cIGPUdYmNiYVfADhU+88LaDZtkLcvga9fQr1c37c/z58wAAHzRojUmTAnCscOHMHnCGO32wFFvp8/6ps8A9O430LRh36HE+x0VEY4F08bgeVws8tnawa1cBUxduAYFHYsAAKr51UfvwWOw/dfVWLV4NpyKl8DwCTNRroK8rUaivMblzNmphjMAYH3fqjrrR2++gu3n384BXd+jIKZ/WUG7bf7/vAAAC/fdwaL9dwEAHasXx7eNSmv3+aVftTTnMQUR7rkIGQFxcoqAZUnpUUmSJMkd4vXr10hOTkaePHmMd04jtawToEmR/RHJkmSN8nNamss+W2qW3ApV/iwfbkWM9/fiU+cV+LfcEbLk8tTP5Y5AJpQiwP89ZoKMlJTxy4L1+umMcsaq9apWQu4ImVLE7bOySv9LNIiIiIiIPlViNPMREREREX2CFNGyTkRERESfBg4wNQxb1omIiIiIFIqVdSIiIiIihWI3GCIiIiIyGfaCMQxb1omIiIiIFIot60RERERkMmwpNgzLi4iIiIhIoVhZJyIiIiJSKHaDISIiIiKTUXGEqUHYsk5EREREpFCsrBMRERERKRS7wRARERGRybATjGHYsk5EREREpFCsrBMRERERKRS7wRARERGRyZhxNhiDsGWdiIiIiEih2LJORERERCbDdnXDsGWdiIiIiEih2LJOmRKlb5mluRg5ReBWJI/cET4ayRpJ7giZujz1c7kjZIlDpzVyR8jU7Z86yR0hU3Y2FnJHyBKNpPzXjhnbiMkEWFknIiIiIpMRpA1QMdgNhoiIiIhIoVhZJyIiIiJSKHaDISIiIiKTUbEfjEHYsk5EREREpFCsrBMRERERKRS7wRARERGRybCl2DAsLyIiIiIihWLLOhERERGZDAeYGoYt60RERERECsXKOhERERGRQrEbDBERERGZDDvBGIYt60RERERECsXKOhERERGRQrEbDBERERGZDGeDMQxb1omIiIiIFIqVdSIiIiIihWI3GCIiIiIyGbYUG4bllQWbNm5A08b1UaViBXT0b4sL58/JHUkvpec8f+4sBg3oi0b1/ODt6Y6DB/bLHSldSi9LQIyMgBg5lZ5x2ZKF8PmsrM7SuJ6f3LH0krMsfcs5YvOoBrj945d4uflrNK/irLO9kK0Vfuzvh9s/fonwdZ2xfUwjlCqcV2ef7g3csHtCEzxd0wkvN38N29wWOZ57w5oV6NOtI5rWrYbWn9dB4PBBCHl4X2cfSZKwevkStGtWH41rVcbgvt1x/+6dHM+WFUp//YQ/e4ZxASPRoFZ1+FatiE7+bRB8/ZrcsfRSelmSPBRRWX/16hV++ukndO/eHU2bNkWzZs3QvXt3rFixAq9evZI1257duzBzehB69e6HTVt/R6VKPujfpxdCnz6VNdf7RMiZkBAPN3d3jB4zXu4oGRKhLEXICIiRU4SMAFCqVBn8ffCYdtm0bYfckdKQuyxzW+bC1QfR+G7Vab3bN46oD9dCedBh1gH4jtyBRxEv8ee4z5Hb8r8Pma0tc2HfpSeYvf2KSTIDwKUL59DavyOWrNyA2QuXQ6PRYMS3fZCQEP9f9p9XYcvGnzF4xBj8uGYjCtg7YPi3vRHP/yMz9Px5HHp264RcuXJhwZLl2LJ9J4Z8NxJ58+bN/GATU3pZGpNKpVLMIgLZK+vXr1+Hm5sbRo4ciZiYGDg7O6NYsWKIiYnBiBEj4O7ujuvXr8uWb93a1WjTrh3atvdHyVKlMDIgEIWLFMbmTRtly6SPCDn9atXBwEFD0aBRY7mjZEiEshQhIyBGThEyAoA6lxoODgW1i12BAnJHSkPustx36Qkmb7qIHf+EpNlWukg+VHMrhCErTuPC3SjcDn2OIStOw8YqF/x9XbX7Ldl1HXP/uIKztyNMkhkAZv3wI5o2bw3XUqVR2s0do8dPwbOwUNwKfvt/nyRJ2PrrenT+uhdq12uIkqXKIGDCVLx+/Rr7//7LZDn1kfueZ2btqhVwdCyCCVOmwbPCZ3AqWhRVq9dAseLOmR9sYkovS5KP7JX1AQMGoHbt2nj27Bl+//13LFu2DMuXL8fvv/+OZ8+eoXbt2hgwYIAs2d4kJSH4+jXUqKn7cXONmr64fOmiLJn0ESWnCEQoSxEyAmLkFCFjqpCHD/F5g1po0aQBAkYOw+PHj+SOpEPpZWmZ6+1/d6/faLTrUiQJb5JTUKOso1yx9Hr58iUAIK+tLQAg9OljREdFokr1mtp9LCws4F3JB9f+vSxLRkD59xwAjh4+hHLly2PUd0PQqI4vOn3ZFtu3bpY7VhoilCXJR/bK+pkzZzBu3DhYWKTtF2hhYYExY8bgzJkzMiQDYmJjoNFoYG9vr7Pe3t4BkZGma3XJjCg5RSBCWYqQERAjpwgZAcCzghcmT52ORUtXYOzEKYiKjECPLl8hNjZG7mhaSi/Lm0/j8DD8JSZ1qoT8NhYwV5thWKsKKGyXG4XzW8sdT0uSJCyZPwsVvCqhZKkyAIDoqCgAgF0B3bK1K2CP6KhIk2dMpfR7DgBPHj/Cts2/wtm5BBb++BPa+XfA7BnTsHPH73JH0yFCWRqTSkGLCGSfDcbOzg63b9+Gh4eH3u137tyBnZ1dhudITExEYmKizjpJbQlLS0ujZHy/T5MkSYrs5yRKThGIUJYiZATEyKn0jL61auv8/Nln3mj1RWPs3PE7OnftLlMq/ZRalskaCf+bcwhL+vni8epOSNak4NCVUPx94bHc0XQsmDUVd+/cwsLla9NsS1u2ABRQtkq95wCQkiLBo3x5DBg8FABQtpwH7t29g22bf0Xzlq3lDaeHksuS5CN7y3qvXr3QrVs3zJ49G5cvX0ZYWBiePXuGy5cvY/bs2ejRowf69OmT4TmCgoJga2urs8yaEZTtbHb57aBWqxEZqdtyER0dBXt7h2yf31hEySkCEcpShIyAGDlFyKiPde7cKF3GDSEPH8odRUuEsrx0Pwo1R+6AU7cNKN17E9pM24cCeS3xMOKF3NEAAAtmTcOJo4cxf8lKFHIsrF1f4P9bW99vRY+NiUKB91rbTUmEe+5Q0AGuJUvprHN1LYmwsFCZEuknQlmSfGSvrE+cOBEBAQGYO3cuKlasiKJFi8LJyQkVK1bE3LlzMXr0aIwfn/HsIQEBAYiLi9NZRowKyHY2cwsLlPMoj9MnT+isP33yJLy8K2b7/MYiSk4RiFCWImQExMgpQkZ9kpKScP/eXTgULCh3FC2RyvJ5whtEvkhEqcJ5UamUPXaelbf/vyRJmD9rKo4dPoB5S1aiSNFiOtuLOBVDAXsHnDtzSrvuzZs3uHThPMp/5mXquFoi3HMv70p4+OCBzrqHDx+gSBEneQKlQ4SyNCaVSjmLCGTvBgMAo0aNwqhRo3D//n2EhYUBAAoXLgxXV9dMjnzL0jJtl5fXycbJ1qVbdwSOHgkPT094eVXEti2bEBoaCv8OHY1zASMRIWd8/CuEhPw3S8OTJ49x40YwbG1tFfWHU4SyFCEjIEZOETLOmz0DtevWQ+HCToiOjsLK5Uvx6tVLtFDYx/hyl6WNZS6ULJxP+3OJQnlQoUQBxLxMxOOoV2hTvQQinyfiUeRLlHe2w8yvq2Hn2RAc/Pe/qfEK2VrDMb81Sv7//OvlnfPjRUIyHke+RMyrpBzJPX/mVOz/exemzl4A69w2iPr/1tU8efLA0soKKpUK7Tt2xvo1K1CseAkUdXbGhtU/wcrKCg0//yJHMmWV3Pc8M526dEOPrp2w6qdlaPR5E1y7cgXbt25B4IRJckdLQ+llSfJRRGU9laura5oK+qNHjzBhwgSsWrVKlkxNmjZDXGwMli9dgoiIcJQu44bFPy6Hk1NRWfKkR4Sc165eRa8eXbU/z5n5tqtSi1ZtMGXqdLlipSFCWYqQERAjpwgZw8OfYcyo7xAbEwu7AnaoUMELa9ZvQhEFZQTkL8tKpRywe2IT7c8zulUFAKw/fAd9lxxHYbvcCOpaFYXyWyEsJgEbj97F9K26s6l809gdY/y9tT/vndwMANBn8XFsOJIzX0L0x7ZNAIAhfXvorB81fgqaNm8NAPiqaw8kJiZi3szv8eLFc3iUr4BZC5cht41NjmTKKrnveWbKe1bA7Hk/YNGCeVixbAmcihbDdyNHo+kXLeSOlobSy9KYzIQZ2qkMKkmSJLlDZOTy5cuoVKkSNBpN5ju/w1gt6/T/g5gEIMrHWfRpSdYo/wWUSy3Gi8eh0xq5I2Tq9k+d5I6QKTubnP9WVmN4o0mRO0KmzNWy9ybOEitFNc0Cf155JncErRYVlDV1qz6y374dOzL+Fr579+6ZKAkRERERkbLIXllv3bo1VCoVMmrg57RFRERERB8HVusMI/vnN0WKFMG2bduQkpKid7lw4YLcEYmIiIiIZCF7Zd3HxyfDCnlmre5ERERERB8r2bvBjBgxAq9evUp3e+nSpXHo0CETJiIiIiKinKLibDAGkb2yXqtWrQy329jYoE6dOiZKQ0RERESkHLJ3gyEiIiIiIv1kb1knIiIiok8HZ4MxDFvWiYiIiIgUii3rRERERGQyZhxgahC2rBMRERERKRQr60RERERECsVuMERERERkMhxgahi2rBMRERERKRQr60RERERECsVuMERERERkMuwGYxi2rBMRERERKRQr60RERERECsVuMERERERkMip+KZJB2LJORERERKRQbFmnTHEgCNGHi0t4I3eETNnnsZA7QpaEb+gmd4RM2bf7Ue4ImYr5rZ/cEbLEXM32xI+VGesVBuErgYiIiIhIoVhZJyIiIiJSKHaDISIiIiKT4QBTw7BlnYiIiIhIoVhZJyIiIiJSKHaDISIiIiKT4SxzhmHLOhERERGRQrFlnYiIiIhMhgNMDcOWdSIiIiIihWJlnYiIiIhIodgNhoiIiIhMxoy9YAzClnUiIiIiIoViZZ2IiIiISKHYDYaIiIiITIazwRiGLetERERERArFyjoRERERkUKxGwwRERERmYyKvWAMwpZ1IiIiIiKFYmU9CzZt3ICmjeujSsUK6OjfFhfOn5M7kl4i5BQhIyBGThEyAmLkVFLGX9asQL+vO+KLetXQtkkdjBsxCCEP7+vsU79aBb3Lr+tWy5T6P0oqS302/7oRX7ZpCb9qPvCr5oOu/+uA48eOmuz6w9tXxPE57RD+a088/PlrbB7TBGWK5k93/4X9ayNhRz8MbPmZznrXwvmwKeBzhKz7Gs9+7Yn1IxuhUH7rHE6v6/y5s/i2f180rOsHr/LuOHhgv0mvbwilP5epRMmZXSoFLSJQfGX92bNnmDx5smzX37N7F2ZOD0Kv3v2waevvqFTJB/379ELo06eyZdJHhJwiZATEyClCRkCMnErLePniObRq3xGLVm7ArB+WQ6PRYOSgPkhIiNfus3XXIZ1lxNjJUKlUqF2/oSyZUymtLPVxLOyIb4d+hw2btmLDpq2oWrU6hn47AHfv3DbJ9Wt5OuHHv66izojf0Hz8n1CrVdg5qTlyW6btldqimguquDniadRLnfW5LXNh56TmkAA0HbsD9Udth0UuNbaNbWrS7gUJCfFwd3fH6MDxprvoBxDhuQTEyUmmp5IkSZI7REYuX76MSpUqQaPRGHTc62TjXP9/Hf1RzsMDY8dP0q5r3aIp6tVviMFDvzPORYxAhJwiZATEyClCRkCMnDmdMeplUraOj42JRtsmdTDvx9XwqlhZ7z7jRgxCfHw85ixe8UHXsM9jkZ2IWjldlik59N9VnZrVMOS7EWjTrn22z2Xf7keD9nfIZ4VH67ujYcDvOHEtVLveqYANjs5uixYTdmL7+GZY9OcVLNrxLwCggXcx/DHhCxTptAovEt4AAPLbWCB0Y080G7cDhy4/yfCaMb/1M/C3ypxXeXfM+2Ex6jeQ9w2jPiL8HQJyNqeVwkYonrgdI3cELd8ydnJHyJTsLev//vtvhsvNmzdly/YmKQnB16+hRk0/nfU1avri8qWLMqVKS4ScImQExMgpQkZAjJwiZHz18m2rar58tnq3R0dF4vSJY2jWso0pY6UhQlm+T6PRYM+uv5CQEI/PvL1lyZDP5u0bpZgXidp1KhWwclgDzNt+CcGP0lZqLM3VkAAkvvmvEev1Gw00mhTU9CiS45lFIspzKUpOYzFTqRSziED291re3t5QqVTQ18Cful4lU2HGxMZAo9HA3t5eZ729vQMiIyNkyaSPCDlFyAiIkVOEjIAYOZWeUZIkLFkwCxW8KsG1VBm9++zdtQO5bXKjVl15WzSVXpbvun3rJrr97yskJSXCOnduzFmwCKVKlZYly4wevjhxLRTXQ6K1675rVxHJmhQs/vOK3mP+ufkMr16/wdSva2D8z2egUgFTv64OtdoMhe1ymyq6EER5LkXJSfKQvbJub2+PGTNmoEGDBnq3X7t2DS1atMjwHImJiUhMTNRZJ6ktYWlpaZSM779ZkPMNREZEyClCRkCMnCJkBMTIqdSMP8yaint3buGHZWvT3Wf3n9vR4PMvYGGkv3fZpdSyfJeLqyt+3bYdL54/x4F9ezE+cDRWrFln8gr7vD61UMGlABqM/l27rmIpBwxo8RlqDt2S7nGRz1/jfzP24od+tdG/eQWkSBI2H72NC3cioElRdM9W2YjwXALi5CTTkr2y7uPjg6dPn6JEiRJ6t8fGxuptdX9XUFAQJk2apLMucNwEjB0/MVvZ7PLbQa1WIzIyUmd9dHQU7O0dsnVuYxIhpwgZATFyipARECOnkjP+MHsaTh47jPnL1qCgY2G9+/x78TwePXyA8d/PNm04PZRclu8zN7eAs/Pb/3PKe1bAtWtXsXH9zxg7wXSTGczt7YfmVV3QcMzveBL1Srvet7wTCtla49bKLtp1udRmmN69Bga2qICyvTYAAA5ceozyfX6BfV4rJKekIO5VEu6v7YaHz16Y7HcQgSjPpSg5jYVvPwwje5/1Pn36wMXFJd3tzs7OWL064+nIAgICEBcXp7OMGBWQ7WzmFhYo51Eep0+e0Fl/+uRJeHlXzPb5jUWEnCJkBMTIKUJGQIycSswoSRIWzJqKY4cPYM7ilSjiVCzdfXf/+RvcynqglJu7CRPqp8SyzDJJQlJS9gYCG2JeHz+0quGKJmN3pKlc/3LoJqoM2oxqg7dol6dRLzFv+yW0mPhXmnNFvXiNuFdJ+L/27jwuymrx4/h3ZBkWAQGVxRIVFHEJBU1FcQ9FQ9FyyVLS9NbNcitT08IdzeqquUW55E6umamIRpZhoqJmSmlpooYLIIigrOf3hz+nxhm2HOZ5jn7f9zWv1+WZh3k+MAaHw5lDh6dqoaaTLXYm/mmmj0IOsvy7lKWTlKH4zHqfPqW/KMrZ2RkRERGlnqPVGi55MdVuMIMjhmLyxHfQqEkT+Ps3x5ZNMUhNTUW/AQNNcwETkaFThkZAjk4ZGgE5OtXWuGDeLOyP3YWZ8xbAzt4eGen3Ztrs7atCa2OjOy/n9m0c2B+H10a/rUinMWr7XBrzyfyP0Ta4Pdzd3ZGTk4PY3btw9EgiFi/7zCzXn/9aMAa0r49+s3bj9p18uP3/3uhZufm4m1+EjOw8ZGTrL+ssKCzGtcw7OHclU3dscBdf/HY5Ezey7qBVQzd8OLwdPtlxUu+cypabk4OUlBTd21cuX8avyclwcnKCh6en2TrKIsO/S0CeTjI/xQfrZbl06RIiIyOxYsUKRa7fPbQHsjJvInrpEty4cR0+9Rtg8bJoeHrWUqSnJDJ0ytAIyNEpQyMgR6faGndsiQEAjP3vML3j77w3A92fDde9HR+3G0IIdA4JNWdeqdT2uTQmPT0dUya9g7QbN1DVwQH1G/hi8bLP0DqorVmu/2qPJgCAuKhwveMj5n+Ltd+Wf/ezBrWqYfqQ1nCpqsXF69n4YNMxLPzqZ1Omlun06V8wfOgQ3dsffhAFAOjVuw9mzJ5j1pbSyPDvEpCn0yS4DqZCuM86EVEleth91s3BVPusV7bK2mfdlCq6z7oSKmOfdVI3te2z/tMfmUon6LT2rqZ0QpkUf/p27NhR6v3nz583UwkRERERVTYNp9YrRPHBenh4eIn7rN/HbYuIiIiI6HGk+G4wHh4e2LJlC4qLi43ekpKSlE4kIiIiIlKE4oP1wMDAUgfkZc26ExEREZE8NBr13GSg+DKY8ePHIycnp8T7fXx8EB8fb8YiIiIiIiJ1UHywHhwcXOr99vb26NChg5lqiIiIiIjUQ/HBOhERERE9PiRZfaIaiq9ZJyIiIiIi4zhYJyIiIiJSKS6DISIiIiLz4TqYCuHMOhERERGRSnFmnYiIiIjMRsOp9QrhzDoRERERkUpxsE5EREREpFJcBkNEREREZqPhKpgK4cw6EREREZFKcbBORERERKRSXAZDRERERGbDVTAVw5l1IiIiIiKV4sw6EREREZkPp9YrRCOEEEpHVIa7hUoXEBHR40aG76gurUYpnVAuNxMXKp3wyLBR2dRs0sVbSifoBHg5Kp1QJi6DISIiIiJSKZX9rEVEREREjzIN18FUCGfWiYiIiIhUioN1IiIiIiKV4mCdiIiIiMxGo1HP7d9YsmQJ6tatCxsbGwQGBuKHH34o8dytW7fimWeeQY0aNeDo6Ig2bdogNja2QtfjYJ2IiIiIqBxiYmIwZswYTJ48GcePH0dwcDBCQ0ORkpJi9Pzvv/8ezzzzDHbt2oVjx46hU6dOCAsLw/Hjx8t9TW7dSEREZCIyfEfl1o2PH7Vt3XgiJVvpBJ1mtR0qdH6rVq0QEBCApUuX6o75+fkhPDwcUVFR5XqMxo0bY8CAAXj//ffLdT5n1omIiIjIbDQqulVEfn4+jh07hpCQEL3jISEhSEhIKNdjFBcXIzs7Gy4uLuW+rsp+1iIiIiIiMo+8vDzk5eXpHdNqtdBqtQbnpqWloaioCG5ubnrH3dzccPXq1XJd76OPPkJOTg769+9f7kbOrBMRERGR+Sg9nf6PW1RUFJycnPRuZS1n0TzwylQhhMExYzZs2ICpU6ciJiYGNWvWLPP8+zizTkRERESPpUmTJmHcuHF6x4zNqgNA9erVYWFhYTCLfv36dYPZ9gfFxMTglVdewaZNm9C1a9cKNXJmnYiIiIgeS1qtFo6Ojnq3kgbr1tbWCAwMRFxcnN7xuLg4BAUFlXiNDRs24OWXX8b69evRs2fPCjdyZp2IiIiIzEZT4Zd2qse4ceMwePBgtGjRAm3atEF0dDRSUlLw2muvAbg3U3/lyhWsXr0awL2B+pAhQ7BgwQK0bt1aNytva2sLJyencl2Tg3UiIiIionIYMGAA0tPTMX36dKSmpqJJkybYtWsXvLy8AACpqal6e65/+umnKCwsxMiRIzFy5Ejd8YiICKxatapc1+Q+60RERCYiw3dU7rP++FHbPus/X7qtdILOU09WVTqhTCp7+oiIiIjoUVaOjVPoH/gCUyIiIiIileJgnYiIiIhIpThYL4eYDesQGtIZLZs3xcB+fZF07KjSSUbJ0ClDIyBHpwyNgBydMjQCcnTK0Aiov/PY0SMYNfI1PNOpHZo18cW3+/eZ9fptA7yxef5/cD52Bu4kLURYx6Z690dPfRF3khbq3Q58ob9XdWz0mwbnrI6KMOeHoaP25/s+WToflgr+FpLuJgPVDNYvX76M27cNX3BQUFCA77//XoGie/bs3oUP5kRhxH/+i5jN2xEQEIjXXx2B1L/+UqzJGBk6ZWgE5OiUoRGQo1OGRkCOThkaATk679zJRQNfX0x8931Frm9vY41TZ69g7NxNJZ4T++MZ1Hlmsu4W/uYyg3OWb/1R75w3ZsVUZrZRMjzfgDydZH6KD9ZTU1Px9NNPw8vLC9WqVUNERITeoD0jIwOdOnVSrG/NFyvR57nn0Pf5fqjn7Y13Jk2Gu4c7vozZoFiTMTJ0ytAIyNEpQyMgR6cMjYAcnTI0AnJ0tgvugDdGjUWXZ0IUuf7ehGRMW/INvvr25xLPyc8vxLX0bN3t5q1cg3Pu3C3QO+fW7buVmW2UDM83IE+nSSg9nS7Z1Lrig/WJEyfCwsIChw8fxp49e3DmzBl07NgRN2/e1J2j1O6SBfn5SD5zGm2C2ukdbxPUFidPHFekyRgZOmVoBOTolKERkKNThkZAjk4ZGgF5OmUQ3MIHF/fNws/bpmDxlIGo4Wy4Bd6A0Ba4tH82jm2ahKgxvVHVzvhfhqwssjzfsnSSMhTfunHfvn3Ytm0bWrRoAQAIDg7GgAED0LlzZ+zfvx8AoFFoj5+bmTdRVFQEV1dXveOurtWRlnZDkSZjZOiUoRGQo1OGRkCOThkaATk6ZWgE5OlUu70JZ7B133GkpN5EnVqueP+/PbD70zcQ9OKHyC+494dONu4+ij+vpONaejYae3tg+pthaNqgFp59fYnZOmV5vmXpJGUoPljPysqCs7Oz7m2tVovNmzejX79+6NSpE9auXVvmY+Tl5SEvL0/vmLDQQqs1zU/wD/6wIIRQ7AeI0sjQKUMjIEenDI2AHJ0yNAJydMrQCMjTqVab9/4923vmj1QknUnBb99MRWhwI93SmZXbDumd8/ulG0hYNx7NGj6BE79eNmuvLM+3LJ0PSyPL+hOVUHwZTL169fDzz/pr4iwtLbFp0ybUq1cPzz77bJmPERUVBScnJ73bvLlRD93mXM0ZFhYWSEtL0zuekZEOV9fqD/34piJDpwyNgBydMjQCcnTK0AjI0SlDIyBPp2yupt1CSmoGfJ6sWeI5x5MvIb+gED61a5itS5bnW5ZOUobig/XQ0FBER0cbHL8/YG/WrFmZa9YnTZqErKwsvdv4CZMeus3K2hp+jRrjp4Qf9Y7/lJAA/2bNH/rxTUWGThkaATk6ZWgE5OiUoRGQo1OGRkCeTtm4ONnhCTdnpKZllXhOI28PWFtZIjXtltm6ZHm+ZekkZSi+DGbWrFnIzTV8BTlwb8C+detWXL5c+q/LtFrDJS93C03TNzhiKCZPfAeNmjSBv39zbNkUg9TUVPQbMNA0FzARGTplaATk6JShEZCjU4ZGQI5OGRoBOTpzc3OQkpKie/vKlcv49ddkODk5wcPDs9Kvb29rDe8n/54Br1PLFU81qIWbt3KRkZWDKa+GYvu3J5F64xa8PF0w/Y0wpGfmYEf8vd+U132iOgaGtkDswdNIy8yBXz13zBkXjuPJl3DoxPlK7/8nGZ5vQJ5OU3gEV/ZUKsUH65aWlnB0dCzx/r/++gvTpk3DihUrzFj1t+6hPZCVeRPRS5fgxo3r8KnfAIuXRcPTs5YiPSWRoVOGRkCOThkaATk6ZWgE5OiUoRGQo/P0L79gxLAhurc/+uDe0s6w3n0wY9acSr9+QKPa2PvZKN3bH7zVFwCwZsdhjIr6Eo3re2LQs0+jmoMtrqbdwoEj5zB44krczr33+rGCgkJ0eroBRr7QAVXttLh87Sb2/HAas6L3oLjYvDu8yfB8A/J0kvlphFL7IpbTyZMnERAQgKKiogq9n6lm1omIiMpL3d9R73FpNarsk1TgZuJCpRMeGTaKT83qO/NXjtIJOo087ZVOKJPiT9+OHTtKvf/8efP+uoyIiIiIKg9XwVSM4oP18PBwaDSaUl9E+ihuW0REREREVBbFd4Px8PDAli1bUFxcbPSWlJSkdCIRERERmYpGRTcJKD5YDwwMLHVAXtasOxERERHRo0rxZTDjx49HTk7JLzTw8fFBfHy8GYuIiIiIiNRB8cF6cHBwqffb29ujQ4cOZqohIiIiosqkkWX9iUoovgyGiIiIiIiM42CdiIiIiEilFF8GQ0RERESPD+7IXTGcWSciIiIiUinOrBMRERGR2XBivWI4s05EREREpFIcrBMRERERqRSXwRARERGR+XAdTIVwZp2IiIiISKU4WCciIiIiUikugyEiIiIis9FwHUyFcGadiIiIiEilOFgnIiIiIlIpLoMhIiIiIrPRcBVMhWiEEELpiMpwt1DpAiJDBYXFSieUS5Uq6v9KaiFBIwAUF6v/S6xGku+cBUXq/+/H0kL9n8ti9X8aAQA1B61UOqFMaRuHKp1QLnZW6vp3+fv1O0on6PjUtFU6oUycWSciIiIis1HXjw7qxzXrREREREQqxcE6EREREZFKcRkMEREREZkP18FUCGfWiYiIiIhUioN1IiIiIiKV4jIYIiIiIjIbDdfBVAhn1omIiIiIVIqDdSIiIiIileIyGCIiIiIyG0n+aLJqcGadiIiIiEilOLNORERERGbDifWK4cw6EREREZFKcbBORERERKRSXAZDRERERObDdTAVwpl1IiIiIiKV4mCdiIiIiEiluAyGiIiIiMxGw3UwFcKZ9XKI2bAOoSGd0bJ5Uwzs1xdJx44qnWSUDJ0yNALq7wwL7YIW/n4Gt7mzpyudVqIVn3+KgKYNMW/ubKVTDKj9+f4yZgP69+2Fdq0D0a51IIa8OAAHf/he6SwDx44ewaiRr+GZTu3QrIkvvt2/T+kkA4WFhVi6aD56h3ZFu6eboXePZ/DZssUoLi5WOk1n+Wef4sUBz6Pt0wHo3D4IY0eNxJ8XziudZeDTJZ8g8KmGereQTu3Mdv23+zyFH+aG4drawfhzxQuImdAF9T0d9c7p3coLX70XgpSVg5C7ZRiequNi8DjDnvHFnmmhuLrmJeRuGQYnO2tzfQg6sjznpAxVDNbT09MRHx+PjIwMAEBaWhrmzp2L6dOnIzk5WdG2Pbt34YM5URjxn/8iZvN2BAQE4vVXRyD1r78U7XqQDJ0yNAJydK5etwl79n+vuy3+dDkAoMsz3RUuM+70L6ewdfOXqN/AV+kUAzI8325ubnhzzFtYt3Ez1m3cjKdbtcbYUSPxx+/nlE7Tc+dOLhr4+mLiu+8rnVKi1Ss/x5ZNMRg/aQq+3PYNRo19G2u/WIGYDWuVTtNJOnoEA14YhNXrY7A0egWKCgvx3/8Mx53cXKXTDHh710fstz/objFbdpjt2sGN3fHpnmR0nPQ1wqbFwrKKBl+/3x122r8XDdjZWOKnX6/j/bUl/wBua22BuBNXMG/rz+bINkqm59wUNBr13GSgEUIIJQMSExMREhKCW7duoVq1aoiLi0O/fv1gaWkJIQSuXLmCgwcPIiAgoEKPe7fQNH0vDuwHv0aNMOX9abpj4WGh6NS5K0aPfcs0FzEBGTplaAQqt7OgsHJm7z76YDZ++P4Atn29BxoTfPWpUsV0X8Fyc3MwqH9fTJocic+jl6JBQz+Mn/DuQz+uhYkaK/vfZXFx5XyJ7dC2Fca8NR59+j7/0I9lin8zD2rWxBcfL1iMzl26muwxC4oe/r+fsW+8BhdXV7w3bZbu2DvjRsHGxgbTZ3/w0I9vaWH6z2VGRga6tA/C56vWILBFy4d+PFP9EuHTJZ/gu/j92LBpu2ke8AE1B62s0PnVHW2QsnIQnnnvG/x45prefbVrVMWvy/qj9Vvb8fOfGUbfP7ixO2Kn94DH4LXIys0v1zXTNg6tUGN5mfo5t7NS16g0JSNP6QSd2i5apRPKpPjM+uTJk9GvXz9kZWXh3XffRXh4OLp06YKzZ8/i3LlzGDRoEGbMmKFIW0F+PpLPnEabIP1f67UJaouTJ44r0mSMDJ0yNALydP5TQUE+dn3zNXqF962UQdfDmjNrOtoFd0SrNkFKpxiQ8fkuKirCnt3f4M6dXDzl30zpHOn4Nw/EkcSfcPHPCwCAs7/9ipPHk9A2uIPCZSW7fTsbAODk5KRwiaGUixfRrUswwrp3waR3xuHy5UuKtTjaWQEAbmarZyD4b6n5OSfzU/wFpseOHcPChQvh4OCA0aNHY8KECRgxYoTu/pEjRyIsLEyRtpuZN1FUVARXV1e9466u1ZGWdkORJmNk6JShEZCn85+++3Y/bmdnI6xXH6VTDMTu/ga/njmDNRs3K51ilEzP97mzvyHipReQn58HWzs7fDR/Eby9fZTOkk7EsOG4fTsb/cJ7ooqFBYqLivDfN8egW2hPpdOMEkLgow/moHlAIHzqN1A6R0+Tpv6YPmsOanvVQUZGOpZHL8WwwS/gy21fo1o1Z7P3zH25FX48cxVnLmWa/dqmpObn3FTUN62kbooP1vPz82FrawsAsLKygp2dHapXr66739XVFenp6aU+Rl5eHvLy9H+SFhZaaLWm+dXGg7OVQghVzmDK0ClDIyBPJwB8tW0LgtoGo0bNmkqn6Ll6NRXz5szGkujlJvtvsbLI8HzXqVsXGzdvQ3b2LeyP24v3p0zE5yvXcMBeQXF7dmH3N19jZtQ81POpj7O/JuPjeVGoUaMmnu0VrnSegTmzZuDc2d+wcvV6pVMMtA1ur/f2U081Q++eIdi5YzteGlI5y0NK8r/hbdDEyxldJ39j1utWBjU/56QMxZfBPPnkkzh//u9XPG/cuBEeHh66t1NTU/UG78ZERUXByclJ7zZvbtRDtzlXc4aFhQXS0tL0jmdkpMPVtfQmc5KhU4ZGQJ7O+1L/uoLEw4fQ2wTrlk0t+fRpZGSk48UBz6Fls8Zo2awxjh09go3r1qBls8YoKipSOlGq59vKyhq1a3uhceOmGDXmLTRo0BAb1q5WOks6C/73ISKGDUdIaE/41G+AHmG98cJLEVi1PFrpNANzZs/Agfhv8dmK1XBzd1c6p0y2dnbwqd8AKRcvmvW6H73SGj1bPonukbtxJUPuF2TK9pyTeSg+WB84cCCuX7+ue7tnz566mXYA2LFjB55++ulSH2PSpEnIysrSu42fMOmh26ysreHXqDF+SvhR7/hPCQnwb9b8oR/fVGTolKERkKfzvh1fbYOziwvaqXC97dOtW+PLrTuwYdM23a1R4yYI7RmGDZu2wcLCQulE6Z5vfQL5+eV7ERz9Le/uHVSpov+tr4qFBYSKtm4UQmDOrOn4dl8cPl2xCrWeeELppHLJz8/HhfN/oHqNGma75sfDW6N3Ky+ETt2Di9dvm+26pibrc/5vKb0DjGy7wSi+DCYyMrLU+ydPnlzmN3Wt1nDJi6l2gxkcMRSTJ76DRk2awN+/ObZsikFqair6DRhomguYiAydMjQC8nQWFxfj66+24tmwcFhaKv6fsgF7+6oG6y1tbW3hVK2aqtZhyvB8f7LgY7Rt1x7u7u7IyclB7J5dOHokEYuXfqZ0mp7c3BykpKTo3r5y5TJ+/TUZTk5O8PDwVLDsb+06dMLKzz6Fu7sH6nnXx2+/nsH6NavQq3dfpdN0omZOx+5dO/G/hYthb2+ve/1E1aoOsLGxUbjub//7cC7ad+wEd3dP3Zr1nJzbCDPTcqL5I9qgf3A99J+zH7fvFMCt2r2JvqzcfNzNv/ebO+eq1niyelV4uNgBAOp73nvB5rXMO7iWeQcA4FbNFm7VbOHtfm+P9sZezrh9pwCX0m7j5m3z/EAsy3NOylDfd/gHpKenIzIyEitWrFDk+t1DeyAr8yaily7BjRvX4VO/ARYvi4anZy1FekoiQ6cMjYA8nYk/HcLV1FT0ClfPIENGMjzf6enpmPLuO0i7cQNVHRxQv74vFi/9DK2D2iqdpuf0L79gxLAhurc/+uDecsSw3n0wY9YcpbL0jJ84BcsWL8Dc2dNxMyMD1WvURN/n+2P4q68rnaazKWYDAGDE0CF6x6fNnK2q/96vX7+Gdye8hcybmXB2cUbTpv5YtTYGHmb6b+c/3f0AAHtn9NA/vuh7rI3/HQDQs2VtRL/x99r6NW91AgDMijmOWV/e2/FpeEhDTB7w92/S9s3safA4lU2W55yUofg+62U5efIkAgICKry+1VQz60SmVFn7rJuaKfdZryym2me9slXWPuumpLYX05bEFPusV7bK2Gfd1FS04qdUFd1nXQmVtc+6qaltn/XLN9WzhO8JZ/P/xdqKUnxmfceO0v/a2T9ffEpERERE9DhRfLAeHh4OjUaD0ib4ZZn1ISIiIqLScVhXMYrvBuPh4YEtW7aguLjY6C0pKUnpRCIiIiIiRSg+WA8MDCx1QF7WrDsRERER0aNK8WUw48ePR05OTon3+/j4ID4+3oxFRERERFRZuAqmYhQfrAcHB5d6v729PTp0UN8ffCEiIiIiqmyKL4MhIiIiIiLjFJ9ZJyIiIqLHB3eDqRjOrBMRERERqRQH60REREREKsVlMERERERkNhruB1MhnFknIiIiIlIpzqwTERERkflwYr1COLNORERERKRSHKwTEREREakUl8EQERERkdlwFUzFcGadiIiIiEilOFgnIiIiIlIpLoMhIiIiIrPRcB1MhXBmnYiIiIhIpTRCCKF0RGW4W6h0ARERET3KnFu+oXRCudw5vkjpBD3XswuUTtCp6WCldEKZuAyGiIiIiMxGw/1gKoTLYIiIiIiIVIoz60RERERkPpxYrxDOrBMRERERqRQH60REREREKsVlMERERERkNlwFUzGcWSciIiIiUikO1omIiIiIVIrLYIiIiIjIbDRcB1MhnFknIiIiIlIpzqwTERERkdnwL5hWDGfWiYiIiIhUioN1IiIiIiKV4jIYIiIiIjIbvsC0YjizTkRERESkUhysExERERGpFAfrREREREQqxcE6EREREZFKcbBeDjEb1iE0pDNaNm+Kgf36IunYUaWTjJKhU4ZGQI5OGRoBOTplaATk6JShEZCjU4ZGQI5ONTX++s003Dm+yOD2v4n9dedMfrUHzu+dhYxDHyP2s9Hwq+euWC8pT7WD9Xr16uHcuXNKZ2DP7l34YE4URvznv4jZvB0BAYF4/dURSP3rL6XT9MjQKUMjIEenDI2AHJ0yNAJydMrQCMjRKUMjIEen2hrbvTQPdbpO0t16vPYJAGBr3HEAwFsvd8Wolzph7Jwv0e6lebiWfgvfLHsTVe20ivRWBo1GPTcZaIQQQsmAhQsXGj0+btw4vPPOO3B3v/fT5KhRoyr0uHcLHzoNAPDiwH7wa9QIU96fpjsWHhaKTp27YvTYt0xzEROQoVOGRkCOThkaATk6ZWgE5OiUoRGQo1OGRkCOzspsdG75xsPmYd7bzyE0uAma9L7Xd37vLCxeH4+PVu0DAFhbWeLi/tmYsuArLN/y47+6xp3jix6605Qy7xQpnaBTzdZC6YQyKb7P+pgxY1CrVi1YWuqnFBcXY/Xq1bCysoJGo6nwYN0UCvLzkXzmNIYN/4/e8TZBbXHyxHGz95REhk4ZGgE5OmVoBOTolKERkKNThkZAjk4ZGgE5OtXeaGVpgYE9WmLh2m8BAHVqucKjhhP2HfpVd05+QSF+OPY7WvvX+9eDdbXRQJIpbZVQfLA+YsQIJCYmYv369fDz89Mdt7Kywt69e9GoUSPF2m5m3kRRURFcXV31jru6Vkda2g2FqgzJ0ClDIyBHpwyNgBydMjQCcnTK0AjI0SlDIyBHp9obe3V6CtUcbLH268MAAPfqjgCA6xnZeuddT89GbQ8Xs/eROii+Zv3TTz9FZGQkunXrhkWL/t2vafLy8nDr1i29W15enskaNQ8sahJCGBxTAxk6ZWgE5OiUoRGQo1OGRkCOThkaATk6ZWgE5OhUa2NEeBBifzyD1BtZescfXKGs0Rgeo8eH4oN1AAgPD8ehQ4ewbds2hIaG4urVqxV6/6ioKDg5Oend5s2Neugu52rOsLCwQFpamt7xjIx0uLpWf+jHNxUZOmVoBOTolKERkKNThkZAjk4ZGgE5OmVoBOToVHNjbQ9ndG7li1XbE3THrqbdAgC4uTrqnVvDxcFgtl1mSr+oVLYXmKpisA4AtWrVwr59+9C+fXs0b968Qj9BTpo0CVlZWXq38RMmPXSTlbU1/Bo1xk8J+mvEfkpIgH+z5g/9+KYiQ6cMjYAcnTI0AnJ0ytAIyNEpQyMgR6cMjYAcnWpuHNyrDa5nZGP3D6d1x/68ko7UG1no0rqh7piVpQWCA33w08nzSmSSCii+Zv2fNBoNJk2ahJCQEBw8eBAeHh7lej+tVgutVn9LI1PtBjM4YigmT3wHjZo0gb9/c2zZFIPU1FT0GzDQNBcwERk6ZWgE5OiUoRGQo1OGRkCOThkaATk6ZWgE5OhUY6NGo8GQ3q2xbudhFBUV6923eH08xr8Sgt9TruP3lBt455VuuHO3ADG71bd/PZmHqgbr9wUGBiIwMBAAcOnSJURGRmLFihWKtHQP7YGszJuIXroEN25ch0/9Bli8LBqenrUU6SmJDJ0yNAJydMrQCMjRKUMjIEenDI2AHJ0yNAJydKqxsXMrX9T2cMEX238yuO+jVftgo7XG/EkD4OxohyO//Iln/7sIt3NN91o8pUmy+kQ1FN9nvSwnT55EQEAAiooqtienqWbWiYiIiIwxxT7r5qC2fdaz7xaXfZKZONioZkV4iRSfWd+xY0ep958/zzVaRERERPR4UnywHh4eDo1GU+oLStWwvRIRERERmQCHdRWi+Ny/h4cHtmzZguLiYqO3pKQkpROJiIiIiBSh+GA9MDCw1AF5WbPuRERERCQPjYr+JwPFl8GMHz8eOTk5Jd7v4+OD+Ph4MxYREREREamD6neD+be4GwwRERFVJu4G8+/czlPP0LOqVv2z64rPrBMRERHR44P7hlSM4mvWiYiIiIjIOA7WiYiIiIhUistgiIiIiMhsuAqmYjizTkRERESkUhysExERERGpFJfBEBEREZH5cB1MhXBmnYiIiIhIpTizTkRERERmo+HUeoVwZp2IiIiIqJyWLFmCunXrwsbGBoGBgfjhhx9KPf/AgQMIDAyEjY0N6tWrh2XLllXoehysExERERGVQ0xMDMaMGYPJkyfj+PHjCA4ORmhoKFJSUoyef+HCBfTo0QPBwcE4fvw43n33XYwaNQpbtmwp9zU1Qghhqg9ATe4WKl1AREREjzLnlm8onVAud44vUjpBj5rGaDYVXBDeqlUrBAQEYOnSpbpjfn5+CA8PR1RUlMH5EyZMwI4dO5CcnKw79tprr+HkyZM4dOhQua7JmXUiIiIiojLk5+fj2LFjCAkJ0TseEhKChIQEo+9z6NAhg/O7deuGo0ePoqCgoFzX5QtMiYiIiOixlJeXh7y8PL1jWq0WWq3W4Ny0tDQUFRXBzc1N77ibmxuuXr1q9PGvXr1q9PzCwkKkpaXBw8Oj7EhB5XL37l0RGRkp7t69q3RKiWRoFEKOThkahZCjU4ZGIeTolKFRCDk6ZWgUQo5OGRqFkKNThsZHTWRkpACgd4uMjDR67pUrVwQAkZCQoHd85syZwtfX1+j71K9fX8yePVvv2MGDBwUAkZqaWq7GR3bNuqndunULTk5OyMrKgqOjo9I5RsnQCMjRKUMjIEenDI2AHJ0yNAJydMrQCMjRKUMjIEenDI2PmorMrOfn58POzg6bNm1Cnz59dMdHjx6NEydO4MCBAwbv0759ezRv3hwLFizQHdu2bRv69++P3NxcWFlZldnINetERERE9FjSarVwdHTUuxkbqAOAtbU1AgMDERcXp3c8Li4OQUFBRt+nTZs2Bufv3bsXLVq0KNdAHeBgnYiIiIioXMaNG4fPP/8cK1asQHJyMsaOHYuUlBS89tprAIBJkyZhyJAhuvNfe+01XLx4EePGjUNycjJWrFiB5cuX4+233y73NfkCUyIiIiKichgwYADS09Mxffp0pKamokmTJti1axe8vLwAAKmpqXp7rtetWxe7du3C2LFjsXjxYnh6emLhwoV47rnnyn1NDtbLSavVIjIyssRfjaiBDI2AHJ0yNAJydMrQCMjRKUMjIEenDI2AHJ0yNAJydMrQSMDrr7+O119/3eh9q1atMjjWoUMHJCUl/evr8QWmREREREQqxTXrREREREQqxcE6EREREZFKcbBORERERKRSHKyX4fvvv0dYWBg8PT2h0Wiwfft2pZMMREVFoWXLlnBwcEDNmjURHh6O3377TeksA0uXLsVTTz2l28e0TZs22L17t9JZpYqKioJGo8GYMWOUTtEzdepUaDQavZu7u7vSWQauXLmCl156Ca6urrCzs0OzZs1w7NgxpbP01KlTx+BzqdFoMHLkSKXTdAoLCzFlyhTUrVsXtra2qFevHqZPn47i4mKl0/RkZ2djzJgx8PLygq2tLYKCgnDkyBFFm8r6Gi6EwNSpU+Hp6QlbW1t07NgRp0+fVlXj1q1b0a1bN1SvXh0ajQYnTpwwa195OgsKCjBhwgQ0bdoU9vb28PT0xJAhQ/DXX3+pphG497WzYcOGsLe3h7OzM7p27YrDhw+btbE8nf/06quvQqPRYP78+WbrI3XhYL0MOTk58Pf3x6JFi5ROKdGBAwcwcuRI/PTTT4iLi0NhYSFCQkKQk5OjdJqeJ554AnPmzMHRo0dx9OhRdO7cGb179zb7N8byOnLkCKKjo/HUU08pnWJU48aNkZqaqrudOnVK6SQ9N2/eRNu2bWFlZYXdu3fjzJkz+Oijj1CtWjWl0/QcOXJE7/N4/49X9OvXT+Gyv82dOxfLli3DokWLkJycjA8++ADz5s3DJ598onSanuHDhyMuLg5r1qzBqVOnEBISgq5du+LKlSuKNZX1NfyDDz7Axx9/jEWLFuHIkSNwd3fHM888g+zsbNU05uTkoG3btpgzZ47ZmkrqKKkzNzcXSUlJeO+995CUlIStW7fi7Nmz6NWrl2oaAaBBgwZYtGgRTp06hYMHD6JOnToICQnBjRs3VNV53/bt23H48GF4enqaqYxUSVC5ARDbtm1TOqNM169fFwDEgQMHlE4pk7Ozs/j888+VzjCQnZ0t6tevL+Li4kSHDh3E6NGjlU7SExkZKfz9/ZXOKNWECRNEu3btlM6osNGjRwtvb29RXFysdIpOz549xbBhw/SO9e3bV7z00ksKFRnKzc0VFhYWYufOnXrH/f39xeTJkxWq0vfg1/Di4mLh7u4u5syZozt29+5d4eTkJJYtW6ZAYenfZy5cuCAAiOPHj5u1yZjyfD9MTEwUAMTFixfNE/WA8jRmZWUJAGLfvn3miTKipM7Lly+LWrVqiV9++UV4eXmJ//3vf2ZvI3XgzPojKCsrCwDg4uKicEnJioqKsHHjRuTk5KBNmzZK5xgYOXIkevbsia5duyqdUqJz587B09MTdevWxcCBA3H+/Hmlk/Ts2LEDLVq0QL9+/VCzZk00b94cn332mdJZpcrPz8fatWsxbNgwaDQapXN02rVrh/379+Ps2bMAgJMnT+LgwYPo0aOHwmV/KywsRFFREWxsbPSO29ra4uDBgwpVle7ChQu4evUqQkJCdMe0Wi06dOiAhIQEBcseDVlZWdBoNKr7bdp9+fn5iI6OhpOTE/z9/ZXO0VNcXIzBgwdj/PjxaNy4sdI5pDD+UaRHjBAC48aNQ7t27dCkSROlcwycOnUKbdq0wd27d1G1alVs27YNjRo1UjpLz8aNG5GUlKT4WtvStGrVCqtXr0aDBg1w7do1zJw5E0FBQTh9+jRcXV2VzgMAnD9/HkuXLsW4cePw7rvvIjExEaNGjYJWq9X7U8xqsn37dmRmZuLll19WOkXPhAkTkJWVhYYNG8LCwgJFRUWYNWsWXnjhBaXTdBwcHNCmTRvMmDEDfn5+cHNzw4YNG3D48GHUr19f6Tyjrl69CgBwc3PTO+7m5oaLFy8qkfTIuHv3LiZOnIhBgwbB0dFR6Rw9O3fuxMCBA5GbmwsPDw/ExcWhevXqSmfpmTt3LiwtLTFq1CilU0gFOFh/xLzxxhv4+eefVTuT5evrixMnTiAzMxNbtmxBREQEDhw4oJoB+6VLlzB69Gjs3bvXYIZQTUJDQ3X/v2nTpmjTpg28vb3xxRdfYNy4cQqW/a24uBgtWrTA7NmzAQDNmzfH6dOnsXTpUtUO1pcvX47Q0FDVrQ+NiYnB2rVrsX79ejRu3BgnTpzAmDFj4OnpiYiICKXzdNasWYNhw4ahVq1asLCwQEBAAAYNGvRQf7nPHB78LYoQQlW/WZFNQUEBBg4ciOLiYixZskTpHAOdOnXCiRMnkJaWhs8++wz9+/fH4cOHUbNmTaXTAADHjh3DggULkJSUxH+HBIAvMH2kvPnmm9ixYwfi4+PxxBNPKJ1jlLW1NXx8fNCiRQtERUXB398fCxYsUDpL59ixY7h+/ToCAwNhaWkJS0tLHDhwAAsXLoSlpSWKioqUTjTK3t4eTZs2xblz55RO0fHw8DD4IczPzw8pKSkKFZXu4sWL2LdvH4YPH650ioHx48dj4sSJGDhwIJo2bYrBgwdj7NixiIqKUjpNj7e3Nw4cOIDbt2/j0qVLSExMREFBAerWrat0mlH3d1C6P8N+3/Xr1w1m26l8CgoK0L9/f1y4cAFxcXGqm1UH7n299PHxQevWrbF8+XJYWlpi+fLlSmfp/PDDD7h+/Tpq166t+z508eJFvPXWW6hTp47SeaQADtYfAUIIvPHGG9i6dSu+/fZb1X5jNEYIgby8PKUzdLp06YJTp07hxIkTuluLFi3w4osv4sSJE7CwsFA60ai8vDwkJyfDw8ND6RSdtm3bGmwhevbsWXh5eSlUVLqVK1eiZs2a6Nmzp9IpBnJzc1Gliv6XawsLC9Vt3Xifvb09PDw8cPPmTcTGxqJ3795KJxlVt25duLu763YAAu6tYz5w4ACCgoIULJPT/YH6uXPnsG/fPtUsySuL2r4PDR48GD///LPe9yFPT0+MHz8esbGxSueRArgMpgy3b9/G77//rnv7woULOHHiBFxcXFC7dm0Fy/42cuRIrF+/Hl999RUcHBx0s0ROTk6wtbVVuO5v7777LkJDQ/Hkk08iOzsbGzduxHfffYc9e/Yonabj4OBgsNbf3t4erq6uqnoNwNtvv42wsDDUrl0b169fx8yZM3Hr1i1VLYkYO3YsgoKCMHv2bPTv3x+JiYmIjo5GdHS00mkGiouLsXLlSkRERMDSUn1fFsPCwjBr1izUrl0bjRs3xvHjx/Hxxx9j2LBhSqfpiY2NhRACvr6++P333zF+/Hj4+vpi6NChijWV9TV8zJgxmD17NurXr4/69etj9uzZsLOzw6BBg1TTmJGRgZSUFN2e5fd/CHZ3dzfr31cordPT0xPPP/88kpKSsHPnThQVFem+F7m4uMDa2lrxRldXV8yaNQu9evWCh4cH0tPTsWTJEly+fNnsW7WW9Zw/+IOOlZUV3N3d4evra9ZOUgklt6KRQXx8vABgcIuIiFA6TcdYHwCxcuVKpdP0DBs2THh5eQlra2tRo0YN0aVLF7F3716ls8qkxq0bBwwYIDw8PISVlZXw9PQUffv2FadPn1Y6y8DXX38tmjRpIrRarWjYsKGIjo5WOsmo2NhYAUD89ttvSqcYdevWLTF69GhRu3ZtYWNjI+rVqycmT54s8vLylE7TExMTI+rVqyesra2Fu7u7GDlypMjMzFS0qayv4cXFxSIyMlK4u7sLrVYr2rdvL06dOqWqxpUrVxq9PzIyUjWd97eVNHaLj49XReOdO3dEnz59hKenp7C2thYeHh6iV69eIjEx0Wx95ek0hls3Pt40Qghh+h8BiIiIiIjoYXHNOhERERGRSnGwTkRERESkUhysExERERGpFAfrREREREQqxcE6EREREZFKcbBORERERKRSHKwTEREREakUB+tERERERCrFwToRVapVq1ZBo9HobpaWlnjiiScwdOhQXLlyxSwNderUwcsvv6x7+7vvvoNGo8F3331XocdJSEjA1KlTkZmZadI+AHj55ZdRp06dMs/r2LEjmjRpYpJr3n9ujh49apLH++dj/vnnnyZ7TCKixxkH60RkFitXrsShQ4cQFxeHESNGYMOGDQgODkZOTo7ZWwICAnDo0CEEBARU6P0SEhIwbdq0ShmsExERGWOpdAARPR6aNGmCFi1aAAA6deqEoqIizJgxA9u3b8eLL75o9H1yc3NhZ2dn8hZHR0e0bt3a5I9LRERkapxZJyJF3B8sX7x4EcC9ZSBVq1bFqVOnEBISAgcHB3Tp0gUAkJ+fj5kzZ6Jhw4bQarWoUaMGhg4dihs3bug9ZkFBAd555x24u7vDzs4O7dq1Q2JiosG1S1oGc/jwYYSFhcHV1RU2Njbw9vbGmDFjAABTp07F+PHjAQB169bVLev552PExMSgTZs2sLe3R9WqVdGtWzccP37c4PqrVq2Cr68vtFot/Pz8sHr16n/1OSzJ0aNHMXDgQNSpUwe2traoU6cOXnjhBd3n+kE3b97E0KFD4eLiAnt7e4SFheH8+fMG5+3btw9dunSBo6Mj7Ozs0LZtW+zfv9+k7UREpI+DdSJSxO+//w4AqFGjhu5Yfn4+evXqhc6dO+Orr77CtGnTUFxcjN69e2POnDkYNGgQvvnmG8yZMwdxcXHo2LEj7ty5o3v/ESNG4MMPP8SQIUPw1Vdf4bnnnkPfvn1x8+bNMntiY2MRHByMlJQUfPzxx9i9ezemTJmCa9euAQCGDx+ON998EwCwdetWHDp0SG8pzezZs/HCCy+gUaNG+PLLL7FmzRpkZ2cjODgYZ86c0V1n1apVGDp0KPz8/LBlyxZMmTIFM2bMwLfffvvwn9T/9+eff8LX1xfz589HbGws5s6di9TUVLRs2RJpaWkG57/yyiuoUqUK1q9fj/nz5yMxMREdO3bUW+6zdu1ahISEwNHREV988QW+/PJLuLi4oFu3bhywExFVJkFEVIlWrlwpAIiffvpJFBQUiOzsbLFz505Ro0YN4eDgIK5evSqEECIiIkIAECtWrNB7/w0bNggAYsuWLXrHjxw5IgCIJUuWCCGESE5OFgDE2LFj9c5bt26dACAiIiJ0x+Lj4wUAER8frzvm7e0tvL29xZ07d0r8WObNmycAiAsXLugdT0lJEZaWluLNN9/UO56dnS3c3d1F//79hRBCFBUVCU9PTxEQECCKi4t15/3555/CyspKeHl5lXjt+zp06CAaN25c5nn/VFhYKG7fvi3s7e3FggULdMfvPzd9+vTRO//HH38UAMTMmTOFEELk5OQIFxcXERYWpndeUVGR8Pf3F08//bTBYz74OSIion+HM+tEZBatW7eGlZUVHBwc8Oyzz8Ld3R27d++Gm5ub3nnPPfec3ts7d+5EtWrVEBYWhsLCQt2tWbNmcHd31y1DiY+PBwCD9e/9+/eHpWXpL885e/Ys/vjjD7zyyiuwsbGp8McWGxuLwsJCDBkyRK/RxsYGHTp00DX+9ttv+OuvvzBo0CBoNBrd+3t5eSEoKKjC1y3J7du3MWHCBPj4+MDS0hKWlpaoWrUqcnJykJycbHD+g5+zoKAgeHl56T6nCQkJyMjIQEREhN7HV1xcjO7du+PIkSOKvFCYiOhxwBeYEpFZrF69Gn5+frC0tISbmxs8PDwMzrGzs4Ojo6PesWvXriEzMxPW1tZGH/f+so709HQAgLu7u979lpaWcHV1LbXt/tr3J554onwfzAPuL5Vp2bKl0furVKlSauP9Y6ba7nDQoEHYv38/3nvvPbRs2RKOjo7QaDTo0aOH3rKhf17b2LH7vfc/vueff77Ea2ZkZMDe3t4k/URE9DcO1onILPz8/HS7wZTkn7PN91WvXh2urq7Ys2eP0fdxcHAAAN2A/OrVq6hVq5bu/sLCQt2gsyT3181fvny51PNKUr16dQDA5s2b4eXlVeJ5/2x8kLFj/0ZWVhZ27tyJyMhITJw4UXc8Ly8PGRkZRt+npB4fHx8Af398n3zySYm76Dz4GxIiIjINDtaJSNWeffZZbNy4EUVFRWjVqlWJ53Xs2BEAsG7dOgQGBuqOf/nllygsLCz1Gg0aNIC3tzdWrFiBcePGQavVGj3v/vEHZ6e7desGS0tL/PHHHwbLeP7J19cXHh4e2LBhA8aNG6f74eTixYtISEiAp6dnqZ3lodFoIIQw+Bg+//xzFBUVGX2fdevW6XUnJCTg4sWLGD58OACgbdu2qFatGs6cOYM33njjoRuJiKj8OFgnIlUbOHAg1q1bhx49emD06NF4+umnYWVlhcuXLyM+Ph69e/dGnz594Ofnh5deegnz58+HlZUVunbtil9++QUffvihwdIaYxYvXoywsDC0bt0aY8eORe3atZGSkoLY2FisW7cOANC0aVMAwIIFCxAREQErKyv4+vqiTp06mD59OiZPnozz58+je/fucHZ2xrVr15CYmAh7e3tMmzYNVapUwYwZMzB8+HD06dMHI0aMQGZmJqZOnWp0KUpJbt26hc2bNxscr1GjBjp06ID27dtj3rx5qF69OurUqYMDBw5g+fLlqFatmtHHO3r0KIYPH45+/frh0qVLmDx5MmrVqoXXX38dAFC1alV88skniIiIQEZGBp5//nnUrFkTN27cwMmTJ3Hjxg0sXbq03P1ERFQBSr/ClYgebfd3Bzly5Eip50VERAh7e3uj9xUUFIgPP/xQ+Pv7CxsbG1G1alXRsGFD8eqrr4pz587pzsvLyxNvvfWWqFmzprCxsRGtW7cWhw4dEl5eXmXuBiOEEIcOHRKhoaHCyclJaLVa4e3tbbC7zKRJk4Snp6eoUqWKwWNs375ddOrUSTg6OgqtViu8vLzE888/L/bt26f3GJ9//rmoX7++sLa2Fg0aNBArVqwQERER5d4NBoDRW4cOHYQQQly+fFk899xzwtnZWTg4OIju3buLX375xeDzcP+52bt3rxg8eLCoVq2asLW1FT169ND7vN534MAB0bNnT+Hi4iKsrKxErVq1RM+ePcWmTZsMHpO7wRARmYZGCCEU+jmBiIiIiIhKwa0biYiIiIhUioN1IiIiIiKV4mCdiIiIiEilOFgnIiIiIlIpDtaJiIiIiFSKg3UiIiIiIpXiYJ2IiIiISKU4WCciIiIiUikO1omIiIiIVIqDdSIiIiIileJgnYiIiIhIpThYJyIiIiJSqf8DqKRhCLZOLs0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 88.82%\n"
     ]
    }
   ],
   "source": [
    "class_names = [str(i+1) for i in range(len(np.unique(y_labels)))]\n",
    "confusion_matrices_dir = 'confusion_matrices'\n",
    "os.makedirs(confusion_matrices_dir, exist_ok=True)\n",
    "print(f\"Saving confusion matrices to: {confusion_matrices_dir}\")\n",
    "plot_conf_matrix('e2e_cnn', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_mlp', class_names, confusion_matrices_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T19:17:10.283386Z",
     "iopub.status.busy": "2025-05-08T19:17:10.283386Z",
     "iopub.status.idle": "2025-05-08T19:17:10.290422Z",
     "shell.execute_reply": "2025-05-08T19:17:10.290422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          96.58\n",
      "1    LRM (CAE)          78.88\n",
      "2    MLP (CAE)          52.69\n",
      "3     TSCL LRM          88.58\n",
      "4     TSCL MLP          88.68\n",
      "5  SCL_SDL LRM          88.72\n",
      "6  SCL_SDL MLP          88.82\n",
      "\n",
      "In Desc. Order (Test Accu)\n",
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          96.58\n",
      "6  SCL_SDL MLP          88.82\n",
      "5  SCL_SDL LRM          88.72\n",
      "4     TSCL MLP          88.68\n",
      "3     TSCL LRM          88.58\n",
      "1    LRM (CAE)          78.88\n",
      "2    MLP (CAE)          52.69\n"
     ]
    }
   ],
   "source": [
    "final_results_df = pd.DataFrame({\n",
    "    \"Model\": [\"E2E CNN\", \"LRM (CAE)\", \"MLP (CAE)\", \"TSCL LRM\", \"TSCL MLP\", \"SCL_SDL LRM\", \"SCL_SDL MLP\"],\n",
    "    \"Test_Accuracy\": [test_accuracy, lrm_test_accuracy * 100, cae_mlp_test_accuracy_pct, \n",
    "                      tscl_lrm_test_accuracy * 100, tscl_mlp_test_accuracy_pct, \n",
    "                      sclsdl_lrm_test_accuracy * 100, sclsdl_mlp_test_accuracy_pct]\n",
    "})\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "print(final_results_df)\n",
    "print(f\"\\nIn Desc. Order (Test Accu)\\n{final_results_df.sort_values('Test_Accuracy', ascending=False)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
