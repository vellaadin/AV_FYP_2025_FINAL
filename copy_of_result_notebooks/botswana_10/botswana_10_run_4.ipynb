{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependancy Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:13.146486Z",
     "iopub.status.busy": "2025-05-08T18:41:13.146486Z",
     "iopub.status.idle": "2025-05-08T18:41:13.150005Z",
     "shell.execute_reply": "2025-05-08T18:41:13.150005Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:13.153012Z",
     "iopub.status.busy": "2025-05-08T18:41:13.153012Z",
     "iopub.status.idle": "2025-05-08T18:41:15.188350Z",
     "shell.execute_reply": "2025-05-08T18:41:15.188350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-metric-learning in c:\\users\\vella\\anaconda3\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (1.5.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (2.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vella\\anaconda3\\lib\\site-packages (from pytorch-metric-learning) (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (4.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vella\\anaconda3\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vella\\anaconda3\\lib\\site-packages (from tqdm->pytorch-metric-learning) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vella\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:15.190359Z",
     "iopub.status.busy": "2025-05-08T18:41:15.190359Z",
     "iopub.status.idle": "2025-05-08T18:41:18.410986Z",
     "shell.execute_reply": "2025-05-08T18:41:18.410986Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nbformat\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "from torch.amp import autocast, GradScaler\n",
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:18.413993Z",
     "iopub.status.busy": "2025-05-08T18:41:18.412993Z",
     "iopub.status.idle": "2025-05-08T18:41:18.430037Z",
     "shell.execute_reply": "2025-05-08T18:41:18.430037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:18.432412Z",
     "iopub.status.busy": "2025-05-08T18:41:18.432412Z",
     "iopub.status.idle": "2025-05-08T18:41:19.333089Z",
     "shell.execute_reply": "2025-05-08T18:41:19.333089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: (1476, 256)\n",
      "Hypercube shape: (1476, 256, 145)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dir = r\"C:\\Users\\vella\\Documents\\GitHub\\FYP2425_LOCAL\\FYP_DATASET\"\n",
    "\n",
    "gt_files = 'Botswana_gt.mat'\n",
    "data_files = 'Botswana.mat'\n",
    "label_files = 'Botswana_gt'\n",
    "hypercube_files = 'Botswana'\n",
    "\n",
    "def extract_Features():\n",
    "    gt_file = os.path.join(dataset_dir, gt_files)\n",
    "    data_file = os.path.join(dataset_dir, data_files)\n",
    "\n",
    "    gt = sio.loadmat(gt_file)\n",
    "    labels = gt[label_files]\n",
    "\n",
    "    data = sio.loadmat(data_file)\n",
    "    hypercube = data[hypercube_files]\n",
    "    #scaling the data in place and setting to float32 to reduce memory usage\n",
    "    max_value = np.max(hypercube)\n",
    "    hypercube = (hypercube / max_value).astype(np.float32)\n",
    "\n",
    "\n",
    "    #shapes of loaded data\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Hypercube shape: {hypercube.shape}\")\n",
    "\n",
    "    #visualisation of label map and a given band of hyperspectral data\n",
    "    plt.figure()\n",
    "    plt.imshow(labels)\n",
    "    plt.title('Labels')\n",
    "\n",
    "    band = 101\n",
    "    plt.figure()\n",
    "    plt.imshow(hypercube[:,:,band])\n",
    "    plt.title(f'Hyperspectral Band {band}')\n",
    "    plt.show()\n",
    "\n",
    "    return hypercube, labels\n",
    "\n",
    "hypercube, labels = extract_Features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:19.335887Z",
     "iopub.status.busy": "2025-05-08T18:41:19.334882Z",
     "iopub.status.idle": "2025-05-08T18:41:19.342036Z",
     "shell.execute_reply": "2025-05-08T18:41:19.342036Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_windows(data, labels, window_size):\n",
    "    extract_windows_save_dir = 'extracted_windows_labels'\n",
    "    if not os.path.exists(extract_windows_save_dir):\n",
    "        os.makedirs(extract_windows_save_dir)\n",
    "        print(f\"Created directory: {extract_windows_save_dir}\")\n",
    "\n",
    "    margin = window_size // 2\n",
    "    padded_data = np.pad(data, ((margin, margin), (margin, margin), (0, 0)), mode='constant')\n",
    "    padded_labels = np.pad(labels, ((margin, margin), (margin, margin)), mode='constant')\n",
    "\n",
    "    X_windows = []  #extracted windows\n",
    "    y_labels = []   #corresponding labels\n",
    "\n",
    "    print(\"Starting window extraction...\")\n",
    "    for i in range(margin, padded_data.shape[0] - margin):\n",
    "        for j in range(margin, padded_data.shape[1] - margin):\n",
    "            window = padded_data[i-margin:i+margin+1, j-margin:j+margin+1, :]\n",
    "            label = padded_labels[i, j]\n",
    "\n",
    "            if label != 0:\n",
    "                #print('ignoring label 0 (background)')\n",
    "                X_windows.append(window)\n",
    "                y_labels.append(label)\n",
    "\n",
    "    #convertying to numpy arrays\n",
    "    X_windows = np.array(X_windows)\n",
    "    y_labels = np.array(y_labels)\n",
    "\n",
    "    #saving extracted windows and labels\n",
    "    windows_file = os.path.join(extract_windows_save_dir, 'extracted_windows.npy')\n",
    "    labels_file = os.path.join(extract_windows_save_dir, 'extracted_labels.npy')\n",
    "\n",
    "    np.save(windows_file, X_windows)\n",
    "    np.save(labels_file, y_labels)\n",
    "\n",
    "    print(f\"Saved extracted windows to: {windows_file}\")\n",
    "    print(f\"Saved corresponding labels to: {labels_file}\")\n",
    "    print(f\"\\nTotal windows extracted: {len(X_windows)}\")\n",
    "    print(f\"Extracted windows shape: {X_windows.shape}\")\n",
    "    print(f\"Corresponding labels shape: {y_labels.shape}\")\n",
    "\n",
    "    return X_windows, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:19.344051Z",
     "iopub.status.busy": "2025-05-08T18:41:19.344051Z",
     "iopub.status.idle": "2025-05-08T18:41:20.139888Z",
     "shell.execute_reply": "2025-05-08T18:41:20.139888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: extracted_windows_labels\n",
      "Starting window extraction...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved extracted windows to: extracted_windows_labels\\extracted_windows.npy\n",
      "Saved corresponding labels to: extracted_windows_labels\\extracted_labels.npy\n",
      "\n",
      "Total windows extracted: 3248\n",
      "Extracted windows shape: (3248, 5, 5, 145)\n",
      "Corresponding labels shape: (3248,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "\n",
    "X_windows, y_labels = extract_windows(hypercube, labels, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:20.143143Z",
     "iopub.status.busy": "2025-05-08T18:41:20.143143Z",
     "iopub.status.idle": "2025-05-08T18:41:20.150528Z",
     "shell.execute_reply": "2025-05-08T18:41:20.150528Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_samples(X_windows, y_labels, samples_per_class):\n",
    "    \n",
    "    indices_save_dir = 'indices'\n",
    "    if not os.path.exists(indices_save_dir):\n",
    "        os.makedirs(indices_save_dir)\n",
    "        print(f\"Created directory: {indices_save_dir}\")\n",
    "    \n",
    "    #get unique classes\n",
    "    classes = np.unique(y_labels)\n",
    "    print(f\"Unique classes found as: {classes}\")\n",
    "\n",
    "    #init lists\n",
    "    X_sampled = [] #to store training samples\n",
    "    y_sampled = [] #to store training labels\n",
    "\n",
    "    X_val = [] # to store validation samples\n",
    "    y_val = [] # to store validation labels\n",
    "\n",
    "    selected_indices_total = [] #to store indices of selected training and validation samples\n",
    "    validation_selected = [] #temp storage for validation indices\n",
    "    validation_total = [] #to store all validation indices\n",
    "\n",
    "    print(\"\\n == STARTING SAMPLING PROCESS ==\")\n",
    "    for cls in classes:\n",
    "        if cls == 0:\n",
    "            print(f\"!! SKIPPING CLASS 0 !!\")\n",
    "            continue\n",
    "\n",
    "        #getting the indices for the current class:\n",
    "        class_indices = np.where(y_labels == cls)[0]\n",
    "        print(f\"Class: {cls}: Found {len(class_indices)} samples\")\n",
    "\n",
    "        # shuffle class-specific indices to ensure randomness\n",
    "        np.random.shuffle(class_indices)\n",
    "        print(f\"Shuffled class indices for class '{cls}'\")\n",
    "\n",
    "        #select 'samples_per_class' samples for training\n",
    "        selected_indices = class_indices[:samples_per_class]\n",
    "        #selecting 5 samples for validation\n",
    "        validation_selected = class_indices[samples_per_class:samples_per_class+5]\n",
    "\n",
    "        print(f\"Selected {len(selected_indices)} training samples and {len(validation_selected)} validation samples for class '{cls}'\\n\")\n",
    "\n",
    "        #store selected indices for training and validation\n",
    "        selected_indices_total.extend(selected_indices)\n",
    "        validation_total.extend(validation_selected)\n",
    "\n",
    "        # appending the selected samples and their labels to the lists\n",
    "        X_sampled.append(X_windows[selected_indices])\n",
    "        y_sampled.append(y_labels[selected_indices])\n",
    "\n",
    "        X_val.append(X_windows[validation_selected])\n",
    "        y_val.append(y_labels[validation_selected])\n",
    "\n",
    "    #concat the sampled arrays for training\n",
    "    X_train = np.vstack(X_sampled)\n",
    "    y_train = np.hstack(y_sampled)\n",
    "\n",
    "    # shift labels to start from 0\n",
    "    y_train = y_train - 1\n",
    "\n",
    "    print(f\"\\n -- Training set created with: \\n\\t{X_train.shape[0]} samples\\n\\tshape {X_train.shape} --\")\n",
    "\n",
    "    #concat the sampled arrays for validation\n",
    "    X_val = np.vstack(X_val)\n",
    "    y_val = np.hstack(y_val)\n",
    "    y_val = y_val - 1\n",
    "\n",
    "    print(f\"\\n -- Validation set created with: \\n\\t{X_val.shape[0]} samples\\n\\tshape {X_val.shape} --\")\n",
    "\n",
    "    #create the test set from the remaining data (i.e. that which is not selected for training or validation)\n",
    "    selected_indices_total.extend(validation_total)\n",
    "\n",
    "    #getting indices not in the training or val sets\n",
    "    test_indices = np.setdiff1d(np.arange(X_windows.shape[0]), selected_indices_total)\n",
    "    X_test = X_windows[test_indices]\n",
    "    y_test = y_labels[test_indices]\n",
    "    y_test = y_test - 1\n",
    "\n",
    "    print(f\"\\n -- Test set created with: \\n\\t{X_test.shape[0]} samples\\n\\tshape {X_test.shape} --\\n\")\n",
    "\n",
    "    # Save the datasets to the 'datasets' folder\n",
    "    np.save(os.path.join(indices_save_dir, 'X_train.npy'), X_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_train.npy'), y_train)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_val.npy'), X_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_val.npy'), y_val)\n",
    "    np.save(os.path.join(indices_save_dir, 'X_test.npy'), X_test)\n",
    "    np.save(os.path.join(indices_save_dir, 'y_test.npy'), y_test)\n",
    "\n",
    "    print(f\"\\nAll datasets saved to the '{indices_save_dir}' folder.\")\n",
    "\n",
    "    #return the training, val, test sets + selected indices\n",
    "    return X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:20.153533Z",
     "iopub.status.busy": "2025-05-08T18:41:20.152576Z",
     "iopub.status.idle": "2025-05-08T18:41:20.382756Z",
     "shell.execute_reply": "2025-05-08T18:41:20.382756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: indices\n",
      "Unique classes found as: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "\n",
      " == STARTING SAMPLING PROCESS ==\n",
      "Class: 1: Found 270 samples\n",
      "Shuffled class indices for class '1'\n",
      "Selected 10 training samples and 5 validation samples for class '1'\n",
      "\n",
      "Class: 2: Found 101 samples\n",
      "Shuffled class indices for class '2'\n",
      "Selected 10 training samples and 5 validation samples for class '2'\n",
      "\n",
      "Class: 3: Found 251 samples\n",
      "Shuffled class indices for class '3'\n",
      "Selected 10 training samples and 5 validation samples for class '3'\n",
      "\n",
      "Class: 4: Found 215 samples\n",
      "Shuffled class indices for class '4'\n",
      "Selected 10 training samples and 5 validation samples for class '4'\n",
      "\n",
      "Class: 5: Found 269 samples\n",
      "Shuffled class indices for class '5'\n",
      "Selected 10 training samples and 5 validation samples for class '5'\n",
      "\n",
      "Class: 6: Found 269 samples\n",
      "Shuffled class indices for class '6'\n",
      "Selected 10 training samples and 5 validation samples for class '6'\n",
      "\n",
      "Class: 7: Found 259 samples\n",
      "Shuffled class indices for class '7'\n",
      "Selected 10 training samples and 5 validation samples for class '7'\n",
      "\n",
      "Class: 8: Found 203 samples\n",
      "Shuffled class indices for class '8'\n",
      "Selected 10 training samples and 5 validation samples for class '8'\n",
      "\n",
      "Class: 9: Found 314 samples\n",
      "Shuffled class indices for class '9'\n",
      "Selected 10 training samples and 5 validation samples for class '9'\n",
      "\n",
      "Class: 10: Found 248 samples\n",
      "Shuffled class indices for class '10'\n",
      "Selected 10 training samples and 5 validation samples for class '10'\n",
      "\n",
      "Class: 11: Found 305 samples\n",
      "Shuffled class indices for class '11'\n",
      "Selected 10 training samples and 5 validation samples for class '11'\n",
      "\n",
      "Class: 12: Found 181 samples\n",
      "Shuffled class indices for class '12'\n",
      "Selected 10 training samples and 5 validation samples for class '12'\n",
      "\n",
      "Class: 13: Found 268 samples\n",
      "Shuffled class indices for class '13'\n",
      "Selected 10 training samples and 5 validation samples for class '13'\n",
      "\n",
      "Class: 14: Found 95 samples\n",
      "Shuffled class indices for class '14'\n",
      "Selected 10 training samples and 5 validation samples for class '14'\n",
      "\n",
      "\n",
      " -- Training set created with: \n",
      "\t140 samples\n",
      "\tshape (140, 5, 5, 145) --\n",
      "\n",
      " -- Validation set created with: \n",
      "\t70 samples\n",
      "\tshape (70, 5, 5, 145) --\n",
      "\n",
      " -- Test set created with: \n",
      "\t3038 samples\n",
      "\tshape (3038, 5, 5, 145) --\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All datasets saved to the 'indices' folder.\n",
      "(140, 5, 5, 145)\n",
      "(70, 5, 5, 145)\n",
      "(3038, 5, 5, 145)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_val, y_val, selected_indices_total = get_samples(X_windows, y_labels, 10)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:20.385617Z",
     "iopub.status.busy": "2025-05-08T18:41:20.385617Z",
     "iopub.status.idle": "2025-05-08T18:41:20.389975Z",
     "shell.execute_reply": "2025-05-08T18:41:20.389975Z"
    }
   },
   "outputs": [],
   "source": [
    "class HyperspectralDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (numpy.ndarray): Hyperspectral data of shape (num_samples, height, width, num_bands).\n",
    "            y (numpy.ndarray): Labels of shape (num_samples,).\n",
    "        \"\"\"\n",
    "        #converting to pytorch tensor\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:20.392980Z",
     "iopub.status.busy": "2025-05-08T18:41:20.392980Z",
     "iopub.status.idle": "2025-05-08T18:41:20.450375Z",
     "shell.execute_reply": "2025-05-08T18:41:20.450375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1 applied\n",
      "DataLoaders created successfully!\n",
      "Training batch size: 140\n",
      "Class distribution in batch: {0: 10, 1: 10, 2: 10, 3: 10, 4: 10, 5: 10, 6: 10, 7: 10, 8: 10, 9: 10, 10: 10, 11: 10, 12: 10, 13: 10}\n"
     ]
    }
   ],
   "source": [
    "#loading the saved datasets\n",
    "X_train = np.load('indices/X_train.npy')\n",
    "y_train = np.load('indices/y_train.npy')\n",
    "X_val = np.load('indices/X_val.npy')\n",
    "y_val = np.load('indices/y_val.npy')\n",
    "X_test = np.load('indices/X_test.npy')\n",
    "y_test = np.load('indices/y_test.npy')\n",
    "\n",
    "\n",
    "#creating pytorch datasets\n",
    "train_dataset = HyperspectralDataset(X_train, y_train)\n",
    "val_dataset = HyperspectralDataset(X_val, y_val)\n",
    "test_dataset = HyperspectralDataset(X_test, y_test)\n",
    "\n",
    "m = 20\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "#theoretical batch size calc\n",
    "required_batch_size = m * num_classes  # 10 * 9 = 90\n",
    "\n",
    "#ensuring batch size doesn't exceed training set size\n",
    "if required_batch_size > len(train_dataset):\n",
    "    #case 1: not enough samples - reduce m proportionally\n",
    "    print(\"Case 1 applied\")\n",
    "    max_possible_m = len(train_dataset) // num_classes\n",
    "    m = max(1, max_possible_m)\n",
    "    batch_size_train = m * num_classes\n",
    "else:\n",
    "    #case 2: use full batch size\n",
    "    print(\"Case 2 applied\")\n",
    "    batch_size_train = required_batch_size\n",
    "\n",
    "sampler = MPerClassSampler(labels = y_train, m=m, batch_size = batch_size_train, length_before_new_iter = len(train_dataset))\n",
    "\n",
    "#dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size_train, sampler=sampler)\n",
    "\n",
    "batch_size = 256\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")\n",
    "\n",
    "#class dist in first batch\n",
    "for X_batch, y_batch in train_loader:\n",
    "    unique, counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(f\"Training batch size: {batch_size_train}\")\n",
    "    print(\"Class distribution in batch:\", dict(zip(unique, counts)))\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating directory for saving model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:20.453380Z",
     "iopub.status.busy": "2025-05-08T18:41:20.452379Z",
     "iopub.status.idle": "2025-05-08T18:41:20.457993Z",
     "shell.execute_reply": "2025-05-08T18:41:20.457993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dir: model_predictions\n"
     ]
    }
   ],
   "source": [
    "predictions_dir = 'model_predictions'\n",
    "os.makedirs(predictions_dir, exist_ok=True)\n",
    "print(f\"Created dir: {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset splits and Dataloaders for unsupervised tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:20.459998Z",
     "iopub.status.busy": "2025-05-08T18:41:20.459998Z",
     "iopub.status.idle": "2025-05-08T18:41:20.476011Z",
     "shell.execute_reply": "2025-05-08T18:41:20.476011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2598, 5, 5, 145)\n",
      "Validation data shape: (650, 5, 5, 145)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = train_test_split(X_windows, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:20.479017Z",
     "iopub.status.busy": "2025-05-08T18:41:20.479017Z",
     "iopub.status.idle": "2025-05-08T18:41:20.483240Z",
     "shell.execute_reply": "2025-05-08T18:41:20.482230Z"
    }
   },
   "outputs": [],
   "source": [
    "class UnsupervisedDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)  #converting to pytorch tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:20.485750Z",
     "iopub.status.busy": "2025-05-08T18:41:20.484745Z",
     "iopub.status.idle": "2025-05-08T18:41:20.493066Z",
     "shell.execute_reply": "2025-05-08T18:41:20.493066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "#creating datasets for unsupervised task\n",
    "unsup_train_dataset = UnsupervisedDataset(X_train)\n",
    "unsup_val_dataset = UnsupervisedDataset(X_val)\n",
    "\n",
    "#dataloaders for unsupervised task\n",
    "batch_size = 64\n",
    "train_loader_cae = DataLoader(unsup_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader_cae = DataLoader(unsup_val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:20.495070Z",
     "iopub.status.busy": "2025-05-08T18:41:20.495070Z",
     "iopub.status.idle": "2025-05-08T18:41:20.498443Z",
     "shell.execute_reply": "2025-05-08T18:41:20.498443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    }
   ],
   "source": [
    "window_num_channels = X_windows.shape[3]\n",
    "print(window_num_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:20.501451Z",
     "iopub.status.busy": "2025-05-08T18:41:20.501451Z",
     "iopub.status.idle": "2025-05-08T18:41:20.506386Z",
     "shell.execute_reply": "2025-05-08T18:41:20.506386Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncode(nn.Module):\n",
    "    def __init__(self, dropout_prob=0.1):\n",
    "        super(ConvAutoEncode, self).__init__()\n",
    "\n",
    "        #encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            #Block 1\n",
    "            nn.Conv2d(window_num_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            #Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            #Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "\n",
    "            nn.ConvTranspose2d(64, window_num_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:20.509390Z",
     "iopub.status.busy": "2025-05-08T18:41:20.508391Z",
     "iopub.status.idle": "2025-05-08T18:41:42.919582Z",
     "shell.execute_reply": "2025-05-08T18:41:42.919582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training Batch [1/41], Loss: 0.2215, PSNR: -8.7265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Training Loss: 0.2150, PSNR: -8.7179\n",
      "\t[Val]   Batch [1/11] Loss: 0.2076, PSNR: -6.2094\n",
      "\t[Val]   Batch [10/11] Loss: 0.2077, PSNR: -8.4483\n",
      "Epoch [1/50] Validation Loss: 0.2076, PSNR: -8.1404\n",
      "\n",
      "LOG: Epoch [2/50]\n",
      "\t Training Batch [1/41], Loss: 0.2015, PSNR: -9.5016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Training Loss: 0.1930, PSNR: -8.3690\n",
      "\t[Val]   Batch [1/11] Loss: 0.1817, PSNR: -5.6297\n",
      "\t[Val]   Batch [10/11] Loss: 0.1819, PSNR: -7.8703\n",
      "Epoch [2/50] Validation Loss: 0.1816, PSNR: -7.5591\n",
      "\n",
      "LOG: Epoch [3/50]\n",
      "\t Training Batch [1/41], Loss: 0.1792, PSNR: -8.5107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Training Loss: 0.1719, PSNR: -7.9900\n",
      "\t[Val]   Batch [1/11] Loss: 0.1565, PSNR: -4.9833\n",
      "\t[Val]   Batch [10/11] Loss: 0.1569, PSNR: -7.2283\n",
      "Epoch [3/50] Validation Loss: 0.1566, PSNR: -6.9167\n",
      "\n",
      "LOG: Epoch [4/50]\n",
      "\t Training Batch [1/41], Loss: 0.1574, PSNR: -7.5944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] Training Loss: 0.1515, PSNR: -7.1417\n",
      "\t[Val]   Batch [1/11] Loss: 0.1348, PSNR: -4.3332\n",
      "\t[Val]   Batch [10/11] Loss: 0.1351, PSNR: -6.5792\n",
      "Epoch [4/50] Validation Loss: 0.1349, PSNR: -6.2693\n",
      "\n",
      "LOG: Epoch [5/50]\n",
      "\t Training Batch [1/41], Loss: 0.1388, PSNR: -7.2640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] Training Loss: 0.1321, PSNR: -6.6725\n",
      "\t[Val]   Batch [1/11] Loss: 0.1179, PSNR: -3.7518\n",
      "\t[Val]   Batch [10/11] Loss: 0.1181, PSNR: -5.9956\n",
      "Epoch [5/50] Validation Loss: 0.1179, PSNR: -5.6847\n",
      "\n",
      "LOG: Epoch [6/50]\n",
      "\t Training Batch [1/41], Loss: 0.1203, PSNR: -7.2601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] Training Loss: 0.1142, PSNR: -6.0952\n",
      "\t[Val]   Batch [1/11] Loss: 0.1005, PSNR: -3.0571\n",
      "\t[Val]   Batch [10/11] Loss: 0.1006, PSNR: -5.2985\n",
      "Epoch [6/50] Validation Loss: 0.1005, PSNR: -4.9888\n",
      "\n",
      "LOG: Epoch [7/50]\n",
      "\t Training Batch [1/41], Loss: 0.1048, PSNR: -7.1732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] Training Loss: 0.0982, PSNR: -5.4366\n",
      "\t[Val]   Batch [1/11] Loss: 0.0867, PSNR: -2.4180\n",
      "\t[Val]   Batch [10/11] Loss: 0.0868, PSNR: -4.6596\n",
      "Epoch [7/50] Validation Loss: 0.0867, PSNR: -4.3493\n",
      "\n",
      "LOG: Epoch [8/50]\n",
      "\t Training Batch [1/41], Loss: 0.0891, PSNR: -6.4680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] Training Loss: 0.0844, PSNR: -4.6542\n",
      "\t[Val]   Batch [1/11] Loss: 0.0748, PSNR: -1.7748\n",
      "\t[Val]   Batch [10/11] Loss: 0.0749, PSNR: -4.0156\n",
      "Epoch [8/50] Validation Loss: 0.0748, PSNR: -3.7050\n",
      "\n",
      "LOG: Epoch [9/50]\n",
      "\t Training Batch [1/41], Loss: 0.0767, PSNR: -6.2461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] Training Loss: 0.0727, PSNR: -4.0931\n",
      "\t[Val]   Batch [1/11] Loss: 0.0652, PSNR: -1.1808\n",
      "\t[Val]   Batch [10/11] Loss: 0.0653, PSNR: -3.4213\n",
      "Epoch [9/50] Validation Loss: 0.0652, PSNR: -3.1105\n",
      "\n",
      "LOG: Epoch [10/50]\n",
      "\t Training Batch [1/41], Loss: 0.0646, PSNR: -1.1394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] Training Loss: 0.0630, PSNR: -3.4549\n",
      "\t[Val]   Batch [1/11] Loss: 0.0567, PSNR: -0.5762\n",
      "\t[Val]   Batch [10/11] Loss: 0.0568, PSNR: -2.8184\n",
      "Epoch [10/50] Validation Loss: 0.0567, PSNR: -2.5060\n",
      "\n",
      "LOG: Epoch [11/50]\n",
      "\t Training Batch [1/41], Loss: 0.0569, PSNR: -0.5869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] Training Loss: 0.0548, PSNR: -2.8562\n",
      "\t[Val]   Batch [1/11] Loss: 0.0501, PSNR: -0.0381\n",
      "\t[Val]   Batch [10/11] Loss: 0.0502, PSNR: -2.2792\n",
      "Epoch [11/50] Validation Loss: 0.0501, PSNR: -1.9685\n",
      "\n",
      "LOG: Epoch [12/50]\n",
      "\t Training Batch [1/41], Loss: 0.0511, PSNR: -0.1244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] Training Loss: 0.0480, PSNR: -2.3513\n",
      "\t[Val]   Batch [1/11] Loss: 0.0443, PSNR: 0.5018\n",
      "\t[Val]   Batch [10/11] Loss: 0.0443, PSNR: -1.7388\n",
      "Epoch [12/50] Validation Loss: 0.0443, PSNR: -1.4287\n",
      "\n",
      "LOG: Epoch [13/50]\n",
      "\t Training Batch [1/41], Loss: 0.0438, PSNR: -2.2566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50] Training Loss: 0.0423, PSNR: -1.6974\n",
      "\t[Val]   Batch [1/11] Loss: 0.0399, PSNR: 0.9502\n",
      "\t[Val]   Batch [10/11] Loss: 0.0400, PSNR: -1.2896\n",
      "Epoch [13/50] Validation Loss: 0.0399, PSNR: -0.9796\n",
      "\n",
      "LOG: Epoch [14/50]\n",
      "\t Training Batch [1/41], Loss: 0.0388, PSNR: -0.8570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50] Training Loss: 0.0376, PSNR: -1.1262\n",
      "\t[Val]   Batch [1/11] Loss: 0.0354, PSNR: 1.4695\n",
      "\t[Val]   Batch [10/11] Loss: 0.0355, PSNR: -0.7700\n",
      "Epoch [14/50] Validation Loss: 0.0354, PSNR: -0.4597\n",
      "\n",
      "LOG: Epoch [15/50]\n",
      "\t Training Batch [1/41], Loss: 0.0351, PSNR: -2.2206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50] Training Loss: 0.0336, PSNR: -0.7818\n",
      "\t[Val]   Batch [1/11] Loss: 0.0319, PSNR: 1.9227\n",
      "\t[Val]   Batch [10/11] Loss: 0.0319, PSNR: -0.3161\n",
      "Epoch [15/50] Validation Loss: 0.0319, PSNR: -0.0060\n",
      "\n",
      "LOG: Epoch [16/50]\n",
      "\t Training Batch [1/41], Loss: 0.0315, PSNR: -2.3559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] Training Loss: 0.0302, PSNR: -0.1929\n",
      "\t[Val]   Batch [1/11] Loss: 0.0290, PSNR: 2.3316\n",
      "\t[Val]   Batch [10/11] Loss: 0.0291, PSNR: 0.0939\n",
      "Epoch [16/50] Validation Loss: 0.0290, PSNR: 0.4029\n",
      "\n",
      "LOG: Epoch [17/50]\n",
      "\t Training Batch [1/41], Loss: 0.0283, PSNR: -0.9765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50] Training Loss: 0.0273, PSNR: 0.0162\n",
      "\t[Val]   Batch [1/11] Loss: 0.0260, PSNR: 2.8064\n",
      "\t[Val]   Batch [10/11] Loss: 0.0261, PSNR: 0.5680\n",
      "Epoch [17/50] Validation Loss: 0.0260, PSNR: 0.8780\n",
      "\n",
      "LOG: Epoch [18/50]\n",
      "\t Training Batch [1/41], Loss: 0.0261, PSNR: -1.9110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50] Training Loss: 0.0248, PSNR: 0.5925\n",
      "\t[Val]   Batch [1/11] Loss: 0.0239, PSNR: 3.1778\n",
      "\t[Val]   Batch [10/11] Loss: 0.0239, PSNR: 0.9400\n",
      "Epoch [18/50] Validation Loss: 0.0239, PSNR: 1.2500\n",
      "\n",
      "LOG: Epoch [19/50]\n",
      "\t Training Batch [1/41], Loss: 0.0234, PSNR: 0.3370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50] Training Loss: 0.0226, PSNR: 1.0116\n",
      "\t[Val]   Batch [1/11] Loss: 0.0220, PSNR: 3.5465\n",
      "\t[Val]   Batch [10/11] Loss: 0.0220, PSNR: 1.3093\n",
      "Epoch [19/50] Validation Loss: 0.0219, PSNR: 1.6187\n",
      "\n",
      "LOG: Epoch [20/50]\n",
      "\t Training Batch [1/41], Loss: 0.0217, PSNR: -0.6217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50] Training Loss: 0.0207, PSNR: 1.2692\n",
      "\t[Val]   Batch [1/11] Loss: 0.0199, PSNR: 3.9663\n",
      "\t[Val]   Batch [10/11] Loss: 0.0199, PSNR: 1.7296\n",
      "Epoch [20/50] Validation Loss: 0.0199, PSNR: 2.0392\n",
      "\n",
      "LOG: Epoch [21/50]\n",
      "\t Training Batch [1/41], Loss: 0.0193, PSNR: 1.6834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50] Training Loss: 0.0190, PSNR: 1.6855\n",
      "\t[Val]   Batch [1/11] Loss: 0.0187, PSNR: 4.2489\n",
      "\t[Val]   Batch [10/11] Loss: 0.0187, PSNR: 2.0119\n",
      "Epoch [21/50] Validation Loss: 0.0187, PSNR: 2.3211\n",
      "\n",
      "LOG: Epoch [22/50]\n",
      "\t Training Batch [1/41], Loss: 0.0178, PSNR: 2.5215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50] Training Loss: 0.0176, PSNR: 2.0891\n",
      "\t[Val]   Batch [1/11] Loss: 0.0171, PSNR: 4.6386\n",
      "\t[Val]   Batch [10/11] Loss: 0.0171, PSNR: 2.4012\n",
      "Epoch [22/50] Validation Loss: 0.0171, PSNR: 2.7118\n",
      "\n",
      "LOG: Epoch [23/50]\n",
      "\t Training Batch [1/41], Loss: 0.0161, PSNR: 4.8984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50] Training Loss: 0.0163, PSNR: 2.5197\n",
      "\t[Val]   Batch [1/11] Loss: 0.0158, PSNR: 4.9685\n",
      "\t[Val]   Batch [10/11] Loss: 0.0158, PSNR: 2.7314\n",
      "Epoch [23/50] Validation Loss: 0.0158, PSNR: 3.0419\n",
      "\n",
      "LOG: Epoch [24/50]\n",
      "\t Training Batch [1/41], Loss: 0.0154, PSNR: 3.4948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50] Training Loss: 0.0151, PSNR: 2.8565\n",
      "\t[Val]   Batch [1/11] Loss: 0.0148, PSNR: 5.2730\n",
      "\t[Val]   Batch [10/11] Loss: 0.0148, PSNR: 3.0355\n",
      "Epoch [24/50] Validation Loss: 0.0147, PSNR: 3.3460\n",
      "\n",
      "LOG: Epoch [25/50]\n",
      "\t Training Batch [1/41], Loss: 0.0143, PSNR: 0.9626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50] Training Loss: 0.0140, PSNR: 3.1097\n",
      "\t[Val]   Batch [1/11] Loss: 0.0137, PSNR: 5.6014\n",
      "\t[Val]   Batch [10/11] Loss: 0.0137, PSNR: 3.3635\n",
      "Epoch [25/50] Validation Loss: 0.0137, PSNR: 3.6748\n",
      "\n",
      "LOG: Epoch [26/50]\n",
      "\t Training Batch [1/41], Loss: 0.0136, PSNR: 1.4124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50] Training Loss: 0.0131, PSNR: 3.2917\n",
      "\t[Val]   Batch [1/11] Loss: 0.0129, PSNR: 5.8731\n",
      "\t[Val]   Batch [10/11] Loss: 0.0129, PSNR: 3.6355\n",
      "Epoch [26/50] Validation Loss: 0.0128, PSNR: 3.9471\n",
      "\n",
      "LOG: Epoch [27/50]\n",
      "\t Training Batch [1/41], Loss: 0.0124, PSNR: 4.0927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50] Training Loss: 0.0123, PSNR: 3.6785\n",
      "\t[Val]   Batch [1/11] Loss: 0.0121, PSNR: 6.1423\n",
      "\t[Val]   Batch [10/11] Loss: 0.0121, PSNR: 3.9051\n",
      "Epoch [27/50] Validation Loss: 0.0121, PSNR: 4.2165\n",
      "\n",
      "LOG: Epoch [28/50]\n",
      "\t Training Batch [1/41], Loss: 0.0119, PSNR: 2.4898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50] Training Loss: 0.0115, PSNR: 3.8148\n",
      "\t[Val]   Batch [1/11] Loss: 0.0113, PSNR: 6.4218\n",
      "\t[Val]   Batch [10/11] Loss: 0.0113, PSNR: 4.1852\n",
      "Epoch [28/50] Validation Loss: 0.0113, PSNR: 4.4959\n",
      "\n",
      "LOG: Epoch [29/50]\n",
      "\t Training Batch [1/41], Loss: 0.0111, PSNR: 4.5564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50] Training Loss: 0.0108, PSNR: 4.1206\n",
      "\t[Val]   Batch [1/11] Loss: 0.0107, PSNR: 6.6793\n",
      "\t[Val]   Batch [10/11] Loss: 0.0107, PSNR: 4.4433\n",
      "Epoch [29/50] Validation Loss: 0.0107, PSNR: 4.7529\n",
      "\n",
      "LOG: Epoch [30/50]\n",
      "\t Training Batch [1/41], Loss: 0.0106, PSNR: 6.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50] Training Loss: 0.0102, PSNR: 4.3870\n",
      "\t[Val]   Batch [1/11] Loss: 0.0100, PSNR: 6.9558\n",
      "\t[Val]   Batch [10/11] Loss: 0.0100, PSNR: 4.7196\n",
      "Epoch [30/50] Validation Loss: 0.0100, PSNR: 5.0292\n",
      "\n",
      "LOG: Epoch [31/50]\n",
      "\t Training Batch [1/41], Loss: 0.0101, PSNR: 4.1319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50] Training Loss: 0.0096, PSNR: 4.7193\n",
      "\t[Val]   Batch [1/11] Loss: 0.0095, PSNR: 7.1995\n",
      "\t[Val]   Batch [10/11] Loss: 0.0095, PSNR: 4.9634\n",
      "Epoch [31/50] Validation Loss: 0.0095, PSNR: 5.2731\n",
      "\n",
      "LOG: Epoch [32/50]\n",
      "\t Training Batch [1/41], Loss: 0.0093, PSNR: 3.0215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50] Training Loss: 0.0090, PSNR: 4.7840\n",
      "\t[Val]   Batch [1/11] Loss: 0.0090, PSNR: 7.4437\n",
      "\t[Val]   Batch [10/11] Loss: 0.0090, PSNR: 5.2082\n",
      "Epoch [32/50] Validation Loss: 0.0089, PSNR: 5.5175\n",
      "\n",
      "LOG: Epoch [33/50]\n",
      "\t Training Batch [1/41], Loss: 0.0086, PSNR: 4.7902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50] Training Loss: 0.0086, PSNR: 5.2365\n",
      "\t[Val]   Batch [1/11] Loss: 0.0085, PSNR: 7.6931\n",
      "\t[Val]   Batch [10/11] Loss: 0.0085, PSNR: 5.4570\n",
      "Epoch [33/50] Validation Loss: 0.0084, PSNR: 5.7667\n",
      "\n",
      "LOG: Epoch [34/50]\n",
      "\t Training Batch [1/41], Loss: 0.0083, PSNR: 5.3808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50] Training Loss: 0.0081, PSNR: 5.3666\n",
      "\t[Val]   Batch [1/11] Loss: 0.0080, PSNR: 7.9086\n",
      "\t[Val]   Batch [10/11] Loss: 0.0080, PSNR: 5.6731\n",
      "Epoch [34/50] Validation Loss: 0.0080, PSNR: 5.9820\n",
      "\n",
      "LOG: Epoch [35/50]\n",
      "\t Training Batch [1/41], Loss: 0.0079, PSNR: 6.6817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50] Training Loss: 0.0077, PSNR: 5.6349\n",
      "\t[Val]   Batch [1/11] Loss: 0.0076, PSNR: 8.1427\n",
      "\t[Val]   Batch [10/11] Loss: 0.0076, PSNR: 5.9071\n",
      "Epoch [35/50] Validation Loss: 0.0076, PSNR: 6.2165\n",
      "\n",
      "LOG: Epoch [36/50]\n",
      "\t Training Batch [1/41], Loss: 0.0072, PSNR: 5.4775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50] Training Loss: 0.0073, PSNR: 5.6953\n",
      "\t[Val]   Batch [1/11] Loss: 0.0073, PSNR: 8.3399\n",
      "\t[Val]   Batch [10/11] Loss: 0.0073, PSNR: 6.1042\n",
      "Epoch [36/50] Validation Loss: 0.0073, PSNR: 6.4137\n",
      "\n",
      "LOG: Epoch [37/50]\n",
      "\t Training Batch [1/41], Loss: 0.0073, PSNR: 6.3865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50] Training Loss: 0.0069, PSNR: 6.2289\n",
      "\t[Val]   Batch [1/11] Loss: 0.0069, PSNR: 8.5946\n",
      "\t[Val]   Batch [10/11] Loss: 0.0069, PSNR: 6.3584\n",
      "Epoch [37/50] Validation Loss: 0.0069, PSNR: 6.6688\n",
      "\n",
      "LOG: Epoch [38/50]\n",
      "\t Training Batch [1/41], Loss: 0.0067, PSNR: 4.0936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50] Training Loss: 0.0066, PSNR: 6.1794\n",
      "\t[Val]   Batch [1/11] Loss: 0.0066, PSNR: 8.7915\n",
      "\t[Val]   Batch [10/11] Loss: 0.0066, PSNR: 6.5551\n",
      "Epoch [38/50] Validation Loss: 0.0066, PSNR: 6.8660\n",
      "\n",
      "LOG: Epoch [39/50]\n",
      "\t Training Batch [1/41], Loss: 0.0065, PSNR: 4.3980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50] Training Loss: 0.0063, PSNR: 6.3926\n",
      "\t[Val]   Batch [1/11] Loss: 0.0063, PSNR: 8.9827\n",
      "\t[Val]   Batch [10/11] Loss: 0.0063, PSNR: 6.7468\n",
      "Epoch [39/50] Validation Loss: 0.0063, PSNR: 7.0577\n",
      "\n",
      "LOG: Epoch [40/50]\n",
      "\t Training Batch [1/41], Loss: 0.0062, PSNR: 9.0462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50] Training Loss: 0.0060, PSNR: 6.5382\n",
      "\t[Val]   Batch [1/11] Loss: 0.0060, PSNR: 9.1737\n",
      "\t[Val]   Batch [10/11] Loss: 0.0060, PSNR: 6.9393\n",
      "Epoch [40/50] Validation Loss: 0.0060, PSNR: 7.2492\n",
      "\n",
      "LOG: Epoch [41/50]\n",
      "\t Training Batch [1/41], Loss: 0.0058, PSNR: 7.7795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50] Training Loss: 0.0057, PSNR: 6.8511\n",
      "\t[Val]   Batch [1/11] Loss: 0.0058, PSNR: 9.3575\n",
      "\t[Val]   Batch [10/11] Loss: 0.0058, PSNR: 7.1233\n",
      "Epoch [41/50] Validation Loss: 0.0058, PSNR: 7.4333\n",
      "\n",
      "LOG: Epoch [42/50]\n",
      "\t Training Batch [1/41], Loss: 0.0057, PSNR: 7.7891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50] Training Loss: 0.0055, PSNR: 6.9929\n",
      "\t[Val]   Batch [1/11] Loss: 0.0055, PSNR: 9.5900\n",
      "\t[Val]   Batch [10/11] Loss: 0.0055, PSNR: 7.3557\n",
      "Epoch [42/50] Validation Loss: 0.0055, PSNR: 7.6664\n",
      "\n",
      "LOG: Epoch [43/50]\n",
      "\t Training Batch [1/41], Loss: 0.0054, PSNR: 7.2078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50] Training Loss: 0.0052, PSNR: 7.5630\n",
      "\t[Val]   Batch [1/11] Loss: 0.0052, PSNR: 9.7662\n",
      "\t[Val]   Batch [10/11] Loss: 0.0052, PSNR: 7.5314\n",
      "Epoch [43/50] Validation Loss: 0.0052, PSNR: 7.8426\n",
      "\n",
      "LOG: Epoch [44/50]\n",
      "\t Training Batch [1/41], Loss: 0.0049, PSNR: 8.4172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50] Training Loss: 0.0050, PSNR: 7.4814\n",
      "\t[Val]   Batch [1/11] Loss: 0.0050, PSNR: 9.9581\n",
      "\t[Val]   Batch [10/11] Loss: 0.0050, PSNR: 7.7230\n",
      "Epoch [44/50] Validation Loss: 0.0050, PSNR: 8.0345\n",
      "\n",
      "LOG: Epoch [45/50]\n",
      "\t Training Batch [1/41], Loss: 0.0047, PSNR: 8.2628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50] Training Loss: 0.0048, PSNR: 7.4617\n",
      "\t[Val]   Batch [1/11] Loss: 0.0048, PSNR: 10.1319\n",
      "\t[Val]   Batch [10/11] Loss: 0.0048, PSNR: 7.8973\n",
      "Epoch [45/50] Validation Loss: 0.0048, PSNR: 8.2085\n",
      "\n",
      "LOG: Epoch [46/50]\n",
      "\t Training Batch [1/41], Loss: 0.0046, PSNR: 7.3677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50] Training Loss: 0.0046, PSNR: 7.9612\n",
      "\t[Val]   Batch [1/11] Loss: 0.0046, PSNR: 10.3591\n",
      "\t[Val]   Batch [10/11] Loss: 0.0046, PSNR: 8.1247\n",
      "Epoch [46/50] Validation Loss: 0.0046, PSNR: 8.4358\n",
      "\n",
      "LOG: Epoch [47/50]\n",
      "\t Training Batch [1/41], Loss: 0.0043, PSNR: 8.2024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50] Training Loss: 0.0044, PSNR: 8.1583\n",
      "\t[Val]   Batch [1/11] Loss: 0.0044, PSNR: 10.5523\n",
      "\t[Val]   Batch [10/11] Loss: 0.0044, PSNR: 8.3186\n",
      "Epoch [47/50] Validation Loss: 0.0044, PSNR: 8.6285\n",
      "\n",
      "LOG: Epoch [48/50]\n",
      "\t Training Batch [1/41], Loss: 0.0044, PSNR: 8.9767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50] Training Loss: 0.0042, PSNR: 8.1986\n",
      "\t[Val]   Batch [1/11] Loss: 0.0042, PSNR: 10.7001\n",
      "\t[Val]   Batch [10/11] Loss: 0.0042, PSNR: 8.4666\n",
      "Epoch [48/50] Validation Loss: 0.0042, PSNR: 8.7766\n",
      "\n",
      "LOG: Epoch [49/50]\n",
      "\t Training Batch [1/41], Loss: 0.0042, PSNR: 9.1090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50] Training Loss: 0.0041, PSNR: 8.4348\n",
      "\t[Val]   Batch [1/11] Loss: 0.0040, PSNR: 10.8989\n",
      "\t[Val]   Batch [10/11] Loss: 0.0040, PSNR: 8.6664\n",
      "Epoch [49/50] Validation Loss: 0.0040, PSNR: 8.9752\n",
      "\n",
      "LOG: Epoch [50/50]\n",
      "\t Training Batch [1/41], Loss: 0.0040, PSNR: 9.4103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50] Training Loss: 0.0039, PSNR: 8.7032\n",
      "\t[Val]   Batch [1/11] Loss: 0.0039, PSNR: 11.0325\n",
      "\t[Val]   Batch [10/11] Loss: 0.0039, PSNR: 8.8004\n",
      "Epoch [50/50] Validation Loss: 0.0039, PSNR: 9.1097\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_cae = ConvAutoEncode()\n",
    "criterion_cae = nn.MSELoss()\n",
    "optimizer_cae = optim.Adam(model_cae.parameters(), lr=0.0001)\n",
    "\n",
    "#parameters for CAE\n",
    "num_epochs_cae = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_cae = model_cae.to(device)\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 3  # number of epochs to wait for improvement\n",
    "tolerance = 1e-4\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "#grad accumulation parameters\n",
    "accumulation_steps = 8 \n",
    "\n",
    "# for loss and metrics tracking\n",
    "autoencoder_epoch_losses_cae = []\n",
    "validation_epoch_losses_cae = []\n",
    "train_psnr = []\n",
    "val_psnr = []\n",
    "\n",
    "psnr = PeakSignalNoiseRatio().to(device)\n",
    "\n",
    "# mixed precision training\n",
    "scaler = GradScaler()  # Gradient scaler for mixed precision\n",
    "\n",
    "for epoch in range(num_epochs_cae):\n",
    "    # training\n",
    "    model_cae.train()\n",
    "    running_loss = 0.0\n",
    "    running_psnr = 0.0\n",
    "\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs_cae}]\")\n",
    "\n",
    "    optimizer_cae.zero_grad()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader_cae):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "        # mixed precision forward pass\n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            _, decoded = model_cae(data)\n",
    "            loss = criterion_cae(decoded, data) / accumulation_steps\n",
    "\n",
    "            with torch.no_grad():\n",
    "                nan_in_out = torch.isnan(decoded).any().item()\n",
    "                inf_in_out = torch.isinf(decoded).any().item()\n",
    "\n",
    "        #backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        loss_value = loss.item() * accumulation_steps\n",
    "        running_loss += loss_value\n",
    "\n",
    "        psnr_value = psnr(decoded, data).item()\n",
    "        running_psnr += psnr_value\n",
    "\n",
    "\n",
    "        # performing optimizer step and reset gradients after `accumulation_steps` batches\n",
    "        if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader_cae):\n",
    "            scaler.step(optimizer_cae)\n",
    "            scaler.update()\n",
    "            optimizer_cae.zero_grad()\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 200 == 0:\n",
    "            print(\n",
    "    f\"\\t Training Batch [{batch_idx + 1}/{len(train_loader_cae)}], \"\n",
    "    f\"Loss: {loss_value:.4f}, PSNR: {psnr_value:.4f}\"\n",
    ")\n",
    "\n",
    "\n",
    "        #delete intermediate variables and clear GPU cache\n",
    "        del data, decoded, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    #compute average metrics for the epoch\n",
    "    avg_train_loss = running_loss / len(train_loader_cae)\n",
    "    avg_train_psnr = running_psnr / len(train_loader_cae)\n",
    "\n",
    "    autoencoder_epoch_losses_cae.append(avg_train_loss)\n",
    "    train_psnr.append(avg_train_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Training Loss: {avg_train_loss:.4f}, PSNR: {avg_train_psnr:.4f}\")\n",
    "\n",
    "    #clear GPU cache after training\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    #validation\n",
    "    model_cae.eval()\n",
    "    validation_loss = 0.0\n",
    "    val_psnr_epoch = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(val_loader_cae):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # Mixed precision forward pass for validation\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                _, decoded = model_cae(data)\n",
    "                loss = criterion_cae(decoded, data)\n",
    "\n",
    "            validation_loss += loss.item()\n",
    "            val_psnr_epoch += psnr(decoded, data).item()\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                loss_val = loss.item()\n",
    "                psnr_val = psnr(decoded, data).item()\n",
    "                print(\n",
    "                    f\"\\t[Val]   Batch [{batch_idx + 1}/{len(val_loader_cae)}] \"\n",
    "                    f\"Loss: {loss_val:.4f}, PSNR: {psnr_val:.4f}\"\n",
    "                )\n",
    "\n",
    "            del data, decoded, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # average validation metrics for the epoch\n",
    "    avg_val_loss = validation_loss / len(val_loader_cae)\n",
    "    avg_val_psnr = val_psnr_epoch / len(val_loader_cae)\n",
    "\n",
    "    validation_epoch_losses_cae.append(avg_val_loss)\n",
    "    val_psnr.append(avg_val_psnr)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs_cae}] Validation Loss: {avg_val_loss:.4f}, PSNR: {avg_val_psnr:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss < best_val_loss - tolerance:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0  # Reset counter\n",
    "        #best model checkpoint\n",
    "        #torch.save(model_cae.state_dict(), 'best_model_cae.pth')\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "#plot for training and validation loss trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(autoencoder_epoch_losses_cae) + 1), autoencoder_epoch_losses_cae, marker='o', label=\"Training Loss\")\n",
    "plt.plot(range(1, len(validation_epoch_losses_cae) + 1), validation_epoch_losses_cae, marker='x', label=\"Validation Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#plot for PSNR trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_psnr) + 1), train_psnr, marker='o', label=\"Training PSNR\")\n",
    "plt.plot(range(1, len(val_psnr) + 1), val_psnr, marker='x', label=\"Validation PSNR\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PSNR')\n",
    "plt.title('PSNR Trend Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the encoder section of CAE as feature extractor to generate compact representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:42.922586Z",
     "iopub.status.busy": "2025-05-08T18:41:42.921585Z",
     "iopub.status.idle": "2025-05-08T18:41:43.060797Z",
     "shell.execute_reply": "2025-05-08T18:41:43.060797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting representations for the train dataset...\n",
      "    Processed batch 1/1 for train dataset.\n",
      "Completed encoding for the train dataset.\n",
      "\n",
      "Extracting representations for the val dataset...\n",
      "    Processed batch 1/1 for val dataset.\n",
      "Completed encoding for the val dataset.\n",
      "\n",
      "Extracting representations for the test dataset...\n",
      "    Processed batch 1/12 for test dataset.\n",
      "Completed encoding for the test dataset.\n",
      "Feature extraction completed for all subsets.\n"
     ]
    }
   ],
   "source": [
    "#dir to save encoded representations\n",
    "encoded_dir = 'encoded_representations'\n",
    "os.makedirs(encoded_dir, exist_ok=True)\n",
    "\n",
    "loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "model_cae.eval()\n",
    "\n",
    "# Feature extraction\n",
    "with torch.no_grad():\n",
    "    for subset_name, loader in loaders.items():\n",
    "        print(f\"\\nExtracting representations for the {subset_name} dataset...\")\n",
    "\n",
    "        # dir for the given subset's encoded features\n",
    "        subset_encoded_dir = os.path.join(encoded_dir, subset_name)\n",
    "        os.makedirs(subset_encoded_dir, exist_ok=True)\n",
    "\n",
    "        for batch_idx, (data, labels) in enumerate(loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "\n",
    "            # passing data through the encoder to obtain representations\n",
    "            encoded_features, _ = model_cae(data)  # latent representation\n",
    "\n",
    "            # moving to CPU and convert to NumPy\n",
    "            encoded_features = encoded_features.cpu().numpy()  \n",
    "            labels = labels.cpu().numpy() \n",
    "\n",
    "            #saving the encoded features and labels\n",
    "            np.save(os.path.join(subset_encoded_dir, f'encoded_batch_{batch_idx}.npy'), encoded_features)\n",
    "            np.save(os.path.join(subset_encoded_dir, f'labels_batch_{batch_idx}.npy'), labels)\n",
    "\n",
    "            if batch_idx % 1 == 0 and subset_name != 'test':\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "            elif subset_name == 'test' and batch_idx % 100 == 0:  # Log less frequently for the test set\n",
    "                print(f\"    Processed batch {batch_idx + 1}/{len(loader)} for {subset_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed encoding for the {subset_name} dataset.\")\n",
    "\n",
    "print(\"Feature extraction completed for all subsets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-To-End CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:43.063802Z",
     "iopub.status.busy": "2025-05-08T18:41:43.063802Z",
     "iopub.status.idle": "2025-05-08T18:41:43.068311Z",
     "shell.execute_reply": "2025-05-08T18:41:43.068311Z"
    }
   },
   "outputs": [],
   "source": [
    "class hyperspectralCNN(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(hyperspectralCNN, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 5x5 -> 2x2\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Bottleneck\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2, 2)  # 2x2 -> 1x1\n",
    "        )\n",
    "\n",
    "        #fully connected layers for classification\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),  #3D to 1D vector for input to FC layers\n",
    "            nn.Linear(16 * 2 * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:43.070712Z",
     "iopub.status.busy": "2025-05-08T18:41:43.070712Z",
     "iopub.status.idle": "2025-05-08T18:41:51.552446Z",
     "shell.execute_reply": "2025-05-08T18:41:51.552446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] completed, Average Training Loss: 2.6314\n",
      "    Validation Batch [1/1], Loss: 2.6450\n",
      "Validation Loss: 2.6450, Validation Accuracy: 7.14%\n",
      "Validation loss improved from inf to 2.6450. Saving model...\n",
      "\n",
      "LOG: Epoch [2/1000] - Training\n",
      "Epoch [2/1000] completed, Average Training Loss: 2.5960\n",
      "    Validation Batch [1/1], Loss: 2.6450\n",
      "Validation Loss: 2.6450, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6450 to 2.6450. Saving model...\n",
      "\n",
      "LOG: Epoch [3/1000] - Training\n",
      "Epoch [3/1000] completed, Average Training Loss: 2.5667\n",
      "    Validation Batch [1/1], Loss: 2.6450\n",
      "Validation Loss: 2.6450, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6450 to 2.6450. Saving model...\n",
      "\n",
      "LOG: Epoch [4/1000] - Training\n",
      "Epoch [4/1000] completed, Average Training Loss: 2.5308\n",
      "    Validation Batch [1/1], Loss: 2.6449\n",
      "Validation Loss: 2.6449, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6450 to 2.6449. Saving model...\n",
      "\n",
      "LOG: Epoch [5/1000] - Training\n",
      "Epoch [5/1000] completed, Average Training Loss: 2.5198\n",
      "    Validation Batch [1/1], Loss: 2.6449\n",
      "Validation Loss: 2.6449, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6449 to 2.6449. Saving model...\n",
      "\n",
      "LOG: Epoch [6/1000] - Training\n",
      "Epoch [6/1000] completed, Average Training Loss: 2.4944\n",
      "    Validation Batch [1/1], Loss: 2.6448\n",
      "Validation Loss: 2.6448, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6449 to 2.6448. Saving model...\n",
      "\n",
      "LOG: Epoch [7/1000] - Training\n",
      "Epoch [7/1000] completed, Average Training Loss: 2.4857\n",
      "    Validation Batch [1/1], Loss: 2.6448\n",
      "Validation Loss: 2.6448, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6448 to 2.6448. Saving model...\n",
      "\n",
      "LOG: Epoch [8/1000] - Training\n",
      "Epoch [8/1000] completed, Average Training Loss: 2.4741\n",
      "    Validation Batch [1/1], Loss: 2.6448\n",
      "Validation Loss: 2.6448, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6448 to 2.6448. Saving model...\n",
      "\n",
      "LOG: Epoch [9/1000] - Training\n",
      "Epoch [9/1000] completed, Average Training Loss: 2.4465\n",
      "    Validation Batch [1/1], Loss: 2.6448\n",
      "Validation Loss: 2.6448, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6448 to 2.6448. Saving model...\n",
      "\n",
      "LOG: Epoch [10/1000] - Training\n",
      "Epoch [10/1000] completed, Average Training Loss: 2.4418\n",
      "    Validation Batch [1/1], Loss: 2.6448\n",
      "Validation Loss: 2.6448, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6448 to 2.6448. Saving model...\n",
      "\n",
      "LOG: Epoch [11/1000] - Training\n",
      "Epoch [11/1000] completed, Average Training Loss: 2.4356\n",
      "    Validation Batch [1/1], Loss: 2.6448\n",
      "Validation Loss: 2.6448, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6448 to 2.6448. Saving model...\n",
      "\n",
      "LOG: Epoch [12/1000] - Training\n",
      "Epoch [12/1000] completed, Average Training Loss: 2.4112\n",
      "    Validation Batch [1/1], Loss: 2.6448\n",
      "Validation Loss: 2.6448, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6448 to 2.6448. Saving model...\n",
      "\n",
      "LOG: Epoch [13/1000] - Training\n",
      "Epoch [13/1000] completed, Average Training Loss: 2.4008\n",
      "    Validation Batch [1/1], Loss: 2.6448\n",
      "Validation Loss: 2.6448, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [14/1000] - Training\n",
      "Epoch [14/1000] completed, Average Training Loss: 2.4158\n",
      "    Validation Batch [1/1], Loss: 2.6448\n",
      "Validation Loss: 2.6448, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [15/1000] - Training\n",
      "Epoch [15/1000] completed, Average Training Loss: 2.3647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 2.6448\n",
      "Validation Loss: 2.6448, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [16/1000] - Training\n",
      "Epoch [16/1000] completed, Average Training Loss: 2.3792\n",
      "    Validation Batch [1/1], Loss: 2.6448\n",
      "Validation Loss: 2.6448, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [17/1000] - Training\n",
      "Epoch [17/1000] completed, Average Training Loss: 2.3556\n",
      "    Validation Batch [1/1], Loss: 2.6449\n",
      "Validation Loss: 2.6449, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [18/1000] - Training\n",
      "Epoch [18/1000] completed, Average Training Loss: 2.3447\n",
      "    Validation Batch [1/1], Loss: 2.6449\n",
      "Validation Loss: 2.6449, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [19/1000] - Training\n",
      "Epoch [19/1000] completed, Average Training Loss: 2.3522\n",
      "    Validation Batch [1/1], Loss: 2.6449\n",
      "Validation Loss: 2.6449, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [20/1000] - Training\n",
      "Epoch [20/1000] completed, Average Training Loss: 2.3251\n",
      "    Validation Batch [1/1], Loss: 2.6450\n",
      "Validation Loss: 2.6450, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [21/1000] - Training\n",
      "Epoch [21/1000] completed, Average Training Loss: 2.3354\n",
      "    Validation Batch [1/1], Loss: 2.6450\n",
      "Validation Loss: 2.6450, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [22/1000] - Training\n",
      "Epoch [22/1000] completed, Average Training Loss: 2.3125\n",
      "    Validation Batch [1/1], Loss: 2.6451\n",
      "Validation Loss: 2.6451, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [23/1000] - Training\n",
      "Epoch [23/1000] completed, Average Training Loss: 2.3110\n",
      "    Validation Batch [1/1], Loss: 2.6450\n",
      "Validation Loss: 2.6450, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [24/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/1000] completed, Average Training Loss: 2.3148\n",
      "    Validation Batch [1/1], Loss: 2.6450\n",
      "Validation Loss: 2.6450, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [25/1000] - Training\n",
      "Epoch [25/1000] completed, Average Training Loss: 2.3081\n",
      "    Validation Batch [1/1], Loss: 2.6450\n",
      "Validation Loss: 2.6450, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [26/1000] - Training\n",
      "Epoch [26/1000] completed, Average Training Loss: 2.3104\n",
      "    Validation Batch [1/1], Loss: 2.6449\n",
      "Validation Loss: 2.6449, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [27/1000] - Training\n",
      "Epoch [27/1000] completed, Average Training Loss: 2.2778\n",
      "    Validation Batch [1/1], Loss: 2.6449\n",
      "Validation Loss: 2.6449, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [28/1000] - Training\n",
      "Epoch [28/1000] completed, Average Training Loss: 2.2608\n",
      "    Validation Batch [1/1], Loss: 2.6448\n",
      "Validation Loss: 2.6448, Validation Accuracy: 7.14%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [29/1000] - Training\n",
      "Epoch [29/1000] completed, Average Training Loss: 2.2537\n",
      "    Validation Batch [1/1], Loss: 2.6446\n",
      "Validation Loss: 2.6446, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6448 to 2.6446. Saving model...\n",
      "\n",
      "LOG: Epoch [30/1000] - Training\n",
      "Epoch [30/1000] completed, Average Training Loss: 2.2527\n",
      "    Validation Batch [1/1], Loss: 2.6445\n",
      "Validation Loss: 2.6445, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6446 to 2.6445. Saving model...\n",
      "\n",
      "LOG: Epoch [31/1000] - Training\n",
      "Epoch [31/1000] completed, Average Training Loss: 2.2278\n",
      "    Validation Batch [1/1], Loss: 2.6443\n",
      "Validation Loss: 2.6443, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6445 to 2.6443. Saving model...\n",
      "\n",
      "LOG: Epoch [32/1000] - Training\n",
      "Epoch [32/1000] completed, Average Training Loss: 2.2338\n",
      "    Validation Batch [1/1], Loss: 2.6442\n",
      "Validation Loss: 2.6442, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6443 to 2.6442. Saving model...\n",
      "\n",
      "LOG: Epoch [33/1000] - Training\n",
      "Epoch [33/1000] completed, Average Training Loss: 2.2130\n",
      "    Validation Batch [1/1], Loss: 2.6440\n",
      "Validation Loss: 2.6440, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6442 to 2.6440. Saving model...\n",
      "\n",
      "LOG: Epoch [34/1000] - Training\n",
      "Epoch [34/1000] completed, Average Training Loss: 2.2195\n",
      "    Validation Batch [1/1], Loss: 2.6438\n",
      "Validation Loss: 2.6438, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6440 to 2.6438. Saving model...\n",
      "\n",
      "LOG: Epoch [35/1000] - Training\n",
      "Epoch [35/1000] completed, Average Training Loss: 2.2252\n",
      "    Validation Batch [1/1], Loss: 2.6436\n",
      "Validation Loss: 2.6436, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6438 to 2.6436. Saving model...\n",
      "\n",
      "LOG: Epoch [36/1000] - Training\n",
      "Epoch [36/1000] completed, Average Training Loss: 2.2049\n",
      "    Validation Batch [1/1], Loss: 2.6433\n",
      "Validation Loss: 2.6433, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6436 to 2.6433. Saving model...\n",
      "\n",
      "LOG: Epoch [37/1000] - Training\n",
      "Epoch [37/1000] completed, Average Training Loss: 2.2044\n",
      "    Validation Batch [1/1], Loss: 2.6431\n",
      "Validation Loss: 2.6431, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6433 to 2.6431. Saving model...\n",
      "\n",
      "LOG: Epoch [38/1000] - Training\n",
      "Epoch [38/1000] completed, Average Training Loss: 2.1790\n",
      "    Validation Batch [1/1], Loss: 2.6430\n",
      "Validation Loss: 2.6430, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6431 to 2.6430. Saving model...\n",
      "\n",
      "LOG: Epoch [39/1000] - Training\n",
      "Epoch [39/1000] completed, Average Training Loss: 2.1924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 2.6428\n",
      "Validation Loss: 2.6428, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6430 to 2.6428. Saving model...\n",
      "\n",
      "LOG: Epoch [40/1000] - Training\n",
      "Epoch [40/1000] completed, Average Training Loss: 2.1857\n",
      "    Validation Batch [1/1], Loss: 2.6425\n",
      "Validation Loss: 2.6425, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6428 to 2.6425. Saving model...\n",
      "\n",
      "LOG: Epoch [41/1000] - Training\n",
      "Epoch [41/1000] completed, Average Training Loss: 2.1408\n",
      "    Validation Batch [1/1], Loss: 2.6421\n",
      "Validation Loss: 2.6421, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6425 to 2.6421. Saving model...\n",
      "\n",
      "LOG: Epoch [42/1000] - Training\n",
      "Epoch [42/1000] completed, Average Training Loss: 2.1709\n",
      "    Validation Batch [1/1], Loss: 2.6417\n",
      "Validation Loss: 2.6417, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6421 to 2.6417. Saving model...\n",
      "\n",
      "LOG: Epoch [43/1000] - Training\n",
      "Epoch [43/1000] completed, Average Training Loss: 2.1675\n",
      "    Validation Batch [1/1], Loss: 2.6410\n",
      "Validation Loss: 2.6410, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6417 to 2.6410. Saving model...\n",
      "\n",
      "LOG: Epoch [44/1000] - Training\n",
      "Epoch [44/1000] completed, Average Training Loss: 2.1614\n",
      "    Validation Batch [1/1], Loss: 2.6404\n",
      "Validation Loss: 2.6404, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6410 to 2.6404. Saving model...\n",
      "\n",
      "LOG: Epoch [45/1000] - Training\n",
      "Epoch [45/1000] completed, Average Training Loss: 2.1326\n",
      "    Validation Batch [1/1], Loss: 2.6398\n",
      "Validation Loss: 2.6398, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6404 to 2.6398. Saving model...\n",
      "\n",
      "LOG: Epoch [46/1000] - Training\n",
      "Epoch [46/1000] completed, Average Training Loss: 2.1186\n",
      "    Validation Batch [1/1], Loss: 2.6389\n",
      "Validation Loss: 2.6389, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6398 to 2.6389. Saving model...\n",
      "\n",
      "LOG: Epoch [47/1000] - Training\n",
      "Epoch [47/1000] completed, Average Training Loss: 2.1170\n",
      "    Validation Batch [1/1], Loss: 2.6380\n",
      "Validation Loss: 2.6380, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6389 to 2.6380. Saving model...\n",
      "\n",
      "LOG: Epoch [48/1000] - Training\n",
      "Epoch [48/1000] completed, Average Training Loss: 2.1087\n",
      "    Validation Batch [1/1], Loss: 2.6364\n",
      "Validation Loss: 2.6364, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6380 to 2.6364. Saving model...\n",
      "\n",
      "LOG: Epoch [49/1000] - Training\n",
      "Epoch [49/1000] completed, Average Training Loss: 2.0903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 2.6345\n",
      "Validation Loss: 2.6345, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6364 to 2.6345. Saving model...\n",
      "\n",
      "LOG: Epoch [50/1000] - Training\n",
      "Epoch [50/1000] completed, Average Training Loss: 2.0971\n",
      "    Validation Batch [1/1], Loss: 2.6327\n",
      "Validation Loss: 2.6327, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6345 to 2.6327. Saving model...\n",
      "\n",
      "LOG: Epoch [51/1000] - Training\n",
      "Epoch [51/1000] completed, Average Training Loss: 2.0792\n",
      "    Validation Batch [1/1], Loss: 2.6310\n",
      "Validation Loss: 2.6310, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6327 to 2.6310. Saving model...\n",
      "\n",
      "LOG: Epoch [52/1000] - Training\n",
      "Epoch [52/1000] completed, Average Training Loss: 2.0609\n",
      "    Validation Batch [1/1], Loss: 2.6294\n",
      "Validation Loss: 2.6294, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6310 to 2.6294. Saving model...\n",
      "\n",
      "LOG: Epoch [53/1000] - Training\n",
      "Epoch [53/1000] completed, Average Training Loss: 2.0670\n",
      "    Validation Batch [1/1], Loss: 2.6265\n",
      "Validation Loss: 2.6265, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6294 to 2.6265. Saving model...\n",
      "\n",
      "LOG: Epoch [54/1000] - Training\n",
      "Epoch [54/1000] completed, Average Training Loss: 2.0395\n",
      "    Validation Batch [1/1], Loss: 2.6229\n",
      "Validation Loss: 2.6229, Validation Accuracy: 7.14%\n",
      "Validation loss improved from 2.6265 to 2.6229. Saving model...\n",
      "\n",
      "LOG: Epoch [55/1000] - Training\n",
      "Epoch [55/1000] completed, Average Training Loss: 2.0444\n",
      "    Validation Batch [1/1], Loss: 2.6189\n",
      "Validation Loss: 2.6189, Validation Accuracy: 8.57%\n",
      "Validation loss improved from 2.6229 to 2.6189. Saving model...\n",
      "\n",
      "LOG: Epoch [56/1000] - Training\n",
      "Epoch [56/1000] completed, Average Training Loss: 2.0303\n",
      "    Validation Batch [1/1], Loss: 2.6137\n",
      "Validation Loss: 2.6137, Validation Accuracy: 8.57%\n",
      "Validation loss improved from 2.6189 to 2.6137. Saving model...\n",
      "\n",
      "LOG: Epoch [57/1000] - Training\n",
      "Epoch [57/1000] completed, Average Training Loss: 2.0262\n",
      "    Validation Batch [1/1], Loss: 2.6081\n",
      "Validation Loss: 2.6081, Validation Accuracy: 8.57%\n",
      "Validation loss improved from 2.6137 to 2.6081. Saving model...\n",
      "\n",
      "LOG: Epoch [58/1000] - Training\n",
      "Epoch [58/1000] completed, Average Training Loss: 2.0381\n",
      "    Validation Batch [1/1], Loss: 2.6026\n",
      "Validation Loss: 2.6026, Validation Accuracy: 10.00%\n",
      "Validation loss improved from 2.6081 to 2.6026. Saving model...\n",
      "\n",
      "LOG: Epoch [59/1000] - Training\n",
      "Epoch [59/1000] completed, Average Training Loss: 2.0068\n",
      "    Validation Batch [1/1], Loss: 2.5985\n",
      "Validation Loss: 2.5985, Validation Accuracy: 10.00%\n",
      "Validation loss improved from 2.6026 to 2.5985. Saving model...\n",
      "\n",
      "LOG: Epoch [60/1000] - Training\n",
      "Epoch [60/1000] completed, Average Training Loss: 2.0203\n",
      "    Validation Batch [1/1], Loss: 2.5948\n",
      "Validation Loss: 2.5948, Validation Accuracy: 10.00%\n",
      "Validation loss improved from 2.5985 to 2.5948. Saving model...\n",
      "\n",
      "LOG: Epoch [61/1000] - Training\n",
      "Epoch [61/1000] completed, Average Training Loss: 2.0153\n",
      "    Validation Batch [1/1], Loss: 2.5886\n",
      "Validation Loss: 2.5886, Validation Accuracy: 11.43%\n",
      "Validation loss improved from 2.5948 to 2.5886. Saving model...\n",
      "\n",
      "LOG: Epoch [62/1000] - Training\n",
      "Epoch [62/1000] completed, Average Training Loss: 1.9932\n",
      "    Validation Batch [1/1], Loss: 2.5789\n",
      "Validation Loss: 2.5789, Validation Accuracy: 11.43%\n",
      "Validation loss improved from 2.5886 to 2.5789. Saving model...\n",
      "\n",
      "LOG: Epoch [63/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/1000] completed, Average Training Loss: 1.9791\n",
      "    Validation Batch [1/1], Loss: 2.5671\n",
      "Validation Loss: 2.5671, Validation Accuracy: 12.86%\n",
      "Validation loss improved from 2.5789 to 2.5671. Saving model...\n",
      "\n",
      "LOG: Epoch [64/1000] - Training\n",
      "Epoch [64/1000] completed, Average Training Loss: 1.9831\n",
      "    Validation Batch [1/1], Loss: 2.5547\n",
      "Validation Loss: 2.5547, Validation Accuracy: 15.71%\n",
      "Validation loss improved from 2.5671 to 2.5547. Saving model...\n",
      "\n",
      "LOG: Epoch [65/1000] - Training\n",
      "Epoch [65/1000] completed, Average Training Loss: 1.9599\n",
      "    Validation Batch [1/1], Loss: 2.5433\n",
      "Validation Loss: 2.5433, Validation Accuracy: 15.71%\n",
      "Validation loss improved from 2.5547 to 2.5433. Saving model...\n",
      "\n",
      "LOG: Epoch [66/1000] - Training\n",
      "Epoch [66/1000] completed, Average Training Loss: 1.9601\n",
      "    Validation Batch [1/1], Loss: 2.5314\n",
      "Validation Loss: 2.5314, Validation Accuracy: 15.71%\n",
      "Validation loss improved from 2.5433 to 2.5314. Saving model...\n",
      "\n",
      "LOG: Epoch [67/1000] - Training\n",
      "Epoch [67/1000] completed, Average Training Loss: 1.9413\n",
      "    Validation Batch [1/1], Loss: 2.5198\n",
      "Validation Loss: 2.5198, Validation Accuracy: 18.57%\n",
      "Validation loss improved from 2.5314 to 2.5198. Saving model...\n",
      "\n",
      "LOG: Epoch [68/1000] - Training\n",
      "Epoch [68/1000] completed, Average Training Loss: 1.9555\n",
      "    Validation Batch [1/1], Loss: 2.5082\n",
      "Validation Loss: 2.5082, Validation Accuracy: 22.86%\n",
      "Validation loss improved from 2.5198 to 2.5082. Saving model...\n",
      "\n",
      "LOG: Epoch [69/1000] - Training\n",
      "Epoch [69/1000] completed, Average Training Loss: 1.9373\n",
      "    Validation Batch [1/1], Loss: 2.4906\n",
      "Validation Loss: 2.4906, Validation Accuracy: 25.71%\n",
      "Validation loss improved from 2.5082 to 2.4906. Saving model...\n",
      "\n",
      "LOG: Epoch [70/1000] - Training\n",
      "Epoch [70/1000] completed, Average Training Loss: 1.9315\n",
      "    Validation Batch [1/1], Loss: 2.4738\n",
      "Validation Loss: 2.4738, Validation Accuracy: 25.71%\n",
      "Validation loss improved from 2.4906 to 2.4738. Saving model...\n",
      "\n",
      "LOG: Epoch [71/1000] - Training\n",
      "Epoch [71/1000] completed, Average Training Loss: 1.8968\n",
      "    Validation Batch [1/1], Loss: 2.4604\n",
      "Validation Loss: 2.4604, Validation Accuracy: 27.14%\n",
      "Validation loss improved from 2.4738 to 2.4604. Saving model...\n",
      "\n",
      "LOG: Epoch [72/1000] - Training\n",
      "Epoch [72/1000] completed, Average Training Loss: 1.8951\n",
      "    Validation Batch [1/1], Loss: 2.4452\n",
      "Validation Loss: 2.4452, Validation Accuracy: 28.57%\n",
      "Validation loss improved from 2.4604 to 2.4452. Saving model...\n",
      "\n",
      "LOG: Epoch [73/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/1000] completed, Average Training Loss: 1.8902\n",
      "    Validation Batch [1/1], Loss: 2.4178\n",
      "Validation Loss: 2.4178, Validation Accuracy: 32.86%\n",
      "Validation loss improved from 2.4452 to 2.4178. Saving model...\n",
      "\n",
      "LOG: Epoch [74/1000] - Training\n",
      "Epoch [74/1000] completed, Average Training Loss: 1.8655\n",
      "    Validation Batch [1/1], Loss: 2.3841\n",
      "Validation Loss: 2.3841, Validation Accuracy: 38.57%\n",
      "Validation loss improved from 2.4178 to 2.3841. Saving model...\n",
      "\n",
      "LOG: Epoch [75/1000] - Training\n",
      "Epoch [75/1000] completed, Average Training Loss: 1.8779\n",
      "    Validation Batch [1/1], Loss: 2.3604\n",
      "Validation Loss: 2.3604, Validation Accuracy: 41.43%\n",
      "Validation loss improved from 2.3841 to 2.3604. Saving model...\n",
      "\n",
      "LOG: Epoch [76/1000] - Training\n",
      "Epoch [76/1000] completed, Average Training Loss: 1.8827\n",
      "    Validation Batch [1/1], Loss: 2.3442\n",
      "Validation Loss: 2.3442, Validation Accuracy: 41.43%\n",
      "Validation loss improved from 2.3604 to 2.3442. Saving model...\n",
      "\n",
      "LOG: Epoch [77/1000] - Training\n",
      "Epoch [77/1000] completed, Average Training Loss: 1.8723\n",
      "    Validation Batch [1/1], Loss: 2.3276\n",
      "Validation Loss: 2.3276, Validation Accuracy: 41.43%\n",
      "Validation loss improved from 2.3442 to 2.3276. Saving model...\n",
      "\n",
      "LOG: Epoch [78/1000] - Training\n",
      "Epoch [78/1000] completed, Average Training Loss: 1.8532\n",
      "    Validation Batch [1/1], Loss: 2.3012\n",
      "Validation Loss: 2.3012, Validation Accuracy: 42.86%\n",
      "Validation loss improved from 2.3276 to 2.3012. Saving model...\n",
      "\n",
      "LOG: Epoch [79/1000] - Training\n",
      "Epoch [79/1000] completed, Average Training Loss: 1.8439\n",
      "    Validation Batch [1/1], Loss: 2.2615\n",
      "Validation Loss: 2.2615, Validation Accuracy: 48.57%\n",
      "Validation loss improved from 2.3012 to 2.2615. Saving model...\n",
      "\n",
      "LOG: Epoch [80/1000] - Training\n",
      "Epoch [80/1000] completed, Average Training Loss: 1.8030\n",
      "    Validation Batch [1/1], Loss: 2.2275\n",
      "Validation Loss: 2.2275, Validation Accuracy: 48.57%\n",
      "Validation loss improved from 2.2615 to 2.2275. Saving model...\n",
      "\n",
      "LOG: Epoch [81/1000] - Training\n",
      "Epoch [81/1000] completed, Average Training Loss: 1.8634\n",
      "    Validation Batch [1/1], Loss: 2.1948\n",
      "Validation Loss: 2.1948, Validation Accuracy: 48.57%\n",
      "Validation loss improved from 2.2275 to 2.1948. Saving model...\n",
      "\n",
      "LOG: Epoch [82/1000] - Training\n",
      "Epoch [82/1000] completed, Average Training Loss: 1.8373\n",
      "    Validation Batch [1/1], Loss: 2.1749\n",
      "Validation Loss: 2.1749, Validation Accuracy: 50.00%\n",
      "Validation loss improved from 2.1948 to 2.1749. Saving model...\n",
      "\n",
      "LOG: Epoch [83/1000] - Training\n",
      "Epoch [83/1000] completed, Average Training Loss: 1.8213\n",
      "    Validation Batch [1/1], Loss: 2.1624\n",
      "Validation Loss: 2.1624, Validation Accuracy: 50.00%\n",
      "Validation loss improved from 2.1749 to 2.1624. Saving model...\n",
      "\n",
      "LOG: Epoch [84/1000] - Training\n",
      "Epoch [84/1000] completed, Average Training Loss: 1.7966\n",
      "    Validation Batch [1/1], Loss: 2.1442\n",
      "Validation Loss: 2.1442, Validation Accuracy: 52.86%\n",
      "Validation loss improved from 2.1624 to 2.1442. Saving model...\n",
      "\n",
      "LOG: Epoch [85/1000] - Training\n",
      "Epoch [85/1000] completed, Average Training Loss: 1.7854\n",
      "    Validation Batch [1/1], Loss: 2.1093\n",
      "Validation Loss: 2.1093, Validation Accuracy: 54.29%\n",
      "Validation loss improved from 2.1442 to 2.1093. Saving model...\n",
      "\n",
      "LOG: Epoch [86/1000] - Training\n",
      "Epoch [86/1000] completed, Average Training Loss: 1.7711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 2.0654\n",
      "Validation Loss: 2.0654, Validation Accuracy: 54.29%\n",
      "Validation loss improved from 2.1093 to 2.0654. Saving model...\n",
      "\n",
      "LOG: Epoch [87/1000] - Training\n",
      "Epoch [87/1000] completed, Average Training Loss: 1.7867\n",
      "    Validation Batch [1/1], Loss: 2.0595\n",
      "Validation Loss: 2.0595, Validation Accuracy: 55.71%\n",
      "Validation loss improved from 2.0654 to 2.0595. Saving model...\n",
      "\n",
      "LOG: Epoch [88/1000] - Training\n",
      "Epoch [88/1000] completed, Average Training Loss: 1.7562\n",
      "    Validation Batch [1/1], Loss: 2.0546\n",
      "Validation Loss: 2.0546, Validation Accuracy: 58.57%\n",
      "Validation loss improved from 2.0595 to 2.0546. Saving model...\n",
      "\n",
      "LOG: Epoch [89/1000] - Training\n",
      "Epoch [89/1000] completed, Average Training Loss: 1.7623\n",
      "    Validation Batch [1/1], Loss: 2.0265\n",
      "Validation Loss: 2.0265, Validation Accuracy: 57.14%\n",
      "Validation loss improved from 2.0546 to 2.0265. Saving model...\n",
      "\n",
      "LOG: Epoch [90/1000] - Training\n",
      "Epoch [90/1000] completed, Average Training Loss: 1.7329\n",
      "    Validation Batch [1/1], Loss: 1.9949\n",
      "Validation Loss: 1.9949, Validation Accuracy: 58.57%\n",
      "Validation loss improved from 2.0265 to 1.9949. Saving model...\n",
      "\n",
      "LOG: Epoch [91/1000] - Training\n",
      "Epoch [91/1000] completed, Average Training Loss: 1.7197\n",
      "    Validation Batch [1/1], Loss: 1.9680\n",
      "Validation Loss: 1.9680, Validation Accuracy: 61.43%\n",
      "Validation loss improved from 1.9949 to 1.9680. Saving model...\n",
      "\n",
      "LOG: Epoch [92/1000] - Training\n",
      "Epoch [92/1000] completed, Average Training Loss: 1.7059\n",
      "    Validation Batch [1/1], Loss: 1.9385\n",
      "Validation Loss: 1.9385, Validation Accuracy: 65.71%\n",
      "Validation loss improved from 1.9680 to 1.9385. Saving model...\n",
      "\n",
      "LOG: Epoch [93/1000] - Training\n",
      "Epoch [93/1000] completed, Average Training Loss: 1.7218\n",
      "    Validation Batch [1/1], Loss: 1.9190\n",
      "Validation Loss: 1.9190, Validation Accuracy: 64.29%\n",
      "Validation loss improved from 1.9385 to 1.9190. Saving model...\n",
      "\n",
      "LOG: Epoch [94/1000] - Training\n",
      "Epoch [94/1000] completed, Average Training Loss: 1.7135\n",
      "    Validation Batch [1/1], Loss: 1.9157\n",
      "Validation Loss: 1.9157, Validation Accuracy: 62.86%\n",
      "Validation loss improved from 1.9190 to 1.9157. Saving model...\n",
      "\n",
      "LOG: Epoch [95/1000] - Training\n",
      "Epoch [95/1000] completed, Average Training Loss: 1.6752\n",
      "    Validation Batch [1/1], Loss: 1.8952\n",
      "Validation Loss: 1.8952, Validation Accuracy: 61.43%\n",
      "Validation loss improved from 1.9157 to 1.8952. Saving model...\n",
      "\n",
      "LOG: Epoch [96/1000] - Training\n",
      "Epoch [96/1000] completed, Average Training Loss: 1.6801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 1.8849\n",
      "Validation Loss: 1.8849, Validation Accuracy: 64.29%\n",
      "Validation loss improved from 1.8952 to 1.8849. Saving model...\n",
      "\n",
      "LOG: Epoch [97/1000] - Training\n",
      "Epoch [97/1000] completed, Average Training Loss: 1.7047\n",
      "    Validation Batch [1/1], Loss: 1.8763\n",
      "Validation Loss: 1.8763, Validation Accuracy: 64.29%\n",
      "Validation loss improved from 1.8849 to 1.8763. Saving model...\n",
      "\n",
      "LOG: Epoch [98/1000] - Training\n",
      "Epoch [98/1000] completed, Average Training Loss: 1.6559\n",
      "    Validation Batch [1/1], Loss: 1.8500\n",
      "Validation Loss: 1.8500, Validation Accuracy: 64.29%\n",
      "Validation loss improved from 1.8763 to 1.8500. Saving model...\n",
      "\n",
      "LOG: Epoch [99/1000] - Training\n",
      "Epoch [99/1000] completed, Average Training Loss: 1.6598\n",
      "    Validation Batch [1/1], Loss: 1.8173\n",
      "Validation Loss: 1.8173, Validation Accuracy: 68.57%\n",
      "Validation loss improved from 1.8500 to 1.8173. Saving model...\n",
      "\n",
      "LOG: Epoch [100/1000] - Training\n",
      "Epoch [100/1000] completed, Average Training Loss: 1.6350\n",
      "    Validation Batch [1/1], Loss: 1.7948\n",
      "Validation Loss: 1.7948, Validation Accuracy: 71.43%\n",
      "Validation loss improved from 1.8173 to 1.7948. Saving model...\n",
      "\n",
      "LOG: Epoch [101/1000] - Training\n",
      "Epoch [101/1000] completed, Average Training Loss: 1.6351\n",
      "    Validation Batch [1/1], Loss: 1.7921\n",
      "Validation Loss: 1.7921, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.7948 to 1.7921. Saving model...\n",
      "\n",
      "LOG: Epoch [102/1000] - Training\n",
      "Epoch [102/1000] completed, Average Training Loss: 1.6257\n",
      "    Validation Batch [1/1], Loss: 1.7810\n",
      "Validation Loss: 1.7810, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.7921 to 1.7810. Saving model...\n",
      "\n",
      "LOG: Epoch [103/1000] - Training\n",
      "Epoch [103/1000] completed, Average Training Loss: 1.6132\n",
      "    Validation Batch [1/1], Loss: 1.7727\n",
      "Validation Loss: 1.7727, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.7810 to 1.7727. Saving model...\n",
      "\n",
      "LOG: Epoch [104/1000] - Training\n",
      "Epoch [104/1000] completed, Average Training Loss: 1.6115\n",
      "    Validation Batch [1/1], Loss: 1.7516\n",
      "Validation Loss: 1.7516, Validation Accuracy: 68.57%\n",
      "Validation loss improved from 1.7727 to 1.7516. Saving model...\n",
      "\n",
      "LOG: Epoch [105/1000] - Training\n",
      "Epoch [105/1000] completed, Average Training Loss: 1.6346\n",
      "    Validation Batch [1/1], Loss: 1.7351\n",
      "Validation Loss: 1.7351, Validation Accuracy: 67.14%\n",
      "Validation loss improved from 1.7516 to 1.7351. Saving model...\n",
      "\n",
      "LOG: Epoch [106/1000] - Training\n",
      "Epoch [106/1000] completed, Average Training Loss: 1.6080\n",
      "    Validation Batch [1/1], Loss: 1.7308\n",
      "Validation Loss: 1.7308, Validation Accuracy: 68.57%\n",
      "Validation loss improved from 1.7351 to 1.7308. Saving model...\n",
      "\n",
      "LOG: Epoch [107/1000] - Training\n",
      "Epoch [107/1000] completed, Average Training Loss: 1.5789\n",
      "    Validation Batch [1/1], Loss: 1.7325\n",
      "Validation Loss: 1.7325, Validation Accuracy: 68.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [108/1000] - Training\n",
      "Epoch [108/1000] completed, Average Training Loss: 1.5481\n",
      "    Validation Batch [1/1], Loss: 1.7253\n",
      "Validation Loss: 1.7253, Validation Accuracy: 71.43%\n",
      "Validation loss improved from 1.7308 to 1.7253. Saving model...\n",
      "\n",
      "LOG: Epoch [109/1000] - Training\n",
      "Epoch [109/1000] completed, Average Training Loss: 1.5648\n",
      "    Validation Batch [1/1], Loss: 1.6918\n",
      "Validation Loss: 1.6918, Validation Accuracy: 71.43%\n",
      "Validation loss improved from 1.7253 to 1.6918. Saving model...\n",
      "\n",
      "LOG: Epoch [110/1000] - Training\n",
      "Epoch [110/1000] completed, Average Training Loss: 1.5599\n",
      "    Validation Batch [1/1], Loss: 1.6707\n",
      "Validation Loss: 1.6707, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.6918 to 1.6707. Saving model...\n",
      "\n",
      "LOG: Epoch [111/1000] - Training\n",
      "Epoch [111/1000] completed, Average Training Loss: 1.5091\n",
      "    Validation Batch [1/1], Loss: 1.6768\n",
      "Validation Loss: 1.6768, Validation Accuracy: 74.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [112/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [112/1000] completed, Average Training Loss: 1.5405\n",
      "    Validation Batch [1/1], Loss: 1.6957\n",
      "Validation Loss: 1.6957, Validation Accuracy: 74.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [113/1000] - Training\n",
      "Epoch [113/1000] completed, Average Training Loss: 1.5223\n",
      "    Validation Batch [1/1], Loss: 1.6740\n",
      "Validation Loss: 1.6740, Validation Accuracy: 74.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [114/1000] - Training\n",
      "Epoch [114/1000] completed, Average Training Loss: 1.5091\n",
      "    Validation Batch [1/1], Loss: 1.6600\n",
      "Validation Loss: 1.6600, Validation Accuracy: 72.86%\n",
      "Validation loss improved from 1.6707 to 1.6600. Saving model...\n",
      "\n",
      "LOG: Epoch [115/1000] - Training\n",
      "Epoch [115/1000] completed, Average Training Loss: 1.5310\n",
      "    Validation Batch [1/1], Loss: 1.6442\n",
      "Validation Loss: 1.6442, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.6600 to 1.6442. Saving model...\n",
      "\n",
      "LOG: Epoch [116/1000] - Training\n",
      "Epoch [116/1000] completed, Average Training Loss: 1.5016\n",
      "    Validation Batch [1/1], Loss: 1.6382\n",
      "Validation Loss: 1.6382, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.6442 to 1.6382. Saving model...\n",
      "\n",
      "LOG: Epoch [117/1000] - Training\n",
      "Epoch [117/1000] completed, Average Training Loss: 1.4813\n",
      "    Validation Batch [1/1], Loss: 1.6310\n",
      "Validation Loss: 1.6310, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.6382 to 1.6310. Saving model...\n",
      "\n",
      "LOG: Epoch [118/1000] - Training\n",
      "Epoch [118/1000] completed, Average Training Loss: 1.4842\n",
      "    Validation Batch [1/1], Loss: 1.6053\n",
      "Validation Loss: 1.6053, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.6310 to 1.6053. Saving model...\n",
      "\n",
      "LOG: Epoch [119/1000] - Training\n",
      "Epoch [119/1000] completed, Average Training Loss: 1.4832\n",
      "    Validation Batch [1/1], Loss: 1.6104\n",
      "Validation Loss: 1.6104, Validation Accuracy: 75.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [120/1000] - Training\n",
      "Epoch [120/1000] completed, Average Training Loss: 1.4631\n",
      "    Validation Batch [1/1], Loss: 1.5833\n",
      "Validation Loss: 1.5833, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.6053 to 1.5833. Saving model...\n",
      "\n",
      "LOG: Epoch [121/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [121/1000] completed, Average Training Loss: 1.4382\n",
      "    Validation Batch [1/1], Loss: 1.5831\n",
      "Validation Loss: 1.5831, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.5833 to 1.5831. Saving model...\n",
      "\n",
      "LOG: Epoch [122/1000] - Training\n",
      "Epoch [122/1000] completed, Average Training Loss: 1.4726\n",
      "    Validation Batch [1/1], Loss: 1.5661\n",
      "Validation Loss: 1.5661, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.5831 to 1.5661. Saving model...\n",
      "\n",
      "LOG: Epoch [123/1000] - Training\n",
      "Epoch [123/1000] completed, Average Training Loss: 1.4395\n",
      "    Validation Batch [1/1], Loss: 1.5476\n",
      "Validation Loss: 1.5476, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.5661 to 1.5476. Saving model...\n",
      "\n",
      "LOG: Epoch [124/1000] - Training\n",
      "Epoch [124/1000] completed, Average Training Loss: 1.4466\n",
      "    Validation Batch [1/1], Loss: 1.5376\n",
      "Validation Loss: 1.5376, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.5476 to 1.5376. Saving model...\n",
      "\n",
      "LOG: Epoch [125/1000] - Training\n",
      "Epoch [125/1000] completed, Average Training Loss: 1.4019\n",
      "    Validation Batch [1/1], Loss: 1.5425\n",
      "Validation Loss: 1.5425, Validation Accuracy: 77.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [126/1000] - Training\n",
      "Epoch [126/1000] completed, Average Training Loss: 1.3994\n",
      "    Validation Batch [1/1], Loss: 1.5587\n",
      "Validation Loss: 1.5587, Validation Accuracy: 75.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [127/1000] - Training\n",
      "Epoch [127/1000] completed, Average Training Loss: 1.3955\n",
      "    Validation Batch [1/1], Loss: 1.5448\n",
      "Validation Loss: 1.5448, Validation Accuracy: 75.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [128/1000] - Training\n",
      "Epoch [128/1000] completed, Average Training Loss: 1.3631\n",
      "    Validation Batch [1/1], Loss: 1.5269\n",
      "Validation Loss: 1.5269, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.5376 to 1.5269. Saving model...\n",
      "\n",
      "LOG: Epoch [129/1000] - Training\n",
      "Epoch [129/1000] completed, Average Training Loss: 1.3658\n",
      "    Validation Batch [1/1], Loss: 1.5189\n",
      "Validation Loss: 1.5189, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.5269 to 1.5189. Saving model...\n",
      "\n",
      "LOG: Epoch [130/1000] - Training\n",
      "Epoch [130/1000] completed, Average Training Loss: 1.3534\n",
      "    Validation Batch [1/1], Loss: 1.5168\n",
      "Validation Loss: 1.5168, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.5189 to 1.5168. Saving model...\n",
      "\n",
      "LOG: Epoch [131/1000] - Training\n",
      "Epoch [131/1000] completed, Average Training Loss: 1.3369\n",
      "    Validation Batch [1/1], Loss: 1.5000\n",
      "Validation Loss: 1.5000, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.5168 to 1.5000. Saving model...\n",
      "\n",
      "LOG: Epoch [132/1000] - Training\n",
      "Epoch [132/1000] completed, Average Training Loss: 1.3250\n",
      "    Validation Batch [1/1], Loss: 1.4857\n",
      "Validation Loss: 1.4857, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.5000 to 1.4857. Saving model...\n",
      "\n",
      "LOG: Epoch [133/1000] - Training\n",
      "Epoch [133/1000] completed, Average Training Loss: 1.3343\n",
      "    Validation Batch [1/1], Loss: 1.4771\n",
      "Validation Loss: 1.4771, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.4857 to 1.4771. Saving model...\n",
      "\n",
      "LOG: Epoch [134/1000] - Training\n",
      "Epoch [134/1000] completed, Average Training Loss: 1.3270\n",
      "    Validation Batch [1/1], Loss: 1.4702\n",
      "Validation Loss: 1.4702, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.4771 to 1.4702. Saving model...\n",
      "\n",
      "LOG: Epoch [135/1000] - Training\n",
      "Epoch [135/1000] completed, Average Training Loss: 1.3159\n",
      "    Validation Batch [1/1], Loss: 1.4718\n",
      "Validation Loss: 1.4718, Validation Accuracy: 77.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [136/1000] - Training\n",
      "Epoch [136/1000] completed, Average Training Loss: 1.3398\n",
      "    Validation Batch [1/1], Loss: 1.4619\n",
      "Validation Loss: 1.4619, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.4702 to 1.4619. Saving model...\n",
      "\n",
      "LOG: Epoch [137/1000] - Training\n",
      "Epoch [137/1000] completed, Average Training Loss: 1.3208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 1.4491\n",
      "Validation Loss: 1.4491, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.4619 to 1.4491. Saving model...\n",
      "\n",
      "LOG: Epoch [138/1000] - Training\n",
      "Epoch [138/1000] completed, Average Training Loss: 1.2999\n",
      "    Validation Batch [1/1], Loss: 1.4278\n",
      "Validation Loss: 1.4278, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.4491 to 1.4278. Saving model...\n",
      "\n",
      "LOG: Epoch [139/1000] - Training\n",
      "Epoch [139/1000] completed, Average Training Loss: 1.2682\n",
      "    Validation Batch [1/1], Loss: 1.4251\n",
      "Validation Loss: 1.4251, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.4278 to 1.4251. Saving model...\n",
      "\n",
      "LOG: Epoch [140/1000] - Training\n",
      "Epoch [140/1000] completed, Average Training Loss: 1.2807\n",
      "    Validation Batch [1/1], Loss: 1.4401\n",
      "Validation Loss: 1.4401, Validation Accuracy: 74.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [141/1000] - Training\n",
      "Epoch [141/1000] completed, Average Training Loss: 1.2834\n",
      "    Validation Batch [1/1], Loss: 1.4542\n",
      "Validation Loss: 1.4542, Validation Accuracy: 74.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [142/1000] - Training\n",
      "Epoch [142/1000] completed, Average Training Loss: 1.2752\n",
      "    Validation Batch [1/1], Loss: 1.4210\n",
      "Validation Loss: 1.4210, Validation Accuracy: 74.29%\n",
      "Validation loss improved from 1.4251 to 1.4210. Saving model...\n",
      "\n",
      "LOG: Epoch [143/1000] - Training\n",
      "Epoch [143/1000] completed, Average Training Loss: 1.2221\n",
      "    Validation Batch [1/1], Loss: 1.4058\n",
      "Validation Loss: 1.4058, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.4210 to 1.4058. Saving model...\n",
      "\n",
      "LOG: Epoch [144/1000] - Training\n",
      "Epoch [144/1000] completed, Average Training Loss: 1.2500\n",
      "    Validation Batch [1/1], Loss: 1.4002\n",
      "Validation Loss: 1.4002, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.4058 to 1.4002. Saving model...\n",
      "\n",
      "LOG: Epoch [145/1000] - Training\n",
      "Epoch [145/1000] completed, Average Training Loss: 1.2114\n",
      "    Validation Batch [1/1], Loss: 1.3921\n",
      "Validation Loss: 1.3921, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.4002 to 1.3921. Saving model...\n",
      "\n",
      "LOG: Epoch [146/1000] - Training\n",
      "Epoch [146/1000] completed, Average Training Loss: 1.2269\n",
      "    Validation Batch [1/1], Loss: 1.3830\n",
      "Validation Loss: 1.3830, Validation Accuracy: 75.71%\n",
      "Validation loss improved from 1.3921 to 1.3830. Saving model...\n",
      "\n",
      "LOG: Epoch [147/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [147/1000] completed, Average Training Loss: 1.2218\n",
      "    Validation Batch [1/1], Loss: 1.3673\n",
      "Validation Loss: 1.3673, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.3830 to 1.3673. Saving model...\n",
      "\n",
      "LOG: Epoch [148/1000] - Training\n",
      "Epoch [148/1000] completed, Average Training Loss: 1.1960\n",
      "    Validation Batch [1/1], Loss: 1.3579\n",
      "Validation Loss: 1.3579, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.3673 to 1.3579. Saving model...\n",
      "\n",
      "LOG: Epoch [149/1000] - Training\n",
      "Epoch [149/1000] completed, Average Training Loss: 1.2038\n",
      "    Validation Batch [1/1], Loss: 1.3616\n",
      "Validation Loss: 1.3616, Validation Accuracy: 78.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [150/1000] - Training\n",
      "Epoch [150/1000] completed, Average Training Loss: 1.1909\n",
      "    Validation Batch [1/1], Loss: 1.3691\n",
      "Validation Loss: 1.3691, Validation Accuracy: 78.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [151/1000] - Training\n",
      "Epoch [151/1000] completed, Average Training Loss: 1.1675\n",
      "    Validation Batch [1/1], Loss: 1.3665\n",
      "Validation Loss: 1.3665, Validation Accuracy: 80.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [152/1000] - Training\n",
      "Epoch [152/1000] completed, Average Training Loss: 1.2085\n",
      "    Validation Batch [1/1], Loss: 1.3387\n",
      "Validation Loss: 1.3387, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.3579 to 1.3387. Saving model...\n",
      "\n",
      "LOG: Epoch [153/1000] - Training\n",
      "Epoch [153/1000] completed, Average Training Loss: 1.1976\n",
      "    Validation Batch [1/1], Loss: 1.3188\n",
      "Validation Loss: 1.3188, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.3387 to 1.3188. Saving model...\n",
      "\n",
      "LOG: Epoch [154/1000] - Training\n",
      "Epoch [154/1000] completed, Average Training Loss: 1.1915\n",
      "    Validation Batch [1/1], Loss: 1.3183\n",
      "Validation Loss: 1.3183, Validation Accuracy: 78.57%\n",
      "Validation loss improved from 1.3188 to 1.3183. Saving model...\n",
      "\n",
      "LOG: Epoch [155/1000] - Training\n",
      "Epoch [155/1000] completed, Average Training Loss: 1.1292\n",
      "    Validation Batch [1/1], Loss: 1.3138\n",
      "Validation Loss: 1.3138, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.3183 to 1.3138. Saving model...\n",
      "\n",
      "LOG: Epoch [156/1000] - Training\n",
      "Epoch [156/1000] completed, Average Training Loss: 1.1452\n",
      "    Validation Batch [1/1], Loss: 1.3107\n",
      "Validation Loss: 1.3107, Validation Accuracy: 77.14%\n",
      "Validation loss improved from 1.3138 to 1.3107. Saving model...\n",
      "\n",
      "LOG: Epoch [157/1000] - Training\n",
      "Epoch [157/1000] completed, Average Training Loss: 1.1406\n",
      "    Validation Batch [1/1], Loss: 1.3080\n",
      "Validation Loss: 1.3080, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.3107 to 1.3080. Saving model...\n",
      "\n",
      "LOG: Epoch [158/1000] - Training\n",
      "Epoch [158/1000] completed, Average Training Loss: 1.1178\n",
      "    Validation Batch [1/1], Loss: 1.2841\n",
      "Validation Loss: 1.2841, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.3080 to 1.2841. Saving model...\n",
      "\n",
      "LOG: Epoch [159/1000] - Training\n",
      "Epoch [159/1000] completed, Average Training Loss: 1.1035\n",
      "    Validation Batch [1/1], Loss: 1.2861\n",
      "Validation Loss: 1.2861, Validation Accuracy: 78.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [160/1000] - Training\n",
      "Epoch [160/1000] completed, Average Training Loss: 1.1198\n",
      "    Validation Batch [1/1], Loss: 1.2760\n",
      "Validation Loss: 1.2760, Validation Accuracy: 80.00%\n",
      "Validation loss improved from 1.2841 to 1.2760. Saving model...\n",
      "\n",
      "LOG: Epoch [161/1000] - Training\n",
      "Epoch [161/1000] completed, Average Training Loss: 1.0988\n",
      "    Validation Batch [1/1], Loss: 1.2642\n",
      "Validation Loss: 1.2642, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.2760 to 1.2642. Saving model...\n",
      "\n",
      "LOG: Epoch [162/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [162/1000] completed, Average Training Loss: 1.1199\n",
      "    Validation Batch [1/1], Loss: 1.2602\n",
      "Validation Loss: 1.2602, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 1.2642 to 1.2602. Saving model...\n",
      "\n",
      "LOG: Epoch [163/1000] - Training\n",
      "Epoch [163/1000] completed, Average Training Loss: 1.1033\n",
      "    Validation Batch [1/1], Loss: 1.2602\n",
      "Validation Loss: 1.2602, Validation Accuracy: 81.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [164/1000] - Training\n",
      "Epoch [164/1000] completed, Average Training Loss: 1.0823\n",
      "    Validation Batch [1/1], Loss: 1.2641\n",
      "Validation Loss: 1.2641, Validation Accuracy: 81.43%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [165/1000] - Training\n",
      "Epoch [165/1000] completed, Average Training Loss: 1.0618\n",
      "    Validation Batch [1/1], Loss: 1.2337\n",
      "Validation Loss: 1.2337, Validation Accuracy: 81.43%\n",
      "Validation loss improved from 1.2602 to 1.2337. Saving model...\n",
      "\n",
      "LOG: Epoch [166/1000] - Training\n",
      "Epoch [166/1000] completed, Average Training Loss: 1.0589\n",
      "    Validation Batch [1/1], Loss: 1.2152\n",
      "Validation Loss: 1.2152, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.2337 to 1.2152. Saving model...\n",
      "\n",
      "LOG: Epoch [167/1000] - Training\n",
      "Epoch [167/1000] completed, Average Training Loss: 1.0575\n",
      "    Validation Batch [1/1], Loss: 1.2034\n",
      "Validation Loss: 1.2034, Validation Accuracy: 82.86%\n",
      "Validation loss improved from 1.2152 to 1.2034. Saving model...\n",
      "\n",
      "LOG: Epoch [168/1000] - Training\n",
      "Epoch [168/1000] completed, Average Training Loss: 1.0403\n",
      "    Validation Batch [1/1], Loss: 1.2048\n",
      "Validation Loss: 1.2048, Validation Accuracy: 85.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [169/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [169/1000] completed, Average Training Loss: 1.0789\n",
      "    Validation Batch [1/1], Loss: 1.2118\n",
      "Validation Loss: 1.2118, Validation Accuracy: 85.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [170/1000] - Training\n",
      "Epoch [170/1000] completed, Average Training Loss: 1.0169\n",
      "    Validation Batch [1/1], Loss: 1.2135\n",
      "Validation Loss: 1.2135, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [171/1000] - Training\n",
      "Epoch [171/1000] completed, Average Training Loss: 1.0158\n",
      "    Validation Batch [1/1], Loss: 1.1840\n",
      "Validation Loss: 1.1840, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.2034 to 1.1840. Saving model...\n",
      "\n",
      "LOG: Epoch [172/1000] - Training\n",
      "Epoch [172/1000] completed, Average Training Loss: 1.0125\n",
      "    Validation Batch [1/1], Loss: 1.1744\n",
      "Validation Loss: 1.1744, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.1840 to 1.1744. Saving model...\n",
      "\n",
      "LOG: Epoch [173/1000] - Training\n",
      "Epoch [173/1000] completed, Average Training Loss: 1.0258\n",
      "    Validation Batch [1/1], Loss: 1.1682\n",
      "Validation Loss: 1.1682, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.1744 to 1.1682. Saving model...\n",
      "\n",
      "LOG: Epoch [174/1000] - Training\n",
      "Epoch [174/1000] completed, Average Training Loss: 1.0344\n",
      "    Validation Batch [1/1], Loss: 1.1711\n",
      "Validation Loss: 1.1711, Validation Accuracy: 85.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [175/1000] - Training\n",
      "Epoch [175/1000] completed, Average Training Loss: 0.9959\n",
      "    Validation Batch [1/1], Loss: 1.1763\n",
      "Validation Loss: 1.1763, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [176/1000] - Training\n",
      "Epoch [176/1000] completed, Average Training Loss: 0.9967\n",
      "    Validation Batch [1/1], Loss: 1.1757\n",
      "Validation Loss: 1.1757, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [177/1000] - Training\n",
      "Epoch [177/1000] completed, Average Training Loss: 0.9828\n",
      "    Validation Batch [1/1], Loss: 1.1663\n",
      "Validation Loss: 1.1663, Validation Accuracy: 84.29%\n",
      "Validation loss improved from 1.1682 to 1.1663. Saving model...\n",
      "\n",
      "LOG: Epoch [178/1000] - Training\n",
      "Epoch [178/1000] completed, Average Training Loss: 0.9333\n",
      "    Validation Batch [1/1], Loss: 1.1652\n",
      "Validation Loss: 1.1652, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.1663 to 1.1652. Saving model...\n",
      "\n",
      "LOG: Epoch [179/1000] - Training\n",
      "Epoch [179/1000] completed, Average Training Loss: 0.9406\n",
      "    Validation Batch [1/1], Loss: 1.1482\n",
      "Validation Loss: 1.1482, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.1652 to 1.1482. Saving model...\n",
      "\n",
      "LOG: Epoch [180/1000] - Training\n",
      "Epoch [180/1000] completed, Average Training Loss: 0.9566\n",
      "    Validation Batch [1/1], Loss: 1.1268\n",
      "Validation Loss: 1.1268, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.1482 to 1.1268. Saving model...\n",
      "\n",
      "LOG: Epoch [181/1000] - Training\n",
      "Epoch [181/1000] completed, Average Training Loss: 0.9384\n",
      "    Validation Batch [1/1], Loss: 1.1228\n",
      "Validation Loss: 1.1228, Validation Accuracy: 85.71%\n",
      "Validation loss improved from 1.1268 to 1.1228. Saving model...\n",
      "\n",
      "LOG: Epoch [182/1000] - Training\n",
      "Epoch [182/1000] completed, Average Training Loss: 0.9284\n",
      "    Validation Batch [1/1], Loss: 1.1295\n",
      "Validation Loss: 1.1295, Validation Accuracy: 81.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [183/1000] - Training\n",
      "Epoch [183/1000] completed, Average Training Loss: 0.9289\n",
      "    Validation Batch [1/1], Loss: 1.1239\n",
      "Validation Loss: 1.1239, Validation Accuracy: 82.86%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [184/1000] - Training\n",
      "Epoch [184/1000] completed, Average Training Loss: 0.9169\n",
      "    Validation Batch [1/1], Loss: 1.0999\n",
      "Validation Loss: 1.0999, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.1228 to 1.0999. Saving model...\n",
      "\n",
      "LOG: Epoch [185/1000] - Training\n",
      "Epoch [185/1000] completed, Average Training Loss: 0.9447\n",
      "    Validation Batch [1/1], Loss: 1.0779\n",
      "Validation Loss: 1.0779, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.0999 to 1.0779. Saving model...\n",
      "\n",
      "LOG: Epoch [186/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [186/1000] completed, Average Training Loss: 0.9280\n",
      "    Validation Batch [1/1], Loss: 1.0720\n",
      "Validation Loss: 1.0720, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.0779 to 1.0720. Saving model...\n",
      "\n",
      "LOG: Epoch [187/1000] - Training\n",
      "Epoch [187/1000] completed, Average Training Loss: 0.8957\n",
      "    Validation Batch [1/1], Loss: 1.0830\n",
      "Validation Loss: 1.0830, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [188/1000] - Training\n",
      "Epoch [188/1000] completed, Average Training Loss: 0.8976\n",
      "    Validation Batch [1/1], Loss: 1.0846\n",
      "Validation Loss: 1.0846, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [189/1000] - Training\n",
      "Epoch [189/1000] completed, Average Training Loss: 0.8818\n",
      "    Validation Batch [1/1], Loss: 1.0757\n",
      "Validation Loss: 1.0757, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [190/1000] - Training\n",
      "Epoch [190/1000] completed, Average Training Loss: 0.8569\n",
      "    Validation Batch [1/1], Loss: 1.0550\n",
      "Validation Loss: 1.0550, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.0720 to 1.0550. Saving model...\n",
      "\n",
      "LOG: Epoch [191/1000] - Training\n",
      "Epoch [191/1000] completed, Average Training Loss: 0.8528\n",
      "    Validation Batch [1/1], Loss: 1.0543\n",
      "Validation Loss: 1.0543, Validation Accuracy: 87.14%\n",
      "Validation loss improved from 1.0550 to 1.0543. Saving model...\n",
      "\n",
      "LOG: Epoch [192/1000] - Training\n",
      "Epoch [192/1000] completed, Average Training Loss: 0.8859\n",
      "    Validation Batch [1/1], Loss: 1.0498\n",
      "Validation Loss: 1.0498, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.0543 to 1.0498. Saving model...\n",
      "\n",
      "LOG: Epoch [193/1000] - Training\n",
      "Epoch [193/1000] completed, Average Training Loss: 0.8298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 1.0390\n",
      "Validation Loss: 1.0390, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.0498 to 1.0390. Saving model...\n",
      "\n",
      "LOG: Epoch [194/1000] - Training\n",
      "Epoch [194/1000] completed, Average Training Loss: 0.8266\n",
      "    Validation Batch [1/1], Loss: 1.0434\n",
      "Validation Loss: 1.0434, Validation Accuracy: 87.14%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [195/1000] - Training\n",
      "Epoch [195/1000] completed, Average Training Loss: 0.8420\n",
      "    Validation Batch [1/1], Loss: 1.0544\n",
      "Validation Loss: 1.0544, Validation Accuracy: 85.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [196/1000] - Training\n",
      "Epoch [196/1000] completed, Average Training Loss: 0.8257\n",
      "    Validation Batch [1/1], Loss: 1.0668\n",
      "Validation Loss: 1.0668, Validation Accuracy: 85.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [197/1000] - Training\n",
      "Epoch [197/1000] completed, Average Training Loss: 0.8344\n",
      "    Validation Batch [1/1], Loss: 1.0619\n",
      "Validation Loss: 1.0619, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [198/1000] - Training\n",
      "Epoch [198/1000] completed, Average Training Loss: 0.8468\n",
      "    Validation Batch [1/1], Loss: 1.0264\n",
      "Validation Loss: 1.0264, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.0390 to 1.0264. Saving model...\n",
      "\n",
      "LOG: Epoch [199/1000] - Training\n",
      "Epoch [199/1000] completed, Average Training Loss: 0.8304\n",
      "    Validation Batch [1/1], Loss: 0.9969\n",
      "Validation Loss: 0.9969, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 1.0264 to 0.9969. Saving model...\n",
      "\n",
      "LOG: Epoch [200/1000] - Training\n",
      "Epoch [200/1000] completed, Average Training Loss: 0.7992\n",
      "    Validation Batch [1/1], Loss: 0.9865\n",
      "Validation Loss: 0.9865, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 0.9969 to 0.9865. Saving model...\n",
      "\n",
      "LOG: Epoch [201/1000] - Training\n",
      "Epoch [201/1000] completed, Average Training Loss: 0.8067\n",
      "    Validation Batch [1/1], Loss: 0.9831\n",
      "Validation Loss: 0.9831, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.9865 to 0.9831. Saving model...\n",
      "\n",
      "LOG: Epoch [202/1000] - Training\n",
      "Epoch [202/1000] completed, Average Training Loss: 0.8122\n",
      "    Validation Batch [1/1], Loss: 0.9760\n",
      "Validation Loss: 0.9760, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 0.9831 to 0.9760. Saving model...\n",
      "\n",
      "LOG: Epoch [203/1000] - Training\n",
      "Epoch [203/1000] completed, Average Training Loss: 0.7831\n",
      "    Validation Batch [1/1], Loss: 0.9679\n",
      "Validation Loss: 0.9679, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 0.9760 to 0.9679. Saving model...\n",
      "\n",
      "LOG: Epoch [204/1000] - Training\n",
      "Epoch [204/1000] completed, Average Training Loss: 0.7630\n",
      "    Validation Batch [1/1], Loss: 0.9630\n",
      "Validation Loss: 0.9630, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 0.9679 to 0.9630. Saving model...\n",
      "\n",
      "LOG: Epoch [205/1000] - Training\n",
      "Epoch [205/1000] completed, Average Training Loss: 0.7702\n",
      "    Validation Batch [1/1], Loss: 0.9655\n",
      "Validation Loss: 0.9655, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [206/1000] - Training\n",
      "Epoch [206/1000] completed, Average Training Loss: 0.7761\n",
      "    Validation Batch [1/1], Loss: 0.9408\n",
      "Validation Loss: 0.9408, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 0.9630 to 0.9408. Saving model...\n",
      "\n",
      "LOG: Epoch [207/1000] - Training\n",
      "Epoch [207/1000] completed, Average Training Loss: 0.7517\n",
      "    Validation Batch [1/1], Loss: 0.9233\n",
      "Validation Loss: 0.9233, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.9408 to 0.9233. Saving model...\n",
      "\n",
      "LOG: Epoch [208/1000] - Training\n",
      "Epoch [208/1000] completed, Average Training Loss: 0.7207\n",
      "    Validation Batch [1/1], Loss: 0.9280\n",
      "Validation Loss: 0.9280, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [209/1000] - Training\n",
      "Epoch [209/1000] completed, Average Training Loss: 0.7181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.9415\n",
      "Validation Loss: 0.9415, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [210/1000] - Training\n",
      "Epoch [210/1000] completed, Average Training Loss: 0.6889\n",
      "    Validation Batch [1/1], Loss: 0.9197\n",
      "Validation Loss: 0.9197, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 0.9233 to 0.9197. Saving model...\n",
      "\n",
      "LOG: Epoch [211/1000] - Training\n",
      "Epoch [211/1000] completed, Average Training Loss: 0.7003\n",
      "    Validation Batch [1/1], Loss: 0.8977\n",
      "Validation Loss: 0.8977, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.9197 to 0.8977. Saving model...\n",
      "\n",
      "LOG: Epoch [212/1000] - Training\n",
      "Epoch [212/1000] completed, Average Training Loss: 0.7122\n",
      "    Validation Batch [1/1], Loss: 0.9028\n",
      "Validation Loss: 0.9028, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [213/1000] - Training\n",
      "Epoch [213/1000] completed, Average Training Loss: 0.7030\n",
      "    Validation Batch [1/1], Loss: 0.9199\n",
      "Validation Loss: 0.9199, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [214/1000] - Training\n",
      "Epoch [214/1000] completed, Average Training Loss: 0.7639\n",
      "    Validation Batch [1/1], Loss: 0.9169\n",
      "Validation Loss: 0.9169, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [215/1000] - Training\n",
      "Epoch [215/1000] completed, Average Training Loss: 0.7337\n",
      "    Validation Batch [1/1], Loss: 0.9038\n",
      "Validation Loss: 0.9038, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [216/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [216/1000] completed, Average Training Loss: 0.6824\n",
      "    Validation Batch [1/1], Loss: 0.8935\n",
      "Validation Loss: 0.8935, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 0.8977 to 0.8935. Saving model...\n",
      "\n",
      "LOG: Epoch [217/1000] - Training\n",
      "Epoch [217/1000] completed, Average Training Loss: 0.6605\n",
      "    Validation Batch [1/1], Loss: 0.8920\n",
      "Validation Loss: 0.8920, Validation Accuracy: 88.57%\n",
      "Validation loss improved from 0.8935 to 0.8920. Saving model...\n",
      "\n",
      "LOG: Epoch [218/1000] - Training\n",
      "Epoch [218/1000] completed, Average Training Loss: 0.6984\n",
      "    Validation Batch [1/1], Loss: 0.8735\n",
      "Validation Loss: 0.8735, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 0.8920 to 0.8735. Saving model...\n",
      "\n",
      "LOG: Epoch [219/1000] - Training\n",
      "Epoch [219/1000] completed, Average Training Loss: 0.6610\n",
      "    Validation Batch [1/1], Loss: 0.8614\n",
      "Validation Loss: 0.8614, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 0.8735 to 0.8614. Saving model...\n",
      "\n",
      "LOG: Epoch [220/1000] - Training\n",
      "Epoch [220/1000] completed, Average Training Loss: 0.6922\n",
      "    Validation Batch [1/1], Loss: 0.8524\n",
      "Validation Loss: 0.8524, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 0.8614 to 0.8524. Saving model...\n",
      "\n",
      "LOG: Epoch [221/1000] - Training\n",
      "Epoch [221/1000] completed, Average Training Loss: 0.6569\n",
      "    Validation Batch [1/1], Loss: 0.8579\n",
      "Validation Loss: 0.8579, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [222/1000] - Training\n",
      "Epoch [222/1000] completed, Average Training Loss: 0.6263\n",
      "    Validation Batch [1/1], Loss: 0.8665\n",
      "Validation Loss: 0.8665, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [223/1000] - Training\n",
      "Epoch [223/1000] completed, Average Training Loss: 0.6621\n",
      "    Validation Batch [1/1], Loss: 0.8492\n",
      "Validation Loss: 0.8492, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.8524 to 0.8492. Saving model...\n",
      "\n",
      "LOG: Epoch [224/1000] - Training\n",
      "Epoch [224/1000] completed, Average Training Loss: 0.6289\n",
      "    Validation Batch [1/1], Loss: 0.8319\n",
      "Validation Loss: 0.8319, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 0.8492 to 0.8319. Saving model...\n",
      "\n",
      "LOG: Epoch [225/1000] - Training\n",
      "Epoch [225/1000] completed, Average Training Loss: 0.6251\n",
      "    Validation Batch [1/1], Loss: 0.8364\n",
      "Validation Loss: 0.8364, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [226/1000] - Training\n",
      "Epoch [226/1000] completed, Average Training Loss: 0.6514\n",
      "    Validation Batch [1/1], Loss: 0.8254\n",
      "Validation Loss: 0.8254, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 0.8319 to 0.8254. Saving model...\n",
      "\n",
      "LOG: Epoch [227/1000] - Training\n",
      "Epoch [227/1000] completed, Average Training Loss: 0.6204\n",
      "    Validation Batch [1/1], Loss: 0.8201\n",
      "Validation Loss: 0.8201, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 0.8254 to 0.8201. Saving model...\n",
      "\n",
      "LOG: Epoch [228/1000] - Training\n",
      "Epoch [228/1000] completed, Average Training Loss: 0.5884\n",
      "    Validation Batch [1/1], Loss: 0.8103\n",
      "Validation Loss: 0.8103, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.8201 to 0.8103. Saving model...\n",
      "\n",
      "LOG: Epoch [229/1000] - Training\n",
      "Epoch [229/1000] completed, Average Training Loss: 0.5924\n",
      "    Validation Batch [1/1], Loss: 0.8105\n",
      "Validation Loss: 0.8105, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [230/1000] - Training\n",
      "Epoch [230/1000] completed, Average Training Loss: 0.6032\n",
      "    Validation Batch [1/1], Loss: 0.8142\n",
      "Validation Loss: 0.8142, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [231/1000] - Training\n",
      "Epoch [231/1000] completed, Average Training Loss: 0.5921\n",
      "    Validation Batch [1/1], Loss: 0.8137\n",
      "Validation Loss: 0.8137, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [232/1000] - Training\n",
      "Epoch [232/1000] completed, Average Training Loss: 0.5926\n",
      "    Validation Batch [1/1], Loss: 0.8127\n",
      "Validation Loss: 0.8127, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [233/1000] - Training\n",
      "Epoch [233/1000] completed, Average Training Loss: 0.5835\n",
      "    Validation Batch [1/1], Loss: 0.8043\n",
      "Validation Loss: 0.8043, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 0.8103 to 0.8043. Saving model...\n",
      "\n",
      "LOG: Epoch [234/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [234/1000] completed, Average Training Loss: 0.6177\n",
      "    Validation Batch [1/1], Loss: 0.7895\n",
      "Validation Loss: 0.7895, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.8043 to 0.7895. Saving model...\n",
      "\n",
      "LOG: Epoch [235/1000] - Training\n",
      "Epoch [235/1000] completed, Average Training Loss: 0.5955\n",
      "    Validation Batch [1/1], Loss: 0.7808\n",
      "Validation Loss: 0.7808, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.7895 to 0.7808. Saving model...\n",
      "\n",
      "LOG: Epoch [236/1000] - Training\n",
      "Epoch [236/1000] completed, Average Training Loss: 0.5975\n",
      "    Validation Batch [1/1], Loss: 0.7823\n",
      "Validation Loss: 0.7823, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [237/1000] - Training\n",
      "Epoch [237/1000] completed, Average Training Loss: 0.5499\n",
      "    Validation Batch [1/1], Loss: 0.7948\n",
      "Validation Loss: 0.7948, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [238/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [238/1000] completed, Average Training Loss: 0.6025\n",
      "    Validation Batch [1/1], Loss: 0.7894\n",
      "Validation Loss: 0.7894, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [239/1000] - Training\n",
      "Epoch [239/1000] completed, Average Training Loss: 0.5651\n",
      "    Validation Batch [1/1], Loss: 0.7818\n",
      "Validation Loss: 0.7818, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [240/1000] - Training\n",
      "Epoch [240/1000] completed, Average Training Loss: 0.5268\n",
      "    Validation Batch [1/1], Loss: 0.7695\n",
      "Validation Loss: 0.7695, Validation Accuracy: 91.43%\n",
      "Validation loss improved from 0.7808 to 0.7695. Saving model...\n",
      "\n",
      "LOG: Epoch [241/1000] - Training\n",
      "Epoch [241/1000] completed, Average Training Loss: 0.5471\n",
      "    Validation Batch [1/1], Loss: 0.7852\n",
      "Validation Loss: 0.7852, Validation Accuracy: 90.00%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [242/1000] - Training\n",
      "Epoch [242/1000] completed, Average Training Loss: 0.6162\n",
      "    Validation Batch [1/1], Loss: 0.7526\n",
      "Validation Loss: 0.7526, Validation Accuracy: 90.00%\n",
      "Validation loss improved from 0.7695 to 0.7526. Saving model...\n",
      "\n",
      "LOG: Epoch [243/1000] - Training\n",
      "Epoch [243/1000] completed, Average Training Loss: 0.5341\n",
      "    Validation Batch [1/1], Loss: 0.7495\n",
      "Validation Loss: 0.7495, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.7526 to 0.7495. Saving model...\n",
      "\n",
      "LOG: Epoch [244/1000] - Training\n",
      "Epoch [244/1000] completed, Average Training Loss: 0.5024\n",
      "    Validation Batch [1/1], Loss: 0.7390\n",
      "Validation Loss: 0.7390, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.7495 to 0.7390. Saving model...\n",
      "\n",
      "LOG: Epoch [245/1000] - Training\n",
      "Epoch [245/1000] completed, Average Training Loss: 0.5046\n",
      "    Validation Batch [1/1], Loss: 0.7429\n",
      "Validation Loss: 0.7429, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [246/1000] - Training\n",
      "Epoch [246/1000] completed, Average Training Loss: 0.5181\n",
      "    Validation Batch [1/1], Loss: 0.7593\n",
      "Validation Loss: 0.7593, Validation Accuracy: 88.57%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [247/1000] - Training\n",
      "Epoch [247/1000] completed, Average Training Loss: 0.5542\n",
      "    Validation Batch [1/1], Loss: 0.7404\n",
      "Validation Loss: 0.7404, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [248/1000] - Training\n",
      "Epoch [248/1000] completed, Average Training Loss: 0.5026\n",
      "    Validation Batch [1/1], Loss: 0.7268\n",
      "Validation Loss: 0.7268, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.7390 to 0.7268. Saving model...\n",
      "\n",
      "LOG: Epoch [249/1000] - Training\n",
      "Epoch [249/1000] completed, Average Training Loss: 0.4945\n",
      "    Validation Batch [1/1], Loss: 0.7235\n",
      "Validation Loss: 0.7235, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.7268 to 0.7235. Saving model...\n",
      "\n",
      "LOG: Epoch [250/1000] - Training\n",
      "Epoch [250/1000] completed, Average Training Loss: 0.5012\n",
      "    Validation Batch [1/1], Loss: 0.7318\n",
      "Validation Loss: 0.7318, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [251/1000] - Training\n",
      "Epoch [251/1000] completed, Average Training Loss: 0.4854\n",
      "    Validation Batch [1/1], Loss: 0.7272\n",
      "Validation Loss: 0.7272, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [252/1000] - Training\n",
      "Epoch [252/1000] completed, Average Training Loss: 0.4621\n",
      "    Validation Batch [1/1], Loss: 0.7166\n",
      "Validation Loss: 0.7166, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.7235 to 0.7166. Saving model...\n",
      "\n",
      "LOG: Epoch [253/1000] - Training\n",
      "Epoch [253/1000] completed, Average Training Loss: 0.4833\n",
      "    Validation Batch [1/1], Loss: 0.6989\n",
      "Validation Loss: 0.6989, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.7166 to 0.6989. Saving model...\n",
      "\n",
      "LOG: Epoch [254/1000] - Training\n",
      "Epoch [254/1000] completed, Average Training Loss: 0.4988\n",
      "    Validation Batch [1/1], Loss: 0.6892\n",
      "Validation Loss: 0.6892, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.6989 to 0.6892. Saving model...\n",
      "\n",
      "LOG: Epoch [255/1000] - Training\n",
      "Epoch [255/1000] completed, Average Training Loss: 0.4874\n",
      "    Validation Batch [1/1], Loss: 0.6832\n",
      "Validation Loss: 0.6832, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.6892 to 0.6832. Saving model...\n",
      "\n",
      "LOG: Epoch [256/1000] - Training\n",
      "Epoch [256/1000] completed, Average Training Loss: 0.4689\n",
      "    Validation Batch [1/1], Loss: 0.6799\n",
      "Validation Loss: 0.6799, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.6832 to 0.6799. Saving model...\n",
      "\n",
      "LOG: Epoch [257/1000] - Training\n",
      "Epoch [257/1000] completed, Average Training Loss: 0.4573\n",
      "    Validation Batch [1/1], Loss: 0.6849\n",
      "Validation Loss: 0.6849, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [258/1000] - Training\n",
      "Epoch [258/1000] completed, Average Training Loss: 0.4803\n",
      "    Validation Batch [1/1], Loss: 0.6850\n",
      "Validation Loss: 0.6850, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [259/1000] - Training\n",
      "Epoch [259/1000] completed, Average Training Loss: 0.4852\n",
      "    Validation Batch [1/1], Loss: 0.6893\n",
      "Validation Loss: 0.6893, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [260/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [260/1000] completed, Average Training Loss: 0.4437\n",
      "    Validation Batch [1/1], Loss: 0.6755\n",
      "Validation Loss: 0.6755, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.6799 to 0.6755. Saving model...\n",
      "\n",
      "LOG: Epoch [261/1000] - Training\n",
      "Epoch [261/1000] completed, Average Training Loss: 0.4482\n",
      "    Validation Batch [1/1], Loss: 0.6565\n",
      "Validation Loss: 0.6565, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.6755 to 0.6565. Saving model...\n",
      "\n",
      "LOG: Epoch [262/1000] - Training\n",
      "Epoch [262/1000] completed, Average Training Loss: 0.4298\n",
      "    Validation Batch [1/1], Loss: 0.6451\n",
      "Validation Loss: 0.6451, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.6565 to 0.6451. Saving model...\n",
      "\n",
      "LOG: Epoch [263/1000] - Training\n",
      "Epoch [263/1000] completed, Average Training Loss: 0.4196\n",
      "    Validation Batch [1/1], Loss: 0.6383\n",
      "Validation Loss: 0.6383, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.6451 to 0.6383. Saving model...\n",
      "\n",
      "LOG: Epoch [264/1000] - Training\n",
      "Epoch [264/1000] completed, Average Training Loss: 0.4117\n",
      "    Validation Batch [1/1], Loss: 0.6390\n",
      "Validation Loss: 0.6390, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [265/1000] - Training\n",
      "Epoch [265/1000] completed, Average Training Loss: 0.4371\n",
      "    Validation Batch [1/1], Loss: 0.6345\n",
      "Validation Loss: 0.6345, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.6383 to 0.6345. Saving model...\n",
      "\n",
      "LOG: Epoch [266/1000] - Training\n",
      "Epoch [266/1000] completed, Average Training Loss: 0.4507\n",
      "    Validation Batch [1/1], Loss: 0.6329\n",
      "Validation Loss: 0.6329, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.6345 to 0.6329. Saving model...\n",
      "\n",
      "LOG: Epoch [267/1000] - Training\n",
      "Epoch [267/1000] completed, Average Training Loss: 0.4320\n",
      "    Validation Batch [1/1], Loss: 0.6235\n",
      "Validation Loss: 0.6235, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.6329 to 0.6235. Saving model...\n",
      "\n",
      "LOG: Epoch [268/1000] - Training\n",
      "Epoch [268/1000] completed, Average Training Loss: 0.4144\n",
      "    Validation Batch [1/1], Loss: 0.6274\n",
      "Validation Loss: 0.6274, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [269/1000] - Training\n",
      "Epoch [269/1000] completed, Average Training Loss: 0.4309\n",
      "    Validation Batch [1/1], Loss: 0.6192\n",
      "Validation Loss: 0.6192, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.6235 to 0.6192. Saving model...\n",
      "\n",
      "LOG: Epoch [270/1000] - Training\n",
      "Epoch [270/1000] completed, Average Training Loss: 0.4124\n",
      "    Validation Batch [1/1], Loss: 0.6123\n",
      "Validation Loss: 0.6123, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.6192 to 0.6123. Saving model...\n",
      "\n",
      "LOG: Epoch [271/1000] - Training\n",
      "Epoch [271/1000] completed, Average Training Loss: 0.3934\n",
      "    Validation Batch [1/1], Loss: 0.6091\n",
      "Validation Loss: 0.6091, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.6123 to 0.6091. Saving model...\n",
      "\n",
      "LOG: Epoch [272/1000] - Training\n",
      "Epoch [272/1000] completed, Average Training Loss: 0.3844\n",
      "    Validation Batch [1/1], Loss: 0.6150\n",
      "Validation Loss: 0.6150, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [273/1000] - Training\n",
      "Epoch [273/1000] completed, Average Training Loss: 0.4222\n",
      "    Validation Batch [1/1], Loss: 0.6173\n",
      "Validation Loss: 0.6173, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [274/1000] - Training\n",
      "Epoch [274/1000] completed, Average Training Loss: 0.4357\n",
      "    Validation Batch [1/1], Loss: 0.6146\n",
      "Validation Loss: 0.6146, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [275/1000] - Training\n",
      "Epoch [275/1000] completed, Average Training Loss: 0.3709\n",
      "    Validation Batch [1/1], Loss: 0.5969\n",
      "Validation Loss: 0.5969, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.6091 to 0.5969. Saving model...\n",
      "\n",
      "LOG: Epoch [276/1000] - Training\n",
      "Epoch [276/1000] completed, Average Training Loss: 0.3939\n",
      "    Validation Batch [1/1], Loss: 0.5792\n",
      "Validation Loss: 0.5792, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.5969 to 0.5792. Saving model...\n",
      "\n",
      "LOG: Epoch [277/1000] - Training\n",
      "Epoch [277/1000] completed, Average Training Loss: 0.3738\n",
      "    Validation Batch [1/1], Loss: 0.5764\n",
      "Validation Loss: 0.5764, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.5792 to 0.5764. Saving model...\n",
      "\n",
      "LOG: Epoch [278/1000] - Training\n",
      "Epoch [278/1000] completed, Average Training Loss: 0.4031\n",
      "    Validation Batch [1/1], Loss: 0.5771\n",
      "Validation Loss: 0.5771, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [279/1000] - Training\n",
      "Epoch [279/1000] completed, Average Training Loss: 0.3706\n",
      "    Validation Batch [1/1], Loss: 0.5802\n",
      "Validation Loss: 0.5802, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [280/1000] - Training\n",
      "Epoch [280/1000] completed, Average Training Loss: 0.3903\n",
      "    Validation Batch [1/1], Loss: 0.5788\n",
      "Validation Loss: 0.5788, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [281/1000] - Training\n",
      "Epoch [281/1000] completed, Average Training Loss: 0.4048\n",
      "    Validation Batch [1/1], Loss: 0.5683\n",
      "Validation Loss: 0.5683, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.5764 to 0.5683. Saving model...\n",
      "\n",
      "LOG: Epoch [282/1000] - Training\n",
      "Epoch [282/1000] completed, Average Training Loss: 0.4011\n",
      "    Validation Batch [1/1], Loss: 0.5632\n",
      "Validation Loss: 0.5632, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.5683 to 0.5632. Saving model...\n",
      "\n",
      "LOG: Epoch [283/1000] - Training\n",
      "Epoch [283/1000] completed, Average Training Loss: 0.3571\n",
      "    Validation Batch [1/1], Loss: 0.5625\n",
      "Validation Loss: 0.5625, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.5632 to 0.5625. Saving model...\n",
      "\n",
      "LOG: Epoch [284/1000] - Training\n",
      "Epoch [284/1000] completed, Average Training Loss: 0.3203\n",
      "    Validation Batch [1/1], Loss: 0.5604\n",
      "Validation Loss: 0.5604, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.5625 to 0.5604. Saving model...\n",
      "\n",
      "LOG: Epoch [285/1000] - Training\n",
      "Epoch [285/1000] completed, Average Training Loss: 0.3745\n",
      "    Validation Batch [1/1], Loss: 0.5633\n",
      "Validation Loss: 0.5633, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [286/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [286/1000] completed, Average Training Loss: 0.3857\n",
      "    Validation Batch [1/1], Loss: 0.5790\n",
      "Validation Loss: 0.5790, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [287/1000] - Training\n",
      "Epoch [287/1000] completed, Average Training Loss: 0.3233\n",
      "    Validation Batch [1/1], Loss: 0.5882\n",
      "Validation Loss: 0.5882, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [288/1000] - Training\n",
      "Epoch [288/1000] completed, Average Training Loss: 0.3451\n",
      "    Validation Batch [1/1], Loss: 0.5747\n",
      "Validation Loss: 0.5747, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [289/1000] - Training\n",
      "Epoch [289/1000] completed, Average Training Loss: 0.3564\n",
      "    Validation Batch [1/1], Loss: 0.5683\n",
      "Validation Loss: 0.5683, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [290/1000] - Training\n",
      "Epoch [290/1000] completed, Average Training Loss: 0.3544\n",
      "    Validation Batch [1/1], Loss: 0.5672\n",
      "Validation Loss: 0.5672, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [291/1000] - Training\n",
      "Epoch [291/1000] completed, Average Training Loss: 0.3495\n",
      "    Validation Batch [1/1], Loss: 0.5549\n",
      "Validation Loss: 0.5549, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.5604 to 0.5549. Saving model...\n",
      "\n",
      "LOG: Epoch [292/1000] - Training\n",
      "Epoch [292/1000] completed, Average Training Loss: 0.3497\n",
      "    Validation Batch [1/1], Loss: 0.5515\n",
      "Validation Loss: 0.5515, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.5549 to 0.5515. Saving model...\n",
      "\n",
      "LOG: Epoch [293/1000] - Training\n",
      "Epoch [293/1000] completed, Average Training Loss: 0.3198\n",
      "    Validation Batch [1/1], Loss: 0.5496\n",
      "Validation Loss: 0.5496, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.5515 to 0.5496. Saving model...\n",
      "\n",
      "LOG: Epoch [294/1000] - Training\n",
      "Epoch [294/1000] completed, Average Training Loss: 0.3412\n",
      "    Validation Batch [1/1], Loss: 0.5232\n",
      "Validation Loss: 0.5232, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.5496 to 0.5232. Saving model...\n",
      "\n",
      "LOG: Epoch [295/1000] - Training\n",
      "Epoch [295/1000] completed, Average Training Loss: 0.3595\n",
      "    Validation Batch [1/1], Loss: 0.5174\n",
      "Validation Loss: 0.5174, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.5232 to 0.5174. Saving model...\n",
      "\n",
      "LOG: Epoch [296/1000] - Training\n",
      "Epoch [296/1000] completed, Average Training Loss: 0.3442\n",
      "    Validation Batch [1/1], Loss: 0.5334\n",
      "Validation Loss: 0.5334, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [297/1000] - Training\n",
      "Epoch [297/1000] completed, Average Training Loss: 0.3157\n",
      "    Validation Batch [1/1], Loss: 0.5335\n",
      "Validation Loss: 0.5335, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [298/1000] - Training\n",
      "Epoch [298/1000] completed, Average Training Loss: 0.3338\n",
      "    Validation Batch [1/1], Loss: 0.5411\n",
      "Validation Loss: 0.5411, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [299/1000] - Training\n",
      "Epoch [299/1000] completed, Average Training Loss: 0.2871\n",
      "    Validation Batch [1/1], Loss: 0.5497\n",
      "Validation Loss: 0.5497, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [300/1000] - Training\n",
      "Epoch [300/1000] completed, Average Training Loss: 0.2892\n",
      "    Validation Batch [1/1], Loss: 0.5324\n",
      "Validation Loss: 0.5324, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [301/1000] - Training\n",
      "Epoch [301/1000] completed, Average Training Loss: 0.3367\n",
      "    Validation Batch [1/1], Loss: 0.5105\n",
      "Validation Loss: 0.5105, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.5174 to 0.5105. Saving model...\n",
      "\n",
      "LOG: Epoch [302/1000] - Training\n",
      "Epoch [302/1000] completed, Average Training Loss: 0.3023\n",
      "    Validation Batch [1/1], Loss: 0.4972\n",
      "Validation Loss: 0.4972, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.5105 to 0.4972. Saving model...\n",
      "\n",
      "LOG: Epoch [303/1000] - Training\n",
      "Epoch [303/1000] completed, Average Training Loss: 0.3004\n",
      "    Validation Batch [1/1], Loss: 0.4906\n",
      "Validation Loss: 0.4906, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.4972 to 0.4906. Saving model...\n",
      "\n",
      "LOG: Epoch [304/1000] - Training\n",
      "Epoch [304/1000] completed, Average Training Loss: 0.3097\n",
      "    Validation Batch [1/1], Loss: 0.4917\n",
      "Validation Loss: 0.4917, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [305/1000] - Training\n",
      "Epoch [305/1000] completed, Average Training Loss: 0.3018\n",
      "    Validation Batch [1/1], Loss: 0.4965\n",
      "Validation Loss: 0.4965, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [306/1000] - Training\n",
      "Epoch [306/1000] completed, Average Training Loss: 0.3125\n",
      "    Validation Batch [1/1], Loss: 0.4994\n",
      "Validation Loss: 0.4994, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [307/1000] - Training\n",
      "Epoch [307/1000] completed, Average Training Loss: 0.2991\n",
      "    Validation Batch [1/1], Loss: 0.4962\n",
      "Validation Loss: 0.4962, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [308/1000] - Training\n",
      "Epoch [308/1000] completed, Average Training Loss: 0.3092\n",
      "    Validation Batch [1/1], Loss: 0.4854\n",
      "Validation Loss: 0.4854, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.4906 to 0.4854. Saving model...\n",
      "\n",
      "LOG: Epoch [309/1000] - Training\n",
      "Epoch [309/1000] completed, Average Training Loss: 0.2745\n",
      "    Validation Batch [1/1], Loss: 0.4761\n",
      "Validation Loss: 0.4761, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.4854 to 0.4761. Saving model...\n",
      "\n",
      "LOG: Epoch [310/1000] - Training\n",
      "Epoch [310/1000] completed, Average Training Loss: 0.3033\n",
      "    Validation Batch [1/1], Loss: 0.4690\n",
      "Validation Loss: 0.4690, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.4761 to 0.4690. Saving model...\n",
      "\n",
      "LOG: Epoch [311/1000] - Training\n",
      "Epoch [311/1000] completed, Average Training Loss: 0.2662\n",
      "    Validation Batch [1/1], Loss: 0.4746\n",
      "Validation Loss: 0.4746, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [312/1000] - Training\n",
      "Epoch [312/1000] completed, Average Training Loss: 0.2556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.4838\n",
      "Validation Loss: 0.4838, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [313/1000] - Training\n",
      "Epoch [313/1000] completed, Average Training Loss: 0.2698\n",
      "    Validation Batch [1/1], Loss: 0.4837\n",
      "Validation Loss: 0.4837, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [314/1000] - Training\n",
      "Epoch [314/1000] completed, Average Training Loss: 0.3004\n",
      "    Validation Batch [1/1], Loss: 0.4839\n",
      "Validation Loss: 0.4839, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [315/1000] - Training\n",
      "Epoch [315/1000] completed, Average Training Loss: 0.2765\n",
      "    Validation Batch [1/1], Loss: 0.4774\n",
      "Validation Loss: 0.4774, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [316/1000] - Training\n",
      "Epoch [316/1000] completed, Average Training Loss: 0.2416\n",
      "    Validation Batch [1/1], Loss: 0.4783\n",
      "Validation Loss: 0.4783, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [317/1000] - Training\n",
      "Epoch [317/1000] completed, Average Training Loss: 0.2484\n",
      "    Validation Batch [1/1], Loss: 0.4701\n",
      "Validation Loss: 0.4701, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [318/1000] - Training\n",
      "Epoch [318/1000] completed, Average Training Loss: 0.2720\n",
      "    Validation Batch [1/1], Loss: 0.4662\n",
      "Validation Loss: 0.4662, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.4690 to 0.4662. Saving model...\n",
      "\n",
      "LOG: Epoch [319/1000] - Training\n",
      "Epoch [319/1000] completed, Average Training Loss: 0.2667\n",
      "    Validation Batch [1/1], Loss: 0.4583\n",
      "Validation Loss: 0.4583, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.4662 to 0.4583. Saving model...\n",
      "\n",
      "LOG: Epoch [320/1000] - Training\n",
      "Epoch [320/1000] completed, Average Training Loss: 0.2802\n",
      "    Validation Batch [1/1], Loss: 0.4475\n",
      "Validation Loss: 0.4475, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.4583 to 0.4475. Saving model...\n",
      "\n",
      "LOG: Epoch [321/1000] - Training\n",
      "Epoch [321/1000] completed, Average Training Loss: 0.2345\n",
      "    Validation Batch [1/1], Loss: 0.4381\n",
      "Validation Loss: 0.4381, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.4475 to 0.4381. Saving model...\n",
      "\n",
      "LOG: Epoch [322/1000] - Training\n",
      "Epoch [322/1000] completed, Average Training Loss: 0.2546\n",
      "    Validation Batch [1/1], Loss: 0.4333\n",
      "Validation Loss: 0.4333, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.4381 to 0.4333. Saving model...\n",
      "\n",
      "LOG: Epoch [323/1000] - Training\n",
      "Epoch [323/1000] completed, Average Training Loss: 0.2460\n",
      "    Validation Batch [1/1], Loss: 0.4359\n",
      "Validation Loss: 0.4359, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [324/1000] - Training\n",
      "Epoch [324/1000] completed, Average Training Loss: 0.2369\n",
      "    Validation Batch [1/1], Loss: 0.4494\n",
      "Validation Loss: 0.4494, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [325/1000] - Training\n",
      "Epoch [325/1000] completed, Average Training Loss: 0.2665\n",
      "    Validation Batch [1/1], Loss: 0.4640\n",
      "Validation Loss: 0.4640, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [326/1000] - Training\n",
      "Epoch [326/1000] completed, Average Training Loss: 0.2793\n",
      "    Validation Batch [1/1], Loss: 0.4540\n",
      "Validation Loss: 0.4540, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [327/1000] - Training\n",
      "Epoch [327/1000] completed, Average Training Loss: 0.2428\n",
      "    Validation Batch [1/1], Loss: 0.4439\n",
      "Validation Loss: 0.4439, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [328/1000] - Training\n",
      "Epoch [328/1000] completed, Average Training Loss: 0.2304\n",
      "    Validation Batch [1/1], Loss: 0.4371\n",
      "Validation Loss: 0.4371, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [329/1000] - Training\n",
      "Epoch [329/1000] completed, Average Training Loss: 0.2328\n",
      "    Validation Batch [1/1], Loss: 0.4389\n",
      "Validation Loss: 0.4389, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [330/1000] - Training\n",
      "Epoch [330/1000] completed, Average Training Loss: 0.2322\n",
      "    Validation Batch [1/1], Loss: 0.4417\n",
      "Validation Loss: 0.4417, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [331/1000] - Training\n",
      "Epoch [331/1000] completed, Average Training Loss: 0.2279\n",
      "    Validation Batch [1/1], Loss: 0.4386\n",
      "Validation Loss: 0.4386, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [332/1000] - Training\n",
      "Epoch [332/1000] completed, Average Training Loss: 0.2667\n",
      "    Validation Batch [1/1], Loss: 0.4364\n",
      "Validation Loss: 0.4364, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [333/1000] - Training\n",
      "Epoch [333/1000] completed, Average Training Loss: 0.2397\n",
      "    Validation Batch [1/1], Loss: 0.4320\n",
      "Validation Loss: 0.4320, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.4333 to 0.4320. Saving model...\n",
      "\n",
      "LOG: Epoch [334/1000] - Training\n",
      "Epoch [334/1000] completed, Average Training Loss: 0.2693\n",
      "    Validation Batch [1/1], Loss: 0.4263\n",
      "Validation Loss: 0.4263, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.4320 to 0.4263. Saving model...\n",
      "\n",
      "LOG: Epoch [335/1000] - Training\n",
      "Epoch [335/1000] completed, Average Training Loss: 0.2344\n",
      "    Validation Batch [1/1], Loss: 0.4177\n",
      "Validation Loss: 0.4177, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.4263 to 0.4177. Saving model...\n",
      "\n",
      "LOG: Epoch [336/1000] - Training\n",
      "Epoch [336/1000] completed, Average Training Loss: 0.1973\n",
      "    Validation Batch [1/1], Loss: 0.4160\n",
      "Validation Loss: 0.4160, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.4177 to 0.4160. Saving model...\n",
      "\n",
      "LOG: Epoch [337/1000] - Training\n",
      "Epoch [337/1000] completed, Average Training Loss: 0.2301\n",
      "    Validation Batch [1/1], Loss: 0.4113\n",
      "Validation Loss: 0.4113, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.4160 to 0.4113. Saving model...\n",
      "\n",
      "LOG: Epoch [338/1000] - Training\n",
      "Epoch [338/1000] completed, Average Training Loss: 0.2062\n",
      "    Validation Batch [1/1], Loss: 0.4316\n",
      "Validation Loss: 0.4316, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [339/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [339/1000] completed, Average Training Loss: 0.2271\n",
      "    Validation Batch [1/1], Loss: 0.4361\n",
      "Validation Loss: 0.4361, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [340/1000] - Training\n",
      "Epoch [340/1000] completed, Average Training Loss: 0.2247\n",
      "    Validation Batch [1/1], Loss: 0.4229\n",
      "Validation Loss: 0.4229, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [341/1000] - Training\n",
      "Epoch [341/1000] completed, Average Training Loss: 0.2103\n",
      "    Validation Batch [1/1], Loss: 0.4155\n",
      "Validation Loss: 0.4155, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [342/1000] - Training\n",
      "Epoch [342/1000] completed, Average Training Loss: 0.2107\n",
      "    Validation Batch [1/1], Loss: 0.4095\n",
      "Validation Loss: 0.4095, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.4113 to 0.4095. Saving model...\n",
      "\n",
      "LOG: Epoch [343/1000] - Training\n",
      "Epoch [343/1000] completed, Average Training Loss: 0.2013\n",
      "    Validation Batch [1/1], Loss: 0.4048\n",
      "Validation Loss: 0.4048, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.4095 to 0.4048. Saving model...\n",
      "\n",
      "LOG: Epoch [344/1000] - Training\n",
      "Epoch [344/1000] completed, Average Training Loss: 0.2163\n",
      "    Validation Batch [1/1], Loss: 0.4052\n",
      "Validation Loss: 0.4052, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [345/1000] - Training\n",
      "Epoch [345/1000] completed, Average Training Loss: 0.2112\n",
      "    Validation Batch [1/1], Loss: 0.4153\n",
      "Validation Loss: 0.4153, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [346/1000] - Training\n",
      "Epoch [346/1000] completed, Average Training Loss: 0.2353\n",
      "    Validation Batch [1/1], Loss: 0.3992\n",
      "Validation Loss: 0.3992, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.4048 to 0.3992. Saving model...\n",
      "\n",
      "LOG: Epoch [347/1000] - Training\n",
      "Epoch [347/1000] completed, Average Training Loss: 0.2308\n",
      "    Validation Batch [1/1], Loss: 0.3899\n",
      "Validation Loss: 0.3899, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.3992 to 0.3899. Saving model...\n",
      "\n",
      "LOG: Epoch [348/1000] - Training\n",
      "Epoch [348/1000] completed, Average Training Loss: 0.2010\n",
      "    Validation Batch [1/1], Loss: 0.3851\n",
      "Validation Loss: 0.3851, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.3899 to 0.3851. Saving model...\n",
      "\n",
      "LOG: Epoch [349/1000] - Training\n",
      "Epoch [349/1000] completed, Average Training Loss: 0.1727\n",
      "    Validation Batch [1/1], Loss: 0.3796\n",
      "Validation Loss: 0.3796, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.3851 to 0.3796. Saving model...\n",
      "\n",
      "LOG: Epoch [350/1000] - Training\n",
      "Epoch [350/1000] completed, Average Training Loss: 0.1925\n",
      "    Validation Batch [1/1], Loss: 0.3884\n",
      "Validation Loss: 0.3884, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [351/1000] - Training\n",
      "Epoch [351/1000] completed, Average Training Loss: 0.2065\n",
      "    Validation Batch [1/1], Loss: 0.4191\n",
      "Validation Loss: 0.4191, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [352/1000] - Training\n",
      "Epoch [352/1000] completed, Average Training Loss: 0.2051\n",
      "    Validation Batch [1/1], Loss: 0.4289\n",
      "Validation Loss: 0.4289, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [353/1000] - Training\n",
      "Epoch [353/1000] completed, Average Training Loss: 0.2186\n",
      "    Validation Batch [1/1], Loss: 0.4164\n",
      "Validation Loss: 0.4164, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [354/1000] - Training\n",
      "Epoch [354/1000] completed, Average Training Loss: 0.1718\n",
      "    Validation Batch [1/1], Loss: 0.4060\n",
      "Validation Loss: 0.4060, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [355/1000] - Training\n",
      "Epoch [355/1000] completed, Average Training Loss: 0.1789\n",
      "    Validation Batch [1/1], Loss: 0.4114\n",
      "Validation Loss: 0.4114, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [356/1000] - Training\n",
      "Epoch [356/1000] completed, Average Training Loss: 0.1862\n",
      "    Validation Batch [1/1], Loss: 0.4112\n",
      "Validation Loss: 0.4112, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [357/1000] - Training\n",
      "Epoch [357/1000] completed, Average Training Loss: 0.2063\n",
      "    Validation Batch [1/1], Loss: 0.3903\n",
      "Validation Loss: 0.3903, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [358/1000] - Training\n",
      "Epoch [358/1000] completed, Average Training Loss: 0.1850\n",
      "    Validation Batch [1/1], Loss: 0.3663\n",
      "Validation Loss: 0.3663, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.3796 to 0.3663. Saving model...\n",
      "\n",
      "LOG: Epoch [359/1000] - Training\n",
      "Epoch [359/1000] completed, Average Training Loss: 0.2023\n",
      "    Validation Batch [1/1], Loss: 0.3771\n",
      "Validation Loss: 0.3771, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [360/1000] - Training\n",
      "Epoch [360/1000] completed, Average Training Loss: 0.1897\n",
      "    Validation Batch [1/1], Loss: 0.3849\n",
      "Validation Loss: 0.3849, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [361/1000] - Training\n",
      "Epoch [361/1000] completed, Average Training Loss: 0.1764\n",
      "    Validation Batch [1/1], Loss: 0.3765\n",
      "Validation Loss: 0.3765, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [362/1000] - Training\n",
      "Epoch [362/1000] completed, Average Training Loss: 0.1875\n",
      "    Validation Batch [1/1], Loss: 0.3852\n",
      "Validation Loss: 0.3852, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [363/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [363/1000] completed, Average Training Loss: 0.1782\n",
      "    Validation Batch [1/1], Loss: 0.3997\n",
      "Validation Loss: 0.3997, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [364/1000] - Training\n",
      "Epoch [364/1000] completed, Average Training Loss: 0.1815\n",
      "    Validation Batch [1/1], Loss: 0.3942\n",
      "Validation Loss: 0.3942, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [365/1000] - Training\n",
      "Epoch [365/1000] completed, Average Training Loss: 0.1844\n",
      "    Validation Batch [1/1], Loss: 0.3760\n",
      "Validation Loss: 0.3760, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [366/1000] - Training\n",
      "Epoch [366/1000] completed, Average Training Loss: 0.1764\n",
      "    Validation Batch [1/1], Loss: 0.3718\n",
      "Validation Loss: 0.3718, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [367/1000] - Training\n",
      "Epoch [367/1000] completed, Average Training Loss: 0.1661\n",
      "    Validation Batch [1/1], Loss: 0.3890\n",
      "Validation Loss: 0.3890, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [368/1000] - Training\n",
      "Epoch [368/1000] completed, Average Training Loss: 0.1772\n",
      "    Validation Batch [1/1], Loss: 0.3894\n",
      "Validation Loss: 0.3894, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [369/1000] - Training\n",
      "Epoch [369/1000] completed, Average Training Loss: 0.1731\n",
      "    Validation Batch [1/1], Loss: 0.3858\n",
      "Validation Loss: 0.3858, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [370/1000] - Training\n",
      "Epoch [370/1000] completed, Average Training Loss: 0.1642\n",
      "    Validation Batch [1/1], Loss: 0.3770\n",
      "Validation Loss: 0.3770, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [371/1000] - Training\n",
      "Epoch [371/1000] completed, Average Training Loss: 0.1566\n",
      "    Validation Batch [1/1], Loss: 0.3555\n",
      "Validation Loss: 0.3555, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.3663 to 0.3555. Saving model...\n",
      "\n",
      "LOG: Epoch [372/1000] - Training\n",
      "Epoch [372/1000] completed, Average Training Loss: 0.1727\n",
      "    Validation Batch [1/1], Loss: 0.3420\n",
      "Validation Loss: 0.3420, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.3555 to 0.3420. Saving model...\n",
      "\n",
      "LOG: Epoch [373/1000] - Training\n",
      "Epoch [373/1000] completed, Average Training Loss: 0.1978\n",
      "    Validation Batch [1/1], Loss: 0.3437\n",
      "Validation Loss: 0.3437, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [374/1000] - Training\n",
      "Epoch [374/1000] completed, Average Training Loss: 0.1742\n",
      "    Validation Batch [1/1], Loss: 0.3570\n",
      "Validation Loss: 0.3570, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [375/1000] - Training\n",
      "Epoch [375/1000] completed, Average Training Loss: 0.1657\n",
      "    Validation Batch [1/1], Loss: 0.3684\n",
      "Validation Loss: 0.3684, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [376/1000] - Training\n",
      "Epoch [376/1000] completed, Average Training Loss: 0.1478\n",
      "    Validation Batch [1/1], Loss: 0.3666\n",
      "Validation Loss: 0.3666, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [377/1000] - Training\n",
      "Epoch [377/1000] completed, Average Training Loss: 0.1723\n",
      "    Validation Batch [1/1], Loss: 0.3588\n",
      "Validation Loss: 0.3588, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [378/1000] - Training\n",
      "Epoch [378/1000] completed, Average Training Loss: 0.1625\n",
      "    Validation Batch [1/1], Loss: 0.3502\n",
      "Validation Loss: 0.3502, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [379/1000] - Training\n",
      "Epoch [379/1000] completed, Average Training Loss: 0.1581\n",
      "    Validation Batch [1/1], Loss: 0.3389\n",
      "Validation Loss: 0.3389, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.3420 to 0.3389. Saving model...\n",
      "\n",
      "LOG: Epoch [380/1000] - Training\n",
      "Epoch [380/1000] completed, Average Training Loss: 0.1830\n",
      "    Validation Batch [1/1], Loss: 0.3388\n",
      "Validation Loss: 0.3388, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.3389 to 0.3388. Saving model...\n",
      "\n",
      "LOG: Epoch [381/1000] - Training\n",
      "Epoch [381/1000] completed, Average Training Loss: 0.1491\n",
      "    Validation Batch [1/1], Loss: 0.3495\n",
      "Validation Loss: 0.3495, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [382/1000] - Training\n",
      "Epoch [382/1000] completed, Average Training Loss: 0.1534\n",
      "    Validation Batch [1/1], Loss: 0.3545\n",
      "Validation Loss: 0.3545, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [383/1000] - Training\n",
      "Epoch [383/1000] completed, Average Training Loss: 0.1587\n",
      "    Validation Batch [1/1], Loss: 0.3485\n",
      "Validation Loss: 0.3485, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [384/1000] - Training\n",
      "Epoch [384/1000] completed, Average Training Loss: 0.1687\n",
      "    Validation Batch [1/1], Loss: 0.3433\n",
      "Validation Loss: 0.3433, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [385/1000] - Training\n",
      "Epoch [385/1000] completed, Average Training Loss: 0.1712\n",
      "    Validation Batch [1/1], Loss: 0.3456\n",
      "Validation Loss: 0.3456, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [386/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [386/1000] completed, Average Training Loss: 0.1678\n",
      "    Validation Batch [1/1], Loss: 0.3565\n",
      "Validation Loss: 0.3565, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [387/1000] - Training\n",
      "Epoch [387/1000] completed, Average Training Loss: 0.1333\n",
      "    Validation Batch [1/1], Loss: 0.3731\n",
      "Validation Loss: 0.3731, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [388/1000] - Training\n",
      "Epoch [388/1000] completed, Average Training Loss: 0.1634\n",
      "    Validation Batch [1/1], Loss: 0.3738\n",
      "Validation Loss: 0.3738, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [389/1000] - Training\n",
      "Epoch [389/1000] completed, Average Training Loss: 0.1500\n",
      "    Validation Batch [1/1], Loss: 0.3453\n",
      "Validation Loss: 0.3453, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [390/1000] - Training\n",
      "Epoch [390/1000] completed, Average Training Loss: 0.1606\n",
      "    Validation Batch [1/1], Loss: 0.3228\n",
      "Validation Loss: 0.3228, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.3388 to 0.3228. Saving model...\n",
      "\n",
      "LOG: Epoch [391/1000] - Training\n",
      "Epoch [391/1000] completed, Average Training Loss: 0.1562\n",
      "    Validation Batch [1/1], Loss: 0.3127\n",
      "Validation Loss: 0.3127, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.3228 to 0.3127. Saving model...\n",
      "\n",
      "LOG: Epoch [392/1000] - Training\n",
      "Epoch [392/1000] completed, Average Training Loss: 0.1492\n",
      "    Validation Batch [1/1], Loss: 0.3086\n",
      "Validation Loss: 0.3086, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.3127 to 0.3086. Saving model...\n",
      "\n",
      "LOG: Epoch [393/1000] - Training\n",
      "Epoch [393/1000] completed, Average Training Loss: 0.1754\n",
      "    Validation Batch [1/1], Loss: 0.3206\n",
      "Validation Loss: 0.3206, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [394/1000] - Training\n",
      "Epoch [394/1000] completed, Average Training Loss: 0.1440\n",
      "    Validation Batch [1/1], Loss: 0.3449\n",
      "Validation Loss: 0.3449, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [395/1000] - Training\n",
      "Epoch [395/1000] completed, Average Training Loss: 0.1439\n",
      "    Validation Batch [1/1], Loss: 0.3554\n",
      "Validation Loss: 0.3554, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [396/1000] - Training\n",
      "Epoch [396/1000] completed, Average Training Loss: 0.1580\n",
      "    Validation Batch [1/1], Loss: 0.3466\n",
      "Validation Loss: 0.3466, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [397/1000] - Training\n",
      "Epoch [397/1000] completed, Average Training Loss: 0.1244\n",
      "    Validation Batch [1/1], Loss: 0.3352\n",
      "Validation Loss: 0.3352, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [398/1000] - Training\n",
      "Epoch [398/1000] completed, Average Training Loss: 0.1559\n",
      "    Validation Batch [1/1], Loss: 0.3235\n",
      "Validation Loss: 0.3235, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [399/1000] - Training\n",
      "Epoch [399/1000] completed, Average Training Loss: 0.1323\n",
      "    Validation Batch [1/1], Loss: 0.3169\n",
      "Validation Loss: 0.3169, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [400/1000] - Training\n",
      "Epoch [400/1000] completed, Average Training Loss: 0.1332\n",
      "    Validation Batch [1/1], Loss: 0.3204\n",
      "Validation Loss: 0.3204, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [401/1000] - Training\n",
      "Epoch [401/1000] completed, Average Training Loss: 0.1573\n",
      "    Validation Batch [1/1], Loss: 0.3284\n",
      "Validation Loss: 0.3284, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [402/1000] - Training\n",
      "Epoch [402/1000] completed, Average Training Loss: 0.1392\n",
      "    Validation Batch [1/1], Loss: 0.3308\n",
      "Validation Loss: 0.3308, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [403/1000] - Training\n",
      "Epoch [403/1000] completed, Average Training Loss: 0.1364\n",
      "    Validation Batch [1/1], Loss: 0.3217\n",
      "Validation Loss: 0.3217, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [404/1000] - Training\n",
      "Epoch [404/1000] completed, Average Training Loss: 0.1550\n",
      "    Validation Batch [1/1], Loss: 0.3169\n",
      "Validation Loss: 0.3169, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [405/1000] - Training\n",
      "Epoch [405/1000] completed, Average Training Loss: 0.1201\n",
      "    Validation Batch [1/1], Loss: 0.3218\n",
      "Validation Loss: 0.3218, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [406/1000] - Training\n",
      "Epoch [406/1000] completed, Average Training Loss: 0.1457\n",
      "    Validation Batch [1/1], Loss: 0.3267\n",
      "Validation Loss: 0.3267, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [407/1000] - Training\n",
      "Epoch [407/1000] completed, Average Training Loss: 0.1380\n",
      "    Validation Batch [1/1], Loss: 0.3456\n",
      "Validation Loss: 0.3456, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [408/1000] - Training\n",
      "Epoch [408/1000] completed, Average Training Loss: 0.1269\n",
      "    Validation Batch [1/1], Loss: 0.3608\n",
      "Validation Loss: 0.3608, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [409/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [409/1000] completed, Average Training Loss: 0.1580\n",
      "    Validation Batch [1/1], Loss: 0.3545\n",
      "Validation Loss: 0.3545, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [410/1000] - Training\n",
      "Epoch [410/1000] completed, Average Training Loss: 0.1268\n",
      "    Validation Batch [1/1], Loss: 0.3323\n",
      "Validation Loss: 0.3323, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [411/1000] - Training\n",
      "Epoch [411/1000] completed, Average Training Loss: 0.1345\n",
      "    Validation Batch [1/1], Loss: 0.3212\n",
      "Validation Loss: 0.3212, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [412/1000] - Training\n",
      "Epoch [412/1000] completed, Average Training Loss: 0.1386\n",
      "    Validation Batch [1/1], Loss: 0.3263\n",
      "Validation Loss: 0.3263, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [413/1000] - Training\n",
      "Epoch [413/1000] completed, Average Training Loss: 0.1512\n",
      "    Validation Batch [1/1], Loss: 0.3264\n",
      "Validation Loss: 0.3264, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [414/1000] - Training\n",
      "Epoch [414/1000] completed, Average Training Loss: 0.1333\n",
      "    Validation Batch [1/1], Loss: 0.3286\n",
      "Validation Loss: 0.3286, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [415/1000] - Training\n",
      "Epoch [415/1000] completed, Average Training Loss: 0.1237\n",
      "    Validation Batch [1/1], Loss: 0.3303\n",
      "Validation Loss: 0.3303, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [416/1000] - Training\n",
      "Epoch [416/1000] completed, Average Training Loss: 0.1155\n",
      "    Validation Batch [1/1], Loss: 0.3309\n",
      "Validation Loss: 0.3309, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [417/1000] - Training\n",
      "Epoch [417/1000] completed, Average Training Loss: 0.1280\n",
      "    Validation Batch [1/1], Loss: 0.3326\n",
      "Validation Loss: 0.3326, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [418/1000] - Training\n",
      "Epoch [418/1000] completed, Average Training Loss: 0.1269\n",
      "    Validation Batch [1/1], Loss: 0.3314\n",
      "Validation Loss: 0.3314, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [419/1000] - Training\n",
      "Epoch [419/1000] completed, Average Training Loss: 0.1473\n",
      "    Validation Batch [1/1], Loss: 0.3269\n",
      "Validation Loss: 0.3269, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [420/1000] - Training\n",
      "Epoch [420/1000] completed, Average Training Loss: 0.1495\n",
      "    Validation Batch [1/1], Loss: 0.3258\n",
      "Validation Loss: 0.3258, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [421/1000] - Training\n",
      "Epoch [421/1000] completed, Average Training Loss: 0.1122\n",
      "    Validation Batch [1/1], Loss: 0.3234\n",
      "Validation Loss: 0.3234, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [422/1000] - Training\n",
      "Epoch [422/1000] completed, Average Training Loss: 0.1426\n",
      "    Validation Batch [1/1], Loss: 0.3196\n",
      "Validation Loss: 0.3196, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [423/1000] - Training\n",
      "Epoch [423/1000] completed, Average Training Loss: 0.1311\n",
      "    Validation Batch [1/1], Loss: 0.3199\n",
      "Validation Loss: 0.3199, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [424/1000] - Training\n",
      "Epoch [424/1000] completed, Average Training Loss: 0.1119\n",
      "    Validation Batch [1/1], Loss: 0.3128\n",
      "Validation Loss: 0.3128, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [425/1000] - Training\n",
      "Epoch [425/1000] completed, Average Training Loss: 0.1282\n",
      "    Validation Batch [1/1], Loss: 0.3103\n",
      "Validation Loss: 0.3103, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [426/1000] - Training\n",
      "Epoch [426/1000] completed, Average Training Loss: 0.1063\n",
      "    Validation Batch [1/1], Loss: 0.3073\n",
      "Validation Loss: 0.3073, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.3086 to 0.3073. Saving model...\n",
      "\n",
      "LOG: Epoch [427/1000] - Training\n",
      "Epoch [427/1000] completed, Average Training Loss: 0.1173\n",
      "    Validation Batch [1/1], Loss: 0.3001\n",
      "Validation Loss: 0.3001, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.3073 to 0.3001. Saving model...\n",
      "\n",
      "LOG: Epoch [428/1000] - Training\n",
      "Epoch [428/1000] completed, Average Training Loss: 0.1285\n",
      "    Validation Batch [1/1], Loss: 0.2989\n",
      "Validation Loss: 0.2989, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.3001 to 0.2989. Saving model...\n",
      "\n",
      "LOG: Epoch [429/1000] - Training\n",
      "Epoch [429/1000] completed, Average Training Loss: 0.1371\n",
      "    Validation Batch [1/1], Loss: 0.2990\n",
      "Validation Loss: 0.2990, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [430/1000] - Training\n",
      "Epoch [430/1000] completed, Average Training Loss: 0.1379\n",
      "    Validation Batch [1/1], Loss: 0.2988\n",
      "Validation Loss: 0.2988, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2989 to 0.2988. Saving model...\n",
      "\n",
      "LOG: Epoch [431/1000] - Training\n",
      "Epoch [431/1000] completed, Average Training Loss: 0.1183\n",
      "    Validation Batch [1/1], Loss: 0.2897\n",
      "Validation Loss: 0.2897, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2988 to 0.2897. Saving model...\n",
      "\n",
      "LOG: Epoch [432/1000] - Training\n",
      "Epoch [432/1000] completed, Average Training Loss: 0.1254\n",
      "    Validation Batch [1/1], Loss: 0.2914\n",
      "Validation Loss: 0.2914, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [433/1000] - Training\n",
      "Epoch [433/1000] completed, Average Training Loss: 0.0997\n",
      "    Validation Batch [1/1], Loss: 0.3016\n",
      "Validation Loss: 0.3016, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [434/1000] - Training\n",
      "Epoch [434/1000] completed, Average Training Loss: 0.1321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.3039\n",
      "Validation Loss: 0.3039, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [435/1000] - Training\n",
      "Epoch [435/1000] completed, Average Training Loss: 0.1160\n",
      "    Validation Batch [1/1], Loss: 0.3042\n",
      "Validation Loss: 0.3042, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [436/1000] - Training\n",
      "Epoch [436/1000] completed, Average Training Loss: 0.1119\n",
      "    Validation Batch [1/1], Loss: 0.2927\n",
      "Validation Loss: 0.2927, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [437/1000] - Training\n",
      "Epoch [437/1000] completed, Average Training Loss: 0.1176\n",
      "    Validation Batch [1/1], Loss: 0.2899\n",
      "Validation Loss: 0.2899, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [438/1000] - Training\n",
      "Epoch [438/1000] completed, Average Training Loss: 0.0997\n",
      "    Validation Batch [1/1], Loss: 0.2869\n",
      "Validation Loss: 0.2869, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2897 to 0.2869. Saving model...\n",
      "\n",
      "LOG: Epoch [439/1000] - Training\n",
      "Epoch [439/1000] completed, Average Training Loss: 0.1048\n",
      "    Validation Batch [1/1], Loss: 0.2833\n",
      "Validation Loss: 0.2833, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2869 to 0.2833. Saving model...\n",
      "\n",
      "LOG: Epoch [440/1000] - Training\n",
      "Epoch [440/1000] completed, Average Training Loss: 0.1065\n",
      "    Validation Batch [1/1], Loss: 0.2851\n",
      "Validation Loss: 0.2851, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [441/1000] - Training\n",
      "Epoch [441/1000] completed, Average Training Loss: 0.0946\n",
      "    Validation Batch [1/1], Loss: 0.2887\n",
      "Validation Loss: 0.2887, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [442/1000] - Training\n",
      "Epoch [442/1000] completed, Average Training Loss: 0.1103\n",
      "    Validation Batch [1/1], Loss: 0.3004\n",
      "Validation Loss: 0.3004, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [443/1000] - Training\n",
      "Epoch [443/1000] completed, Average Training Loss: 0.1081\n",
      "    Validation Batch [1/1], Loss: 0.3114\n",
      "Validation Loss: 0.3114, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [444/1000] - Training\n",
      "Epoch [444/1000] completed, Average Training Loss: 0.1224\n",
      "    Validation Batch [1/1], Loss: 0.3033\n",
      "Validation Loss: 0.3033, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [445/1000] - Training\n",
      "Epoch [445/1000] completed, Average Training Loss: 0.1051\n",
      "    Validation Batch [1/1], Loss: 0.2909\n",
      "Validation Loss: 0.2909, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [446/1000] - Training\n",
      "Epoch [446/1000] completed, Average Training Loss: 0.1049\n",
      "    Validation Batch [1/1], Loss: 0.2846\n",
      "Validation Loss: 0.2846, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [447/1000] - Training\n",
      "Epoch [447/1000] completed, Average Training Loss: 0.1048\n",
      "    Validation Batch [1/1], Loss: 0.2888\n",
      "Validation Loss: 0.2888, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [448/1000] - Training\n",
      "Epoch [448/1000] completed, Average Training Loss: 0.1098\n",
      "    Validation Batch [1/1], Loss: 0.2926\n",
      "Validation Loss: 0.2926, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [449/1000] - Training\n",
      "Epoch [449/1000] completed, Average Training Loss: 0.1027\n",
      "    Validation Batch [1/1], Loss: 0.2898\n",
      "Validation Loss: 0.2898, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [450/1000] - Training\n",
      "Epoch [450/1000] completed, Average Training Loss: 0.1096\n",
      "    Validation Batch [1/1], Loss: 0.2824\n",
      "Validation Loss: 0.2824, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.2833 to 0.2824. Saving model...\n",
      "\n",
      "LOG: Epoch [451/1000] - Training\n",
      "Epoch [451/1000] completed, Average Training Loss: 0.1078\n",
      "    Validation Batch [1/1], Loss: 0.2787\n",
      "Validation Loss: 0.2787, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.2824 to 0.2787. Saving model...\n",
      "\n",
      "LOG: Epoch [452/1000] - Training\n",
      "Epoch [452/1000] completed, Average Training Loss: 0.1045\n",
      "    Validation Batch [1/1], Loss: 0.2751\n",
      "Validation Loss: 0.2751, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.2787 to 0.2751. Saving model...\n",
      "\n",
      "LOG: Epoch [453/1000] - Training\n",
      "Epoch [453/1000] completed, Average Training Loss: 0.1012\n",
      "    Validation Batch [1/1], Loss: 0.2651\n",
      "Validation Loss: 0.2651, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2751 to 0.2651. Saving model...\n",
      "\n",
      "LOG: Epoch [454/1000] - Training\n",
      "Epoch [454/1000] completed, Average Training Loss: 0.1039\n",
      "    Validation Batch [1/1], Loss: 0.2620\n",
      "Validation Loss: 0.2620, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2651 to 0.2620. Saving model...\n",
      "\n",
      "LOG: Epoch [455/1000] - Training\n",
      "Epoch [455/1000] completed, Average Training Loss: 0.1019\n",
      "    Validation Batch [1/1], Loss: 0.2697\n",
      "Validation Loss: 0.2697, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [456/1000] - Training\n",
      "Epoch [456/1000] completed, Average Training Loss: 0.1006\n",
      "    Validation Batch [1/1], Loss: 0.2844\n",
      "Validation Loss: 0.2844, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [457/1000] - Training\n",
      "Epoch [457/1000] completed, Average Training Loss: 0.0884\n",
      "    Validation Batch [1/1], Loss: 0.3002\n",
      "Validation Loss: 0.3002, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [458/1000] - Training\n",
      "Epoch [458/1000] completed, Average Training Loss: 0.0965\n",
      "    Validation Batch [1/1], Loss: 0.3033\n",
      "Validation Loss: 0.3033, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [459/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [459/1000] completed, Average Training Loss: 0.0791\n",
      "    Validation Batch [1/1], Loss: 0.2963\n",
      "Validation Loss: 0.2963, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [460/1000] - Training\n",
      "Epoch [460/1000] completed, Average Training Loss: 0.1006\n",
      "    Validation Batch [1/1], Loss: 0.2859\n",
      "Validation Loss: 0.2859, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [461/1000] - Training\n",
      "Epoch [461/1000] completed, Average Training Loss: 0.0964\n",
      "    Validation Batch [1/1], Loss: 0.2790\n",
      "Validation Loss: 0.2790, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [462/1000] - Training\n",
      "Epoch [462/1000] completed, Average Training Loss: 0.0853\n",
      "    Validation Batch [1/1], Loss: 0.2831\n",
      "Validation Loss: 0.2831, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [463/1000] - Training\n",
      "Epoch [463/1000] completed, Average Training Loss: 0.1003\n",
      "    Validation Batch [1/1], Loss: 0.2968\n",
      "Validation Loss: 0.2968, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [464/1000] - Training\n",
      "Epoch [464/1000] completed, Average Training Loss: 0.1147\n",
      "    Validation Batch [1/1], Loss: 0.3156\n",
      "Validation Loss: 0.3156, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [465/1000] - Training\n",
      "Epoch [465/1000] completed, Average Training Loss: 0.0931\n",
      "    Validation Batch [1/1], Loss: 0.3193\n",
      "Validation Loss: 0.3193, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [466/1000] - Training\n",
      "Epoch [466/1000] completed, Average Training Loss: 0.1010\n",
      "    Validation Batch [1/1], Loss: 0.2948\n",
      "Validation Loss: 0.2948, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [467/1000] - Training\n",
      "Epoch [467/1000] completed, Average Training Loss: 0.0967\n",
      "    Validation Batch [1/1], Loss: 0.2713\n",
      "Validation Loss: 0.2713, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [468/1000] - Training\n",
      "Epoch [468/1000] completed, Average Training Loss: 0.1024\n",
      "    Validation Batch [1/1], Loss: 0.2637\n",
      "Validation Loss: 0.2637, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [469/1000] - Training\n",
      "Epoch [469/1000] completed, Average Training Loss: 0.0817\n",
      "    Validation Batch [1/1], Loss: 0.2721\n",
      "Validation Loss: 0.2721, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [470/1000] - Training\n",
      "Epoch [470/1000] completed, Average Training Loss: 0.1004\n",
      "    Validation Batch [1/1], Loss: 0.2782\n",
      "Validation Loss: 0.2782, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [471/1000] - Training\n",
      "Epoch [471/1000] completed, Average Training Loss: 0.0967\n",
      "    Validation Batch [1/1], Loss: 0.2820\n",
      "Validation Loss: 0.2820, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [472/1000] - Training\n",
      "Epoch [472/1000] completed, Average Training Loss: 0.0972\n",
      "    Validation Batch [1/1], Loss: 0.2824\n",
      "Validation Loss: 0.2824, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [473/1000] - Training\n",
      "Epoch [473/1000] completed, Average Training Loss: 0.0894\n",
      "    Validation Batch [1/1], Loss: 0.2862\n",
      "Validation Loss: 0.2862, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [474/1000] - Training\n",
      "Epoch [474/1000] completed, Average Training Loss: 0.0967\n",
      "    Validation Batch [1/1], Loss: 0.2814\n",
      "Validation Loss: 0.2814, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [475/1000] - Training\n",
      "Epoch [475/1000] completed, Average Training Loss: 0.0752\n",
      "    Validation Batch [1/1], Loss: 0.2773\n",
      "Validation Loss: 0.2773, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [476/1000] - Training\n",
      "Epoch [476/1000] completed, Average Training Loss: 0.0979\n",
      "    Validation Batch [1/1], Loss: 0.2625\n",
      "Validation Loss: 0.2625, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [477/1000] - Training\n",
      "Epoch [477/1000] completed, Average Training Loss: 0.0928\n",
      "    Validation Batch [1/1], Loss: 0.2567\n",
      "Validation Loss: 0.2567, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2620 to 0.2567. Saving model...\n",
      "\n",
      "LOG: Epoch [478/1000] - Training\n",
      "Epoch [478/1000] completed, Average Training Loss: 0.0910\n",
      "    Validation Batch [1/1], Loss: 0.2540\n",
      "Validation Loss: 0.2540, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2567 to 0.2540. Saving model...\n",
      "\n",
      "LOG: Epoch [479/1000] - Training\n",
      "Epoch [479/1000] completed, Average Training Loss: 0.0900\n",
      "    Validation Batch [1/1], Loss: 0.2639\n",
      "Validation Loss: 0.2639, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [480/1000] - Training\n",
      "Epoch [480/1000] completed, Average Training Loss: 0.0750\n",
      "    Validation Batch [1/1], Loss: 0.2690\n",
      "Validation Loss: 0.2690, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [481/1000] - Training\n",
      "Epoch [481/1000] completed, Average Training Loss: 0.1055\n",
      "    Validation Batch [1/1], Loss: 0.2703\n",
      "Validation Loss: 0.2703, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [482/1000] - Training\n",
      "Epoch [482/1000] completed, Average Training Loss: 0.0919\n",
      "    Validation Batch [1/1], Loss: 0.2708\n",
      "Validation Loss: 0.2708, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [483/1000] - Training\n",
      "Epoch [483/1000] completed, Average Training Loss: 0.1038\n",
      "    Validation Batch [1/1], Loss: 0.2668\n",
      "Validation Loss: 0.2668, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [484/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [484/1000] completed, Average Training Loss: 0.0884\n",
      "    Validation Batch [1/1], Loss: 0.2663\n",
      "Validation Loss: 0.2663, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [485/1000] - Training\n",
      "Epoch [485/1000] completed, Average Training Loss: 0.0842\n",
      "    Validation Batch [1/1], Loss: 0.2648\n",
      "Validation Loss: 0.2648, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [486/1000] - Training\n",
      "Epoch [486/1000] completed, Average Training Loss: 0.0852\n",
      "    Validation Batch [1/1], Loss: 0.2614\n",
      "Validation Loss: 0.2614, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [487/1000] - Training\n",
      "Epoch [487/1000] completed, Average Training Loss: 0.0855\n",
      "    Validation Batch [1/1], Loss: 0.2680\n",
      "Validation Loss: 0.2680, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [488/1000] - Training\n",
      "Epoch [488/1000] completed, Average Training Loss: 0.0764\n",
      "    Validation Batch [1/1], Loss: 0.2766\n",
      "Validation Loss: 0.2766, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [489/1000] - Training\n",
      "Epoch [489/1000] completed, Average Training Loss: 0.0977\n",
      "    Validation Batch [1/1], Loss: 0.2668\n",
      "Validation Loss: 0.2668, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [490/1000] - Training\n",
      "Epoch [490/1000] completed, Average Training Loss: 0.0898\n",
      "    Validation Batch [1/1], Loss: 0.2617\n",
      "Validation Loss: 0.2617, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [491/1000] - Training\n",
      "Epoch [491/1000] completed, Average Training Loss: 0.0967\n",
      "    Validation Batch [1/1], Loss: 0.2613\n",
      "Validation Loss: 0.2613, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [492/1000] - Training\n",
      "Epoch [492/1000] completed, Average Training Loss: 0.0739\n",
      "    Validation Batch [1/1], Loss: 0.2646\n",
      "Validation Loss: 0.2646, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [493/1000] - Training\n",
      "Epoch [493/1000] completed, Average Training Loss: 0.0794\n",
      "    Validation Batch [1/1], Loss: 0.2646\n",
      "Validation Loss: 0.2646, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [494/1000] - Training\n",
      "Epoch [494/1000] completed, Average Training Loss: 0.0954\n",
      "    Validation Batch [1/1], Loss: 0.2628\n",
      "Validation Loss: 0.2628, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [495/1000] - Training\n",
      "Epoch [495/1000] completed, Average Training Loss: 0.0799\n",
      "    Validation Batch [1/1], Loss: 0.2645\n",
      "Validation Loss: 0.2645, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [496/1000] - Training\n",
      "Epoch [496/1000] completed, Average Training Loss: 0.0832\n",
      "    Validation Batch [1/1], Loss: 0.2664\n",
      "Validation Loss: 0.2664, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [497/1000] - Training\n",
      "Epoch [497/1000] completed, Average Training Loss: 0.0793\n",
      "    Validation Batch [1/1], Loss: 0.2776\n",
      "Validation Loss: 0.2776, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [498/1000] - Training\n",
      "Epoch [498/1000] completed, Average Training Loss: 0.0806\n",
      "    Validation Batch [1/1], Loss: 0.2822\n",
      "Validation Loss: 0.2822, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [499/1000] - Training\n",
      "Epoch [499/1000] completed, Average Training Loss: 0.0678\n",
      "    Validation Batch [1/1], Loss: 0.2827\n",
      "Validation Loss: 0.2827, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [500/1000] - Training\n",
      "Epoch [500/1000] completed, Average Training Loss: 0.0646\n",
      "    Validation Batch [1/1], Loss: 0.2719\n",
      "Validation Loss: 0.2719, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [501/1000] - Training\n",
      "Epoch [501/1000] completed, Average Training Loss: 0.0927\n",
      "    Validation Batch [1/1], Loss: 0.2590\n",
      "Validation Loss: 0.2590, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [502/1000] - Training\n",
      "Epoch [502/1000] completed, Average Training Loss: 0.0974\n",
      "    Validation Batch [1/1], Loss: 0.2443\n",
      "Validation Loss: 0.2443, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.2540 to 0.2443. Saving model...\n",
      "\n",
      "LOG: Epoch [503/1000] - Training\n",
      "Epoch [503/1000] completed, Average Training Loss: 0.0809\n",
      "    Validation Batch [1/1], Loss: 0.2398\n",
      "Validation Loss: 0.2398, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2443 to 0.2398. Saving model...\n",
      "\n",
      "LOG: Epoch [504/1000] - Training\n",
      "Epoch [504/1000] completed, Average Training Loss: 0.0629\n",
      "    Validation Batch [1/1], Loss: 0.2463\n",
      "Validation Loss: 0.2463, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [505/1000] - Training\n",
      "Epoch [505/1000] completed, Average Training Loss: 0.0781\n",
      "    Validation Batch [1/1], Loss: 0.2551\n",
      "Validation Loss: 0.2551, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [506/1000] - Training\n",
      "Epoch [506/1000] completed, Average Training Loss: 0.0783\n",
      "    Validation Batch [1/1], Loss: 0.2753\n",
      "Validation Loss: 0.2753, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [507/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [507/1000] completed, Average Training Loss: 0.0742\n",
      "    Validation Batch [1/1], Loss: 0.2817\n",
      "Validation Loss: 0.2817, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [508/1000] - Training\n",
      "Epoch [508/1000] completed, Average Training Loss: 0.0724\n",
      "    Validation Batch [1/1], Loss: 0.2748\n",
      "Validation Loss: 0.2748, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [509/1000] - Training\n",
      "Epoch [509/1000] completed, Average Training Loss: 0.0784\n",
      "    Validation Batch [1/1], Loss: 0.2630\n",
      "Validation Loss: 0.2630, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [510/1000] - Training\n",
      "Epoch [510/1000] completed, Average Training Loss: 0.0895\n",
      "    Validation Batch [1/1], Loss: 0.2503\n",
      "Validation Loss: 0.2503, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [511/1000] - Training\n",
      "Epoch [511/1000] completed, Average Training Loss: 0.0712\n",
      "    Validation Batch [1/1], Loss: 0.2506\n",
      "Validation Loss: 0.2506, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [512/1000] - Training\n",
      "Epoch [512/1000] completed, Average Training Loss: 0.0814\n",
      "    Validation Batch [1/1], Loss: 0.2548\n",
      "Validation Loss: 0.2548, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [513/1000] - Training\n",
      "Epoch [513/1000] completed, Average Training Loss: 0.0786\n",
      "    Validation Batch [1/1], Loss: 0.2542\n",
      "Validation Loss: 0.2542, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [514/1000] - Training\n",
      "Epoch [514/1000] completed, Average Training Loss: 0.0752\n",
      "    Validation Batch [1/1], Loss: 0.2482\n",
      "Validation Loss: 0.2482, Validation Accuracy: 97.14%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [515/1000] - Training\n",
      "Epoch [515/1000] completed, Average Training Loss: 0.0726\n",
      "    Validation Batch [1/1], Loss: 0.2484\n",
      "Validation Loss: 0.2484, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [516/1000] - Training\n",
      "Epoch [516/1000] completed, Average Training Loss: 0.0658\n",
      "    Validation Batch [1/1], Loss: 0.2523\n",
      "Validation Loss: 0.2523, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [517/1000] - Training\n",
      "Epoch [517/1000] completed, Average Training Loss: 0.0836\n",
      "    Validation Batch [1/1], Loss: 0.2629\n",
      "Validation Loss: 0.2629, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [518/1000] - Training\n",
      "Epoch [518/1000] completed, Average Training Loss: 0.0789\n",
      "    Validation Batch [1/1], Loss: 0.2809\n",
      "Validation Loss: 0.2809, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [519/1000] - Training\n",
      "Epoch [519/1000] completed, Average Training Loss: 0.0604\n",
      "    Validation Batch [1/1], Loss: 0.2908\n",
      "Validation Loss: 0.2908, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [520/1000] - Training\n",
      "Epoch [520/1000] completed, Average Training Loss: 0.0568\n",
      "    Validation Batch [1/1], Loss: 0.2878\n",
      "Validation Loss: 0.2878, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [521/1000] - Training\n",
      "Epoch [521/1000] completed, Average Training Loss: 0.0577\n",
      "    Validation Batch [1/1], Loss: 0.2832\n",
      "Validation Loss: 0.2832, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [522/1000] - Training\n",
      "Epoch [522/1000] completed, Average Training Loss: 0.0625\n",
      "    Validation Batch [1/1], Loss: 0.2786\n",
      "Validation Loss: 0.2786, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [523/1000] - Training\n",
      "Epoch [523/1000] completed, Average Training Loss: 0.0753\n",
      "    Validation Batch [1/1], Loss: 0.2786\n",
      "Validation Loss: 0.2786, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [524/1000] - Training\n",
      "Epoch [524/1000] completed, Average Training Loss: 0.0572\n",
      "    Validation Batch [1/1], Loss: 0.2790\n",
      "Validation Loss: 0.2790, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [525/1000] - Training\n",
      "Epoch [525/1000] completed, Average Training Loss: 0.0809\n",
      "    Validation Batch [1/1], Loss: 0.2804\n",
      "Validation Loss: 0.2804, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [526/1000] - Training\n",
      "Epoch [526/1000] completed, Average Training Loss: 0.0565\n",
      "    Validation Batch [1/1], Loss: 0.2714\n",
      "Validation Loss: 0.2714, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [527/1000] - Training\n",
      "Epoch [527/1000] completed, Average Training Loss: 0.0631\n",
      "    Validation Batch [1/1], Loss: 0.2549\n",
      "Validation Loss: 0.2549, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [528/1000] - Training\n",
      "Epoch [528/1000] completed, Average Training Loss: 0.0723\n",
      "    Validation Batch [1/1], Loss: 0.2381\n",
      "Validation Loss: 0.2381, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2398 to 0.2381. Saving model...\n",
      "\n",
      "LOG: Epoch [529/1000] - Training\n",
      "Epoch [529/1000] completed, Average Training Loss: 0.0693\n",
      "    Validation Batch [1/1], Loss: 0.2344\n",
      "Validation Loss: 0.2344, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2381 to 0.2344. Saving model...\n",
      "\n",
      "LOG: Epoch [530/1000] - Training\n",
      "Epoch [530/1000] completed, Average Training Loss: 0.0861\n",
      "    Validation Batch [1/1], Loss: 0.2317\n",
      "Validation Loss: 0.2317, Validation Accuracy: 97.14%\n",
      "Validation loss improved from 0.2344 to 0.2317. Saving model...\n",
      "\n",
      "LOG: Epoch [531/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [531/1000] completed, Average Training Loss: 0.0682\n",
      "    Validation Batch [1/1], Loss: 0.2396\n",
      "Validation Loss: 0.2396, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [532/1000] - Training\n",
      "Epoch [532/1000] completed, Average Training Loss: 0.0744\n",
      "    Validation Batch [1/1], Loss: 0.2698\n",
      "Validation Loss: 0.2698, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [533/1000] - Training\n",
      "Epoch [533/1000] completed, Average Training Loss: 0.0677\n",
      "    Validation Batch [1/1], Loss: 0.3061\n",
      "Validation Loss: 0.3061, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [534/1000] - Training\n",
      "Epoch [534/1000] completed, Average Training Loss: 0.0649\n",
      "    Validation Batch [1/1], Loss: 0.3130\n",
      "Validation Loss: 0.3130, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [535/1000] - Training\n",
      "Epoch [535/1000] completed, Average Training Loss: 0.0745\n",
      "    Validation Batch [1/1], Loss: 0.2884\n",
      "Validation Loss: 0.2884, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [536/1000] - Training\n",
      "Epoch [536/1000] completed, Average Training Loss: 0.0820\n",
      "    Validation Batch [1/1], Loss: 0.2647\n",
      "Validation Loss: 0.2647, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [537/1000] - Training\n",
      "Epoch [537/1000] completed, Average Training Loss: 0.0616\n",
      "    Validation Batch [1/1], Loss: 0.2507\n",
      "Validation Loss: 0.2507, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [538/1000] - Training\n",
      "Epoch [538/1000] completed, Average Training Loss: 0.0620\n",
      "    Validation Batch [1/1], Loss: 0.2417\n",
      "Validation Loss: 0.2417, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [539/1000] - Training\n",
      "Epoch [539/1000] completed, Average Training Loss: 0.0693\n",
      "    Validation Batch [1/1], Loss: 0.2295\n",
      "Validation Loss: 0.2295, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2317 to 0.2295. Saving model...\n",
      "\n",
      "LOG: Epoch [540/1000] - Training\n",
      "Epoch [540/1000] completed, Average Training Loss: 0.0705\n",
      "    Validation Batch [1/1], Loss: 0.2237\n",
      "Validation Loss: 0.2237, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2295 to 0.2237. Saving model...\n",
      "\n",
      "LOG: Epoch [541/1000] - Training\n",
      "Epoch [541/1000] completed, Average Training Loss: 0.0650\n",
      "    Validation Batch [1/1], Loss: 0.2297\n",
      "Validation Loss: 0.2297, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [542/1000] - Training\n",
      "Epoch [542/1000] completed, Average Training Loss: 0.0655\n",
      "    Validation Batch [1/1], Loss: 0.2374\n",
      "Validation Loss: 0.2374, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [543/1000] - Training\n",
      "Epoch [543/1000] completed, Average Training Loss: 0.0617\n",
      "    Validation Batch [1/1], Loss: 0.2465\n",
      "Validation Loss: 0.2465, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [544/1000] - Training\n",
      "Epoch [544/1000] completed, Average Training Loss: 0.0621\n",
      "    Validation Batch [1/1], Loss: 0.2515\n",
      "Validation Loss: 0.2515, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [545/1000] - Training\n",
      "Epoch [545/1000] completed, Average Training Loss: 0.0744\n",
      "    Validation Batch [1/1], Loss: 0.2496\n",
      "Validation Loss: 0.2496, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [546/1000] - Training\n",
      "Epoch [546/1000] completed, Average Training Loss: 0.0577\n",
      "    Validation Batch [1/1], Loss: 0.2442\n",
      "Validation Loss: 0.2442, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [547/1000] - Training\n",
      "Epoch [547/1000] completed, Average Training Loss: 0.0607\n",
      "    Validation Batch [1/1], Loss: 0.2395\n",
      "Validation Loss: 0.2395, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [548/1000] - Training\n",
      "Epoch [548/1000] completed, Average Training Loss: 0.0609\n",
      "    Validation Batch [1/1], Loss: 0.2401\n",
      "Validation Loss: 0.2401, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [549/1000] - Training\n",
      "Epoch [549/1000] completed, Average Training Loss: 0.0585\n",
      "    Validation Batch [1/1], Loss: 0.2382\n",
      "Validation Loss: 0.2382, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [550/1000] - Training\n",
      "Epoch [550/1000] completed, Average Training Loss: 0.0587\n",
      "    Validation Batch [1/1], Loss: 0.2388\n",
      "Validation Loss: 0.2388, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [551/1000] - Training\n",
      "Epoch [551/1000] completed, Average Training Loss: 0.0651\n",
      "    Validation Batch [1/1], Loss: 0.2396\n",
      "Validation Loss: 0.2396, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [552/1000] - Training\n",
      "Epoch [552/1000] completed, Average Training Loss: 0.0674\n",
      "    Validation Batch [1/1], Loss: 0.2458\n",
      "Validation Loss: 0.2458, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [553/1000] - Training\n",
      "Epoch [553/1000] completed, Average Training Loss: 0.0574\n",
      "    Validation Batch [1/1], Loss: 0.2449\n",
      "Validation Loss: 0.2449, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [554/1000] - Training\n",
      "Epoch [554/1000] completed, Average Training Loss: 0.0808\n",
      "    Validation Batch [1/1], Loss: 0.2410\n",
      "Validation Loss: 0.2410, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [555/1000] - Training\n",
      "Epoch [555/1000] completed, Average Training Loss: 0.0587\n",
      "    Validation Batch [1/1], Loss: 0.2436\n",
      "Validation Loss: 0.2436, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [556/1000] - Training\n",
      "Epoch [556/1000] completed, Average Training Loss: 0.0609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.2418\n",
      "Validation Loss: 0.2418, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [557/1000] - Training\n",
      "Epoch [557/1000] completed, Average Training Loss: 0.0650\n",
      "    Validation Batch [1/1], Loss: 0.2394\n",
      "Validation Loss: 0.2394, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [558/1000] - Training\n",
      "Epoch [558/1000] completed, Average Training Loss: 0.0739\n",
      "    Validation Batch [1/1], Loss: 0.2376\n",
      "Validation Loss: 0.2376, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [559/1000] - Training\n",
      "Epoch [559/1000] completed, Average Training Loss: 0.0551\n",
      "    Validation Batch [1/1], Loss: 0.2360\n",
      "Validation Loss: 0.2360, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [560/1000] - Training\n",
      "Epoch [560/1000] completed, Average Training Loss: 0.0721\n",
      "    Validation Batch [1/1], Loss: 0.2346\n",
      "Validation Loss: 0.2346, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [561/1000] - Training\n",
      "Epoch [561/1000] completed, Average Training Loss: 0.0603\n",
      "    Validation Batch [1/1], Loss: 0.2384\n",
      "Validation Loss: 0.2384, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [562/1000] - Training\n",
      "Epoch [562/1000] completed, Average Training Loss: 0.0545\n",
      "    Validation Batch [1/1], Loss: 0.2471\n",
      "Validation Loss: 0.2471, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [563/1000] - Training\n",
      "Epoch [563/1000] completed, Average Training Loss: 0.0514\n",
      "    Validation Batch [1/1], Loss: 0.2508\n",
      "Validation Loss: 0.2508, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [564/1000] - Training\n",
      "Epoch [564/1000] completed, Average Training Loss: 0.0615\n",
      "    Validation Batch [1/1], Loss: 0.2479\n",
      "Validation Loss: 0.2479, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [565/1000] - Training\n",
      "Epoch [565/1000] completed, Average Training Loss: 0.0643\n",
      "    Validation Batch [1/1], Loss: 0.2440\n",
      "Validation Loss: 0.2440, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [566/1000] - Training\n",
      "Epoch [566/1000] completed, Average Training Loss: 0.0587\n",
      "    Validation Batch [1/1], Loss: 0.2384\n",
      "Validation Loss: 0.2384, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [567/1000] - Training\n",
      "Epoch [567/1000] completed, Average Training Loss: 0.0619\n",
      "    Validation Batch [1/1], Loss: 0.2387\n",
      "Validation Loss: 0.2387, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [568/1000] - Training\n",
      "Epoch [568/1000] completed, Average Training Loss: 0.0624\n",
      "    Validation Batch [1/1], Loss: 0.2325\n",
      "Validation Loss: 0.2325, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [569/1000] - Training\n",
      "Epoch [569/1000] completed, Average Training Loss: 0.0577\n",
      "    Validation Batch [1/1], Loss: 0.2303\n",
      "Validation Loss: 0.2303, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [570/1000] - Training\n",
      "Epoch [570/1000] completed, Average Training Loss: 0.0537\n",
      "    Validation Batch [1/1], Loss: 0.2296\n",
      "Validation Loss: 0.2296, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [571/1000] - Training\n",
      "Epoch [571/1000] completed, Average Training Loss: 0.0639\n",
      "    Validation Batch [1/1], Loss: 0.2327\n",
      "Validation Loss: 0.2327, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [572/1000] - Training\n",
      "Epoch [572/1000] completed, Average Training Loss: 0.0571\n",
      "    Validation Batch [1/1], Loss: 0.2328\n",
      "Validation Loss: 0.2328, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [573/1000] - Training\n",
      "Epoch [573/1000] completed, Average Training Loss: 0.0727\n",
      "    Validation Batch [1/1], Loss: 0.2318\n",
      "Validation Loss: 0.2318, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [574/1000] - Training\n",
      "Epoch [574/1000] completed, Average Training Loss: 0.0530\n",
      "    Validation Batch [1/1], Loss: 0.2313\n",
      "Validation Loss: 0.2313, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [575/1000] - Training\n",
      "Epoch [575/1000] completed, Average Training Loss: 0.0539\n",
      "    Validation Batch [1/1], Loss: 0.2271\n",
      "Validation Loss: 0.2271, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [576/1000] - Training\n",
      "Epoch [576/1000] completed, Average Training Loss: 0.0490\n",
      "    Validation Batch [1/1], Loss: 0.2223\n",
      "Validation Loss: 0.2223, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2237 to 0.2223. Saving model...\n",
      "\n",
      "LOG: Epoch [577/1000] - Training\n",
      "Epoch [577/1000] completed, Average Training Loss: 0.0636\n",
      "    Validation Batch [1/1], Loss: 0.2215\n",
      "Validation Loss: 0.2215, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2223 to 0.2215. Saving model...\n",
      "\n",
      "LOG: Epoch [578/1000] - Training\n",
      "Epoch [578/1000] completed, Average Training Loss: 0.0577\n",
      "    Validation Batch [1/1], Loss: 0.2193\n",
      "Validation Loss: 0.2193, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2215 to 0.2193. Saving model...\n",
      "\n",
      "LOG: Epoch [579/1000] - Training\n",
      "Epoch [579/1000] completed, Average Training Loss: 0.0521\n",
      "    Validation Batch [1/1], Loss: 0.2195\n",
      "Validation Loss: 0.2195, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [580/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [580/1000] completed, Average Training Loss: 0.0585\n",
      "    Validation Batch [1/1], Loss: 0.2261\n",
      "Validation Loss: 0.2261, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [581/1000] - Training\n",
      "Epoch [581/1000] completed, Average Training Loss: 0.0540\n",
      "    Validation Batch [1/1], Loss: 0.2381\n",
      "Validation Loss: 0.2381, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [582/1000] - Training\n",
      "Epoch [582/1000] completed, Average Training Loss: 0.0435\n",
      "    Validation Batch [1/1], Loss: 0.2465\n",
      "Validation Loss: 0.2465, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [583/1000] - Training\n",
      "Epoch [583/1000] completed, Average Training Loss: 0.0440\n",
      "    Validation Batch [1/1], Loss: 0.2464\n",
      "Validation Loss: 0.2464, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [584/1000] - Training\n",
      "Epoch [584/1000] completed, Average Training Loss: 0.0518\n",
      "    Validation Batch [1/1], Loss: 0.2414\n",
      "Validation Loss: 0.2414, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [585/1000] - Training\n",
      "Epoch [585/1000] completed, Average Training Loss: 0.0459\n",
      "    Validation Batch [1/1], Loss: 0.2355\n",
      "Validation Loss: 0.2355, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [586/1000] - Training\n",
      "Epoch [586/1000] completed, Average Training Loss: 0.0525\n",
      "    Validation Batch [1/1], Loss: 0.2307\n",
      "Validation Loss: 0.2307, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [587/1000] - Training\n",
      "Epoch [587/1000] completed, Average Training Loss: 0.0513\n",
      "    Validation Batch [1/1], Loss: 0.2285\n",
      "Validation Loss: 0.2285, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [588/1000] - Training\n",
      "Epoch [588/1000] completed, Average Training Loss: 0.0520\n",
      "    Validation Batch [1/1], Loss: 0.2307\n",
      "Validation Loss: 0.2307, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [589/1000] - Training\n",
      "Epoch [589/1000] completed, Average Training Loss: 0.0563\n",
      "    Validation Batch [1/1], Loss: 0.2319\n",
      "Validation Loss: 0.2319, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [590/1000] - Training\n",
      "Epoch [590/1000] completed, Average Training Loss: 0.0545\n",
      "    Validation Batch [1/1], Loss: 0.2271\n",
      "Validation Loss: 0.2271, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [591/1000] - Training\n",
      "Epoch [591/1000] completed, Average Training Loss: 0.0616\n",
      "    Validation Batch [1/1], Loss: 0.2308\n",
      "Validation Loss: 0.2308, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [592/1000] - Training\n",
      "Epoch [592/1000] completed, Average Training Loss: 0.0582\n",
      "    Validation Batch [1/1], Loss: 0.2346\n",
      "Validation Loss: 0.2346, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [593/1000] - Training\n",
      "Epoch [593/1000] completed, Average Training Loss: 0.0460\n",
      "    Validation Batch [1/1], Loss: 0.2410\n",
      "Validation Loss: 0.2410, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [594/1000] - Training\n",
      "Epoch [594/1000] completed, Average Training Loss: 0.0427\n",
      "    Validation Batch [1/1], Loss: 0.2471\n",
      "Validation Loss: 0.2471, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [595/1000] - Training\n",
      "Epoch [595/1000] completed, Average Training Loss: 0.0481\n",
      "    Validation Batch [1/1], Loss: 0.2512\n",
      "Validation Loss: 0.2512, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [596/1000] - Training\n",
      "Epoch [596/1000] completed, Average Training Loss: 0.0672\n",
      "    Validation Batch [1/1], Loss: 0.2469\n",
      "Validation Loss: 0.2469, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [597/1000] - Training\n",
      "Epoch [597/1000] completed, Average Training Loss: 0.0473\n",
      "    Validation Batch [1/1], Loss: 0.2400\n",
      "Validation Loss: 0.2400, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [598/1000] - Training\n",
      "Epoch [598/1000] completed, Average Training Loss: 0.0568\n",
      "    Validation Batch [1/1], Loss: 0.2290\n",
      "Validation Loss: 0.2290, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [599/1000] - Training\n",
      "Epoch [599/1000] completed, Average Training Loss: 0.0563\n",
      "    Validation Batch [1/1], Loss: 0.2219\n",
      "Validation Loss: 0.2219, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [600/1000] - Training\n",
      "Epoch [600/1000] completed, Average Training Loss: 0.0672\n",
      "    Validation Batch [1/1], Loss: 0.2129\n",
      "Validation Loss: 0.2129, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2193 to 0.2129. Saving model...\n",
      "\n",
      "LOG: Epoch [601/1000] - Training\n",
      "Epoch [601/1000] completed, Average Training Loss: 0.0491\n",
      "    Validation Batch [1/1], Loss: 0.2116\n",
      "Validation Loss: 0.2116, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2129 to 0.2116. Saving model...\n",
      "\n",
      "LOG: Epoch [602/1000] - Training\n",
      "Epoch [602/1000] completed, Average Training Loss: 0.0619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.2165\n",
      "Validation Loss: 0.2165, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [603/1000] - Training\n",
      "Epoch [603/1000] completed, Average Training Loss: 0.0510\n",
      "    Validation Batch [1/1], Loss: 0.2293\n",
      "Validation Loss: 0.2293, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [604/1000] - Training\n",
      "Epoch [604/1000] completed, Average Training Loss: 0.0467\n",
      "    Validation Batch [1/1], Loss: 0.2407\n",
      "Validation Loss: 0.2407, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [605/1000] - Training\n",
      "Epoch [605/1000] completed, Average Training Loss: 0.0536\n",
      "    Validation Batch [1/1], Loss: 0.2581\n",
      "Validation Loss: 0.2581, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [606/1000] - Training\n",
      "Epoch [606/1000] completed, Average Training Loss: 0.0483\n",
      "    Validation Batch [1/1], Loss: 0.2738\n",
      "Validation Loss: 0.2738, Validation Accuracy: 91.43%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [607/1000] - Training\n",
      "Epoch [607/1000] completed, Average Training Loss: 0.0673\n",
      "    Validation Batch [1/1], Loss: 0.2594\n",
      "Validation Loss: 0.2594, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [608/1000] - Training\n",
      "Epoch [608/1000] completed, Average Training Loss: 0.0530\n",
      "    Validation Batch [1/1], Loss: 0.2416\n",
      "Validation Loss: 0.2416, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [609/1000] - Training\n",
      "Epoch [609/1000] completed, Average Training Loss: 0.0499\n",
      "    Validation Batch [1/1], Loss: 0.2314\n",
      "Validation Loss: 0.2314, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [610/1000] - Training\n",
      "Epoch [610/1000] completed, Average Training Loss: 0.0433\n",
      "    Validation Batch [1/1], Loss: 0.2275\n",
      "Validation Loss: 0.2275, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [611/1000] - Training\n",
      "Epoch [611/1000] completed, Average Training Loss: 0.0451\n",
      "    Validation Batch [1/1], Loss: 0.2314\n",
      "Validation Loss: 0.2314, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [612/1000] - Training\n",
      "Epoch [612/1000] completed, Average Training Loss: 0.0444\n",
      "    Validation Batch [1/1], Loss: 0.2290\n",
      "Validation Loss: 0.2290, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [613/1000] - Training\n",
      "Epoch [613/1000] completed, Average Training Loss: 0.0548\n",
      "    Validation Batch [1/1], Loss: 0.2277\n",
      "Validation Loss: 0.2277, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [614/1000] - Training\n",
      "Epoch [614/1000] completed, Average Training Loss: 0.0516\n",
      "    Validation Batch [1/1], Loss: 0.2269\n",
      "Validation Loss: 0.2269, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [615/1000] - Training\n",
      "Epoch [615/1000] completed, Average Training Loss: 0.0463\n",
      "    Validation Batch [1/1], Loss: 0.2238\n",
      "Validation Loss: 0.2238, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [616/1000] - Training\n",
      "Epoch [616/1000] completed, Average Training Loss: 0.0436\n",
      "    Validation Batch [1/1], Loss: 0.2259\n",
      "Validation Loss: 0.2259, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [617/1000] - Training\n",
      "Epoch [617/1000] completed, Average Training Loss: 0.0422\n",
      "    Validation Batch [1/1], Loss: 0.2313\n",
      "Validation Loss: 0.2313, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [618/1000] - Training\n",
      "Epoch [618/1000] completed, Average Training Loss: 0.0494\n",
      "    Validation Batch [1/1], Loss: 0.2360\n",
      "Validation Loss: 0.2360, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [619/1000] - Training\n",
      "Epoch [619/1000] completed, Average Training Loss: 0.0481\n",
      "    Validation Batch [1/1], Loss: 0.2390\n",
      "Validation Loss: 0.2390, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [620/1000] - Training\n",
      "Epoch [620/1000] completed, Average Training Loss: 0.0535\n",
      "    Validation Batch [1/1], Loss: 0.2331\n",
      "Validation Loss: 0.2331, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [621/1000] - Training\n",
      "Epoch [621/1000] completed, Average Training Loss: 0.0474\n",
      "    Validation Batch [1/1], Loss: 0.2232\n",
      "Validation Loss: 0.2232, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [622/1000] - Training\n",
      "Epoch [622/1000] completed, Average Training Loss: 0.0390\n",
      "    Validation Batch [1/1], Loss: 0.2146\n",
      "Validation Loss: 0.2146, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [623/1000] - Training\n",
      "Epoch [623/1000] completed, Average Training Loss: 0.0512\n",
      "    Validation Batch [1/1], Loss: 0.2079\n",
      "Validation Loss: 0.2079, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2116 to 0.2079. Saving model...\n",
      "\n",
      "LOG: Epoch [624/1000] - Training\n",
      "Epoch [624/1000] completed, Average Training Loss: 0.0535\n",
      "    Validation Batch [1/1], Loss: 0.2077\n",
      "Validation Loss: 0.2077, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2079 to 0.2077. Saving model...\n",
      "\n",
      "LOG: Epoch [625/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [625/1000] completed, Average Training Loss: 0.0424\n",
      "    Validation Batch [1/1], Loss: 0.2127\n",
      "Validation Loss: 0.2127, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [626/1000] - Training\n",
      "Epoch [626/1000] completed, Average Training Loss: 0.0438\n",
      "    Validation Batch [1/1], Loss: 0.2197\n",
      "Validation Loss: 0.2197, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [627/1000] - Training\n",
      "Epoch [627/1000] completed, Average Training Loss: 0.0449\n",
      "    Validation Batch [1/1], Loss: 0.2256\n",
      "Validation Loss: 0.2256, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [628/1000] - Training\n",
      "Epoch [628/1000] completed, Average Training Loss: 0.0316\n",
      "    Validation Batch [1/1], Loss: 0.2306\n",
      "Validation Loss: 0.2306, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [629/1000] - Training\n",
      "Epoch [629/1000] completed, Average Training Loss: 0.0397\n",
      "    Validation Batch [1/1], Loss: 0.2380\n",
      "Validation Loss: 0.2380, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [630/1000] - Training\n",
      "Epoch [630/1000] completed, Average Training Loss: 0.0456\n",
      "    Validation Batch [1/1], Loss: 0.2360\n",
      "Validation Loss: 0.2360, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [631/1000] - Training\n",
      "Epoch [631/1000] completed, Average Training Loss: 0.0440\n",
      "    Validation Batch [1/1], Loss: 0.2314\n",
      "Validation Loss: 0.2314, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [632/1000] - Training\n",
      "Epoch [632/1000] completed, Average Training Loss: 0.0528\n",
      "    Validation Batch [1/1], Loss: 0.2283\n",
      "Validation Loss: 0.2283, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [633/1000] - Training\n",
      "Epoch [633/1000] completed, Average Training Loss: 0.0548\n",
      "    Validation Batch [1/1], Loss: 0.2237\n",
      "Validation Loss: 0.2237, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [634/1000] - Training\n",
      "Epoch [634/1000] completed, Average Training Loss: 0.0459\n",
      "    Validation Batch [1/1], Loss: 0.2234\n",
      "Validation Loss: 0.2234, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [635/1000] - Training\n",
      "Epoch [635/1000] completed, Average Training Loss: 0.0426\n",
      "    Validation Batch [1/1], Loss: 0.2358\n",
      "Validation Loss: 0.2358, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [636/1000] - Training\n",
      "Epoch [636/1000] completed, Average Training Loss: 0.0388\n",
      "    Validation Batch [1/1], Loss: 0.2434\n",
      "Validation Loss: 0.2434, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [637/1000] - Training\n",
      "Epoch [637/1000] completed, Average Training Loss: 0.0455\n",
      "    Validation Batch [1/1], Loss: 0.2526\n",
      "Validation Loss: 0.2526, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [638/1000] - Training\n",
      "Epoch [638/1000] completed, Average Training Loss: 0.0361\n",
      "    Validation Batch [1/1], Loss: 0.2530\n",
      "Validation Loss: 0.2530, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [639/1000] - Training\n",
      "Epoch [639/1000] completed, Average Training Loss: 0.0482\n",
      "    Validation Batch [1/1], Loss: 0.2446\n",
      "Validation Loss: 0.2446, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [640/1000] - Training\n",
      "Epoch [640/1000] completed, Average Training Loss: 0.0400\n",
      "    Validation Batch [1/1], Loss: 0.2331\n",
      "Validation Loss: 0.2331, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [641/1000] - Training\n",
      "Epoch [641/1000] completed, Average Training Loss: 0.0545\n",
      "    Validation Batch [1/1], Loss: 0.2217\n",
      "Validation Loss: 0.2217, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [642/1000] - Training\n",
      "Epoch [642/1000] completed, Average Training Loss: 0.0405\n",
      "    Validation Batch [1/1], Loss: 0.2138\n",
      "Validation Loss: 0.2138, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [643/1000] - Training\n",
      "Epoch [643/1000] completed, Average Training Loss: 0.0393\n",
      "    Validation Batch [1/1], Loss: 0.2125\n",
      "Validation Loss: 0.2125, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [644/1000] - Training\n",
      "Epoch [644/1000] completed, Average Training Loss: 0.0387\n",
      "    Validation Batch [1/1], Loss: 0.2151\n",
      "Validation Loss: 0.2151, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [645/1000] - Training\n",
      "Epoch [645/1000] completed, Average Training Loss: 0.0412\n",
      "    Validation Batch [1/1], Loss: 0.2174\n",
      "Validation Loss: 0.2174, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [646/1000] - Training\n",
      "Epoch [646/1000] completed, Average Training Loss: 0.0467\n",
      "    Validation Batch [1/1], Loss: 0.2200\n",
      "Validation Loss: 0.2200, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [647/1000] - Training\n",
      "Epoch [647/1000] completed, Average Training Loss: 0.0355\n",
      "    Validation Batch [1/1], Loss: 0.2208\n",
      "Validation Loss: 0.2208, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [648/1000] - Training\n",
      "Epoch [648/1000] completed, Average Training Loss: 0.0363\n",
      "    Validation Batch [1/1], Loss: 0.2189\n",
      "Validation Loss: 0.2189, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [649/1000] - Training\n",
      "Epoch [649/1000] completed, Average Training Loss: 0.0495\n",
      "    Validation Batch [1/1], Loss: 0.2158\n",
      "Validation Loss: 0.2158, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [650/1000] - Training\n",
      "Epoch [650/1000] completed, Average Training Loss: 0.0371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.2112\n",
      "Validation Loss: 0.2112, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [651/1000] - Training\n",
      "Epoch [651/1000] completed, Average Training Loss: 0.0360\n",
      "    Validation Batch [1/1], Loss: 0.2087\n",
      "Validation Loss: 0.2087, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [652/1000] - Training\n",
      "Epoch [652/1000] completed, Average Training Loss: 0.0459\n",
      "    Validation Batch [1/1], Loss: 0.2097\n",
      "Validation Loss: 0.2097, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [653/1000] - Training\n",
      "Epoch [653/1000] completed, Average Training Loss: 0.0420\n",
      "    Validation Batch [1/1], Loss: 0.2072\n",
      "Validation Loss: 0.2072, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2077 to 0.2072. Saving model...\n",
      "\n",
      "LOG: Epoch [654/1000] - Training\n",
      "Epoch [654/1000] completed, Average Training Loss: 0.0463\n",
      "    Validation Batch [1/1], Loss: 0.2130\n",
      "Validation Loss: 0.2130, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [655/1000] - Training\n",
      "Epoch [655/1000] completed, Average Training Loss: 0.0435\n",
      "    Validation Batch [1/1], Loss: 0.2216\n",
      "Validation Loss: 0.2216, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [656/1000] - Training\n",
      "Epoch [656/1000] completed, Average Training Loss: 0.0427\n",
      "    Validation Batch [1/1], Loss: 0.2305\n",
      "Validation Loss: 0.2305, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [657/1000] - Training\n",
      "Epoch [657/1000] completed, Average Training Loss: 0.0427\n",
      "    Validation Batch [1/1], Loss: 0.2368\n",
      "Validation Loss: 0.2368, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [658/1000] - Training\n",
      "Epoch [658/1000] completed, Average Training Loss: 0.0494\n",
      "    Validation Batch [1/1], Loss: 0.2380\n",
      "Validation Loss: 0.2380, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [659/1000] - Training\n",
      "Epoch [659/1000] completed, Average Training Loss: 0.0303\n",
      "    Validation Batch [1/1], Loss: 0.2284\n",
      "Validation Loss: 0.2284, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [660/1000] - Training\n",
      "Epoch [660/1000] completed, Average Training Loss: 0.0474\n",
      "    Validation Batch [1/1], Loss: 0.2162\n",
      "Validation Loss: 0.2162, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [661/1000] - Training\n",
      "Epoch [661/1000] completed, Average Training Loss: 0.0430\n",
      "    Validation Batch [1/1], Loss: 0.2055\n",
      "Validation Loss: 0.2055, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2072 to 0.2055. Saving model...\n",
      "\n",
      "LOG: Epoch [662/1000] - Training\n",
      "Epoch [662/1000] completed, Average Training Loss: 0.0455\n",
      "    Validation Batch [1/1], Loss: 0.1998\n",
      "Validation Loss: 0.1998, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.2055 to 0.1998. Saving model...\n",
      "\n",
      "LOG: Epoch [663/1000] - Training\n",
      "Epoch [663/1000] completed, Average Training Loss: 0.0429\n",
      "    Validation Batch [1/1], Loss: 0.2023\n",
      "Validation Loss: 0.2023, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [664/1000] - Training\n",
      "Epoch [664/1000] completed, Average Training Loss: 0.0377\n",
      "    Validation Batch [1/1], Loss: 0.2111\n",
      "Validation Loss: 0.2111, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [665/1000] - Training\n",
      "Epoch [665/1000] completed, Average Training Loss: 0.0470\n",
      "    Validation Batch [1/1], Loss: 0.2145\n",
      "Validation Loss: 0.2145, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [666/1000] - Training\n",
      "Epoch [666/1000] completed, Average Training Loss: 0.0560\n",
      "    Validation Batch [1/1], Loss: 0.2134\n",
      "Validation Loss: 0.2134, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [667/1000] - Training\n",
      "Epoch [667/1000] completed, Average Training Loss: 0.0341\n",
      "    Validation Batch [1/1], Loss: 0.2131\n",
      "Validation Loss: 0.2131, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [668/1000] - Training\n",
      "Epoch [668/1000] completed, Average Training Loss: 0.0399\n",
      "    Validation Batch [1/1], Loss: 0.2123\n",
      "Validation Loss: 0.2123, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [669/1000] - Training\n",
      "Epoch [669/1000] completed, Average Training Loss: 0.0336\n",
      "    Validation Batch [1/1], Loss: 0.2168\n",
      "Validation Loss: 0.2168, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [670/1000] - Training\n",
      "Epoch [670/1000] completed, Average Training Loss: 0.0429\n",
      "    Validation Batch [1/1], Loss: 0.2260\n",
      "Validation Loss: 0.2260, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [671/1000] - Training\n",
      "Epoch [671/1000] completed, Average Training Loss: 0.0364\n",
      "    Validation Batch [1/1], Loss: 0.2330\n",
      "Validation Loss: 0.2330, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [672/1000] - Training\n",
      "Epoch [672/1000] completed, Average Training Loss: 0.0430\n",
      "    Validation Batch [1/1], Loss: 0.2376\n",
      "Validation Loss: 0.2376, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [673/1000] - Training\n",
      "Epoch [673/1000] completed, Average Training Loss: 0.0412\n",
      "    Validation Batch [1/1], Loss: 0.2393\n",
      "Validation Loss: 0.2393, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [674/1000] - Training\n",
      "Epoch [674/1000] completed, Average Training Loss: 0.0311\n",
      "    Validation Batch [1/1], Loss: 0.2371\n",
      "Validation Loss: 0.2371, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [675/1000] - Training\n",
      "Epoch [675/1000] completed, Average Training Loss: 0.0350\n",
      "    Validation Batch [1/1], Loss: 0.2318\n",
      "Validation Loss: 0.2318, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [676/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [676/1000] completed, Average Training Loss: 0.0526\n",
      "    Validation Batch [1/1], Loss: 0.2241\n",
      "Validation Loss: 0.2241, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [677/1000] - Training\n",
      "Epoch [677/1000] completed, Average Training Loss: 0.0525\n",
      "    Validation Batch [1/1], Loss: 0.2152\n",
      "Validation Loss: 0.2152, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [678/1000] - Training\n",
      "Epoch [678/1000] completed, Average Training Loss: 0.0384\n",
      "    Validation Batch [1/1], Loss: 0.2065\n",
      "Validation Loss: 0.2065, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [679/1000] - Training\n",
      "Epoch [679/1000] completed, Average Training Loss: 0.0391\n",
      "    Validation Batch [1/1], Loss: 0.2037\n",
      "Validation Loss: 0.2037, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [680/1000] - Training\n",
      "Epoch [680/1000] completed, Average Training Loss: 0.0498\n",
      "    Validation Batch [1/1], Loss: 0.2038\n",
      "Validation Loss: 0.2038, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [681/1000] - Training\n",
      "Epoch [681/1000] completed, Average Training Loss: 0.0311\n",
      "    Validation Batch [1/1], Loss: 0.2097\n",
      "Validation Loss: 0.2097, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [682/1000] - Training\n",
      "Epoch [682/1000] completed, Average Training Loss: 0.0310\n",
      "    Validation Batch [1/1], Loss: 0.2132\n",
      "Validation Loss: 0.2132, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [683/1000] - Training\n",
      "Epoch [683/1000] completed, Average Training Loss: 0.0312\n",
      "    Validation Batch [1/1], Loss: 0.2139\n",
      "Validation Loss: 0.2139, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [684/1000] - Training\n",
      "Epoch [684/1000] completed, Average Training Loss: 0.0366\n",
      "    Validation Batch [1/1], Loss: 0.2093\n",
      "Validation Loss: 0.2093, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [685/1000] - Training\n",
      "Epoch [685/1000] completed, Average Training Loss: 0.0541\n",
      "    Validation Batch [1/1], Loss: 0.2072\n",
      "Validation Loss: 0.2072, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [686/1000] - Training\n",
      "Epoch [686/1000] completed, Average Training Loss: 0.0285\n",
      "    Validation Batch [1/1], Loss: 0.2064\n",
      "Validation Loss: 0.2064, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [687/1000] - Training\n",
      "Epoch [687/1000] completed, Average Training Loss: 0.0560\n",
      "    Validation Batch [1/1], Loss: 0.2063\n",
      "Validation Loss: 0.2063, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [688/1000] - Training\n",
      "Epoch [688/1000] completed, Average Training Loss: 0.0342\n",
      "    Validation Batch [1/1], Loss: 0.2098\n",
      "Validation Loss: 0.2098, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [689/1000] - Training\n",
      "Epoch [689/1000] completed, Average Training Loss: 0.0379\n",
      "    Validation Batch [1/1], Loss: 0.2126\n",
      "Validation Loss: 0.2126, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [690/1000] - Training\n",
      "Epoch [690/1000] completed, Average Training Loss: 0.0328\n",
      "    Validation Batch [1/1], Loss: 0.2148\n",
      "Validation Loss: 0.2148, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [691/1000] - Training\n",
      "Epoch [691/1000] completed, Average Training Loss: 0.0452\n",
      "    Validation Batch [1/1], Loss: 0.2190\n",
      "Validation Loss: 0.2190, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [692/1000] - Training\n",
      "Epoch [692/1000] completed, Average Training Loss: 0.0295\n",
      "    Validation Batch [1/1], Loss: 0.2249\n",
      "Validation Loss: 0.2249, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [693/1000] - Training\n",
      "Epoch [693/1000] completed, Average Training Loss: 0.0331\n",
      "    Validation Batch [1/1], Loss: 0.2273\n",
      "Validation Loss: 0.2273, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [694/1000] - Training\n",
      "Epoch [694/1000] completed, Average Training Loss: 0.0370\n",
      "    Validation Batch [1/1], Loss: 0.2313\n",
      "Validation Loss: 0.2313, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [695/1000] - Training\n",
      "Epoch [695/1000] completed, Average Training Loss: 0.0338\n",
      "    Validation Batch [1/1], Loss: 0.2261\n",
      "Validation Loss: 0.2261, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [696/1000] - Training\n",
      "Epoch [696/1000] completed, Average Training Loss: 0.0322\n",
      "    Validation Batch [1/1], Loss: 0.2131\n",
      "Validation Loss: 0.2131, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [697/1000] - Training\n",
      "Epoch [697/1000] completed, Average Training Loss: 0.0451\n",
      "    Validation Batch [1/1], Loss: 0.2040\n",
      "Validation Loss: 0.2040, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [698/1000] - Training\n",
      "Epoch [698/1000] completed, Average Training Loss: 0.0381\n",
      "    Validation Batch [1/1], Loss: 0.2048\n",
      "Validation Loss: 0.2048, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [699/1000] - Training\n",
      "Epoch [699/1000] completed, Average Training Loss: 0.0342\n",
      "    Validation Batch [1/1], Loss: 0.2146\n",
      "Validation Loss: 0.2146, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [700/1000] - Training\n",
      "Epoch [700/1000] completed, Average Training Loss: 0.0382\n",
      "    Validation Batch [1/1], Loss: 0.2192\n",
      "Validation Loss: 0.2192, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [701/1000] - Training\n",
      "Epoch [701/1000] completed, Average Training Loss: 0.0310\n",
      "    Validation Batch [1/1], Loss: 0.2177\n",
      "Validation Loss: 0.2177, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [702/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [702/1000] completed, Average Training Loss: 0.0319\n",
      "    Validation Batch [1/1], Loss: 0.2163\n",
      "Validation Loss: 0.2163, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [703/1000] - Training\n",
      "Epoch [703/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.2155\n",
      "Validation Loss: 0.2155, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [704/1000] - Training\n",
      "Epoch [704/1000] completed, Average Training Loss: 0.0346\n",
      "    Validation Batch [1/1], Loss: 0.2204\n",
      "Validation Loss: 0.2204, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [705/1000] - Training\n",
      "Epoch [705/1000] completed, Average Training Loss: 0.0329\n",
      "    Validation Batch [1/1], Loss: 0.2236\n",
      "Validation Loss: 0.2236, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [706/1000] - Training\n",
      "Epoch [706/1000] completed, Average Training Loss: 0.0384\n",
      "    Validation Batch [1/1], Loss: 0.2217\n",
      "Validation Loss: 0.2217, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [707/1000] - Training\n",
      "Epoch [707/1000] completed, Average Training Loss: 0.0362\n",
      "    Validation Batch [1/1], Loss: 0.2131\n",
      "Validation Loss: 0.2131, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [708/1000] - Training\n",
      "Epoch [708/1000] completed, Average Training Loss: 0.0365\n",
      "    Validation Batch [1/1], Loss: 0.2070\n",
      "Validation Loss: 0.2070, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [709/1000] - Training\n",
      "Epoch [709/1000] completed, Average Training Loss: 0.0407\n",
      "    Validation Batch [1/1], Loss: 0.2050\n",
      "Validation Loss: 0.2050, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [710/1000] - Training\n",
      "Epoch [710/1000] completed, Average Training Loss: 0.0339\n",
      "    Validation Batch [1/1], Loss: 0.2086\n",
      "Validation Loss: 0.2086, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [711/1000] - Training\n",
      "Epoch [711/1000] completed, Average Training Loss: 0.0345\n",
      "    Validation Batch [1/1], Loss: 0.2066\n",
      "Validation Loss: 0.2066, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [712/1000] - Training\n",
      "Epoch [712/1000] completed, Average Training Loss: 0.0398\n",
      "    Validation Batch [1/1], Loss: 0.2002\n",
      "Validation Loss: 0.2002, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [713/1000] - Training\n",
      "Epoch [713/1000] completed, Average Training Loss: 0.0399\n",
      "    Validation Batch [1/1], Loss: 0.1998\n",
      "Validation Loss: 0.1998, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [714/1000] - Training\n",
      "Epoch [714/1000] completed, Average Training Loss: 0.0300\n",
      "    Validation Batch [1/1], Loss: 0.2093\n",
      "Validation Loss: 0.2093, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [715/1000] - Training\n",
      "Epoch [715/1000] completed, Average Training Loss: 0.0381\n",
      "    Validation Batch [1/1], Loss: 0.2216\n",
      "Validation Loss: 0.2216, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [716/1000] - Training\n",
      "Epoch [716/1000] completed, Average Training Loss: 0.0384\n",
      "    Validation Batch [1/1], Loss: 0.2447\n",
      "Validation Loss: 0.2447, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [717/1000] - Training\n",
      "Epoch [717/1000] completed, Average Training Loss: 0.0392\n",
      "    Validation Batch [1/1], Loss: 0.2412\n",
      "Validation Loss: 0.2412, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [718/1000] - Training\n",
      "Epoch [718/1000] completed, Average Training Loss: 0.0310\n",
      "    Validation Batch [1/1], Loss: 0.2265\n",
      "Validation Loss: 0.2265, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [719/1000] - Training\n",
      "Epoch [719/1000] completed, Average Training Loss: 0.0356\n",
      "    Validation Batch [1/1], Loss: 0.2111\n",
      "Validation Loss: 0.2111, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [720/1000] - Training\n",
      "Epoch [720/1000] completed, Average Training Loss: 0.0364\n",
      "    Validation Batch [1/1], Loss: 0.2025\n",
      "Validation Loss: 0.2025, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [721/1000] - Training\n",
      "Epoch [721/1000] completed, Average Training Loss: 0.0265\n",
      "    Validation Batch [1/1], Loss: 0.2002\n",
      "Validation Loss: 0.2002, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [722/1000] - Training\n",
      "Epoch [722/1000] completed, Average Training Loss: 0.0294\n",
      "    Validation Batch [1/1], Loss: 0.1991\n",
      "Validation Loss: 0.1991, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.1998 to 0.1991. Saving model...\n",
      "\n",
      "LOG: Epoch [723/1000] - Training\n",
      "Epoch [723/1000] completed, Average Training Loss: 0.0362\n",
      "    Validation Batch [1/1], Loss: 0.2011\n",
      "Validation Loss: 0.2011, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [724/1000] - Training\n",
      "Epoch [724/1000] completed, Average Training Loss: 0.0362\n",
      "    Validation Batch [1/1], Loss: 0.2017\n",
      "Validation Loss: 0.2017, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [725/1000] - Training\n",
      "Epoch [725/1000] completed, Average Training Loss: 0.0317\n",
      "    Validation Batch [1/1], Loss: 0.2080\n",
      "Validation Loss: 0.2080, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [726/1000] - Training\n",
      "Epoch [726/1000] completed, Average Training Loss: 0.0278\n",
      "    Validation Batch [1/1], Loss: 0.2184\n",
      "Validation Loss: 0.2184, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [727/1000] - Training\n",
      "Epoch [727/1000] completed, Average Training Loss: 0.0397\n",
      "    Validation Batch [1/1], Loss: 0.2239\n",
      "Validation Loss: 0.2239, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [728/1000] - Training\n",
      "Epoch [728/1000] completed, Average Training Loss: 0.0404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.2094\n",
      "Validation Loss: 0.2094, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [729/1000] - Training\n",
      "Epoch [729/1000] completed, Average Training Loss: 0.0321\n",
      "    Validation Batch [1/1], Loss: 0.2012\n",
      "Validation Loss: 0.2012, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [730/1000] - Training\n",
      "Epoch [730/1000] completed, Average Training Loss: 0.0504\n",
      "    Validation Batch [1/1], Loss: 0.1935\n",
      "Validation Loss: 0.1935, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.1991 to 0.1935. Saving model...\n",
      "\n",
      "LOG: Epoch [731/1000] - Training\n",
      "Epoch [731/1000] completed, Average Training Loss: 0.0310\n",
      "    Validation Batch [1/1], Loss: 0.1920\n",
      "Validation Loss: 0.1920, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.1935 to 0.1920. Saving model...\n",
      "\n",
      "LOG: Epoch [732/1000] - Training\n",
      "Epoch [732/1000] completed, Average Training Loss: 0.0278\n",
      "    Validation Batch [1/1], Loss: 0.1997\n",
      "Validation Loss: 0.1997, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [733/1000] - Training\n",
      "Epoch [733/1000] completed, Average Training Loss: 0.0278\n",
      "    Validation Batch [1/1], Loss: 0.2056\n",
      "Validation Loss: 0.2056, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [734/1000] - Training\n",
      "Epoch [734/1000] completed, Average Training Loss: 0.0297\n",
      "    Validation Batch [1/1], Loss: 0.2078\n",
      "Validation Loss: 0.2078, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [735/1000] - Training\n",
      "Epoch [735/1000] completed, Average Training Loss: 0.0337\n",
      "    Validation Batch [1/1], Loss: 0.2166\n",
      "Validation Loss: 0.2166, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [736/1000] - Training\n",
      "Epoch [736/1000] completed, Average Training Loss: 0.0328\n",
      "    Validation Batch [1/1], Loss: 0.2249\n",
      "Validation Loss: 0.2249, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [737/1000] - Training\n",
      "Epoch [737/1000] completed, Average Training Loss: 0.0333\n",
      "    Validation Batch [1/1], Loss: 0.2316\n",
      "Validation Loss: 0.2316, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [738/1000] - Training\n",
      "Epoch [738/1000] completed, Average Training Loss: 0.0282\n",
      "    Validation Batch [1/1], Loss: 0.2317\n",
      "Validation Loss: 0.2317, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [739/1000] - Training\n",
      "Epoch [739/1000] completed, Average Training Loss: 0.0312\n",
      "    Validation Batch [1/1], Loss: 0.2228\n",
      "Validation Loss: 0.2228, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [740/1000] - Training\n",
      "Epoch [740/1000] completed, Average Training Loss: 0.0370\n",
      "    Validation Batch [1/1], Loss: 0.2181\n",
      "Validation Loss: 0.2181, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [741/1000] - Training\n",
      "Epoch [741/1000] completed, Average Training Loss: 0.0308\n",
      "    Validation Batch [1/1], Loss: 0.2151\n",
      "Validation Loss: 0.2151, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [742/1000] - Training\n",
      "Epoch [742/1000] completed, Average Training Loss: 0.0301\n",
      "    Validation Batch [1/1], Loss: 0.2176\n",
      "Validation Loss: 0.2176, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [743/1000] - Training\n",
      "Epoch [743/1000] completed, Average Training Loss: 0.0269\n",
      "    Validation Batch [1/1], Loss: 0.2243\n",
      "Validation Loss: 0.2243, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [744/1000] - Training\n",
      "Epoch [744/1000] completed, Average Training Loss: 0.0365\n",
      "    Validation Batch [1/1], Loss: 0.2316\n",
      "Validation Loss: 0.2316, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [745/1000] - Training\n",
      "Epoch [745/1000] completed, Average Training Loss: 0.0280\n",
      "    Validation Batch [1/1], Loss: 0.2284\n",
      "Validation Loss: 0.2284, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [746/1000] - Training\n",
      "Epoch [746/1000] completed, Average Training Loss: 0.0332\n",
      "    Validation Batch [1/1], Loss: 0.2225\n",
      "Validation Loss: 0.2225, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [747/1000] - Training\n",
      "Epoch [747/1000] completed, Average Training Loss: 0.0412\n",
      "    Validation Batch [1/1], Loss: 0.2121\n",
      "Validation Loss: 0.2121, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [748/1000] - Training\n",
      "Epoch [748/1000] completed, Average Training Loss: 0.0326\n",
      "    Validation Batch [1/1], Loss: 0.2058\n",
      "Validation Loss: 0.2058, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [749/1000] - Training\n",
      "Epoch [749/1000] completed, Average Training Loss: 0.0233\n",
      "    Validation Batch [1/1], Loss: 0.2052\n",
      "Validation Loss: 0.2052, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [750/1000] - Training\n",
      "Epoch [750/1000] completed, Average Training Loss: 0.0271\n",
      "    Validation Batch [1/1], Loss: 0.2145\n",
      "Validation Loss: 0.2145, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [751/1000] - Training\n",
      "Epoch [751/1000] completed, Average Training Loss: 0.0332\n",
      "    Validation Batch [1/1], Loss: 0.2259\n",
      "Validation Loss: 0.2259, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [752/1000] - Training\n",
      "Epoch [752/1000] completed, Average Training Loss: 0.0300\n",
      "    Validation Batch [1/1], Loss: 0.2300\n",
      "Validation Loss: 0.2300, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [753/1000] - Training\n",
      "Epoch [753/1000] completed, Average Training Loss: 0.0325\n",
      "    Validation Batch [1/1], Loss: 0.2354\n",
      "Validation Loss: 0.2354, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [754/1000] - Training\n",
      "Epoch [754/1000] completed, Average Training Loss: 0.0307\n",
      "    Validation Batch [1/1], Loss: 0.2429\n",
      "Validation Loss: 0.2429, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [755/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [755/1000] completed, Average Training Loss: 0.0206\n",
      "    Validation Batch [1/1], Loss: 0.2482\n",
      "Validation Loss: 0.2482, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [756/1000] - Training\n",
      "Epoch [756/1000] completed, Average Training Loss: 0.0233\n",
      "    Validation Batch [1/1], Loss: 0.2431\n",
      "Validation Loss: 0.2431, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [757/1000] - Training\n",
      "Epoch [757/1000] completed, Average Training Loss: 0.0387\n",
      "    Validation Batch [1/1], Loss: 0.2425\n",
      "Validation Loss: 0.2425, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [758/1000] - Training\n",
      "Epoch [758/1000] completed, Average Training Loss: 0.0240\n",
      "    Validation Batch [1/1], Loss: 0.2436\n",
      "Validation Loss: 0.2436, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [759/1000] - Training\n",
      "Epoch [759/1000] completed, Average Training Loss: 0.0273\n",
      "    Validation Batch [1/1], Loss: 0.2408\n",
      "Validation Loss: 0.2408, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [760/1000] - Training\n",
      "Epoch [760/1000] completed, Average Training Loss: 0.0245\n",
      "    Validation Batch [1/1], Loss: 0.2358\n",
      "Validation Loss: 0.2358, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [761/1000] - Training\n",
      "Epoch [761/1000] completed, Average Training Loss: 0.0297\n",
      "    Validation Batch [1/1], Loss: 0.2224\n",
      "Validation Loss: 0.2224, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [762/1000] - Training\n",
      "Epoch [762/1000] completed, Average Training Loss: 0.0325\n",
      "    Validation Batch [1/1], Loss: 0.2119\n",
      "Validation Loss: 0.2119, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [763/1000] - Training\n",
      "Epoch [763/1000] completed, Average Training Loss: 0.0246\n",
      "    Validation Batch [1/1], Loss: 0.2108\n",
      "Validation Loss: 0.2108, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [764/1000] - Training\n",
      "Epoch [764/1000] completed, Average Training Loss: 0.0278\n",
      "    Validation Batch [1/1], Loss: 0.2123\n",
      "Validation Loss: 0.2123, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [765/1000] - Training\n",
      "Epoch [765/1000] completed, Average Training Loss: 0.0249\n",
      "    Validation Batch [1/1], Loss: 0.2168\n",
      "Validation Loss: 0.2168, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [766/1000] - Training\n",
      "Epoch [766/1000] completed, Average Training Loss: 0.0332\n",
      "    Validation Batch [1/1], Loss: 0.2204\n",
      "Validation Loss: 0.2204, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [767/1000] - Training\n",
      "Epoch [767/1000] completed, Average Training Loss: 0.0283\n",
      "    Validation Batch [1/1], Loss: 0.2194\n",
      "Validation Loss: 0.2194, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [768/1000] - Training\n",
      "Epoch [768/1000] completed, Average Training Loss: 0.0290\n",
      "    Validation Batch [1/1], Loss: 0.2127\n",
      "Validation Loss: 0.2127, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [769/1000] - Training\n",
      "Epoch [769/1000] completed, Average Training Loss: 0.0235\n",
      "    Validation Batch [1/1], Loss: 0.2080\n",
      "Validation Loss: 0.2080, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [770/1000] - Training\n",
      "Epoch [770/1000] completed, Average Training Loss: 0.0319\n",
      "    Validation Batch [1/1], Loss: 0.1988\n",
      "Validation Loss: 0.1988, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [771/1000] - Training\n",
      "Epoch [771/1000] completed, Average Training Loss: 0.0366\n",
      "    Validation Batch [1/1], Loss: 0.1924\n",
      "Validation Loss: 0.1924, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [772/1000] - Training\n",
      "Epoch [772/1000] completed, Average Training Loss: 0.0283\n",
      "    Validation Batch [1/1], Loss: 0.1910\n",
      "Validation Loss: 0.1910, Validation Accuracy: 92.86%\n",
      "Validation loss improved from 0.1920 to 0.1910. Saving model...\n",
      "\n",
      "LOG: Epoch [773/1000] - Training\n",
      "Epoch [773/1000] completed, Average Training Loss: 0.0273\n",
      "    Validation Batch [1/1], Loss: 0.1924\n",
      "Validation Loss: 0.1924, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [774/1000] - Training\n",
      "Epoch [774/1000] completed, Average Training Loss: 0.0254\n",
      "    Validation Batch [1/1], Loss: 0.1980\n",
      "Validation Loss: 0.1980, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [775/1000] - Training\n",
      "Epoch [775/1000] completed, Average Training Loss: 0.0259\n",
      "    Validation Batch [1/1], Loss: 0.2027\n",
      "Validation Loss: 0.2027, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [776/1000] - Training\n",
      "Epoch [776/1000] completed, Average Training Loss: 0.0273\n",
      "    Validation Batch [1/1], Loss: 0.2056\n",
      "Validation Loss: 0.2056, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [777/1000] - Training\n",
      "Epoch [777/1000] completed, Average Training Loss: 0.0341\n",
      "    Validation Batch [1/1], Loss: 0.2051\n",
      "Validation Loss: 0.2051, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [778/1000] - Training\n",
      "Epoch [778/1000] completed, Average Training Loss: 0.0252\n",
      "    Validation Batch [1/1], Loss: 0.2071\n",
      "Validation Loss: 0.2071, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [779/1000] - Training\n",
      "Epoch [779/1000] completed, Average Training Loss: 0.0261\n",
      "    Validation Batch [1/1], Loss: 0.2082\n",
      "Validation Loss: 0.2082, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [780/1000] - Training\n",
      "Epoch [780/1000] completed, Average Training Loss: 0.0266\n",
      "    Validation Batch [1/1], Loss: 0.2108\n",
      "Validation Loss: 0.2108, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [781/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [781/1000] completed, Average Training Loss: 0.0262\n",
      "    Validation Batch [1/1], Loss: 0.2154\n",
      "Validation Loss: 0.2154, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [782/1000] - Training\n",
      "Epoch [782/1000] completed, Average Training Loss: 0.0273\n",
      "    Validation Batch [1/1], Loss: 0.2220\n",
      "Validation Loss: 0.2220, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [783/1000] - Training\n",
      "Epoch [783/1000] completed, Average Training Loss: 0.0273\n",
      "    Validation Batch [1/1], Loss: 0.2255\n",
      "Validation Loss: 0.2255, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [784/1000] - Training\n",
      "Epoch [784/1000] completed, Average Training Loss: 0.0294\n",
      "    Validation Batch [1/1], Loss: 0.2260\n",
      "Validation Loss: 0.2260, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [785/1000] - Training\n",
      "Epoch [785/1000] completed, Average Training Loss: 0.0226\n",
      "    Validation Batch [1/1], Loss: 0.2261\n",
      "Validation Loss: 0.2261, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [786/1000] - Training\n",
      "Epoch [786/1000] completed, Average Training Loss: 0.0273\n",
      "    Validation Batch [1/1], Loss: 0.2245\n",
      "Validation Loss: 0.2245, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [787/1000] - Training\n",
      "Epoch [787/1000] completed, Average Training Loss: 0.0384\n",
      "    Validation Batch [1/1], Loss: 0.2165\n",
      "Validation Loss: 0.2165, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [788/1000] - Training\n",
      "Epoch [788/1000] completed, Average Training Loss: 0.0259\n",
      "    Validation Batch [1/1], Loss: 0.2017\n",
      "Validation Loss: 0.2017, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [789/1000] - Training\n",
      "Epoch [789/1000] completed, Average Training Loss: 0.0349\n",
      "    Validation Batch [1/1], Loss: 0.1911\n",
      "Validation Loss: 0.1911, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [790/1000] - Training\n",
      "Epoch [790/1000] completed, Average Training Loss: 0.0304\n",
      "    Validation Batch [1/1], Loss: 0.1921\n",
      "Validation Loss: 0.1921, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [791/1000] - Training\n",
      "Epoch [791/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.1959\n",
      "Validation Loss: 0.1959, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [792/1000] - Training\n",
      "Epoch [792/1000] completed, Average Training Loss: 0.0207\n",
      "    Validation Batch [1/1], Loss: 0.1973\n",
      "Validation Loss: 0.1973, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [793/1000] - Training\n",
      "Epoch [793/1000] completed, Average Training Loss: 0.0293\n",
      "    Validation Batch [1/1], Loss: 0.1925\n",
      "Validation Loss: 0.1925, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [794/1000] - Training\n",
      "Epoch [794/1000] completed, Average Training Loss: 0.0214\n",
      "    Validation Batch [1/1], Loss: 0.1901\n",
      "Validation Loss: 0.1901, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.1910 to 0.1901. Saving model...\n",
      "\n",
      "LOG: Epoch [795/1000] - Training\n",
      "Epoch [795/1000] completed, Average Training Loss: 0.0269\n",
      "    Validation Batch [1/1], Loss: 0.1922\n",
      "Validation Loss: 0.1922, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [796/1000] - Training\n",
      "Epoch [796/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.1989\n",
      "Validation Loss: 0.1989, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [797/1000] - Training\n",
      "Epoch [797/1000] completed, Average Training Loss: 0.0240\n",
      "    Validation Batch [1/1], Loss: 0.2082\n",
      "Validation Loss: 0.2082, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [798/1000] - Training\n",
      "Epoch [798/1000] completed, Average Training Loss: 0.0201\n",
      "    Validation Batch [1/1], Loss: 0.2219\n",
      "Validation Loss: 0.2219, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [799/1000] - Training\n",
      "Epoch [799/1000] completed, Average Training Loss: 0.0221\n",
      "    Validation Batch [1/1], Loss: 0.2261\n",
      "Validation Loss: 0.2261, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [800/1000] - Training\n",
      "Epoch [800/1000] completed, Average Training Loss: 0.0300\n",
      "    Validation Batch [1/1], Loss: 0.2243\n",
      "Validation Loss: 0.2243, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [801/1000] - Training\n",
      "Epoch [801/1000] completed, Average Training Loss: 0.0219\n",
      "    Validation Batch [1/1], Loss: 0.2188\n",
      "Validation Loss: 0.2188, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [802/1000] - Training\n",
      "Epoch [802/1000] completed, Average Training Loss: 0.0216\n",
      "    Validation Batch [1/1], Loss: 0.2127\n",
      "Validation Loss: 0.2127, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [803/1000] - Training\n",
      "Epoch [803/1000] completed, Average Training Loss: 0.0214\n",
      "    Validation Batch [1/1], Loss: 0.2069\n",
      "Validation Loss: 0.2069, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [804/1000] - Training\n",
      "Epoch [804/1000] completed, Average Training Loss: 0.0217\n",
      "    Validation Batch [1/1], Loss: 0.2014\n",
      "Validation Loss: 0.2014, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [805/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [805/1000] completed, Average Training Loss: 0.0246\n",
      "    Validation Batch [1/1], Loss: 0.2007\n",
      "Validation Loss: 0.2007, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [806/1000] - Training\n",
      "Epoch [806/1000] completed, Average Training Loss: 0.0242\n",
      "    Validation Batch [1/1], Loss: 0.2008\n",
      "Validation Loss: 0.2008, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [807/1000] - Training\n",
      "Epoch [807/1000] completed, Average Training Loss: 0.0261\n",
      "    Validation Batch [1/1], Loss: 0.2038\n",
      "Validation Loss: 0.2038, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [808/1000] - Training\n",
      "Epoch [808/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.2070\n",
      "Validation Loss: 0.2070, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [809/1000] - Training\n",
      "Epoch [809/1000] completed, Average Training Loss: 0.0212\n",
      "    Validation Batch [1/1], Loss: 0.2141\n",
      "Validation Loss: 0.2141, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [810/1000] - Training\n",
      "Epoch [810/1000] completed, Average Training Loss: 0.0220\n",
      "    Validation Batch [1/1], Loss: 0.2141\n",
      "Validation Loss: 0.2141, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [811/1000] - Training\n",
      "Epoch [811/1000] completed, Average Training Loss: 0.0301\n",
      "    Validation Batch [1/1], Loss: 0.2150\n",
      "Validation Loss: 0.2150, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [812/1000] - Training\n",
      "Epoch [812/1000] completed, Average Training Loss: 0.0235\n",
      "    Validation Batch [1/1], Loss: 0.2072\n",
      "Validation Loss: 0.2072, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [813/1000] - Training\n",
      "Epoch [813/1000] completed, Average Training Loss: 0.0303\n",
      "    Validation Batch [1/1], Loss: 0.2010\n",
      "Validation Loss: 0.2010, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [814/1000] - Training\n",
      "Epoch [814/1000] completed, Average Training Loss: 0.0309\n",
      "    Validation Batch [1/1], Loss: 0.1998\n",
      "Validation Loss: 0.1998, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [815/1000] - Training\n",
      "Epoch [815/1000] completed, Average Training Loss: 0.0338\n",
      "    Validation Batch [1/1], Loss: 0.2023\n",
      "Validation Loss: 0.2023, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [816/1000] - Training\n",
      "Epoch [816/1000] completed, Average Training Loss: 0.0312\n",
      "    Validation Batch [1/1], Loss: 0.2037\n",
      "Validation Loss: 0.2037, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [817/1000] - Training\n",
      "Epoch [817/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.2024\n",
      "Validation Loss: 0.2024, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [818/1000] - Training\n",
      "Epoch [818/1000] completed, Average Training Loss: 0.0251\n",
      "    Validation Batch [1/1], Loss: 0.2020\n",
      "Validation Loss: 0.2020, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [819/1000] - Training\n",
      "Epoch [819/1000] completed, Average Training Loss: 0.0294\n",
      "    Validation Batch [1/1], Loss: 0.2106\n",
      "Validation Loss: 0.2106, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [820/1000] - Training\n",
      "Epoch [820/1000] completed, Average Training Loss: 0.0174\n",
      "    Validation Batch [1/1], Loss: 0.2227\n",
      "Validation Loss: 0.2227, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [821/1000] - Training\n",
      "Epoch [821/1000] completed, Average Training Loss: 0.0197\n",
      "    Validation Batch [1/1], Loss: 0.2339\n",
      "Validation Loss: 0.2339, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [822/1000] - Training\n",
      "Epoch [822/1000] completed, Average Training Loss: 0.0209\n",
      "    Validation Batch [1/1], Loss: 0.2385\n",
      "Validation Loss: 0.2385, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [823/1000] - Training\n",
      "Epoch [823/1000] completed, Average Training Loss: 0.0203\n",
      "    Validation Batch [1/1], Loss: 0.2274\n",
      "Validation Loss: 0.2274, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [824/1000] - Training\n",
      "Epoch [824/1000] completed, Average Training Loss: 0.0284\n",
      "    Validation Batch [1/1], Loss: 0.2059\n",
      "Validation Loss: 0.2059, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [825/1000] - Training\n",
      "Epoch [825/1000] completed, Average Training Loss: 0.0256\n",
      "    Validation Batch [1/1], Loss: 0.1847\n",
      "Validation Loss: 0.1847, Validation Accuracy: 95.71%\n",
      "Validation loss improved from 0.1901 to 0.1847. Saving model...\n",
      "\n",
      "LOG: Epoch [826/1000] - Training\n",
      "Epoch [826/1000] completed, Average Training Loss: 0.0221\n",
      "    Validation Batch [1/1], Loss: 0.1727\n",
      "Validation Loss: 0.1727, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.1847 to 0.1727. Saving model...\n",
      "\n",
      "LOG: Epoch [827/1000] - Training\n",
      "Epoch [827/1000] completed, Average Training Loss: 0.0199\n",
      "    Validation Batch [1/1], Loss: 0.1688\n",
      "Validation Loss: 0.1688, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.1727 to 0.1688. Saving model...\n",
      "\n",
      "LOG: Epoch [828/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [828/1000] completed, Average Training Loss: 0.0278\n",
      "    Validation Batch [1/1], Loss: 0.1683\n",
      "Validation Loss: 0.1683, Validation Accuracy: 94.29%\n",
      "Validation loss improved from 0.1688 to 0.1683. Saving model...\n",
      "\n",
      "LOG: Epoch [829/1000] - Training\n",
      "Epoch [829/1000] completed, Average Training Loss: 0.0177\n",
      "    Validation Batch [1/1], Loss: 0.1705\n",
      "Validation Loss: 0.1705, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [830/1000] - Training\n",
      "Epoch [830/1000] completed, Average Training Loss: 0.0260\n",
      "    Validation Batch [1/1], Loss: 0.1797\n",
      "Validation Loss: 0.1797, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [831/1000] - Training\n",
      "Epoch [831/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.1915\n",
      "Validation Loss: 0.1915, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [832/1000] - Training\n",
      "Epoch [832/1000] completed, Average Training Loss: 0.0199\n",
      "    Validation Batch [1/1], Loss: 0.2029\n",
      "Validation Loss: 0.2029, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [833/1000] - Training\n",
      "Epoch [833/1000] completed, Average Training Loss: 0.0280\n",
      "    Validation Batch [1/1], Loss: 0.2018\n",
      "Validation Loss: 0.2018, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [834/1000] - Training\n",
      "Epoch [834/1000] completed, Average Training Loss: 0.0234\n",
      "    Validation Batch [1/1], Loss: 0.1971\n",
      "Validation Loss: 0.1971, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [835/1000] - Training\n",
      "Epoch [835/1000] completed, Average Training Loss: 0.0212\n",
      "    Validation Batch [1/1], Loss: 0.1942\n",
      "Validation Loss: 0.1942, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [836/1000] - Training\n",
      "Epoch [836/1000] completed, Average Training Loss: 0.0209\n",
      "    Validation Batch [1/1], Loss: 0.1931\n",
      "Validation Loss: 0.1931, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [837/1000] - Training\n",
      "Epoch [837/1000] completed, Average Training Loss: 0.0283\n",
      "    Validation Batch [1/1], Loss: 0.1935\n",
      "Validation Loss: 0.1935, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [838/1000] - Training\n",
      "Epoch [838/1000] completed, Average Training Loss: 0.0242\n",
      "    Validation Batch [1/1], Loss: 0.1960\n",
      "Validation Loss: 0.1960, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [839/1000] - Training\n",
      "Epoch [839/1000] completed, Average Training Loss: 0.0247\n",
      "    Validation Batch [1/1], Loss: 0.1975\n",
      "Validation Loss: 0.1975, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [840/1000] - Training\n",
      "Epoch [840/1000] completed, Average Training Loss: 0.0200\n",
      "    Validation Batch [1/1], Loss: 0.2009\n",
      "Validation Loss: 0.2009, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [841/1000] - Training\n",
      "Epoch [841/1000] completed, Average Training Loss: 0.0197\n",
      "    Validation Batch [1/1], Loss: 0.2044\n",
      "Validation Loss: 0.2044, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [842/1000] - Training\n",
      "Epoch [842/1000] completed, Average Training Loss: 0.0259\n",
      "    Validation Batch [1/1], Loss: 0.2077\n",
      "Validation Loss: 0.2077, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [843/1000] - Training\n",
      "Epoch [843/1000] completed, Average Training Loss: 0.0277\n",
      "    Validation Batch [1/1], Loss: 0.2149\n",
      "Validation Loss: 0.2149, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [844/1000] - Training\n",
      "Epoch [844/1000] completed, Average Training Loss: 0.0187\n",
      "    Validation Batch [1/1], Loss: 0.2218\n",
      "Validation Loss: 0.2218, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [845/1000] - Training\n",
      "Epoch [845/1000] completed, Average Training Loss: 0.0189\n",
      "    Validation Batch [1/1], Loss: 0.2096\n",
      "Validation Loss: 0.2096, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [846/1000] - Training\n",
      "Epoch [846/1000] completed, Average Training Loss: 0.0187\n",
      "    Validation Batch [1/1], Loss: 0.1913\n",
      "Validation Loss: 0.1913, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [847/1000] - Training\n",
      "Epoch [847/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.1859\n",
      "Validation Loss: 0.1859, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [848/1000] - Training\n",
      "Epoch [848/1000] completed, Average Training Loss: 0.0222\n",
      "    Validation Batch [1/1], Loss: 0.1776\n",
      "Validation Loss: 0.1776, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [849/1000] - Training\n",
      "Epoch [849/1000] completed, Average Training Loss: 0.0203\n",
      "    Validation Batch [1/1], Loss: 0.1738\n",
      "Validation Loss: 0.1738, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [850/1000] - Training\n",
      "Epoch [850/1000] completed, Average Training Loss: 0.0164\n",
      "    Validation Batch [1/1], Loss: 0.1754\n",
      "Validation Loss: 0.1754, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [851/1000] - Training\n",
      "Epoch [851/1000] completed, Average Training Loss: 0.0231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1866\n",
      "Validation Loss: 0.1866, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [852/1000] - Training\n",
      "Epoch [852/1000] completed, Average Training Loss: 0.0156\n",
      "    Validation Batch [1/1], Loss: 0.1952\n",
      "Validation Loss: 0.1952, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [853/1000] - Training\n",
      "Epoch [853/1000] completed, Average Training Loss: 0.0294\n",
      "    Validation Batch [1/1], Loss: 0.2008\n",
      "Validation Loss: 0.2008, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [854/1000] - Training\n",
      "Epoch [854/1000] completed, Average Training Loss: 0.0237\n",
      "    Validation Batch [1/1], Loss: 0.2085\n",
      "Validation Loss: 0.2085, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [855/1000] - Training\n",
      "Epoch [855/1000] completed, Average Training Loss: 0.0292\n",
      "    Validation Batch [1/1], Loss: 0.2149\n",
      "Validation Loss: 0.2149, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [856/1000] - Training\n",
      "Epoch [856/1000] completed, Average Training Loss: 0.0159\n",
      "    Validation Batch [1/1], Loss: 0.2214\n",
      "Validation Loss: 0.2214, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [857/1000] - Training\n",
      "Epoch [857/1000] completed, Average Training Loss: 0.0338\n",
      "    Validation Batch [1/1], Loss: 0.2197\n",
      "Validation Loss: 0.2197, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [858/1000] - Training\n",
      "Epoch [858/1000] completed, Average Training Loss: 0.0268\n",
      "    Validation Batch [1/1], Loss: 0.2146\n",
      "Validation Loss: 0.2146, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [859/1000] - Training\n",
      "Epoch [859/1000] completed, Average Training Loss: 0.0264\n",
      "    Validation Batch [1/1], Loss: 0.2084\n",
      "Validation Loss: 0.2084, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [860/1000] - Training\n",
      "Epoch [860/1000] completed, Average Training Loss: 0.0215\n",
      "    Validation Batch [1/1], Loss: 0.2006\n",
      "Validation Loss: 0.2006, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [861/1000] - Training\n",
      "Epoch [861/1000] completed, Average Training Loss: 0.0236\n",
      "    Validation Batch [1/1], Loss: 0.1981\n",
      "Validation Loss: 0.1981, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [862/1000] - Training\n",
      "Epoch [862/1000] completed, Average Training Loss: 0.0253\n",
      "    Validation Batch [1/1], Loss: 0.1979\n",
      "Validation Loss: 0.1979, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [863/1000] - Training\n",
      "Epoch [863/1000] completed, Average Training Loss: 0.0299\n",
      "    Validation Batch [1/1], Loss: 0.1949\n",
      "Validation Loss: 0.1949, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [864/1000] - Training\n",
      "Epoch [864/1000] completed, Average Training Loss: 0.0237\n",
      "    Validation Batch [1/1], Loss: 0.1959\n",
      "Validation Loss: 0.1959, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [865/1000] - Training\n",
      "Epoch [865/1000] completed, Average Training Loss: 0.0242\n",
      "    Validation Batch [1/1], Loss: 0.1990\n",
      "Validation Loss: 0.1990, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [866/1000] - Training\n",
      "Epoch [866/1000] completed, Average Training Loss: 0.0161\n",
      "    Validation Batch [1/1], Loss: 0.2044\n",
      "Validation Loss: 0.2044, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [867/1000] - Training\n",
      "Epoch [867/1000] completed, Average Training Loss: 0.0202\n",
      "    Validation Batch [1/1], Loss: 0.2012\n",
      "Validation Loss: 0.2012, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [868/1000] - Training\n",
      "Epoch [868/1000] completed, Average Training Loss: 0.0139\n",
      "    Validation Batch [1/1], Loss: 0.1971\n",
      "Validation Loss: 0.1971, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [869/1000] - Training\n",
      "Epoch [869/1000] completed, Average Training Loss: 0.0208\n",
      "    Validation Batch [1/1], Loss: 0.1908\n",
      "Validation Loss: 0.1908, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [870/1000] - Training\n",
      "Epoch [870/1000] completed, Average Training Loss: 0.0173\n",
      "    Validation Batch [1/1], Loss: 0.1833\n",
      "Validation Loss: 0.1833, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [871/1000] - Training\n",
      "Epoch [871/1000] completed, Average Training Loss: 0.0237\n",
      "    Validation Batch [1/1], Loss: 0.1810\n",
      "Validation Loss: 0.1810, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [872/1000] - Training\n",
      "Epoch [872/1000] completed, Average Training Loss: 0.0186\n",
      "    Validation Batch [1/1], Loss: 0.1825\n",
      "Validation Loss: 0.1825, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [873/1000] - Training\n",
      "Epoch [873/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.1850\n",
      "Validation Loss: 0.1850, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [874/1000] - Training\n",
      "Epoch [874/1000] completed, Average Training Loss: 0.0238\n",
      "    Validation Batch [1/1], Loss: 0.1883\n",
      "Validation Loss: 0.1883, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [875/1000] - Training\n",
      "Epoch [875/1000] completed, Average Training Loss: 0.0277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Validation Batch [1/1], Loss: 0.1956\n",
      "Validation Loss: 0.1956, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [876/1000] - Training\n",
      "Epoch [876/1000] completed, Average Training Loss: 0.0175\n",
      "    Validation Batch [1/1], Loss: 0.2029\n",
      "Validation Loss: 0.2029, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [877/1000] - Training\n",
      "Epoch [877/1000] completed, Average Training Loss: 0.0231\n",
      "    Validation Batch [1/1], Loss: 0.2099\n",
      "Validation Loss: 0.2099, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [878/1000] - Training\n",
      "Epoch [878/1000] completed, Average Training Loss: 0.0208\n",
      "    Validation Batch [1/1], Loss: 0.2128\n",
      "Validation Loss: 0.2128, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [879/1000] - Training\n",
      "Epoch [879/1000] completed, Average Training Loss: 0.0206\n",
      "    Validation Batch [1/1], Loss: 0.2181\n",
      "Validation Loss: 0.2181, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [880/1000] - Training\n",
      "Epoch [880/1000] completed, Average Training Loss: 0.0188\n",
      "    Validation Batch [1/1], Loss: 0.2215\n",
      "Validation Loss: 0.2215, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [881/1000] - Training\n",
      "Epoch [881/1000] completed, Average Training Loss: 0.0320\n",
      "    Validation Batch [1/1], Loss: 0.2166\n",
      "Validation Loss: 0.2166, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [882/1000] - Training\n",
      "Epoch [882/1000] completed, Average Training Loss: 0.0193\n",
      "    Validation Batch [1/1], Loss: 0.2149\n",
      "Validation Loss: 0.2149, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [883/1000] - Training\n",
      "Epoch [883/1000] completed, Average Training Loss: 0.0210\n",
      "    Validation Batch [1/1], Loss: 0.2158\n",
      "Validation Loss: 0.2158, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [884/1000] - Training\n",
      "Epoch [884/1000] completed, Average Training Loss: 0.0253\n",
      "    Validation Batch [1/1], Loss: 0.2102\n",
      "Validation Loss: 0.2102, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [885/1000] - Training\n",
      "Epoch [885/1000] completed, Average Training Loss: 0.0269\n",
      "    Validation Batch [1/1], Loss: 0.1962\n",
      "Validation Loss: 0.1962, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [886/1000] - Training\n",
      "Epoch [886/1000] completed, Average Training Loss: 0.0243\n",
      "    Validation Batch [1/1], Loss: 0.1891\n",
      "Validation Loss: 0.1891, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [887/1000] - Training\n",
      "Epoch [887/1000] completed, Average Training Loss: 0.0256\n",
      "    Validation Batch [1/1], Loss: 0.1879\n",
      "Validation Loss: 0.1879, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [888/1000] - Training\n",
      "Epoch [888/1000] completed, Average Training Loss: 0.0274\n",
      "    Validation Batch [1/1], Loss: 0.1901\n",
      "Validation Loss: 0.1901, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [889/1000] - Training\n",
      "Epoch [889/1000] completed, Average Training Loss: 0.0211\n",
      "    Validation Batch [1/1], Loss: 0.1933\n",
      "Validation Loss: 0.1933, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [890/1000] - Training\n",
      "Epoch [890/1000] completed, Average Training Loss: 0.0173\n",
      "    Validation Batch [1/1], Loss: 0.1964\n",
      "Validation Loss: 0.1964, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [891/1000] - Training\n",
      "Epoch [891/1000] completed, Average Training Loss: 0.0211\n",
      "    Validation Batch [1/1], Loss: 0.2023\n",
      "Validation Loss: 0.2023, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [892/1000] - Training\n",
      "Epoch [892/1000] completed, Average Training Loss: 0.0189\n",
      "    Validation Batch [1/1], Loss: 0.2043\n",
      "Validation Loss: 0.2043, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [893/1000] - Training\n",
      "Epoch [893/1000] completed, Average Training Loss: 0.0255\n",
      "    Validation Batch [1/1], Loss: 0.2027\n",
      "Validation Loss: 0.2027, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [894/1000] - Training\n",
      "Epoch [894/1000] completed, Average Training Loss: 0.0189\n",
      "    Validation Batch [1/1], Loss: 0.1949\n",
      "Validation Loss: 0.1949, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [895/1000] - Training\n",
      "Epoch [895/1000] completed, Average Training Loss: 0.0201\n",
      "    Validation Batch [1/1], Loss: 0.1865\n",
      "Validation Loss: 0.1865, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [896/1000] - Training\n",
      "Epoch [896/1000] completed, Average Training Loss: 0.0223\n",
      "    Validation Batch [1/1], Loss: 0.1770\n",
      "Validation Loss: 0.1770, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [897/1000] - Training\n",
      "Epoch [897/1000] completed, Average Training Loss: 0.0251\n",
      "    Validation Batch [1/1], Loss: 0.1734\n",
      "Validation Loss: 0.1734, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [898/1000] - Training\n",
      "Epoch [898/1000] completed, Average Training Loss: 0.0212\n",
      "    Validation Batch [1/1], Loss: 0.1714\n",
      "Validation Loss: 0.1714, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [899/1000] - Training\n",
      "Epoch [899/1000] completed, Average Training Loss: 0.0186\n",
      "    Validation Batch [1/1], Loss: 0.1725\n",
      "Validation Loss: 0.1725, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [900/1000] - Training\n",
      "Epoch [900/1000] completed, Average Training Loss: 0.0252\n",
      "    Validation Batch [1/1], Loss: 0.1779\n",
      "Validation Loss: 0.1779, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [901/1000] - Training\n",
      "Epoch [901/1000] completed, Average Training Loss: 0.0126\n",
      "    Validation Batch [1/1], Loss: 0.1823\n",
      "Validation Loss: 0.1823, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [902/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [902/1000] completed, Average Training Loss: 0.0160\n",
      "    Validation Batch [1/1], Loss: 0.1867\n",
      "Validation Loss: 0.1867, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [903/1000] - Training\n",
      "Epoch [903/1000] completed, Average Training Loss: 0.0211\n",
      "    Validation Batch [1/1], Loss: 0.1875\n",
      "Validation Loss: 0.1875, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [904/1000] - Training\n",
      "Epoch [904/1000] completed, Average Training Loss: 0.0164\n",
      "    Validation Batch [1/1], Loss: 0.1908\n",
      "Validation Loss: 0.1908, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [905/1000] - Training\n",
      "Epoch [905/1000] completed, Average Training Loss: 0.0268\n",
      "    Validation Batch [1/1], Loss: 0.1911\n",
      "Validation Loss: 0.1911, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [906/1000] - Training\n",
      "Epoch [906/1000] completed, Average Training Loss: 0.0208\n",
      "    Validation Batch [1/1], Loss: 0.1926\n",
      "Validation Loss: 0.1926, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [907/1000] - Training\n",
      "Epoch [907/1000] completed, Average Training Loss: 0.0189\n",
      "    Validation Batch [1/1], Loss: 0.2004\n",
      "Validation Loss: 0.2004, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [908/1000] - Training\n",
      "Epoch [908/1000] completed, Average Training Loss: 0.0268\n",
      "    Validation Batch [1/1], Loss: 0.2028\n",
      "Validation Loss: 0.2028, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [909/1000] - Training\n",
      "Epoch [909/1000] completed, Average Training Loss: 0.0175\n",
      "    Validation Batch [1/1], Loss: 0.1919\n",
      "Validation Loss: 0.1919, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [910/1000] - Training\n",
      "Epoch [910/1000] completed, Average Training Loss: 0.0206\n",
      "    Validation Batch [1/1], Loss: 0.1836\n",
      "Validation Loss: 0.1836, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [911/1000] - Training\n",
      "Epoch [911/1000] completed, Average Training Loss: 0.0240\n",
      "    Validation Batch [1/1], Loss: 0.1774\n",
      "Validation Loss: 0.1774, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [912/1000] - Training\n",
      "Epoch [912/1000] completed, Average Training Loss: 0.0195\n",
      "    Validation Batch [1/1], Loss: 0.1762\n",
      "Validation Loss: 0.1762, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [913/1000] - Training\n",
      "Epoch [913/1000] completed, Average Training Loss: 0.0224\n",
      "    Validation Batch [1/1], Loss: 0.1790\n",
      "Validation Loss: 0.1790, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [914/1000] - Training\n",
      "Epoch [914/1000] completed, Average Training Loss: 0.0236\n",
      "    Validation Batch [1/1], Loss: 0.1810\n",
      "Validation Loss: 0.1810, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [915/1000] - Training\n",
      "Epoch [915/1000] completed, Average Training Loss: 0.0160\n",
      "    Validation Batch [1/1], Loss: 0.1827\n",
      "Validation Loss: 0.1827, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [916/1000] - Training\n",
      "Epoch [916/1000] completed, Average Training Loss: 0.0164\n",
      "    Validation Batch [1/1], Loss: 0.1866\n",
      "Validation Loss: 0.1866, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [917/1000] - Training\n",
      "Epoch [917/1000] completed, Average Training Loss: 0.0246\n",
      "    Validation Batch [1/1], Loss: 0.1888\n",
      "Validation Loss: 0.1888, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [918/1000] - Training\n",
      "Epoch [918/1000] completed, Average Training Loss: 0.0183\n",
      "    Validation Batch [1/1], Loss: 0.1903\n",
      "Validation Loss: 0.1903, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [919/1000] - Training\n",
      "Epoch [919/1000] completed, Average Training Loss: 0.0161\n",
      "    Validation Batch [1/1], Loss: 0.1932\n",
      "Validation Loss: 0.1932, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [920/1000] - Training\n",
      "Epoch [920/1000] completed, Average Training Loss: 0.0173\n",
      "    Validation Batch [1/1], Loss: 0.1947\n",
      "Validation Loss: 0.1947, Validation Accuracy: 95.71%\n",
      "Validation loss did not improve. Patience: 92/100\n",
      "\n",
      "LOG: Epoch [921/1000] - Training\n",
      "Epoch [921/1000] completed, Average Training Loss: 0.0197\n",
      "    Validation Batch [1/1], Loss: 0.2009\n",
      "Validation Loss: 0.2009, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 93/100\n",
      "\n",
      "LOG: Epoch [922/1000] - Training\n",
      "Epoch [922/1000] completed, Average Training Loss: 0.0175\n",
      "    Validation Batch [1/1], Loss: 0.2060\n",
      "Validation Loss: 0.2060, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 94/100\n",
      "\n",
      "LOG: Epoch [923/1000] - Training\n",
      "Epoch [923/1000] completed, Average Training Loss: 0.0142\n",
      "    Validation Batch [1/1], Loss: 0.2050\n",
      "Validation Loss: 0.2050, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 95/100\n",
      "\n",
      "LOG: Epoch [924/1000] - Training\n",
      "Epoch [924/1000] completed, Average Training Loss: 0.0215\n",
      "    Validation Batch [1/1], Loss: 0.1944\n",
      "Validation Loss: 0.1944, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 96/100\n",
      "\n",
      "LOG: Epoch [925/1000] - Training\n",
      "Epoch [925/1000] completed, Average Training Loss: 0.0162\n",
      "    Validation Batch [1/1], Loss: 0.1886\n",
      "Validation Loss: 0.1886, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 97/100\n",
      "\n",
      "LOG: Epoch [926/1000] - Training\n",
      "Epoch [926/1000] completed, Average Training Loss: 0.0199\n",
      "    Validation Batch [1/1], Loss: 0.1795\n",
      "Validation Loss: 0.1795, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 98/100\n",
      "\n",
      "LOG: Epoch [927/1000] - Training\n",
      "Epoch [927/1000] completed, Average Training Loss: 0.0237\n",
      "    Validation Batch [1/1], Loss: 0.1772\n",
      "Validation Loss: 0.1772, Validation Accuracy: 94.29%\n",
      "Validation loss did not improve. Patience: 99/100\n",
      "\n",
      "LOG: Epoch [928/1000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [928/1000] completed, Average Training Loss: 0.0201\n",
      "    Validation Batch [1/1], Loss: 0.1796\n",
      "Validation Loss: 0.1796, Validation Accuracy: 92.86%\n",
      "Validation loss did not improve. Patience: 100/100\n",
      "Early stopping triggered at epoch 928. No improvement for 100 epochs.\n",
      "Loading the best model weights...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIhCAYAAAB5deq6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACVhUlEQVR4nOzdeVhU1R8G8Hdm2PfFhUER0XBBIrdQcE1NkUJJS8tcMlvcKjXLJc3KSm3TzNLql0tZpom5pOGSa4lbaqaYW4imkAIKsi9zf39MMzIwzNw7CzPA+3kenuTOOfcedDRezjnfIxMEQQARERERERFVSW7rARAREREREdk7BiciIiIiIiIjGJyIiIiIiIiMYHAiIiIiIiIygsGJiIiIiIjICAYnIiIiIiIiIxiciIiIiIiIjGBwIiIiIiIiMoLBiYiIiIiIyAgGJyKyOJlMJupj7969Zj3njTfegEwmM6nv3r17LTIGe/fUU0+hadOmVb5+8+ZNODk54fHHH6+yTU5ODtzc3DBgwADRz125ciVkMhkuX74seizlyWQyvPHGG6Kfp3H9+nW88cYbOHnyZKXXzHm/mKtp06Z4+OGHbfJsqTIzMzFjxgyEhYXBzc0NXl5e6Ny5Mz799FOUlJTYeniV9OzZs8p/Y8S+36xJ877LyMiw9VCIyEwOth4AEdU+SUlJOp/PnTsXe/bswe7du3Wuh4WFmfWcZ555BjExMSb1bd++PZKSksweQ01Xv359DBgwABs3bsStW7fg6+tbqc3333+PgoICjBkzxqxnzZ49Gy+99JJZ9zDm+vXrePPNN9G0aVO0bdtW5zVz3i91xV9//YW+ffsiNzcXL7/8MqKjo1FQUICffvoJL730En744Qds27YNbm5uth6qjmbNmuHbb7+tdN3Z2dkGoyGi2orBiYgsrnPnzjqf169fH3K5vNL1ivLz8yV9Q9a4cWM0btzYpDFqfopOwJgxY5CQkIBvv/0WEydOrPT68uXL0bBhQzz00ENmPad58+Zm9TeXOe+XuqCsrAyDBw9GTk4Ojhw5ghYtWmhfi42NRY8ePfD4449jypQpWLZsWbWNSxAEFBYWwtXVtco2rq6u/PtMRFbHpXpEZBM9e/ZEeHg49u/fj+joaLi5ueHpp58GAKxduxZ9+/aFUqmEq6srWrdujenTpyMvL0/nHvqWXmmWRCUmJqJ9+/ZwdXVFq1atsHz5cp12+pbqPfXUU/Dw8MDFixcRGxsLDw8PBAUF4eWXX0ZRUZFO/3/++QePPvooPD094ePjgyeffBJHjx6FTCbDypUrDX7tN2/exPjx4xEWFgYPDw80aNAAvXr1woEDB3TaXb58GTKZDB988AE++ugjhISEwMPDA1FRUTh06FCl+65cuRItW7aEs7MzWrduja+//trgODT69euHxo0bY8WKFZVeO3v2LA4fPoyRI0fCwcEBO3fuxMCBA9G4cWO4uLjgnnvuwfPPPy9qGZK+pXo5OTl49tln4e/vDw8PD8TExOD8+fOV+l68eBGjR49GaGgo3Nzc0KhRI8TFxeHPP//Uttm7dy/uv/9+AMDo0aO1y7U0S/70vV9UKhXee+89tGrVCs7OzmjQoAFGjhyJf/75R6ed5v169OhRdOvWDW5ubmjWrBnmz58PlUpl9GsXo7CwEDNmzEBISAicnJzQqFEjTJgwAbdv39Zpt3v3bvTs2RP+/v5wdXVFkyZNMHjwYOTn52vbLF26FPfddx88PDzg6emJVq1aYebMmQaf/+OPPyI5ORnTp0/XCU0aQ4cORd++ffHVV18hPT0dJSUlaNCgAUaMGFGp7e3bt+Hq6oopU6Zor+Xk5GDq1Kk6X9+kSZMq/b2WyWSYOHEili1bhtatW8PZ2RmrVq0S81tokGb56M6dOzF69Gj4+fnB3d0dcXFx+Pvvvyu1X758Oe677z64uLjAz88PjzzyCM6ePVup3eHDhxEXFwd/f3+4uLigefPmmDRpUqV2//77L5544gl4e3ujYcOGePrpp5Gdna3T5ocffkCnTp3g7e2tfY9p/l0kIttjcCIim0lLS8Pw4cMxbNgwbNu2DePHjwcAXLhwAbGxsfjqq6+QmJiISZMmYd26dYiLixN13z/++AMvv/wyJk+ejE2bNiEiIgJjxozB/v37jfYtKSnBgAED0Lt3b2zatAlPP/00Fi5ciAULFmjb5OXl4YEHHsCePXuwYMECrFu3Dg0bNsTQoUNFjS8rKwsAMGfOHGzduhUrVqxAs2bN0LNnT717rj799FPs3LkTixYtwrfffou8vDzExsbqfNO1cuVKjB49Gq1bt0ZCQgJmzZqFuXPnVloeqY9cLsdTTz2F48eP448//tB5TROmNN+8Xbp0CVFRUVi6dCl27NiB119/HYcPH0bXrl0l738RBAHx8fH45ptv8PLLL+PHH39E586d0b9//0ptr1+/Dn9/f8yfPx+JiYn49NNP4eDggE6dOuHcuXMA1MsvNeOdNWsWkpKSkJSUhGeeeabKMYwbNw7Tpk3Dgw8+iM2bN2Pu3LlITExEdHR0pTCYnp6OJ598EsOHD8fmzZvRv39/zJgxA6tXr5b0dRv6vfjggw8wYsQIbN26FVOmTMGqVavQq1cvbXC/fPkyHnroITg5OWH58uVITEzE/Pnz4e7ujuLiYgDqpZXjx49Hjx498OOPP2Ljxo2YPHlypYBS0c6dOwEA8fHxVbaJj49HaWkp9u7dC0dHRwwfPhwJCQnIycnRabdmzRoUFhZi9OjRANSzyT169MCqVavw4osv4ueff8a0adOwcuVKDBgwAIIg6PTfuHEjli5ditdffx3bt29Ht27djP4elpaWVvrQF2rHjBkDuVyO7777DosWLcKRI0fQs2dPnYA6b948jBkzBm3atMGGDRvw8ccf49SpU4iKisKFCxe07TRju3LlCj766CP8/PPPmDVrFv79999Kzx08eDBatGiBhIQETJ8+Hd999x0mT56sfT0pKQlDhw5Fs2bN8P3332Pr1q14/fXXUVpaavRrJ6JqIhARWdmoUaMEd3d3nWs9evQQAAi//PKLwb4qlUooKSkR9u3bJwAQ/vjjD+1rc+bMESr+MxYcHCy4uLgIqamp2msFBQWCn5+f8Pzzz2uv7dmzRwAg7NmzR2ecAIR169bp3DM2NlZo2bKl9vNPP/1UACD8/PPPOu2ef/55AYCwYsUKg19TRaWlpUJJSYnQu3dv4ZFHHtFeT0lJEQAI9957r1BaWqq9fuTIEQGAsGbNGkEQBKGsrEwIDAwU2rdvL6hUKm27y5cvC46OjkJwcLDRMfz999+CTCYTXnzxRe21kpISISAgQOjSpYvePpo/m9TUVAGAsGnTJu1rK1asEAAIKSkp2mujRo3SGcvPP/8sABA+/vhjnfu+8847AgBhzpw5VY63tLRUKC4uFkJDQ4XJkydrrx89erTKP4OK75ezZ88KAITx48frtDt8+LAAQJg5c6b2mub9evjwYZ22YWFhQr9+/aocp0ZwcLDw0EMPVfl6YmKiAEB47733dK6vXbtWACB88cUXgiAIwvr16wUAwsmTJ6u818SJEwUfHx+jY6ooJiZGACAUFhZW2UbzZ7ZgwQJBEATh1KlTOuPTiIyMFDp06KD9fN68eYJcLheOHj2q007z9Wzbtk17DYDg7e0tZGVliRq35s9G38eYMWO07TTvyfJ/xwRBEH777TcBgPD2228LgiAIt27dElxdXYXY2FiddleuXBGcnZ2FYcOGaa81b95caN68uVBQUFDl+DTvu4p/tuPHjxdcXFy0f2c/+OADAYBw+/ZtUV83EVU/zjgRkc34+vqiV69ela7//fffGDZsGAICAqBQKODo6IgePXoAgN6lMhW1bdsWTZo00X7u4uKCFi1aIDU11WhfmUxWaWYrIiJCp+++ffvg6elZqdDAE088YfT+GsuWLUP79u3h4uICBwcHODo64pdfftH79T300ENQKBQ64wGgHdO5c+dw/fp1DBs2TGcpWnBwMKKjo0WNJyQkBA888AC+/fZb7czFzz//jPT0dJ2lQjdu3MDYsWMRFBSkHXdwcDAAcX825e3ZswcA8OSTT+pcHzZsWKW2paWlePfddxEWFgYnJyc4ODjAyckJFy5ckPzcis9/6qmndK5HRkaidevW+OWXX3SuBwQEIDIyUudaxfeGqTQzgxXH8thjj8Hd3V07lrZt28LJyQnPPfccVq1apXeJWWRkJG7fvo0nnngCmzZtsmg1N+G/mSHN++zee+9Fhw4ddJZ5nj17FkeOHNF53/z0008IDw9H27ZtdWaE+vXrp7e6Za9evfQWKqlK8+bNcfTo0Uofs2fPrtS24vstOjoawcHB2vdDUlISCgoKKv1ZBAUFoVevXto/i/Pnz+PSpUsYM2YMXFxcjI6xYlXKiIgIFBYW4saNGwCgXWY6ZMgQrFu3DteuXRP3xRNRtWFwIiKbUSqVla7l5uaiW7duOHz4MN5++23s3bsXR48exYYNGwAABQUFRu/r7+9f6Zqzs7Oovm5ubpW+CXJ2dkZhYaH288zMTDRs2LBSX33X9Pnoo48wbtw4dOrUCQkJCTh06BCOHj2KmJgYvWOs+PVoKoVp2mZmZgJQf2Nfkb5rVRkzZgwyMzOxefNmAOpleh4eHhgyZAgA9X6gvn37YsOGDXj11Vfxyy+/4MiRI9r9VmJ+f8vLzMyEg4NDpa9P35inTJmC2bNnIz4+Hlu2bMHhw4dx9OhR3HfffZKfW/75gP73YWBgoPZ1DXPeV2LG4uDggPr16+tcl8lkCAgI0I6lefPm2LVrFxo0aIAJEyagefPmaN68OT7++GNtnxEjRmD58uVITU3F4MGD0aBBA3Tq1Em7FK8qmh82pKSkVNlGU14+KChIe+3pp59GUlIS/vrrLwDq942zs7PODxL+/fdfnDp1Co6Ojjofnp6eEAShUrjT92diiIuLCzp27FjpQxPqy6vq74nm91js++LmzZsAILrgiLG/x927d8fGjRtRWlqKkSNHonHjxggPD8eaNWtE3Z+IrI9V9YjIZvSdqbN7925cv34de/fu1c4yAai0Qd6W/P39ceTIkUrX09PTRfVfvXo1evbsiaVLl+pcv3Pnjsnjqer5YscEAIMGDYKvry+WL1+OHj164KeffsLIkSPh4eEBADh9+jT++OMPrFy5EqNGjdL2u3jxosnjLi0tRWZmps43lfrGvHr1aowcORLvvvuuzvWMjAz4+PiY/HxAvdeu4je/169fR7169Uy6r6ljKS0txc2bN3XCkyAISE9P185GAEC3bt3QrVs3lJWV4dixY/jkk08wadIkNGzYUHse1+jRozF69Gjk5eVh//79mDNnDh5++GGcP39eb5gAgAcffBBffPEFNm7ciOnTp+tts3HjRjg4OKBnz57aa0888QSmTJmClStX4p133sE333yD+Ph4nRmjevXqwdXVtVKRlvKvl2fN87aq+ntyzz33ANB9X1RU/n2h+XOqWEjEHAMHDsTAgQNRVFSEQ4cOYd68eRg2bBiaNm2KqKgoiz2HiEzDGScisiuab5gqnr/y+eef22I4evXo0QN37tzBzz//rHP9+++/F9VfJpNV+vpOnTpV6fwrsVq2bAmlUok1a9bobLJPTU3FwYMHRd/HxcUFw4YNw44dO7BgwQKUlJToLLey9J/NAw88AACVzt/57rvvKrXV93u2devWSsuZKv4U3xDNMtGKxR2OHj2Ks2fPonfv3kbvYSmaZ1UcS0JCAvLy8vSORaFQoFOnTvj0008BAMePH6/Uxt3dHf3798drr72G4uJinDlzpsoxPPLIIwgLC8P8+fP1VjZcu3YtduzYgWeeeUZn1sbX1xfx8fH4+uuv8dNPP1Va3gkADz/8MC5dugR/f3+9M0PVeVBtxffbwYMHkZqaqg2DUVFRcHV1rfRn8c8//2D37t3aP4sWLVqgefPmWL58eaWqm+ZydnZGjx49tEVpTpw4YdH7E5FpOONERHYlOjoavr6+GDt2LObMmQNHR0d8++23laq92dKoUaOwcOFCDB8+HG+//Tbuuece/Pzzz9i+fTsAdZU6Qx5++GHMnTsXc+bMQY8ePXDu3Dm89dZbCAkJMamCllwux9y5c/HMM8/gkUcewbPPPovbt2/jjTfekLRUD1Av1/v000/x0UcfoVWrVjp7pFq1aoXmzZtj+vTpEAQBfn5+2LJli9ElYFXp27cvunfvjldffRV5eXno2LEjfvvtN3zzzTeV2j788MNYuXIlWrVqhYiICPz+++94//33K80UNW/eHK6urvj222/RunVreHh4IDAwEIGBgZXu2bJlSzz33HP45JNPIJfL0b9/f1y+fBmzZ89GUFCQTsUzS0hPT8f69esrXW/atCkefPBB9OvXD9OmTUNOTg66dOmCU6dOYc6cOWjXrp225PeyZcuwe/duPPTQQ2jSpAkKCwu1szh9+vQBADz77LNwdXVFly5doFQqkZ6ejnnz5sHb21tn5qoihUKBhIQEPPjgg4iKisLLL7+MqKgoFBUVYcuWLfjiiy/Qo0cPfPjhh5X6Pv3001i7di0mTpyIxo0ba8eiMWnSJCQkJKB79+6YPHkyIiIioFKpcOXKFezYsQMvv/wyOnXqZPLvbUFBgd4S/UDlc+WOHTuGZ555Bo899hiuXr2K1157DY0aNdJW9fTx8cHs2bMxc+ZMjBw5Ek888QQyMzPx5ptvwsXFBXPmzNHe69NPP0VcXBw6d+6MyZMno0mTJrhy5Qq2b9+u90BeQ15//XX8888/6N27Nxo3bozbt2/j448/1tnjSUQ2ZtPSFERUJ1RVVa9NmzZ62x88eFCIiooS3NzchPr16wvPPPOMcPz48UrV0qqqqqevelmPHj2EHj16aD+vqqpexXFW9ZwrV64IgwYNEjw8PARPT09h8ODBwrZt2ypVl9OnqKhImDp1qtCoUSPBxcVFaN++vbBx48ZKVec0VfXef//9SveAnqpz//vf/4TQ0FDByclJaNGihbB8+fJK9xSjXbt2equACYIgJCcnCw8++KDg6ekp+Pr6Co899phw5cqVSuMRU1VPEATh9u3bwtNPPy34+PgIbm5uwoMPPij89ddfle5369YtYcyYMUKDBg0ENzc3oWvXrsKBAwcq/bkKgiCsWbNGaNWqleDo6KhzH31/jmVlZcKCBQuEFi1aCI6OjkK9evWE4cOHC1evXtVpV9X7Vezvb3BwcJWV30aNGiUIgrr647Rp04Tg4GDB0dFRUCqVwrhx44Rbt25p75OUlCQ88sgjQnBwsODs7Cz4+/sLPXr0EDZv3qxts2rVKuGBBx4QGjZsKDg5OQmBgYHCkCFDhFOnThkdpyAIQkZGhjB9+nShVatWgouLi+Dh4SFERkYKS5YsEYqLi/X2KSsrE4KCggQAwmuvvaa3TW5urjBr1iyhZcuWgpOTk+Dt7S3ce++9wuTJk4X09HRtOwDChAkTRI1VEAxX1QMglJSUCIJw9z25Y8cOYcSIEYKPj4+2et6FCxcq3fd///ufEBERoR3rwIEDhTNnzlRql5SUJPTv31/w9vYWnJ2dhebNm+tUetS8727evKnTr+LfkZ9++kno37+/0KhRI8HJyUlo0KCBEBsbKxw4cED07wURWZdMECocnkBERCZ59913MWvWLFy5ckX0hnEiqh6as86OHj2Kjh072no4RFQDcakeEZEJlixZAkC9fK2kpAS7d+/G4sWLMXz4cIYmIiKiWojBiYjIBG5ubli4cCEuX76MoqIiNGnSBNOmTcOsWbNsPTQiIiKyAi7VIyIiIiIiMoLlyImIiIiIiIxgcCIiIiIiIjKCwYmIiIiIiMiIOlccQqVS4fr16/D09IRMJrP1cIiIiIiIyEYEQcCdO3cQGBho9AD7Ohecrl+/jqCgIFsPg4iIiIiI7MTVq1eNHidS54KTp6cnAPVvjpeXl41HQ0REREREtpKTk4OgoCBtRjCkzgUnzfI8Ly8vBiciIiIiIhK1hYfFIYiIiIiIiIxgcCIiIiIiIjKCwYmIiIiIiMiIOrfHiYiIiIjsjyAIKC0tRVlZma2HQrWMo6MjFAqF2fdhcCIiIiIimyouLkZaWhry8/NtPRSqhWQyGRo3bgwPDw+z7sPgREREREQ2o1KpkJKSAoVCgcDAQDg5OYmqcEYkhiAIuHnzJv755x+EhoaaNfPE4ERERERENlNcXAyVSoWgoCC4ubnZejhUC9WvXx+XL19GSUmJWcGJxSGIiIiIyObkcn5bStZhqRlMvkOJiIiIiIiMYHAiIiIiIiIygsGJiIiIiGq8MpWApEuZ2HTyGpIuZaJMJdh6SJL17NkTkyZNEt3+8uXLkMlkOHnypNXGRHexOAQRERER1WiJp9Pw5pZkpGUXaq8pvV0wJy4MMeFKiz/P2J6ZUaNGYeXKlZLvu2HDBjg6OopuHxQUhLS0NNSrV0/ys6S4fPkyQkJCcOLECbRt29aqz7JnDE5EREREVGMlnk7DuNXHUXF+KT27EONWH8fS4e0tHp7S0tK0v167di1ef/11nDt3TnvN1dVVp31JSYmoQOTn5ydpHAqFAgEBAZL6kOkYnGyptBg48jmQmgQU5QKCAJQVAgoX9etlhYCDK+BWD8jPAEoLdF+T+mt995LJAGd3ILgLEPkc4OBUfV8/ERERkR6CIKCgpMxouzKVgDmbz1QKTQAgAJABeGNzMrrcUw8KufHKaq6OClEV2MqHFW9vb8hkMu21y5cvQ6lUYu3atfjss89w6NAhLF26FAMGDMDEiRNx4MABZGVloXnz5pg5cyaeeOIJ7b169uyJtm3bYtGiRQCApk2b4rnnnsPFixfxww8/wNfXF7NmzcJzzz2nfVb5maC9e/figQcewK5duzBt2jQkJyejbdu2WLFiBVq2bKl9zttvv43FixejoKAAQ4cORb169ZCYmGjykr+ioiK88sor+P7775GTk4OOHTti4cKFuP/++wEAt27dwsSJE7Fjxw7k5uaicePGmDlzJkaPHo3i4mJMmTIFCQkJuHXrFgICAvD8889jxowZJo3FmhicbGXHbODgJ4Dev+o2cG4bsOM1wCMACOkO3DcMaNYdkJte656IiIjIFAUlZQh7fbvZ9xEApOcU4t43dohqn/xWP7g5Webb42nTpuHDDz/EihUr4OzsjMLCQnTo0AHTpk2Dl5cXtm7dihEjRqBZs2bo1KlTlff58MMPMXfuXMycORPr16/HuHHj0L17d7Rq1arKPq+99ho+/PBD1K9fH2PHjsXTTz+N3377DQDw7bff4p133sFnn32GLl264Pvvv8eHH36IkJAQk7/WV199FQkJCVi1ahWCg4Px3nvvoV+/frh48SL8/Pwwe/ZsJCcn4+eff0a9evVw8eJFFBQUAAAWL16MzZs3Y926dWjSpAmuXr2Kq1evmjwWa2JwsoUds4GDi7U/CbEruenAn+vUHzIFcO8QYMBizkQRERERSTBp0iQMGjRI59rUqVO1v37hhReQmJiIH374wWBwio2Nxfjx4wGow9jChQuxd+9eg8HpnXfeQY8ePQAA06dPx0MPPYTCwkK4uLjgk08+wZgxYzB69GgAwOuvv66dCTJFXl4eli5dipUrV6J///4AgC+//BI7d+7EV199hVdeeQVXrlxBu3bt0LFjRwDqmTSNK1euIDQ0FF27doVMJkNwcLBJ46gODE7VrbQYOPiJfYamioQy4NQa9UdYPPDocs5AERERkdW5OiqQ/FY/o+2OpGThqRVHjbZbOfp+RIYY3z/k6mi573M0IUGjrKwM8+fPx9q1a3Ht2jUUFRWhqKgI7u7uBu8TERGh/bVmSeCNGzdE91Eq1fu7bty4gSZNmuDcuXPaIKYRGRmJ3bt3i/q6Krp06RJKSkrQpUsX7TVHR0dERkbi7NmzAIBx48Zh8ODBOH78OPr27Yv4+HhER0cDAJ566ik8+OCDaNmyJWJiYvDwww+jb9++Jo3F2liOvLod/RKAYP+hqaLkjcDbDYHTG209EiIiIqrlZDIZ3JwcjH50C60PpbdLld9XyaCurtcttL6o+4nZ3yRWxUD04YcfYuHChXj11Vexe/dunDx5Ev369UNxcbHB+1QsKiGTyaBSqUT30XxN5ftU/DoFwfStI5q++u6puda/f3+kpqZi0qRJuH79Onr37q2dfWvfvj1SUlIwd+5cFBQUYMiQIXj00UdNHo81MThVM1VWiq2HYDpVCbB+lHqpIREREZGNKeQyzIkLA1B5JY/m8zlxYaIKQ1jbgQMHMHDgQAwfPhz33XcfmjVrhgsXLlT7OFq2bIkjR47oXDt27JjJ97vnnnvg5OSEX3/9VXutpKQEx44dQ+vWrbXX6tevj6eeegqrV6/GokWL8MUXX2hf8/LywtChQ/Hll19i7dq1SEhIQFZWlsljshYu1atmqaqGMH3rnZ04uBgIbAeEDzLeloiIiMiKYsKVWDq8faVznAKseI6TKe655x4kJCTg4MGD8PX1xUcffYT09HSdcFEdXnjhBTz77LPo2LEjoqOjsXbtWpw6dQrNmjUz2rd8yXWNsLAwjBs3Dq+88gr8/PzQpEkTvPfee8jPz8eYMWMAqPdRdejQAW3atEFRURF++ukn7de9cOFCKJVKtG3bFnK5HD/88AMCAgLg4+Nj0a/bEhicqtmpRo+iybG3IYe6EniNtV69oZDhiYiIiGwtJlyJB8MCcCQlCzfuFKKBpwsiQ/zsYqZJY/bs2UhJSUG/fv3g5uaG5557DvHx8cjOzq7WcTz55JP4+++/MXXqVBQWFmLIkCF46qmnKs1C6fP4449XupaSkoL58+dDpVJhxIgRuHPnDjp27Ijt27fD19cXAODk5IQZM2bg8uXLcHV1Rbdu3fD9998DADw8PLBgwQJcuHABCoUC999/P7Zt2wa53P4WxskEcxY11kA5OTnw9vZGdnY2vLy8qv35SZcy8cfyF/G8w08Aanh4AoDoF4G+c209CiIiIqqhCgsLkZKSgpCQELi4uNh6OHXSgw8+iICAAHzzzTe2HopVGHqPSckGnHGqZpEhfpji8TSQCzzr8BNqfI26g4uBRh2ANvG2HgkRERERGZGfn49ly5ahX79+UCgUWLNmDXbt2oWdO3faemh2j8GpminkMgy4T4n5+4fhg7IhGKVIxP3yc3BFAeQAnFGCel5eaFbPHSgrBBxcAbd6QH4GUFoAKP5LyWWF0n9d8V5FuUDmeUBVat4XteE5oHUcS5UTERER2TmZTIZt27bh7bffRlFREVq2bImEhAT06dPH1kOzewxO1axMJWDzH2kAgFI44Kuyh/FV2cM6bZSlLvh1VK/qWZerKgNSDgApe4FzO4CbyVCfsy1BWRGwfgwwZKUVBkhEREREluLq6opdu3bZehg1kv3tuqrljqRk6VR80SctuxBHUqqpBKNcATTvCfR5A5hwEHg9E+g61VivypJ/BM5stPDgiIiIiIjsA4NTNbtxx3BoktrO4uQKoM9s4NEV0vtumqiewSIiIiIiqmUYnKpZA09x1WIuZ+RbeSRGhA9SV8yTovgOsP8D64yHiIiIiMiGGJyqWWSIHwK8nI22+/7oFZSpbFwpvu9c6TNPBxdz1omIiIiIah0Gp2qmkMvwRGQTo+2qdZ+TIeGDpIWn4lzOOhERERFRrcPgZANN67mLamezfU4VhQ8CoiaKb394GWediIiIiKhWYXCyAbH7nMS2qxb93gHCHhHXtiALSD1o3fEQERERlac5YuXP9er/1oAf4vbs2ROTJk3Sft60aVMsWrTIYB+ZTIaNGzea/WxL3acuYXCygcgQPyi9XWDolCYfN0dEhvhV25hEefQrwMFNXNs7adYdCxEREZFG8mZgUTiw6mEgYYz6v4vC1detIC4ursoDY5OSkiCTyXD8+HHJ9z169Ciee+45c4en44033kDbtm0rXU9LS0P//v0t+qyKVq5cCR8fH6s+ozoxONmAQi7DnLgwg8fM3s4vwc7k9GobkyhyBdBG5KzT33usOxYiIiIiQB2O1o0Ecq7rXs9JU1+3QngaM2YMdu/ejdTU1EqvLV++HG3btkX79u0l37d+/fpwcxP5Q2ozBQQEwNnZeMEyuovByUYeDAuAj5ujwTbTN/xp+8p6FTXvKa5d8qYaMUVOREREdkgQgOI84x+FOcDPrwJ6fxz937XEaep2Yu4niPu+6+GHH0aDBg2wcuVKnev5+flYu3YtxowZg8zMTDzxxBNo3Lgx3NzccO+992LNmjUG71txqd6FCxfQvXt3uLi4ICwsDDt37qzUZ9q0aWjRogXc3NzQrFkzzJ49GyUlJQDUMz5vvvkm/vjjD8hkMshkMu2YKy7V+/PPP9GrVy+4urrC398fzz33HHJzc7WvP/XUU4iPj8cHH3wApVIJf39/TJgwQfssU1y5cgUDBw6Eh4cHvLy8MGTIEPz777/a1//44w888MAD8PT0hJeXFzp06IBjx44BAFJTUxEXFwdfX1+4u7ujTZs22LZtm8ljEcPBqnenKh1JycLtfMNvtNv5JViy+yJe6hNaTaMSwVMprl1xnrq6Xs9p1h0PERER1T4l+cC7gRa4kaCeiZofJK75zOuAk/EiXg4ODhg5ciRWrlyJ119/HTKZegPGDz/8gOLiYjz55JPIz89Hhw4dMG3aNHh5eWHr1q0YMWIEmjVrhk6dOhl9hkqlwqBBg1CvXj0cOnQIOTk5OvuhNDw9PbFy5UoEBgbizz//xLPPPgtPT0+8+uqrGDp0KE6fPo3ExETs2rULAODt7V3pHvn5+YiJiUHnzp1x9OhR3LhxA8888wwmTpyoEw737NkDpVKJPXv24OLFixg6dCjatm2LZ5991ujXU5EgCIiPj4e7uzv27duH0tJSjB8/HkOHDsXevXsBAE8++STatWuHpUuXQqFQ4OTJk3B0VE88TJgwAcXFxdi/fz/c3d2RnJwMDw8PyeOQgsHJRsRWzFtxMAUTe90DhdzQjqhqFBwNuPoABbeNtz24GOg+Vb3Ej4iIiKgWefrpp/H+++9j7969eOCBBwCol+kNGjQIvr6+8PX1xdSpU7XtX3jhBSQmJuKHH34QFZx27dqFs2fP4vLly2jcuDEA4N133620L2nWrFnaXzdt2hQvv/wy1q5di1dffRWurq7w8PCAg4MDAgICqnzWt99+i4KCAnz99ddwd1cHxyVLliAuLg4LFixAw4YNAQC+vr5YsmQJFAoFWrVqhYceegi//PKLScFp165dOHXqFFJSUhAUpA6233zzDdq0aYOjR4/i/vvvx5UrV/DKK6+gVatWAIDQ0LuTCVeuXMHgwYNx7733AgCaNWsmeQxS2TQ4zZs3Dxs2bMBff/0FV1dXREdHY8GCBWjZsmWVfcq/Ocs7e/as9je1JhBbMe92fgmOpGQhqrm/lUckklwBdBoP7H3XeFvNmU6cdSIiIiIpHN3Usz/GpB4Evn3UeLsn16t/+CvmuSK1atUK0dHRWL58OR544AFcunQJBw4cwI4dOwAAZWVlmD9/PtauXYtr166hqKgIRUVF2mBizNmzZ9GkSRNtaAKAqKioSu3Wr1+PRYsW4eLFi8jNzUVpaSm8vLxEfx2aZ9133306Y+vSpQtUKhXOnTunDU5t2rSBQnH3B+JKpRJ//vmnpGeVf2ZQUJA2NAFAWFgYfHx8cPbsWdx///2YMmUKnnnmGXzzzTfo06cPHnvsMTRv3hwA8OKLL2LcuHHYsWMH+vTpg8GDByMiIsKksYhl0z1O+/btw4QJE3Do0CHs3LkTpaWl6Nu3L/Ly8oz2PXfuHNLS0rQf5RNoTRAZ4gcfV8N7nDTs5jwnje5TAUdxf+l5phMRERFJJpOpl8wZ+2jeC/AKBKqsVSwDvBqp24m5n0zaCp8xY8YgISEBOTk5WLFiBYKDg9G7d28AwIcffoiFCxfi1Vdfxe7du3Hy5En069cPxcXFou4t6NlvJaswvkOHDuHxxx9H//798dNPP+HEiRN47bXXRD+j/LMq3lvfMzXL5Mq/plKpJD3L2DPLX3/jjTdw5swZPPTQQ9i9ezfCwsLw448/AgCeeeYZ/P333xgxYgT+/PNPdOzYEZ988olJYxHLpsEpMTERTz31FNq0aYP77rsPK1aswJUrV/D7778b7dugQQMEBARoP8qn35pAIZdhdJemotra1XlOgHrWqctL4tryTCciIiKyFrkCiFnw3ycVvwn/7/OY+VbbNjBkyBAoFAp89913WLVqFUaPHq39pv/AgQMYOHAghg8fjvvuuw/NmjXDhQsXRN87LCwMV65cwfXrd2fekpKSdNr89ttvCA4OxmuvvYaOHTsiNDS0UqU/JycnlJUZ/iF2WFgYTp48qTN58dtvv0Eul6NFixaixyyF5uu7evWq9lpycjKys7PRunVr7bUWLVpg8uTJ2LFjBwYNGoQVK1ZoXwsKCsLYsWOxYcMGvPzyy/jyyy+tMlYNu6qql52dDQDw8zN+flG7du2gVCrRu3dv7NlTdenroqIi5OTk6HzYi3E97xH1g42M3CLrD0aq7lN5phMRERHZXtgAYMjXgFeFAlZegerrYQOs9mgPDw8MHToUM2fOxPXr1/HUU09pX7vnnnuwc+dOHDx4EGfPnsXzzz+P9HTxR8306dMHLVu2xMiRI/HHH3/gwIEDeO2113Ta3HPPPbhy5Qq+//57XLp0CYsXL9bOyGg0bdoUKSkpOHnyJDIyMlBUVPn7yieffBIuLi4YNWoUTp8+jT179uCFF17AiBEjtMv0TFVWVoaTJ0/qfCQnJ6NPnz6IiIjAk08+iePHj+PIkSMYOXIkevTogY4dO6KgoAATJ07E3r17kZqait9++w1Hjx7VhqpJkyZh+/btSElJwfHjx7F7926dwGUNdhOcBEHAlClT0LVrV4SHh1fZTqlU4osvvkBCQgI2bNiAli1bonfv3ti/f7/e9vPmzYO3t7f2o/w6Slv7PfWWqKqXM+yxLLmUM53yblp3LERERFS3hQ0AJp0GRv0EDP5K/d9Jf1o1NGmMGTMGt27dQp8+fdCkSRPt9dmzZ6N9+/bo168fevbsiYCAAMTHx4u+r1wux48//oiioiJERkbimWeewTvvvKPTZuDAgZg8eTImTpyItm3b4uDBg5g9e7ZOm8GDByMmJgYPPPAA6tevr7ckupubG7Zv346srCzcf//9ePTRR9G7d28sWbJE2m+GHrm5uWjXrp3OR2xsrLYcuq+vL7p3744+ffqgWbNmWLt2LQBAoVAgMzMTI0eORIsWLTBkyBD0798fb775JgB1IJswYQJat26NmJgYtGzZEp999pnZ4zVEJuhbQGkDEyZMwNatW/Hrr7/qbIITIy4uDjKZDJs3Vz7gTLMRTyMnJwdBQUHIzs6WvHHO0jadvIaXvj8pqu3kPi3sqyw5AJxaB2wQUUWl0zig/3zrj4eIiIhqnMLCQqSkpCAkJAQuLna2PYFqBUPvsZycHHh7e4vKBnYx4/TCCy9g8+bN2LNnj+TQBACdO3eucs2os7MzvLy8dD7shZS9SysOptjfrJPYM51OrGaBCCIiIiKq0WwanARBwMSJE7Fhwwbs3r0bISEhJt3nxIkTUCpFfhNvRyJD/ODnLq6ynqYsuV0JjgbcRJRJL76jLktORERERFRD2TQ4TZgwAatXr8Z3330HT09PpKenIz09HQUFBdo2M2bMwMiRI7WfL1q0CBs3bsSFCxdw5swZzJgxAwkJCZg4caItvgSzKOQyvD2w6v1cFdldWXK5AogYKq4ty5ITERERUQ1m0+C0dOlSZGdno2fPnlAqldoPzaYwAEhLS8OVK1e0nxcXF2Pq1KmIiIhAt27d8Ouvv2Lr1q0YNGiQLb4Es8VGBCIuouqTnMu7nJFv5dGYoGWsuHYsS05ERERENZjdFIeoLlI2gFWXMpWA9nN3ILug1GA7NycF/nyjHxRyaYezWZWqDHi/GVBw23jbzuOBmHlWHxIRERHVHJqN+02bNoWrq6uth0O1UEFBAS5fvlw7ikPUdQq5DE9FNzXaLr+4DJ/8Iv7gtGohVwCdxotre2odl+sRERGRDkdH9X7v/Hw7XFlDtUJxcTEAdYlzczhYYjBkPrEV85btv4TxD9wDJwc7yrzdpwIHP1EXgTAkP0O9XC+kW/WMi4iIiOyeQqGAj48Pbty4AUB9ppBMZkera6hGU6lUuHnzJtzc3ODgYF70YXCyG+L+gSgsUaHzvF/w7iPhiAm3k0qCcgXQfgRwSMShY7n/Wn88REREVKMEBKj3e2vCE5ElyeVyNGnSxOxAzuBkJ6Ka+2PJnoui2mblFWPc6uNYOry9/YSnlrHigpNHQ+uPhYiIiGoUmUwGpVKJBg0aoKSkxNbDoVrGyckJcrn5q7UYnOxE52b+cHdWIK9I/B6gN7ck48GwAPsoFhHUCZDJAUFVdRuZQt2OiIiISA+FQmH2PhQia7GjjTJ1m0Iuw/uDI0S3FwCkZRfaz6G4Vw8bDk0AIJSp2xERERER1TAMTnZEyplOGnZzKK7YvUvc40RERERENRCDk53pEyYtODXwdDHeqDqI3bvEPU5EREREVAMxONkZKUHIw9kBkSF+VhyNBMHRgFeg8Xb5mdYfCxERERGRhTE42ZnIED/4uDqKaptbVIqdyelWHpFIcgXQd57xdttn8hBcIiIiIqpxGJzsjEIuw+guTUW3f3NLsujDc63O3d94m5xr6kNwiYiIiIhqEAYnOzSxVyh83MTNOtlVZT0WiCAiIiKiWorByQ4p5DK8Gx8uur3dLNcTW/gh85J1x0FEREREZGEMTnbK191ZdNvlv11G4uk0K45GpOBowFNpvN3xVdznREREREQ1CoOTnZJ6PtMbm8/Yfq+TXAF0GG28Hfc5EREREVENw+Bkp6Sez5SeU4Qluy9aaTQS+DcX1+7cNuuOg4iIiIjIghic7FRkiB+U3tLC08Jd522/ZE/sPqdT67hcj4iIiIhqDAYnO6WQyzAnLkxyP5sv2QuOBtxElCXPz+ByPSIiIiKqMRic7FhMuBKfDWsnqU96ThFeXf+H7cKTXAHc+5i4tnfsoKAFEREREZEIDE52LjYiEJN6h0rqk3D8GiLe2G67ZXs+TcS1y7tp3XEQEREREVkIg1MN8ELvULg7KyT1ySsuw9jVx20TntzrW7YdEREREZGNMTjVAAq5DI93DDKp75tbkqt/2Z6Ys5yktCMiIiIisjEGpxqiT1iASf3SsgtxJCXLwqMxIjga8Ao03i4/0/pjISIiIiKyAAanGsKU8uQaUg/TNZtcAfSdZ7zd9pksSU5ERERENQKDUw1hanlyQPphuhbhLqIkec41liQnIiIiohqBwakGiQlXYsnjbSX18XFzRGSIn3UGZEjuv5ZtR0RERERkQwxONczDbRvh2W4hotvLrDgWgzwaWrYdEREREZENMTjVQK89FIbnu4eICkW38ktw6JINijBoC0QYGKWrn7odEREREZGdY3CqoWbEhuHDx+4T1fbpVUer/zwnuQKIWQDAQCn0gizgr63VNiQiIiIiIlMxONVgSh9XUe2KSlW2OQy31UPqWaUqyYDE6aysR0RERER2j8GpBosM8YOfu6Po9tV+GG7qQfWsUpUEVtYjIiIiohqBwakGU8hleKRtI9Htq/0wXFbWIyIiIqJagsGphusTFiCp/fYz1bhcj5X1iIiIiKiWYHCq4aQu11uVlIptp6opPGkr6xmRb4Oqf0REREREEjA41XAKuQxvDwwX3V4QgPHfVVOhCLkC6DvPeLvtM1kggoiIiIjsGoNTLRAbEYi4CGlL9qYnnKqeQhHu/sbbsEAEEREREdk5BqdaQupep9sFpfjklwtWGk05LBBBRERERLUAg1Mt0cDTRXKfRb9cwLZT160wmnJYIIKIiIiIagEGp1oiMsQPSm/p4WnCdyesWyxCTIEIr0bqdkREREREdorBqZZQyGWYExcmuZ8AKxeLkCuA8EcNtwkfrG5HRERERGSnGJxqkZhwJSb3CTWp7zRrFYtQlQGn1xtuczqBVfWIiIiIyK4xONUyE3uFIsBL+pK97IJSfLzrvOUHlHoQyDGyj4pV9YiIiIjIzjE41TIKuQxvDJC+ZA8AFu++iHnbki07ILHV8s5ts+xziYiIiIgsiMGpFooJV2LZ8PbwcXOU3Pfz/SmWLRYhtlre8W+4XI+IiIiI7BaDUy0VE67E77MeRP9waec7AcCrltzvFBwNuIk4BLf4DrD/A8s8k4iIiIjIwhicajGFXIaRUU0l98stKsWhS5mWGYRcAUQMFdf28DLOOhERERGRXWJwquVMPd8p6e8Myw2iZay4dgVZLBJBRERERHaJwamW05zvJJPcU3qPKgVHA64+4tqySAQRERER2SEGpzogJlyJT4e1g1xCFnKQ0tgYuQLoNF5c21PruFyPiIiIiOwOg1Md4evuDCn1Hr4/esWyB+J2nwo4eRpvl5/B5XpEREREZHcYnOqIG3cKJbVPzynCkt0XLTcAuQJoP0JcW7FnPxERERERVRMGpzqigaf0AhELd51H4mkLnukktkiE2LOfiIiIiIiqCYNTHaGprid159I0S5/p5OpruI2rn7odEREREZEdYXCqIzTV9aTKLijFJ79csOBILFh0goiIiIiomjA41SEx4UosHd5e8rlOi365YJkle6kH1Wc1GcKznIiIiIjIDjE41TEx4Ur8Oq0XZj/UWlK/N7ckm79kT2zRBxaHICIiIiI7w+BUBynkMjzVJQS+bo6i+6RlF+JIipHZImPEFn1gcQgiIiIisjMMTnWUQi7DO/HhkvrsTE4376HB0YBXIAzuc/JqxOIQRERERGR3GJzqsNiIQPRuVV90+3XH/jFvuZ5cAcQsMNymzSPqdkREREREdoTBqY57pltz0W1zi0rNPxQ3bAAQ/ULVryctAba/Zt4ziIiIiIgsjMGpjtOc7yTWioMp5s06qcqA0+sNt0laAmyfZfoziIiIiIgsjMGpjpN6vtPt/BLzikSkHgRyrhtvl/QJcGaj6c8hIiIiIrIgBidCTLgSk3rfI7r910lmzDpJKTW+9WX1DBURERERkY0xOBEAIKS+h+i2P5/+Fx3e3mnaobhSSo3nZ/AwXCIiIiKyCwxOBABo4Cl+nxOgXrI3dvVx6eEpOBpw8xffnofhEhEREZEdYHAiANKLRGhMSzglbdmeXAHEfiS+feYlyWMiIiIiIrI0BicCIL1IhEZ2QSle+v6EtE7h8UDURHFtj6/iPiciIiIisjkGJ9KKCVdicp9Qyf1+OpWGbackLtnr9w4Q9ojxdjnXuM+JiIiIiGyOwYl0TOwVCi8XB8n9Zm86Lb3SXuuHxbXjPiciIiIisjGbBqd58+bh/vvvh6enJxo0aID4+HicO3fOaL99+/ahQ4cOcHFxQbNmzbBs2bJqGG3doJDLMKZriOR+mXnF0s93ElthT0olPiIiIiIiK7BpcNq3bx8mTJiAQ4cOYefOnSgtLUXfvn2Rl5dXZZ+UlBTExsaiW7duOHHiBGbOnIkXX3wRCQkJ1Tjy2m1ir1B4u0qfdUrPLpDWITgacPU13MbVT92OiIiIiMiGZIIgmHiSqeXdvHkTDRo0wL59+9C9e3e9baZNm4bNmzfj7Nmz2mtjx47FH3/8gaSkJKPPyMnJgbe3N7Kzs+Hl5WWxsdc2iafTMHb1cUl9PJwd8MFjEYgJV4rroCoD3r8HKDAwU+XqB7xyUV2Nj4iIiIjIgqRkA7va45SdnQ0A8PPzq7JNUlIS+vbtq3OtX79+OHbsGEpKSiq1LyoqQk5Ojs4HGRcTrsSy4e3h5iQ+sOQWlWKclLOdUg8aDk2A+nUWhyAiIiIiG7Ob4CQIAqZMmYKuXbsiPDy8ynbp6elo2FB3z0vDhg1RWlqKjIyMSu3nzZsHb29v7UdQUJDFx15bxYQr8eXIjpL6CADe3JIsrlCE2KIPLA5BRERERDZmN8Fp4sSJOHXqFNasWWO0rUwm0/lcs9qw4nUAmDFjBrKzs7UfV69etcyA64jOzfwlH4ybll0orlAEi0MQERERUQ1hF8HphRdewObNm7Fnzx40btzYYNuAgACkp6frXLtx4wYcHBzg7+9fqb2zszO8vLx0Pkg8Uw/GFVUoIjga8Ao03i4/U/LziYiIiIgsyabBSRAETJw4ERs2bMDu3bsREmK8DHZUVBR27typc23Hjh3o2LEjHB0drTXUOi0mXInPhrVD5fm8qs3edMb4Xie5Aug7z/jNts9UF5IgIiIiIrIRmwanCRMmYPXq1fjuu+/g6emJ9PR0pKeno6Dg7mzFjBkzMHLkSO3nY8eORWpqKqZMmYKzZ89i+fLl+OqrrzB16lRbfAl1RmxEIF7qHSq6vehCEe6VZwkrybnGAhFEREREZFM2DU5Lly5FdnY2evbsCaVSqf1Yu3attk1aWhquXLmi/TwkJATbtm3D3r170bZtW8ydOxeLFy/G4MGDbfEl1Ckv9A6Fu7P4KnuiCkWwQAQRERER1QDSTzm1IDFHSK1cubLStR49euD4cWlnDJH5FHIZHu8YhK9+uyy6j6ZQRFTzKmaWxBZ+yLwk+plERERERJZmF8UhqOboExYguc+NO4VVvxgcDXiKODD3+CrucyIiIiIim2FwIkkiQ/wQ4OUsqU/KzbyqX5QrgA6jjd+E+5yIiIiIyIYYnEgShVyGNwa0kdTn60Ophvc5+TcXdyPucyIiIiIiG2FwIsliwpWY3Ed8hb2svGLDB+KK3ef011bRzyQiIiIisiQGJzLJxF6h8HUTf26W0X1OHiL2TiVvAkqLRT+TiIiIiMhSGJzIJAq5DO/Eh4tufzkjv+oX5QqgeW/jNxHKgKNfin4mEREREZGlMDiRyWIjAvFst6ai2i7cdR4f7zpf9V4nZ3dxD720R1w7IiIiIiILYnAis7z2UBuM6dpUVNuFuy6gy/zdSDydVvlFX3H3wOVfWZaciIiIiKodgxOZrU9r8Wc7pecUYtzq45XD0/3PApAZv0FpAZDwjLQBEhERERGZicGJzGaw8IMeAoCZP/6J4lLV3YsOTkBoX3E3OLMBOLNR0jOJiIiIiMzB4ERma+DpIrlPVl4JOs/7RXfmKfoF8TfY+jKX7BERERFRtWFwIrNFhvhJKk2ukZVXrLtsLzgacPUR1zk/A0g9KPmZRERERESmYHAis0ktTV7Rm1uS1dX25Aqg03jxHXP/NfmZRERERERSMDiRRcRGBCIuQnyRCA0BQFp2IY6kZKkvdJ8KOHmK6+zRUPLziIiIiIhMweBEFtMnTHpw0tAWmJArgAFLjHdw9VMv7SMiIiIiqgYMTmQxphSJ0Ns3LA5w8rDAiIiIiIiILIPBiSwmMsQPSm8XMacxVXIrr/juJ6kHgeJcwx0KslgcgoiIiIiqDYMTWYxCLsOcuDCT+s7c+Ke6QAQgvugDi0MQERERUTVhcCKLiglXYunw9gjwcpbU73Z+CZbsvqj+RGzRBxaHICIiIqJqwuBEFhcTrsRv03vj0faNJfVbcTBFPesUHA14BRrvkJ9p4giJiIiIiKRhcCKrUMhlWPBoBHwkHIx7O79EXZZcrgD6zjPeYftMQFVmxiiJiIiIiMRhcCKrUchlmD/oXkl9tGXJ3f2NN865xgIRRERERFQtGJzIqh4MC5A06/T3zTz1L8QWfkj6xIRRERERERFJw+BEVnUkJQu380tEt/9k9wVsO5UmvvDD+e3AmY2mDY6IiIiISCQGJ7Iq7dI7kVQCMP6740jMDQHcRCzXA4CtL3OvExERERFZFYMTWVUDTxeT+r350zmo7h0irnF+Bvc6EREREZFVMTiRVUWG+EHp7QKZxH5p2YU469VNfIe/tkp8AhERERGReAxOZFUKuQxz4sJM6rshMwhw9hLX+I/vuFyPiIiIiKyGwYmsLiZciaXD28PPXXx1PQD46uBVXA4aKK5xYTaX6xERERGR1TA4UbWICVfi0Iw+cHdWSOr3Xmqo+MbntkkcFRERERGROAxOVG2cHOR4rlszSX0S7zRDsbOvuMZ/rOVyPSIiIiKyCgYnqlYTe4VKOhBXBTlORrwurnFBJrDvPRNHRkRERERUNQYnqlYKuQzzB90rqU9JiwFAaD9xjffNB3bMNmFkRERERERVY3CiahcTrsTkPuL3Lk1ZdxJHlMPEP+DgYuDMRukDIyIiIiKqAoMT2cTEXqHwFblk7987RXh8hwJFjj7iH7D1Ze53IiIiIiKLYXAim1DIZRjUrpHo9irIsae4pfgH5GewPDkRERERWQyDE9lMn7AASe3PlymlPeBOmrT2RERERERVYHAim4kM8YOPq/gKe0mqMGkPSJwBJG+WOCoiIiIiosoYnMhmFHIZRndpKrr9YVUYsgQPCILIDvmZwLqRDE9EREREZDYGJ7Kpib1C4e6sENVWBTlmlDwDACLD03+NEqezUAQRERERmYXBiWxKIZfh8Y5BottvV0VibMkkpMNXZA8ByLnGQhFEREREZBYGJ7I5qUUitqsiMaVknLSH5P4rrT0RERERUTkMTmRzkSF+UHq7SOoT6lYg7SGZl6S1JyIiIiIqh8GJbE4hl2FOnLSKefUaNpb2kMPLuM+JiIiIiEzG4ER2ISZciTESKuwlpWRKe0BBFrD/A2l9iIiIiIj+w+BEdkPKXqf6yJH+AM46EREREZGJGJzIbkSG+CHAy1lU2xvwkf6AgixW1yMiIiIikzA4kd1QyGV4Y0AbUW2PqFrhuuAHldjDcDX+2ip9YERERERU5zE4kV0Ru9dJBTneLBmp/rWU8HR8FZfrEREREZFkDE5kd8TuddquisS4kklIh5/4m5fks0gEEREREUnG4ER2R8q5TttVkehatBhvlQwX/wAWiSAiIiIiiRicyO5IPddJBTlWlsUgQ/AU14FFIoiIiIhIIgYnsksx4UpM7hMqur0KcswqGQ1B7H6nc9tMGxgRERER1UkMTmS3JvYKha+ro+j2iarO2KLqLK7xidVcrkdEREREojE4kd1SyGV455FwSX0mlUxEqcLdeMOiHODyryaOjIiIiIjqGgYnsmuxEYGIixBXZQ9QL9n7t2EXcY2PfmXiqIiIiIiormFwIru36PH2cHdWiG6v8hO5N+rsJiB5s4mjIiIiIqK6hMGJ7J5CLsP7gyNEt//Hq6P4mydO514nIiIiIjKKwYlqhNiIQDzfPURU2+G7HVHsIGKfEwDkXOO5TkRERERkFIMT1RgzYsMwqbfxZXhlkOPrwm7ib7x9JrAonMv2iIiIiKhKDE5Uo4TUFzeTtEslYbkeAORcB9aNZHgiIiIiIr0YnKhGaeDpIqrdEVUrXBd8IfY8XDWBe56IiIiISC8GJ6pRIkP8oPQ2Hp5UkOPNklHSH5BzDUg9aMLIiIiIiKg2Y3CiGkUhl2H2Q61Ftd2uisTCkkHSH3InTXofIiIiIqrVGJyoxvF1dxbd9qjQSvoD8m5K70NEREREtRqDE9U4N+4Uim5bHznSH3Bpr/Q+RERERFSrMThRjSO2QAQA3ICP9Adc3AFsnyW9HxERERHVWgxOVONoCkTIRLQ9omqFDMFT+kOSPgHObJTej4iIiIhqJQYnqnEUchnmxIWJaquCHLNKRkMQAEFabXJg68ssTU5EREREAGwcnPbv34+4uDgEBgZCJpNh48aNBtvv3bsXMpms0sdff/1VPQMmuxETrsSnw9pBLmLaKVHVGZ+XPiz9IfkZLE1ORERERABsHJzy8vJw3333YcmSJZL6nTt3DmlpadqP0NBQK42Q7JmvuzNUImeR5pcNw/iSl3AH4vdHAWBpciIiIiICADjY8uH9+/dH//79Jfdr0KABfHx8RLUtKipCUVGR9vOcHBOqrJFdklJdDwB+VnXC9sL78YlyOx669Y24TixNTkRERESooXuc2rVrB6VSid69e2PPnj0G286bNw/e3t7aj6CgoGoaJVmblOp6GirIMSGtP/50jRTX4aLh9xcRERER1Q01KjgplUp88cUXSEhIwIYNG9CyZUv07t0b+/fvr7LPjBkzkJ2drf24evVqNY6YrElKdb2K3snuK67hpZ3At0NNeAIRERER1SYyQZBca8wqZDIZfvzxR8THx0vqFxcXB5lMhs2bN4tqn5OTA29vb2RnZ8PLy8uEkZI9STydhnGrjwMApLyR5VDhiPM41JPdEdehRX9g2PfSB0hEREREdktKNqhRM076dO7cGRcuXLD1MMhGYsKVWDq8PQK8pS3bU0GOjWVdxHc4/zOw7VUg5QBLlBMRERHVQTU+OJ04cQJKpdLWwyAbiglX4tdpvbDm2c6Y+EBz0f12qTpKe9CRz4FVDwOLwoFkcTOcRERERFQ72LSqXm5uLi5evKj9PCUlBSdPnoSfnx+aNGmCGTNm4Nq1a/j6668BAIsWLULTpk3Rpk0bFBcXY/Xq1UhISEBCQoKtvgSyEwq5DFHN/REZ4ocfjl3Fv3eKjfY5omqFDMFT/HI9jZw0YN1IYMjXQNgAE0dMRERERDWJTWecjh07hnbt2qFdu3YAgClTpqBdu3Z4/fXXAQBpaWm4cuWKtn1xcTGmTp2KiIgIdOvWDb/++iu2bt2KQYMG2WT8ZH8UchneHBguqq0KcswqGQ3pu/z+65A4ncv2iIiIiOoIuykOUV1YHKJu+HjXeSzcJW7v20zFajzruM2k6nwY9RMQ0s2UnkRERERkY3WqOASRPhN7haKhp7Ootu+WDcfO0naSqvJp5f5rSi8iIiIiqmEYnKhWUshlGNapiej2z5W+gtteYdIf5NFQeh8iIiIiqnEYnKjWalrPXVL7651mSX9Ifqb0PkRERERU4zA4Ua3VwFP82U5+bo5o1akf4OYv7SE/TWaBCCIiIqI6gMGJaq3IED8EeInb51RYUoadf90EIoZKe0hBFrD/AxNGR0REREQ1CYMT1VoKuQxvDGgjqm1+iQpjVx/HEadO0h90cDFnnYiIiIhqOQYnqtViwpVYNrw9vF3FnfU89oAzBE+ltIcU5wIpB0wYHRERERHVFAxOVOvFhCvx2ZMdRLXNKlDhr7azpT9kz9vS+xARERFRjWFScLp69Sr++ecf7edHjhzBpEmT8MUXX1hsYESWlJFbJLrt1tIOwJBvAFdf8Q/45yiwZx6X7BERERHVUiYFp2HDhmHPnj0AgPT0dDz44IM4cuQIZs6cibfeesuiAySyBCkV9gAZEDYAeOUS0EfC+3nffOCDUOD0RqnDIyIiIiI7Z1JwOn36NCIjIwEA69atQ3h4OA4ePIjvvvsOK1eutOT4iCwiMsQPvm6Ooto6yGXqX8gVQPREwFHCeVD5mcD6UcAOE5b7EREREZHdMik4lZSUwNlZXeZ5165dGDBgAACgVatWSEtLs9zoiCxEIZfhnfhwUW0X/XIBiaf/ex/LFUCXl6Q/8OBi4MxG6f2IiIiIyC6ZFJzatGmDZcuW4cCBA9i5cydiYmIAANevX4e/v8QDRImqSWxEIJ7t1lRU2+kb/kSZSlB/0n0q4OQp/YFbX+aeJyIiIqJawqTgtGDBAnz++efo2bMnnnjiCdx3330AgM2bN2uX8BHZo16tAkS1u51fgonfHUfSpUyUQQ4MWCL9YfkZQOpB6f2IiIiIyO6IO9ymgp49eyIjIwM5OTnw9b1beey5556Dm5ubxQZHZGk37hSKbvvz6XT8fDodSm8XzInrhJhG9wPXjkp7YO6/EkdIRERERPbIpBmngoICFBUVaUNTamoqFi1ahHPnzqFBgwYWHSCRJUmrrqeWnl2IcauP46KnuLOgdHg0lN6HiIiIiOyOScFp4MCB+PrrrwEAt2/fRqdOnfDhhx8iPj4eS5cutegAiSwpMsQPAV7OkvoI/30suihumd9dciCok8Q+RERERGSPTApOx48fR7du3QAA69evR8OGDZGamoqvv/4aixcvtugAiSxJIZfhjQFtTOq7LfcelDj5SOihAg58aNKziIiIiMi+mBSc8vPz4emprjK2Y8cODBo0CHK5HJ07d0ZqaqpFB0hkaTHhSoyODpbcTwU5fmz8qrRO++YD21+T/CwiIiIisi8mBad77rkHGzduxNWrV7F9+3b07dsXAHDjxg14eXlZdIBE1tC3jdKkfgtSW6Dssa8BNwll95OWANtnmfQ8IiIiIrIPJgWn119/HVOnTkXTpk0RGRmJqKgoAOrZp3bt2ll0gETWEBniBx9XR8n9MvOKccSlKzDlL8BZwg8Jkj7hgbhERERENZhJwenRRx/FlStXcOzYMWzfvl17vXfv3li4cKHFBkdkLQq5DKO7NDWp787kdMDBCWg3XFpHHohLREREVGOZFJwAICAgAO3atcP169dx7do1AEBkZCRatWplscERWdPEXqHwcZM+67TxxDWUqQSgZay0jjwQl4iIiKjGMik4qVQqvPXWW/D29kZwcDCaNGkCHx8fzJ07FyqVytJjJLIKhVyG+YPuldwvK78Ei3+5AARHA54S90qd2yb5eURERERkeyYFp9deew1LlizB/PnzceLECRw/fhzvvvsuPvnkE8yePdvSYySymphwJT4b1g5ymbR+H/9yAfMSzwH935PW8dBnQPJmaX2IiIiIyOZkgiAIUjsFBgZi2bJlGDBggM71TZs2Yfz48dqle/YoJycH3t7eyM7OZgVA0tp2Kg3jvzsuud9nw9ojVn4YWD9KfCdHd+CJNUDTroBcIfmZRERERGQZUrKBSTNOWVlZevcytWrVCllZWabcksimYiOUWDa8PQK8nCX1m73pNMrCBgKPrRLfqSQP+HoAsCics09ERERENYRJwem+++7DkiVLKl1fsmQJIiIizB4UkS3EhCvx2/TeiGkTILpPZl4xjqRkAW3igc7jpT0w5zqwbiTDExEREVEN4GBKp/feew8PPfQQdu3ahaioKMhkMhw8eBBXr17Ftm3c/E41l0Iuw/1NfZF4Jl10nxt3CtW/aBmr3sMkiQAkTgdaPcRle0RERER2zKQZpx49euD8+fN45JFHcPv2bWRlZWHQoEE4c+YMVqxYYekxElUrP3cnSe0vZ+SrfxEcDbj6SX9gzjWWKSciIiKycyYVh6jKH3/8gfbt26OszH4P+WRxCDIm6VImnvjykOj2Sm8X/DqtFxRyGXB6o7RCERqDvwLufVR6PyIiIiIymdWLQxDVZpEhflB6u4hun5ZdqN7nBADh8UCbQdIf6tFQeh8iIiIiqjYMTkQVKOQyzIkLg5SjnbafSbv7yeD/AU4e4js7eaqX+RERERGR3WJwItIjJlyJpcPbw8/dUVT7lQdTMW9bsvoTuQIY8Kn4h5WVAH/vB1T2u8SViIiIqK6TVFVv0CDDS5Bu375tzliI7EpMuBK9WjVE+7k7kVtUarT95/tT4OrogBd6h0IRHg9cfxE4uNj4g8oKgdXx6sIScR8DYQOMdiEiIiKi6iUpOHl7ext9feTIkWYNiMieKOQyOCjEL9pb9MsFfH/0Kt4YEIaYvnOBsmLg8DJxnQuygHUjgCHfMDwRERER2RmLVtWrCVhVj6SQWmGvvGXD2yPG/SKw6mFpHb0aAZP+5LlORERERFbGqnpEFqI93NYE0xJOoSwoCnDzl9aR5zoRERER2R0GJyIDGniKL0teUXZBKV5adwqIGCq9c+6/Jj+XiIiIiCyPwYnIgMgQP9GV9fT56VQaDjl2kt7xwg7g732stEdERERkJxiciAxQyGV4e2C4Wfd44TcXCK4+0jqdWgt8PQB4/x4gebNZzyciIiIi8zE4ERkRGxGI57uHmNz/Zn4ZrrZ4yrTOmkp7DE9ERERENsXgRCTCjNgwTOodanL/E03HAC6+pg9gy0tctkdERERkQwxORCK90DsUAV6mFYto4OUODBBxGG5VCrKA/R+Y3p+IiIiIzMLgRCSSQi7DGwPCJPdTersgMsRPfajtkG8AJw/TBnB4KWediIiIiGyEwYlIgphwJZYNbw83J/GH0z4cEQCFXKb+JGwA8GoK4OAq/eEFt3i+ExEREZGNMDgRSRQTrsSXIzuKbv/lgcuYty357gUHJyD6JdMefm6baf2IiIiIyCwMTkQm6NzMH0pvF8hEtv98fwq2nUq7e6Hnq4Cju/QHH18NlBZL70dEREREZmFwIjKBQi7DnDhp+51eWf8HfruYgTKVAMgVwCPLpD+4OAd4vxnLkxMRERFVMwYnIhPFhCuxdHh7+Lg6imqfV1yGJ/93GF0X7Ebi6bS7xSJcJZYpL7rDs52IiIiIqhmDE5EZYsKV+OSJdpL6pGUXYtzq43fD0yuXgBGbgOAu0h6eOJ1V9oiIiIiqCYMTkZnkMrE7ne4SALy5Jfnusr3mPYFRWwBXP/E3ybnGKntERERE1YTBichMGXlFJvVLyy7EkZSsuxfkCqBpN2k3yf3XpGcTERERkTQMTkRmauDpYnLfncnpuhfqtZB2g8xLJj+biIiIiMRjcCIyU2SIH5TepoWnTSevq5fraYRInHE6/DnLkxMRERFVAwYnIjOZUppcIzOvGCt/S7kbnpp2lbbPqSATWNAEOL3RpOcTERERkTgMTkQWEBOuxLLh7eHmpJDcd+7Ws3dLlMsVQNzH0m5QUgCsHwXsmC352UREREQkjkwQBMF4s9ojJycH3t7eyM7OhpeXl62HQ7XMbxcz8OT/Dkvup6nLt3R4e8SEK9VnNP00CcjPlHaj7q8CENRl+0K6qWew5NLDHBEREVFdICUbMDgRWVCZSkCX+b8gPUd6pT0ZgABvF/w6rRcUchlQXADMCwQElekDcvVTz2CFDTD9HkRERES1lJRswKV6RBakkMvwxoA2JvUVUKFE+bVj5oUmACjIAtaNUM9gEREREZHJGJyILEyz38nHzdGk/jfuFKp/YckzmhKnA6oyy92PiIiIqI5hcCKygphwJX6f9SBmxrSS3Fd7LpRHQ8sNKOcakHrQcvcjIiIiqmMYnIisRCGXoaGPtPOdPJwVUAmCujx5cDTg5m+5AVlyBouIiIiojmFwIrIi7eyRSLlFZXjyf4fV5cmTbwCxH1luMJacwSIiIiKqYxiciKwoMsQPfu7S9zqlZRdi3OrjSEQnIPpF8wfi1Ug9g0VEREREJmFwIrIihVyGtweGm9RXAPDmlmSU9XkLeGwV4GrGsr3wwTzPiYiIiMgMDE5EVhYbEYjnu4eY1FdbnrxNPPDKBaDHdNMGcTqBVfWIiIiIzMDgRFQNZsSGYVLvUJP6asuTyxXAAzNMW7rHqnpEREREZrFpcNq/fz/i4uIQGBgImUyGjRs3Gu2zb98+dOjQAS4uLmjWrBmWLVtm/YESWcALvUPha8LZTpUKTPSdCzy6QvoAWFWPiIiIyGQ2DU55eXm47777sGTJElHtU1JSEBsbi27duuHEiROYOXMmXnzxRSQkJFh5pETmU8hlGNSukeR+t/KKK18MH6Te9yQFq+oRERERmczBlg/v378/+vfvL7r9smXL0KRJEyxatAgA0Lp1axw7dgwffPABBg8ebKVREllOn7AAfPXbZUl9xn93HMvk7RETrtR9oU08IPsG2PYKkJtu/EbnfgZCukl6NhERERGp1ag9TklJSejbt6/OtX79+uHYsWMoKSnR26eoqAg5OTk6H0S2Ymp58je3JKsPxa0obAAwJVlc0YhDnwLbZ0l+NhERERHVsOCUnp6Ohg11lxs1bNgQpaWlyMjI0Ntn3rx58Pb21n4EBQVVx1CJ9DK1PLm2up4+cgXQtKu4GyV9ApzZKPn5RERERHVdjQpOACCTyXQ+FwRB73WNGTNmIDs7W/tx9epVq4+RyBBTy5OnZxdU/aKUwg8JzwClevZNEREREVGValRwCggIQHq67l6OGzduwMHBAf7++g8HdXZ2hpeXl84Hka3NiA3DZ8Paw8VR/F/BjNyiql+UUvhBVQLMDwKSN4vvQ0RERFTH1ajgFBUVhZ07d+pc27FjBzp27AhHR+n7RohsKTZCiVNz+sHdSSGq/ZI9l5B4Ok3/i8HRgJv+Hx7oVVoIrBvB8EREREQkkk2DU25uLk6ePImTJ08CUJcbP3nyJK5cuQJAvcxu5MiR2vZjx45FamoqpkyZgrNnz2L58uX46quvMHXqVFsMn8hsTg5yPNe9mai22QUlGLv6OD7edb5yoQi5Aoj9SPoAEqcDqjLp/YiIiIjqGJsGp2PHjqFdu3Zo164dAGDKlClo164dXn/9dQBAWlqaNkQBQEhICLZt24a9e/eibdu2mDt3LhYvXsxS5FSjTewVCh8JB+Mu3HUBXebvrjz7FB4PhMVLe3jONSDlgLQ+RERERHWQTNBUV6gjcnJy4O3tjezsbO53IruReDoN41Yfh5S/jDIAS4dXON9JVQa8G6heiieWqy8Qt1hd2pyIiIioDpGSDWrUHiei2iomXImlw9vDSaG/OqQ+AvSc7yRXAPGfS3t4wS1g3UjudyIiIiIygMGJyE6oVAKKy6RNAOs93yk8HoiaKPHpArBxPHBxD/c8EREREenB4ERkB8pUAmZtOm1S353J6ZUv9nsHCHtE2o2K7wCr44H37+HsExEREVEFDE5EduBIShay8kpM6rvp5PXKVfYAoPXDpg2mIIulyomIiIgqYHAisgM37kgo5lBBZl5x5eV6gLRDcfVhqXIiIiIiLQYnIjvQwNPFrP56g1dwNODqY/pNc64BqQdN709ERERUizA4EdmByBA/KL1ND0+Jp9ORdCmzcoW9TuPNG9i5beb1JyIiIqolGJyI7IBCLsOcuDCIL0au6+fT6Xjiy0PouqDCwbjdpwIuvqYP7NBn3OtEREREBAYnIruhOcvJnJmn9OxCjFt9/G54kiuAAYvNGxj3OhERERExOBHZk5hwJX6d1gtrnu2Mp7s0hYuDtL+imoV6Ogfjhg0AhnwDOJgYyHKuAYeXMTwRERFRncbgRGRnFHIZopr74/W4NjjzVgxi2gRI6i9Az8G4YQOAAZ+YPqjtM4FF4Vy2R0RERHUWgxORHVPIZRgV3dSkvpUq7XkqzRtMThqwbiTDExEREdVJDE5Edi4yxA8BXs6S+1UqcR4cDXgFmjGS/5b+cc8TERER1UEMTkR2TiGX4Y0BbST18XZ1gEoQKpcnj1kAmFy7DwAEnu9EREREdRKDE1ENEBOuxJLH24pun11Qiif/d7hyefKwAcCQr82ceQKQ+695/YmIiIhqGAYnohrCv+LSOxHSsgsxtnx5ckAdniadBkb9BAz+Cuj6svTBZFyQ3oeIiIioBmNwIqohKhV7kGD6hj8rL9sL6Qbc+yjQ/AHpN9w3n0UiiIiIqE5hcCKqISoVe5Dgdn4Jluy+qP/F4GjA1Uf6Tbe8xCIRREREVGcwOBHVEJEhfvBzdzS5//Jf/9adddKQK4BO46XfsCALWNYVuLiHAYqIiIhqPQYnohpCIZfh7YHhJvfPLiytetap+1TA1U/6TW8kA6vjgXcDgdMbTR4bERERkb1jcCKqQWIjAvF89xCT+y/cdV63UISGXAHEfQyTS5WXFgLrRwE7Zps8NiIiIiJ7xuBEVMPMiA1DTJsA0/tXLBShoSlV7uZv+uAOLgb2zOPSPSIiIqp1GJyIaqARUcEm972VX4JDf2fqfzFsADDlL8Ctnsn3x775wIKmwLZpQMoBhigiIiKqFRiciGqgzs384eNmeqGIpEtVBCcAcHACHl5o8r0BAEU5wJFlwKqHgUXhLF1ORERENR6DE1ENpJDLMH/QvSb3Vwkqww3CBgCPrjL5/jpyrgPrRjI8ERERUY3G4ERUQ8WEK7FseHsEeEk/3+nrpFT9RSLKC48HHl1h2uAqEYDE6Vy2R0RERDUWgxNRDRYTrsRv03thzbOdMaFnc9H9covKMHb1cSSeTkOZSkDSpUxsOnkNSZcydQtHhA8Col+0zGBzrgGpBy1zLyIiIqJqJhMEQU95rdorJycH3t7eyM7OhpeXl62HQ2QxZSoBXRfsRlp2oeg+7k4KeLo4Ij3nbh+ltwvmxIUhJlx5t+GZjcCmiUDxHfMG2f0VoOcMdflzIiIiIhuTkg0440RUSyjkMsyJC5PUJ6+4TCc0AUB6diHG/TcbpdUmHpieCozYBDSONH2Q+99nsQgiIiKqkRiciGqRmHAlJvcJNeseminoN7ck6y7bkyuA5j2BXrPMuj9y0lgsgoiIiGocBieiWmZir1D4mlGqHFCHp7TsQhxJyar8YtOugIuvmXdnsQgiIiKqWRiciGoZhVyGQe0aWeReN+7o2S8lVwADFpt/85xr6gNyiYiIiGoABieiWqhPWIBF7tPAs4pS52EDgCHfAK7mzDwBWDMUOL3RvHsQERERVQMGJ6JaKDLED0pv6ec7lefj5ojIEL+qG4QNAF65pC4YETbQtIeUFgLrRwE7ZpvWn4iIiKiaMDgR1UKmVNirSCamkaZgxJCvgZ4zTX/YwcXqkudEREREdorBiaiWiglX4rNh7SAXlYAqu5Vfor84RFW6TwVcfEx7GKA+J4rFIoiIiMhOMTgR1WKxEYFYPLSdyf3TswvEN5YrgM7jTX4Wiu+wWAQRERHZLQYnolrO39PZ5L6vbz6Dbaeui+/QfSrgamBflDGpv5rel4iIiMiKGJyIajm9JcVFulNYivHfncC8bcniOsgVQNzHELlDqrKTa4Bf3gL+3sdle0RERGRXGJyIarkqS4pL8Pn+FGw7lSaucdgAdbEIT6X0B+X8Axz4EPh6APD+PUDyZun3ICIiIrICBieiWi4yxA8BXqYv19OYvek0ylSCuMZhA4DJZ8yrtFeQBawbwfBEREREdoHBiaiWU8hleP1h80qTA0BmXrG0KntyBdBzmvkH5SZO57I9IiIisjkGJ6I6wNfd/BknwMT9UpqDch9827SH5lwDUg+a1peIiIjIQhiciOoAcwpElHc5I9+0jnIFEDUecPUxrf8dkfuriIiIiKyEwYmoDrBEgQgAWLjrPD7edV78Xqfy5Aqgk4nnPOXdNK0fERERkYUwOBHVAZEhflB6u5haJFzHwl0X0GX+biSeNmEWqPtUwMFVer/bV6X3ISIiIrIgBieiOkAhl2FOnLpAhCXCU3pOIcatPi49PMkVwMDPpD/w2AqgtFh6PyIiIiILYXAiqiNiwpVYOrw9Arwts2wPAN7ckix92d69g4CWsdL6lBUC7wYCpzdK60dERERkITJBEEzYrFBz5eTkwNvbG9nZ2fDy8rL1cIiqXZlKwJGULNy4U4iMO0WYu/WsWfdb82xnRDX3l95x+yzg0KeAoJLWLyweeHS5evaKiIiIyAxSsgGDE1EdVqYS0GX+L0jPKTL5HhMfaI7Qhp5o4OmCyBA/KOQynXBW/nolpcXA9hnA0f9Je6jCBbj/afXMVXA0QxQRERGZhMHJAAYnIl2Jp9MwdvVxi9xL6e2CAfcpsfmPNKRlF+pcnxMXhphwZeVOqjLg/WZAwW3THurmD8R+BITHm9afiIiI6iwp2YB7nIjquJhwJZYNbw8fN0ez75WWXYjP96fohCYASM82UEzCnDLlAJCfCawfBeyYbfo9iIiIiIxgcCIixIQr8fusB/FabGur3F8zrV1lMYnuUwEnT/MecnAxcGajefcgIiIiqgKDExEBUJcsb+DlbLX7C1DPSB1Jyar8olwBDFhi/kM2TVQv/SMiIiKyMAYnItJq4Gm5UuVVuXGnUP8L4fFA1ETzbl58B9j/wd3PVWVAygHgz/Xq/zJUERERkYkcbD0AIrIfkSF+UHq7VNqjZEkGw1m/dwDIgKRPTH/AgY+AxpFA4S1g2ytAfsbd17wCgZgFQNgA0+9PREREdRJnnIhISyGXYU5cGPQUDjebDOrqepEhfoYb9nsbeGwVoDBx2WBZIbA6Hlg/Wjc0AUDOdWDdCCB5s2n3JiIiojqLwYmIdMSEK7F0eHsovS2/bG9OXJj+85wqahMPvJYGtI63+BgAAJte4LI9IiIikoTBiYgqiQlX4tdpvTD7IctU2fN3d8LS4e31n+NUFbkCGLoK6DzBImPQUXQbWNHf8vclIiKiWovBiYj0UshlqOdpfpU9N0c5fp3WC96uTth08hqSLmXqL0lelZh3gagXzB5HJVcPA9tnWf6+REREVCuxOAQRVckSVfbyS1SImv8LbueXaK8pvV0wJy5M/AxUv7eBxh2BrS9X3rdkjqRPgB7TgbQTQO6/gEdDIDhaPdtFREREVI5MEAQJP/qt+XJycuDt7Y3s7Gx4eXnZejhEdq1MJaDrgt0Wr7Kn2eUkefmeqgzYOA44tdai49HByntERER1hpRswKV6RFQla1XZ0/y05s0tydKW7ckVQNsnLTyaCnKuA+tGsvIeERER6WBwIiKDrFVlTwCQll2IIylZ0jo27Qq4+Fp0LJUJQOJ0Vt4jIiIiLe5xIiKjYsKVeDAsAEdSsnDjTiEuZ+Rj5cEU3Cq3b8lUN+5IXAYoVwADFqvPY7KmnGtA6kEgpJt1n0NEREQ1AoMTEYmikMsQ1dxf+3kTfzdMXnvS7PuaVIAibAAw5Btgy4tAwS2zx1Clc9sYnIiIiAgAl+oRkYkCvMxbuieDurpeZIifaTcIGwC8cgkYsQlofL9ZY6nSqXVcrkdEREQAGJyIyESRIX5m7XsSAMyJC4NCbkbpCbkCaN4TeGYX8NgqwMnT9Hvpk5+hXq5HREREdR6DExGZRFNxz1RuTnK4OzmYdiiuPm3igemp6hmorpOBkAeAlrFA33eAsHjT73vkS846ERERke3Pcfrss8/w/vvvIy0tDW3atMGiRYvQrZv+PQV79+7FAw88UOn62bNn0apVK1HP4zlORJY1d8sZfPXbZbPvI/lQXCn+XA8kjDG9v6s/8NBHQHi8xYZEREREtldjznFau3YtJk2ahNdeew0nTpxAt27d0L9/f1y5csVgv3PnziEtLU37ERoaWk0jJqKK+oQFWOQ+admFGLv6OOZuOWOZGajyPBqa178gE1g/Ctj+mmXGQ0RERDWOTWecOnXqhPbt22Pp0qXaa61bt0Z8fDzmzZtXqb1mxunWrVvw8fEx6ZmccSKyrDKVgK4LdiM9uxCW/MfEojNQqjLgg1AgP9P8ewV2BPxCAJkM8AkCQnqoz5aSK8y/NxEREVWrGjHjVFxcjN9//x19+/bVud63b18cPGh4M3a7du2gVCrRu3dv7Nmzx2DboqIi5OTk6HwQkeWYu9epKmnZhRi3+jgST6eZfzO5Aoj9yPz7AMD1Y8DpH4A/1wEHPgS+HgC8fw+QvNky9yciIiK7ZLPglJGRgbKyMjRsqLuEpmHDhkhPT9fbR6lU4osvvkBCQgI2bNiAli1bonfv3ti/f3+Vz5k3bx68vb21H0FBQRb9OohIfUDu0uHt4ePqaNH7CgDe3JJsmWV74fFA9Ivm30efgiz1gbynN1rn/kRERGRzNj8AVybTLUUsCEKlaxotW7ZEy5YttZ9HRUXh6tWr+OCDD9C9e3e9fWbMmIEpU6ZoP8/JyWF4IrKCmHAlPF0c8eT/Dlv0vmnZhTiSkqVz+K7J+s4FGnUAtr6sLjVuaeufArAccK8P5P6r3lsVHM1lfERERLWAzYJTvXr1oFAoKs0u3bhxo9IslCGdO3fG6tWrq3zd2dkZzs7OJo+TiMTr3MwfSm8XpGUXWvS+N+5Y8H5t4oHWcerzme6kqUNUkaWW8ArA+tG6l9z81csEWZGPiIioRrPZUj0nJyd06NABO3fu1Lm+c+dOREdHi77PiRMnoFRaoXwxEUmm2e9kxpG2el34N9eylfbkCiCkGxAxBIj7xDL3rEr+fxX5dsy27nOIiIjIqmy6VG/KlCkYMWIEOnbsiKioKHzxxRe4cuUKxo4dC0C9zO7atWv4+uuvAQCLFi1C06ZN0aZNGxQXF2P16tVISEhAQkKCLb8MIipHs9/pzS3JFpt5WrLnIpbsuWids57C44HrLwIHF1vunvocXAw4ugE9XuXSPSIiohrIpsFp6NChyMzMxFtvvYW0tDSEh4dj27ZtCA4OBgCkpaXpnOlUXFyMqVOn4tq1a3B1dUWbNm2wdetWxMbG2upLICI9YsKVeDAsAEdSsnDjTiH2n7+JhOPXzL5v+n+V9j4d1g6+7s64cacQDTxdEBniB4XcjHkuzd6nTROB4jtmj7NK++YDR74AHlqoDmyqMvWSQe6HIiIisns2PcfJFniOE1H123TyGl76/qTF7ieXAeVX7VlsJkpVBqQcAE58A5xeb969jGnRD/jnd90iFV6BQMwCIGyA7pgYroiIiKxCSjZgcCIiq0u6lIknvjxktftr5pqWDm9vuQNz379HXWa82smAIV+rw1PyZiBxGpBz/e7L+sIVERERmaRGHIBLRHVHZIgflN4uFi8aoaH56Y/FznySK4C4j82/j0kEYMuLwJ55wLqRuqEJUH++bgQP3CUiIqpmDE5EZHWaansArBqeNGc+WUTYAGDIN+oZnvJc/AC5ZQ/6raTglno/FAyEwA3PAcUF1h0HERERaXGpHhFVm8TTaRattqfPiM5NEHtvoPkFIzT07TFK3qIuMW5zMiD6BXVxCyIiIpKMe5wMYHAisq0ylaCttvf3zTx8svsCLHU8U3l+7o54e2A4YiMCjTc2xQ+jgTMbrHNvqaImAi1iWECCiIhIIgYnAxiciOzLtlNpGP/dcavd//nuIZgRG2b5G6vKgHlBQEme5e9tLjd/IPYjdclzIiIiqhKLQxBRjREbocRnw9pZbe/T5/tTsGjnecsUjShPrgAGfmbZe1pKfqZ6KeHidsDBJUBpsa1HREREVOMxOBGRzcVGBOKl3qFWu/+iXy6gy/zdSDydZtkbh8cD0S9a9p6WlPU3sOM14O0GwI7Zth4NERFRjcbgRER24YXeoXB3tt6+nPScQoxbfdzy4anvXOCxVYCrv+51DyXQYzrQdTIgs/V+IwE4uNh4eFKVAZf2ArvfBn55G/h7n/oaERERcY8TEdmPbaeuY/x3J6x2fxmAAG8X/Dqtl2Uq7pWnr/qepkBD8mb12Uv2oMsU9bhCugFNu+qOccuL6lLo5bn6qc+04oG7RERUC7E4hAEMTkT2bd62ZHy+P8Wqz/h2TCfI5TLcuFOIBp4ulitdbkjyZmDjWKDYjopJuPgCAxarf20s2A35xnh4MhQeiYiI7BCDkwEMTkT2b9upNMzadBpZedYpauDt6ojsghLt50pvF8yJC0NMuNIqz9NSlQH73gOSlgDFudZ9lhSObkBJvuE2bvWAmHmAp1J/IEreDCROA3Kul+vD6n5ERGTfGJwMYHAiqhk05z2lZxfg9c1ncKew1GrP0sw1LR3e3vrhCag8M3P+ZyDpU+s/11IqBqLkzcC6kQCq+N9J9Is8pJeIiOwSg5MBDE5ENY+19z5pKK21/0mMwlxgfqPqf645ol8E+rwBLArXnWnS57FVQJv46hgVERGRaDzHiYhqldiIQDzfPcTqz0nLLsTCneeRdCnT8uc+GePiAURNrN5nmuvgYvXSQ2OhCQC2vswKfUREVKNxxomIaoxFO89j0S8XquVZ1bbvqaI1TwDntlXvM80iQ5VL9CoKuA+o1wLwbQKE9NCt6kdERGQDXKpnAIMTUc1VphLQZf5upOcUWv1Z1b7vqbzTG4AtLwFFOXevufoDUFUuF16TKZyBLpOBnq8yQBERkU0wOBnA4ERUsyWeTsO41cfFznGYxarnPhmjr7T3X1sNF2GoqeSOwCNfAPcOqr5nlhYDR78Ebl0GfJsC9z8LODhV3/OJiMguMDgZwOBEVPMlnk7Dm1uSkZZt/ZknAJjQszm6htavnvOejNFX9tvJE+g0DgiOAlJ/BX79GBCsV4XQahpHAk8nipt9MufMqB2z1SXhBdXdazK5eo9ZTa7+x3O0iIgkY3AygMGJqHbQlCu/cacQ9dydcfRyltX3P/m5O+LtgeGIjQi06nOMMvYN8o/jgT++td34zCF3BAb9T13qvKpZoeTNwM+vAnfS7vbzVAL939N/SG/536+/tgJnNlT9/JpaOv3MRnUBjvyMu9e8AoGYBcYPLiYiqsMYnAxgcCKqncpUAjq8vRO380uMNzZTXEQA+oQFoIGni33MQlVUWgy83QA1ekmfe0Mg7wZ0vgaZHGgRY7h4xpBvdIOCvkBhiEwBvJZes5bt7ZitrnColwwY8jXDExFRFViOnIjqnCMpWdUSmgBgy6l0vPT9STzx5SF0XbAbiafTjHeqTg5OQPQLth6FefL+RaXgJ6iMVxxMeBa4uEc9y7RjNvDDKPGhCQCEMvUslz1QlQEpB4A/16v/q6+c++mNBkITAAhA4nSWgicisgAHWw+AiMgSbtypnv1OFaVnF2Lc6uO2qb5niGa5WcW9PLVdWSGwOh5wdAdK8ky7R+pB9RJIW+4T0reXzc0fiP1IvYwRUIehbVOM3yvnmvprCulmlaESEdUVDE5EVCs08HSxyXM1cyLTE/6Ep4sjOjfzBwDt/iubLufrOxfoNVt3n5CnEtg6pXJZc4ULoCqtmUUl9DE1NAHAXz+pPwDAyQPoPNG0kumlxcCRz4ErhwAndyDiCaBZd/V9DO1TS96sv3pifiawfhSwozFw7xDA3V99TYzcf6WNnYiIKuEeJyKqFcpUArou2I307EKb7uzxcXMEAJ1lgzY7TLcqmiVgqb+qvzcP6aY+jHb/B8Ded209Ovvk5AHEL628V6iqALRjNnDwE1QKPw4uQMcxwKm1uksINbNJYXHAonDdmSZLGPVTzZ1xYrVAIrIiFocwgMGJqPbSnPEE2GdZhNHRwWjs6wY/D2cEeNlhYQlVGfBec6CwFh2ya2nK9oCzp/rXRTlAxnnd2S03f3VZ9fM/m3b/NoMMV/0zhUwOvPZvzSp4oaFvySKrBRKRBTE4GcDgRFS76TvjycfVEaO7NEVoA0/M3Vp95z8ZY3czUcB/y8RGmN7f2Qt4aCHgXg+4vB+4/Q/g0xgI6QE0iVLPHGydAmRdstyYybiaOONU1ZJFjYoVFImITMDgZACDE1HtV/6Mp4p7jMpUAhbuPI8ley7aeJRqMsD+Ckskbwa2vFh5H5STJxC3GHDzu7vMT7NsKu+mtGVUf64HEsZYZfikR+fxQMw8W49CPFWZ8SWLrn7AKxfNX7ZX1dJVLgckqhMYnAxgcCKipEuZeOLLQ7YeBgB1cArwdsGv03rZ37I9a38zeWajulw4WZ+LH9BtMnD1cOVCFYZo3gcVZw/FvBfEvIequj8AfC1iNqnnTKDnNOPtqlLVDwlc/YC4jzmjZUncq0Z2isHJAAYnIipTCegy/xek5xTZeihaa57tjKjm/rYeRvVL3gxsfgEovG3rkdQ9ckcg+iXA1Vtd+a8oV33d2R0I7qLeS6SvAiMAuPgCAxZXHSwMzVoOWKIuqV5VG0Bd5bFMxJJac2adxCxLrY3LAW0xw3ZmI/DTFKCgXBVIhQsQ2heIfIYzfGRTDE4GMDgREaDeCzX2v0IS9uDjx9tiYNtGBpcZ1lqqMmDfe8C++bYeCUn16Kq750ppiAkkLWONH2Yslmb/Vmmxbun9+5/VLYhRPjCoVMDhz4GSXMP3NhbMpIYQQyXqq4MtZti2zwKSPjHcxlgQtydc2lnrMDgZwOBERBqJp9MwfcOfOqXDAcDH1QElKgF5RWXVNpY1z3ZGdkFxpcIWfu6OeHtgOGIjAqttLDajr4Kaqz/g1xy4dsR24yLD6rUCXLwARzdA2RY4+j/jgcSSAtsDPk2As5srHPYsA6ImAP3eUc94bJoIFN+Rfv+qlgNWdc/ys2rlbZ+lPpBaX4n6+M8rt9fHWDg0xFIzbPqCg6bwS8UwsWM2cOhTceMT+3xbqip41qTgR5UwOBnA4ERE5ZWpBBy6lImkvzMAyBDV3B+dm/lj++k0jP/uRLWNo3OIHw6nZFVZRv357iGYERtWbeOxmar2Qehb6uPqD8R+oC5WsXsucO2YzYZNdsynKXD7sun99c067ZgNHFxsuF/0i+pDqAHgu8eNl6iPmqgOeVXZPksdQqoKhxr6wpVcASxsA9xJMzwGr0bAiyfVe+H07UWSEkBlDtIP1Jay9FIT4FL2Av+cAMoKAJ9g4L5h+mfxzNmvB1h2aaeY/V6W3BPG/WUGMTgZwOBERGK98N3v2HIq3dbD0Bod3RR92wTUjeV7+hj7n3/iTHE/3W4dB/i3AI58YdoMBNU9DSIAZ1f1N+Y+wcCB98X1e2yVelne4aXi2ke9APR7W/eaqgxYHgP8Y2DW1SdEPa6Mv4DcCv9myeRAWLz488Hc/IH8cj+g0JybdfWI8SV3ltC0BxDU0XCoMRbgKs7iGdpPV3GGUN+/M4C4M+7EBD8xZ5Ppa+PkAXSeCPR8VVro0fdDJ0d39XtN6r1qKQYnAxiciEisMpWADm/vrLSUz9bs8vwne2FsP0X5WQBj5wQR2UJQFOATpP6QKYBfFwGqYluPyjb0LXsUM9unEf0i0Ph+cWfTRb8IBLYDtrykPtxawysQCOosPniO2AQ076n/NWOzVkO+Uf/XUBuxSztVZcD6MUDyj+bfq5ZjcDKAwYmIpEg8nYZxq4/b5bfWj7ZvhC6h9RHgVUeKSIh1ZiOw9WUgP+PuNbd6QOyH+gsZVNpX5QcUZBl+hkwBCNW3Bw4AEBABpJ+q3mcS2YOoiUCzXsD+94CrEo+ScPGp3qqd3V4Gmj1QeWZcVQa831z/rJeGozsgkwHFIvYIRk0EWsTon4FP3gz8+DxQki9uzFETgXselLaMUcryP3P25lUDBicDGJyISKrE02l4Y/MZuypfXlFVs1B1skofIO1/6vra/rXVcDntsLi7fdzqqfedpP4KZKWqDwMuKwS8g4BLu42HMDFa9FfvZVn1sPn3IiLrcfLQDT5OHkCn8cCtFOD0D9Z9bueJQMPWljsfr6pqi/p+OFVxuaGGvr15Mrk6rGlm/22MwckABiciMkWZSsCS3RexcNd5Ww+lSjIAS4e314anxNNplar0cZmfBJYoOyxmQ7lBciBqvHrzv6pM3AZ/IiJL0hS9UJUBPzwNnN1ovG1pMfB5N+DmX1W3Lb902oYYnAxgcCIic+gLI/bE29UBnz3ZAdn5JZjwXeUlhpq5pvIBi6zM0GGwcYvVVQE14SyoE5BxDridqn9Ji9lBjIhIIs9AoN1wYP8HAFSG27r4As16AMkbRdxYBsy6YfNlewxOBjA4EZG5yi9/u5yRjzVHriA9x76ClEwGVPWvuwxAQy9nfDikLTJyi+rWEj5bseShmcmbgY1jgeI8iw8TMnmFctdERFbUIBwYu9+m1f0YnAxgcCIiS9MEqfTsAmTlFeOf2wX44dg/yC2SeIaJDfm5O+KRto3QJ0y33Hmd3SNl71RlwL73gIOfACXlApRnIHDvo4arjnUeD4T2078RHKj6bJymXYANzxmu0mUyOYz+JJuIaicHF2DQlzY7QJjByQAGJyKqDpqDdQ9cvIHdZ2/i/A0RVZLshK+bI96JD4dcLuMeKXtXVREMfdUCq6osKFVpMXDkcyA1CSjKVU9t/nvKeOWysEcA/2a6BTTKh7IPQo3fw9kH6P6y+myktFNAzlXzvhaqfo4egMKheivdUc0g9gBhC2NwMoDBiYiqW9KlTDzxpcQSunaKe6RqECmVBS3h9AZg43igtED3ur6zePQRs3+r4jdWmhB35RDg6Apc/EVcFcPOE4DQvrpLJwtuWa4aGVXtsVXqJaHcq0cVeTUCJv1Z7cv2GJwMYHAioupWphLQdcFupGcX2uV5UKbwcXXAJ0+0R0ZuEbLyiuHn4YwALxd0CPbF76m3uLSvrjJ3L1dVhTRcfIEBi43/NFpM+IqaqK5SKOX5kMFiByW7+ALtR4g/xLUSI8saK5bDtrZWA9ShtbQAOLvZcNuKB1Dr/b2mOm3UT+p/N6oRg5MBDE5EZAuag3QBi337ZZcqFqUov3eqQ7AvjqZkIenvDAAyRDX3R+dm/gxWpMta4UvszFdVzweAPfOBQ58AJeVm1dzqAY3vB87/XPU9/Vuoz/4qf6io1OCgcAG6TAJ6vgrsnKPnbByF+qyvvnPV5+xsmggU3xF3b1M4eQDxS3XDrNTfe83vtWa/XeZF4PrvEsfhqa74dnipSV8G2ZnBX6n3aVYjBicDGJyIyFb0lTL3cXVE19B6OHb5lt1V5rM0fT+zd3NS4PnuzTCxVygDFFmOJasY6ru3viWQ+g4FNbavrGJw8GkMBP8X0lJ/rVy8o/z4S4uBo18Cty7rL12vufexr4DziUBZse6zXf2Atk+q71Eq8d+expHA04n6fz/N/b3fPgtI+sRwG1d/oP0ooHnPu/de8wRwbpv4r6FFP+Dvffq/9kb3AzfPVp65kzsCoTHApZ3Sf8/sgaO7bjEZe8QZJ/vC4EREtlRVlboylYCVv6Vg7tazth6iTfi4OeLd+HB4uzpxRopqrureVyZlXFWFGVUZcGkvcGoNcPsq4NNEXbDj0k7g0NIK5enLHchsTWc2Aj8+rz+cGFpquX1W5Zm4ihxcgPjP1WFW87X/uRYoygOCo4DI59QB1NDv2dqRwNlNpn1tMkcgfJC6v9jw1WM60CRKHYIv7tSd8RQr6gUgKNK+95Zxj5P9YXAiIntVG/dCmcvdWYHHOwZVKpNORNXA2KyWNRkKNYaUH7N3Y0AlANeOAk7uQMQTQLPu5n9j/vc+4GsJ1d8ahAMt++nOHJ7eCKwXUYzE1Q945eLdMVcM5+d/BpI+NXyP8mGzquWUChf1ONOOif+6RJMBfs2ArEuGm7Gqnv1hcCIie1ZX9kKZonwpdJ4vRUQ2oyoD3msOFIrYn1Yx+JS3Y7bxIiFiwkRVe9ocPYCBn1a9t0zfbNp3jxverweoQ9YjnwPXjhlfVhkWDzy6XH3v7bOApCWo9H83ffvlqhGDkwEMTkRk7/TthZLL1D841fBwVsBBIcft/BIbjNC2nu0Wgp9OpZl1vhSDFxGZRUwFR8B48Kkq9Lj6AXEfiw8TltzXV1XAkTsCXV9WFyjR3Fff3j6FC9DmEXUlzIozhOWPELDkLKAZGJwMYHAiopqg4jf2+sp8A9Bpk5FbhOkJp5BXXGbj0dvOo+0boUtofQR4VR2G9AVTHuxLRJIZqowoJfhYs5iJqaQEHHvd2ycSg5MBDE5EVJuVqQS89P0J/HQqzdZDsTkXBxl6tGiA0Iae2kITO5PTMW718SqXQU7uE6q3wp8myKZnF+icW8WZKqI6Tl9lRH1VEMluMTgZwOBERHXBtlNpmLXpNLLyio03riMcZIBcLkNxmeH/7TkrZIgI8kHHpr7wc3PG9ewCbDp5Xe/vpdLbBbMfam20GiCXBhIR2ScGJwMYnIiorij/zfrljHysOXKl1p8VZS/Kn0+1Mzkdb2xO1vm9D/BywRsDwvBgWAADFRGRDTE4GcDgRER1VfkgVc/dGZABGblFuJyRj0W7zgNgJT9Lc3KQo7i06jNlfNwcdQp8aPZaiQ1UnMkiIjIPg5MBDE5ERJVVVTDhtf6t8PqWZC75q2YezgrkFt0t8uHn7oi3B4ajX7jS4CxigJcznohsgqb13CUFKQYwIqqrGJwMYHAiItKvqm+eNWdL1an/WdgpZwc5igzMYFXk5+6IR9o2Qp+wAL2VGTV/vhVDs6+bA6Ka+aNZfU+9e7Y0GLiIqKZjcDKAwYmISDp931xrZkVk4BK/mqDin5PS2wUPhQfgf79dNtrX29UBT3cJ0ZnJ2pmcbrGy7lUtI62q9D4DGhFZCoOTAQxORESm0Te7oO+b5/KzHBm5RZiz+QyX+tUyjnIZSlRVf/vwUu97EBnirxN+KlYZPHQpE0l/Z+DSzTwcTsmq8j2i77BnnrtFRJbC4GQAgxMRkWUZW67F6n7k4+qA6Ob+aFrPA9dvF2Drn2koMVIWXoyXet+DMpUATRn4+5v6aZcj6pu5UshlOqGtYvl4Sy49NHav4lIVvkm6jNSsfAT7uWFEVFM4Och5ZhhRNWNwMoDBiYjItsp/Y/jbxQzsPHsD2QUlxjsSmUHp7YKHI5RYc+QqcotKdV5zcZSjc4gffr9yG3cK776mKbbRxM8NWXnF8HFzwu38u//183BGAw9nqAQBh1MyoRIAXzcn/HMrHxtOXNO5V/lZsnnbkvHlgRSUn7STAQhv5IVrtwurPDOsumfZuIeN6gIGJwMYnIiI7EvFb85u5RVj7lbd5X/G9lHdH+yDRr5uyCsuxa8XMlBQIr6AAlF1auzjgn9umz7jOrlPKCb2CgVgfN9X+R9SZOQW4XZBCWSQoVOIH+Rymd6llJoZudWHL+PAhQyd6o5iwhvDFtU0DE4GMDgREdm/it98dQj2xdK9l7DitxTcLjC816VMJWDJ7otY+N/ZVES1jYNcBhkElP/5gLuTAmO6NkWHJn7YcOIf/HktG1ezCgzuRdNwc5Ijpk1D5JeosPevmyg0Urnx0faNENW8ns6sG2TAruR0rD+uO9MmprIjoP/vfPm2hvqW72/JJY62DoG2fn5dweBkAIMTEVHNJeUbicTTaZi+4U+dogJEZDsVZ47dHOUIb+QNX3cnHLyUqRO4jPX1cXVAVDM/ODkocP12Af68noNCPTPNmv11mtL65ffBGQpgO86kVQqBHs4KPNahMfq2UeoEuYr76Qy9ZqxKpKHn+7k74q24NvD3dBE106gvdJYfT1X7AA2pjXvwGJwMYHAiIqo7NLNPFWeqfFwdMbpLU4Q28Ky0LJCI6g6FDGhe3w0eLo7ILSzF5cwCFJcZX+praPmwodecHGRQyGQ6y4k9nOVoXt8Dzgo5zv6bazBAVuThLMfT0SEIqe+BjNwiHEu9hX3nb+oNkca4OcnRPzwA0c3rIyO3EGfT7iCvqBQNvVzQNsgHh/7OxI7kf5GjZ3yaWUuljxuE//b61fO8G6oA2G3gYnAygMGJiKjuMTRTJWaPlVwGnY38Sm8XDLhPic1/pDF0EREZIAcgl8tQqmfZqK+bI96JD0dsRGD1D+w/DE4GMDgREZExxvZblC9tXdXBrbfyijFzo7ilgoPbB6JraAOk3MjF5wcuoai0Tv2vmYjquOe7h2BGbJhNns3gZACDExERVRdjB71WVdzipe9P4KdTaZKeNaidUvTmfiIie/PZsPaIjaj+Q60ZnAxgcCIiIluRUtxi26k0vJpwqtKZQxUFeDnjjQFttOFL3wGv7Zv4YvbGP7HtdDryi++Wl1bIAQe5HEXlgpaTQg6FHCzpTkTVys/dCUdf61Pte55qVHD67LPP8P777yMtLQ1t2rTBokWL0K1btyrb79u3D1OmTMGZM2cQGBiIV199FWPHjhX9PAYnIiKqKcqHIM3hqn7udw9flbq5Wl9wAypX+NJc01fZK8DLGUPvD0KZSoBKALxdHXH8iukb0omINNY82xlRzf2r9Zk1JjitXbsWI0aMwGeffYYuXbrg888/x//+9z8kJyejSZMmldqnpKQgPDwczz77LJ5//nn89ttvGD9+PNasWYPBgweLeiaDExERkXhiZ8nKt7uckV+pkiEAuDjK8cT9QejbRolbecV466dkpOfcLa7h6aLAo+0bo0/rAKgEAUl/Z+DarQLIZDIUlpbh1/OZyC0WX3GMiGqWjx9vi4FtG1XrM2tMcOrUqRPat2+PpUuXaq+1bt0a8fHxmDdvXqX206ZNw+bNm3H27FnttbFjx+KPP/5AUlKSqGcyOBEREVmfviWDnZv56z0zR+wBn5p7/nbpJq7fLkQjX1d0DlH/dPpwSiYAGRzkMnx/9KpOIKuKh7MCuUVlla4bKiddXsVqi0RkHnufcXKopjFVUlxcjN9//x3Tp0/Xud63b18cPHhQb5+kpCT07dtX51q/fv3w1VdfoaSkBI6OjpX6FBUVoaioSPt5Tk6OBUZPREREhijkMnQJrYcuofUMtpHyTZKhe3ZrUV/76xd6h+rMfq05ckUnSGmKcjwYFqD3bJnyVRT9XJ3w1793kJqVB0EQ4O3iBLn8bhDcmZyON7folq8P8HLGE5FN0MTPDRm5RbhdUAJBAP7NKcSuszeQXW4mzsVRDpUAFBso6OEolwEyoKRMekrr2MQbjf3cUVhahsN/Z+EWD4QmO6X0vrtU2F7ZLDhlZGSgrKwMDRs21LnesGFDpKen6+2Tnp6ut31paSkyMjKgVFauxDFv3jy8+eablhs4ERER2bWKgWxir3uqnNmqKriVv96tZX29bQAgJlypDWBiZs6q2mdWfiZN6eMCPzdnvQeI6it9f+NOIWZtPK2zF62qio3l73H0chZWHryss6TSw1mOrvfUR7P6HvB2dcTtgmJcv1WgfV0mk0Hp4wIfVye9rxWUlOHgpUydsXBmjsSYExdm88NwjbFZcNKQyXR/gwRBqHTNWHt91zVmzJiBKVOmaD/PyclBUFCQqcMlIiKiGkbqzJY1719VW2Ozc0DVIQ8AHo4INBreKj67S2g9ndk5McslxdAXDstUAr5JuoyUTN2Zu07/hULNUstOIX6Qy2XaUNgh2BdHU7K0BVI0YS6t3FJNTXtNoLyRU4iM3CJk5avb6QtzLg4ytGjgAQ9nB+C/PXTOCjnkcjlcneQI8HJF+ya+UPq4okOwLz7bcxHL9l2SXOrfWSFHYz8XXLtVaNYxAR7OcjSr5w4vFye4Oimw59xNvQfKiuUgA4LruSM9pxB5eparVidfN0fMG3SvTsi3VzYLTvXq1YNCoag0u3Tjxo1Ks0oaAQEBets7ODjA31//PybOzs5wdna2zKCJiIiI7JCp4dAaoVLfPRVyGcZ0a1Zln/JLLSsSEyqNkbqfrqJJD7bAC71DK+3bu7+pH35PvaVd7unjpr/qZcUKmfoCIFB1gKw43jKVgE9+uYD//fq3zj698gVWNLOS9dydoRIE7b3L7zfU/L6kZxfohE3NmH5PvYUVv6Ugu1zo9HJRoG9YAKKa18Pt/Ltfs4+bE7Ly1EtTy1QCcgpKcCOnCPlFJZD9F0gbeLrAy8UR6TnqZ0Q3r1dp76M9s3lxiA4dOuCzzz7TXgsLC8PAgQOrLA6xZcsWJCcna6+NGzcOJ0+eZHEIIiIiIqpTzA2E9vIMW6oRxSEAYMqUKRgxYgQ6duyIqKgofPHFF7hy5Yr2XKYZM2bg2rVr+PrrrwGoK+gtWbIEU6ZMwbPPPoukpCR89dVXWLNmjS2/DCIiIiKiamftZajV9YyawqbBaejQocjMzMRbb72FtLQ0hIeHY9u2bQgODgYApKWl4cqVK9r2ISEh2LZtGyZPnoxPP/0UgYGBWLx4segznIiIiIiIiExh06V6tsClekREREREBEjLBvJqGhMREREREVGNxeBERERERERkBIMTERERERGREQxORERERERERjA4ERERERERGcHgREREREREZASDExERERERkREMTkREREREREYwOBERERERERnB4ERERERERGQEgxMREREREZERDrYeQHUTBAEAkJOTY+OREBERERGRLWkygSYjGFLngtOdO3cAAEFBQTYeCRERERER2YM7d+7A29vbYBuZICZe1SIqlQrXr1+Hp6cnZDKZTceSk5ODoKAgXL16FV5eXjYdC9U+fH+RNfH9RdbE9xdZE99fVJ4gCLhz5w4CAwMhlxvexVTnZpzkcjkaN25s62Ho8PLy4l9cshq+v8ia+P4ia+L7i6yJ7y/S+H97dx9TZfnHcfxz5OFwODHGw+AAToRlEZKmYMtkmdoMpZplTwwU6g9HCUGuwpUOKg3+qtaWtJjxDzQaixo1Z4EVS1vhYEePD2ktUlMZOcsnEtJz/f5o3fudH9r5xVEO6Pu13dvhur4crnv77Iwv931f+LvS9Dc2hwAAAAAAP2icAAAAAMAPGqcgstvtqq6ult1uD/ZScA0iX7iayBeuJvKFq4l8YbSuu80hAAAAAODf4ooTAAAAAPhB4wQAAAAAftA4AQAAAIAfNE4AAAAA4AeNU5Bs2rRJaWlpioiIUHZ2tr7++utgLwkTQG1trebMmaOoqCglJCRo2bJlOnDggE+NMUY1NTVKTk6Ww+HQ3Xffrb179/rUDA0Nqby8XPHx8XI6nXrggQf0yy+/jOWpYJyrra2VzWZTZWWlNUa2EKijR4+qqKhIcXFxioyM1G233aaenh5rnoxhtC5cuKB169YpLS1NDodD6enpeuWVV+T1eq0a8oWAGYy5lpYWExYWZhoaGsy+fftMRUWFcTqd5tChQ8FeGsa5e++91zQ2Npo9e/YYt9tt8vPzzZQpU8zZs2etmrq6OhMVFWU+/PBD4/F4zGOPPWaSkpLM6dOnrZrS0lKTkpJiOjo6TG9vr1mwYIGZOXOmuXDhQjBOC+NMd3e3mTp1qpkxY4apqKiwxskWAnHy5EmTmppqSkpKzHfffWf6+vpMZ2en+fHHH60aMobR2rBhg4mLizOffvqp6evrM62treaGG24wb775plVDvhAoGqcguP32201paanPWEZGhlm7dm2QVoSJamBgwEgyXV1dxhhjvF6vcblcpq6uzqo5f/68iY6ONu+8844xxpjff//dhIWFmZaWFqvm6NGjZtKkSWbr1q1jewIYd86cOWOmTZtmOjo6zPz5863GiWwhUFVVVSY3N/ey82QMgcjPzzdPPvmkz9hDDz1kioqKjDHkC1cGt+qNseHhYfX09Gjx4sU+44sXL9Y333wTpFVhojp16pQkKTY2VpLU19en/v5+n3zZ7XbNnz/fyldPT4/+/PNPn5rk5GRlZWWRQWj16tXKz8/XPffc4zNOthCo9vZ25eTk6JFHHlFCQoJmzZqlhoYGa56MIRC5ubnatm2bDh48KEnatWuXtm/frqVLl0oiX7gyQoO9gOvNiRMndPHiRSUmJvqMJyYmqr+/P0irwkRkjNGaNWuUm5urrKwsSbIydKl8HTp0yKoJDw9XTEzMiBoyeH1raWlRb2+vdu7cOWKObCFQP/30k+rr67VmzRq9+OKL6u7u1jPPPCO73a6VK1eSMQSkqqpKp06dUkZGhkJCQnTx4kVt3LhRBQUFkvgMw5VB4xQkNpvN52tjzIgx4J+UlZVp9+7d2r59+4i50eSLDF7fjhw5ooqKCn3++eeKiIi4bB3Zwmh5vV7l5OTotddekyTNmjVLe/fuVX19vVauXGnVkTGMxgcffKCmpia9//77mj59utxutyorK5WcnKzi4mKrjnwhENyqN8bi4+MVEhIy4i8XAwMDI/4KAlxOeXm52tvb9eWXX2ry5MnWuMvlkqR/zJfL5dLw8LB+++23y9bg+tPT06OBgQFlZ2crNDRUoaGh6urq0ltvvaXQ0FArG2QLo5WUlKTMzEyfsVtuuUWHDx+WxOcXAvP8889r7dq1evzxx3XrrbdqxYoVevbZZ1VbWyuJfOHKoHEaY+Hh4crOzlZHR4fPeEdHh+68884grQoThTFGZWVlamtr0xdffKG0tDSf+bS0NLlcLp98DQ8Pq6ury8pXdna2wsLCfGqOHz+uPXv2kMHr2KJFi+TxeOR2u60jJydHhYWFcrvdSk9PJ1sIyLx580b8+4SDBw8qNTVVEp9fCMzg4KAmTfL9tTYkJMTajpx84YoI0qYU17W/tyPfvHmz2bdvn6msrDROp9P8/PPPwV4axrmnnnrKREdHm6+++socP37cOgYHB62auro6Ex0dbdra2ozH4zEFBQWX3G518uTJprOz0/T29pqFCxey3SpG+O9d9YwhWwhMd3e3CQ0NNRs3bjQ//PCDaW5uNpGRkaapqcmqIWMYreLiYpOSkmJtR97W1mbi4+PNCy+8YNWQLwSKxilI3n77bZOammrCw8PN7Nmzre2kgX8i6ZJHY2OjVeP1ek11dbVxuVzGbrebu+66y3g8Hp/3+eOPP0xZWZmJjY01DofD3Hfffebw4cNjfDYY7/63cSJbCNQnn3xisrKyjN1uNxkZGebdd9/1mSdjGK3Tp0+biooKM2XKFBMREWHS09PNSy+9ZIaGhqwa8oVA2YwxJphXvAAAAABgvOMZJwAAAADwg8YJAAAAAPygcQIAAAAAP2icAAAAAMAPGicAAAAA8IPGCQAAAAD8oHECAAAAAD9onAAAAADADxonAAD+BZvNpo8//jjYywAAjDEaJwDAhFFSUiKbzTbiyMvLC/bSAADXuNBgLwAAgH8jLy9PjY2NPmN2uz1IqwEAXC+44gQAmFDsdrtcLpfPERMTI+mv2+jq6+u1ZMkSORwOpaWlqbW11ef7PR6PFi5cKIfDobi4OK1atUpnz571qXnvvfc0ffp02e12JSUlqayszGf+xIkTevDBBxUZGalp06apvb396p40ACDoaJwAANeU9evXa/ny5dq1a5eKiopUUFCg/fv3S5IGBweVl5enmJgY7dy5U62trers7PRpjOrr67V69WqtWrVKHo9H7e3tuvHGG31+xssvv6xHH31Uu3fv1tKlS1VYWKiTJ0+O6XkCAMaWzRhjgr0IAAD+HyUlJWpqalJERITPeFVVldavXy+bzabS0lLV19dbc3fccYdmz56tTZs2qaGhQVVVVTpy5IicTqckacuWLbr//vt17NgxJSYmKiUlRU888YQ2bNhwyTXYbDatW7dOr776qiTp3LlzioqK0pYtW3jWCgCuYTzjBACYUBYsWODTGElSbGys9Xru3Lk+c3PnzpXb7ZYk7d+/XzNnzrSaJkmaN2+evF6vDhw4IJvNpmPHjmnRokX/uIYZM2ZYr51Op6KiojQwMDDaUwIATAA0TgCACcXpdI64dc4fm80mSTLGWK8vVeNwOP6v9wsLCxvxvV6v91+tCQAwsfCMEwDgmvLtt9+O+DojI0OSlJmZKbfbrXPnzlnzO3bs0KRJk3TTTTcpKipKU6dO1bZt28Z0zQCA8Y8rTgCACWVoaEj9/f0+Y6GhoYqPj5cktba2KicnR7m5uWpublZ3d7c2b94sSSosLFR1dbWKi4tVU1OjX3/9VeXl5VqxYoUSExMlSTU1NSotLVVCQoKWLFmiM2fOaMeOHSovLx/bEwUAjCs0TgCACWXr1q1KSkryGbv55pv1/fffS/prx7uWlhY9/fTTcrlcam5uVmZmpiQpMjJSn332mSoqKjRnzhxFRkZq+fLlev311633Ki4u1vnz5/XGG2/oueeeU3x8vB5++OGxO0EAwLjErnoAgGuGzWbTRx99pGXLlgV7KQCAawzPOAEAAACAHzROAAAAAOAHzzgBAK4Z3H0OALhauOIEAAAAAH7QOAEAAACAHzROAAAAAOAHjRMAAAAA+EHjBAAAAAB+0DgBAAAAgB80TgAAAADgB40TAAAAAPjxH43+0efVpYLgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on the test set...\n",
      "    Test Batch [1/12], Loss: 0.0397\n",
      "\n",
      "Final Test Loss: 0.1928, Test Accuracy: 95.16%\n",
      "Saved E2E CNN predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "#init the model, CrossEntropy loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#getting unique labels from entire dataset (train, validation, test)\n",
    "all_labels = []\n",
    "for loader in [train_loader, val_loader, test_loader]:\n",
    "    for _, labels in loader:\n",
    "        all_labels.extend(labels.tolist())\n",
    "all_labels = np.unique(all_labels)\n",
    "\n",
    "# init model with correct number of classes\n",
    "num_classes = len(all_labels)\n",
    "model = hyperspectralCNN(input_channels=window_num_channels, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#lists to store losses and accuracies\n",
    "classification_epoch_losses = []\n",
    "validation_epoch_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "#early stopping parameters\n",
    "patience = 100\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "best_model_weights = None\n",
    "\n",
    "#training loop + validation with early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    # TRAINING\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    print(f\"\\nLOG: Epoch [{epoch + 1}/{num_epochs}] - Training\")\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2) \n",
    "        target = target.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        # backward pass + optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accum loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"    Training Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store average training loss per epoch\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    classification_epoch_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] completed, Average Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            data = data.to(device).permute(0, 3, 1, 2)\n",
    "            target = target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # accu calculation\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "            if batch_idx == 0 or (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Validation Batch [{batch_idx + 1}/{len(val_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc + store validation metrics\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    validation_epoch_losses.append(avg_val_loss)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if avg_val_loss <= best_val_loss:\n",
    "        print(f\"Validation loss improved from {best_val_loss:.4f} to {avg_val_loss:.4f}. Saving model...\")\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        best_model_weights = model.state_dict()\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {epochs_without_improvement}/{patience}\")\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}. No improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "# loading the best model weights\n",
    "if best_model_weights is not None:\n",
    "    print(\"Loading the best model weights...\")\n",
    "    model.load_state_dict(best_model_weights)\n",
    "\n",
    "completed_epochs = len(classification_epoch_losses)\n",
    "\n",
    "# plot for loss and accuracy trends over epochs\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), classification_epoch_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, completed_epochs + 1), validation_epoch_losses, label=\"Validation Loss\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, completed_epochs + 1), val_accuracies, label=\"Validation Accuracy\", marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Validation Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#test Set Evaluation\n",
    "print(\"\\nEvaluating on the test set...\")\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "e2ecnn_test_predictions = []\n",
    "e2ecnn_test_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data = data.to(device).permute(0, 3, 1, 2)\n",
    "        target = target.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        #accuracy calc\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "        e2ecnn_test_predictions.extend(predicted.cpu().numpy())\n",
    "        e2ecnn_test_true_labels.extend(target.cpu().numpy())\n",
    "\n",
    "        if batch_idx == 0 or (batch_idx + 1) % 1000 == 0:\n",
    "            print(f\"    Test Batch [{batch_idx + 1}/{len(test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "#calc + print test metrics\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"\\nFinal Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Convert to numpy arrays and save\n",
    "e2e_test_predictions = np.array(e2ecnn_test_predictions)\n",
    "e2e_test_true_labels = np.array(e2ecnn_test_true_labels)\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_predictions.npy'), e2e_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'e2e_cnn_true_labels.npy'), e2e_test_true_labels)\n",
    "print(f\"Saved E2E CNN predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:51.555466Z",
     "iopub.status.busy": "2025-05-08T18:41:51.555466Z",
     "iopub.status.idle": "2025-05-08T18:41:51.654274Z",
     "shell.execute_reply": "2025-05-08T18:41:51.654274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'e2ecnn_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'e2ecnn_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/12 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'e2ecnn_representations\\test'.\n",
      "E2E CNN representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the cnn representations\n",
    "e2ecnn_rep_dir = \"e2ecnn_representations\"\n",
    "os.makedirs(e2ecnn_rep_dir, exist_ok=True)\n",
    "\n",
    "e2ecnn_loaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for e2ecnn_split_name, e2ecnn_loader in e2ecnn_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {e2ecnn_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        e2ecnn_split_dir = os.path.join(e2ecnn_rep_dir, e2ecnn_split_name)\n",
    "        os.makedirs(e2ecnn_split_dir, exist_ok=True)\n",
    "\n",
    "        # processing the data batch-wise\n",
    "        for e2ecnn_batch_idx, (e2ecnn_vectors, e2ecnn_labels) in enumerate(e2ecnn_loader):\n",
    "            e2ecnn_vectors = e2ecnn_vectors.permute(0, 3, 1, 2) \n",
    "            e2ecnn_vectors = e2ecnn_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            e2ecnn_projections = model(e2ecnn_vectors)\n",
    "\n",
    "            # converting projections and labels to np arrays\n",
    "            e2ecnn_projections_np = e2ecnn_projections.cpu().numpy()\n",
    "            e2ecnn_labels_np = e2ecnn_labels.cpu().numpy()\n",
    "\n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_encoded_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_projections_np)\n",
    "            np.save(os.path.join(e2ecnn_split_dir, f\"cnn_labels_batch_{e2ecnn_batch_idx}.npy\"), e2ecnn_labels_np)\n",
    "\n",
    "            if (e2ecnn_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {e2ecnn_batch_idx + 1}/{len(e2ecnn_loader)} for {e2ecnn_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {e2ecnn_split_name} dataset. Representations saved in '{e2ecnn_split_dir}'.\")\n",
    "\n",
    "print(\"E2E CNN representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:51.657398Z",
     "iopub.status.busy": "2025-05-08T18:41:51.656401Z",
     "iopub.status.idle": "2025-05-08T18:41:51.660909Z",
     "shell.execute_reply": "2025-05-08T18:41:51.660909Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_cnn_reps_and_labels(split_dir):\n",
    "    #gather all the cnn_encoded_batch npy files in sorted order\n",
    "    cnn_rep_files = sorted(glob.glob(os.path.join(split_dir, \"cnn_encoded_batch_*.npy\")))\n",
    "\n",
    "    cnn_all_reps = []\n",
    "    cnn_all_labels = []\n",
    "\n",
    "    for cnn_rep_file in cnn_rep_files:\n",
    "        #deriving label filenames\n",
    "        cnn_label_file = cnn_rep_file.replace(\"cnn_encoded_batch_\", \"cnn_labels_batch_\")\n",
    "\n",
    "        cnn_reps = np.load(cnn_rep_file)\n",
    "        cnn_labels = np.load(cnn_label_file)\n",
    "\n",
    "        cnn_all_reps.append(cnn_reps)\n",
    "        cnn_all_labels.append(cnn_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    cnn_all_reps = np.concatenate(cnn_all_reps, axis = 0)\n",
    "    cnn_all_labels = np.concatenate(cnn_all_labels, axis = 0)\n",
    "\n",
    "    return cnn_all_reps, cnn_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:51.662913Z",
     "iopub.status.busy": "2025-05-08T18:41:51.662913Z",
     "iopub.status.idle": "2025-05-08T18:41:51.844041Z",
     "shell.execute_reply": "2025-05-08T18:41:51.844041Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_train_dir = os.path.join(\"e2ecnn_representations\", \"train\")\n",
    "cnn_val_dir   = os.path.join(\"e2ecnn_representations\", \"val\")\n",
    "cnn_test_dir  = os.path.join(\"e2ecnn_representations\", \"test\")\n",
    "\n",
    "cnn_train_reps, cnn_train_labels = load_cnn_reps_and_labels(cnn_train_dir)\n",
    "cnn_val_reps, cnn_val_labels = load_cnn_reps_and_labels(cnn_val_dir)\n",
    "cnn_test_reps, cnn_test_labels = load_cnn_reps_and_labels(cnn_test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:51.847562Z",
     "iopub.status.busy": "2025-05-08T18:41:51.847562Z",
     "iopub.status.idle": "2025-05-08T18:41:51.851680Z",
     "shell.execute_reply": "2025-05-08T18:41:51.851680Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_encoded_data(encoded_dir):\n",
    "    print(f\"LOG: Loading encoded data (representations) from {encoded_dir}...\")\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    #iter through batches\n",
    "    for filename in sorted(os.listdir(encoded_dir)):\n",
    "        if filename.startswith('encoded_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load the features\n",
    "            features = np.load(os.path.join(encoded_dir, filename))\n",
    "            features_flat = features.reshape(features.shape[0], -1) #flatten features for LRM\n",
    "            features_list.append(features_flat)\n",
    "        \n",
    "        elif filename.startswith('labels_batch_') and filename.endswith('.npy'):\n",
    "\n",
    "            #load labels\n",
    "            labels = np.load(os.path.join(encoded_dir, filename))\n",
    "            labels_list.append(labels)\n",
    "\n",
    "    #concat all batches into a single array\n",
    "    encoded_features = np.vstack(features_list)\n",
    "    encoded_labels = np.hstack(labels_list)\n",
    "\n",
    "    print(f\"LOG: Loaded {encoded_features.shape[0]} samples with {encoded_features.shape[1]} features each\")\n",
    "    print(f\"LOG: Labels shape: {encoded_labels.shape}\")\n",
    "\n",
    "    return encoded_features, encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:51.855190Z",
     "iopub.status.busy": "2025-05-08T18:41:51.853686Z",
     "iopub.status.idle": "2025-05-08T18:41:52.020093Z",
     "shell.execute_reply": "2025-05-08T18:41:52.020093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 140 samples with 64 features each\n",
      "LOG: Labels shape: (140,)\n",
      "\n",
      "Loading validation data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "\n",
      "Loading test data for LRM...\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 3038 samples with 64 features each\n",
      "LOG: Labels shape: (3038,)\n",
      "\n",
      "LOG: Training features shape: (140, 64), Training labels shape: (140,)\n",
      "LOG: Validation features shape: (70, 64), Validation labels shape: (70,)\n",
      "LOG: Test features shape: (3038, 64), Test labels shape: (3038,)\n",
      "\n",
      "LOG: Training Logistic Regression model...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 71.43%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       0.83      1.00      0.91         5\n",
      "           2       0.67      0.40      0.50         5\n",
      "           3       0.80      0.80      0.80         5\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.50      0.60      0.55         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.60      0.60      0.60         5\n",
      "           8       0.67      0.40      0.50         5\n",
      "           9       0.56      1.00      0.71         5\n",
      "          10       0.75      0.60      0.67         5\n",
      "          11       0.71      1.00      0.83         5\n",
      "          12       0.43      0.60      0.50         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.71        70\n",
      "   macro avg       0.68      0.71      0.68        70\n",
      "weighted avg       0.68      0.71      0.68        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 75.48%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       255\n",
      "           1       0.46      0.98      0.62        86\n",
      "           2       0.81      0.84      0.82       236\n",
      "           3       0.76      0.83      0.79       200\n",
      "           4       0.97      0.54      0.70       254\n",
      "           5       0.54      0.54      0.54       254\n",
      "           6       0.94      0.90      0.92       244\n",
      "           7       0.50      0.39      0.44       188\n",
      "           8       0.82      0.46      0.59       299\n",
      "           9       0.74      0.83      0.78       233\n",
      "          10       0.74      0.87      0.80       290\n",
      "          11       0.74      1.00      0.85       166\n",
      "          12       0.69      0.77      0.73       253\n",
      "          13       0.95      0.97      0.96        80\n",
      "\n",
      "    accuracy                           0.75      3038\n",
      "   macro avg       0.76      0.78      0.75      3038\n",
      "weighted avg       0.77      0.75      0.75      3038\n",
      "\n",
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vella\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vella\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vella\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "lrm_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "lrm_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "lrm_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "print(\"\\nLoading training data for LRM...\")\n",
    "lrm_train_features, lrm_train_labels = load_encoded_data(lrm_encoded_train_dir)\n",
    "\n",
    "print(\"\\nLoading validation data for LRM...\")\n",
    "lrm_val_features, lrm_val_labels = load_encoded_data(lrm_encoded_val_dir)\n",
    "\n",
    "print(\"\\nLoading test data for LRM...\")\n",
    "lrm_test_features, lrm_test_labels = load_encoded_data(lrm_encoded_test_dir)\n",
    "\n",
    "#verify shapes\n",
    "print(f\"\\nLOG: Training features shape: {lrm_train_features.shape}, Training labels shape: {lrm_train_labels.shape}\")\n",
    "print(f\"LOG: Validation features shape: {lrm_val_features.shape}, Validation labels shape: {lrm_val_labels.shape}\")\n",
    "print(f\"LOG: Test features shape: {lrm_test_features.shape}, Test labels shape: {lrm_test_labels.shape}\")\n",
    "\n",
    "print(\"\\nLOG: Training Logistic Regression model...\")\n",
    "logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight = 'balanced')\n",
    "logistic_clf.fit(lrm_train_features, lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "#eval on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "lrm_val_predictions = logistic_clf.predict(lrm_val_features)\n",
    "lrm_val_accuracy = accuracy_score(lrm_val_labels, lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(lrm_val_labels, lrm_val_predictions))\n",
    "\n",
    "#eval on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "lrm_test_predictions = logistic_clf.predict(lrm_test_features)\n",
    "lrm_test_accuracy = accuracy_score(lrm_test_labels, lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(lrm_test_labels, lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_predictions.npy'), lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'cae_lrm_true_labels.npy'), lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying CAE Embeddings with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:52.022097Z",
     "iopub.status.busy": "2025-05-08T18:41:52.022097Z",
     "iopub.status.idle": "2025-05-08T18:41:52.026606Z",
     "shell.execute_reply": "2025-05-08T18:41:52.026606Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:52.028653Z",
     "iopub.status.busy": "2025-05-08T18:41:52.028653Z",
     "iopub.status.idle": "2025-05-08T18:41:52.038164Z",
     "shell.execute_reply": "2025-05-08T18:41:52.038164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 140 samples with 64 features each\n",
      "LOG: Labels shape: (140,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 3038 samples with 64 features each\n",
      "LOG: Labels shape: (3038,)\n",
      "Train reps shape: (140, 64)\n",
      "Train labels shape: (140,)\n",
      "Val reps shape: (70, 64)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (3038, 64)\n",
      "Test labels shape: (3038,)\n"
     ]
    }
   ],
   "source": [
    "cae_mlp_train_dir = os.path.join(\"encoded_representations\", \"train\")\n",
    "cae_mlp_val_dir   = os.path.join(\"encoded_representations\", \"val\")\n",
    "cae_mlp_test_dir  = os.path.join(\"encoded_representations\", \"test\")\n",
    "\n",
    "cae_mlp_train_reps, cae_mlp_train_labels = load_encoded_data(cae_mlp_train_dir)\n",
    "cae_mlp_val_reps, cae_mlp_val_labels = load_encoded_data(cae_mlp_val_dir)\n",
    "cae_mlp_test_reps, cae_mlp_test_labels = load_encoded_data(cae_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",cae_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", cae_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", cae_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", cae_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", cae_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", cae_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:52.040244Z",
     "iopub.status.busy": "2025-05-08T18:41:52.040244Z",
     "iopub.status.idle": "2025-05-08T18:41:52.045268Z",
     "shell.execute_reply": "2025-05-08T18:41:52.045268Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "cae_mlp_train_embeddings_torch = torch.tensor(cae_mlp_train_reps, dtype=torch.float32)\n",
    "cae_mlp_train_labels_torch = torch.tensor(cae_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_val_embeddings_torch = torch.tensor(cae_mlp_val_reps, dtype=torch.float32)\n",
    "cae_mlp_val_labels_torch = torch.tensor(cae_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "cae_mlp_test_embeddings_torch = torch.tensor(cae_mlp_test_reps, dtype=torch.float32)\n",
    "cae_mlp_test_labels_torch = torch.tensor(cae_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "cae_mlp_train_dataset = TensorDataset(cae_mlp_train_embeddings_torch, cae_mlp_train_labels_torch)\n",
    "cae_mlp_val_dataset = TensorDataset(cae_mlp_val_embeddings_torch, cae_mlp_val_labels_torch)\n",
    "cae_mlp_test_dataset = TensorDataset(cae_mlp_test_embeddings_torch, cae_mlp_test_labels_torch)\n",
    "\n",
    "cae_mlp_batch_size = 64\n",
    "cae_mlp_train_loader = DataLoader(cae_mlp_train_dataset, batch_size=cae_mlp_batch_size, shuffle=True)\n",
    "cae_mlp_val_loader = DataLoader(cae_mlp_val_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n",
    "cae_mlp_test_loader = DataLoader(cae_mlp_test_dataset, batch_size=cae_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:52.048273Z",
     "iopub.status.busy": "2025-05-08T18:41:52.048273Z",
     "iopub.status.idle": "2025-05-08T18:41:59.350221Z",
     "shell.execute_reply": "2025-05-08T18:41:59.349575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.9315  |  Val Loss: 2.7504\n",
      "Validation loss improved from inf to 2.7504.\n",
      "[Epoch 2/1000] Train Loss: 2.7324  |  Val Loss: 2.6785\n",
      "Validation loss improved from 2.7504 to 2.6785.\n",
      "[Epoch 3/1000] Train Loss: 2.6665  |  Val Loss: 2.6440\n",
      "Validation loss improved from 2.6785 to 2.6440.\n",
      "[Epoch 4/1000] Train Loss: 2.6491  |  Val Loss: 2.6460\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 5/1000] Train Loss: 2.6466  |  Val Loss: 2.6402\n",
      "Validation loss improved from 2.6440 to 2.6402.\n",
      "[Epoch 6/1000] Train Loss: 2.6365  |  Val Loss: 2.6284\n",
      "Validation loss improved from 2.6402 to 2.6284.\n",
      "[Epoch 7/1000] Train Loss: 2.6301  |  Val Loss: 2.6217\n",
      "Validation loss improved from 2.6284 to 2.6217.\n",
      "[Epoch 8/1000] Train Loss: 2.6161  |  Val Loss: 2.6070\n",
      "Validation loss improved from 2.6217 to 2.6070.\n",
      "[Epoch 9/1000] Train Loss: 2.6000  |  Val Loss: 2.5975\n",
      "Validation loss improved from 2.6070 to 2.5975.\n",
      "[Epoch 10/1000] Train Loss: 2.5972  |  Val Loss: 2.6015\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 11/1000] Train Loss: 2.5957  |  Val Loss: 2.5999\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 12/1000] Train Loss: 2.5936  |  Val Loss: 2.5882\n",
      "Validation loss improved from 2.5975 to 2.5882.\n",
      "[Epoch 13/1000] Train Loss: 2.5799  |  Val Loss: 2.5759\n",
      "Validation loss improved from 2.5882 to 2.5759.\n",
      "[Epoch 14/1000] Train Loss: 2.5715  |  Val Loss: 2.5678\n",
      "Validation loss improved from 2.5759 to 2.5678.\n",
      "[Epoch 15/1000] Train Loss: 2.5616  |  Val Loss: 2.5620\n",
      "Validation loss improved from 2.5678 to 2.5620.\n",
      "[Epoch 16/1000] Train Loss: 2.5541  |  Val Loss: 2.5560\n",
      "Validation loss improved from 2.5620 to 2.5560.\n",
      "[Epoch 17/1000] Train Loss: 2.5468  |  Val Loss: 2.5457\n",
      "Validation loss improved from 2.5560 to 2.5457.\n",
      "[Epoch 18/1000] Train Loss: 2.5374  |  Val Loss: 2.5377\n",
      "Validation loss improved from 2.5457 to 2.5377.\n",
      "[Epoch 19/1000] Train Loss: 2.5287  |  Val Loss: 2.5342\n",
      "Validation loss improved from 2.5377 to 2.5342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/1000] Train Loss: 2.5322  |  Val Loss: 2.5357\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 21/1000] Train Loss: 2.5214  |  Val Loss: 2.5181\n",
      "Validation loss improved from 2.5342 to 2.5181.\n",
      "[Epoch 22/1000] Train Loss: 2.5098  |  Val Loss: 2.5057\n",
      "Validation loss improved from 2.5181 to 2.5057.\n",
      "[Epoch 23/1000] Train Loss: 2.4934  |  Val Loss: 2.4908\n",
      "Validation loss improved from 2.5057 to 2.4908.\n",
      "[Epoch 24/1000] Train Loss: 2.4786  |  Val Loss: 2.4750\n",
      "Validation loss improved from 2.4908 to 2.4750.\n",
      "[Epoch 25/1000] Train Loss: 2.4573  |  Val Loss: 2.4560\n",
      "Validation loss improved from 2.4750 to 2.4560.\n",
      "[Epoch 26/1000] Train Loss: 2.4446  |  Val Loss: 2.4564\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 27/1000] Train Loss: 2.4454  |  Val Loss: 2.4397\n",
      "Validation loss improved from 2.4560 to 2.4397.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/1000] Train Loss: 2.4213  |  Val Loss: 2.4138\n",
      "Validation loss improved from 2.4397 to 2.4138.\n",
      "[Epoch 29/1000] Train Loss: 2.4021  |  Val Loss: 2.4022\n",
      "Validation loss improved from 2.4138 to 2.4022.\n",
      "[Epoch 30/1000] Train Loss: 2.3863  |  Val Loss: 2.3840\n",
      "Validation loss improved from 2.4022 to 2.3840.\n",
      "[Epoch 31/1000] Train Loss: 2.3664  |  Val Loss: 2.3678\n",
      "Validation loss improved from 2.3840 to 2.3678.\n",
      "[Epoch 32/1000] Train Loss: 2.3494  |  Val Loss: 2.3559\n",
      "Validation loss improved from 2.3678 to 2.3559.\n",
      "[Epoch 33/1000] Train Loss: 2.3332  |  Val Loss: 2.3324\n",
      "Validation loss improved from 2.3559 to 2.3324.\n",
      "[Epoch 34/1000] Train Loss: 2.3138  |  Val Loss: 2.3300\n",
      "Validation loss improved from 2.3324 to 2.3300.\n",
      "[Epoch 35/1000] Train Loss: 2.3051  |  Val Loss: 2.3070\n",
      "Validation loss improved from 2.3300 to 2.3070.\n",
      "[Epoch 36/1000] Train Loss: 2.2816  |  Val Loss: 2.2728\n",
      "Validation loss improved from 2.3070 to 2.2728.\n",
      "[Epoch 37/1000] Train Loss: 2.2566  |  Val Loss: 2.2700\n",
      "Validation loss improved from 2.2728 to 2.2700.\n",
      "[Epoch 38/1000] Train Loss: 2.2463  |  Val Loss: 2.2510\n",
      "Validation loss improved from 2.2700 to 2.2510.\n",
      "[Epoch 39/1000] Train Loss: 2.2216  |  Val Loss: 2.2202\n",
      "Validation loss improved from 2.2510 to 2.2202.\n",
      "[Epoch 40/1000] Train Loss: 2.1931  |  Val Loss: 2.2057\n",
      "Validation loss improved from 2.2202 to 2.2057.\n",
      "[Epoch 41/1000] Train Loss: 2.1774  |  Val Loss: 2.1889\n",
      "Validation loss improved from 2.2057 to 2.1889.\n",
      "[Epoch 42/1000] Train Loss: 2.1610  |  Val Loss: 2.1586\n",
      "Validation loss improved from 2.1889 to 2.1586.\n",
      "[Epoch 43/1000] Train Loss: 2.1302  |  Val Loss: 2.1345\n",
      "Validation loss improved from 2.1586 to 2.1345.\n",
      "[Epoch 44/1000] Train Loss: 2.1094  |  Val Loss: 2.1253\n",
      "Validation loss improved from 2.1345 to 2.1253.\n",
      "[Epoch 45/1000] Train Loss: 2.0976  |  Val Loss: 2.1024\n",
      "Validation loss improved from 2.1253 to 2.1024.\n",
      "[Epoch 46/1000] Train Loss: 2.0864  |  Val Loss: 2.0731\n",
      "Validation loss improved from 2.1024 to 2.0731.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 47/1000] Train Loss: 2.0507  |  Val Loss: 2.0878\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 48/1000] Train Loss: 2.0407  |  Val Loss: 2.0401\n",
      "Validation loss improved from 2.0731 to 2.0401.\n",
      "[Epoch 49/1000] Train Loss: 2.0260  |  Val Loss: 2.0154\n",
      "Validation loss improved from 2.0401 to 2.0154.\n",
      "[Epoch 50/1000] Train Loss: 1.9861  |  Val Loss: 2.0158\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 51/1000] Train Loss: 1.9804  |  Val Loss: 1.9850\n",
      "Validation loss improved from 2.0154 to 1.9850.\n",
      "[Epoch 52/1000] Train Loss: 1.9567  |  Val Loss: 1.9586\n",
      "Validation loss improved from 1.9850 to 1.9586.\n",
      "[Epoch 53/1000] Train Loss: 1.9477  |  Val Loss: 1.9688\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 54/1000] Train Loss: 1.9226  |  Val Loss: 1.9305\n",
      "Validation loss improved from 1.9586 to 1.9305.\n",
      "[Epoch 55/1000] Train Loss: 1.9071  |  Val Loss: 1.9134\n",
      "Validation loss improved from 1.9305 to 1.9134.\n",
      "[Epoch 56/1000] Train Loss: 1.8779  |  Val Loss: 1.8949\n",
      "Validation loss improved from 1.9134 to 1.8949.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 57/1000] Train Loss: 1.8541  |  Val Loss: 1.8638\n",
      "Validation loss improved from 1.8949 to 1.8638.\n",
      "[Epoch 58/1000] Train Loss: 1.8456  |  Val Loss: 1.8737\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 59/1000] Train Loss: 1.8425  |  Val Loss: 1.8592\n",
      "Validation loss improved from 1.8638 to 1.8592.\n",
      "[Epoch 60/1000] Train Loss: 1.8197  |  Val Loss: 1.8312\n",
      "Validation loss improved from 1.8592 to 1.8312.\n",
      "[Epoch 61/1000] Train Loss: 1.8013  |  Val Loss: 1.8319\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 62/1000] Train Loss: 1.7927  |  Val Loss: 1.8072\n",
      "Validation loss improved from 1.8312 to 1.8072.\n",
      "[Epoch 63/1000] Train Loss: 1.7660  |  Val Loss: 1.8342\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 64/1000] Train Loss: 1.7739  |  Val Loss: 1.8064\n",
      "Validation loss improved from 1.8072 to 1.8064.\n",
      "[Epoch 65/1000] Train Loss: 1.7843  |  Val Loss: 1.7884\n",
      "Validation loss improved from 1.8064 to 1.7884.\n",
      "[Epoch 66/1000] Train Loss: 1.7519  |  Val Loss: 1.7453\n",
      "Validation loss improved from 1.7884 to 1.7453.\n",
      "[Epoch 67/1000] Train Loss: 1.7140  |  Val Loss: 1.7512\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 68/1000] Train Loss: 1.7208  |  Val Loss: 1.7506\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 69/1000] Train Loss: 1.7082  |  Val Loss: 1.7254\n",
      "Validation loss improved from 1.7453 to 1.7254.\n",
      "[Epoch 70/1000] Train Loss: 1.6845  |  Val Loss: 1.6964\n",
      "Validation loss improved from 1.7254 to 1.6964.\n",
      "[Epoch 71/1000] Train Loss: 1.6625  |  Val Loss: 1.6691\n",
      "Validation loss improved from 1.6964 to 1.6691.\n",
      "[Epoch 72/1000] Train Loss: 1.6366  |  Val Loss: 1.6568\n",
      "Validation loss improved from 1.6691 to 1.6568.\n",
      "[Epoch 73/1000] Train Loss: 1.6268  |  Val Loss: 1.6512\n",
      "Validation loss improved from 1.6568 to 1.6512.\n",
      "[Epoch 74/1000] Train Loss: 1.6357  |  Val Loss: 1.6367\n",
      "Validation loss improved from 1.6512 to 1.6367.\n",
      "[Epoch 75/1000] Train Loss: 1.6108  |  Val Loss: 1.6641\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 76/1000] Train Loss: 1.6177  |  Val Loss: 1.6505\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 77/1000] Train Loss: 1.6447  |  Val Loss: 1.6501\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 78/1000] Train Loss: 1.6120  |  Val Loss: 1.6243\n",
      "Validation loss improved from 1.6367 to 1.6243.\n",
      "[Epoch 79/1000] Train Loss: 1.5843  |  Val Loss: 1.6161\n",
      "Validation loss improved from 1.6243 to 1.6161.\n",
      "[Epoch 80/1000] Train Loss: 1.5929  |  Val Loss: 1.5993\n",
      "Validation loss improved from 1.6161 to 1.5993.\n",
      "[Epoch 81/1000] Train Loss: 1.5746  |  Val Loss: 1.6071\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 82/1000] Train Loss: 1.5647  |  Val Loss: 1.5863\n",
      "Validation loss improved from 1.5993 to 1.5863.\n",
      "[Epoch 83/1000] Train Loss: 1.5625  |  Val Loss: 1.6010\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 84/1000] Train Loss: 1.5479  |  Val Loss: 1.5836\n",
      "Validation loss improved from 1.5863 to 1.5836.\n",
      "[Epoch 85/1000] Train Loss: 1.5383  |  Val Loss: 1.5585\n",
      "Validation loss improved from 1.5836 to 1.5585.\n",
      "[Epoch 86/1000] Train Loss: 1.5341  |  Val Loss: 1.5701\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 87/1000] Train Loss: 1.5181  |  Val Loss: 1.6077\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 88/1000] Train Loss: 1.5322  |  Val Loss: 1.5445\n",
      "Validation loss improved from 1.5585 to 1.5445.\n",
      "[Epoch 89/1000] Train Loss: 1.5257  |  Val Loss: 1.5332\n",
      "Validation loss improved from 1.5445 to 1.5332.\n",
      "[Epoch 90/1000] Train Loss: 1.5129  |  Val Loss: 1.5214\n",
      "Validation loss improved from 1.5332 to 1.5214.\n",
      "[Epoch 91/1000] Train Loss: 1.4964  |  Val Loss: 1.5456\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 92/1000] Train Loss: 1.4936  |  Val Loss: 1.5074\n",
      "Validation loss improved from 1.5214 to 1.5074.\n",
      "[Epoch 93/1000] Train Loss: 1.4795  |  Val Loss: 1.5321\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 94/1000] Train Loss: 1.4733  |  Val Loss: 1.5608\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 95/1000] Train Loss: 1.5018  |  Val Loss: 1.5339\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 96/1000] Train Loss: 1.4708  |  Val Loss: 1.4810\n",
      "Validation loss improved from 1.5074 to 1.4810.\n",
      "[Epoch 97/1000] Train Loss: 1.4469  |  Val Loss: 1.4926\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 98/1000] Train Loss: 1.4632  |  Val Loss: 1.5465\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 99/1000] Train Loss: 1.4780  |  Val Loss: 1.4772\n",
      "Validation loss improved from 1.4810 to 1.4772.\n",
      "[Epoch 100/1000] Train Loss: 1.4533  |  Val Loss: 1.4992\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 101/1000] Train Loss: 1.4515  |  Val Loss: 1.5083\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 102/1000] Train Loss: 1.4422  |  Val Loss: 1.4594\n",
      "Validation loss improved from 1.4772 to 1.4594.\n",
      "[Epoch 103/1000] Train Loss: 1.4359  |  Val Loss: 1.4584\n",
      "Validation loss improved from 1.4594 to 1.4584.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 104/1000] Train Loss: 1.4273  |  Val Loss: 1.4580\n",
      "Validation loss improved from 1.4584 to 1.4580.\n",
      "[Epoch 105/1000] Train Loss: 1.4325  |  Val Loss: 1.5172\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 106/1000] Train Loss: 1.4575  |  Val Loss: 1.4567\n",
      "Validation loss improved from 1.4580 to 1.4567.\n",
      "[Epoch 107/1000] Train Loss: 1.4712  |  Val Loss: 1.4197\n",
      "Validation loss improved from 1.4567 to 1.4197.\n",
      "[Epoch 108/1000] Train Loss: 1.4066  |  Val Loss: 1.4471\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 109/1000] Train Loss: 1.3990  |  Val Loss: 1.4390\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 110/1000] Train Loss: 1.4367  |  Val Loss: 1.4705\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 111/1000] Train Loss: 1.4059  |  Val Loss: 1.4467\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 112/1000] Train Loss: 1.3872  |  Val Loss: 1.4524\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 113/1000] Train Loss: 1.4126  |  Val Loss: 1.4280\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 114/1000] Train Loss: 1.4053  |  Val Loss: 1.4158\n",
      "Validation loss improved from 1.4197 to 1.4158.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 115/1000] Train Loss: 1.3965  |  Val Loss: 1.4692\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 116/1000] Train Loss: 1.3923  |  Val Loss: 1.4168\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 117/1000] Train Loss: 1.4105  |  Val Loss: 1.4427\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 118/1000] Train Loss: 1.3864  |  Val Loss: 1.4184\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 119/1000] Train Loss: 1.3726  |  Val Loss: 1.4246\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 120/1000] Train Loss: 1.3641  |  Val Loss: 1.4336\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 121/1000] Train Loss: 1.3956  |  Val Loss: 1.4449\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 122/1000] Train Loss: 1.4453  |  Val Loss: 1.4513\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 123/1000] Train Loss: 1.4000  |  Val Loss: 1.4607\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 124/1000] Train Loss: 1.3850  |  Val Loss: 1.3993\n",
      "Validation loss improved from 1.4158 to 1.3993.\n",
      "[Epoch 125/1000] Train Loss: 1.3756  |  Val Loss: 1.4267\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 126/1000] Train Loss: 1.3476  |  Val Loss: 1.3947\n",
      "Validation loss improved from 1.3993 to 1.3947.\n",
      "[Epoch 127/1000] Train Loss: 1.3874  |  Val Loss: 1.4749\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 128/1000] Train Loss: 1.4181  |  Val Loss: 1.4154\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 129/1000] Train Loss: 1.3406  |  Val Loss: 1.3572\n",
      "Validation loss improved from 1.3947 to 1.3572.\n",
      "[Epoch 130/1000] Train Loss: 1.3384  |  Val Loss: 1.4572\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 131/1000] Train Loss: 1.3692  |  Val Loss: 1.3754\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 132/1000] Train Loss: 1.3502  |  Val Loss: 1.4248\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 133/1000] Train Loss: 1.3813  |  Val Loss: 1.3537\n",
      "Validation loss improved from 1.3572 to 1.3537.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 134/1000] Train Loss: 1.3546  |  Val Loss: 1.3333\n",
      "Validation loss improved from 1.3537 to 1.3333.\n",
      "[Epoch 135/1000] Train Loss: 1.3421  |  Val Loss: 1.4788\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 136/1000] Train Loss: 1.3559  |  Val Loss: 1.3442\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 137/1000] Train Loss: 1.3470  |  Val Loss: 1.3887\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 138/1000] Train Loss: 1.3468  |  Val Loss: 1.4044\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 139/1000] Train Loss: 1.3401  |  Val Loss: 1.4074\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 140/1000] Train Loss: 1.3456  |  Val Loss: 1.4815\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 141/1000] Train Loss: 1.3389  |  Val Loss: 1.3794\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 142/1000] Train Loss: 1.3524  |  Val Loss: 1.4352\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 143/1000] Train Loss: 1.3609  |  Val Loss: 1.4155\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 144/1000] Train Loss: 1.3409  |  Val Loss: 1.3722\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 145/1000] Train Loss: 1.3813  |  Val Loss: 1.4601\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 146/1000] Train Loss: 1.3987  |  Val Loss: 1.3743\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 147/1000] Train Loss: 1.3499  |  Val Loss: 1.3442\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 148/1000] Train Loss: 1.3270  |  Val Loss: 1.5022\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 149/1000] Train Loss: 1.3480  |  Val Loss: 1.3591\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 150/1000] Train Loss: 1.3514  |  Val Loss: 1.3559\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 151/1000] Train Loss: 1.3102  |  Val Loss: 1.4165\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 152/1000] Train Loss: 1.3092  |  Val Loss: 1.3386\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 153/1000] Train Loss: 1.3355  |  Val Loss: 1.3821\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 154/1000] Train Loss: 1.3213  |  Val Loss: 1.3465\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 155/1000] Train Loss: 1.2925  |  Val Loss: 1.3149\n",
      "Validation loss improved from 1.3333 to 1.3149.\n",
      "[Epoch 156/1000] Train Loss: 1.3094  |  Val Loss: 1.3920\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 157/1000] Train Loss: 1.3065  |  Val Loss: 1.2982\n",
      "Validation loss improved from 1.3149 to 1.2982.\n",
      "[Epoch 158/1000] Train Loss: 1.2997  |  Val Loss: 1.3187\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 159/1000] Train Loss: 1.3028  |  Val Loss: 1.3863\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 160/1000] Train Loss: 1.3129  |  Val Loss: 1.3443\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 161/1000] Train Loss: 1.3192  |  Val Loss: 1.3847\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 162/1000] Train Loss: 1.2964  |  Val Loss: 1.3638\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 163/1000] Train Loss: 1.2844  |  Val Loss: 1.3425\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 164/1000] Train Loss: 1.2975  |  Val Loss: 1.3404\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 165/1000] Train Loss: 1.2850  |  Val Loss: 1.3130\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 166/1000] Train Loss: 1.2722  |  Val Loss: 1.3209\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 167/1000] Train Loss: 1.2816  |  Val Loss: 1.3036\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 168/1000] Train Loss: 1.2729  |  Val Loss: 1.2836\n",
      "Validation loss improved from 1.2982 to 1.2836.\n",
      "[Epoch 169/1000] Train Loss: 1.2684  |  Val Loss: 1.3202\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 170/1000] Train Loss: 1.2790  |  Val Loss: 1.3057\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 171/1000] Train Loss: 1.2887  |  Val Loss: 1.3282\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 172/1000] Train Loss: 1.2761  |  Val Loss: 1.3494\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 173/1000] Train Loss: 1.2718  |  Val Loss: 1.2998\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 174/1000] Train Loss: 1.2546  |  Val Loss: 1.3337\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 175/1000] Train Loss: 1.2585  |  Val Loss: 1.2982\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 176/1000] Train Loss: 1.2560  |  Val Loss: 1.3207\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 177/1000] Train Loss: 1.2682  |  Val Loss: 1.3049\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 178/1000] Train Loss: 1.2632  |  Val Loss: 1.2874\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 179/1000] Train Loss: 1.2591  |  Val Loss: 1.4159\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 180/1000] Train Loss: 1.2869  |  Val Loss: 1.3025\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 181/1000] Train Loss: 1.2597  |  Val Loss: 1.3056\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 182/1000] Train Loss: 1.2895  |  Val Loss: 1.4257\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 183/1000] Train Loss: 1.3067  |  Val Loss: 1.2888\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 184/1000] Train Loss: 1.2498  |  Val Loss: 1.2757\n",
      "Validation loss improved from 1.2836 to 1.2757.\n",
      "[Epoch 185/1000] Train Loss: 1.2483  |  Val Loss: 1.3479\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 186/1000] Train Loss: 1.2694  |  Val Loss: 1.3172\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 187/1000] Train Loss: 1.2695  |  Val Loss: 1.3208\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 188/1000] Train Loss: 1.2501  |  Val Loss: 1.2968\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 189/1000] Train Loss: 1.2586  |  Val Loss: 1.3148\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 190/1000] Train Loss: 1.2650  |  Val Loss: 1.2911\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 191/1000] Train Loss: 1.2554  |  Val Loss: 1.3189\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 192/1000] Train Loss: 1.2602  |  Val Loss: 1.3246\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 193/1000] Train Loss: 1.2560  |  Val Loss: 1.2739\n",
      "Validation loss improved from 1.2757 to 1.2739.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 194/1000] Train Loss: 1.2739  |  Val Loss: 1.3025\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 195/1000] Train Loss: 1.2774  |  Val Loss: 1.5240\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 196/1000] Train Loss: 1.3335  |  Val Loss: 1.2921\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 197/1000] Train Loss: 1.2537  |  Val Loss: 1.3452\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 198/1000] Train Loss: 1.2567  |  Val Loss: 1.2532\n",
      "Validation loss improved from 1.2739 to 1.2532.\n",
      "[Epoch 199/1000] Train Loss: 1.2671  |  Val Loss: 1.2669\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 200/1000] Train Loss: 1.2603  |  Val Loss: 1.2966\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 201/1000] Train Loss: 1.2228  |  Val Loss: 1.2754\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 202/1000] Train Loss: 1.3011  |  Val Loss: 1.3900\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 203/1000] Train Loss: 1.2867  |  Val Loss: 1.2746\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 204/1000] Train Loss: 1.2521  |  Val Loss: 1.2639\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 205/1000] Train Loss: 1.2692  |  Val Loss: 1.4063\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 206/1000] Train Loss: 1.2470  |  Val Loss: 1.2771\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 207/1000] Train Loss: 1.3041  |  Val Loss: 1.2893\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 208/1000] Train Loss: 1.2565  |  Val Loss: 1.2969\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 209/1000] Train Loss: 1.2333  |  Val Loss: 1.2434\n",
      "Validation loss improved from 1.2532 to 1.2434.\n",
      "[Epoch 210/1000] Train Loss: 1.2372  |  Val Loss: 1.4123\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 211/1000] Train Loss: 1.2904  |  Val Loss: 1.2562\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 212/1000] Train Loss: 1.2731  |  Val Loss: 1.2590\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 213/1000] Train Loss: 1.2510  |  Val Loss: 1.3807\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 214/1000] Train Loss: 1.2459  |  Val Loss: 1.2558\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 215/1000] Train Loss: 1.2300  |  Val Loss: 1.3213\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 216/1000] Train Loss: 1.2534  |  Val Loss: 1.2772\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 217/1000] Train Loss: 1.2457  |  Val Loss: 1.2543\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 218/1000] Train Loss: 1.2253  |  Val Loss: 1.3935\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 219/1000] Train Loss: 1.2523  |  Val Loss: 1.2454\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 220/1000] Train Loss: 1.2618  |  Val Loss: 1.2557\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 221/1000] Train Loss: 1.2300  |  Val Loss: 1.3154\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 222/1000] Train Loss: 1.2245  |  Val Loss: 1.2374\n",
      "Validation loss improved from 1.2434 to 1.2374.\n",
      "[Epoch 223/1000] Train Loss: 1.2159  |  Val Loss: 1.3114\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 224/1000] Train Loss: 1.2330  |  Val Loss: 1.3247\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 225/1000] Train Loss: 1.2405  |  Val Loss: 1.2899\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 226/1000] Train Loss: 1.2194  |  Val Loss: 1.2375\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 227/1000] Train Loss: 1.2284  |  Val Loss: 1.2804\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 228/1000] Train Loss: 1.2412  |  Val Loss: 1.3064\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 229/1000] Train Loss: 1.2208  |  Val Loss: 1.2489\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 230/1000] Train Loss: 1.2216  |  Val Loss: 1.4797\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 231/1000] Train Loss: 1.3124  |  Val Loss: 1.2493\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 232/1000] Train Loss: 1.2787  |  Val Loss: 1.2486\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 233/1000] Train Loss: 1.2172  |  Val Loss: 1.4613\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 234/1000] Train Loss: 1.2660  |  Val Loss: 1.2451\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 235/1000] Train Loss: 1.2964  |  Val Loss: 1.2470\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 236/1000] Train Loss: 1.2376  |  Val Loss: 1.3876\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 237/1000] Train Loss: 1.2331  |  Val Loss: 1.2686\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 238/1000] Train Loss: 1.2488  |  Val Loss: 1.2722\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 239/1000] Train Loss: 1.2318  |  Val Loss: 1.2513\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 240/1000] Train Loss: 1.2185  |  Val Loss: 1.2351\n",
      "Validation loss improved from 1.2374 to 1.2351.\n",
      "[Epoch 241/1000] Train Loss: 1.2196  |  Val Loss: 1.2525\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 242/1000] Train Loss: 1.2038  |  Val Loss: 1.2963\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 243/1000] Train Loss: 1.2039  |  Val Loss: 1.2278\n",
      "Validation loss improved from 1.2351 to 1.2278.\n",
      "[Epoch 244/1000] Train Loss: 1.2192  |  Val Loss: 1.2345\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 245/1000] Train Loss: 1.2127  |  Val Loss: 1.2781\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 246/1000] Train Loss: 1.2212  |  Val Loss: 1.2485\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 247/1000] Train Loss: 1.1940  |  Val Loss: 1.2221\n",
      "Validation loss improved from 1.2278 to 1.2221.\n",
      "[Epoch 248/1000] Train Loss: 1.2137  |  Val Loss: 1.3170\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 249/1000] Train Loss: 1.2279  |  Val Loss: 1.2350\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 250/1000] Train Loss: 1.2045  |  Val Loss: 1.2228\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 251/1000] Train Loss: 1.2185  |  Val Loss: 1.2750\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 252/1000] Train Loss: 1.2017  |  Val Loss: 1.2555\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 253/1000] Train Loss: 1.1879  |  Val Loss: 1.2481\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 254/1000] Train Loss: 1.1975  |  Val Loss: 1.3382\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 255/1000] Train Loss: 1.2461  |  Val Loss: 1.2610\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 256/1000] Train Loss: 1.2476  |  Val Loss: 1.2251\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 257/1000] Train Loss: 1.2014  |  Val Loss: 1.3949\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 258/1000] Train Loss: 1.2228  |  Val Loss: 1.2006\n",
      "Validation loss improved from 1.2221 to 1.2006.\n",
      "[Epoch 259/1000] Train Loss: 1.2339  |  Val Loss: 1.2552\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 260/1000] Train Loss: 1.2207  |  Val Loss: 1.3651\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 261/1000] Train Loss: 1.1982  |  Val Loss: 1.2473\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 262/1000] Train Loss: 1.3318  |  Val Loss: 1.2715\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 263/1000] Train Loss: 1.2440  |  Val Loss: 1.4758\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 264/1000] Train Loss: 1.2340  |  Val Loss: 1.2595\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 265/1000] Train Loss: 1.2873  |  Val Loss: 1.3133\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 266/1000] Train Loss: 1.2131  |  Val Loss: 1.4008\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 267/1000] Train Loss: 1.2160  |  Val Loss: 1.2105\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 268/1000] Train Loss: 1.1971  |  Val Loss: 1.2744\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 269/1000] Train Loss: 1.1950  |  Val Loss: 1.2545\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 270/1000] Train Loss: 1.2050  |  Val Loss: 1.2252\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 271/1000] Train Loss: 1.1982  |  Val Loss: 1.3894\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 272/1000] Train Loss: 1.2276  |  Val Loss: 1.2589\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 273/1000] Train Loss: 1.1847  |  Val Loss: 1.2425\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 274/1000] Train Loss: 1.2015  |  Val Loss: 1.2825\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 275/1000] Train Loss: 1.1864  |  Val Loss: 1.3063\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 276/1000] Train Loss: 1.1826  |  Val Loss: 1.2391\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 277/1000] Train Loss: 1.1813  |  Val Loss: 1.2224\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 278/1000] Train Loss: 1.1920  |  Val Loss: 1.2887\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 279/1000] Train Loss: 1.2067  |  Val Loss: 1.2941\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 280/1000] Train Loss: 1.1874  |  Val Loss: 1.2110\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 281/1000] Train Loss: 1.2253  |  Val Loss: 1.2597\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 282/1000] Train Loss: 1.2120  |  Val Loss: 1.3436\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 283/1000] Train Loss: 1.2052  |  Val Loss: 1.2097\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 284/1000] Train Loss: 1.2043  |  Val Loss: 1.2504\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 285/1000] Train Loss: 1.1831  |  Val Loss: 1.2360\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 286/1000] Train Loss: 1.1858  |  Val Loss: 1.2121\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 287/1000] Train Loss: 1.1788  |  Val Loss: 1.3515\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 288/1000] Train Loss: 1.2218  |  Val Loss: 1.2715\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 289/1000] Train Loss: 1.1621  |  Val Loss: 1.1994\n",
      "Validation loss improved from 1.2006 to 1.1994.\n",
      "[Epoch 290/1000] Train Loss: 1.2333  |  Val Loss: 1.2509\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 291/1000] Train Loss: 1.2086  |  Val Loss: 1.4123\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 292/1000] Train Loss: 1.2070  |  Val Loss: 1.2084\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 293/1000] Train Loss: 1.2458  |  Val Loss: 1.2109\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 294/1000] Train Loss: 1.1631  |  Val Loss: 1.2659\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 295/1000] Train Loss: 1.1698  |  Val Loss: 1.2106\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 296/1000] Train Loss: 1.1961  |  Val Loss: 1.3062\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 297/1000] Train Loss: 1.2084  |  Val Loss: 1.2929\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 298/1000] Train Loss: 1.1694  |  Val Loss: 1.1958\n",
      "Validation loss improved from 1.1994 to 1.1958.\n",
      "[Epoch 299/1000] Train Loss: 1.2002  |  Val Loss: 1.2978\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 300/1000] Train Loss: 1.2194  |  Val Loss: 1.3355\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 301/1000] Train Loss: 1.1942  |  Val Loss: 1.2044\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 302/1000] Train Loss: 1.1965  |  Val Loss: 1.3126\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 303/1000] Train Loss: 1.1963  |  Val Loss: 1.1824\n",
      "Validation loss improved from 1.1958 to 1.1824.\n",
      "[Epoch 304/1000] Train Loss: 1.1895  |  Val Loss: 1.2934\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 305/1000] Train Loss: 1.2098  |  Val Loss: 1.2888\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 306/1000] Train Loss: 1.1728  |  Val Loss: 1.1780\n",
      "Validation loss improved from 1.1824 to 1.1780.\n",
      "[Epoch 307/1000] Train Loss: 1.1640  |  Val Loss: 1.2558\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 308/1000] Train Loss: 1.1731  |  Val Loss: 1.2943\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 309/1000] Train Loss: 1.1840  |  Val Loss: 1.2088\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 310/1000] Train Loss: 1.1729  |  Val Loss: 1.2127\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 311/1000] Train Loss: 1.1758  |  Val Loss: 1.2933\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 312/1000] Train Loss: 1.1925  |  Val Loss: 1.3317\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 313/1000] Train Loss: 1.1680  |  Val Loss: 1.1917\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 314/1000] Train Loss: 1.1909  |  Val Loss: 1.2225\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 315/1000] Train Loss: 1.1607  |  Val Loss: 1.2340\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 316/1000] Train Loss: 1.1566  |  Val Loss: 1.2294\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 317/1000] Train Loss: 1.1594  |  Val Loss: 1.3174\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 318/1000] Train Loss: 1.1682  |  Val Loss: 1.1704\n",
      "Validation loss improved from 1.1780 to 1.1704.\n",
      "[Epoch 319/1000] Train Loss: 1.1934  |  Val Loss: 1.1878\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 320/1000] Train Loss: 1.1623  |  Val Loss: 1.3002\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 321/1000] Train Loss: 1.1750  |  Val Loss: 1.1767\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 322/1000] Train Loss: 1.1652  |  Val Loss: 1.2169\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 323/1000] Train Loss: 1.1583  |  Val Loss: 1.2740\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 324/1000] Train Loss: 1.1643  |  Val Loss: 1.2666\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 325/1000] Train Loss: 1.1708  |  Val Loss: 1.3039\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 326/1000] Train Loss: 1.1566  |  Val Loss: 1.1971\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 327/1000] Train Loss: 1.1390  |  Val Loss: 1.2194\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 328/1000] Train Loss: 1.1581  |  Val Loss: 1.2619\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 329/1000] Train Loss: 1.1707  |  Val Loss: 1.2411\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 330/1000] Train Loss: 1.1849  |  Val Loss: 1.2895\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 331/1000] Train Loss: 1.1670  |  Val Loss: 1.2236\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 332/1000] Train Loss: 1.1475  |  Val Loss: 1.2228\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 333/1000] Train Loss: 1.1726  |  Val Loss: 1.2255\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 334/1000] Train Loss: 1.1369  |  Val Loss: 1.1930\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 335/1000] Train Loss: 1.1508  |  Val Loss: 1.2237\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 336/1000] Train Loss: 1.1907  |  Val Loss: 1.2258\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 337/1000] Train Loss: 1.1521  |  Val Loss: 1.1954\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 338/1000] Train Loss: 1.2089  |  Val Loss: 1.2744\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 339/1000] Train Loss: 1.1828  |  Val Loss: 1.3459\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 340/1000] Train Loss: 1.1696  |  Val Loss: 1.2197\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 341/1000] Train Loss: 1.1820  |  Val Loss: 1.3836\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 342/1000] Train Loss: 1.2053  |  Val Loss: 1.1774\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 343/1000] Train Loss: 1.2393  |  Val Loss: 1.2310\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 344/1000] Train Loss: 1.1982  |  Val Loss: 1.5408\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 345/1000] Train Loss: 1.2763  |  Val Loss: 1.1792\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 346/1000] Train Loss: 1.2302  |  Val Loss: 1.1643\n",
      "Validation loss improved from 1.1704 to 1.1643.\n",
      "[Epoch 347/1000] Train Loss: 1.1556  |  Val Loss: 1.4875\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 348/1000] Train Loss: 1.2300  |  Val Loss: 1.2143\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 349/1000] Train Loss: 1.1728  |  Val Loss: 1.2012\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 350/1000] Train Loss: 1.1695  |  Val Loss: 1.3082\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 351/1000] Train Loss: 1.1492  |  Val Loss: 1.2523\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 352/1000] Train Loss: 1.1403  |  Val Loss: 1.2053\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 353/1000] Train Loss: 1.1561  |  Val Loss: 1.2780\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 354/1000] Train Loss: 1.1527  |  Val Loss: 1.3419\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 355/1000] Train Loss: 1.1328  |  Val Loss: 1.1892\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 356/1000] Train Loss: 1.2116  |  Val Loss: 1.2072\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 357/1000] Train Loss: 1.1729  |  Val Loss: 1.4257\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 358/1000] Train Loss: 1.1931  |  Val Loss: 1.1683\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 359/1000] Train Loss: 1.1861  |  Val Loss: 1.1860\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 360/1000] Train Loss: 1.1944  |  Val Loss: 1.3746\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 361/1000] Train Loss: 1.1744  |  Val Loss: 1.2155\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 362/1000] Train Loss: 1.2171  |  Val Loss: 1.2310\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 363/1000] Train Loss: 1.1840  |  Val Loss: 1.3259\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 364/1000] Train Loss: 1.1609  |  Val Loss: 1.2037\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 365/1000] Train Loss: 1.1570  |  Val Loss: 1.1943\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 366/1000] Train Loss: 1.1670  |  Val Loss: 1.2602\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 367/1000] Train Loss: 1.1391  |  Val Loss: 1.2635\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 368/1000] Train Loss: 1.1431  |  Val Loss: 1.2217\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 369/1000] Train Loss: 1.1350  |  Val Loss: 1.2102\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 370/1000] Train Loss: 1.1374  |  Val Loss: 1.2491\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 371/1000] Train Loss: 1.1455  |  Val Loss: 1.2588\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 372/1000] Train Loss: 1.1253  |  Val Loss: 1.1774\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 373/1000] Train Loss: 1.1578  |  Val Loss: 1.2532\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 374/1000] Train Loss: 1.1713  |  Val Loss: 1.3361\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 375/1000] Train Loss: 1.1488  |  Val Loss: 1.1893\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 376/1000] Train Loss: 1.1587  |  Val Loss: 1.2001\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 377/1000] Train Loss: 1.1191  |  Val Loss: 1.2824\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 378/1000] Train Loss: 1.1305  |  Val Loss: 1.2112\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 379/1000] Train Loss: 1.1476  |  Val Loss: 1.2012\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 380/1000] Train Loss: 1.1311  |  Val Loss: 1.2341\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 381/1000] Train Loss: 1.1282  |  Val Loss: 1.1662\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 382/1000] Train Loss: 1.1659  |  Val Loss: 1.1706\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 383/1000] Train Loss: 1.1176  |  Val Loss: 1.1836\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 384/1000] Train Loss: 1.1301  |  Val Loss: 1.1936\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 385/1000] Train Loss: 1.1527  |  Val Loss: 1.2314\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 386/1000] Train Loss: 1.1261  |  Val Loss: 1.2572\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 387/1000] Train Loss: 1.1238  |  Val Loss: 1.1691\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 388/1000] Train Loss: 1.1235  |  Val Loss: 1.1484\n",
      "Validation loss improved from 1.1643 to 1.1484.\n",
      "[Epoch 389/1000] Train Loss: 1.1083  |  Val Loss: 1.1625\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 390/1000] Train Loss: 1.1123  |  Val Loss: 1.2044\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 391/1000] Train Loss: 1.1222  |  Val Loss: 1.2414\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 392/1000] Train Loss: 1.1255  |  Val Loss: 1.1530\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 393/1000] Train Loss: 1.1164  |  Val Loss: 1.1639\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 394/1000] Train Loss: 1.1122  |  Val Loss: 1.2114\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 395/1000] Train Loss: 1.1345  |  Val Loss: 1.2095\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 396/1000] Train Loss: 1.1243  |  Val Loss: 1.1890\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 397/1000] Train Loss: 1.0895  |  Val Loss: 1.1701\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 398/1000] Train Loss: 1.1701  |  Val Loss: 1.1937\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 399/1000] Train Loss: 1.1323  |  Val Loss: 1.2040\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 400/1000] Train Loss: 1.0987  |  Val Loss: 1.1976\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 401/1000] Train Loss: 1.1261  |  Val Loss: 1.2219\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 402/1000] Train Loss: 1.1103  |  Val Loss: 1.2019\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 403/1000] Train Loss: 1.0941  |  Val Loss: 1.1921\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 404/1000] Train Loss: 1.1236  |  Val Loss: 1.2404\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 405/1000] Train Loss: 1.1143  |  Val Loss: 1.2079\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 406/1000] Train Loss: 1.1023  |  Val Loss: 1.1808\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 407/1000] Train Loss: 1.1169  |  Val Loss: 1.2006\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 408/1000] Train Loss: 1.1099  |  Val Loss: 1.1864\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 409/1000] Train Loss: 1.0993  |  Val Loss: 1.1581\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 410/1000] Train Loss: 1.0899  |  Val Loss: 1.1562\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 411/1000] Train Loss: 1.0960  |  Val Loss: 1.1448\n",
      "Validation loss improved from 1.1484 to 1.1448.\n",
      "[Epoch 412/1000] Train Loss: 1.0939  |  Val Loss: 1.1676\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 413/1000] Train Loss: 1.1020  |  Val Loss: 1.1681\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 414/1000] Train Loss: 1.1023  |  Val Loss: 1.1766\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 415/1000] Train Loss: 1.0824  |  Val Loss: 1.1834\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 416/1000] Train Loss: 1.1029  |  Val Loss: 1.1711\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 417/1000] Train Loss: 1.1176  |  Val Loss: 1.2194\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 418/1000] Train Loss: 1.1093  |  Val Loss: 1.1557\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 419/1000] Train Loss: 1.0915  |  Val Loss: 1.1519\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 420/1000] Train Loss: 1.0926  |  Val Loss: 1.3229\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 421/1000] Train Loss: 1.1604  |  Val Loss: 1.2166\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 422/1000] Train Loss: 1.1245  |  Val Loss: 1.1462\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 423/1000] Train Loss: 1.0998  |  Val Loss: 1.4051\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 424/1000] Train Loss: 1.1800  |  Val Loss: 1.1657\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 425/1000] Train Loss: 1.1490  |  Val Loss: 1.1475\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 426/1000] Train Loss: 1.1019  |  Val Loss: 1.3580\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 427/1000] Train Loss: 1.1594  |  Val Loss: 1.1533\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 428/1000] Train Loss: 1.1984  |  Val Loss: 1.1597\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 429/1000] Train Loss: 1.1418  |  Val Loss: 1.4903\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 430/1000] Train Loss: 1.1653  |  Val Loss: 1.1773\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 431/1000] Train Loss: 1.1553  |  Val Loss: 1.2711\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 432/1000] Train Loss: 1.1472  |  Val Loss: 1.4389\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 433/1000] Train Loss: 1.1364  |  Val Loss: 1.1422\n",
      "Validation loss improved from 1.1448 to 1.1422.\n",
      "[Epoch 434/1000] Train Loss: 1.1619  |  Val Loss: 1.1441\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 435/1000] Train Loss: 1.1115  |  Val Loss: 1.2848\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 436/1000] Train Loss: 1.1222  |  Val Loss: 1.1471\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 437/1000] Train Loss: 1.0951  |  Val Loss: 1.1368\n",
      "Validation loss improved from 1.1422 to 1.1368.\n",
      "[Epoch 438/1000] Train Loss: 1.0855  |  Val Loss: 1.2272\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 439/1000] Train Loss: 1.1007  |  Val Loss: 1.1396\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 440/1000] Train Loss: 1.1001  |  Val Loss: 1.1289\n",
      "Validation loss improved from 1.1368 to 1.1289.\n",
      "[Epoch 441/1000] Train Loss: 1.0981  |  Val Loss: 1.2303\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 442/1000] Train Loss: 1.1037  |  Val Loss: 1.2086\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 443/1000] Train Loss: 1.1012  |  Val Loss: 1.1676\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 444/1000] Train Loss: 1.0909  |  Val Loss: 1.2602\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 445/1000] Train Loss: 1.1042  |  Val Loss: 1.1542\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 446/1000] Train Loss: 1.1116  |  Val Loss: 1.1681\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 447/1000] Train Loss: 1.1008  |  Val Loss: 1.1466\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 448/1000] Train Loss: 1.1247  |  Val Loss: 1.1207\n",
      "Validation loss improved from 1.1289 to 1.1207.\n",
      "[Epoch 449/1000] Train Loss: 1.1074  |  Val Loss: 1.2325\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 450/1000] Train Loss: 1.0972  |  Val Loss: 1.1556\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 451/1000] Train Loss: 1.1714  |  Val Loss: 1.3165\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 452/1000] Train Loss: 1.2746  |  Val Loss: 1.3295\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 453/1000] Train Loss: 1.1496  |  Val Loss: 1.1262\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 454/1000] Train Loss: 1.1074  |  Val Loss: 1.3598\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 455/1000] Train Loss: 1.1370  |  Val Loss: 1.1550\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 456/1000] Train Loss: 1.0850  |  Val Loss: 1.1200\n",
      "Validation loss improved from 1.1207 to 1.1200.\n",
      "[Epoch 457/1000] Train Loss: 1.1297  |  Val Loss: 1.1946\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 458/1000] Train Loss: 1.1011  |  Val Loss: 1.2478\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 459/1000] Train Loss: 1.0880  |  Val Loss: 1.1325\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 460/1000] Train Loss: 1.0826  |  Val Loss: 1.1775\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 461/1000] Train Loss: 1.0693  |  Val Loss: 1.1936\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 462/1000] Train Loss: 1.0828  |  Val Loss: 1.2114\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 463/1000] Train Loss: 1.0777  |  Val Loss: 1.2493\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 464/1000] Train Loss: 1.0829  |  Val Loss: 1.1545\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 465/1000] Train Loss: 1.0666  |  Val Loss: 1.1316\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 466/1000] Train Loss: 1.0848  |  Val Loss: 1.2233\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 467/1000] Train Loss: 1.0956  |  Val Loss: 1.1519\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 468/1000] Train Loss: 1.0654  |  Val Loss: 1.1275\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 469/1000] Train Loss: 1.0830  |  Val Loss: 1.2160\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 470/1000] Train Loss: 1.0827  |  Val Loss: 1.2006\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 471/1000] Train Loss: 1.0790  |  Val Loss: 1.1252\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 472/1000] Train Loss: 1.0584  |  Val Loss: 1.1877\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 473/1000] Train Loss: 1.0723  |  Val Loss: 1.2095\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 474/1000] Train Loss: 1.0762  |  Val Loss: 1.1327\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 475/1000] Train Loss: 1.0750  |  Val Loss: 1.1171\n",
      "Validation loss improved from 1.1200 to 1.1171.\n",
      "[Epoch 476/1000] Train Loss: 1.0784  |  Val Loss: 1.1129\n",
      "Validation loss improved from 1.1171 to 1.1129.\n",
      "[Epoch 477/1000] Train Loss: 1.0659  |  Val Loss: 1.1292\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 478/1000] Train Loss: 1.0586  |  Val Loss: 1.1624\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 479/1000] Train Loss: 1.0646  |  Val Loss: 1.1387\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 480/1000] Train Loss: 1.0736  |  Val Loss: 1.1525\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 481/1000] Train Loss: 1.0485  |  Val Loss: 1.1464\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 482/1000] Train Loss: 1.0497  |  Val Loss: 1.2125\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 483/1000] Train Loss: 1.0646  |  Val Loss: 1.1153\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 484/1000] Train Loss: 1.0721  |  Val Loss: 1.0996\n",
      "Validation loss improved from 1.1129 to 1.0996.\n",
      "[Epoch 485/1000] Train Loss: 1.0623  |  Val Loss: 1.1609\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 486/1000] Train Loss: 1.0588  |  Val Loss: 1.1209\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 487/1000] Train Loss: 1.0764  |  Val Loss: 1.1641\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 488/1000] Train Loss: 1.0621  |  Val Loss: 1.0891\n",
      "Validation loss improved from 1.0996 to 1.0891.\n",
      "[Epoch 489/1000] Train Loss: 1.0646  |  Val Loss: 1.1658\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 490/1000] Train Loss: 1.0733  |  Val Loss: 1.1303\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 491/1000] Train Loss: 1.0734  |  Val Loss: 1.1350\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 492/1000] Train Loss: 1.0777  |  Val Loss: 1.1396\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 493/1000] Train Loss: 1.0729  |  Val Loss: 1.1127\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 494/1000] Train Loss: 1.0511  |  Val Loss: 1.1525\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 495/1000] Train Loss: 1.0492  |  Val Loss: 1.1503\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 496/1000] Train Loss: 1.0634  |  Val Loss: 1.1989\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 497/1000] Train Loss: 1.0513  |  Val Loss: 1.1408\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 498/1000] Train Loss: 1.0631  |  Val Loss: 1.1554\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 499/1000] Train Loss: 1.0511  |  Val Loss: 1.1446\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 500/1000] Train Loss: 1.0655  |  Val Loss: 1.2255\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 501/1000] Train Loss: 1.0778  |  Val Loss: 1.1413\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 502/1000] Train Loss: 1.0472  |  Val Loss: 1.1685\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 503/1000] Train Loss: 1.1013  |  Val Loss: 1.1963\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 504/1000] Train Loss: 1.0707  |  Val Loss: 1.1834\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 505/1000] Train Loss: 1.1020  |  Val Loss: 1.1516\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 506/1000] Train Loss: 1.0570  |  Val Loss: 1.1561\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 507/1000] Train Loss: 1.0831  |  Val Loss: 1.1221\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 508/1000] Train Loss: 1.1567  |  Val Loss: 1.1485\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 509/1000] Train Loss: 1.1276  |  Val Loss: 1.3498\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 510/1000] Train Loss: 1.1272  |  Val Loss: 1.1590\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 511/1000] Train Loss: 1.1425  |  Val Loss: 1.1984\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 512/1000] Train Loss: 1.0915  |  Val Loss: 1.2140\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 513/1000] Train Loss: 1.0821  |  Val Loss: 1.1136\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 514/1000] Train Loss: 1.0960  |  Val Loss: 1.2001\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 515/1000] Train Loss: 1.0658  |  Val Loss: 1.1413\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 516/1000] Train Loss: 1.0605  |  Val Loss: 1.1035\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 517/1000] Train Loss: 1.0787  |  Val Loss: 1.2954\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 518/1000] Train Loss: 1.0868  |  Val Loss: 1.1812\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 519/1000] Train Loss: 1.0498  |  Val Loss: 1.1128\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 520/1000] Train Loss: 1.0348  |  Val Loss: 1.1739\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 521/1000] Train Loss: 1.0613  |  Val Loss: 1.1644\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 522/1000] Train Loss: 1.0483  |  Val Loss: 1.1485\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 523/1000] Train Loss: 1.0459  |  Val Loss: 1.1561\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 524/1000] Train Loss: 1.0328  |  Val Loss: 1.1378\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 525/1000] Train Loss: 1.0377  |  Val Loss: 1.1580\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 526/1000] Train Loss: 1.0537  |  Val Loss: 1.1449\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 527/1000] Train Loss: 1.0390  |  Val Loss: 1.0706\n",
      "Validation loss improved from 1.0891 to 1.0706.\n",
      "[Epoch 528/1000] Train Loss: 1.0485  |  Val Loss: 1.1591\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 529/1000] Train Loss: 1.0492  |  Val Loss: 1.1286\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 530/1000] Train Loss: 1.0693  |  Val Loss: 1.1239\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 531/1000] Train Loss: 1.0404  |  Val Loss: 1.3169\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 532/1000] Train Loss: 1.0731  |  Val Loss: 1.0927\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 533/1000] Train Loss: 1.1215  |  Val Loss: 1.1188\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 534/1000] Train Loss: 1.0569  |  Val Loss: 1.3925\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 535/1000] Train Loss: 1.1071  |  Val Loss: 1.0919\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 536/1000] Train Loss: 1.0524  |  Val Loss: 1.0871\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 537/1000] Train Loss: 1.0543  |  Val Loss: 1.2001\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 538/1000] Train Loss: 1.0577  |  Val Loss: 1.0901\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 539/1000] Train Loss: 1.0573  |  Val Loss: 1.0723\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 540/1000] Train Loss: 1.0488  |  Val Loss: 1.2948\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 541/1000] Train Loss: 1.1016  |  Val Loss: 1.0998\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 542/1000] Train Loss: 1.0711  |  Val Loss: 1.1155\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 543/1000] Train Loss: 1.0699  |  Val Loss: 1.1709\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 544/1000] Train Loss: 1.0462  |  Val Loss: 1.1156\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 545/1000] Train Loss: 1.0449  |  Val Loss: 1.0929\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 546/1000] Train Loss: 1.0875  |  Val Loss: 1.2106\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 547/1000] Train Loss: 1.0725  |  Val Loss: 1.3748\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 548/1000] Train Loss: 1.1057  |  Val Loss: 1.1198\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 549/1000] Train Loss: 1.0624  |  Val Loss: 1.1378\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 550/1000] Train Loss: 1.0173  |  Val Loss: 1.1713\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 551/1000] Train Loss: 1.0294  |  Val Loss: 1.1043\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 552/1000] Train Loss: 1.0600  |  Val Loss: 1.0941\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 553/1000] Train Loss: 1.0438  |  Val Loss: 1.1465\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 554/1000] Train Loss: 1.0602  |  Val Loss: 1.0956\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 555/1000] Train Loss: 1.0203  |  Val Loss: 1.1623\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 556/1000] Train Loss: 1.0565  |  Val Loss: 1.0856\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 557/1000] Train Loss: 1.0352  |  Val Loss: 1.1078\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 558/1000] Train Loss: 1.0300  |  Val Loss: 1.2240\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 559/1000] Train Loss: 1.0411  |  Val Loss: 1.0871\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 560/1000] Train Loss: 1.0109  |  Val Loss: 1.1070\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 561/1000] Train Loss: 1.0172  |  Val Loss: 1.1384\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 562/1000] Train Loss: 1.0235  |  Val Loss: 1.0851\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 563/1000] Train Loss: 1.0313  |  Val Loss: 1.1988\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 564/1000] Train Loss: 1.0499  |  Val Loss: 1.1941\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 565/1000] Train Loss: 1.0420  |  Val Loss: 1.0933\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 566/1000] Train Loss: 1.0341  |  Val Loss: 1.1055\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 567/1000] Train Loss: 1.0160  |  Val Loss: 1.1137\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 568/1000] Train Loss: 1.0052  |  Val Loss: 1.1304\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 569/1000] Train Loss: 1.0264  |  Val Loss: 1.1508\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 570/1000] Train Loss: 1.0166  |  Val Loss: 1.1196\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 571/1000] Train Loss: 1.0131  |  Val Loss: 1.1612\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 572/1000] Train Loss: 1.0095  |  Val Loss: 1.1012\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 573/1000] Train Loss: 1.0021  |  Val Loss: 1.0759\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 574/1000] Train Loss: 1.0106  |  Val Loss: 1.0884\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 575/1000] Train Loss: 1.0090  |  Val Loss: 1.1626\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 576/1000] Train Loss: 1.0168  |  Val Loss: 1.0961\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 577/1000] Train Loss: 1.0235  |  Val Loss: 1.1019\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 578/1000] Train Loss: 1.0008  |  Val Loss: 1.0963\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 579/1000] Train Loss: 0.9959  |  Val Loss: 1.0746\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 580/1000] Train Loss: 1.0187  |  Val Loss: 1.0685\n",
      "Validation loss improved from 1.0706 to 1.0685.\n",
      "[Epoch 581/1000] Train Loss: 0.9983  |  Val Loss: 1.0802\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 582/1000] Train Loss: 0.9930  |  Val Loss: 1.0857\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 583/1000] Train Loss: 1.0006  |  Val Loss: 1.1247\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 584/1000] Train Loss: 1.0181  |  Val Loss: 1.1337\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 585/1000] Train Loss: 0.9936  |  Val Loss: 1.0784\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 586/1000] Train Loss: 1.0102  |  Val Loss: 1.1873\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 587/1000] Train Loss: 1.0433  |  Val Loss: 1.1605\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 588/1000] Train Loss: 1.0305  |  Val Loss: 1.1458\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 589/1000] Train Loss: 1.0233  |  Val Loss: 1.2345\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 590/1000] Train Loss: 1.0111  |  Val Loss: 1.0894\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 591/1000] Train Loss: 1.0312  |  Val Loss: 1.1928\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 592/1000] Train Loss: 1.0482  |  Val Loss: 1.1357\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 593/1000] Train Loss: 1.0170  |  Val Loss: 1.1070\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 594/1000] Train Loss: 1.0003  |  Val Loss: 1.2589\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 595/1000] Train Loss: 1.0189  |  Val Loss: 1.0799\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 596/1000] Train Loss: 1.1073  |  Val Loss: 1.1037\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 597/1000] Train Loss: 1.0088  |  Val Loss: 1.2378\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 598/1000] Train Loss: 1.0307  |  Val Loss: 1.0645\n",
      "Validation loss improved from 1.0685 to 1.0645.\n",
      "[Epoch 599/1000] Train Loss: 1.0010  |  Val Loss: 1.2513\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 600/1000] Train Loss: 1.0460  |  Val Loss: 1.1149\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 601/1000] Train Loss: 1.0153  |  Val Loss: 1.0426\n",
      "Validation loss improved from 1.0645 to 1.0426.\n",
      "[Epoch 602/1000] Train Loss: 1.0211  |  Val Loss: 1.1773\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 603/1000] Train Loss: 1.0222  |  Val Loss: 1.0868\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 604/1000] Train Loss: 1.0181  |  Val Loss: 1.1050\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 605/1000] Train Loss: 0.9937  |  Val Loss: 1.1083\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 606/1000] Train Loss: 1.0412  |  Val Loss: 1.0555\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 607/1000] Train Loss: 0.9964  |  Val Loss: 1.1245\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 608/1000] Train Loss: 0.9996  |  Val Loss: 1.1109\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 609/1000] Train Loss: 0.9981  |  Val Loss: 1.0914\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 610/1000] Train Loss: 0.9826  |  Val Loss: 1.0648\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 611/1000] Train Loss: 0.9749  |  Val Loss: 1.0869\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 612/1000] Train Loss: 0.9902  |  Val Loss: 1.1077\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 613/1000] Train Loss: 0.9938  |  Val Loss: 1.2880\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 614/1000] Train Loss: 1.0651  |  Val Loss: 1.0975\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 615/1000] Train Loss: 1.0062  |  Val Loss: 1.0257\n",
      "Validation loss improved from 1.0426 to 1.0257.\n",
      "[Epoch 616/1000] Train Loss: 0.9811  |  Val Loss: 1.3331\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 617/1000] Train Loss: 1.0785  |  Val Loss: 1.0370\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 618/1000] Train Loss: 1.0348  |  Val Loss: 1.0164\n",
      "Validation loss improved from 1.0257 to 1.0164.\n",
      "[Epoch 619/1000] Train Loss: 1.0123  |  Val Loss: 1.1454\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 620/1000] Train Loss: 1.0058  |  Val Loss: 1.0257\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 621/1000] Train Loss: 0.9813  |  Val Loss: 1.1732\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 622/1000] Train Loss: 0.9854  |  Val Loss: 1.0971\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 623/1000] Train Loss: 0.9700  |  Val Loss: 1.1407\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 624/1000] Train Loss: 1.0017  |  Val Loss: 1.1138\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 625/1000] Train Loss: 0.9633  |  Val Loss: 1.0431\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 626/1000] Train Loss: 0.9902  |  Val Loss: 1.1179\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 627/1000] Train Loss: 0.9773  |  Val Loss: 1.0788\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 628/1000] Train Loss: 0.9876  |  Val Loss: 1.1227\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 629/1000] Train Loss: 0.9975  |  Val Loss: 1.1720\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 630/1000] Train Loss: 1.0092  |  Val Loss: 1.0683\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 631/1000] Train Loss: 0.9764  |  Val Loss: 1.2197\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 632/1000] Train Loss: 1.0244  |  Val Loss: 1.0852\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 633/1000] Train Loss: 0.9990  |  Val Loss: 1.0416\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 634/1000] Train Loss: 0.9774  |  Val Loss: 1.1377\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 635/1000] Train Loss: 0.9838  |  Val Loss: 1.0463\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 636/1000] Train Loss: 0.9724  |  Val Loss: 1.1236\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 637/1000] Train Loss: 0.9927  |  Val Loss: 1.0166\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 638/1000] Train Loss: 1.0536  |  Val Loss: 1.0211\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 639/1000] Train Loss: 1.0150  |  Val Loss: 1.1985\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 640/1000] Train Loss: 0.9863  |  Val Loss: 1.0397\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 641/1000] Train Loss: 1.0592  |  Val Loss: 1.1440\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 642/1000] Train Loss: 1.0022  |  Val Loss: 1.1945\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 643/1000] Train Loss: 0.9807  |  Val Loss: 1.0470\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 644/1000] Train Loss: 0.9967  |  Val Loss: 1.1387\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 645/1000] Train Loss: 0.9713  |  Val Loss: 1.1881\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 646/1000] Train Loss: 0.9935  |  Val Loss: 1.0851\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 647/1000] Train Loss: 0.9645  |  Val Loss: 1.0581\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 648/1000] Train Loss: 0.9718  |  Val Loss: 1.1624\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 649/1000] Train Loss: 0.9914  |  Val Loss: 1.1218\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 650/1000] Train Loss: 0.9657  |  Val Loss: 1.1323\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 651/1000] Train Loss: 0.9990  |  Val Loss: 1.1523\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 652/1000] Train Loss: 0.9434  |  Val Loss: 1.0297\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 653/1000] Train Loss: 1.0243  |  Val Loss: 1.0950\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 654/1000] Train Loss: 0.9773  |  Val Loss: 1.2240\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 655/1000] Train Loss: 1.0132  |  Val Loss: 1.0692\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 656/1000] Train Loss: 0.9576  |  Val Loss: 1.0582\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 657/1000] Train Loss: 0.9676  |  Val Loss: 1.0575\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 658/1000] Train Loss: 0.9449  |  Val Loss: 1.1309\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 659/1000] Train Loss: 0.9754  |  Val Loss: 1.0564\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 660/1000] Train Loss: 0.9733  |  Val Loss: 1.1043\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 661/1000] Train Loss: 0.9688  |  Val Loss: 1.1367\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 662/1000] Train Loss: 0.9405  |  Val Loss: 1.0492\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 663/1000] Train Loss: 1.0251  |  Val Loss: 1.0849\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 664/1000] Train Loss: 0.9657  |  Val Loss: 1.1636\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 665/1000] Train Loss: 0.9634  |  Val Loss: 1.0246\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 666/1000] Train Loss: 0.9550  |  Val Loss: 1.1679\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 667/1000] Train Loss: 0.9672  |  Val Loss: 1.0757\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 668/1000] Train Loss: 0.9347  |  Val Loss: 1.0161\n",
      "Validation loss improved from 1.0164 to 1.0161.\n",
      "[Epoch 669/1000] Train Loss: 0.9636  |  Val Loss: 1.0788\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 670/1000] Train Loss: 0.9616  |  Val Loss: 1.0970\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 671/1000] Train Loss: 0.9387  |  Val Loss: 1.0203\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 672/1000] Train Loss: 0.9444  |  Val Loss: 1.0942\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 673/1000] Train Loss: 0.9978  |  Val Loss: 1.0469\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 674/1000] Train Loss: 0.9466  |  Val Loss: 1.0358\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 675/1000] Train Loss: 0.9562  |  Val Loss: 1.0911\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 676/1000] Train Loss: 0.9575  |  Val Loss: 1.0963\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 677/1000] Train Loss: 0.9471  |  Val Loss: 0.9916\n",
      "Validation loss improved from 1.0161 to 0.9916.\n",
      "[Epoch 678/1000] Train Loss: 0.9560  |  Val Loss: 1.0946\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 679/1000] Train Loss: 0.9896  |  Val Loss: 1.0367\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 680/1000] Train Loss: 0.9747  |  Val Loss: 1.0936\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 681/1000] Train Loss: 0.9685  |  Val Loss: 1.1484\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 682/1000] Train Loss: 0.9600  |  Val Loss: 1.0452\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 683/1000] Train Loss: 0.9592  |  Val Loss: 1.1482\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 684/1000] Train Loss: 0.9722  |  Val Loss: 1.0288\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 685/1000] Train Loss: 0.9573  |  Val Loss: 1.0240\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 686/1000] Train Loss: 0.9711  |  Val Loss: 1.0936\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 687/1000] Train Loss: 0.9812  |  Val Loss: 1.0213\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 688/1000] Train Loss: 0.9788  |  Val Loss: 1.1238\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 689/1000] Train Loss: 0.9982  |  Val Loss: 1.0774\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 690/1000] Train Loss: 0.9407  |  Val Loss: 1.0123\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 691/1000] Train Loss: 0.9507  |  Val Loss: 1.1568\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 692/1000] Train Loss: 0.9538  |  Val Loss: 1.0578\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 693/1000] Train Loss: 0.9791  |  Val Loss: 1.0697\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 694/1000] Train Loss: 0.9776  |  Val Loss: 1.1755\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 695/1000] Train Loss: 0.9630  |  Val Loss: 1.0527\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 696/1000] Train Loss: 0.9533  |  Val Loss: 1.0339\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 697/1000] Train Loss: 0.9791  |  Val Loss: 1.0515\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 698/1000] Train Loss: 0.9229  |  Val Loss: 1.1054\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 699/1000] Train Loss: 0.9289  |  Val Loss: 1.0215\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 700/1000] Train Loss: 0.9132  |  Val Loss: 1.0275\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 701/1000] Train Loss: 0.9425  |  Val Loss: 1.0561\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 702/1000] Train Loss: 0.9146  |  Val Loss: 1.0382\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 703/1000] Train Loss: 0.9468  |  Val Loss: 1.0336\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 704/1000] Train Loss: 0.9365  |  Val Loss: 1.1201\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 705/1000] Train Loss: 0.9289  |  Val Loss: 0.9962\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 706/1000] Train Loss: 0.9479  |  Val Loss: 1.0217\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 707/1000] Train Loss: 0.9205  |  Val Loss: 1.0364\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 708/1000] Train Loss: 0.9411  |  Val Loss: 1.0610\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 709/1000] Train Loss: 0.9196  |  Val Loss: 1.2145\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 710/1000] Train Loss: 0.9771  |  Val Loss: 1.0273\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 711/1000] Train Loss: 0.9847  |  Val Loss: 1.0119\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 712/1000] Train Loss: 0.9242  |  Val Loss: 1.3000\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 713/1000] Train Loss: 0.9665  |  Val Loss: 0.9974\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 714/1000] Train Loss: 0.9878  |  Val Loss: 1.0461\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 715/1000] Train Loss: 0.9067  |  Val Loss: 1.2348\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 716/1000] Train Loss: 0.9628  |  Val Loss: 1.0494\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 717/1000] Train Loss: 1.0438  |  Val Loss: 1.0107\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 718/1000] Train Loss: 0.9495  |  Val Loss: 1.1638\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 719/1000] Train Loss: 0.9259  |  Val Loss: 1.0266\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 720/1000] Train Loss: 0.9085  |  Val Loss: 1.0401\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 721/1000] Train Loss: 0.9132  |  Val Loss: 1.1282\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 722/1000] Train Loss: 0.9485  |  Val Loss: 1.0350\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 723/1000] Train Loss: 0.9317  |  Val Loss: 0.9752\n",
      "Validation loss improved from 0.9916 to 0.9752.\n",
      "[Epoch 724/1000] Train Loss: 0.9133  |  Val Loss: 1.1827\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 725/1000] Train Loss: 0.9438  |  Val Loss: 1.0044\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 726/1000] Train Loss: 0.9286  |  Val Loss: 1.0018\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 727/1000] Train Loss: 0.9060  |  Val Loss: 1.2486\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 728/1000] Train Loss: 0.9947  |  Val Loss: 0.9859\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 729/1000] Train Loss: 0.9743  |  Val Loss: 1.0845\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 730/1000] Train Loss: 1.0051  |  Val Loss: 1.1923\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 731/1000] Train Loss: 0.9437  |  Val Loss: 1.0382\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 732/1000] Train Loss: 0.9503  |  Val Loss: 1.0554\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 733/1000] Train Loss: 0.9145  |  Val Loss: 1.0320\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 734/1000] Train Loss: 0.8842  |  Val Loss: 1.0340\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 735/1000] Train Loss: 0.9045  |  Val Loss: 1.1328\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 736/1000] Train Loss: 0.9217  |  Val Loss: 1.0252\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 737/1000] Train Loss: 0.9565  |  Val Loss: 1.0425\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 738/1000] Train Loss: 0.9343  |  Val Loss: 1.2291\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 739/1000] Train Loss: 0.9507  |  Val Loss: 0.9674\n",
      "Validation loss improved from 0.9752 to 0.9674.\n",
      "[Epoch 740/1000] Train Loss: 0.9233  |  Val Loss: 1.0557\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 741/1000] Train Loss: 0.9338  |  Val Loss: 1.0412\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 742/1000] Train Loss: 0.9053  |  Val Loss: 0.9997\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 743/1000] Train Loss: 0.9613  |  Val Loss: 1.1000\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 744/1000] Train Loss: 0.8980  |  Val Loss: 1.0770\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 745/1000] Train Loss: 1.0061  |  Val Loss: 1.1394\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 746/1000] Train Loss: 0.9667  |  Val Loss: 1.1353\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 747/1000] Train Loss: 0.9113  |  Val Loss: 0.9883\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 748/1000] Train Loss: 0.9258  |  Val Loss: 1.1740\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 749/1000] Train Loss: 0.9529  |  Val Loss: 1.0871\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 750/1000] Train Loss: 0.9202  |  Val Loss: 1.0089\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 751/1000] Train Loss: 0.9075  |  Val Loss: 1.1473\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 752/1000] Train Loss: 0.9040  |  Val Loss: 0.9857\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 753/1000] Train Loss: 0.9012  |  Val Loss: 1.0852\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 754/1000] Train Loss: 0.9368  |  Val Loss: 1.1212\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 755/1000] Train Loss: 0.9175  |  Val Loss: 0.9934\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 756/1000] Train Loss: 0.9420  |  Val Loss: 1.1074\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 757/1000] Train Loss: 0.9676  |  Val Loss: 1.0100\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 758/1000] Train Loss: 0.9026  |  Val Loss: 1.0040\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 759/1000] Train Loss: 0.9114  |  Val Loss: 1.2186\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 760/1000] Train Loss: 0.9827  |  Val Loss: 1.0173\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 761/1000] Train Loss: 0.9210  |  Val Loss: 1.0251\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 762/1000] Train Loss: 0.9241  |  Val Loss: 1.2736\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 763/1000] Train Loss: 0.9651  |  Val Loss: 1.0104\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 764/1000] Train Loss: 0.9733  |  Val Loss: 1.0012\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 765/1000] Train Loss: 0.9385  |  Val Loss: 1.1053\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 766/1000] Train Loss: 0.9213  |  Val Loss: 1.0454\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 767/1000] Train Loss: 0.9099  |  Val Loss: 1.0044\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 768/1000] Train Loss: 0.9164  |  Val Loss: 1.0274\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 769/1000] Train Loss: 0.8681  |  Val Loss: 1.0789\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 770/1000] Train Loss: 0.8831  |  Val Loss: 1.1269\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 771/1000] Train Loss: 0.8937  |  Val Loss: 1.0317\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 772/1000] Train Loss: 0.8717  |  Val Loss: 0.9933\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 773/1000] Train Loss: 0.8950  |  Val Loss: 1.0344\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 774/1000] Train Loss: 0.8797  |  Val Loss: 1.0475\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 775/1000] Train Loss: 0.9051  |  Val Loss: 0.9928\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 776/1000] Train Loss: 0.8719  |  Val Loss: 1.1375\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 777/1000] Train Loss: 0.9061  |  Val Loss: 0.9686\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 778/1000] Train Loss: 0.9009  |  Val Loss: 0.9662\n",
      "Validation loss improved from 0.9674 to 0.9662.\n",
      "[Epoch 779/1000] Train Loss: 0.9058  |  Val Loss: 1.0251\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 780/1000] Train Loss: 0.8887  |  Val Loss: 0.9475\n",
      "Validation loss improved from 0.9662 to 0.9475.\n",
      "[Epoch 781/1000] Train Loss: 0.8714  |  Val Loss: 1.1777\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 782/1000] Train Loss: 0.9180  |  Val Loss: 1.0245\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 783/1000] Train Loss: 0.8851  |  Val Loss: 1.0150\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 784/1000] Train Loss: 0.8803  |  Val Loss: 1.0895\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 785/1000] Train Loss: 0.8762  |  Val Loss: 0.9639\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 786/1000] Train Loss: 0.8489  |  Val Loss: 0.9875\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 787/1000] Train Loss: 0.8733  |  Val Loss: 0.9845\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 788/1000] Train Loss: 0.8666  |  Val Loss: 1.0312\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 789/1000] Train Loss: 0.8755  |  Val Loss: 1.0226\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 790/1000] Train Loss: 0.8754  |  Val Loss: 1.1112\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 791/1000] Train Loss: 0.9365  |  Val Loss: 1.0112\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 792/1000] Train Loss: 0.8711  |  Val Loss: 0.9505\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 793/1000] Train Loss: 0.9094  |  Val Loss: 1.2148\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 794/1000] Train Loss: 0.9159  |  Val Loss: 0.9884\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 795/1000] Train Loss: 0.8616  |  Val Loss: 0.9666\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 796/1000] Train Loss: 0.8658  |  Val Loss: 1.0629\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 797/1000] Train Loss: 0.8635  |  Val Loss: 0.9739\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 798/1000] Train Loss: 0.8616  |  Val Loss: 0.9744\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 799/1000] Train Loss: 0.8581  |  Val Loss: 1.0572\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 800/1000] Train Loss: 0.8772  |  Val Loss: 1.1353\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 801/1000] Train Loss: 0.8622  |  Val Loss: 0.9558\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 802/1000] Train Loss: 0.8950  |  Val Loss: 1.0631\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 803/1000] Train Loss: 0.8850  |  Val Loss: 1.0237\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 804/1000] Train Loss: 0.8589  |  Val Loss: 0.9155\n",
      "Validation loss improved from 0.9475 to 0.9155.\n",
      "[Epoch 805/1000] Train Loss: 0.8640  |  Val Loss: 1.0572\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 806/1000] Train Loss: 0.8628  |  Val Loss: 0.9566\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 807/1000] Train Loss: 0.8811  |  Val Loss: 0.9479\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 808/1000] Train Loss: 0.8557  |  Val Loss: 0.9771\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 809/1000] Train Loss: 0.8515  |  Val Loss: 0.9917\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 810/1000] Train Loss: 0.8344  |  Val Loss: 1.0430\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 811/1000] Train Loss: 0.8460  |  Val Loss: 0.9410\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 812/1000] Train Loss: 0.8835  |  Val Loss: 1.0844\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 813/1000] Train Loss: 0.8718  |  Val Loss: 1.0494\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 814/1000] Train Loss: 0.8924  |  Val Loss: 0.9999\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 815/1000] Train Loss: 0.8850  |  Val Loss: 1.3064\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 816/1000] Train Loss: 0.9308  |  Val Loss: 0.9410\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 817/1000] Train Loss: 0.9117  |  Val Loss: 0.9920\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 818/1000] Train Loss: 0.8410  |  Val Loss: 1.2087\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 819/1000] Train Loss: 0.8975  |  Val Loss: 0.9681\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 820/1000] Train Loss: 0.8662  |  Val Loss: 0.9289\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 821/1000] Train Loss: 0.8494  |  Val Loss: 1.0979\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 822/1000] Train Loss: 0.8767  |  Val Loss: 1.0429\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 823/1000] Train Loss: 0.8330  |  Val Loss: 0.9414\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 824/1000] Train Loss: 0.8422  |  Val Loss: 1.0353\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 825/1000] Train Loss: 0.8362  |  Val Loss: 1.0884\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 826/1000] Train Loss: 0.8704  |  Val Loss: 0.9705\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 827/1000] Train Loss: 0.8447  |  Val Loss: 0.9774\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 828/1000] Train Loss: 0.8461  |  Val Loss: 1.1535\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 829/1000] Train Loss: 0.8624  |  Val Loss: 0.9285\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 830/1000] Train Loss: 0.8314  |  Val Loss: 0.9946\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 831/1000] Train Loss: 0.8462  |  Val Loss: 1.0040\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 832/1000] Train Loss: 0.8201  |  Val Loss: 0.9719\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 833/1000] Train Loss: 0.8099  |  Val Loss: 1.0636\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 834/1000] Train Loss: 0.8369  |  Val Loss: 0.9608\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 835/1000] Train Loss: 0.8413  |  Val Loss: 1.0069\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 836/1000] Train Loss: 0.8399  |  Val Loss: 1.0275\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 837/1000] Train Loss: 0.8366  |  Val Loss: 1.0054\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 838/1000] Train Loss: 0.8149  |  Val Loss: 1.0013\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 839/1000] Train Loss: 0.8045  |  Val Loss: 0.9922\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 840/1000] Train Loss: 0.8263  |  Val Loss: 1.0562\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 841/1000] Train Loss: 0.8388  |  Val Loss: 1.0072\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 842/1000] Train Loss: 0.8333  |  Val Loss: 0.9814\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 843/1000] Train Loss: 0.8256  |  Val Loss: 0.9624\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 844/1000] Train Loss: 0.8168  |  Val Loss: 1.0236\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 845/1000] Train Loss: 0.8076  |  Val Loss: 0.9566\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 846/1000] Train Loss: 0.8034  |  Val Loss: 0.9526\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 847/1000] Train Loss: 0.7990  |  Val Loss: 0.9864\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 848/1000] Train Loss: 0.8066  |  Val Loss: 1.0004\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 849/1000] Train Loss: 0.8166  |  Val Loss: 1.0522\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 850/1000] Train Loss: 0.8151  |  Val Loss: 0.9572\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 851/1000] Train Loss: 0.8427  |  Val Loss: 0.9927\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 852/1000] Train Loss: 0.8270  |  Val Loss: 1.0206\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 853/1000] Train Loss: 0.8116  |  Val Loss: 0.9607\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 854/1000] Train Loss: 0.8548  |  Val Loss: 1.0871\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 855/1000] Train Loss: 0.8821  |  Val Loss: 1.1240\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 856/1000] Train Loss: 0.8478  |  Val Loss: 0.9458\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 857/1000] Train Loss: 0.8154  |  Val Loss: 1.0313\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 858/1000] Train Loss: 0.8293  |  Val Loss: 1.0068\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 859/1000] Train Loss: 0.8385  |  Val Loss: 0.9021\n",
      "Validation loss improved from 0.9155 to 0.9021.\n",
      "[Epoch 860/1000] Train Loss: 0.8363  |  Val Loss: 1.0264\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 861/1000] Train Loss: 0.8221  |  Val Loss: 0.9727\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 862/1000] Train Loss: 0.7963  |  Val Loss: 0.9918\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 863/1000] Train Loss: 0.8123  |  Val Loss: 0.9640\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 864/1000] Train Loss: 0.8354  |  Val Loss: 0.9274\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 865/1000] Train Loss: 0.8209  |  Val Loss: 1.0514\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 866/1000] Train Loss: 0.8225  |  Val Loss: 0.9451\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 867/1000] Train Loss: 0.7960  |  Val Loss: 0.9271\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 868/1000] Train Loss: 0.8058  |  Val Loss: 0.9795\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 869/1000] Train Loss: 0.8181  |  Val Loss: 0.9928\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 870/1000] Train Loss: 0.8103  |  Val Loss: 0.9468\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 871/1000] Train Loss: 0.8169  |  Val Loss: 1.0034\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 872/1000] Train Loss: 0.8054  |  Val Loss: 0.9324\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 873/1000] Train Loss: 0.8002  |  Val Loss: 1.0066\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 874/1000] Train Loss: 0.8298  |  Val Loss: 1.1032\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 875/1000] Train Loss: 0.8145  |  Val Loss: 0.9505\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 876/1000] Train Loss: 0.7841  |  Val Loss: 1.0322\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 877/1000] Train Loss: 0.8032  |  Val Loss: 0.9948\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 878/1000] Train Loss: 0.8018  |  Val Loss: 0.9267\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 879/1000] Train Loss: 0.7996  |  Val Loss: 1.0326\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 880/1000] Train Loss: 0.8326  |  Val Loss: 0.9585\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 881/1000] Train Loss: 0.7881  |  Val Loss: 0.8999\n",
      "Validation loss improved from 0.9021 to 0.8999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 882/1000] Train Loss: 0.7803  |  Val Loss: 1.0596\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 883/1000] Train Loss: 0.8280  |  Val Loss: 0.9352\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 884/1000] Train Loss: 0.8008  |  Val Loss: 0.9008\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 885/1000] Train Loss: 0.7845  |  Val Loss: 1.1867\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 886/1000] Train Loss: 0.8960  |  Val Loss: 0.9554\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 887/1000] Train Loss: 0.8324  |  Val Loss: 0.9284\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 888/1000] Train Loss: 0.8135  |  Val Loss: 1.2049\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 889/1000] Train Loss: 0.8572  |  Val Loss: 0.9403\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 890/1000] Train Loss: 0.8109  |  Val Loss: 0.9918\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 891/1000] Train Loss: 0.8175  |  Val Loss: 1.1941\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 892/1000] Train Loss: 0.8288  |  Val Loss: 0.9310\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 893/1000] Train Loss: 0.8399  |  Val Loss: 1.0324\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 894/1000] Train Loss: 0.8764  |  Val Loss: 1.3185\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 895/1000] Train Loss: 0.8614  |  Val Loss: 0.8991\n",
      "Validation loss improved from 0.8999 to 0.8991.\n",
      "[Epoch 896/1000] Train Loss: 0.8653  |  Val Loss: 1.0802\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 897/1000] Train Loss: 0.9123  |  Val Loss: 1.2559\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 898/1000] Train Loss: 0.8650  |  Val Loss: 0.9341\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 899/1000] Train Loss: 0.9604  |  Val Loss: 0.9447\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 900/1000] Train Loss: 0.8078  |  Val Loss: 1.1601\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 901/1000] Train Loss: 0.8292  |  Val Loss: 0.9154\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 902/1000] Train Loss: 0.8628  |  Val Loss: 0.9612\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 903/1000] Train Loss: 0.7870  |  Val Loss: 1.0513\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 904/1000] Train Loss: 0.7917  |  Val Loss: 0.9254\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 905/1000] Train Loss: 0.7766  |  Val Loss: 1.0118\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 906/1000] Train Loss: 0.8361  |  Val Loss: 1.0104\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 907/1000] Train Loss: 0.7908  |  Val Loss: 0.9067\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 908/1000] Train Loss: 0.8108  |  Val Loss: 1.0199\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 909/1000] Train Loss: 0.7907  |  Val Loss: 0.9448\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 910/1000] Train Loss: 0.7974  |  Val Loss: 0.9111\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 911/1000] Train Loss: 0.7677  |  Val Loss: 1.0907\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 912/1000] Train Loss: 0.7916  |  Val Loss: 0.9119\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 913/1000] Train Loss: 0.7862  |  Val Loss: 0.9164\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 914/1000] Train Loss: 0.7684  |  Val Loss: 1.0361\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 915/1000] Train Loss: 0.7687  |  Val Loss: 0.9377\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 916/1000] Train Loss: 0.7580  |  Val Loss: 0.9777\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 917/1000] Train Loss: 0.7558  |  Val Loss: 0.9817\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 918/1000] Train Loss: 0.7518  |  Val Loss: 0.9441\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 919/1000] Train Loss: 0.7570  |  Val Loss: 0.8986\n",
      "Validation loss improved from 0.8991 to 0.8986.\n",
      "[Epoch 920/1000] Train Loss: 0.7408  |  Val Loss: 1.0087\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 921/1000] Train Loss: 0.7654  |  Val Loss: 0.9696\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 922/1000] Train Loss: 0.7562  |  Val Loss: 0.9085\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 923/1000] Train Loss: 0.7529  |  Val Loss: 0.9380\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 924/1000] Train Loss: 0.7503  |  Val Loss: 0.9074\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 925/1000] Train Loss: 0.7884  |  Val Loss: 0.8953\n",
      "Validation loss improved from 0.8986 to 0.8953.\n",
      "[Epoch 926/1000] Train Loss: 0.7846  |  Val Loss: 1.0998\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 927/1000] Train Loss: 0.7890  |  Val Loss: 0.9494\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 928/1000] Train Loss: 0.7723  |  Val Loss: 0.9297\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 929/1000] Train Loss: 0.7457  |  Val Loss: 0.9893\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 930/1000] Train Loss: 0.7575  |  Val Loss: 0.8958\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 931/1000] Train Loss: 0.7822  |  Val Loss: 0.9162\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 932/1000] Train Loss: 0.7435  |  Val Loss: 0.9154\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 933/1000] Train Loss: 0.7199  |  Val Loss: 0.9373\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 934/1000] Train Loss: 0.7374  |  Val Loss: 0.9221\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 935/1000] Train Loss: 0.7170  |  Val Loss: 0.9111\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 936/1000] Train Loss: 0.7468  |  Val Loss: 0.9150\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 937/1000] Train Loss: 0.7325  |  Val Loss: 0.9652\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 938/1000] Train Loss: 0.7467  |  Val Loss: 1.0220\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 939/1000] Train Loss: 0.7509  |  Val Loss: 0.9834\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 940/1000] Train Loss: 0.7880  |  Val Loss: 0.9990\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 941/1000] Train Loss: 0.7773  |  Val Loss: 1.1290\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 942/1000] Train Loss: 0.7774  |  Val Loss: 0.9442\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 943/1000] Train Loss: 0.7402  |  Val Loss: 0.9193\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 944/1000] Train Loss: 0.7283  |  Val Loss: 0.9009\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 945/1000] Train Loss: 0.7531  |  Val Loss: 0.9682\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 946/1000] Train Loss: 0.7638  |  Val Loss: 0.9292\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 947/1000] Train Loss: 0.7420  |  Val Loss: 0.9401\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 948/1000] Train Loss: 0.7799  |  Val Loss: 1.0357\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 949/1000] Train Loss: 0.7632  |  Val Loss: 0.8717\n",
      "Validation loss improved from 0.8953 to 0.8717.\n",
      "[Epoch 950/1000] Train Loss: 0.7537  |  Val Loss: 0.9371\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 951/1000] Train Loss: 0.7488  |  Val Loss: 1.0153\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 952/1000] Train Loss: 0.7932  |  Val Loss: 0.8886\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 953/1000] Train Loss: 0.7541  |  Val Loss: 1.0766\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 954/1000] Train Loss: 0.8047  |  Val Loss: 1.0931\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 955/1000] Train Loss: 0.7896  |  Val Loss: 0.9312\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 956/1000] Train Loss: 0.7646  |  Val Loss: 1.0300\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 957/1000] Train Loss: 0.7552  |  Val Loss: 0.9709\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 958/1000] Train Loss: 0.7306  |  Val Loss: 0.8611\n",
      "Validation loss improved from 0.8717 to 0.8611.\n",
      "[Epoch 959/1000] Train Loss: 0.7859  |  Val Loss: 0.8945\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 960/1000] Train Loss: 0.7141  |  Val Loss: 0.9315\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 961/1000] Train Loss: 0.7095  |  Val Loss: 0.9170\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 962/1000] Train Loss: 0.7310  |  Val Loss: 0.9805\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 963/1000] Train Loss: 0.7309  |  Val Loss: 0.9406\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 964/1000] Train Loss: 0.7074  |  Val Loss: 0.9546\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 965/1000] Train Loss: 0.7382  |  Val Loss: 0.9171\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 966/1000] Train Loss: 0.7055  |  Val Loss: 0.8851\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 967/1000] Train Loss: 0.7293  |  Val Loss: 0.9203\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 968/1000] Train Loss: 0.6998  |  Val Loss: 1.0181\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 969/1000] Train Loss: 0.7215  |  Val Loss: 0.8904\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 970/1000] Train Loss: 0.7184  |  Val Loss: 0.9318\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 971/1000] Train Loss: 0.7037  |  Val Loss: 0.9485\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 972/1000] Train Loss: 0.7272  |  Val Loss: 0.8744\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 973/1000] Train Loss: 0.7376  |  Val Loss: 0.8943\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 974/1000] Train Loss: 0.6952  |  Val Loss: 0.9472\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 975/1000] Train Loss: 0.7370  |  Val Loss: 0.8948\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 976/1000] Train Loss: 0.7085  |  Val Loss: 0.8902\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 977/1000] Train Loss: 0.6879  |  Val Loss: 0.9332\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 978/1000] Train Loss: 0.7015  |  Val Loss: 0.8603\n",
      "Validation loss improved from 0.8611 to 0.8603.\n",
      "[Epoch 979/1000] Train Loss: 0.7035  |  Val Loss: 0.8529\n",
      "Validation loss improved from 0.8603 to 0.8529.\n",
      "[Epoch 980/1000] Train Loss: 0.7223  |  Val Loss: 0.9344\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 981/1000] Train Loss: 0.7480  |  Val Loss: 0.9494\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 982/1000] Train Loss: 0.7064  |  Val Loss: 0.9779\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 983/1000] Train Loss: 0.7359  |  Val Loss: 0.9298\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 984/1000] Train Loss: 0.7360  |  Val Loss: 1.0352\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 985/1000] Train Loss: 0.7164  |  Val Loss: 0.9016\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 986/1000] Train Loss: 0.6906  |  Val Loss: 0.9323\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 987/1000] Train Loss: 0.7132  |  Val Loss: 0.9514\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 988/1000] Train Loss: 0.6908  |  Val Loss: 0.9972\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 989/1000] Train Loss: 0.7713  |  Val Loss: 0.9728\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 990/1000] Train Loss: 0.7114  |  Val Loss: 0.9018\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 991/1000] Train Loss: 0.7322  |  Val Loss: 0.9810\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 992/1000] Train Loss: 0.7182  |  Val Loss: 0.8958\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 993/1000] Train Loss: 0.6792  |  Val Loss: 0.8474\n",
      "Validation loss improved from 0.8529 to 0.8474.\n",
      "[Epoch 994/1000] Train Loss: 0.7433  |  Val Loss: 1.0313\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 995/1000] Train Loss: 0.7909  |  Val Loss: 0.9626\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 996/1000] Train Loss: 0.6943  |  Val Loss: 0.8161\n",
      "Validation loss improved from 0.8474 to 0.8161.\n",
      "[Epoch 997/1000] Train Loss: 0.7048  |  Val Loss: 0.9930\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 998/1000] Train Loss: 0.7098  |  Val Loss: 0.8584\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 999/1000] Train Loss: 0.6974  |  Val Loss: 0.8273\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1000/1000] Train Loss: 0.6898  |  Val Loss: 0.9825\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_input_dim = cae_mlp_train_reps.shape[1]\n",
    "cae_mlp_num_classes = len(torch.unique(cae_mlp_train_labels_torch))\n",
    "cae_mlp_model = MLPClassifier(cae_mlp_input_dim, cae_mlp_num_classes).to(device)\n",
    "\n",
    "cae_mlp_criterion = nn.CrossEntropyLoss()\n",
    "cae_mlp_optimizer = optim.Adam(cae_mlp_model.parameters(), lr=1e-3)\n",
    "\n",
    "cae_mlp_num_epochs = 1000\n",
    "cae_mlp_patience = 100\n",
    "\n",
    "cae_mlp_train_losses = []\n",
    "cae_mlp_val_losses = []\n",
    "\n",
    "cae_mlp_best_val_loss = float('inf')\n",
    "cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for cae_mlp_epoch in range(cae_mlp_num_epochs):\n",
    "    # Training\n",
    "    cae_mlp_model.train()\n",
    "    cae_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for cae_mlp_embeddings_batch, cae_mlp_labels_batch in cae_mlp_train_loader:\n",
    "        cae_mlp_embeddings_batch = cae_mlp_embeddings_batch.to(device)\n",
    "        cae_mlp_labels_batch = cae_mlp_labels_batch.to(device)\n",
    "        \n",
    "        cae_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        cae_mlp_outputs = cae_mlp_model(cae_mlp_embeddings_batch)\n",
    "        cae_mlp_loss = cae_mlp_criterion(cae_mlp_outputs, cae_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        cae_mlp_loss.backward()\n",
    "        cae_mlp_optimizer.step()\n",
    "        \n",
    "        cae_mlp_train_running_loss += cae_mlp_loss.item() * cae_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    cae_mlp_epoch_train_loss = cae_mlp_train_running_loss / len(cae_mlp_train_loader.dataset)\n",
    "    cae_mlp_train_losses.append(cae_mlp_epoch_train_loss)\n",
    "\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    cae_mlp_model.eval()\n",
    "    cae_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for cae_mlp_val_embeddings_batch, cae_mlp_val_labels_batch in cae_mlp_val_loader:\n",
    "            cae_mlp_val_embeddings_batch = cae_mlp_val_embeddings_batch.to(device)\n",
    "            cae_mlp_val_labels_batch = cae_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            cae_mlp_val_outputs = cae_mlp_model(cae_mlp_val_embeddings_batch)\n",
    "            cae_mlp_val_loss = cae_mlp_criterion(cae_mlp_val_outputs, cae_mlp_val_labels_batch)\n",
    "\n",
    "            cae_mlp_val_running_loss += cae_mlp_val_loss.item() * cae_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    cae_mlp_epoch_val_loss = cae_mlp_val_running_loss / len(cae_mlp_val_loader.dataset)\n",
    "    cae_mlp_val_losses.append(cae_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {cae_mlp_epoch+1}/{cae_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {cae_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {cae_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "\n",
    "    if cae_mlp_epoch_val_loss < cae_mlp_best_val_loss:\n",
    "        # improvement, reset patience\n",
    "        print(f\"Validation loss improved from {cae_mlp_best_val_loss:.4f} to {cae_mlp_epoch_val_loss:.4f}.\")\n",
    "        cae_mlp_best_val_loss = cae_mlp_epoch_val_loss\n",
    "        cae_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        cae_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {cae_mlp_epochs_without_improvement}/{cae_mlp_patience}\")\n",
    "        \n",
    "        if cae_mlp_epochs_without_improvement >= cae_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {cae_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {cae_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(cae_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(cae_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:59.352228Z",
     "iopub.status.busy": "2025-05-08T18:41:59.352228Z",
     "iopub.status.idle": "2025-05-08T18:41:59.493006Z",
     "shell.execute_reply": "2025-05-08T18:41:59.493006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CAE+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.9890 | Test Accuracy: 63.82%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cae_mlp_model.eval()\n",
    "\n",
    "cae_mlp_test_running_loss = 0.0\n",
    "cae_mlp_test_correct = 0\n",
    "cae_mlp_all_predictions = []\n",
    "cae_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cae_mlp_test_embeddings_batch, cae_mlp_test_labels_batch in cae_mlp_test_loader:\n",
    "        cae_mlp_test_embeddings_batch = cae_mlp_test_embeddings_batch.to(device)\n",
    "        cae_mlp_test_labels_batch = cae_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        cae_mlp_test_outputs = cae_mlp_model(cae_mlp_test_embeddings_batch)\n",
    "        \n",
    "        cae_mlp_test_loss_batch = cae_mlp_criterion(cae_mlp_test_outputs, cae_mlp_test_labels_batch)\n",
    "        cae_mlp_test_running_loss += cae_mlp_test_loss_batch.item() * cae_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, cae_mlp_test_predicted = torch.max(cae_mlp_test_outputs, dim=1)\n",
    "        cae_mlp_test_correct += (cae_mlp_test_predicted == cae_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        #saving predictions for conf matrix\n",
    "        cae_mlp_all_predictions.extend(cae_mlp_test_predicted.cpu().numpy())\n",
    "        cae_mlp_all_true_labels.extend(cae_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_predictions.npy'), np.array(cae_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'cae_mlp_true_labels.npy'), np.array(cae_mlp_all_true_labels))\n",
    "print(f\"Saved CAE+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "cae_mlp_epoch_test_loss = cae_mlp_test_running_loss / len(cae_mlp_test_loader.dataset)\n",
    "cae_mlp_test_accuracy = cae_mlp_test_correct / len(cae_mlp_test_loader.dataset)\n",
    "\n",
    "cae_mlp_test_accuracy_pct = cae_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {cae_mlp_epoch_test_loss:.4f} | Test Accuracy: {cae_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "cae_mlp_num_epochs_run = len(cae_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         cae_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, cae_mlp_num_epochs_run + 1),\n",
    "         [cae_mlp_epoch_test_loss]*cae_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical SCL with Cosine Similarity (Supervised Contrastive Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:59.496016Z",
     "iopub.status.busy": "2025-05-08T18:41:59.495018Z",
     "iopub.status.idle": "2025-05-08T18:41:59.505303Z",
     "shell.execute_reply": "2025-05-08T18:41:59.505303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 140 samples with 64 features each\n",
      "LOG: Labels shape: (140,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 3038 samples with 64 features each\n",
      "LOG: Labels shape: (3038,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (140, 64), \n",
      "Train labels shape: (140,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (70, 64), \n",
      "Val labels shape: (70,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (3038, 64), \n",
      "Test labels shape: (3038,)\n"
     ]
    }
   ],
   "source": [
    "tscl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "tscl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "tscl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "tscl_train_embeddings, tscl_train_labels = load_encoded_data(tscl_encoded_train_dir)\n",
    "tscl_val_embeddings, tscl_val_labels = load_encoded_data(tscl_encoded_val_dir)\n",
    "tscl_test_embeddings, tscl_test_labels = load_encoded_data(tscl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {tscl_train_embeddings.shape}, \\nTrain labels shape: {tscl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {tscl_val_embeddings.shape}, \\nVal labels shape: {tscl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {tscl_test_embeddings.shape}, \\nTest labels shape: {tscl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:59.508415Z",
     "iopub.status.busy": "2025-05-08T18:41:59.508415Z",
     "iopub.status.idle": "2025-05-08T18:41:59.519420Z",
     "shell.execute_reply": "2025-05-08T18:41:59.518918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 10, 1: 10, 2: 10, 3: 10, 4: 10, 5: 10, 6: 10, 7: 10, 8: 10, 9: 10, 10: 10, 11: 10, 12: 10, 13: 10}\n",
      "Training batch size: 140\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "tscl_train_embeddings = tscl_train_embeddings.reshape(tscl_train_embeddings.shape[0], -1)\n",
    "tscl_val_embeddings = tscl_val_embeddings.reshape(tscl_val_embeddings.shape[0], -1)\n",
    "tscl_test_embeddings = tscl_test_embeddings.reshape(tscl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "tscl_train_mean = np.mean(tscl_train_embeddings, axis=0)\n",
    "tscl_train_std = np.std(tscl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "tscl_train_embeddings = (tscl_train_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_val_embeddings = (tscl_val_embeddings - tscl_train_mean) / tscl_train_std\n",
    "tscl_test_embeddings = (tscl_test_embeddings - tscl_train_mean) / tscl_train_std\n",
    "\n",
    "tscl_train_dataset = TensorDataset(torch.tensor(tscl_train_embeddings, dtype=torch.float32), torch.tensor(tscl_train_labels, dtype=torch.long))\n",
    "tscl_val_dataset = TensorDataset(torch.tensor(tscl_val_embeddings, dtype=torch.float32), torch.tensor(tscl_val_labels, dtype=torch.long))\n",
    "tscl_test_dataset = TensorDataset(torch.tensor(tscl_test_embeddings, dtype=torch.float32), torch.tensor(tscl_test_labels, dtype=torch.long))\n",
    "\n",
    "tscl_m = 20\n",
    "tscl_num_classes = len(np.unique(tscl_train_labels))\n",
    "\n",
    "# Calculate theoretical required batch size\n",
    "tscl_required_batch_size = tscl_m * tscl_num_classes\n",
    "\n",
    "# Ensure batch size doesn't exceed training set size\n",
    "if tscl_required_batch_size > len(tscl_train_dataset):\n",
    "    #case 1: Not enough samples - reduce m proportionally\n",
    "    tscl_max_possible_m = len(tscl_train_dataset) // tscl_num_classes\n",
    "    tscl_m = max(1, tscl_max_possible_m)  # Ensure m >= 1\n",
    "    tscl_batch_size_train = tscl_m * tscl_num_classes\n",
    "else:\n",
    "    #case 2: Use full batch size\n",
    "    tscl_batch_size_train = tscl_required_batch_size\n",
    "\n",
    "tscl_sampler = MPerClassSampler(labels = tscl_train_labels, m = tscl_m, batch_size = tscl_batch_size_train, length_before_new_iter=len(tscl_train_dataset))\n",
    "tscl_train_loader = DataLoader(tscl_train_dataset, batch_size=tscl_batch_size_train, sampler=tscl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "tscl_dataloader_bs = 256\n",
    "tscl_val_loader = DataLoader(tscl_val_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "tscl_test_loader = DataLoader(tscl_test_dataset, batch_size=tscl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for tscl_X_batch, tscl_y_batch in tscl_train_loader:\n",
    "    tscl_unique, tscl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(tscl_unique, tscl_counts)))\n",
    "    print(f\"Training batch size: {tscl_batch_size_train}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:59.522425Z",
     "iopub.status.busy": "2025-05-08T18:41:59.521423Z",
     "iopub.status.idle": "2025-05-08T18:41:59.526929Z",
     "shell.execute_reply": "2025-05-08T18:41:59.526425Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature = 0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        #normalize feat vectors\n",
    "        features = F.normalize(features, p=2, dim = 1)\n",
    "\n",
    "        #compute cosine simi matrix\n",
    "        similarity_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "\n",
    "        #create a mask for +ve pairs - i.e. same class\n",
    "        labels = labels.unsqueeze(1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(features.device)\n",
    "\n",
    "        #loss computation\n",
    "        exp_sim = torch.exp(similarity_matrix)\n",
    "        log_prob = similarity_matrix - torch.log(exp_sim.sum(dim = 1, keepdim=True))\n",
    "\n",
    "        #mask out diagonal - i.e. self similarity\n",
    "        mask_self = torch.eye(mask.shape[0], dtype = torch.bool).to(features.device)\n",
    "        mask = mask * (~mask_self)\n",
    "\n",
    "        #handling edge cases when there is no +ve pair\n",
    "        mask_pos_pairs = mask.sum(dim=1)\n",
    "        mask_pos_pairs = torch.where(mask_pos_pairs < 1e-6, 1, mask_pos_pairs)\n",
    "\n",
    "        loss = -(mask * log_prob).sum(dim=1) / mask_pos_pairs\n",
    "\n",
    "        return loss.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:59.528938Z",
     "iopub.status.busy": "2025-05-08T18:41:59.528938Z",
     "iopub.status.idle": "2025-05-08T18:41:59.533441Z",
     "shell.execute_reply": "2025-05-08T18:41:59.532937Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128), #expects input of shape (batch_size, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #flattening input tensor\n",
    "        #x = x.view(x.size(0), -1)  #reshaping -> (batch_size, channels * height * width)\n",
    "        projections = self.projection_head(x)\n",
    "        return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:41:59.535993Z",
     "iopub.status.busy": "2025-05-08T18:41:59.534489Z",
     "iopub.status.idle": "2025-05-08T18:42:07.501134Z",
     "shell.execute_reply": "2025-05-08T18:42:07.501134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Epoch [1/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.3331\n",
      "Epoch [1/2000], Avg Train Loss: 8.3331\n",
      "Epoch [1/2000], Avg Val Loss: 3.5523\n",
      "Validation loss improved from inf to 3.5523. Saving model...\n",
      "\n",
      "LOG: Epoch [2/2000] - Training\n",
      "    Batch [1/1], Train Loss: 8.1113\n",
      "Epoch [2/2000], Avg Train Loss: 8.1113\n",
      "Epoch [2/2000], Avg Val Loss: 3.5342\n",
      "Validation loss improved from 3.5523 to 3.5342. Saving model...\n",
      "\n",
      "LOG: Epoch [3/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.9573\n",
      "Epoch [3/2000], Avg Train Loss: 7.9573\n",
      "Epoch [3/2000], Avg Val Loss: 3.5173\n",
      "Validation loss improved from 3.5342 to 3.5173. Saving model...\n",
      "\n",
      "LOG: Epoch [4/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.9340\n",
      "Epoch [4/2000], Avg Train Loss: 7.9340\n",
      "Epoch [4/2000], Avg Val Loss: 3.5013\n",
      "Validation loss improved from 3.5173 to 3.5013. Saving model...\n",
      "\n",
      "LOG: Epoch [5/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.8974\n",
      "Epoch [5/2000], Avg Train Loss: 7.8974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/2000], Avg Val Loss: 3.4860\n",
      "Validation loss improved from 3.5013 to 3.4860. Saving model...\n",
      "\n",
      "LOG: Epoch [6/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.8138\n",
      "Epoch [6/2000], Avg Train Loss: 7.8138\n",
      "Epoch [6/2000], Avg Val Loss: 3.4713\n",
      "Validation loss improved from 3.4860 to 3.4713. Saving model...\n",
      "\n",
      "LOG: Epoch [7/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.7739\n",
      "Epoch [7/2000], Avg Train Loss: 7.7739\n",
      "Epoch [7/2000], Avg Val Loss: 3.4572\n",
      "Validation loss improved from 3.4713 to 3.4572. Saving model...\n",
      "\n",
      "LOG: Epoch [8/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.6817\n",
      "Epoch [8/2000], Avg Train Loss: 7.6817\n",
      "Epoch [8/2000], Avg Val Loss: 3.4438\n",
      "Validation loss improved from 3.4572 to 3.4438. Saving model...\n",
      "\n",
      "LOG: Epoch [9/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.7169\n",
      "Epoch [9/2000], Avg Train Loss: 7.7169\n",
      "Epoch [9/2000], Avg Val Loss: 3.4310\n",
      "Validation loss improved from 3.4438 to 3.4310. Saving model...\n",
      "\n",
      "LOG: Epoch [10/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.4428\n",
      "Epoch [10/2000], Avg Train Loss: 7.4428\n",
      "Epoch [10/2000], Avg Val Loss: 3.4188\n",
      "Validation loss improved from 3.4310 to 3.4188. Saving model...\n",
      "\n",
      "LOG: Epoch [11/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.3345\n",
      "Epoch [11/2000], Avg Train Loss: 7.3345\n",
      "Epoch [11/2000], Avg Val Loss: 3.4074\n",
      "Validation loss improved from 3.4188 to 3.4074. Saving model...\n",
      "\n",
      "LOG: Epoch [12/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.2199\n",
      "Epoch [12/2000], Avg Train Loss: 7.2199\n",
      "Epoch [12/2000], Avg Val Loss: 3.3963\n",
      "Validation loss improved from 3.4074 to 3.3963. Saving model...\n",
      "\n",
      "LOG: Epoch [13/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.2513\n",
      "Epoch [13/2000], Avg Train Loss: 7.2513\n",
      "Epoch [13/2000], Avg Val Loss: 3.3860\n",
      "Validation loss improved from 3.3963 to 3.3860. Saving model...\n",
      "\n",
      "LOG: Epoch [14/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.1315\n",
      "Epoch [14/2000], Avg Train Loss: 7.1315\n",
      "Epoch [14/2000], Avg Val Loss: 3.3761\n",
      "Validation loss improved from 3.3860 to 3.3761. Saving model...\n",
      "\n",
      "LOG: Epoch [15/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.2616\n",
      "Epoch [15/2000], Avg Train Loss: 7.2616\n",
      "Epoch [15/2000], Avg Val Loss: 3.3668\n",
      "Validation loss improved from 3.3761 to 3.3668. Saving model...\n",
      "\n",
      "LOG: Epoch [16/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.0914\n",
      "Epoch [16/2000], Avg Train Loss: 7.0914\n",
      "Epoch [16/2000], Avg Val Loss: 3.3579\n",
      "Validation loss improved from 3.3668 to 3.3579. Saving model...\n",
      "\n",
      "LOG: Epoch [17/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.0009\n",
      "Epoch [17/2000], Avg Train Loss: 7.0009\n",
      "Epoch [17/2000], Avg Val Loss: 3.3494\n",
      "Validation loss improved from 3.3579 to 3.3494. Saving model...\n",
      "\n",
      "LOG: Epoch [18/2000] - Training\n",
      "    Batch [1/1], Train Loss: 7.0359\n",
      "Epoch [18/2000], Avg Train Loss: 7.0359\n",
      "Epoch [18/2000], Avg Val Loss: 3.3415\n",
      "Validation loss improved from 3.3494 to 3.3415. Saving model...\n",
      "\n",
      "LOG: Epoch [19/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.9195\n",
      "Epoch [19/2000], Avg Train Loss: 6.9195\n",
      "Epoch [19/2000], Avg Val Loss: 3.3340\n",
      "Validation loss improved from 3.3415 to 3.3340. Saving model...\n",
      "\n",
      "LOG: Epoch [20/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.5991\n",
      "Epoch [20/2000], Avg Train Loss: 6.5991\n",
      "Epoch [20/2000], Avg Val Loss: 3.3270\n",
      "Validation loss improved from 3.3340 to 3.3270. Saving model...\n",
      "\n",
      "LOG: Epoch [21/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 6.4418\n",
      "Epoch [21/2000], Avg Train Loss: 6.4418\n",
      "Epoch [21/2000], Avg Val Loss: 3.3203\n",
      "Validation loss improved from 3.3270 to 3.3203. Saving model...\n",
      "\n",
      "LOG: Epoch [22/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.4778\n",
      "Epoch [22/2000], Avg Train Loss: 6.4778\n",
      "Epoch [22/2000], Avg Val Loss: 3.3140\n",
      "Validation loss improved from 3.3203 to 3.3140. Saving model...\n",
      "\n",
      "LOG: Epoch [23/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6057\n",
      "Epoch [23/2000], Avg Train Loss: 6.6057\n",
      "Epoch [23/2000], Avg Val Loss: 3.3081\n",
      "Validation loss improved from 3.3140 to 3.3081. Saving model...\n",
      "\n",
      "LOG: Epoch [24/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6239\n",
      "Epoch [24/2000], Avg Train Loss: 6.6239\n",
      "Epoch [24/2000], Avg Val Loss: 3.3025\n",
      "Validation loss improved from 3.3081 to 3.3025. Saving model...\n",
      "\n",
      "LOG: Epoch [25/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.6491\n",
      "Epoch [25/2000], Avg Train Loss: 6.6491\n",
      "Epoch [25/2000], Avg Val Loss: 3.2973\n",
      "Validation loss improved from 3.3025 to 3.2973. Saving model...\n",
      "\n",
      "LOG: Epoch [26/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.5540\n",
      "Epoch [26/2000], Avg Train Loss: 6.5540\n",
      "Epoch [26/2000], Avg Val Loss: 3.2923\n",
      "Validation loss improved from 3.2973 to 3.2923. Saving model...\n",
      "\n",
      "LOG: Epoch [27/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.4817\n",
      "Epoch [27/2000], Avg Train Loss: 6.4817\n",
      "Epoch [27/2000], Avg Val Loss: 3.2878\n",
      "Validation loss improved from 3.2923 to 3.2878. Saving model...\n",
      "\n",
      "LOG: Epoch [28/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.3807\n",
      "Epoch [28/2000], Avg Train Loss: 6.3807\n",
      "Epoch [28/2000], Avg Val Loss: 3.2835\n",
      "Validation loss improved from 3.2878 to 3.2835. Saving model...\n",
      "\n",
      "LOG: Epoch [29/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2593\n",
      "Epoch [29/2000], Avg Train Loss: 6.2593\n",
      "Epoch [29/2000], Avg Val Loss: 3.2796\n",
      "Validation loss improved from 3.2835 to 3.2796. Saving model...\n",
      "\n",
      "LOG: Epoch [30/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2980\n",
      "Epoch [30/2000], Avg Train Loss: 6.2980\n",
      "Epoch [30/2000], Avg Val Loss: 3.2760\n",
      "Validation loss improved from 3.2796 to 3.2760. Saving model...\n",
      "\n",
      "LOG: Epoch [31/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 6.1970\n",
      "Epoch [31/2000], Avg Train Loss: 6.1970\n",
      "Epoch [31/2000], Avg Val Loss: 3.2726\n",
      "Validation loss improved from 3.2760 to 3.2726. Saving model...\n",
      "\n",
      "LOG: Epoch [32/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2717\n",
      "Epoch [32/2000], Avg Train Loss: 6.2717\n",
      "Epoch [32/2000], Avg Val Loss: 3.2696\n",
      "Validation loss improved from 3.2726 to 3.2696. Saving model...\n",
      "\n",
      "LOG: Epoch [33/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2134\n",
      "Epoch [33/2000], Avg Train Loss: 6.2134\n",
      "Epoch [33/2000], Avg Val Loss: 3.2667\n",
      "Validation loss improved from 3.2696 to 3.2667. Saving model...\n",
      "\n",
      "LOG: Epoch [34/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0388\n",
      "Epoch [34/2000], Avg Train Loss: 6.0388\n",
      "Epoch [34/2000], Avg Val Loss: 3.2641\n",
      "Validation loss improved from 3.2667 to 3.2641. Saving model...\n",
      "\n",
      "LOG: Epoch [35/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.2134\n",
      "Epoch [35/2000], Avg Train Loss: 6.2134\n",
      "Epoch [35/2000], Avg Val Loss: 3.2616\n",
      "Validation loss improved from 3.2641 to 3.2616. Saving model...\n",
      "\n",
      "LOG: Epoch [36/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9067\n",
      "Epoch [36/2000], Avg Train Loss: 5.9067\n",
      "Epoch [36/2000], Avg Val Loss: 3.2593\n",
      "Validation loss improved from 3.2616 to 3.2593. Saving model...\n",
      "\n",
      "LOG: Epoch [37/2000] - Training\n",
      "    Batch [1/1], Train Loss: 6.0000\n",
      "Epoch [37/2000], Avg Train Loss: 6.0000\n",
      "Epoch [37/2000], Avg Val Loss: 3.2572\n",
      "Validation loss improved from 3.2593 to 3.2572. Saving model...\n",
      "\n",
      "LOG: Epoch [38/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9028\n",
      "Epoch [38/2000], Avg Train Loss: 5.9028\n",
      "Epoch [38/2000], Avg Val Loss: 3.2553\n",
      "Validation loss improved from 3.2572 to 3.2553. Saving model...\n",
      "\n",
      "LOG: Epoch [39/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9040\n",
      "Epoch [39/2000], Avg Train Loss: 5.9040\n",
      "Epoch [39/2000], Avg Val Loss: 3.2535\n",
      "Validation loss improved from 3.2553 to 3.2535. Saving model...\n",
      "\n",
      "LOG: Epoch [40/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8370\n",
      "Epoch [40/2000], Avg Train Loss: 5.8370\n",
      "Epoch [40/2000], Avg Val Loss: 3.2518\n",
      "Validation loss improved from 3.2535 to 3.2518. Saving model...\n",
      "\n",
      "LOG: Epoch [41/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.9134\n",
      "Epoch [41/2000], Avg Train Loss: 5.9134\n",
      "Epoch [41/2000], Avg Val Loss: 3.2503\n",
      "Validation loss improved from 3.2518 to 3.2503. Saving model...\n",
      "\n",
      "LOG: Epoch [42/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.7208\n",
      "Epoch [42/2000], Avg Train Loss: 5.7208\n",
      "Epoch [42/2000], Avg Val Loss: 3.2489\n",
      "Validation loss improved from 3.2503 to 3.2489. Saving model...\n",
      "\n",
      "LOG: Epoch [43/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6105\n",
      "Epoch [43/2000], Avg Train Loss: 5.6105\n",
      "Epoch [43/2000], Avg Val Loss: 3.2476\n",
      "Validation loss improved from 3.2489 to 3.2476. Saving model...\n",
      "\n",
      "LOG: Epoch [44/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.8635\n",
      "Epoch [44/2000], Avg Train Loss: 5.8635\n",
      "Epoch [44/2000], Avg Val Loss: 3.2465\n",
      "Validation loss improved from 3.2476 to 3.2465. Saving model...\n",
      "\n",
      "LOG: Epoch [45/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6943\n",
      "Epoch [45/2000], Avg Train Loss: 5.6943\n",
      "Epoch [45/2000], Avg Val Loss: 3.2455\n",
      "Validation loss improved from 3.2465 to 3.2455. Saving model...\n",
      "\n",
      "LOG: Epoch [46/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.6126\n",
      "Epoch [46/2000], Avg Train Loss: 5.6126\n",
      "Epoch [46/2000], Avg Val Loss: 3.2445\n",
      "Validation loss improved from 3.2455 to 3.2445. Saving model...\n",
      "\n",
      "LOG: Epoch [47/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5819\n",
      "Epoch [47/2000], Avg Train Loss: 5.5819\n",
      "Epoch [47/2000], Avg Val Loss: 3.2435\n",
      "Validation loss improved from 3.2445 to 3.2435. Saving model...\n",
      "\n",
      "LOG: Epoch [48/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5262\n",
      "Epoch [48/2000], Avg Train Loss: 5.5262\n",
      "Epoch [48/2000], Avg Val Loss: 3.2425\n",
      "Validation loss improved from 3.2435 to 3.2425. Saving model...\n",
      "\n",
      "LOG: Epoch [49/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5166\n",
      "Epoch [49/2000], Avg Train Loss: 5.5166\n",
      "Epoch [49/2000], Avg Val Loss: 3.2416\n",
      "Validation loss improved from 3.2425 to 3.2416. Saving model...\n",
      "\n",
      "LOG: Epoch [50/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4833\n",
      "Epoch [50/2000], Avg Train Loss: 5.4833\n",
      "Epoch [50/2000], Avg Val Loss: 3.2408\n",
      "Validation loss improved from 3.2416 to 3.2408. Saving model...\n",
      "\n",
      "LOG: Epoch [51/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 5.3632\n",
      "Epoch [51/2000], Avg Train Loss: 5.3632\n",
      "Epoch [51/2000], Avg Val Loss: 3.2401\n",
      "Validation loss improved from 3.2408 to 3.2401. Saving model...\n",
      "\n",
      "LOG: Epoch [52/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.5144\n",
      "Epoch [52/2000], Avg Train Loss: 5.5144\n",
      "Epoch [52/2000], Avg Val Loss: 3.2394\n",
      "Validation loss improved from 3.2401 to 3.2394. Saving model...\n",
      "\n",
      "LOG: Epoch [53/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4032\n",
      "Epoch [53/2000], Avg Train Loss: 5.4032\n",
      "Epoch [53/2000], Avg Val Loss: 3.2388\n",
      "Validation loss improved from 3.2394 to 3.2388. Saving model...\n",
      "\n",
      "LOG: Epoch [54/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2762\n",
      "Epoch [54/2000], Avg Train Loss: 5.2762\n",
      "Epoch [54/2000], Avg Val Loss: 3.2383\n",
      "Validation loss improved from 3.2388 to 3.2383. Saving model...\n",
      "\n",
      "LOG: Epoch [55/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.4352\n",
      "Epoch [55/2000], Avg Train Loss: 5.4352\n",
      "Epoch [55/2000], Avg Val Loss: 3.2378\n",
      "Validation loss improved from 3.2383 to 3.2378. Saving model...\n",
      "\n",
      "LOG: Epoch [56/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3668\n",
      "Epoch [56/2000], Avg Train Loss: 5.3668\n",
      "Epoch [56/2000], Avg Val Loss: 3.2374\n",
      "Validation loss improved from 3.2378 to 3.2374. Saving model...\n",
      "\n",
      "LOG: Epoch [57/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1400\n",
      "Epoch [57/2000], Avg Train Loss: 5.1400\n",
      "Epoch [57/2000], Avg Val Loss: 3.2370\n",
      "Validation loss improved from 3.2374 to 3.2370. Saving model...\n",
      "\n",
      "LOG: Epoch [58/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.3002\n",
      "Epoch [58/2000], Avg Train Loss: 5.3002\n",
      "Epoch [58/2000], Avg Val Loss: 3.2367\n",
      "Validation loss improved from 3.2370 to 3.2367. Saving model...\n",
      "\n",
      "LOG: Epoch [59/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1120\n",
      "Epoch [59/2000], Avg Train Loss: 5.1120\n",
      "Epoch [59/2000], Avg Val Loss: 3.2364\n",
      "Validation loss improved from 3.2367 to 3.2364. Saving model...\n",
      "\n",
      "LOG: Epoch [60/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2540\n",
      "Epoch [60/2000], Avg Train Loss: 5.2540\n",
      "Epoch [60/2000], Avg Val Loss: 3.2360\n",
      "Validation loss improved from 3.2364 to 3.2360. Saving model...\n",
      "\n",
      "LOG: Epoch [61/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.2250\n",
      "Epoch [61/2000], Avg Train Loss: 5.2250\n",
      "Epoch [61/2000], Avg Val Loss: 3.2357\n",
      "Validation loss improved from 3.2360 to 3.2357. Saving model...\n",
      "\n",
      "LOG: Epoch [62/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1801\n",
      "Epoch [62/2000], Avg Train Loss: 5.1801\n",
      "Epoch [62/2000], Avg Val Loss: 3.2354\n",
      "Validation loss improved from 3.2357 to 3.2354. Saving model...\n",
      "\n",
      "LOG: Epoch [63/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1181\n",
      "Epoch [63/2000], Avg Train Loss: 5.1181\n",
      "Epoch [63/2000], Avg Val Loss: 3.2350\n",
      "Validation loss improved from 3.2354 to 3.2350. Saving model...\n",
      "\n",
      "LOG: Epoch [64/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1539\n",
      "Epoch [64/2000], Avg Train Loss: 5.1539\n",
      "Epoch [64/2000], Avg Val Loss: 3.2347\n",
      "Validation loss improved from 3.2350 to 3.2347. Saving model...\n",
      "\n",
      "LOG: Epoch [65/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0633\n",
      "Epoch [65/2000], Avg Train Loss: 5.0633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/2000], Avg Val Loss: 3.2344\n",
      "Validation loss improved from 3.2347 to 3.2344. Saving model...\n",
      "\n",
      "LOG: Epoch [66/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1202\n",
      "Epoch [66/2000], Avg Train Loss: 5.1202\n",
      "Epoch [66/2000], Avg Val Loss: 3.2341\n",
      "Validation loss improved from 3.2344 to 3.2341. Saving model...\n",
      "\n",
      "LOG: Epoch [67/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.1038\n",
      "Epoch [67/2000], Avg Train Loss: 5.1038\n",
      "Epoch [67/2000], Avg Val Loss: 3.2339\n",
      "Validation loss improved from 3.2341 to 3.2339. Saving model...\n",
      "\n",
      "LOG: Epoch [68/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9846\n",
      "Epoch [68/2000], Avg Train Loss: 4.9846\n",
      "Epoch [68/2000], Avg Val Loss: 3.2336\n",
      "Validation loss improved from 3.2339 to 3.2336. Saving model...\n",
      "\n",
      "LOG: Epoch [69/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0245\n",
      "Epoch [69/2000], Avg Train Loss: 5.0245\n",
      "Epoch [69/2000], Avg Val Loss: 3.2334\n",
      "Validation loss improved from 3.2336 to 3.2334. Saving model...\n",
      "\n",
      "LOG: Epoch [70/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0900\n",
      "Epoch [70/2000], Avg Train Loss: 5.0900\n",
      "Epoch [70/2000], Avg Val Loss: 3.2332\n",
      "Validation loss improved from 3.2334 to 3.2332. Saving model...\n",
      "\n",
      "LOG: Epoch [71/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9889\n",
      "Epoch [71/2000], Avg Train Loss: 4.9889\n",
      "Epoch [71/2000], Avg Val Loss: 3.2330\n",
      "Validation loss improved from 3.2332 to 3.2330. Saving model...\n",
      "\n",
      "LOG: Epoch [72/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.9720\n",
      "Epoch [72/2000], Avg Train Loss: 4.9720\n",
      "Epoch [72/2000], Avg Val Loss: 3.2328\n",
      "Validation loss improved from 3.2330 to 3.2328. Saving model...\n",
      "\n",
      "LOG: Epoch [73/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8622\n",
      "Epoch [73/2000], Avg Train Loss: 4.8622\n",
      "Epoch [73/2000], Avg Val Loss: 3.2327\n",
      "Validation loss improved from 3.2328 to 3.2327. Saving model...\n",
      "\n",
      "LOG: Epoch [74/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9396\n",
      "Epoch [74/2000], Avg Train Loss: 4.9396\n",
      "Epoch [74/2000], Avg Val Loss: 3.2325\n",
      "Validation loss improved from 3.2327 to 3.2325. Saving model...\n",
      "\n",
      "LOG: Epoch [75/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9552\n",
      "Epoch [75/2000], Avg Train Loss: 4.9552\n",
      "Epoch [75/2000], Avg Val Loss: 3.2323\n",
      "Validation loss improved from 3.2325 to 3.2323. Saving model...\n",
      "\n",
      "LOG: Epoch [76/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7876\n",
      "Epoch [76/2000], Avg Train Loss: 4.7876\n",
      "Epoch [76/2000], Avg Val Loss: 3.2321\n",
      "Validation loss improved from 3.2323 to 3.2321. Saving model...\n",
      "\n",
      "LOG: Epoch [77/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8549\n",
      "Epoch [77/2000], Avg Train Loss: 4.8549\n",
      "Epoch [77/2000], Avg Val Loss: 3.2319\n",
      "Validation loss improved from 3.2321 to 3.2319. Saving model...\n",
      "\n",
      "LOG: Epoch [78/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9328\n",
      "Epoch [78/2000], Avg Train Loss: 4.9328\n",
      "Epoch [78/2000], Avg Val Loss: 3.2317\n",
      "Validation loss improved from 3.2319 to 3.2317. Saving model...\n",
      "\n",
      "LOG: Epoch [79/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8529\n",
      "Epoch [79/2000], Avg Train Loss: 4.8529\n",
      "Epoch [79/2000], Avg Val Loss: 3.2315\n",
      "Validation loss improved from 3.2317 to 3.2315. Saving model...\n",
      "\n",
      "LOG: Epoch [80/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9168\n",
      "Epoch [80/2000], Avg Train Loss: 4.9168\n",
      "Epoch [80/2000], Avg Val Loss: 3.2313\n",
      "Validation loss improved from 3.2315 to 3.2313. Saving model...\n",
      "\n",
      "LOG: Epoch [81/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8691\n",
      "Epoch [81/2000], Avg Train Loss: 4.8691\n",
      "Epoch [81/2000], Avg Val Loss: 3.2311\n",
      "Validation loss improved from 3.2313 to 3.2311. Saving model...\n",
      "\n",
      "LOG: Epoch [82/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.9087\n",
      "Epoch [82/2000], Avg Train Loss: 4.9087\n",
      "Epoch [82/2000], Avg Val Loss: 3.2309\n",
      "Validation loss improved from 3.2311 to 3.2309. Saving model...\n",
      "\n",
      "LOG: Epoch [83/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8582\n",
      "Epoch [83/2000], Avg Train Loss: 4.8582\n",
      "Epoch [83/2000], Avg Val Loss: 3.2307\n",
      "Validation loss improved from 3.2309 to 3.2307. Saving model...\n",
      "\n",
      "LOG: Epoch [84/2000] - Training\n",
      "    Batch [1/1], Train Loss: 5.0256\n",
      "Epoch [84/2000], Avg Train Loss: 5.0256\n",
      "Epoch [84/2000], Avg Val Loss: 3.2305\n",
      "Validation loss improved from 3.2307 to 3.2305. Saving model...\n",
      "\n",
      "LOG: Epoch [85/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7919\n",
      "Epoch [85/2000], Avg Train Loss: 4.7919\n",
      "Epoch [85/2000], Avg Val Loss: 3.2304\n",
      "Validation loss improved from 3.2305 to 3.2304. Saving model...\n",
      "\n",
      "LOG: Epoch [86/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7909\n",
      "Epoch [86/2000], Avg Train Loss: 4.7909\n",
      "Epoch [86/2000], Avg Val Loss: 3.2302\n",
      "Validation loss improved from 3.2304 to 3.2302. Saving model...\n",
      "\n",
      "LOG: Epoch [87/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8258\n",
      "Epoch [87/2000], Avg Train Loss: 4.8258\n",
      "Epoch [87/2000], Avg Val Loss: 3.2299\n",
      "Validation loss improved from 3.2302 to 3.2299. Saving model...\n",
      "\n",
      "LOG: Epoch [88/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7599\n",
      "Epoch [88/2000], Avg Train Loss: 4.7599\n",
      "Epoch [88/2000], Avg Val Loss: 3.2298\n",
      "Validation loss improved from 3.2299 to 3.2298. Saving model...\n",
      "\n",
      "LOG: Epoch [89/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7471\n",
      "Epoch [89/2000], Avg Train Loss: 4.7471\n",
      "Epoch [89/2000], Avg Val Loss: 3.2295\n",
      "Validation loss improved from 3.2298 to 3.2295. Saving model...\n",
      "\n",
      "LOG: Epoch [90/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.8380\n",
      "Epoch [90/2000], Avg Train Loss: 4.8380\n",
      "Epoch [90/2000], Avg Val Loss: 3.2293\n",
      "Validation loss improved from 3.2295 to 3.2293. Saving model...\n",
      "\n",
      "LOG: Epoch [91/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.8105\n",
      "Epoch [91/2000], Avg Train Loss: 4.8105\n",
      "Epoch [91/2000], Avg Val Loss: 3.2291\n",
      "Validation loss improved from 3.2293 to 3.2291. Saving model...\n",
      "\n",
      "LOG: Epoch [92/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7172\n",
      "Epoch [92/2000], Avg Train Loss: 4.7172\n",
      "Epoch [92/2000], Avg Val Loss: 3.2288\n",
      "Validation loss improved from 3.2291 to 3.2288. Saving model...\n",
      "\n",
      "LOG: Epoch [93/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7199\n",
      "Epoch [93/2000], Avg Train Loss: 4.7199\n",
      "Epoch [93/2000], Avg Val Loss: 3.2286\n",
      "Validation loss improved from 3.2288 to 3.2286. Saving model...\n",
      "\n",
      "LOG: Epoch [94/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6566\n",
      "Epoch [94/2000], Avg Train Loss: 4.6566\n",
      "Epoch [94/2000], Avg Val Loss: 3.2282\n",
      "Validation loss improved from 3.2286 to 3.2282. Saving model...\n",
      "\n",
      "LOG: Epoch [95/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6710\n",
      "Epoch [95/2000], Avg Train Loss: 4.6710\n",
      "Epoch [95/2000], Avg Val Loss: 3.2279\n",
      "Validation loss improved from 3.2282 to 3.2279. Saving model...\n",
      "\n",
      "LOG: Epoch [96/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6530\n",
      "Epoch [96/2000], Avg Train Loss: 4.6530\n",
      "Epoch [96/2000], Avg Val Loss: 3.2276\n",
      "Validation loss improved from 3.2279 to 3.2276. Saving model...\n",
      "\n",
      "LOG: Epoch [97/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6797\n",
      "Epoch [97/2000], Avg Train Loss: 4.6797\n",
      "Epoch [97/2000], Avg Val Loss: 3.2272\n",
      "Validation loss improved from 3.2276 to 3.2272. Saving model...\n",
      "\n",
      "LOG: Epoch [98/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6004\n",
      "Epoch [98/2000], Avg Train Loss: 4.6004\n",
      "Epoch [98/2000], Avg Val Loss: 3.2267\n",
      "Validation loss improved from 3.2272 to 3.2267. Saving model...\n",
      "\n",
      "LOG: Epoch [99/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6966\n",
      "Epoch [99/2000], Avg Train Loss: 4.6966\n",
      "Epoch [99/2000], Avg Val Loss: 3.2263\n",
      "Validation loss improved from 3.2267 to 3.2263. Saving model...\n",
      "\n",
      "LOG: Epoch [100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5564\n",
      "Epoch [100/2000], Avg Train Loss: 4.5564\n",
      "Epoch [100/2000], Avg Val Loss: 3.2258\n",
      "Validation loss improved from 3.2263 to 3.2258. Saving model...\n",
      "\n",
      "LOG: Epoch [101/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6030\n",
      "Epoch [101/2000], Avg Train Loss: 4.6030\n",
      "Epoch [101/2000], Avg Val Loss: 3.2253\n",
      "Validation loss improved from 3.2258 to 3.2253. Saving model...\n",
      "\n",
      "LOG: Epoch [102/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6588\n",
      "Epoch [102/2000], Avg Train Loss: 4.6588\n",
      "Epoch [102/2000], Avg Val Loss: 3.2248\n",
      "Validation loss improved from 3.2253 to 3.2248. Saving model...\n",
      "\n",
      "LOG: Epoch [103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7038\n",
      "Epoch [103/2000], Avg Train Loss: 4.7038\n",
      "Epoch [103/2000], Avg Val Loss: 3.2242\n",
      "Validation loss improved from 3.2248 to 3.2242. Saving model...\n",
      "\n",
      "LOG: Epoch [104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4957\n",
      "Epoch [104/2000], Avg Train Loss: 4.4957\n",
      "Epoch [104/2000], Avg Val Loss: 3.2237\n",
      "Validation loss improved from 3.2242 to 3.2237. Saving model...\n",
      "\n",
      "LOG: Epoch [105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.7310\n",
      "Epoch [105/2000], Avg Train Loss: 4.7310\n",
      "Epoch [105/2000], Avg Val Loss: 3.2233\n",
      "Validation loss improved from 3.2237 to 3.2233. Saving model...\n",
      "\n",
      "LOG: Epoch [106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6655\n",
      "Epoch [106/2000], Avg Train Loss: 4.6655\n",
      "Epoch [106/2000], Avg Val Loss: 3.2228\n",
      "Validation loss improved from 3.2233 to 3.2228. Saving model...\n",
      "\n",
      "LOG: Epoch [107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5790\n",
      "Epoch [107/2000], Avg Train Loss: 4.5790\n",
      "Epoch [107/2000], Avg Val Loss: 3.2223\n",
      "Validation loss improved from 3.2228 to 3.2223. Saving model...\n",
      "\n",
      "LOG: Epoch [108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5834\n",
      "Epoch [108/2000], Avg Train Loss: 4.5834\n",
      "Epoch [108/2000], Avg Val Loss: 3.2218\n",
      "Validation loss improved from 3.2223 to 3.2218. Saving model...\n",
      "\n",
      "LOG: Epoch [109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5614\n",
      "Epoch [109/2000], Avg Train Loss: 4.5614\n",
      "Epoch [109/2000], Avg Val Loss: 3.2213\n",
      "Validation loss improved from 3.2218 to 3.2213. Saving model...\n",
      "\n",
      "LOG: Epoch [110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5703\n",
      "Epoch [110/2000], Avg Train Loss: 4.5703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [110/2000], Avg Val Loss: 3.2208\n",
      "Validation loss improved from 3.2213 to 3.2208. Saving model...\n",
      "\n",
      "LOG: Epoch [111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5282\n",
      "Epoch [111/2000], Avg Train Loss: 4.5282\n",
      "Epoch [111/2000], Avg Val Loss: 3.2202\n",
      "Validation loss improved from 3.2208 to 3.2202. Saving model...\n",
      "\n",
      "LOG: Epoch [112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4728\n",
      "Epoch [112/2000], Avg Train Loss: 4.4728\n",
      "Epoch [112/2000], Avg Val Loss: 3.2197\n",
      "Validation loss improved from 3.2202 to 3.2197. Saving model...\n",
      "\n",
      "LOG: Epoch [113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4920\n",
      "Epoch [113/2000], Avg Train Loss: 4.4920\n",
      "Epoch [113/2000], Avg Val Loss: 3.2191\n",
      "Validation loss improved from 3.2197 to 3.2191. Saving model...\n",
      "\n",
      "LOG: Epoch [114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5444\n",
      "Epoch [114/2000], Avg Train Loss: 4.5444\n",
      "Epoch [114/2000], Avg Val Loss: 3.2185\n",
      "Validation loss improved from 3.2191 to 3.2185. Saving model...\n",
      "\n",
      "LOG: Epoch [115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.6363\n",
      "Epoch [115/2000], Avg Train Loss: 4.6363\n",
      "Epoch [115/2000], Avg Val Loss: 3.2179\n",
      "Validation loss improved from 3.2185 to 3.2179. Saving model...\n",
      "\n",
      "LOG: Epoch [116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5934\n",
      "Epoch [116/2000], Avg Train Loss: 4.5934\n",
      "Epoch [116/2000], Avg Val Loss: 3.2173\n",
      "Validation loss improved from 3.2179 to 3.2173. Saving model...\n",
      "\n",
      "LOG: Epoch [117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5365\n",
      "Epoch [117/2000], Avg Train Loss: 4.5365\n",
      "Epoch [117/2000], Avg Val Loss: 3.2168\n",
      "Validation loss improved from 3.2173 to 3.2168. Saving model...\n",
      "\n",
      "LOG: Epoch [118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5498\n",
      "Epoch [118/2000], Avg Train Loss: 4.5498\n",
      "Epoch [118/2000], Avg Val Loss: 3.2161\n",
      "Validation loss improved from 3.2168 to 3.2161. Saving model...\n",
      "\n",
      "LOG: Epoch [119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5462\n",
      "Epoch [119/2000], Avg Train Loss: 4.5462\n",
      "Epoch [119/2000], Avg Val Loss: 3.2156\n",
      "Validation loss improved from 3.2161 to 3.2156. Saving model...\n",
      "\n",
      "LOG: Epoch [120/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5135\n",
      "Epoch [120/2000], Avg Train Loss: 4.5135\n",
      "Epoch [120/2000], Avg Val Loss: 3.2149\n",
      "Validation loss improved from 3.2156 to 3.2149. Saving model...\n",
      "\n",
      "LOG: Epoch [121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5714\n",
      "Epoch [121/2000], Avg Train Loss: 4.5714\n",
      "Epoch [121/2000], Avg Val Loss: 3.2142\n",
      "Validation loss improved from 3.2149 to 3.2142. Saving model...\n",
      "\n",
      "LOG: Epoch [122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5807\n",
      "Epoch [122/2000], Avg Train Loss: 4.5807\n",
      "Epoch [122/2000], Avg Val Loss: 3.2136\n",
      "Validation loss improved from 3.2142 to 3.2136. Saving model...\n",
      "\n",
      "LOG: Epoch [123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4346\n",
      "Epoch [123/2000], Avg Train Loss: 4.4346\n",
      "Epoch [123/2000], Avg Val Loss: 3.2129\n",
      "Validation loss improved from 3.2136 to 3.2129. Saving model...\n",
      "\n",
      "LOG: Epoch [124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4669\n",
      "Epoch [124/2000], Avg Train Loss: 4.4669\n",
      "Epoch [124/2000], Avg Val Loss: 3.2122\n",
      "Validation loss improved from 3.2129 to 3.2122. Saving model...\n",
      "\n",
      "LOG: Epoch [125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4460\n",
      "Epoch [125/2000], Avg Train Loss: 4.4460\n",
      "Epoch [125/2000], Avg Val Loss: 3.2115\n",
      "Validation loss improved from 3.2122 to 3.2115. Saving model...\n",
      "\n",
      "LOG: Epoch [126/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4848\n",
      "Epoch [126/2000], Avg Train Loss: 4.4848\n",
      "Epoch [126/2000], Avg Val Loss: 3.2108\n",
      "Validation loss improved from 3.2115 to 3.2108. Saving model...\n",
      "\n",
      "LOG: Epoch [127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4613\n",
      "Epoch [127/2000], Avg Train Loss: 4.4613\n",
      "Epoch [127/2000], Avg Val Loss: 3.2102\n",
      "Validation loss improved from 3.2108 to 3.2102. Saving model...\n",
      "\n",
      "LOG: Epoch [128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4131\n",
      "Epoch [128/2000], Avg Train Loss: 4.4131\n",
      "Epoch [128/2000], Avg Val Loss: 3.2095\n",
      "Validation loss improved from 3.2102 to 3.2095. Saving model...\n",
      "\n",
      "LOG: Epoch [129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.5003\n",
      "Epoch [129/2000], Avg Train Loss: 4.5003\n",
      "Epoch [129/2000], Avg Val Loss: 3.2088\n",
      "Validation loss improved from 3.2095 to 3.2088. Saving model...\n",
      "\n",
      "LOG: Epoch [130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4626\n",
      "Epoch [130/2000], Avg Train Loss: 4.4626\n",
      "Epoch [130/2000], Avg Val Loss: 3.2081\n",
      "Validation loss improved from 3.2088 to 3.2081. Saving model...\n",
      "\n",
      "LOG: Epoch [131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4086\n",
      "Epoch [131/2000], Avg Train Loss: 4.4086\n",
      "Epoch [131/2000], Avg Val Loss: 3.2074\n",
      "Validation loss improved from 3.2081 to 3.2074. Saving model...\n",
      "\n",
      "LOG: Epoch [132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4101\n",
      "Epoch [132/2000], Avg Train Loss: 4.4101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [132/2000], Avg Val Loss: 3.2067\n",
      "Validation loss improved from 3.2074 to 3.2067. Saving model...\n",
      "\n",
      "LOG: Epoch [133/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4140\n",
      "Epoch [133/2000], Avg Train Loss: 4.4140\n",
      "Epoch [133/2000], Avg Val Loss: 3.2059\n",
      "Validation loss improved from 3.2067 to 3.2059. Saving model...\n",
      "\n",
      "LOG: Epoch [134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4461\n",
      "Epoch [134/2000], Avg Train Loss: 4.4461\n",
      "Epoch [134/2000], Avg Val Loss: 3.2051\n",
      "Validation loss improved from 3.2059 to 3.2051. Saving model...\n",
      "\n",
      "LOG: Epoch [135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4546\n",
      "Epoch [135/2000], Avg Train Loss: 4.4546\n",
      "Epoch [135/2000], Avg Val Loss: 3.2043\n",
      "Validation loss improved from 3.2051 to 3.2043. Saving model...\n",
      "\n",
      "LOG: Epoch [136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3965\n",
      "Epoch [136/2000], Avg Train Loss: 4.3965\n",
      "Epoch [136/2000], Avg Val Loss: 3.2035\n",
      "Validation loss improved from 3.2043 to 3.2035. Saving model...\n",
      "\n",
      "LOG: Epoch [137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3079\n",
      "Epoch [137/2000], Avg Train Loss: 4.3079\n",
      "Epoch [137/2000], Avg Val Loss: 3.2027\n",
      "Validation loss improved from 3.2035 to 3.2027. Saving model...\n",
      "\n",
      "LOG: Epoch [138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4094\n",
      "Epoch [138/2000], Avg Train Loss: 4.4094\n",
      "Epoch [138/2000], Avg Val Loss: 3.2019\n",
      "Validation loss improved from 3.2027 to 3.2019. Saving model...\n",
      "\n",
      "LOG: Epoch [139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3814\n",
      "Epoch [139/2000], Avg Train Loss: 4.3814\n",
      "Epoch [139/2000], Avg Val Loss: 3.2011\n",
      "Validation loss improved from 3.2019 to 3.2011. Saving model...\n",
      "\n",
      "LOG: Epoch [140/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3993\n",
      "Epoch [140/2000], Avg Train Loss: 4.3993\n",
      "Epoch [140/2000], Avg Val Loss: 3.2004\n",
      "Validation loss improved from 3.2011 to 3.2004. Saving model...\n",
      "\n",
      "LOG: Epoch [141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3810\n",
      "Epoch [141/2000], Avg Train Loss: 4.3810\n",
      "Epoch [141/2000], Avg Val Loss: 3.1996\n",
      "Validation loss improved from 3.2004 to 3.1996. Saving model...\n",
      "\n",
      "LOG: Epoch [142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4113\n",
      "Epoch [142/2000], Avg Train Loss: 4.4113\n",
      "Epoch [142/2000], Avg Val Loss: 3.1989\n",
      "Validation loss improved from 3.1996 to 3.1989. Saving model...\n",
      "\n",
      "LOG: Epoch [143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3849\n",
      "Epoch [143/2000], Avg Train Loss: 4.3849\n",
      "Epoch [143/2000], Avg Val Loss: 3.1982\n",
      "Validation loss improved from 3.1989 to 3.1982. Saving model...\n",
      "\n",
      "LOG: Epoch [144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4349\n",
      "Epoch [144/2000], Avg Train Loss: 4.4349\n",
      "Epoch [144/2000], Avg Val Loss: 3.1974\n",
      "Validation loss improved from 3.1982 to 3.1974. Saving model...\n",
      "\n",
      "LOG: Epoch [145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3594\n",
      "Epoch [145/2000], Avg Train Loss: 4.3594\n",
      "Epoch [145/2000], Avg Val Loss: 3.1967\n",
      "Validation loss improved from 3.1974 to 3.1967. Saving model...\n",
      "\n",
      "LOG: Epoch [146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3868\n",
      "Epoch [146/2000], Avg Train Loss: 4.3868\n",
      "Epoch [146/2000], Avg Val Loss: 3.1959\n",
      "Validation loss improved from 3.1967 to 3.1959. Saving model...\n",
      "\n",
      "LOG: Epoch [147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3862\n",
      "Epoch [147/2000], Avg Train Loss: 4.3862\n",
      "Epoch [147/2000], Avg Val Loss: 3.1952\n",
      "Validation loss improved from 3.1959 to 3.1952. Saving model...\n",
      "\n",
      "LOG: Epoch [148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4278\n",
      "Epoch [148/2000], Avg Train Loss: 4.4278\n",
      "Epoch [148/2000], Avg Val Loss: 3.1945\n",
      "Validation loss improved from 3.1952 to 3.1945. Saving model...\n",
      "\n",
      "LOG: Epoch [149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3666\n",
      "Epoch [149/2000], Avg Train Loss: 4.3666\n",
      "Epoch [149/2000], Avg Val Loss: 3.1937\n",
      "Validation loss improved from 3.1945 to 3.1937. Saving model...\n",
      "\n",
      "LOG: Epoch [150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4123\n",
      "Epoch [150/2000], Avg Train Loss: 4.4123\n",
      "Epoch [150/2000], Avg Val Loss: 3.1930\n",
      "Validation loss improved from 3.1937 to 3.1930. Saving model...\n",
      "\n",
      "LOG: Epoch [151/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.3589\n",
      "Epoch [151/2000], Avg Train Loss: 4.3589\n",
      "Epoch [151/2000], Avg Val Loss: 3.1922\n",
      "Validation loss improved from 3.1930 to 3.1922. Saving model...\n",
      "\n",
      "LOG: Epoch [152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.4321\n",
      "Epoch [152/2000], Avg Train Loss: 4.4321\n",
      "Epoch [152/2000], Avg Val Loss: 3.1914\n",
      "Validation loss improved from 3.1922 to 3.1914. Saving model...\n",
      "\n",
      "LOG: Epoch [153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3521\n",
      "Epoch [153/2000], Avg Train Loss: 4.3521\n",
      "Epoch [153/2000], Avg Val Loss: 3.1907\n",
      "Validation loss improved from 3.1914 to 3.1907. Saving model...\n",
      "\n",
      "LOG: Epoch [154/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3281\n",
      "Epoch [154/2000], Avg Train Loss: 4.3281\n",
      "Epoch [154/2000], Avg Val Loss: 3.1899\n",
      "Validation loss improved from 3.1907 to 3.1899. Saving model...\n",
      "\n",
      "LOG: Epoch [155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3719\n",
      "Epoch [155/2000], Avg Train Loss: 4.3719\n",
      "Epoch [155/2000], Avg Val Loss: 3.1891\n",
      "Validation loss improved from 3.1899 to 3.1891. Saving model...\n",
      "\n",
      "LOG: Epoch [156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3752\n",
      "Epoch [156/2000], Avg Train Loss: 4.3752\n",
      "Epoch [156/2000], Avg Val Loss: 3.1882\n",
      "Validation loss improved from 3.1891 to 3.1882. Saving model...\n",
      "\n",
      "LOG: Epoch [157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2980\n",
      "Epoch [157/2000], Avg Train Loss: 4.2980\n",
      "Epoch [157/2000], Avg Val Loss: 3.1874\n",
      "Validation loss improved from 3.1882 to 3.1874. Saving model...\n",
      "\n",
      "LOG: Epoch [158/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2597\n",
      "Epoch [158/2000], Avg Train Loss: 4.2597\n",
      "Epoch [158/2000], Avg Val Loss: 3.1864\n",
      "Validation loss improved from 3.1874 to 3.1864. Saving model...\n",
      "\n",
      "LOG: Epoch [159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2669\n",
      "Epoch [159/2000], Avg Train Loss: 4.2669\n",
      "Epoch [159/2000], Avg Val Loss: 3.1855\n",
      "Validation loss improved from 3.1864 to 3.1855. Saving model...\n",
      "\n",
      "LOG: Epoch [160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3179\n",
      "Epoch [160/2000], Avg Train Loss: 4.3179\n",
      "Epoch [160/2000], Avg Val Loss: 3.1845\n",
      "Validation loss improved from 3.1855 to 3.1845. Saving model...\n",
      "\n",
      "LOG: Epoch [161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3680\n",
      "Epoch [161/2000], Avg Train Loss: 4.3680\n",
      "Epoch [161/2000], Avg Val Loss: 3.1836\n",
      "Validation loss improved from 3.1845 to 3.1836. Saving model...\n",
      "\n",
      "LOG: Epoch [162/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3218\n",
      "Epoch [162/2000], Avg Train Loss: 4.3218\n",
      "Epoch [162/2000], Avg Val Loss: 3.1826\n",
      "Validation loss improved from 3.1836 to 3.1826. Saving model...\n",
      "\n",
      "LOG: Epoch [163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2785\n",
      "Epoch [163/2000], Avg Train Loss: 4.2785\n",
      "Epoch [163/2000], Avg Val Loss: 3.1816\n",
      "Validation loss improved from 3.1826 to 3.1816. Saving model...\n",
      "\n",
      "LOG: Epoch [164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3569\n",
      "Epoch [164/2000], Avg Train Loss: 4.3569\n",
      "Epoch [164/2000], Avg Val Loss: 3.1807\n",
      "Validation loss improved from 3.1816 to 3.1807. Saving model...\n",
      "\n",
      "LOG: Epoch [165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2823\n",
      "Epoch [165/2000], Avg Train Loss: 4.2823\n",
      "Epoch [165/2000], Avg Val Loss: 3.1797\n",
      "Validation loss improved from 3.1807 to 3.1797. Saving model...\n",
      "\n",
      "LOG: Epoch [166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3320\n",
      "Epoch [166/2000], Avg Train Loss: 4.3320\n",
      "Epoch [166/2000], Avg Val Loss: 3.1787\n",
      "Validation loss improved from 3.1797 to 3.1787. Saving model...\n",
      "\n",
      "LOG: Epoch [167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2997\n",
      "Epoch [167/2000], Avg Train Loss: 4.2997\n",
      "Epoch [167/2000], Avg Val Loss: 3.1777\n",
      "Validation loss improved from 3.1787 to 3.1777. Saving model...\n",
      "\n",
      "LOG: Epoch [168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2907\n",
      "Epoch [168/2000], Avg Train Loss: 4.2907\n",
      "Epoch [168/2000], Avg Val Loss: 3.1767\n",
      "Validation loss improved from 3.1777 to 3.1767. Saving model...\n",
      "\n",
      "LOG: Epoch [169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2992\n",
      "Epoch [169/2000], Avg Train Loss: 4.2992\n",
      "Epoch [169/2000], Avg Val Loss: 3.1757\n",
      "Validation loss improved from 3.1767 to 3.1757. Saving model...\n",
      "\n",
      "LOG: Epoch [170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2423\n",
      "Epoch [170/2000], Avg Train Loss: 4.2423\n",
      "Epoch [170/2000], Avg Val Loss: 3.1746\n",
      "Validation loss improved from 3.1757 to 3.1746. Saving model...\n",
      "\n",
      "LOG: Epoch [171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3335\n",
      "Epoch [171/2000], Avg Train Loss: 4.3335\n",
      "Epoch [171/2000], Avg Val Loss: 3.1734\n",
      "Validation loss improved from 3.1746 to 3.1734. Saving model...\n",
      "\n",
      "LOG: Epoch [172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3100\n",
      "Epoch [172/2000], Avg Train Loss: 4.3100\n",
      "Epoch [172/2000], Avg Val Loss: 3.1724\n",
      "Validation loss improved from 3.1734 to 3.1724. Saving model...\n",
      "\n",
      "LOG: Epoch [173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2624\n",
      "Epoch [173/2000], Avg Train Loss: 4.2624\n",
      "Epoch [173/2000], Avg Val Loss: 3.1713\n",
      "Validation loss improved from 3.1724 to 3.1713. Saving model...\n",
      "\n",
      "LOG: Epoch [174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2257\n",
      "Epoch [174/2000], Avg Train Loss: 4.2257\n",
      "Epoch [174/2000], Avg Val Loss: 3.1702\n",
      "Validation loss improved from 3.1713 to 3.1702. Saving model...\n",
      "\n",
      "LOG: Epoch [175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2884\n",
      "Epoch [175/2000], Avg Train Loss: 4.2884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [175/2000], Avg Val Loss: 3.1691\n",
      "Validation loss improved from 3.1702 to 3.1691. Saving model...\n",
      "\n",
      "LOG: Epoch [176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2966\n",
      "Epoch [176/2000], Avg Train Loss: 4.2966\n",
      "Epoch [176/2000], Avg Val Loss: 3.1680\n",
      "Validation loss improved from 3.1691 to 3.1680. Saving model...\n",
      "\n",
      "LOG: Epoch [177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2554\n",
      "Epoch [177/2000], Avg Train Loss: 4.2554\n",
      "Epoch [177/2000], Avg Val Loss: 3.1668\n",
      "Validation loss improved from 3.1680 to 3.1668. Saving model...\n",
      "\n",
      "LOG: Epoch [178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2888\n",
      "Epoch [178/2000], Avg Train Loss: 4.2888\n",
      "Epoch [178/2000], Avg Val Loss: 3.1657\n",
      "Validation loss improved from 3.1668 to 3.1657. Saving model...\n",
      "\n",
      "LOG: Epoch [179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2273\n",
      "Epoch [179/2000], Avg Train Loss: 4.2273\n",
      "Epoch [179/2000], Avg Val Loss: 3.1646\n",
      "Validation loss improved from 3.1657 to 3.1646. Saving model...\n",
      "\n",
      "LOG: Epoch [180/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2397\n",
      "Epoch [180/2000], Avg Train Loss: 4.2397\n",
      "Epoch [180/2000], Avg Val Loss: 3.1635\n",
      "Validation loss improved from 3.1646 to 3.1635. Saving model...\n",
      "\n",
      "LOG: Epoch [181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2730\n",
      "Epoch [181/2000], Avg Train Loss: 4.2730\n",
      "Epoch [181/2000], Avg Val Loss: 3.1624\n",
      "Validation loss improved from 3.1635 to 3.1624. Saving model...\n",
      "\n",
      "LOG: Epoch [182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2631\n",
      "Epoch [182/2000], Avg Train Loss: 4.2631\n",
      "Epoch [182/2000], Avg Val Loss: 3.1613\n",
      "Validation loss improved from 3.1624 to 3.1613. Saving model...\n",
      "\n",
      "LOG: Epoch [183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2465\n",
      "Epoch [183/2000], Avg Train Loss: 4.2465\n",
      "Epoch [183/2000], Avg Val Loss: 3.1602\n",
      "Validation loss improved from 3.1613 to 3.1602. Saving model...\n",
      "\n",
      "LOG: Epoch [184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2730\n",
      "Epoch [184/2000], Avg Train Loss: 4.2730\n",
      "Epoch [184/2000], Avg Val Loss: 3.1591\n",
      "Validation loss improved from 3.1602 to 3.1591. Saving model...\n",
      "\n",
      "LOG: Epoch [185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2707\n",
      "Epoch [185/2000], Avg Train Loss: 4.2707\n",
      "Epoch [185/2000], Avg Val Loss: 3.1580\n",
      "Validation loss improved from 3.1591 to 3.1580. Saving model...\n",
      "\n",
      "LOG: Epoch [186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2907\n",
      "Epoch [186/2000], Avg Train Loss: 4.2907\n",
      "Epoch [186/2000], Avg Val Loss: 3.1569\n",
      "Validation loss improved from 3.1580 to 3.1569. Saving model...\n",
      "\n",
      "LOG: Epoch [187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2452\n",
      "Epoch [187/2000], Avg Train Loss: 4.2452\n",
      "Epoch [187/2000], Avg Val Loss: 3.1558\n",
      "Validation loss improved from 3.1569 to 3.1558. Saving model...\n",
      "\n",
      "LOG: Epoch [188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2299\n",
      "Epoch [188/2000], Avg Train Loss: 4.2299\n",
      "Epoch [188/2000], Avg Val Loss: 3.1547\n",
      "Validation loss improved from 3.1558 to 3.1547. Saving model...\n",
      "\n",
      "LOG: Epoch [189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1733\n",
      "Epoch [189/2000], Avg Train Loss: 4.1733\n",
      "Epoch [189/2000], Avg Val Loss: 3.1537\n",
      "Validation loss improved from 3.1547 to 3.1537. Saving model...\n",
      "\n",
      "LOG: Epoch [190/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2436\n",
      "Epoch [190/2000], Avg Train Loss: 4.2436\n",
      "Epoch [190/2000], Avg Val Loss: 3.1526\n",
      "Validation loss improved from 3.1537 to 3.1526. Saving model...\n",
      "\n",
      "LOG: Epoch [191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2022\n",
      "Epoch [191/2000], Avg Train Loss: 4.2022\n",
      "Epoch [191/2000], Avg Val Loss: 3.1515\n",
      "Validation loss improved from 3.1526 to 3.1515. Saving model...\n",
      "\n",
      "LOG: Epoch [192/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.2651\n",
      "Epoch [192/2000], Avg Train Loss: 4.2651\n",
      "Epoch [192/2000], Avg Val Loss: 3.1504\n",
      "Validation loss improved from 3.1515 to 3.1504. Saving model...\n",
      "\n",
      "LOG: Epoch [193/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1802\n",
      "Epoch [193/2000], Avg Train Loss: 4.1802\n",
      "Epoch [193/2000], Avg Val Loss: 3.1493\n",
      "Validation loss improved from 3.1504 to 3.1493. Saving model...\n",
      "\n",
      "LOG: Epoch [194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2486\n",
      "Epoch [194/2000], Avg Train Loss: 4.2486\n",
      "Epoch [194/2000], Avg Val Loss: 3.1481\n",
      "Validation loss improved from 3.1493 to 3.1481. Saving model...\n",
      "\n",
      "LOG: Epoch [195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2523\n",
      "Epoch [195/2000], Avg Train Loss: 4.2523\n",
      "Epoch [195/2000], Avg Val Loss: 3.1470\n",
      "Validation loss improved from 3.1481 to 3.1470. Saving model...\n",
      "\n",
      "LOG: Epoch [196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1935\n",
      "Epoch [196/2000], Avg Train Loss: 4.1935\n",
      "Epoch [196/2000], Avg Val Loss: 3.1459\n",
      "Validation loss improved from 3.1470 to 3.1459. Saving model...\n",
      "\n",
      "LOG: Epoch [197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1834\n",
      "Epoch [197/2000], Avg Train Loss: 4.1834\n",
      "Epoch [197/2000], Avg Val Loss: 3.1448\n",
      "Validation loss improved from 3.1459 to 3.1448. Saving model...\n",
      "\n",
      "LOG: Epoch [198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2176\n",
      "Epoch [198/2000], Avg Train Loss: 4.2176\n",
      "Epoch [198/2000], Avg Val Loss: 3.1437\n",
      "Validation loss improved from 3.1448 to 3.1437. Saving model...\n",
      "\n",
      "LOG: Epoch [199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.3156\n",
      "Epoch [199/2000], Avg Train Loss: 4.3156\n",
      "Epoch [199/2000], Avg Val Loss: 3.1426\n",
      "Validation loss improved from 3.1437 to 3.1426. Saving model...\n",
      "\n",
      "LOG: Epoch [200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1867\n",
      "Epoch [200/2000], Avg Train Loss: 4.1867\n",
      "Epoch [200/2000], Avg Val Loss: 3.1416\n",
      "Validation loss improved from 3.1426 to 3.1416. Saving model...\n",
      "\n",
      "LOG: Epoch [201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1931\n",
      "Epoch [201/2000], Avg Train Loss: 4.1931\n",
      "Epoch [201/2000], Avg Val Loss: 3.1405\n",
      "Validation loss improved from 3.1416 to 3.1405. Saving model...\n",
      "\n",
      "LOG: Epoch [202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1912\n",
      "Epoch [202/2000], Avg Train Loss: 4.1912\n",
      "Epoch [202/2000], Avg Val Loss: 3.1395\n",
      "Validation loss improved from 3.1405 to 3.1395. Saving model...\n",
      "\n",
      "LOG: Epoch [203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1551\n",
      "Epoch [203/2000], Avg Train Loss: 4.1551\n",
      "Epoch [203/2000], Avg Val Loss: 3.1384\n",
      "Validation loss improved from 3.1395 to 3.1384. Saving model...\n",
      "\n",
      "LOG: Epoch [204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1942\n",
      "Epoch [204/2000], Avg Train Loss: 4.1942\n",
      "Epoch [204/2000], Avg Val Loss: 3.1373\n",
      "Validation loss improved from 3.1384 to 3.1373. Saving model...\n",
      "\n",
      "LOG: Epoch [205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1855\n",
      "Epoch [205/2000], Avg Train Loss: 4.1855\n",
      "Epoch [205/2000], Avg Val Loss: 3.1363\n",
      "Validation loss improved from 3.1373 to 3.1363. Saving model...\n",
      "\n",
      "LOG: Epoch [206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2177\n",
      "Epoch [206/2000], Avg Train Loss: 4.2177\n",
      "Epoch [206/2000], Avg Val Loss: 3.1352\n",
      "Validation loss improved from 3.1363 to 3.1352. Saving model...\n",
      "\n",
      "LOG: Epoch [207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1286\n",
      "Epoch [207/2000], Avg Train Loss: 4.1286\n",
      "Epoch [207/2000], Avg Val Loss: 3.1341\n",
      "Validation loss improved from 3.1352 to 3.1341. Saving model...\n",
      "\n",
      "LOG: Epoch [208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1734\n",
      "Epoch [208/2000], Avg Train Loss: 4.1734\n",
      "Epoch [208/2000], Avg Val Loss: 3.1330\n",
      "Validation loss improved from 3.1341 to 3.1330. Saving model...\n",
      "\n",
      "LOG: Epoch [209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2495\n",
      "Epoch [209/2000], Avg Train Loss: 4.2495\n",
      "Epoch [209/2000], Avg Val Loss: 3.1318\n",
      "Validation loss improved from 3.1330 to 3.1318. Saving model...\n",
      "\n",
      "LOG: Epoch [210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1263\n",
      "Epoch [210/2000], Avg Train Loss: 4.1263\n",
      "Epoch [210/2000], Avg Val Loss: 3.1307\n",
      "Validation loss improved from 3.1318 to 3.1307. Saving model...\n",
      "\n",
      "LOG: Epoch [211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2186\n",
      "Epoch [211/2000], Avg Train Loss: 4.2186\n",
      "Epoch [211/2000], Avg Val Loss: 3.1296\n",
      "Validation loss improved from 3.1307 to 3.1296. Saving model...\n",
      "\n",
      "LOG: Epoch [212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1729\n",
      "Epoch [212/2000], Avg Train Loss: 4.1729\n",
      "Epoch [212/2000], Avg Val Loss: 3.1285\n",
      "Validation loss improved from 3.1296 to 3.1285. Saving model...\n",
      "\n",
      "LOG: Epoch [213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2083\n",
      "Epoch [213/2000], Avg Train Loss: 4.2083\n",
      "Epoch [213/2000], Avg Val Loss: 3.1274\n",
      "Validation loss improved from 3.1285 to 3.1274. Saving model...\n",
      "\n",
      "LOG: Epoch [214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1616\n",
      "Epoch [214/2000], Avg Train Loss: 4.1616\n",
      "Epoch [214/2000], Avg Val Loss: 3.1264\n",
      "Validation loss improved from 3.1274 to 3.1264. Saving model...\n",
      "\n",
      "LOG: Epoch [215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1664\n",
      "Epoch [215/2000], Avg Train Loss: 4.1664\n",
      "Epoch [215/2000], Avg Val Loss: 3.1253\n",
      "Validation loss improved from 3.1264 to 3.1253. Saving model...\n",
      "\n",
      "LOG: Epoch [216/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2342\n",
      "Epoch [216/2000], Avg Train Loss: 4.2342\n",
      "Epoch [216/2000], Avg Val Loss: 3.1243\n",
      "Validation loss improved from 3.1253 to 3.1243. Saving model...\n",
      "\n",
      "LOG: Epoch [217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1513\n",
      "Epoch [217/2000], Avg Train Loss: 4.1513\n",
      "Epoch [217/2000], Avg Val Loss: 3.1233\n",
      "Validation loss improved from 3.1243 to 3.1233. Saving model...\n",
      "\n",
      "LOG: Epoch [218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0999\n",
      "Epoch [218/2000], Avg Train Loss: 4.0999\n",
      "Epoch [218/2000], Avg Val Loss: 3.1223\n",
      "Validation loss improved from 3.1233 to 3.1223. Saving model...\n",
      "\n",
      "LOG: Epoch [219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1421\n",
      "Epoch [219/2000], Avg Train Loss: 4.1421\n",
      "Epoch [219/2000], Avg Val Loss: 3.1212\n",
      "Validation loss improved from 3.1223 to 3.1212. Saving model...\n",
      "\n",
      "LOG: Epoch [220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1679\n",
      "Epoch [220/2000], Avg Train Loss: 4.1679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [220/2000], Avg Val Loss: 3.1201\n",
      "Validation loss improved from 3.1212 to 3.1201. Saving model...\n",
      "\n",
      "LOG: Epoch [221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1317\n",
      "Epoch [221/2000], Avg Train Loss: 4.1317\n",
      "Epoch [221/2000], Avg Val Loss: 3.1190\n",
      "Validation loss improved from 3.1201 to 3.1190. Saving model...\n",
      "\n",
      "LOG: Epoch [222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1067\n",
      "Epoch [222/2000], Avg Train Loss: 4.1067\n",
      "Epoch [222/2000], Avg Val Loss: 3.1178\n",
      "Validation loss improved from 3.1190 to 3.1178. Saving model...\n",
      "\n",
      "LOG: Epoch [223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1083\n",
      "Epoch [223/2000], Avg Train Loss: 4.1083\n",
      "Epoch [223/2000], Avg Val Loss: 3.1167\n",
      "Validation loss improved from 3.1178 to 3.1167. Saving model...\n",
      "\n",
      "LOG: Epoch [224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1111\n",
      "Epoch [224/2000], Avg Train Loss: 4.1111\n",
      "Epoch [224/2000], Avg Val Loss: 3.1155\n",
      "Validation loss improved from 3.1167 to 3.1155. Saving model...\n",
      "\n",
      "LOG: Epoch [225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1413\n",
      "Epoch [225/2000], Avg Train Loss: 4.1413\n",
      "Epoch [225/2000], Avg Val Loss: 3.1143\n",
      "Validation loss improved from 3.1155 to 3.1143. Saving model...\n",
      "\n",
      "LOG: Epoch [226/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1651\n",
      "Epoch [226/2000], Avg Train Loss: 4.1651\n",
      "Epoch [226/2000], Avg Val Loss: 3.1132\n",
      "Validation loss improved from 3.1143 to 3.1132. Saving model...\n",
      "\n",
      "LOG: Epoch [227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1251\n",
      "Epoch [227/2000], Avg Train Loss: 4.1251\n",
      "Epoch [227/2000], Avg Val Loss: 3.1120\n",
      "Validation loss improved from 3.1132 to 3.1120. Saving model...\n",
      "\n",
      "LOG: Epoch [228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1125\n",
      "Epoch [228/2000], Avg Train Loss: 4.1125\n",
      "Epoch [228/2000], Avg Val Loss: 3.1108\n",
      "Validation loss improved from 3.1120 to 3.1108. Saving model...\n",
      "\n",
      "LOG: Epoch [229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0889\n",
      "Epoch [229/2000], Avg Train Loss: 4.0889\n",
      "Epoch [229/2000], Avg Val Loss: 3.1096\n",
      "Validation loss improved from 3.1108 to 3.1096. Saving model...\n",
      "\n",
      "LOG: Epoch [230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1665\n",
      "Epoch [230/2000], Avg Train Loss: 4.1665\n",
      "Epoch [230/2000], Avg Val Loss: 3.1085\n",
      "Validation loss improved from 3.1096 to 3.1085. Saving model...\n",
      "\n",
      "LOG: Epoch [231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1025\n",
      "Epoch [231/2000], Avg Train Loss: 4.1025\n",
      "Epoch [231/2000], Avg Val Loss: 3.1073\n",
      "Validation loss improved from 3.1085 to 3.1073. Saving model...\n",
      "\n",
      "LOG: Epoch [232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.2077\n",
      "Epoch [232/2000], Avg Train Loss: 4.2077\n",
      "Epoch [232/2000], Avg Val Loss: 3.1062\n",
      "Validation loss improved from 3.1073 to 3.1062. Saving model...\n",
      "\n",
      "LOG: Epoch [233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0609\n",
      "Epoch [233/2000], Avg Train Loss: 4.0609\n",
      "Epoch [233/2000], Avg Val Loss: 3.1050\n",
      "Validation loss improved from 3.1062 to 3.1050. Saving model...\n",
      "\n",
      "LOG: Epoch [234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1194\n",
      "Epoch [234/2000], Avg Train Loss: 4.1194\n",
      "Epoch [234/2000], Avg Val Loss: 3.1039\n",
      "Validation loss improved from 3.1050 to 3.1039. Saving model...\n",
      "\n",
      "LOG: Epoch [235/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0915\n",
      "Epoch [235/2000], Avg Train Loss: 4.0915\n",
      "Epoch [235/2000], Avg Val Loss: 3.1027\n",
      "Validation loss improved from 3.1039 to 3.1027. Saving model...\n",
      "\n",
      "LOG: Epoch [236/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.1167\n",
      "Epoch [236/2000], Avg Train Loss: 4.1167\n",
      "Epoch [236/2000], Avg Val Loss: 3.1016\n",
      "Validation loss improved from 3.1027 to 3.1016. Saving model...\n",
      "\n",
      "LOG: Epoch [237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1341\n",
      "Epoch [237/2000], Avg Train Loss: 4.1341\n",
      "Epoch [237/2000], Avg Val Loss: 3.1006\n",
      "Validation loss improved from 3.1016 to 3.1006. Saving model...\n",
      "\n",
      "LOG: Epoch [238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1381\n",
      "Epoch [238/2000], Avg Train Loss: 4.1381\n",
      "Epoch [238/2000], Avg Val Loss: 3.0995\n",
      "Validation loss improved from 3.1006 to 3.0995. Saving model...\n",
      "\n",
      "LOG: Epoch [239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0837\n",
      "Epoch [239/2000], Avg Train Loss: 4.0837\n",
      "Epoch [239/2000], Avg Val Loss: 3.0984\n",
      "Validation loss improved from 3.0995 to 3.0984. Saving model...\n",
      "\n",
      "LOG: Epoch [240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1302\n",
      "Epoch [240/2000], Avg Train Loss: 4.1302\n",
      "Epoch [240/2000], Avg Val Loss: 3.0974\n",
      "Validation loss improved from 3.0984 to 3.0974. Saving model...\n",
      "\n",
      "LOG: Epoch [241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1061\n",
      "Epoch [241/2000], Avg Train Loss: 4.1061\n",
      "Epoch [241/2000], Avg Val Loss: 3.0963\n",
      "Validation loss improved from 3.0974 to 3.0963. Saving model...\n",
      "\n",
      "LOG: Epoch [242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1260\n",
      "Epoch [242/2000], Avg Train Loss: 4.1260\n",
      "Epoch [242/2000], Avg Val Loss: 3.0953\n",
      "Validation loss improved from 3.0963 to 3.0953. Saving model...\n",
      "\n",
      "LOG: Epoch [243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1328\n",
      "Epoch [243/2000], Avg Train Loss: 4.1328\n",
      "Epoch [243/2000], Avg Val Loss: 3.0942\n",
      "Validation loss improved from 3.0953 to 3.0942. Saving model...\n",
      "\n",
      "LOG: Epoch [244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1380\n",
      "Epoch [244/2000], Avg Train Loss: 4.1380\n",
      "Epoch [244/2000], Avg Val Loss: 3.0932\n",
      "Validation loss improved from 3.0942 to 3.0932. Saving model...\n",
      "\n",
      "LOG: Epoch [245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0823\n",
      "Epoch [245/2000], Avg Train Loss: 4.0823\n",
      "Epoch [245/2000], Avg Val Loss: 3.0922\n",
      "Validation loss improved from 3.0932 to 3.0922. Saving model...\n",
      "\n",
      "LOG: Epoch [246/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0795\n",
      "Epoch [246/2000], Avg Train Loss: 4.0795\n",
      "Epoch [246/2000], Avg Val Loss: 3.0911\n",
      "Validation loss improved from 3.0922 to 3.0911. Saving model...\n",
      "\n",
      "LOG: Epoch [247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0610\n",
      "Epoch [247/2000], Avg Train Loss: 4.0610\n",
      "Epoch [247/2000], Avg Val Loss: 3.0900\n",
      "Validation loss improved from 3.0911 to 3.0900. Saving model...\n",
      "\n",
      "LOG: Epoch [248/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0746\n",
      "Epoch [248/2000], Avg Train Loss: 4.0746\n",
      "Epoch [248/2000], Avg Val Loss: 3.0890\n",
      "Validation loss improved from 3.0900 to 3.0890. Saving model...\n",
      "\n",
      "LOG: Epoch [249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0983\n",
      "Epoch [249/2000], Avg Train Loss: 4.0983\n",
      "Epoch [249/2000], Avg Val Loss: 3.0879\n",
      "Validation loss improved from 3.0890 to 3.0879. Saving model...\n",
      "\n",
      "LOG: Epoch [250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0702\n",
      "Epoch [250/2000], Avg Train Loss: 4.0702\n",
      "Epoch [250/2000], Avg Val Loss: 3.0868\n",
      "Validation loss improved from 3.0879 to 3.0868. Saving model...\n",
      "\n",
      "LOG: Epoch [251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0823\n",
      "Epoch [251/2000], Avg Train Loss: 4.0823\n",
      "Epoch [251/2000], Avg Val Loss: 3.0856\n",
      "Validation loss improved from 3.0868 to 3.0856. Saving model...\n",
      "\n",
      "LOG: Epoch [252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0893\n",
      "Epoch [252/2000], Avg Train Loss: 4.0893\n",
      "Epoch [252/2000], Avg Val Loss: 3.0845\n",
      "Validation loss improved from 3.0856 to 3.0845. Saving model...\n",
      "\n",
      "LOG: Epoch [253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0858\n",
      "Epoch [253/2000], Avg Train Loss: 4.0858\n",
      "Epoch [253/2000], Avg Val Loss: 3.0834\n",
      "Validation loss improved from 3.0845 to 3.0834. Saving model...\n",
      "\n",
      "LOG: Epoch [254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0516\n",
      "Epoch [254/2000], Avg Train Loss: 4.0516\n",
      "Epoch [254/2000], Avg Val Loss: 3.0823\n",
      "Validation loss improved from 3.0834 to 3.0823. Saving model...\n",
      "\n",
      "LOG: Epoch [255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0706\n",
      "Epoch [255/2000], Avg Train Loss: 4.0706\n",
      "Epoch [255/2000], Avg Val Loss: 3.0812\n",
      "Validation loss improved from 3.0823 to 3.0812. Saving model...\n",
      "\n",
      "LOG: Epoch [256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0820\n",
      "Epoch [256/2000], Avg Train Loss: 4.0820\n",
      "Epoch [256/2000], Avg Val Loss: 3.0801\n",
      "Validation loss improved from 3.0812 to 3.0801. Saving model...\n",
      "\n",
      "LOG: Epoch [257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1203\n",
      "Epoch [257/2000], Avg Train Loss: 4.1203\n",
      "Epoch [257/2000], Avg Val Loss: 3.0790\n",
      "Validation loss improved from 3.0801 to 3.0790. Saving model...\n",
      "\n",
      "LOG: Epoch [258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0927\n",
      "Epoch [258/2000], Avg Train Loss: 4.0927\n",
      "Epoch [258/2000], Avg Val Loss: 3.0779\n",
      "Validation loss improved from 3.0790 to 3.0779. Saving model...\n",
      "\n",
      "LOG: Epoch [259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1018\n",
      "Epoch [259/2000], Avg Train Loss: 4.1018\n",
      "Epoch [259/2000], Avg Val Loss: 3.0769\n",
      "Validation loss improved from 3.0779 to 3.0769. Saving model...\n",
      "\n",
      "LOG: Epoch [260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0932\n",
      "Epoch [260/2000], Avg Train Loss: 4.0932\n",
      "Epoch [260/2000], Avg Val Loss: 3.0758\n",
      "Validation loss improved from 3.0769 to 3.0758. Saving model...\n",
      "\n",
      "LOG: Epoch [261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0365\n",
      "Epoch [261/2000], Avg Train Loss: 4.0365\n",
      "Epoch [261/2000], Avg Val Loss: 3.0747\n",
      "Validation loss improved from 3.0758 to 3.0747. Saving model...\n",
      "\n",
      "LOG: Epoch [262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0669\n",
      "Epoch [262/2000], Avg Train Loss: 4.0669\n",
      "Epoch [262/2000], Avg Val Loss: 3.0736\n",
      "Validation loss improved from 3.0747 to 3.0736. Saving model...\n",
      "\n",
      "LOG: Epoch [263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1065\n",
      "Epoch [263/2000], Avg Train Loss: 4.1065\n",
      "Epoch [263/2000], Avg Val Loss: 3.0726\n",
      "Validation loss improved from 3.0736 to 3.0726. Saving model...\n",
      "\n",
      "LOG: Epoch [264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0969\n",
      "Epoch [264/2000], Avg Train Loss: 4.0969\n",
      "Epoch [264/2000], Avg Val Loss: 3.0716\n",
      "Validation loss improved from 3.0726 to 3.0716. Saving model...\n",
      "\n",
      "LOG: Epoch [265/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0898\n",
      "Epoch [265/2000], Avg Train Loss: 4.0898\n",
      "Epoch [265/2000], Avg Val Loss: 3.0706\n",
      "Validation loss improved from 3.0716 to 3.0706. Saving model...\n",
      "\n",
      "LOG: Epoch [266/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0600\n",
      "Epoch [266/2000], Avg Train Loss: 4.0600\n",
      "Epoch [266/2000], Avg Val Loss: 3.0695\n",
      "Validation loss improved from 3.0706 to 3.0695. Saving model...\n",
      "\n",
      "LOG: Epoch [267/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9974\n",
      "Epoch [267/2000], Avg Train Loss: 3.9974\n",
      "Epoch [267/2000], Avg Val Loss: 3.0685\n",
      "Validation loss improved from 3.0695 to 3.0685. Saving model...\n",
      "\n",
      "LOG: Epoch [268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0028\n",
      "Epoch [268/2000], Avg Train Loss: 4.0028\n",
      "Epoch [268/2000], Avg Val Loss: 3.0674\n",
      "Validation loss improved from 3.0685 to 3.0674. Saving model...\n",
      "\n",
      "LOG: Epoch [269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0302\n",
      "Epoch [269/2000], Avg Train Loss: 4.0302\n",
      "Epoch [269/2000], Avg Val Loss: 3.0663\n",
      "Validation loss improved from 3.0674 to 3.0663. Saving model...\n",
      "\n",
      "LOG: Epoch [270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0727\n",
      "Epoch [270/2000], Avg Train Loss: 4.0727\n",
      "Epoch [270/2000], Avg Val Loss: 3.0652\n",
      "Validation loss improved from 3.0663 to 3.0652. Saving model...\n",
      "\n",
      "LOG: Epoch [271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0483\n",
      "Epoch [271/2000], Avg Train Loss: 4.0483\n",
      "Epoch [271/2000], Avg Val Loss: 3.0642\n",
      "Validation loss improved from 3.0652 to 3.0642. Saving model...\n",
      "\n",
      "LOG: Epoch [272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.1123\n",
      "Epoch [272/2000], Avg Train Loss: 4.1123\n",
      "Epoch [272/2000], Avg Val Loss: 3.0632\n",
      "Validation loss improved from 3.0642 to 3.0632. Saving model...\n",
      "\n",
      "LOG: Epoch [273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0666\n",
      "Epoch [273/2000], Avg Train Loss: 4.0666\n",
      "Epoch [273/2000], Avg Val Loss: 3.0622\n",
      "Validation loss improved from 3.0632 to 3.0622. Saving model...\n",
      "\n",
      "LOG: Epoch [274/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0135\n",
      "Epoch [274/2000], Avg Train Loss: 4.0135\n",
      "Epoch [274/2000], Avg Val Loss: 3.0612\n",
      "Validation loss improved from 3.0622 to 3.0612. Saving model...\n",
      "\n",
      "LOG: Epoch [275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0434\n",
      "Epoch [275/2000], Avg Train Loss: 4.0434\n",
      "Epoch [275/2000], Avg Val Loss: 3.0601\n",
      "Validation loss improved from 3.0612 to 3.0601. Saving model...\n",
      "\n",
      "LOG: Epoch [276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0287\n",
      "Epoch [276/2000], Avg Train Loss: 4.0287\n",
      "Epoch [276/2000], Avg Val Loss: 3.0591\n",
      "Validation loss improved from 3.0601 to 3.0591. Saving model...\n",
      "\n",
      "LOG: Epoch [277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0208\n",
      "Epoch [277/2000], Avg Train Loss: 4.0208\n",
      "Epoch [277/2000], Avg Val Loss: 3.0580\n",
      "Validation loss improved from 3.0591 to 3.0580. Saving model...\n",
      "\n",
      "LOG: Epoch [278/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0649\n",
      "Epoch [278/2000], Avg Train Loss: 4.0649\n",
      "Epoch [278/2000], Avg Val Loss: 3.0570\n",
      "Validation loss improved from 3.0580 to 3.0570. Saving model...\n",
      "\n",
      "LOG: Epoch [279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0438\n",
      "Epoch [279/2000], Avg Train Loss: 4.0438\n",
      "Epoch [279/2000], Avg Val Loss: 3.0559\n",
      "Validation loss improved from 3.0570 to 3.0559. Saving model...\n",
      "\n",
      "LOG: Epoch [280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9770\n",
      "Epoch [280/2000], Avg Train Loss: 3.9770\n",
      "Epoch [280/2000], Avg Val Loss: 3.0549\n",
      "Validation loss improved from 3.0559 to 3.0549. Saving model...\n",
      "\n",
      "LOG: Epoch [281/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 4.0167\n",
      "Epoch [281/2000], Avg Train Loss: 4.0167\n",
      "Epoch [281/2000], Avg Val Loss: 3.0538\n",
      "Validation loss improved from 3.0549 to 3.0538. Saving model...\n",
      "\n",
      "LOG: Epoch [282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0182\n",
      "Epoch [282/2000], Avg Train Loss: 4.0182\n",
      "Epoch [282/2000], Avg Val Loss: 3.0527\n",
      "Validation loss improved from 3.0538 to 3.0527. Saving model...\n",
      "\n",
      "LOG: Epoch [283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0113\n",
      "Epoch [283/2000], Avg Train Loss: 4.0113\n",
      "Epoch [283/2000], Avg Val Loss: 3.0516\n",
      "Validation loss improved from 3.0527 to 3.0516. Saving model...\n",
      "\n",
      "LOG: Epoch [284/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0734\n",
      "Epoch [284/2000], Avg Train Loss: 4.0734\n",
      "Epoch [284/2000], Avg Val Loss: 3.0506\n",
      "Validation loss improved from 3.0516 to 3.0506. Saving model...\n",
      "\n",
      "LOG: Epoch [285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0046\n",
      "Epoch [285/2000], Avg Train Loss: 4.0046\n",
      "Epoch [285/2000], Avg Val Loss: 3.0495\n",
      "Validation loss improved from 3.0506 to 3.0495. Saving model...\n",
      "\n",
      "LOG: Epoch [286/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0478\n",
      "Epoch [286/2000], Avg Train Loss: 4.0478\n",
      "Epoch [286/2000], Avg Val Loss: 3.0485\n",
      "Validation loss improved from 3.0495 to 3.0485. Saving model...\n",
      "\n",
      "LOG: Epoch [287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0344\n",
      "Epoch [287/2000], Avg Train Loss: 4.0344\n",
      "Epoch [287/2000], Avg Val Loss: 3.0475\n",
      "Validation loss improved from 3.0485 to 3.0475. Saving model...\n",
      "\n",
      "LOG: Epoch [288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9896\n",
      "Epoch [288/2000], Avg Train Loss: 3.9896\n",
      "Epoch [288/2000], Avg Val Loss: 3.0465\n",
      "Validation loss improved from 3.0475 to 3.0465. Saving model...\n",
      "\n",
      "LOG: Epoch [289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0226\n",
      "Epoch [289/2000], Avg Train Loss: 4.0226\n",
      "Epoch [289/2000], Avg Val Loss: 3.0455\n",
      "Validation loss improved from 3.0465 to 3.0455. Saving model...\n",
      "\n",
      "LOG: Epoch [290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9595\n",
      "Epoch [290/2000], Avg Train Loss: 3.9595\n",
      "Epoch [290/2000], Avg Val Loss: 3.0445\n",
      "Validation loss improved from 3.0455 to 3.0445. Saving model...\n",
      "\n",
      "LOG: Epoch [291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9875\n",
      "Epoch [291/2000], Avg Train Loss: 3.9875\n",
      "Epoch [291/2000], Avg Val Loss: 3.0434\n",
      "Validation loss improved from 3.0445 to 3.0434. Saving model...\n",
      "\n",
      "LOG: Epoch [292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0497\n",
      "Epoch [292/2000], Avg Train Loss: 4.0497\n",
      "Epoch [292/2000], Avg Val Loss: 3.0424\n",
      "Validation loss improved from 3.0434 to 3.0424. Saving model...\n",
      "\n",
      "LOG: Epoch [293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0004\n",
      "Epoch [293/2000], Avg Train Loss: 4.0004\n",
      "Epoch [293/2000], Avg Val Loss: 3.0414\n",
      "Validation loss improved from 3.0424 to 3.0414. Saving model...\n",
      "\n",
      "LOG: Epoch [294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0089\n",
      "Epoch [294/2000], Avg Train Loss: 4.0089\n",
      "Epoch [294/2000], Avg Val Loss: 3.0404\n",
      "Validation loss improved from 3.0414 to 3.0404. Saving model...\n",
      "\n",
      "LOG: Epoch [295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0204\n",
      "Epoch [295/2000], Avg Train Loss: 4.0204\n",
      "Epoch [295/2000], Avg Val Loss: 3.0394\n",
      "Validation loss improved from 3.0404 to 3.0394. Saving model...\n",
      "\n",
      "LOG: Epoch [296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9907\n",
      "Epoch [296/2000], Avg Train Loss: 3.9907\n",
      "Epoch [296/2000], Avg Val Loss: 3.0384\n",
      "Validation loss improved from 3.0394 to 3.0384. Saving model...\n",
      "\n",
      "LOG: Epoch [297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0083\n",
      "Epoch [297/2000], Avg Train Loss: 4.0083\n",
      "Epoch [297/2000], Avg Val Loss: 3.0375\n",
      "Validation loss improved from 3.0384 to 3.0375. Saving model...\n",
      "\n",
      "LOG: Epoch [298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9737\n",
      "Epoch [298/2000], Avg Train Loss: 3.9737\n",
      "Epoch [298/2000], Avg Val Loss: 3.0365\n",
      "Validation loss improved from 3.0375 to 3.0365. Saving model...\n",
      "\n",
      "LOG: Epoch [299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9698\n",
      "Epoch [299/2000], Avg Train Loss: 3.9698\n",
      "Epoch [299/2000], Avg Val Loss: 3.0355\n",
      "Validation loss improved from 3.0365 to 3.0355. Saving model...\n",
      "\n",
      "LOG: Epoch [300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0629\n",
      "Epoch [300/2000], Avg Train Loss: 4.0629\n",
      "Epoch [300/2000], Avg Val Loss: 3.0345\n",
      "Validation loss improved from 3.0355 to 3.0345. Saving model...\n",
      "\n",
      "LOG: Epoch [301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0004\n",
      "Epoch [301/2000], Avg Train Loss: 4.0004\n",
      "Epoch [301/2000], Avg Val Loss: 3.0336\n",
      "Validation loss improved from 3.0345 to 3.0336. Saving model...\n",
      "\n",
      "LOG: Epoch [302/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9520\n",
      "Epoch [302/2000], Avg Train Loss: 3.9520\n",
      "Epoch [302/2000], Avg Val Loss: 3.0326\n",
      "Validation loss improved from 3.0336 to 3.0326. Saving model...\n",
      "\n",
      "LOG: Epoch [303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9862\n",
      "Epoch [303/2000], Avg Train Loss: 3.9862\n",
      "Epoch [303/2000], Avg Val Loss: 3.0316\n",
      "Validation loss improved from 3.0326 to 3.0316. Saving model...\n",
      "\n",
      "LOG: Epoch [304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0346\n",
      "Epoch [304/2000], Avg Train Loss: 4.0346\n",
      "Epoch [304/2000], Avg Val Loss: 3.0306\n",
      "Validation loss improved from 3.0316 to 3.0306. Saving model...\n",
      "\n",
      "LOG: Epoch [305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9059\n",
      "Epoch [305/2000], Avg Train Loss: 3.9059\n",
      "Epoch [305/2000], Avg Val Loss: 3.0296\n",
      "Validation loss improved from 3.0306 to 3.0296. Saving model...\n",
      "\n",
      "LOG: Epoch [306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9907\n",
      "Epoch [306/2000], Avg Train Loss: 3.9907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [306/2000], Avg Val Loss: 3.0286\n",
      "Validation loss improved from 3.0296 to 3.0286. Saving model...\n",
      "\n",
      "LOG: Epoch [307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9391\n",
      "Epoch [307/2000], Avg Train Loss: 3.9391\n",
      "Epoch [307/2000], Avg Val Loss: 3.0275\n",
      "Validation loss improved from 3.0286 to 3.0275. Saving model...\n",
      "\n",
      "LOG: Epoch [308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9936\n",
      "Epoch [308/2000], Avg Train Loss: 3.9936\n",
      "Epoch [308/2000], Avg Val Loss: 3.0265\n",
      "Validation loss improved from 3.0275 to 3.0265. Saving model...\n",
      "\n",
      "LOG: Epoch [309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9882\n",
      "Epoch [309/2000], Avg Train Loss: 3.9882\n",
      "Epoch [309/2000], Avg Val Loss: 3.0255\n",
      "Validation loss improved from 3.0265 to 3.0255. Saving model...\n",
      "\n",
      "LOG: Epoch [310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9457\n",
      "Epoch [310/2000], Avg Train Loss: 3.9457\n",
      "Epoch [310/2000], Avg Val Loss: 3.0244\n",
      "Validation loss improved from 3.0255 to 3.0244. Saving model...\n",
      "\n",
      "LOG: Epoch [311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9739\n",
      "Epoch [311/2000], Avg Train Loss: 3.9739\n",
      "Epoch [311/2000], Avg Val Loss: 3.0234\n",
      "Validation loss improved from 3.0244 to 3.0234. Saving model...\n",
      "\n",
      "LOG: Epoch [312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9717\n",
      "Epoch [312/2000], Avg Train Loss: 3.9717\n",
      "Epoch [312/2000], Avg Val Loss: 3.0223\n",
      "Validation loss improved from 3.0234 to 3.0223. Saving model...\n",
      "\n",
      "LOG: Epoch [313/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9938\n",
      "Epoch [313/2000], Avg Train Loss: 3.9938\n",
      "Epoch [313/2000], Avg Val Loss: 3.0213\n",
      "Validation loss improved from 3.0223 to 3.0213. Saving model...\n",
      "\n",
      "LOG: Epoch [314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9613\n",
      "Epoch [314/2000], Avg Train Loss: 3.9613\n",
      "Epoch [314/2000], Avg Val Loss: 3.0202\n",
      "Validation loss improved from 3.0213 to 3.0202. Saving model...\n",
      "\n",
      "LOG: Epoch [315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9386\n",
      "Epoch [315/2000], Avg Train Loss: 3.9386\n",
      "Epoch [315/2000], Avg Val Loss: 3.0191\n",
      "Validation loss improved from 3.0202 to 3.0191. Saving model...\n",
      "\n",
      "LOG: Epoch [316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9858\n",
      "Epoch [316/2000], Avg Train Loss: 3.9858\n",
      "Epoch [316/2000], Avg Val Loss: 3.0181\n",
      "Validation loss improved from 3.0191 to 3.0181. Saving model...\n",
      "\n",
      "LOG: Epoch [317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0165\n",
      "Epoch [317/2000], Avg Train Loss: 4.0165\n",
      "Epoch [317/2000], Avg Val Loss: 3.0171\n",
      "Validation loss improved from 3.0181 to 3.0171. Saving model...\n",
      "\n",
      "LOG: Epoch [318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9139\n",
      "Epoch [318/2000], Avg Train Loss: 3.9139\n",
      "Epoch [318/2000], Avg Val Loss: 3.0161\n",
      "Validation loss improved from 3.0171 to 3.0161. Saving model...\n",
      "\n",
      "LOG: Epoch [319/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9322\n",
      "Epoch [319/2000], Avg Train Loss: 3.9322\n",
      "Epoch [319/2000], Avg Val Loss: 3.0151\n",
      "Validation loss improved from 3.0161 to 3.0151. Saving model...\n",
      "\n",
      "LOG: Epoch [320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9374\n",
      "Epoch [320/2000], Avg Train Loss: 3.9374\n",
      "Epoch [320/2000], Avg Val Loss: 3.0141\n",
      "Validation loss improved from 3.0151 to 3.0141. Saving model...\n",
      "\n",
      "LOG: Epoch [321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9579\n",
      "Epoch [321/2000], Avg Train Loss: 3.9579\n",
      "Epoch [321/2000], Avg Val Loss: 3.0131\n",
      "Validation loss improved from 3.0141 to 3.0131. Saving model...\n",
      "\n",
      "LOG: Epoch [322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9005\n",
      "Epoch [322/2000], Avg Train Loss: 3.9005\n",
      "Epoch [322/2000], Avg Val Loss: 3.0121\n",
      "Validation loss improved from 3.0131 to 3.0121. Saving model...\n",
      "\n",
      "LOG: Epoch [323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 4.0038\n",
      "Epoch [323/2000], Avg Train Loss: 4.0038\n",
      "Epoch [323/2000], Avg Val Loss: 3.0111\n",
      "Validation loss improved from 3.0121 to 3.0111. Saving model...\n",
      "\n",
      "LOG: Epoch [324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9303\n",
      "Epoch [324/2000], Avg Train Loss: 3.9303\n",
      "Epoch [324/2000], Avg Val Loss: 3.0101\n",
      "Validation loss improved from 3.0111 to 3.0101. Saving model...\n",
      "\n",
      "LOG: Epoch [325/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.9615\n",
      "Epoch [325/2000], Avg Train Loss: 3.9615\n",
      "Epoch [325/2000], Avg Val Loss: 3.0092\n",
      "Validation loss improved from 3.0101 to 3.0092. Saving model...\n",
      "\n",
      "LOG: Epoch [326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9909\n",
      "Epoch [326/2000], Avg Train Loss: 3.9909\n",
      "Epoch [326/2000], Avg Val Loss: 3.0082\n",
      "Validation loss improved from 3.0092 to 3.0082. Saving model...\n",
      "\n",
      "LOG: Epoch [327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9412\n",
      "Epoch [327/2000], Avg Train Loss: 3.9412\n",
      "Epoch [327/2000], Avg Val Loss: 3.0073\n",
      "Validation loss improved from 3.0082 to 3.0073. Saving model...\n",
      "\n",
      "LOG: Epoch [328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9590\n",
      "Epoch [328/2000], Avg Train Loss: 3.9590\n",
      "Epoch [328/2000], Avg Val Loss: 3.0064\n",
      "Validation loss improved from 3.0073 to 3.0064. Saving model...\n",
      "\n",
      "LOG: Epoch [329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9728\n",
      "Epoch [329/2000], Avg Train Loss: 3.9728\n",
      "Epoch [329/2000], Avg Val Loss: 3.0055\n",
      "Validation loss improved from 3.0064 to 3.0055. Saving model...\n",
      "\n",
      "LOG: Epoch [330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9660\n",
      "Epoch [330/2000], Avg Train Loss: 3.9660\n",
      "Epoch [330/2000], Avg Val Loss: 3.0046\n",
      "Validation loss improved from 3.0055 to 3.0046. Saving model...\n",
      "\n",
      "LOG: Epoch [331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9361\n",
      "Epoch [331/2000], Avg Train Loss: 3.9361\n",
      "Epoch [331/2000], Avg Val Loss: 3.0037\n",
      "Validation loss improved from 3.0046 to 3.0037. Saving model...\n",
      "\n",
      "LOG: Epoch [332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9225\n",
      "Epoch [332/2000], Avg Train Loss: 3.9225\n",
      "Epoch [332/2000], Avg Val Loss: 3.0028\n",
      "Validation loss improved from 3.0037 to 3.0028. Saving model...\n",
      "\n",
      "LOG: Epoch [333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9563\n",
      "Epoch [333/2000], Avg Train Loss: 3.9563\n",
      "Epoch [333/2000], Avg Val Loss: 3.0020\n",
      "Validation loss improved from 3.0028 to 3.0020. Saving model...\n",
      "\n",
      "LOG: Epoch [334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8937\n",
      "Epoch [334/2000], Avg Train Loss: 3.8937\n",
      "Epoch [334/2000], Avg Val Loss: 3.0011\n",
      "Validation loss improved from 3.0020 to 3.0011. Saving model...\n",
      "\n",
      "LOG: Epoch [335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9477\n",
      "Epoch [335/2000], Avg Train Loss: 3.9477\n",
      "Epoch [335/2000], Avg Val Loss: 3.0002\n",
      "Validation loss improved from 3.0011 to 3.0002. Saving model...\n",
      "\n",
      "LOG: Epoch [336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9241\n",
      "Epoch [336/2000], Avg Train Loss: 3.9241\n",
      "Epoch [336/2000], Avg Val Loss: 2.9993\n",
      "Validation loss improved from 3.0002 to 2.9993. Saving model...\n",
      "\n",
      "LOG: Epoch [337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9391\n",
      "Epoch [337/2000], Avg Train Loss: 3.9391\n",
      "Epoch [337/2000], Avg Val Loss: 2.9984\n",
      "Validation loss improved from 2.9993 to 2.9984. Saving model...\n",
      "\n",
      "LOG: Epoch [338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9093\n",
      "Epoch [338/2000], Avg Train Loss: 3.9093\n",
      "Epoch [338/2000], Avg Val Loss: 2.9975\n",
      "Validation loss improved from 2.9984 to 2.9975. Saving model...\n",
      "\n",
      "LOG: Epoch [339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9225\n",
      "Epoch [339/2000], Avg Train Loss: 3.9225\n",
      "Epoch [339/2000], Avg Val Loss: 2.9966\n",
      "Validation loss improved from 2.9975 to 2.9966. Saving model...\n",
      "\n",
      "LOG: Epoch [340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9291\n",
      "Epoch [340/2000], Avg Train Loss: 3.9291\n",
      "Epoch [340/2000], Avg Val Loss: 2.9957\n",
      "Validation loss improved from 2.9966 to 2.9957. Saving model...\n",
      "\n",
      "LOG: Epoch [341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9464\n",
      "Epoch [341/2000], Avg Train Loss: 3.9464\n",
      "Epoch [341/2000], Avg Val Loss: 2.9948\n",
      "Validation loss improved from 2.9957 to 2.9948. Saving model...\n",
      "\n",
      "LOG: Epoch [342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9596\n",
      "Epoch [342/2000], Avg Train Loss: 3.9596\n",
      "Epoch [342/2000], Avg Val Loss: 2.9938\n",
      "Validation loss improved from 2.9948 to 2.9938. Saving model...\n",
      "\n",
      "LOG: Epoch [343/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8561\n",
      "Epoch [343/2000], Avg Train Loss: 3.8561\n",
      "Epoch [343/2000], Avg Val Loss: 2.9929\n",
      "Validation loss improved from 2.9938 to 2.9929. Saving model...\n",
      "\n",
      "LOG: Epoch [344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9404\n",
      "Epoch [344/2000], Avg Train Loss: 3.9404\n",
      "Epoch [344/2000], Avg Val Loss: 2.9919\n",
      "Validation loss improved from 2.9929 to 2.9919. Saving model...\n",
      "\n",
      "LOG: Epoch [345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9406\n",
      "Epoch [345/2000], Avg Train Loss: 3.9406\n",
      "Epoch [345/2000], Avg Val Loss: 2.9910\n",
      "Validation loss improved from 2.9919 to 2.9910. Saving model...\n",
      "\n",
      "LOG: Epoch [346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8961\n",
      "Epoch [346/2000], Avg Train Loss: 3.8961\n",
      "Epoch [346/2000], Avg Val Loss: 2.9901\n",
      "Validation loss improved from 2.9910 to 2.9901. Saving model...\n",
      "\n",
      "LOG: Epoch [347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9170\n",
      "Epoch [347/2000], Avg Train Loss: 3.9170\n",
      "Epoch [347/2000], Avg Val Loss: 2.9891\n",
      "Validation loss improved from 2.9901 to 2.9891. Saving model...\n",
      "\n",
      "LOG: Epoch [348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9275\n",
      "Epoch [348/2000], Avg Train Loss: 3.9275\n",
      "Epoch [348/2000], Avg Val Loss: 2.9882\n",
      "Validation loss improved from 2.9891 to 2.9882. Saving model...\n",
      "\n",
      "LOG: Epoch [349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9111\n",
      "Epoch [349/2000], Avg Train Loss: 3.9111\n",
      "Epoch [349/2000], Avg Val Loss: 2.9872\n",
      "Validation loss improved from 2.9882 to 2.9872. Saving model...\n",
      "\n",
      "LOG: Epoch [350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8721\n",
      "Epoch [350/2000], Avg Train Loss: 3.8721\n",
      "Epoch [350/2000], Avg Val Loss: 2.9862\n",
      "Validation loss improved from 2.9872 to 2.9862. Saving model...\n",
      "\n",
      "LOG: Epoch [351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9419\n",
      "Epoch [351/2000], Avg Train Loss: 3.9419\n",
      "Epoch [351/2000], Avg Val Loss: 2.9853\n",
      "Validation loss improved from 2.9862 to 2.9853. Saving model...\n",
      "\n",
      "LOG: Epoch [352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8672\n",
      "Epoch [352/2000], Avg Train Loss: 3.8672\n",
      "Epoch [352/2000], Avg Val Loss: 2.9844\n",
      "Validation loss improved from 2.9853 to 2.9844. Saving model...\n",
      "\n",
      "LOG: Epoch [353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8874\n",
      "Epoch [353/2000], Avg Train Loss: 3.8874\n",
      "Epoch [353/2000], Avg Val Loss: 2.9835\n",
      "Validation loss improved from 2.9844 to 2.9835. Saving model...\n",
      "\n",
      "LOG: Epoch [354/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8704\n",
      "Epoch [354/2000], Avg Train Loss: 3.8704\n",
      "Epoch [354/2000], Avg Val Loss: 2.9826\n",
      "Validation loss improved from 2.9835 to 2.9826. Saving model...\n",
      "\n",
      "LOG: Epoch [355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8812\n",
      "Epoch [355/2000], Avg Train Loss: 3.8812\n",
      "Epoch [355/2000], Avg Val Loss: 2.9817\n",
      "Validation loss improved from 2.9826 to 2.9817. Saving model...\n",
      "\n",
      "LOG: Epoch [356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9116\n",
      "Epoch [356/2000], Avg Train Loss: 3.9116\n",
      "Epoch [356/2000], Avg Val Loss: 2.9807\n",
      "Validation loss improved from 2.9817 to 2.9807. Saving model...\n",
      "\n",
      "LOG: Epoch [357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8881\n",
      "Epoch [357/2000], Avg Train Loss: 3.8881\n",
      "Epoch [357/2000], Avg Val Loss: 2.9798\n",
      "Validation loss improved from 2.9807 to 2.9798. Saving model...\n",
      "\n",
      "LOG: Epoch [358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8847\n",
      "Epoch [358/2000], Avg Train Loss: 3.8847\n",
      "Epoch [358/2000], Avg Val Loss: 2.9790\n",
      "Validation loss improved from 2.9798 to 2.9790. Saving model...\n",
      "\n",
      "LOG: Epoch [359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9072\n",
      "Epoch [359/2000], Avg Train Loss: 3.9072\n",
      "Epoch [359/2000], Avg Val Loss: 2.9781\n",
      "Validation loss improved from 2.9790 to 2.9781. Saving model...\n",
      "\n",
      "LOG: Epoch [360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8449\n",
      "Epoch [360/2000], Avg Train Loss: 3.8449\n",
      "Epoch [360/2000], Avg Val Loss: 2.9772\n",
      "Validation loss improved from 2.9781 to 2.9772. Saving model...\n",
      "\n",
      "LOG: Epoch [361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8663\n",
      "Epoch [361/2000], Avg Train Loss: 3.8663\n",
      "Epoch [361/2000], Avg Val Loss: 2.9763\n",
      "Validation loss improved from 2.9772 to 2.9763. Saving model...\n",
      "\n",
      "LOG: Epoch [362/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9143\n",
      "Epoch [362/2000], Avg Train Loss: 3.9143\n",
      "Epoch [362/2000], Avg Val Loss: 2.9754\n",
      "Validation loss improved from 2.9763 to 2.9754. Saving model...\n",
      "\n",
      "LOG: Epoch [363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8888\n",
      "Epoch [363/2000], Avg Train Loss: 3.8888\n",
      "Epoch [363/2000], Avg Val Loss: 2.9746\n",
      "Validation loss improved from 2.9754 to 2.9746. Saving model...\n",
      "\n",
      "LOG: Epoch [364/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8835\n",
      "Epoch [364/2000], Avg Train Loss: 3.8835\n",
      "Epoch [364/2000], Avg Val Loss: 2.9737\n",
      "Validation loss improved from 2.9746 to 2.9737. Saving model...\n",
      "\n",
      "LOG: Epoch [365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8760\n",
      "Epoch [365/2000], Avg Train Loss: 3.8760\n",
      "Epoch [365/2000], Avg Val Loss: 2.9729\n",
      "Validation loss improved from 2.9737 to 2.9729. Saving model...\n",
      "\n",
      "LOG: Epoch [366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8807\n",
      "Epoch [366/2000], Avg Train Loss: 3.8807\n",
      "Epoch [366/2000], Avg Val Loss: 2.9720\n",
      "Validation loss improved from 2.9729 to 2.9720. Saving model...\n",
      "\n",
      "LOG: Epoch [367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8517\n",
      "Epoch [367/2000], Avg Train Loss: 3.8517\n",
      "Epoch [367/2000], Avg Val Loss: 2.9712\n",
      "Validation loss improved from 2.9720 to 2.9712. Saving model...\n",
      "\n",
      "LOG: Epoch [368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8496\n",
      "Epoch [368/2000], Avg Train Loss: 3.8496\n",
      "Epoch [368/2000], Avg Val Loss: 2.9703\n",
      "Validation loss improved from 2.9712 to 2.9703. Saving model...\n",
      "\n",
      "LOG: Epoch [369/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.8942\n",
      "Epoch [369/2000], Avg Train Loss: 3.8942\n",
      "Epoch [369/2000], Avg Val Loss: 2.9695\n",
      "Validation loss improved from 2.9703 to 2.9695. Saving model...\n",
      "\n",
      "LOG: Epoch [370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8141\n",
      "Epoch [370/2000], Avg Train Loss: 3.8141\n",
      "Epoch [370/2000], Avg Val Loss: 2.9686\n",
      "Validation loss improved from 2.9695 to 2.9686. Saving model...\n",
      "\n",
      "LOG: Epoch [371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8176\n",
      "Epoch [371/2000], Avg Train Loss: 3.8176\n",
      "Epoch [371/2000], Avg Val Loss: 2.9677\n",
      "Validation loss improved from 2.9686 to 2.9677. Saving model...\n",
      "\n",
      "LOG: Epoch [372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.9316\n",
      "Epoch [372/2000], Avg Train Loss: 3.9316\n",
      "Epoch [372/2000], Avg Val Loss: 2.9668\n",
      "Validation loss improved from 2.9677 to 2.9668. Saving model...\n",
      "\n",
      "LOG: Epoch [373/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7926\n",
      "Epoch [373/2000], Avg Train Loss: 3.7926\n",
      "Epoch [373/2000], Avg Val Loss: 2.9659\n",
      "Validation loss improved from 2.9668 to 2.9659. Saving model...\n",
      "\n",
      "LOG: Epoch [374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8696\n",
      "Epoch [374/2000], Avg Train Loss: 3.8696\n",
      "Epoch [374/2000], Avg Val Loss: 2.9651\n",
      "Validation loss improved from 2.9659 to 2.9651. Saving model...\n",
      "\n",
      "LOG: Epoch [375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8545\n",
      "Epoch [375/2000], Avg Train Loss: 3.8545\n",
      "Epoch [375/2000], Avg Val Loss: 2.9643\n",
      "Validation loss improved from 2.9651 to 2.9643. Saving model...\n",
      "\n",
      "LOG: Epoch [376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8720\n",
      "Epoch [376/2000], Avg Train Loss: 3.8720\n",
      "Epoch [376/2000], Avg Val Loss: 2.9635\n",
      "Validation loss improved from 2.9643 to 2.9635. Saving model...\n",
      "\n",
      "LOG: Epoch [377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8774\n",
      "Epoch [377/2000], Avg Train Loss: 3.8774\n",
      "Epoch [377/2000], Avg Val Loss: 2.9626\n",
      "Validation loss improved from 2.9635 to 2.9626. Saving model...\n",
      "\n",
      "LOG: Epoch [378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8212\n",
      "Epoch [378/2000], Avg Train Loss: 3.8212\n",
      "Epoch [378/2000], Avg Val Loss: 2.9618\n",
      "Validation loss improved from 2.9626 to 2.9618. Saving model...\n",
      "\n",
      "LOG: Epoch [379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8495\n",
      "Epoch [379/2000], Avg Train Loss: 3.8495\n",
      "Epoch [379/2000], Avg Val Loss: 2.9609\n",
      "Validation loss improved from 2.9618 to 2.9609. Saving model...\n",
      "\n",
      "LOG: Epoch [380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8710\n",
      "Epoch [380/2000], Avg Train Loss: 3.8710\n",
      "Epoch [380/2000], Avg Val Loss: 2.9601\n",
      "Validation loss improved from 2.9609 to 2.9601. Saving model...\n",
      "\n",
      "LOG: Epoch [381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8397\n",
      "Epoch [381/2000], Avg Train Loss: 3.8397\n",
      "Epoch [381/2000], Avg Val Loss: 2.9592\n",
      "Validation loss improved from 2.9601 to 2.9592. Saving model...\n",
      "\n",
      "LOG: Epoch [382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8412\n",
      "Epoch [382/2000], Avg Train Loss: 3.8412\n",
      "Epoch [382/2000], Avg Val Loss: 2.9583\n",
      "Validation loss improved from 2.9592 to 2.9583. Saving model...\n",
      "\n",
      "LOG: Epoch [383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8288\n",
      "Epoch [383/2000], Avg Train Loss: 3.8288\n",
      "Epoch [383/2000], Avg Val Loss: 2.9573\n",
      "Validation loss improved from 2.9583 to 2.9573. Saving model...\n",
      "\n",
      "LOG: Epoch [384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8482\n",
      "Epoch [384/2000], Avg Train Loss: 3.8482\n",
      "Epoch [384/2000], Avg Val Loss: 2.9564\n",
      "Validation loss improved from 2.9573 to 2.9564. Saving model...\n",
      "\n",
      "LOG: Epoch [385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8729\n",
      "Epoch [385/2000], Avg Train Loss: 3.8729\n",
      "Epoch [385/2000], Avg Val Loss: 2.9555\n",
      "Validation loss improved from 2.9564 to 2.9555. Saving model...\n",
      "\n",
      "LOG: Epoch [386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8394\n",
      "Epoch [386/2000], Avg Train Loss: 3.8394\n",
      "Epoch [386/2000], Avg Val Loss: 2.9546\n",
      "Validation loss improved from 2.9555 to 2.9546. Saving model...\n",
      "\n",
      "LOG: Epoch [387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8788\n",
      "Epoch [387/2000], Avg Train Loss: 3.8788\n",
      "Epoch [387/2000], Avg Val Loss: 2.9538\n",
      "Validation loss improved from 2.9546 to 2.9538. Saving model...\n",
      "\n",
      "LOG: Epoch [388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8322\n",
      "Epoch [388/2000], Avg Train Loss: 3.8322\n",
      "Epoch [388/2000], Avg Val Loss: 2.9530\n",
      "Validation loss improved from 2.9538 to 2.9530. Saving model...\n",
      "\n",
      "LOG: Epoch [389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8383\n",
      "Epoch [389/2000], Avg Train Loss: 3.8383\n",
      "Epoch [389/2000], Avg Val Loss: 2.9522\n",
      "Validation loss improved from 2.9530 to 2.9522. Saving model...\n",
      "\n",
      "LOG: Epoch [390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8707\n",
      "Epoch [390/2000], Avg Train Loss: 3.8707\n",
      "Epoch [390/2000], Avg Val Loss: 2.9514\n",
      "Validation loss improved from 2.9522 to 2.9514. Saving model...\n",
      "\n",
      "LOG: Epoch [391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8237\n",
      "Epoch [391/2000], Avg Train Loss: 3.8237\n",
      "Epoch [391/2000], Avg Val Loss: 2.9506\n",
      "Validation loss improved from 2.9514 to 2.9506. Saving model...\n",
      "\n",
      "LOG: Epoch [392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8595\n",
      "Epoch [392/2000], Avg Train Loss: 3.8595\n",
      "Epoch [392/2000], Avg Val Loss: 2.9498\n",
      "Validation loss improved from 2.9506 to 2.9498. Saving model...\n",
      "\n",
      "LOG: Epoch [393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8404\n",
      "Epoch [393/2000], Avg Train Loss: 3.8404\n",
      "Epoch [393/2000], Avg Val Loss: 2.9490\n",
      "Validation loss improved from 2.9498 to 2.9490. Saving model...\n",
      "\n",
      "LOG: Epoch [394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8307\n",
      "Epoch [394/2000], Avg Train Loss: 3.8307\n",
      "Epoch [394/2000], Avg Val Loss: 2.9481\n",
      "Validation loss improved from 2.9490 to 2.9481. Saving model...\n",
      "\n",
      "LOG: Epoch [395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8693\n",
      "Epoch [395/2000], Avg Train Loss: 3.8693\n",
      "Epoch [395/2000], Avg Val Loss: 2.9473\n",
      "Validation loss improved from 2.9481 to 2.9473. Saving model...\n",
      "\n",
      "LOG: Epoch [396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8362\n",
      "Epoch [396/2000], Avg Train Loss: 3.8362\n",
      "Epoch [396/2000], Avg Val Loss: 2.9464\n",
      "Validation loss improved from 2.9473 to 2.9464. Saving model...\n",
      "\n",
      "LOG: Epoch [397/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7729\n",
      "Epoch [397/2000], Avg Train Loss: 3.7729\n",
      "Epoch [397/2000], Avg Val Loss: 2.9456\n",
      "Validation loss improved from 2.9464 to 2.9456. Saving model...\n",
      "\n",
      "LOG: Epoch [398/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7950\n",
      "Epoch [398/2000], Avg Train Loss: 3.7950\n",
      "Epoch [398/2000], Avg Val Loss: 2.9447\n",
      "Validation loss improved from 2.9456 to 2.9447. Saving model...\n",
      "\n",
      "LOG: Epoch [399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8194\n",
      "Epoch [399/2000], Avg Train Loss: 3.8194\n",
      "Epoch [399/2000], Avg Val Loss: 2.9439\n",
      "Validation loss improved from 2.9447 to 2.9439. Saving model...\n",
      "\n",
      "LOG: Epoch [400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8058\n",
      "Epoch [400/2000], Avg Train Loss: 3.8058\n",
      "Epoch [400/2000], Avg Val Loss: 2.9430\n",
      "Validation loss improved from 2.9439 to 2.9430. Saving model...\n",
      "\n",
      "LOG: Epoch [401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8167\n",
      "Epoch [401/2000], Avg Train Loss: 3.8167\n",
      "Epoch [401/2000], Avg Val Loss: 2.9422\n",
      "Validation loss improved from 2.9430 to 2.9422. Saving model...\n",
      "\n",
      "LOG: Epoch [402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8421\n",
      "Epoch [402/2000], Avg Train Loss: 3.8421\n",
      "Epoch [402/2000], Avg Val Loss: 2.9413\n",
      "Validation loss improved from 2.9422 to 2.9413. Saving model...\n",
      "\n",
      "LOG: Epoch [403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8164\n",
      "Epoch [403/2000], Avg Train Loss: 3.8164\n",
      "Epoch [403/2000], Avg Val Loss: 2.9404\n",
      "Validation loss improved from 2.9413 to 2.9404. Saving model...\n",
      "\n",
      "LOG: Epoch [404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8515\n",
      "Epoch [404/2000], Avg Train Loss: 3.8515\n",
      "Epoch [404/2000], Avg Val Loss: 2.9396\n",
      "Validation loss improved from 2.9404 to 2.9396. Saving model...\n",
      "\n",
      "LOG: Epoch [405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8090\n",
      "Epoch [405/2000], Avg Train Loss: 3.8090\n",
      "Epoch [405/2000], Avg Val Loss: 2.9387\n",
      "Validation loss improved from 2.9396 to 2.9387. Saving model...\n",
      "\n",
      "LOG: Epoch [406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8284\n",
      "Epoch [406/2000], Avg Train Loss: 3.8284\n",
      "Epoch [406/2000], Avg Val Loss: 2.9379\n",
      "Validation loss improved from 2.9387 to 2.9379. Saving model...\n",
      "\n",
      "LOG: Epoch [407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7948\n",
      "Epoch [407/2000], Avg Train Loss: 3.7948\n",
      "Epoch [407/2000], Avg Val Loss: 2.9371\n",
      "Validation loss improved from 2.9379 to 2.9371. Saving model...\n",
      "\n",
      "LOG: Epoch [408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8249\n",
      "Epoch [408/2000], Avg Train Loss: 3.8249\n",
      "Epoch [408/2000], Avg Val Loss: 2.9363\n",
      "Validation loss improved from 2.9371 to 2.9363. Saving model...\n",
      "\n",
      "LOG: Epoch [409/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7768\n",
      "Epoch [409/2000], Avg Train Loss: 3.7768\n",
      "Epoch [409/2000], Avg Val Loss: 2.9355\n",
      "Validation loss improved from 2.9363 to 2.9355. Saving model...\n",
      "\n",
      "LOG: Epoch [410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8347\n",
      "Epoch [410/2000], Avg Train Loss: 3.8347\n",
      "Epoch [410/2000], Avg Val Loss: 2.9348\n",
      "Validation loss improved from 2.9355 to 2.9348. Saving model...\n",
      "\n",
      "LOG: Epoch [411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7958\n",
      "Epoch [411/2000], Avg Train Loss: 3.7958\n",
      "Epoch [411/2000], Avg Val Loss: 2.9340\n",
      "Validation loss improved from 2.9348 to 2.9340. Saving model...\n",
      "\n",
      "LOG: Epoch [412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8474\n",
      "Epoch [412/2000], Avg Train Loss: 3.8474\n",
      "Epoch [412/2000], Avg Val Loss: 2.9333\n",
      "Validation loss improved from 2.9340 to 2.9333. Saving model...\n",
      "\n",
      "LOG: Epoch [413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7740\n",
      "Epoch [413/2000], Avg Train Loss: 3.7740\n",
      "Epoch [413/2000], Avg Val Loss: 2.9325\n",
      "Validation loss improved from 2.9333 to 2.9325. Saving model...\n",
      "\n",
      "LOG: Epoch [414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7809\n",
      "Epoch [414/2000], Avg Train Loss: 3.7809\n",
      "Epoch [414/2000], Avg Val Loss: 2.9317\n",
      "Validation loss improved from 2.9325 to 2.9317. Saving model...\n",
      "\n",
      "LOG: Epoch [415/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7802\n",
      "Epoch [415/2000], Avg Train Loss: 3.7802\n",
      "Epoch [415/2000], Avg Val Loss: 2.9309\n",
      "Validation loss improved from 2.9317 to 2.9309. Saving model...\n",
      "\n",
      "LOG: Epoch [416/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8090\n",
      "Epoch [416/2000], Avg Train Loss: 3.8090\n",
      "Epoch [416/2000], Avg Val Loss: 2.9301\n",
      "Validation loss improved from 2.9309 to 2.9301. Saving model...\n",
      "\n",
      "LOG: Epoch [417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7756\n",
      "Epoch [417/2000], Avg Train Loss: 3.7756\n",
      "Epoch [417/2000], Avg Val Loss: 2.9293\n",
      "Validation loss improved from 2.9301 to 2.9293. Saving model...\n",
      "\n",
      "LOG: Epoch [418/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7050\n",
      "Epoch [418/2000], Avg Train Loss: 3.7050\n",
      "Epoch [418/2000], Avg Val Loss: 2.9286\n",
      "Validation loss improved from 2.9293 to 2.9286. Saving model...\n",
      "\n",
      "LOG: Epoch [419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7848\n",
      "Epoch [419/2000], Avg Train Loss: 3.7848\n",
      "Epoch [419/2000], Avg Val Loss: 2.9278\n",
      "Validation loss improved from 2.9286 to 2.9278. Saving model...\n",
      "\n",
      "LOG: Epoch [420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8034\n",
      "Epoch [420/2000], Avg Train Loss: 3.8034\n",
      "Epoch [420/2000], Avg Val Loss: 2.9271\n",
      "Validation loss improved from 2.9278 to 2.9271. Saving model...\n",
      "\n",
      "LOG: Epoch [421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8100\n",
      "Epoch [421/2000], Avg Train Loss: 3.8100\n",
      "Epoch [421/2000], Avg Val Loss: 2.9264\n",
      "Validation loss improved from 2.9271 to 2.9264. Saving model...\n",
      "\n",
      "LOG: Epoch [422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7842\n",
      "Epoch [422/2000], Avg Train Loss: 3.7842\n",
      "Epoch [422/2000], Avg Val Loss: 2.9257\n",
      "Validation loss improved from 2.9264 to 2.9257. Saving model...\n",
      "\n",
      "LOG: Epoch [423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7317\n",
      "Epoch [423/2000], Avg Train Loss: 3.7317\n",
      "Epoch [423/2000], Avg Val Loss: 2.9250\n",
      "Validation loss improved from 2.9257 to 2.9250. Saving model...\n",
      "\n",
      "LOG: Epoch [424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7646\n",
      "Epoch [424/2000], Avg Train Loss: 3.7646\n",
      "Epoch [424/2000], Avg Val Loss: 2.9243\n",
      "Validation loss improved from 2.9250 to 2.9243. Saving model...\n",
      "\n",
      "LOG: Epoch [425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8299\n",
      "Epoch [425/2000], Avg Train Loss: 3.8299\n",
      "Epoch [425/2000], Avg Val Loss: 2.9236\n",
      "Validation loss improved from 2.9243 to 2.9236. Saving model...\n",
      "\n",
      "LOG: Epoch [426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7390\n",
      "Epoch [426/2000], Avg Train Loss: 3.7390\n",
      "Epoch [426/2000], Avg Val Loss: 2.9229\n",
      "Validation loss improved from 2.9236 to 2.9229. Saving model...\n",
      "\n",
      "LOG: Epoch [427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7625\n",
      "Epoch [427/2000], Avg Train Loss: 3.7625\n",
      "Epoch [427/2000], Avg Val Loss: 2.9222\n",
      "Validation loss improved from 2.9229 to 2.9222. Saving model...\n",
      "\n",
      "LOG: Epoch [428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8475\n",
      "Epoch [428/2000], Avg Train Loss: 3.8475\n",
      "Epoch [428/2000], Avg Val Loss: 2.9214\n",
      "Validation loss improved from 2.9222 to 2.9214. Saving model...\n",
      "\n",
      "LOG: Epoch [429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7884\n",
      "Epoch [429/2000], Avg Train Loss: 3.7884\n",
      "Epoch [429/2000], Avg Val Loss: 2.9207\n",
      "Validation loss improved from 2.9214 to 2.9207. Saving model...\n",
      "\n",
      "LOG: Epoch [430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8021\n",
      "Epoch [430/2000], Avg Train Loss: 3.8021\n",
      "Epoch [430/2000], Avg Val Loss: 2.9200\n",
      "Validation loss improved from 2.9207 to 2.9200. Saving model...\n",
      "\n",
      "LOG: Epoch [431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7460\n",
      "Epoch [431/2000], Avg Train Loss: 3.7460\n",
      "Epoch [431/2000], Avg Val Loss: 2.9193\n",
      "Validation loss improved from 2.9200 to 2.9193. Saving model...\n",
      "\n",
      "LOG: Epoch [432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7795\n",
      "Epoch [432/2000], Avg Train Loss: 3.7795\n",
      "Epoch [432/2000], Avg Val Loss: 2.9186\n",
      "Validation loss improved from 2.9193 to 2.9186. Saving model...\n",
      "\n",
      "LOG: Epoch [433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7621\n",
      "Epoch [433/2000], Avg Train Loss: 3.7621\n",
      "Epoch [433/2000], Avg Val Loss: 2.9180\n",
      "Validation loss improved from 2.9186 to 2.9180. Saving model...\n",
      "\n",
      "LOG: Epoch [434/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7346\n",
      "Epoch [434/2000], Avg Train Loss: 3.7346\n",
      "Epoch [434/2000], Avg Val Loss: 2.9173\n",
      "Validation loss improved from 2.9180 to 2.9173. Saving model...\n",
      "\n",
      "LOG: Epoch [435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7825\n",
      "Epoch [435/2000], Avg Train Loss: 3.7825\n",
      "Epoch [435/2000], Avg Val Loss: 2.9167\n",
      "Validation loss improved from 2.9173 to 2.9167. Saving model...\n",
      "\n",
      "LOG: Epoch [436/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7630\n",
      "Epoch [436/2000], Avg Train Loss: 3.7630\n",
      "Epoch [436/2000], Avg Val Loss: 2.9160\n",
      "Validation loss improved from 2.9167 to 2.9160. Saving model...\n",
      "\n",
      "LOG: Epoch [437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7481\n",
      "Epoch [437/2000], Avg Train Loss: 3.7481\n",
      "Epoch [437/2000], Avg Val Loss: 2.9154\n",
      "Validation loss improved from 2.9160 to 2.9154. Saving model...\n",
      "\n",
      "LOG: Epoch [438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8057\n",
      "Epoch [438/2000], Avg Train Loss: 3.8057\n",
      "Epoch [438/2000], Avg Val Loss: 2.9149\n",
      "Validation loss improved from 2.9154 to 2.9149. Saving model...\n",
      "\n",
      "LOG: Epoch [439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7823\n",
      "Epoch [439/2000], Avg Train Loss: 3.7823\n",
      "Epoch [439/2000], Avg Val Loss: 2.9142\n",
      "Validation loss improved from 2.9149 to 2.9142. Saving model...\n",
      "\n",
      "LOG: Epoch [440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7248\n",
      "Epoch [440/2000], Avg Train Loss: 3.7248\n",
      "Epoch [440/2000], Avg Val Loss: 2.9137\n",
      "Validation loss improved from 2.9142 to 2.9137. Saving model...\n",
      "\n",
      "LOG: Epoch [441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7220\n",
      "Epoch [441/2000], Avg Train Loss: 3.7220\n",
      "Epoch [441/2000], Avg Val Loss: 2.9131\n",
      "Validation loss improved from 2.9137 to 2.9131. Saving model...\n",
      "\n",
      "LOG: Epoch [442/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7159\n",
      "Epoch [442/2000], Avg Train Loss: 3.7159\n",
      "Epoch [442/2000], Avg Val Loss: 2.9125\n",
      "Validation loss improved from 2.9131 to 2.9125. Saving model...\n",
      "\n",
      "LOG: Epoch [443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7355\n",
      "Epoch [443/2000], Avg Train Loss: 3.7355\n",
      "Epoch [443/2000], Avg Val Loss: 2.9119\n",
      "Validation loss improved from 2.9125 to 2.9119. Saving model...\n",
      "\n",
      "LOG: Epoch [444/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7997\n",
      "Epoch [444/2000], Avg Train Loss: 3.7997\n",
      "Epoch [444/2000], Avg Val Loss: 2.9113\n",
      "Validation loss improved from 2.9119 to 2.9113. Saving model...\n",
      "\n",
      "LOG: Epoch [445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8129\n",
      "Epoch [445/2000], Avg Train Loss: 3.8129\n",
      "Epoch [445/2000], Avg Val Loss: 2.9107\n",
      "Validation loss improved from 2.9113 to 2.9107. Saving model...\n",
      "\n",
      "LOG: Epoch [446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7600\n",
      "Epoch [446/2000], Avg Train Loss: 3.7600\n",
      "Epoch [446/2000], Avg Val Loss: 2.9101\n",
      "Validation loss improved from 2.9107 to 2.9101. Saving model...\n",
      "\n",
      "LOG: Epoch [447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7721\n",
      "Epoch [447/2000], Avg Train Loss: 3.7721\n",
      "Epoch [447/2000], Avg Val Loss: 2.9094\n",
      "Validation loss improved from 2.9101 to 2.9094. Saving model...\n",
      "\n",
      "LOG: Epoch [448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7623\n",
      "Epoch [448/2000], Avg Train Loss: 3.7623\n",
      "Epoch [448/2000], Avg Val Loss: 2.9088\n",
      "Validation loss improved from 2.9094 to 2.9088. Saving model...\n",
      "\n",
      "LOG: Epoch [449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7727\n",
      "Epoch [449/2000], Avg Train Loss: 3.7727\n",
      "Epoch [449/2000], Avg Val Loss: 2.9081\n",
      "Validation loss improved from 2.9088 to 2.9081. Saving model...\n",
      "\n",
      "LOG: Epoch [450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7283\n",
      "Epoch [450/2000], Avg Train Loss: 3.7283\n",
      "Epoch [450/2000], Avg Val Loss: 2.9075\n",
      "Validation loss improved from 2.9081 to 2.9075. Saving model...\n",
      "\n",
      "LOG: Epoch [451/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7422\n",
      "Epoch [451/2000], Avg Train Loss: 3.7422\n",
      "Epoch [451/2000], Avg Val Loss: 2.9069\n",
      "Validation loss improved from 2.9075 to 2.9069. Saving model...\n",
      "\n",
      "LOG: Epoch [452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7033\n",
      "Epoch [452/2000], Avg Train Loss: 3.7033\n",
      "Epoch [452/2000], Avg Val Loss: 2.9063\n",
      "Validation loss improved from 2.9069 to 2.9063. Saving model...\n",
      "\n",
      "LOG: Epoch [453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7387\n",
      "Epoch [453/2000], Avg Train Loss: 3.7387\n",
      "Epoch [453/2000], Avg Val Loss: 2.9057\n",
      "Validation loss improved from 2.9063 to 2.9057. Saving model...\n",
      "\n",
      "LOG: Epoch [454/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7446\n",
      "Epoch [454/2000], Avg Train Loss: 3.7446\n",
      "Epoch [454/2000], Avg Val Loss: 2.9050\n",
      "Validation loss improved from 2.9057 to 2.9050. Saving model...\n",
      "\n",
      "LOG: Epoch [455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7136\n",
      "Epoch [455/2000], Avg Train Loss: 3.7136\n",
      "Epoch [455/2000], Avg Val Loss: 2.9044\n",
      "Validation loss improved from 2.9050 to 2.9044. Saving model...\n",
      "\n",
      "LOG: Epoch [456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7405\n",
      "Epoch [456/2000], Avg Train Loss: 3.7405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [456/2000], Avg Val Loss: 2.9038\n",
      "Validation loss improved from 2.9044 to 2.9038. Saving model...\n",
      "\n",
      "LOG: Epoch [457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8036\n",
      "Epoch [457/2000], Avg Train Loss: 3.8036\n",
      "Epoch [457/2000], Avg Val Loss: 2.9032\n",
      "Validation loss improved from 2.9038 to 2.9032. Saving model...\n",
      "\n",
      "LOG: Epoch [458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6859\n",
      "Epoch [458/2000], Avg Train Loss: 3.6859\n",
      "Epoch [458/2000], Avg Val Loss: 2.9026\n",
      "Validation loss improved from 2.9032 to 2.9026. Saving model...\n",
      "\n",
      "LOG: Epoch [459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7085\n",
      "Epoch [459/2000], Avg Train Loss: 3.7085\n",
      "Epoch [459/2000], Avg Val Loss: 2.9019\n",
      "Validation loss improved from 2.9026 to 2.9019. Saving model...\n",
      "\n",
      "LOG: Epoch [460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7591\n",
      "Epoch [460/2000], Avg Train Loss: 3.7591\n",
      "Epoch [460/2000], Avg Val Loss: 2.9014\n",
      "Validation loss improved from 2.9019 to 2.9014. Saving model...\n",
      "\n",
      "LOG: Epoch [461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7485\n",
      "Epoch [461/2000], Avg Train Loss: 3.7485\n",
      "Epoch [461/2000], Avg Val Loss: 2.9008\n",
      "Validation loss improved from 2.9014 to 2.9008. Saving model...\n",
      "\n",
      "LOG: Epoch [462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7306\n",
      "Epoch [462/2000], Avg Train Loss: 3.7306\n",
      "Epoch [462/2000], Avg Val Loss: 2.9002\n",
      "Validation loss improved from 2.9008 to 2.9002. Saving model...\n",
      "\n",
      "LOG: Epoch [463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7216\n",
      "Epoch [463/2000], Avg Train Loss: 3.7216\n",
      "Epoch [463/2000], Avg Val Loss: 2.8997\n",
      "Validation loss improved from 2.9002 to 2.8997. Saving model...\n",
      "\n",
      "LOG: Epoch [464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7336\n",
      "Epoch [464/2000], Avg Train Loss: 3.7336\n",
      "Epoch [464/2000], Avg Val Loss: 2.8991\n",
      "Validation loss improved from 2.8997 to 2.8991. Saving model...\n",
      "\n",
      "LOG: Epoch [465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7218\n",
      "Epoch [465/2000], Avg Train Loss: 3.7218\n",
      "Epoch [465/2000], Avg Val Loss: 2.8985\n",
      "Validation loss improved from 2.8991 to 2.8985. Saving model...\n",
      "\n",
      "LOG: Epoch [466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7394\n",
      "Epoch [466/2000], Avg Train Loss: 3.7394\n",
      "Epoch [466/2000], Avg Val Loss: 2.8979\n",
      "Validation loss improved from 2.8985 to 2.8979. Saving model...\n",
      "\n",
      "LOG: Epoch [467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7206\n",
      "Epoch [467/2000], Avg Train Loss: 3.7206\n",
      "Epoch [467/2000], Avg Val Loss: 2.8974\n",
      "Validation loss improved from 2.8979 to 2.8974. Saving model...\n",
      "\n",
      "LOG: Epoch [468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7157\n",
      "Epoch [468/2000], Avg Train Loss: 3.7157\n",
      "Epoch [468/2000], Avg Val Loss: 2.8968\n",
      "Validation loss improved from 2.8974 to 2.8968. Saving model...\n",
      "\n",
      "LOG: Epoch [469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7927\n",
      "Epoch [469/2000], Avg Train Loss: 3.7927\n",
      "Epoch [469/2000], Avg Val Loss: 2.8962\n",
      "Validation loss improved from 2.8968 to 2.8962. Saving model...\n",
      "\n",
      "LOG: Epoch [470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.8016\n",
      "Epoch [470/2000], Avg Train Loss: 3.8016\n",
      "Epoch [470/2000], Avg Val Loss: 2.8956\n",
      "Validation loss improved from 2.8962 to 2.8956. Saving model...\n",
      "\n",
      "LOG: Epoch [471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7142\n",
      "Epoch [471/2000], Avg Train Loss: 3.7142\n",
      "Epoch [471/2000], Avg Val Loss: 2.8950\n",
      "Validation loss improved from 2.8956 to 2.8950. Saving model...\n",
      "\n",
      "LOG: Epoch [472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7044\n",
      "Epoch [472/2000], Avg Train Loss: 3.7044\n",
      "Epoch [472/2000], Avg Val Loss: 2.8944\n",
      "Validation loss improved from 2.8950 to 2.8944. Saving model...\n",
      "\n",
      "LOG: Epoch [473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7122\n",
      "Epoch [473/2000], Avg Train Loss: 3.7122\n",
      "Epoch [473/2000], Avg Val Loss: 2.8938\n",
      "Validation loss improved from 2.8944 to 2.8938. Saving model...\n",
      "\n",
      "LOG: Epoch [474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7025\n",
      "Epoch [474/2000], Avg Train Loss: 3.7025\n",
      "Epoch [474/2000], Avg Val Loss: 2.8932\n",
      "Validation loss improved from 2.8938 to 2.8932. Saving model...\n",
      "\n",
      "LOG: Epoch [475/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7270\n",
      "Epoch [475/2000], Avg Train Loss: 3.7270\n",
      "Epoch [475/2000], Avg Val Loss: 2.8926\n",
      "Validation loss improved from 2.8932 to 2.8926. Saving model...\n",
      "\n",
      "LOG: Epoch [476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7590\n",
      "Epoch [476/2000], Avg Train Loss: 3.7590\n",
      "Epoch [476/2000], Avg Val Loss: 2.8920\n",
      "Validation loss improved from 2.8926 to 2.8920. Saving model...\n",
      "\n",
      "LOG: Epoch [477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7486\n",
      "Epoch [477/2000], Avg Train Loss: 3.7486\n",
      "Epoch [477/2000], Avg Val Loss: 2.8915\n",
      "Validation loss improved from 2.8920 to 2.8915. Saving model...\n",
      "\n",
      "LOG: Epoch [478/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7389\n",
      "Epoch [478/2000], Avg Train Loss: 3.7389\n",
      "Epoch [478/2000], Avg Val Loss: 2.8909\n",
      "Validation loss improved from 2.8915 to 2.8909. Saving model...\n",
      "\n",
      "LOG: Epoch [479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7168\n",
      "Epoch [479/2000], Avg Train Loss: 3.7168\n",
      "Epoch [479/2000], Avg Val Loss: 2.8904\n",
      "Validation loss improved from 2.8909 to 2.8904. Saving model...\n",
      "\n",
      "LOG: Epoch [480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6906\n",
      "Epoch [480/2000], Avg Train Loss: 3.6906\n",
      "Epoch [480/2000], Avg Val Loss: 2.8898\n",
      "Validation loss improved from 2.8904 to 2.8898. Saving model...\n",
      "\n",
      "LOG: Epoch [481/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6904\n",
      "Epoch [481/2000], Avg Train Loss: 3.6904\n",
      "Epoch [481/2000], Avg Val Loss: 2.8892\n",
      "Validation loss improved from 2.8898 to 2.8892. Saving model...\n",
      "\n",
      "LOG: Epoch [482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6932\n",
      "Epoch [482/2000], Avg Train Loss: 3.6932\n",
      "Epoch [482/2000], Avg Val Loss: 2.8887\n",
      "Validation loss improved from 2.8892 to 2.8887. Saving model...\n",
      "\n",
      "LOG: Epoch [483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7263\n",
      "Epoch [483/2000], Avg Train Loss: 3.7263\n",
      "Epoch [483/2000], Avg Val Loss: 2.8881\n",
      "Validation loss improved from 2.8887 to 2.8881. Saving model...\n",
      "\n",
      "LOG: Epoch [484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7080\n",
      "Epoch [484/2000], Avg Train Loss: 3.7080\n",
      "Epoch [484/2000], Avg Val Loss: 2.8876\n",
      "Validation loss improved from 2.8881 to 2.8876. Saving model...\n",
      "\n",
      "LOG: Epoch [485/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7554\n",
      "Epoch [485/2000], Avg Train Loss: 3.7554\n",
      "Epoch [485/2000], Avg Val Loss: 2.8872\n",
      "Validation loss improved from 2.8876 to 2.8872. Saving model...\n",
      "\n",
      "LOG: Epoch [486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7020\n",
      "Epoch [486/2000], Avg Train Loss: 3.7020\n",
      "Epoch [486/2000], Avg Val Loss: 2.8866\n",
      "Validation loss improved from 2.8872 to 2.8866. Saving model...\n",
      "\n",
      "LOG: Epoch [487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7283\n",
      "Epoch [487/2000], Avg Train Loss: 3.7283\n",
      "Epoch [487/2000], Avg Val Loss: 2.8860\n",
      "Validation loss improved from 2.8866 to 2.8860. Saving model...\n",
      "\n",
      "LOG: Epoch [488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6872\n",
      "Epoch [488/2000], Avg Train Loss: 3.6872\n",
      "Epoch [488/2000], Avg Val Loss: 2.8854\n",
      "Validation loss improved from 2.8860 to 2.8854. Saving model...\n",
      "\n",
      "LOG: Epoch [489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6457\n",
      "Epoch [489/2000], Avg Train Loss: 3.6457\n",
      "Epoch [489/2000], Avg Val Loss: 2.8848\n",
      "Validation loss improved from 2.8854 to 2.8848. Saving model...\n",
      "\n",
      "LOG: Epoch [490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6084\n",
      "Epoch [490/2000], Avg Train Loss: 3.6084\n",
      "Epoch [490/2000], Avg Val Loss: 2.8842\n",
      "Validation loss improved from 2.8848 to 2.8842. Saving model...\n",
      "\n",
      "LOG: Epoch [491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7225\n",
      "Epoch [491/2000], Avg Train Loss: 3.7225\n",
      "Epoch [491/2000], Avg Val Loss: 2.8836\n",
      "Validation loss improved from 2.8842 to 2.8836. Saving model...\n",
      "\n",
      "LOG: Epoch [492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6552\n",
      "Epoch [492/2000], Avg Train Loss: 3.6552\n",
      "Epoch [492/2000], Avg Val Loss: 2.8829\n",
      "Validation loss improved from 2.8836 to 2.8829. Saving model...\n",
      "\n",
      "LOG: Epoch [493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6592\n",
      "Epoch [493/2000], Avg Train Loss: 3.6592\n",
      "Epoch [493/2000], Avg Val Loss: 2.8823\n",
      "Validation loss improved from 2.8829 to 2.8823. Saving model...\n",
      "\n",
      "LOG: Epoch [494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6912\n",
      "Epoch [494/2000], Avg Train Loss: 3.6912\n",
      "Epoch [494/2000], Avg Val Loss: 2.8818\n",
      "Validation loss improved from 2.8823 to 2.8818. Saving model...\n",
      "\n",
      "LOG: Epoch [495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6328\n",
      "Epoch [495/2000], Avg Train Loss: 3.6328\n",
      "Epoch [495/2000], Avg Val Loss: 2.8811\n",
      "Validation loss improved from 2.8818 to 2.8811. Saving model...\n",
      "\n",
      "LOG: Epoch [496/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6517\n",
      "Epoch [496/2000], Avg Train Loss: 3.6517\n",
      "Epoch [496/2000], Avg Val Loss: 2.8805\n",
      "Validation loss improved from 2.8811 to 2.8805. Saving model...\n",
      "\n",
      "LOG: Epoch [497/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6683\n",
      "Epoch [497/2000], Avg Train Loss: 3.6683\n",
      "Epoch [497/2000], Avg Val Loss: 2.8800\n",
      "Validation loss improved from 2.8805 to 2.8800. Saving model...\n",
      "\n",
      "LOG: Epoch [498/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.7458\n",
      "Epoch [498/2000], Avg Train Loss: 3.7458\n",
      "Epoch [498/2000], Avg Val Loss: 2.8794\n",
      "Validation loss improved from 2.8800 to 2.8794. Saving model...\n",
      "\n",
      "LOG: Epoch [499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7049\n",
      "Epoch [499/2000], Avg Train Loss: 3.7049\n",
      "Epoch [499/2000], Avg Val Loss: 2.8790\n",
      "Validation loss improved from 2.8794 to 2.8790. Saving model...\n",
      "\n",
      "LOG: Epoch [500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6930\n",
      "Epoch [500/2000], Avg Train Loss: 3.6930\n",
      "Epoch [500/2000], Avg Val Loss: 2.8784\n",
      "Validation loss improved from 2.8790 to 2.8784. Saving model...\n",
      "\n",
      "LOG: Epoch [501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6914\n",
      "Epoch [501/2000], Avg Train Loss: 3.6914\n",
      "Epoch [501/2000], Avg Val Loss: 2.8779\n",
      "Validation loss improved from 2.8784 to 2.8779. Saving model...\n",
      "\n",
      "LOG: Epoch [502/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6714\n",
      "Epoch [502/2000], Avg Train Loss: 3.6714\n",
      "Epoch [502/2000], Avg Val Loss: 2.8774\n",
      "Validation loss improved from 2.8779 to 2.8774. Saving model...\n",
      "\n",
      "LOG: Epoch [503/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6564\n",
      "Epoch [503/2000], Avg Train Loss: 3.6564\n",
      "Epoch [503/2000], Avg Val Loss: 2.8769\n",
      "Validation loss improved from 2.8774 to 2.8769. Saving model...\n",
      "\n",
      "LOG: Epoch [504/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6582\n",
      "Epoch [504/2000], Avg Train Loss: 3.6582\n",
      "Epoch [504/2000], Avg Val Loss: 2.8764\n",
      "Validation loss improved from 2.8769 to 2.8764. Saving model...\n",
      "\n",
      "LOG: Epoch [505/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6796\n",
      "Epoch [505/2000], Avg Train Loss: 3.6796\n",
      "Epoch [505/2000], Avg Val Loss: 2.8759\n",
      "Validation loss improved from 2.8764 to 2.8759. Saving model...\n",
      "\n",
      "LOG: Epoch [506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6593\n",
      "Epoch [506/2000], Avg Train Loss: 3.6593\n",
      "Epoch [506/2000], Avg Val Loss: 2.8754\n",
      "Validation loss improved from 2.8759 to 2.8754. Saving model...\n",
      "\n",
      "LOG: Epoch [507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6531\n",
      "Epoch [507/2000], Avg Train Loss: 3.6531\n",
      "Epoch [507/2000], Avg Val Loss: 2.8749\n",
      "Validation loss improved from 2.8754 to 2.8749. Saving model...\n",
      "\n",
      "LOG: Epoch [508/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6981\n",
      "Epoch [508/2000], Avg Train Loss: 3.6981\n",
      "Epoch [508/2000], Avg Val Loss: 2.8743\n",
      "Validation loss improved from 2.8749 to 2.8743. Saving model...\n",
      "\n",
      "LOG: Epoch [509/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6349\n",
      "Epoch [509/2000], Avg Train Loss: 3.6349\n",
      "Epoch [509/2000], Avg Val Loss: 2.8738\n",
      "Validation loss improved from 2.8743 to 2.8738. Saving model...\n",
      "\n",
      "LOG: Epoch [510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6471\n",
      "Epoch [510/2000], Avg Train Loss: 3.6471\n",
      "Epoch [510/2000], Avg Val Loss: 2.8732\n",
      "Validation loss improved from 2.8738 to 2.8732. Saving model...\n",
      "\n",
      "LOG: Epoch [511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6938\n",
      "Epoch [511/2000], Avg Train Loss: 3.6938\n",
      "Epoch [511/2000], Avg Val Loss: 2.8727\n",
      "Validation loss improved from 2.8732 to 2.8727. Saving model...\n",
      "\n",
      "LOG: Epoch [512/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6813\n",
      "Epoch [512/2000], Avg Train Loss: 3.6813\n",
      "Epoch [512/2000], Avg Val Loss: 2.8721\n",
      "Validation loss improved from 2.8727 to 2.8721. Saving model...\n",
      "\n",
      "LOG: Epoch [513/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7092\n",
      "Epoch [513/2000], Avg Train Loss: 3.7092\n",
      "Epoch [513/2000], Avg Val Loss: 2.8716\n",
      "Validation loss improved from 2.8721 to 2.8716. Saving model...\n",
      "\n",
      "LOG: Epoch [514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6571\n",
      "Epoch [514/2000], Avg Train Loss: 3.6571\n",
      "Epoch [514/2000], Avg Val Loss: 2.8711\n",
      "Validation loss improved from 2.8716 to 2.8711. Saving model...\n",
      "\n",
      "LOG: Epoch [515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6470\n",
      "Epoch [515/2000], Avg Train Loss: 3.6470\n",
      "Epoch [515/2000], Avg Val Loss: 2.8706\n",
      "Validation loss improved from 2.8711 to 2.8706. Saving model...\n",
      "\n",
      "LOG: Epoch [516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6793\n",
      "Epoch [516/2000], Avg Train Loss: 3.6793\n",
      "Epoch [516/2000], Avg Val Loss: 2.8700\n",
      "Validation loss improved from 2.8706 to 2.8700. Saving model...\n",
      "\n",
      "LOG: Epoch [517/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5986\n",
      "Epoch [517/2000], Avg Train Loss: 3.5986\n",
      "Epoch [517/2000], Avg Val Loss: 2.8695\n",
      "Validation loss improved from 2.8700 to 2.8695. Saving model...\n",
      "\n",
      "LOG: Epoch [518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6656\n",
      "Epoch [518/2000], Avg Train Loss: 3.6656\n",
      "Epoch [518/2000], Avg Val Loss: 2.8690\n",
      "Validation loss improved from 2.8695 to 2.8690. Saving model...\n",
      "\n",
      "LOG: Epoch [519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6238\n",
      "Epoch [519/2000], Avg Train Loss: 3.6238\n",
      "Epoch [519/2000], Avg Val Loss: 2.8685\n",
      "Validation loss improved from 2.8690 to 2.8685. Saving model...\n",
      "\n",
      "LOG: Epoch [520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6709\n",
      "Epoch [520/2000], Avg Train Loss: 3.6709\n",
      "Epoch [520/2000], Avg Val Loss: 2.8680\n",
      "Validation loss improved from 2.8685 to 2.8680. Saving model...\n",
      "\n",
      "LOG: Epoch [521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6408\n",
      "Epoch [521/2000], Avg Train Loss: 3.6408\n",
      "Epoch [521/2000], Avg Val Loss: 2.8674\n",
      "Validation loss improved from 2.8680 to 2.8674. Saving model...\n",
      "\n",
      "LOG: Epoch [522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6857\n",
      "Epoch [522/2000], Avg Train Loss: 3.6857\n",
      "Epoch [522/2000], Avg Val Loss: 2.8669\n",
      "Validation loss improved from 2.8674 to 2.8669. Saving model...\n",
      "\n",
      "LOG: Epoch [523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6182\n",
      "Epoch [523/2000], Avg Train Loss: 3.6182\n",
      "Epoch [523/2000], Avg Val Loss: 2.8664\n",
      "Validation loss improved from 2.8669 to 2.8664. Saving model...\n",
      "\n",
      "LOG: Epoch [524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6654\n",
      "Epoch [524/2000], Avg Train Loss: 3.6654\n",
      "Epoch [524/2000], Avg Val Loss: 2.8659\n",
      "Validation loss improved from 2.8664 to 2.8659. Saving model...\n",
      "\n",
      "LOG: Epoch [525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6024\n",
      "Epoch [525/2000], Avg Train Loss: 3.6024\n",
      "Epoch [525/2000], Avg Val Loss: 2.8653\n",
      "Validation loss improved from 2.8659 to 2.8653. Saving model...\n",
      "\n",
      "LOG: Epoch [526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6861\n",
      "Epoch [526/2000], Avg Train Loss: 3.6861\n",
      "Epoch [526/2000], Avg Val Loss: 2.8647\n",
      "Validation loss improved from 2.8653 to 2.8647. Saving model...\n",
      "\n",
      "LOG: Epoch [527/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6310\n",
      "Epoch [527/2000], Avg Train Loss: 3.6310\n",
      "Epoch [527/2000], Avg Val Loss: 2.8641\n",
      "Validation loss improved from 2.8647 to 2.8641. Saving model...\n",
      "\n",
      "LOG: Epoch [528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6624\n",
      "Epoch [528/2000], Avg Train Loss: 3.6624\n",
      "Epoch [528/2000], Avg Val Loss: 2.8636\n",
      "Validation loss improved from 2.8641 to 2.8636. Saving model...\n",
      "\n",
      "LOG: Epoch [529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6335\n",
      "Epoch [529/2000], Avg Train Loss: 3.6335\n",
      "Epoch [529/2000], Avg Val Loss: 2.8630\n",
      "Validation loss improved from 2.8636 to 2.8630. Saving model...\n",
      "\n",
      "LOG: Epoch [530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6563\n",
      "Epoch [530/2000], Avg Train Loss: 3.6563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [530/2000], Avg Val Loss: 2.8624\n",
      "Validation loss improved from 2.8630 to 2.8624. Saving model...\n",
      "\n",
      "LOG: Epoch [531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6293\n",
      "Epoch [531/2000], Avg Train Loss: 3.6293\n",
      "Epoch [531/2000], Avg Val Loss: 2.8618\n",
      "Validation loss improved from 2.8624 to 2.8618. Saving model...\n",
      "\n",
      "LOG: Epoch [532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5962\n",
      "Epoch [532/2000], Avg Train Loss: 3.5962\n",
      "Epoch [532/2000], Avg Val Loss: 2.8612\n",
      "Validation loss improved from 2.8618 to 2.8612. Saving model...\n",
      "\n",
      "LOG: Epoch [533/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6620\n",
      "Epoch [533/2000], Avg Train Loss: 3.6620\n",
      "Epoch [533/2000], Avg Val Loss: 2.8607\n",
      "Validation loss improved from 2.8612 to 2.8607. Saving model...\n",
      "\n",
      "LOG: Epoch [534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5879\n",
      "Epoch [534/2000], Avg Train Loss: 3.5879\n",
      "Epoch [534/2000], Avg Val Loss: 2.8601\n",
      "Validation loss improved from 2.8607 to 2.8601. Saving model...\n",
      "\n",
      "LOG: Epoch [535/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6476\n",
      "Epoch [535/2000], Avg Train Loss: 3.6476\n",
      "Epoch [535/2000], Avg Val Loss: 2.8595\n",
      "Validation loss improved from 2.8601 to 2.8595. Saving model...\n",
      "\n",
      "LOG: Epoch [536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.7058\n",
      "Epoch [536/2000], Avg Train Loss: 3.7058\n",
      "Epoch [536/2000], Avg Val Loss: 2.8590\n",
      "Validation loss improved from 2.8595 to 2.8590. Saving model...\n",
      "\n",
      "LOG: Epoch [537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6217\n",
      "Epoch [537/2000], Avg Train Loss: 3.6217\n",
      "Epoch [537/2000], Avg Val Loss: 2.8584\n",
      "Validation loss improved from 2.8590 to 2.8584. Saving model...\n",
      "\n",
      "LOG: Epoch [538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6052\n",
      "Epoch [538/2000], Avg Train Loss: 3.6052\n",
      "Epoch [538/2000], Avg Val Loss: 2.8578\n",
      "Validation loss improved from 2.8584 to 2.8578. Saving model...\n",
      "\n",
      "LOG: Epoch [539/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6368\n",
      "Epoch [539/2000], Avg Train Loss: 3.6368\n",
      "Epoch [539/2000], Avg Val Loss: 2.8573\n",
      "Validation loss improved from 2.8578 to 2.8573. Saving model...\n",
      "\n",
      "LOG: Epoch [540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6187\n",
      "Epoch [540/2000], Avg Train Loss: 3.6187\n",
      "Epoch [540/2000], Avg Val Loss: 2.8568\n",
      "Validation loss improved from 2.8573 to 2.8568. Saving model...\n",
      "\n",
      "LOG: Epoch [541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6302\n",
      "Epoch [541/2000], Avg Train Loss: 3.6302\n",
      "Epoch [541/2000], Avg Val Loss: 2.8562\n",
      "Validation loss improved from 2.8568 to 2.8562. Saving model...\n",
      "\n",
      "LOG: Epoch [542/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6342\n",
      "Epoch [542/2000], Avg Train Loss: 3.6342\n",
      "Epoch [542/2000], Avg Val Loss: 2.8556\n",
      "Validation loss improved from 2.8562 to 2.8556. Saving model...\n",
      "\n",
      "LOG: Epoch [543/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5886\n",
      "Epoch [543/2000], Avg Train Loss: 3.5886\n",
      "Epoch [543/2000], Avg Val Loss: 2.8550\n",
      "Validation loss improved from 2.8556 to 2.8550. Saving model...\n",
      "\n",
      "LOG: Epoch [544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6313\n",
      "Epoch [544/2000], Avg Train Loss: 3.6313\n",
      "Epoch [544/2000], Avg Val Loss: 2.8545\n",
      "Validation loss improved from 2.8550 to 2.8545. Saving model...\n",
      "\n",
      "LOG: Epoch [545/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6473\n",
      "Epoch [545/2000], Avg Train Loss: 3.6473\n",
      "Epoch [545/2000], Avg Val Loss: 2.8539\n",
      "Validation loss improved from 2.8545 to 2.8539. Saving model...\n",
      "\n",
      "LOG: Epoch [546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6305\n",
      "Epoch [546/2000], Avg Train Loss: 3.6305\n",
      "Epoch [546/2000], Avg Val Loss: 2.8533\n",
      "Validation loss improved from 2.8539 to 2.8533. Saving model...\n",
      "\n",
      "LOG: Epoch [547/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5708\n",
      "Epoch [547/2000], Avg Train Loss: 3.5708\n",
      "Epoch [547/2000], Avg Val Loss: 2.8526\n",
      "Validation loss improved from 2.8533 to 2.8526. Saving model...\n",
      "\n",
      "LOG: Epoch [548/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5607\n",
      "Epoch [548/2000], Avg Train Loss: 3.5607\n",
      "Epoch [548/2000], Avg Val Loss: 2.8520\n",
      "Validation loss improved from 2.8526 to 2.8520. Saving model...\n",
      "\n",
      "LOG: Epoch [549/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6705\n",
      "Epoch [549/2000], Avg Train Loss: 3.6705\n",
      "Epoch [549/2000], Avg Val Loss: 2.8513\n",
      "Validation loss improved from 2.8520 to 2.8513. Saving model...\n",
      "\n",
      "LOG: Epoch [550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6670\n",
      "Epoch [550/2000], Avg Train Loss: 3.6670\n",
      "Epoch [550/2000], Avg Val Loss: 2.8507\n",
      "Validation loss improved from 2.8513 to 2.8507. Saving model...\n",
      "\n",
      "LOG: Epoch [551/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5785\n",
      "Epoch [551/2000], Avg Train Loss: 3.5785\n",
      "Epoch [551/2000], Avg Val Loss: 2.8501\n",
      "Validation loss improved from 2.8507 to 2.8501. Saving model...\n",
      "\n",
      "LOG: Epoch [552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5921\n",
      "Epoch [552/2000], Avg Train Loss: 3.5921\n",
      "Epoch [552/2000], Avg Val Loss: 2.8496\n",
      "Validation loss improved from 2.8501 to 2.8496. Saving model...\n",
      "\n",
      "LOG: Epoch [553/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6015\n",
      "Epoch [553/2000], Avg Train Loss: 3.6015\n",
      "Epoch [553/2000], Avg Val Loss: 2.8491\n",
      "Validation loss improved from 2.8496 to 2.8491. Saving model...\n",
      "\n",
      "LOG: Epoch [554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6308\n",
      "Epoch [554/2000], Avg Train Loss: 3.6308\n",
      "Epoch [554/2000], Avg Val Loss: 2.8486\n",
      "Validation loss improved from 2.8491 to 2.8486. Saving model...\n",
      "\n",
      "LOG: Epoch [555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5753\n",
      "Epoch [555/2000], Avg Train Loss: 3.5753\n",
      "Epoch [555/2000], Avg Val Loss: 2.8482\n",
      "Validation loss improved from 2.8486 to 2.8482. Saving model...\n",
      "\n",
      "LOG: Epoch [556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6135\n",
      "Epoch [556/2000], Avg Train Loss: 3.6135\n",
      "Epoch [556/2000], Avg Val Loss: 2.8476\n",
      "Validation loss improved from 2.8482 to 2.8476. Saving model...\n",
      "\n",
      "LOG: Epoch [557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5786\n",
      "Epoch [557/2000], Avg Train Loss: 3.5786\n",
      "Epoch [557/2000], Avg Val Loss: 2.8471\n",
      "Validation loss improved from 2.8476 to 2.8471. Saving model...\n",
      "\n",
      "LOG: Epoch [558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6407\n",
      "Epoch [558/2000], Avg Train Loss: 3.6407\n",
      "Epoch [558/2000], Avg Val Loss: 2.8465\n",
      "Validation loss improved from 2.8471 to 2.8465. Saving model...\n",
      "\n",
      "LOG: Epoch [559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6182\n",
      "Epoch [559/2000], Avg Train Loss: 3.6182\n",
      "Epoch [559/2000], Avg Val Loss: 2.8460\n",
      "Validation loss improved from 2.8465 to 2.8460. Saving model...\n",
      "\n",
      "LOG: Epoch [560/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5788\n",
      "Epoch [560/2000], Avg Train Loss: 3.5788\n",
      "Epoch [560/2000], Avg Val Loss: 2.8454\n",
      "Validation loss improved from 2.8460 to 2.8454. Saving model...\n",
      "\n",
      "LOG: Epoch [561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5321\n",
      "Epoch [561/2000], Avg Train Loss: 3.5321\n",
      "Epoch [561/2000], Avg Val Loss: 2.8449\n",
      "Validation loss improved from 2.8454 to 2.8449. Saving model...\n",
      "\n",
      "LOG: Epoch [562/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6039\n",
      "Epoch [562/2000], Avg Train Loss: 3.6039\n",
      "Epoch [562/2000], Avg Val Loss: 2.8445\n",
      "Validation loss improved from 2.8449 to 2.8445. Saving model...\n",
      "\n",
      "LOG: Epoch [563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6541\n",
      "Epoch [563/2000], Avg Train Loss: 3.6541\n",
      "Epoch [563/2000], Avg Val Loss: 2.8441\n",
      "Validation loss improved from 2.8445 to 2.8441. Saving model...\n",
      "\n",
      "LOG: Epoch [564/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6026\n",
      "Epoch [564/2000], Avg Train Loss: 3.6026\n",
      "Epoch [564/2000], Avg Val Loss: 2.8437\n",
      "Validation loss improved from 2.8441 to 2.8437. Saving model...\n",
      "\n",
      "LOG: Epoch [565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6186\n",
      "Epoch [565/2000], Avg Train Loss: 3.6186\n",
      "Epoch [565/2000], Avg Val Loss: 2.8433\n",
      "Validation loss improved from 2.8437 to 2.8433. Saving model...\n",
      "\n",
      "LOG: Epoch [566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5757\n",
      "Epoch [566/2000], Avg Train Loss: 3.5757\n",
      "Epoch [566/2000], Avg Val Loss: 2.8428\n",
      "Validation loss improved from 2.8433 to 2.8428. Saving model...\n",
      "\n",
      "LOG: Epoch [567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5602\n",
      "Epoch [567/2000], Avg Train Loss: 3.5602\n",
      "Epoch [567/2000], Avg Val Loss: 2.8423\n",
      "Validation loss improved from 2.8428 to 2.8423. Saving model...\n",
      "\n",
      "LOG: Epoch [568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5578\n",
      "Epoch [568/2000], Avg Train Loss: 3.5578\n",
      "Epoch [568/2000], Avg Val Loss: 2.8417\n",
      "Validation loss improved from 2.8423 to 2.8417. Saving model...\n",
      "\n",
      "LOG: Epoch [569/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5863\n",
      "Epoch [569/2000], Avg Train Loss: 3.5863\n",
      "Epoch [569/2000], Avg Val Loss: 2.8411\n",
      "Validation loss improved from 2.8417 to 2.8411. Saving model...\n",
      "\n",
      "LOG: Epoch [570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5765\n",
      "Epoch [570/2000], Avg Train Loss: 3.5765\n",
      "Epoch [570/2000], Avg Val Loss: 2.8405\n",
      "Validation loss improved from 2.8411 to 2.8405. Saving model...\n",
      "\n",
      "LOG: Epoch [571/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6276\n",
      "Epoch [571/2000], Avg Train Loss: 3.6276\n",
      "Epoch [571/2000], Avg Val Loss: 2.8401\n",
      "Validation loss improved from 2.8405 to 2.8401. Saving model...\n",
      "\n",
      "LOG: Epoch [572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5531\n",
      "Epoch [572/2000], Avg Train Loss: 3.5531\n",
      "Epoch [572/2000], Avg Val Loss: 2.8396\n",
      "Validation loss improved from 2.8401 to 2.8396. Saving model...\n",
      "\n",
      "LOG: Epoch [573/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5474\n",
      "Epoch [573/2000], Avg Train Loss: 3.5474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [573/2000], Avg Val Loss: 2.8392\n",
      "Validation loss improved from 2.8396 to 2.8392. Saving model...\n",
      "\n",
      "LOG: Epoch [574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6113\n",
      "Epoch [574/2000], Avg Train Loss: 3.6113\n",
      "Epoch [574/2000], Avg Val Loss: 2.8388\n",
      "Validation loss improved from 2.8392 to 2.8388. Saving model...\n",
      "\n",
      "LOG: Epoch [575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5771\n",
      "Epoch [575/2000], Avg Train Loss: 3.5771\n",
      "Epoch [575/2000], Avg Val Loss: 2.8383\n",
      "Validation loss improved from 2.8388 to 2.8383. Saving model...\n",
      "\n",
      "LOG: Epoch [576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5195\n",
      "Epoch [576/2000], Avg Train Loss: 3.5195\n",
      "Epoch [576/2000], Avg Val Loss: 2.8379\n",
      "Validation loss improved from 2.8383 to 2.8379. Saving model...\n",
      "\n",
      "LOG: Epoch [577/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5950\n",
      "Epoch [577/2000], Avg Train Loss: 3.5950\n",
      "Epoch [577/2000], Avg Val Loss: 2.8375\n",
      "Validation loss improved from 2.8379 to 2.8375. Saving model...\n",
      "\n",
      "LOG: Epoch [578/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5333\n",
      "Epoch [578/2000], Avg Train Loss: 3.5333\n",
      "Epoch [578/2000], Avg Val Loss: 2.8370\n",
      "Validation loss improved from 2.8375 to 2.8370. Saving model...\n",
      "\n",
      "LOG: Epoch [579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5723\n",
      "Epoch [579/2000], Avg Train Loss: 3.5723\n",
      "Epoch [579/2000], Avg Val Loss: 2.8365\n",
      "Validation loss improved from 2.8370 to 2.8365. Saving model...\n",
      "\n",
      "LOG: Epoch [580/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5677\n",
      "Epoch [580/2000], Avg Train Loss: 3.5677\n",
      "Epoch [580/2000], Avg Val Loss: 2.8359\n",
      "Validation loss improved from 2.8365 to 2.8359. Saving model...\n",
      "\n",
      "LOG: Epoch [581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5119\n",
      "Epoch [581/2000], Avg Train Loss: 3.5119\n",
      "Epoch [581/2000], Avg Val Loss: 2.8354\n",
      "Validation loss improved from 2.8359 to 2.8354. Saving model...\n",
      "\n",
      "LOG: Epoch [582/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6022\n",
      "Epoch [582/2000], Avg Train Loss: 3.6022\n",
      "Epoch [582/2000], Avg Val Loss: 2.8348\n",
      "Validation loss improved from 2.8354 to 2.8348. Saving model...\n",
      "\n",
      "LOG: Epoch [583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5326\n",
      "Epoch [583/2000], Avg Train Loss: 3.5326\n",
      "Epoch [583/2000], Avg Val Loss: 2.8343\n",
      "Validation loss improved from 2.8348 to 2.8343. Saving model...\n",
      "\n",
      "LOG: Epoch [584/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4876\n",
      "Epoch [584/2000], Avg Train Loss: 3.4876\n",
      "Epoch [584/2000], Avg Val Loss: 2.8337\n",
      "Validation loss improved from 2.8343 to 2.8337. Saving model...\n",
      "\n",
      "LOG: Epoch [585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5854\n",
      "Epoch [585/2000], Avg Train Loss: 3.5854\n",
      "Epoch [585/2000], Avg Val Loss: 2.8331\n",
      "Validation loss improved from 2.8337 to 2.8331. Saving model...\n",
      "\n",
      "LOG: Epoch [586/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5743\n",
      "Epoch [586/2000], Avg Train Loss: 3.5743\n",
      "Epoch [586/2000], Avg Val Loss: 2.8325\n",
      "Validation loss improved from 2.8331 to 2.8325. Saving model...\n",
      "\n",
      "LOG: Epoch [587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5559\n",
      "Epoch [587/2000], Avg Train Loss: 3.5559\n",
      "Epoch [587/2000], Avg Val Loss: 2.8319\n",
      "Validation loss improved from 2.8325 to 2.8319. Saving model...\n",
      "\n",
      "LOG: Epoch [588/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5536\n",
      "Epoch [588/2000], Avg Train Loss: 3.5536\n",
      "Epoch [588/2000], Avg Val Loss: 2.8314\n",
      "Validation loss improved from 2.8319 to 2.8314. Saving model...\n",
      "\n",
      "LOG: Epoch [589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5558\n",
      "Epoch [589/2000], Avg Train Loss: 3.5558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [589/2000], Avg Val Loss: 2.8308\n",
      "Validation loss improved from 2.8314 to 2.8308. Saving model...\n",
      "\n",
      "LOG: Epoch [590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5934\n",
      "Epoch [590/2000], Avg Train Loss: 3.5934\n",
      "Epoch [590/2000], Avg Val Loss: 2.8303\n",
      "Validation loss improved from 2.8308 to 2.8303. Saving model...\n",
      "\n",
      "LOG: Epoch [591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6043\n",
      "Epoch [591/2000], Avg Train Loss: 3.6043\n",
      "Epoch [591/2000], Avg Val Loss: 2.8298\n",
      "Validation loss improved from 2.8303 to 2.8298. Saving model...\n",
      "\n",
      "LOG: Epoch [592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5795\n",
      "Epoch [592/2000], Avg Train Loss: 3.5795\n",
      "Epoch [592/2000], Avg Val Loss: 2.8293\n",
      "Validation loss improved from 2.8298 to 2.8293. Saving model...\n",
      "\n",
      "LOG: Epoch [593/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5902\n",
      "Epoch [593/2000], Avg Train Loss: 3.5902\n",
      "Epoch [593/2000], Avg Val Loss: 2.8289\n",
      "Validation loss improved from 2.8293 to 2.8289. Saving model...\n",
      "\n",
      "LOG: Epoch [594/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5596\n",
      "Epoch [594/2000], Avg Train Loss: 3.5596\n",
      "Epoch [594/2000], Avg Val Loss: 2.8284\n",
      "Validation loss improved from 2.8289 to 2.8284. Saving model...\n",
      "\n",
      "LOG: Epoch [595/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6101\n",
      "Epoch [595/2000], Avg Train Loss: 3.6101\n",
      "Epoch [595/2000], Avg Val Loss: 2.8280\n",
      "Validation loss improved from 2.8284 to 2.8280. Saving model...\n",
      "\n",
      "LOG: Epoch [596/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5182\n",
      "Epoch [596/2000], Avg Train Loss: 3.5182\n",
      "Epoch [596/2000], Avg Val Loss: 2.8277\n",
      "Validation loss improved from 2.8280 to 2.8277. Saving model...\n",
      "\n",
      "LOG: Epoch [597/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5483\n",
      "Epoch [597/2000], Avg Train Loss: 3.5483\n",
      "Epoch [597/2000], Avg Val Loss: 2.8273\n",
      "Validation loss improved from 2.8277 to 2.8273. Saving model...\n",
      "\n",
      "LOG: Epoch [598/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.6021\n",
      "Epoch [598/2000], Avg Train Loss: 3.6021\n",
      "Epoch [598/2000], Avg Val Loss: 2.8270\n",
      "Validation loss improved from 2.8273 to 2.8270. Saving model...\n",
      "\n",
      "LOG: Epoch [599/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5574\n",
      "Epoch [599/2000], Avg Train Loss: 3.5574\n",
      "Epoch [599/2000], Avg Val Loss: 2.8268\n",
      "Validation loss improved from 2.8270 to 2.8268. Saving model...\n",
      "\n",
      "LOG: Epoch [600/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5707\n",
      "Epoch [600/2000], Avg Train Loss: 3.5707\n",
      "Epoch [600/2000], Avg Val Loss: 2.8266\n",
      "Validation loss improved from 2.8268 to 2.8266. Saving model...\n",
      "\n",
      "LOG: Epoch [601/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5460\n",
      "Epoch [601/2000], Avg Train Loss: 3.5460\n",
      "Epoch [601/2000], Avg Val Loss: 2.8264\n",
      "Validation loss improved from 2.8266 to 2.8264. Saving model...\n",
      "\n",
      "LOG: Epoch [602/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4969\n",
      "Epoch [602/2000], Avg Train Loss: 3.4969\n",
      "Epoch [602/2000], Avg Val Loss: 2.8262\n",
      "Validation loss improved from 2.8264 to 2.8262. Saving model...\n",
      "\n",
      "LOG: Epoch [603/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5787\n",
      "Epoch [603/2000], Avg Train Loss: 3.5787\n",
      "Epoch [603/2000], Avg Val Loss: 2.8259\n",
      "Validation loss improved from 2.8262 to 2.8259. Saving model...\n",
      "\n",
      "LOG: Epoch [604/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5349\n",
      "Epoch [604/2000], Avg Train Loss: 3.5349\n",
      "Epoch [604/2000], Avg Val Loss: 2.8256\n",
      "Validation loss improved from 2.8259 to 2.8256. Saving model...\n",
      "\n",
      "LOG: Epoch [605/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5818\n",
      "Epoch [605/2000], Avg Train Loss: 3.5818\n",
      "Epoch [605/2000], Avg Val Loss: 2.8253\n",
      "Validation loss improved from 2.8256 to 2.8253. Saving model...\n",
      "\n",
      "LOG: Epoch [606/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5249\n",
      "Epoch [606/2000], Avg Train Loss: 3.5249\n",
      "Epoch [606/2000], Avg Val Loss: 2.8250\n",
      "Validation loss improved from 2.8253 to 2.8250. Saving model...\n",
      "\n",
      "LOG: Epoch [607/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5531\n",
      "Epoch [607/2000], Avg Train Loss: 3.5531\n",
      "Epoch [607/2000], Avg Val Loss: 2.8248\n",
      "Validation loss improved from 2.8250 to 2.8248. Saving model...\n",
      "\n",
      "LOG: Epoch [608/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5433\n",
      "Epoch [608/2000], Avg Train Loss: 3.5433\n",
      "Epoch [608/2000], Avg Val Loss: 2.8245\n",
      "Validation loss improved from 2.8248 to 2.8245. Saving model...\n",
      "\n",
      "LOG: Epoch [609/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5590\n",
      "Epoch [609/2000], Avg Train Loss: 3.5590\n",
      "Epoch [609/2000], Avg Val Loss: 2.8243\n",
      "Validation loss improved from 2.8245 to 2.8243. Saving model...\n",
      "\n",
      "LOG: Epoch [610/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5923\n",
      "Epoch [610/2000], Avg Train Loss: 3.5923\n",
      "Epoch [610/2000], Avg Val Loss: 2.8240\n",
      "Validation loss improved from 2.8243 to 2.8240. Saving model...\n",
      "\n",
      "LOG: Epoch [611/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5492\n",
      "Epoch [611/2000], Avg Train Loss: 3.5492\n",
      "Epoch [611/2000], Avg Val Loss: 2.8238\n",
      "Validation loss improved from 2.8240 to 2.8238. Saving model...\n",
      "\n",
      "LOG: Epoch [612/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5263\n",
      "Epoch [612/2000], Avg Train Loss: 3.5263\n",
      "Epoch [612/2000], Avg Val Loss: 2.8235\n",
      "Validation loss improved from 2.8238 to 2.8235. Saving model...\n",
      "\n",
      "LOG: Epoch [613/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4994\n",
      "Epoch [613/2000], Avg Train Loss: 3.4994\n",
      "Epoch [613/2000], Avg Val Loss: 2.8233\n",
      "Validation loss improved from 2.8235 to 2.8233. Saving model...\n",
      "\n",
      "LOG: Epoch [614/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5272\n",
      "Epoch [614/2000], Avg Train Loss: 3.5272\n",
      "Epoch [614/2000], Avg Val Loss: 2.8230\n",
      "Validation loss improved from 2.8233 to 2.8230. Saving model...\n",
      "\n",
      "LOG: Epoch [615/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.5925\n",
      "Epoch [615/2000], Avg Train Loss: 3.5925\n",
      "Epoch [615/2000], Avg Val Loss: 2.8227\n",
      "Validation loss improved from 2.8230 to 2.8227. Saving model...\n",
      "\n",
      "LOG: Epoch [616/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5699\n",
      "Epoch [616/2000], Avg Train Loss: 3.5699\n",
      "Epoch [616/2000], Avg Val Loss: 2.8224\n",
      "Validation loss improved from 2.8227 to 2.8224. Saving model...\n",
      "\n",
      "LOG: Epoch [617/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5130\n",
      "Epoch [617/2000], Avg Train Loss: 3.5130\n",
      "Epoch [617/2000], Avg Val Loss: 2.8220\n",
      "Validation loss improved from 2.8224 to 2.8220. Saving model...\n",
      "\n",
      "LOG: Epoch [618/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4974\n",
      "Epoch [618/2000], Avg Train Loss: 3.4974\n",
      "Epoch [618/2000], Avg Val Loss: 2.8217\n",
      "Validation loss improved from 2.8220 to 2.8217. Saving model...\n",
      "\n",
      "LOG: Epoch [619/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5332\n",
      "Epoch [619/2000], Avg Train Loss: 3.5332\n",
      "Epoch [619/2000], Avg Val Loss: 2.8214\n",
      "Validation loss improved from 2.8217 to 2.8214. Saving model...\n",
      "\n",
      "LOG: Epoch [620/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5695\n",
      "Epoch [620/2000], Avg Train Loss: 3.5695\n",
      "Epoch [620/2000], Avg Val Loss: 2.8210\n",
      "Validation loss improved from 2.8214 to 2.8210. Saving model...\n",
      "\n",
      "LOG: Epoch [621/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5713\n",
      "Epoch [621/2000], Avg Train Loss: 3.5713\n",
      "Epoch [621/2000], Avg Val Loss: 2.8207\n",
      "Validation loss improved from 2.8210 to 2.8207. Saving model...\n",
      "\n",
      "LOG: Epoch [622/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4926\n",
      "Epoch [622/2000], Avg Train Loss: 3.4926\n",
      "Epoch [622/2000], Avg Val Loss: 2.8203\n",
      "Validation loss improved from 2.8207 to 2.8203. Saving model...\n",
      "\n",
      "LOG: Epoch [623/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5234\n",
      "Epoch [623/2000], Avg Train Loss: 3.5234\n",
      "Epoch [623/2000], Avg Val Loss: 2.8199\n",
      "Validation loss improved from 2.8203 to 2.8199. Saving model...\n",
      "\n",
      "LOG: Epoch [624/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5132\n",
      "Epoch [624/2000], Avg Train Loss: 3.5132\n",
      "Epoch [624/2000], Avg Val Loss: 2.8195\n",
      "Validation loss improved from 2.8199 to 2.8195. Saving model...\n",
      "\n",
      "LOG: Epoch [625/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4932\n",
      "Epoch [625/2000], Avg Train Loss: 3.4932\n",
      "Epoch [625/2000], Avg Val Loss: 2.8191\n",
      "Validation loss improved from 2.8195 to 2.8191. Saving model...\n",
      "\n",
      "LOG: Epoch [626/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5167\n",
      "Epoch [626/2000], Avg Train Loss: 3.5167\n",
      "Epoch [626/2000], Avg Val Loss: 2.8187\n",
      "Validation loss improved from 2.8191 to 2.8187. Saving model...\n",
      "\n",
      "LOG: Epoch [627/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5549\n",
      "Epoch [627/2000], Avg Train Loss: 3.5549\n",
      "Epoch [627/2000], Avg Val Loss: 2.8184\n",
      "Validation loss improved from 2.8187 to 2.8184. Saving model...\n",
      "\n",
      "LOG: Epoch [628/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5170\n",
      "Epoch [628/2000], Avg Train Loss: 3.5170\n",
      "Epoch [628/2000], Avg Val Loss: 2.8180\n",
      "Validation loss improved from 2.8184 to 2.8180. Saving model...\n",
      "\n",
      "LOG: Epoch [629/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5236\n",
      "Epoch [629/2000], Avg Train Loss: 3.5236\n",
      "Epoch [629/2000], Avg Val Loss: 2.8177\n",
      "Validation loss improved from 2.8180 to 2.8177. Saving model...\n",
      "\n",
      "LOG: Epoch [630/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5560\n",
      "Epoch [630/2000], Avg Train Loss: 3.5560\n",
      "Epoch [630/2000], Avg Val Loss: 2.8173\n",
      "Validation loss improved from 2.8177 to 2.8173. Saving model...\n",
      "\n",
      "LOG: Epoch [631/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5069\n",
      "Epoch [631/2000], Avg Train Loss: 3.5069\n",
      "Epoch [631/2000], Avg Val Loss: 2.8169\n",
      "Validation loss improved from 2.8173 to 2.8169. Saving model...\n",
      "\n",
      "LOG: Epoch [632/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4907\n",
      "Epoch [632/2000], Avg Train Loss: 3.4907\n",
      "Epoch [632/2000], Avg Val Loss: 2.8166\n",
      "Validation loss improved from 2.8169 to 2.8166. Saving model...\n",
      "\n",
      "LOG: Epoch [633/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5475\n",
      "Epoch [633/2000], Avg Train Loss: 3.5475\n",
      "Epoch [633/2000], Avg Val Loss: 2.8163\n",
      "Validation loss improved from 2.8166 to 2.8163. Saving model...\n",
      "\n",
      "LOG: Epoch [634/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4616\n",
      "Epoch [634/2000], Avg Train Loss: 3.4616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [634/2000], Avg Val Loss: 2.8159\n",
      "Validation loss improved from 2.8163 to 2.8159. Saving model...\n",
      "\n",
      "LOG: Epoch [635/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5072\n",
      "Epoch [635/2000], Avg Train Loss: 3.5072\n",
      "Epoch [635/2000], Avg Val Loss: 2.8155\n",
      "Validation loss improved from 2.8159 to 2.8155. Saving model...\n",
      "\n",
      "LOG: Epoch [636/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5614\n",
      "Epoch [636/2000], Avg Train Loss: 3.5614\n",
      "Epoch [636/2000], Avg Val Loss: 2.8151\n",
      "Validation loss improved from 2.8155 to 2.8151. Saving model...\n",
      "\n",
      "LOG: Epoch [637/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5420\n",
      "Epoch [637/2000], Avg Train Loss: 3.5420\n",
      "Epoch [637/2000], Avg Val Loss: 2.8147\n",
      "Validation loss improved from 2.8151 to 2.8147. Saving model...\n",
      "\n",
      "LOG: Epoch [638/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4917\n",
      "Epoch [638/2000], Avg Train Loss: 3.4917\n",
      "Epoch [638/2000], Avg Val Loss: 2.8143\n",
      "Validation loss improved from 2.8147 to 2.8143. Saving model...\n",
      "\n",
      "LOG: Epoch [639/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4563\n",
      "Epoch [639/2000], Avg Train Loss: 3.4563\n",
      "Epoch [639/2000], Avg Val Loss: 2.8139\n",
      "Validation loss improved from 2.8143 to 2.8139. Saving model...\n",
      "\n",
      "LOG: Epoch [640/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4866\n",
      "Epoch [640/2000], Avg Train Loss: 3.4866\n",
      "Epoch [640/2000], Avg Val Loss: 2.8134\n",
      "Validation loss improved from 2.8139 to 2.8134. Saving model...\n",
      "\n",
      "LOG: Epoch [641/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4882\n",
      "Epoch [641/2000], Avg Train Loss: 3.4882\n",
      "Epoch [641/2000], Avg Val Loss: 2.8128\n",
      "Validation loss improved from 2.8134 to 2.8128. Saving model...\n",
      "\n",
      "LOG: Epoch [642/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4529\n",
      "Epoch [642/2000], Avg Train Loss: 3.4529\n",
      "Epoch [642/2000], Avg Val Loss: 2.8123\n",
      "Validation loss improved from 2.8128 to 2.8123. Saving model...\n",
      "\n",
      "LOG: Epoch [643/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5225\n",
      "Epoch [643/2000], Avg Train Loss: 3.5225\n",
      "Epoch [643/2000], Avg Val Loss: 2.8118\n",
      "Validation loss improved from 2.8123 to 2.8118. Saving model...\n",
      "\n",
      "LOG: Epoch [644/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5555\n",
      "Epoch [644/2000], Avg Train Loss: 3.5555\n",
      "Epoch [644/2000], Avg Val Loss: 2.8114\n",
      "Validation loss improved from 2.8118 to 2.8114. Saving model...\n",
      "\n",
      "LOG: Epoch [645/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4392\n",
      "Epoch [645/2000], Avg Train Loss: 3.4392\n",
      "Epoch [645/2000], Avg Val Loss: 2.8110\n",
      "Validation loss improved from 2.8114 to 2.8110. Saving model...\n",
      "\n",
      "LOG: Epoch [646/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5219\n",
      "Epoch [646/2000], Avg Train Loss: 3.5219\n",
      "Epoch [646/2000], Avg Val Loss: 2.8105\n",
      "Validation loss improved from 2.8110 to 2.8105. Saving model...\n",
      "\n",
      "LOG: Epoch [647/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5485\n",
      "Epoch [647/2000], Avg Train Loss: 3.5485\n",
      "Epoch [647/2000], Avg Val Loss: 2.8101\n",
      "Validation loss improved from 2.8105 to 2.8101. Saving model...\n",
      "\n",
      "LOG: Epoch [648/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4820\n",
      "Epoch [648/2000], Avg Train Loss: 3.4820\n",
      "Epoch [648/2000], Avg Val Loss: 2.8098\n",
      "Validation loss improved from 2.8101 to 2.8098. Saving model...\n",
      "\n",
      "LOG: Epoch [649/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4768\n",
      "Epoch [649/2000], Avg Train Loss: 3.4768\n",
      "Epoch [649/2000], Avg Val Loss: 2.8095\n",
      "Validation loss improved from 2.8098 to 2.8095. Saving model...\n",
      "\n",
      "LOG: Epoch [650/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4939\n",
      "Epoch [650/2000], Avg Train Loss: 3.4939\n",
      "Epoch [650/2000], Avg Val Loss: 2.8092\n",
      "Validation loss improved from 2.8095 to 2.8092. Saving model...\n",
      "\n",
      "LOG: Epoch [651/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5201\n",
      "Epoch [651/2000], Avg Train Loss: 3.5201\n",
      "Epoch [651/2000], Avg Val Loss: 2.8089\n",
      "Validation loss improved from 2.8092 to 2.8089. Saving model...\n",
      "\n",
      "LOG: Epoch [652/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5251\n",
      "Epoch [652/2000], Avg Train Loss: 3.5251\n",
      "Epoch [652/2000], Avg Val Loss: 2.8085\n",
      "Validation loss improved from 2.8089 to 2.8085. Saving model...\n",
      "\n",
      "LOG: Epoch [653/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4949\n",
      "Epoch [653/2000], Avg Train Loss: 3.4949\n",
      "Epoch [653/2000], Avg Val Loss: 2.8082\n",
      "Validation loss improved from 2.8085 to 2.8082. Saving model...\n",
      "\n",
      "LOG: Epoch [654/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5370\n",
      "Epoch [654/2000], Avg Train Loss: 3.5370\n",
      "Epoch [654/2000], Avg Val Loss: 2.8078\n",
      "Validation loss improved from 2.8082 to 2.8078. Saving model...\n",
      "\n",
      "LOG: Epoch [655/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5118\n",
      "Epoch [655/2000], Avg Train Loss: 3.5118\n",
      "Epoch [655/2000], Avg Val Loss: 2.8075\n",
      "Validation loss improved from 2.8078 to 2.8075. Saving model...\n",
      "\n",
      "LOG: Epoch [656/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4543\n",
      "Epoch [656/2000], Avg Train Loss: 3.4543\n",
      "Epoch [656/2000], Avg Val Loss: 2.8072\n",
      "Validation loss improved from 2.8075 to 2.8072. Saving model...\n",
      "\n",
      "LOG: Epoch [657/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4588\n",
      "Epoch [657/2000], Avg Train Loss: 3.4588\n",
      "Epoch [657/2000], Avg Val Loss: 2.8070\n",
      "Validation loss improved from 2.8072 to 2.8070. Saving model...\n",
      "\n",
      "LOG: Epoch [658/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5212\n",
      "Epoch [658/2000], Avg Train Loss: 3.5212\n",
      "Epoch [658/2000], Avg Val Loss: 2.8067\n",
      "Validation loss improved from 2.8070 to 2.8067. Saving model...\n",
      "\n",
      "LOG: Epoch [659/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4587\n",
      "Epoch [659/2000], Avg Train Loss: 3.4587\n",
      "Epoch [659/2000], Avg Val Loss: 2.8065\n",
      "Validation loss improved from 2.8067 to 2.8065. Saving model...\n",
      "\n",
      "LOG: Epoch [660/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5006\n",
      "Epoch [660/2000], Avg Train Loss: 3.5006\n",
      "Epoch [660/2000], Avg Val Loss: 2.8063\n",
      "Validation loss improved from 2.8065 to 2.8063. Saving model...\n",
      "\n",
      "LOG: Epoch [661/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4786\n",
      "Epoch [661/2000], Avg Train Loss: 3.4786\n",
      "Epoch [661/2000], Avg Val Loss: 2.8060\n",
      "Validation loss improved from 2.8063 to 2.8060. Saving model...\n",
      "\n",
      "LOG: Epoch [662/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5319\n",
      "Epoch [662/2000], Avg Train Loss: 3.5319\n",
      "Epoch [662/2000], Avg Val Loss: 2.8057\n",
      "Validation loss improved from 2.8060 to 2.8057. Saving model...\n",
      "\n",
      "LOG: Epoch [663/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4435\n",
      "Epoch [663/2000], Avg Train Loss: 3.4435\n",
      "Epoch [663/2000], Avg Val Loss: 2.8055\n",
      "Validation loss improved from 2.8057 to 2.8055. Saving model...\n",
      "\n",
      "LOG: Epoch [664/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4914\n",
      "Epoch [664/2000], Avg Train Loss: 3.4914\n",
      "Epoch [664/2000], Avg Val Loss: 2.8053\n",
      "Validation loss improved from 2.8055 to 2.8053. Saving model...\n",
      "\n",
      "LOG: Epoch [665/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5381\n",
      "Epoch [665/2000], Avg Train Loss: 3.5381\n",
      "Epoch [665/2000], Avg Val Loss: 2.8051\n",
      "Validation loss improved from 2.8053 to 2.8051. Saving model...\n",
      "\n",
      "LOG: Epoch [666/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5023\n",
      "Epoch [666/2000], Avg Train Loss: 3.5023\n",
      "Epoch [666/2000], Avg Val Loss: 2.8049\n",
      "Validation loss improved from 2.8051 to 2.8049. Saving model...\n",
      "\n",
      "LOG: Epoch [667/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5130\n",
      "Epoch [667/2000], Avg Train Loss: 3.5130\n",
      "Epoch [667/2000], Avg Val Loss: 2.8047\n",
      "Validation loss improved from 2.8049 to 2.8047. Saving model...\n",
      "\n",
      "LOG: Epoch [668/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4224\n",
      "Epoch [668/2000], Avg Train Loss: 3.4224\n",
      "Epoch [668/2000], Avg Val Loss: 2.8044\n",
      "Validation loss improved from 2.8047 to 2.8044. Saving model...\n",
      "\n",
      "LOG: Epoch [669/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4643\n",
      "Epoch [669/2000], Avg Train Loss: 3.4643\n",
      "Epoch [669/2000], Avg Val Loss: 2.8040\n",
      "Validation loss improved from 2.8044 to 2.8040. Saving model...\n",
      "\n",
      "LOG: Epoch [670/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4662\n",
      "Epoch [670/2000], Avg Train Loss: 3.4662\n",
      "Epoch [670/2000], Avg Val Loss: 2.8036\n",
      "Validation loss improved from 2.8040 to 2.8036. Saving model...\n",
      "\n",
      "LOG: Epoch [671/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4423\n",
      "Epoch [671/2000], Avg Train Loss: 3.4423\n",
      "Epoch [671/2000], Avg Val Loss: 2.8032\n",
      "Validation loss improved from 2.8036 to 2.8032. Saving model...\n",
      "\n",
      "LOG: Epoch [672/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4320\n",
      "Epoch [672/2000], Avg Train Loss: 3.4320\n",
      "Epoch [672/2000], Avg Val Loss: 2.8029\n",
      "Validation loss improved from 2.8032 to 2.8029. Saving model...\n",
      "\n",
      "LOG: Epoch [673/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4744\n",
      "Epoch [673/2000], Avg Train Loss: 3.4744\n",
      "Epoch [673/2000], Avg Val Loss: 2.8025\n",
      "Validation loss improved from 2.8029 to 2.8025. Saving model...\n",
      "\n",
      "LOG: Epoch [674/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5015\n",
      "Epoch [674/2000], Avg Train Loss: 3.5015\n",
      "Epoch [674/2000], Avg Val Loss: 2.8021\n",
      "Validation loss improved from 2.8025 to 2.8021. Saving model...\n",
      "\n",
      "LOG: Epoch [675/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4700\n",
      "Epoch [675/2000], Avg Train Loss: 3.4700\n",
      "Epoch [675/2000], Avg Val Loss: 2.8018\n",
      "Validation loss improved from 2.8021 to 2.8018. Saving model...\n",
      "\n",
      "LOG: Epoch [676/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4396\n",
      "Epoch [676/2000], Avg Train Loss: 3.4396\n",
      "Epoch [676/2000], Avg Val Loss: 2.8013\n",
      "Validation loss improved from 2.8018 to 2.8013. Saving model...\n",
      "\n",
      "LOG: Epoch [677/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4864\n",
      "Epoch [677/2000], Avg Train Loss: 3.4864\n",
      "Epoch [677/2000], Avg Val Loss: 2.8009\n",
      "Validation loss improved from 2.8013 to 2.8009. Saving model...\n",
      "\n",
      "LOG: Epoch [678/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4176\n",
      "Epoch [678/2000], Avg Train Loss: 3.4176\n",
      "Epoch [678/2000], Avg Val Loss: 2.8005\n",
      "Validation loss improved from 2.8009 to 2.8005. Saving model...\n",
      "\n",
      "LOG: Epoch [679/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5317\n",
      "Epoch [679/2000], Avg Train Loss: 3.5317\n",
      "Epoch [679/2000], Avg Val Loss: 2.8000\n",
      "Validation loss improved from 2.8005 to 2.8000. Saving model...\n",
      "\n",
      "LOG: Epoch [680/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4642\n",
      "Epoch [680/2000], Avg Train Loss: 3.4642\n",
      "Epoch [680/2000], Avg Val Loss: 2.7997\n",
      "Validation loss improved from 2.8000 to 2.7997. Saving model...\n",
      "\n",
      "LOG: Epoch [681/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4591\n",
      "Epoch [681/2000], Avg Train Loss: 3.4591\n",
      "Epoch [681/2000], Avg Val Loss: 2.7993\n",
      "Validation loss improved from 2.7997 to 2.7993. Saving model...\n",
      "\n",
      "LOG: Epoch [682/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4420\n",
      "Epoch [682/2000], Avg Train Loss: 3.4420\n",
      "Epoch [682/2000], Avg Val Loss: 2.7990\n",
      "Validation loss improved from 2.7993 to 2.7990. Saving model...\n",
      "\n",
      "LOG: Epoch [683/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4698\n",
      "Epoch [683/2000], Avg Train Loss: 3.4698\n",
      "Epoch [683/2000], Avg Val Loss: 2.7988\n",
      "Validation loss improved from 2.7990 to 2.7988. Saving model...\n",
      "\n",
      "LOG: Epoch [684/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4478\n",
      "Epoch [684/2000], Avg Train Loss: 3.4478\n",
      "Epoch [684/2000], Avg Val Loss: 2.7984\n",
      "Validation loss improved from 2.7988 to 2.7984. Saving model...\n",
      "\n",
      "LOG: Epoch [685/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5327\n",
      "Epoch [685/2000], Avg Train Loss: 3.5327\n",
      "Epoch [685/2000], Avg Val Loss: 2.7981\n",
      "Validation loss improved from 2.7984 to 2.7981. Saving model...\n",
      "\n",
      "LOG: Epoch [686/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4732\n",
      "Epoch [686/2000], Avg Train Loss: 3.4732\n",
      "Epoch [686/2000], Avg Val Loss: 2.7978\n",
      "Validation loss improved from 2.7981 to 2.7978. Saving model...\n",
      "\n",
      "LOG: Epoch [687/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5010\n",
      "Epoch [687/2000], Avg Train Loss: 3.5010\n",
      "Epoch [687/2000], Avg Val Loss: 2.7974\n",
      "Validation loss improved from 2.7978 to 2.7974. Saving model...\n",
      "\n",
      "LOG: Epoch [688/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4354\n",
      "Epoch [688/2000], Avg Train Loss: 3.4354\n",
      "Epoch [688/2000], Avg Val Loss: 2.7970\n",
      "Validation loss improved from 2.7974 to 2.7970. Saving model...\n",
      "\n",
      "LOG: Epoch [689/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4143\n",
      "Epoch [689/2000], Avg Train Loss: 3.4143\n",
      "Epoch [689/2000], Avg Val Loss: 2.7966\n",
      "Validation loss improved from 2.7970 to 2.7966. Saving model...\n",
      "\n",
      "LOG: Epoch [690/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4607\n",
      "Epoch [690/2000], Avg Train Loss: 3.4607\n",
      "Epoch [690/2000], Avg Val Loss: 2.7962\n",
      "Validation loss improved from 2.7966 to 2.7962. Saving model...\n",
      "\n",
      "LOG: Epoch [691/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4403\n",
      "Epoch [691/2000], Avg Train Loss: 3.4403\n",
      "Epoch [691/2000], Avg Val Loss: 2.7959\n",
      "Validation loss improved from 2.7962 to 2.7959. Saving model...\n",
      "\n",
      "LOG: Epoch [692/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4746\n",
      "Epoch [692/2000], Avg Train Loss: 3.4746\n",
      "Epoch [692/2000], Avg Val Loss: 2.7957\n",
      "Validation loss improved from 2.7959 to 2.7957. Saving model...\n",
      "\n",
      "LOG: Epoch [693/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4761\n",
      "Epoch [693/2000], Avg Train Loss: 3.4761\n",
      "Epoch [693/2000], Avg Val Loss: 2.7955\n",
      "Validation loss improved from 2.7957 to 2.7955. Saving model...\n",
      "\n",
      "LOG: Epoch [694/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4384\n",
      "Epoch [694/2000], Avg Train Loss: 3.4384\n",
      "Epoch [694/2000], Avg Val Loss: 2.7952\n",
      "Validation loss improved from 2.7955 to 2.7952. Saving model...\n",
      "\n",
      "LOG: Epoch [695/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4711\n",
      "Epoch [695/2000], Avg Train Loss: 3.4711\n",
      "Epoch [695/2000], Avg Val Loss: 2.7949\n",
      "Validation loss improved from 2.7952 to 2.7949. Saving model...\n",
      "\n",
      "LOG: Epoch [696/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4277\n",
      "Epoch [696/2000], Avg Train Loss: 3.4277\n",
      "Epoch [696/2000], Avg Val Loss: 2.7946\n",
      "Validation loss improved from 2.7949 to 2.7946. Saving model...\n",
      "\n",
      "LOG: Epoch [697/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4728\n",
      "Epoch [697/2000], Avg Train Loss: 3.4728\n",
      "Epoch [697/2000], Avg Val Loss: 2.7944\n",
      "Validation loss improved from 2.7946 to 2.7944. Saving model...\n",
      "\n",
      "LOG: Epoch [698/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4275\n",
      "Epoch [698/2000], Avg Train Loss: 3.4275\n",
      "Epoch [698/2000], Avg Val Loss: 2.7941\n",
      "Validation loss improved from 2.7944 to 2.7941. Saving model...\n",
      "\n",
      "LOG: Epoch [699/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4058\n",
      "Epoch [699/2000], Avg Train Loss: 3.4058\n",
      "Epoch [699/2000], Avg Val Loss: 2.7937\n",
      "Validation loss improved from 2.7941 to 2.7937. Saving model...\n",
      "\n",
      "LOG: Epoch [700/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4484\n",
      "Epoch [700/2000], Avg Train Loss: 3.4484\n",
      "Epoch [700/2000], Avg Val Loss: 2.7934\n",
      "Validation loss improved from 2.7937 to 2.7934. Saving model...\n",
      "\n",
      "LOG: Epoch [701/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4470\n",
      "Epoch [701/2000], Avg Train Loss: 3.4470\n",
      "Epoch [701/2000], Avg Val Loss: 2.7931\n",
      "Validation loss improved from 2.7934 to 2.7931. Saving model...\n",
      "\n",
      "LOG: Epoch [702/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.5116\n",
      "Epoch [702/2000], Avg Train Loss: 3.5116\n",
      "Epoch [702/2000], Avg Val Loss: 2.7928\n",
      "Validation loss improved from 2.7931 to 2.7928. Saving model...\n",
      "\n",
      "LOG: Epoch [703/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4855\n",
      "Epoch [703/2000], Avg Train Loss: 3.4855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [703/2000], Avg Val Loss: 2.7925\n",
      "Validation loss improved from 2.7928 to 2.7925. Saving model...\n",
      "\n",
      "LOG: Epoch [704/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4710\n",
      "Epoch [704/2000], Avg Train Loss: 3.4710\n",
      "Epoch [704/2000], Avg Val Loss: 2.7922\n",
      "Validation loss improved from 2.7925 to 2.7922. Saving model...\n",
      "\n",
      "LOG: Epoch [705/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4437\n",
      "Epoch [705/2000], Avg Train Loss: 3.4437\n",
      "Epoch [705/2000], Avg Val Loss: 2.7919\n",
      "Validation loss improved from 2.7922 to 2.7919. Saving model...\n",
      "\n",
      "LOG: Epoch [706/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4236\n",
      "Epoch [706/2000], Avg Train Loss: 3.4236\n",
      "Epoch [706/2000], Avg Val Loss: 2.7917\n",
      "Validation loss improved from 2.7919 to 2.7917. Saving model...\n",
      "\n",
      "LOG: Epoch [707/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4103\n",
      "Epoch [707/2000], Avg Train Loss: 3.4103\n",
      "Epoch [707/2000], Avg Val Loss: 2.7914\n",
      "Validation loss improved from 2.7917 to 2.7914. Saving model...\n",
      "\n",
      "LOG: Epoch [708/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3827\n",
      "Epoch [708/2000], Avg Train Loss: 3.3827\n",
      "Epoch [708/2000], Avg Val Loss: 2.7911\n",
      "Validation loss improved from 2.7914 to 2.7911. Saving model...\n",
      "\n",
      "LOG: Epoch [709/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4501\n",
      "Epoch [709/2000], Avg Train Loss: 3.4501\n",
      "Epoch [709/2000], Avg Val Loss: 2.7908\n",
      "Validation loss improved from 2.7911 to 2.7908. Saving model...\n",
      "\n",
      "LOG: Epoch [710/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4083\n",
      "Epoch [710/2000], Avg Train Loss: 3.4083\n",
      "Epoch [710/2000], Avg Val Loss: 2.7904\n",
      "Validation loss improved from 2.7908 to 2.7904. Saving model...\n",
      "\n",
      "LOG: Epoch [711/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4406\n",
      "Epoch [711/2000], Avg Train Loss: 3.4406\n",
      "Epoch [711/2000], Avg Val Loss: 2.7901\n",
      "Validation loss improved from 2.7904 to 2.7901. Saving model...\n",
      "\n",
      "LOG: Epoch [712/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4434\n",
      "Epoch [712/2000], Avg Train Loss: 3.4434\n",
      "Epoch [712/2000], Avg Val Loss: 2.7897\n",
      "Validation loss improved from 2.7901 to 2.7897. Saving model...\n",
      "\n",
      "LOG: Epoch [713/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4232\n",
      "Epoch [713/2000], Avg Train Loss: 3.4232\n",
      "Epoch [713/2000], Avg Val Loss: 2.7894\n",
      "Validation loss improved from 2.7897 to 2.7894. Saving model...\n",
      "\n",
      "LOG: Epoch [714/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4509\n",
      "Epoch [714/2000], Avg Train Loss: 3.4509\n",
      "Epoch [714/2000], Avg Val Loss: 2.7891\n",
      "Validation loss improved from 2.7894 to 2.7891. Saving model...\n",
      "\n",
      "LOG: Epoch [715/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4484\n",
      "Epoch [715/2000], Avg Train Loss: 3.4484\n",
      "Epoch [715/2000], Avg Val Loss: 2.7889\n",
      "Validation loss improved from 2.7891 to 2.7889. Saving model...\n",
      "\n",
      "LOG: Epoch [716/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4061\n",
      "Epoch [716/2000], Avg Train Loss: 3.4061\n",
      "Epoch [716/2000], Avg Val Loss: 2.7886\n",
      "Validation loss improved from 2.7889 to 2.7886. Saving model...\n",
      "\n",
      "LOG: Epoch [717/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4542\n",
      "Epoch [717/2000], Avg Train Loss: 3.4542\n",
      "Epoch [717/2000], Avg Val Loss: 2.7883\n",
      "Validation loss improved from 2.7886 to 2.7883. Saving model...\n",
      "\n",
      "LOG: Epoch [718/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4244\n",
      "Epoch [718/2000], Avg Train Loss: 3.4244\n",
      "Epoch [718/2000], Avg Val Loss: 2.7880\n",
      "Validation loss improved from 2.7883 to 2.7880. Saving model...\n",
      "\n",
      "LOG: Epoch [719/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4715\n",
      "Epoch [719/2000], Avg Train Loss: 3.4715\n",
      "Epoch [719/2000], Avg Val Loss: 2.7878\n",
      "Validation loss improved from 2.7880 to 2.7878. Saving model...\n",
      "\n",
      "LOG: Epoch [720/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4051\n",
      "Epoch [720/2000], Avg Train Loss: 3.4051\n",
      "Epoch [720/2000], Avg Val Loss: 2.7877\n",
      "Validation loss improved from 2.7878 to 2.7877. Saving model...\n",
      "\n",
      "LOG: Epoch [721/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4177\n",
      "Epoch [721/2000], Avg Train Loss: 3.4177\n",
      "Epoch [721/2000], Avg Val Loss: 2.7875\n",
      "Validation loss improved from 2.7877 to 2.7875. Saving model...\n",
      "\n",
      "LOG: Epoch [722/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4219\n",
      "Epoch [722/2000], Avg Train Loss: 3.4219\n",
      "Epoch [722/2000], Avg Val Loss: 2.7872\n",
      "Validation loss improved from 2.7875 to 2.7872. Saving model...\n",
      "\n",
      "LOG: Epoch [723/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4308\n",
      "Epoch [723/2000], Avg Train Loss: 3.4308\n",
      "Epoch [723/2000], Avg Val Loss: 2.7870\n",
      "Validation loss improved from 2.7872 to 2.7870. Saving model...\n",
      "\n",
      "LOG: Epoch [724/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4095\n",
      "Epoch [724/2000], Avg Train Loss: 3.4095\n",
      "Epoch [724/2000], Avg Val Loss: 2.7868\n",
      "Validation loss improved from 2.7870 to 2.7868. Saving model...\n",
      "\n",
      "LOG: Epoch [725/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3854\n",
      "Epoch [725/2000], Avg Train Loss: 3.3854\n",
      "Epoch [725/2000], Avg Val Loss: 2.7866\n",
      "Validation loss improved from 2.7868 to 2.7866. Saving model...\n",
      "\n",
      "LOG: Epoch [726/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4840\n",
      "Epoch [726/2000], Avg Train Loss: 3.4840\n",
      "Epoch [726/2000], Avg Val Loss: 2.7863\n",
      "Validation loss improved from 2.7866 to 2.7863. Saving model...\n",
      "\n",
      "LOG: Epoch [727/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3677\n",
      "Epoch [727/2000], Avg Train Loss: 3.3677\n",
      "Epoch [727/2000], Avg Val Loss: 2.7860\n",
      "Validation loss improved from 2.7863 to 2.7860. Saving model...\n",
      "\n",
      "LOG: Epoch [728/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4415\n",
      "Epoch [728/2000], Avg Train Loss: 3.4415\n",
      "Epoch [728/2000], Avg Val Loss: 2.7857\n",
      "Validation loss improved from 2.7860 to 2.7857. Saving model...\n",
      "\n",
      "LOG: Epoch [729/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4336\n",
      "Epoch [729/2000], Avg Train Loss: 3.4336\n",
      "Epoch [729/2000], Avg Val Loss: 2.7855\n",
      "Validation loss improved from 2.7857 to 2.7855. Saving model...\n",
      "\n",
      "LOG: Epoch [730/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3984\n",
      "Epoch [730/2000], Avg Train Loss: 3.3984\n",
      "Epoch [730/2000], Avg Val Loss: 2.7853\n",
      "Validation loss improved from 2.7855 to 2.7853. Saving model...\n",
      "\n",
      "LOG: Epoch [731/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4031\n",
      "Epoch [731/2000], Avg Train Loss: 3.4031\n",
      "Epoch [731/2000], Avg Val Loss: 2.7851\n",
      "Validation loss improved from 2.7853 to 2.7851. Saving model...\n",
      "\n",
      "LOG: Epoch [732/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4471\n",
      "Epoch [732/2000], Avg Train Loss: 3.4471\n",
      "Epoch [732/2000], Avg Val Loss: 2.7849\n",
      "Validation loss improved from 2.7851 to 2.7849. Saving model...\n",
      "\n",
      "LOG: Epoch [733/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4464\n",
      "Epoch [733/2000], Avg Train Loss: 3.4464\n",
      "Epoch [733/2000], Avg Val Loss: 2.7845\n",
      "Validation loss improved from 2.7849 to 2.7845. Saving model...\n",
      "\n",
      "LOG: Epoch [734/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4282\n",
      "Epoch [734/2000], Avg Train Loss: 3.4282\n",
      "Epoch [734/2000], Avg Val Loss: 2.7841\n",
      "Validation loss improved from 2.7845 to 2.7841. Saving model...\n",
      "\n",
      "LOG: Epoch [735/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4328\n",
      "Epoch [735/2000], Avg Train Loss: 3.4328\n",
      "Epoch [735/2000], Avg Val Loss: 2.7838\n",
      "Validation loss improved from 2.7841 to 2.7838. Saving model...\n",
      "\n",
      "LOG: Epoch [736/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4470\n",
      "Epoch [736/2000], Avg Train Loss: 3.4470\n",
      "Epoch [736/2000], Avg Val Loss: 2.7835\n",
      "Validation loss improved from 2.7838 to 2.7835. Saving model...\n",
      "\n",
      "LOG: Epoch [737/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4566\n",
      "Epoch [737/2000], Avg Train Loss: 3.4566\n",
      "Epoch [737/2000], Avg Val Loss: 2.7833\n",
      "Validation loss improved from 2.7835 to 2.7833. Saving model...\n",
      "\n",
      "LOG: Epoch [738/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3546\n",
      "Epoch [738/2000], Avg Train Loss: 3.3546\n",
      "Epoch [738/2000], Avg Val Loss: 2.7830\n",
      "Validation loss improved from 2.7833 to 2.7830. Saving model...\n",
      "\n",
      "LOG: Epoch [739/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4155\n",
      "Epoch [739/2000], Avg Train Loss: 3.4155\n",
      "Epoch [739/2000], Avg Val Loss: 2.7826\n",
      "Validation loss improved from 2.7830 to 2.7826. Saving model...\n",
      "\n",
      "LOG: Epoch [740/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4308\n",
      "Epoch [740/2000], Avg Train Loss: 3.4308\n",
      "Epoch [740/2000], Avg Val Loss: 2.7822\n",
      "Validation loss improved from 2.7826 to 2.7822. Saving model...\n",
      "\n",
      "LOG: Epoch [741/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3590\n",
      "Epoch [741/2000], Avg Train Loss: 3.3590\n",
      "Epoch [741/2000], Avg Val Loss: 2.7818\n",
      "Validation loss improved from 2.7822 to 2.7818. Saving model...\n",
      "\n",
      "LOG: Epoch [742/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4555\n",
      "Epoch [742/2000], Avg Train Loss: 3.4555\n",
      "Epoch [742/2000], Avg Val Loss: 2.7814\n",
      "Validation loss improved from 2.7818 to 2.7814. Saving model...\n",
      "\n",
      "LOG: Epoch [743/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4913\n",
      "Epoch [743/2000], Avg Train Loss: 3.4913\n",
      "Epoch [743/2000], Avg Val Loss: 2.7812\n",
      "Validation loss improved from 2.7814 to 2.7812. Saving model...\n",
      "\n",
      "LOG: Epoch [744/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3708\n",
      "Epoch [744/2000], Avg Train Loss: 3.3708\n",
      "Epoch [744/2000], Avg Val Loss: 2.7808\n",
      "Validation loss improved from 2.7812 to 2.7808. Saving model...\n",
      "\n",
      "LOG: Epoch [745/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4014\n",
      "Epoch [745/2000], Avg Train Loss: 3.4014\n",
      "Epoch [745/2000], Avg Val Loss: 2.7804\n",
      "Validation loss improved from 2.7808 to 2.7804. Saving model...\n",
      "\n",
      "LOG: Epoch [746/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3844\n",
      "Epoch [746/2000], Avg Train Loss: 3.3844\n",
      "Epoch [746/2000], Avg Val Loss: 2.7799\n",
      "Validation loss improved from 2.7804 to 2.7799. Saving model...\n",
      "\n",
      "LOG: Epoch [747/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4135\n",
      "Epoch [747/2000], Avg Train Loss: 3.4135\n",
      "Epoch [747/2000], Avg Val Loss: 2.7794\n",
      "Validation loss improved from 2.7799 to 2.7794. Saving model...\n",
      "\n",
      "LOG: Epoch [748/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.4016\n",
      "Epoch [748/2000], Avg Train Loss: 3.4016\n",
      "Epoch [748/2000], Avg Val Loss: 2.7790\n",
      "Validation loss improved from 2.7794 to 2.7790. Saving model...\n",
      "\n",
      "LOG: Epoch [749/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4414\n",
      "Epoch [749/2000], Avg Train Loss: 3.4414\n",
      "Epoch [749/2000], Avg Val Loss: 2.7785\n",
      "Validation loss improved from 2.7790 to 2.7785. Saving model...\n",
      "\n",
      "LOG: Epoch [750/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3872\n",
      "Epoch [750/2000], Avg Train Loss: 3.3872\n",
      "Epoch [750/2000], Avg Val Loss: 2.7780\n",
      "Validation loss improved from 2.7785 to 2.7780. Saving model...\n",
      "\n",
      "LOG: Epoch [751/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4591\n",
      "Epoch [751/2000], Avg Train Loss: 3.4591\n",
      "Epoch [751/2000], Avg Val Loss: 2.7776\n",
      "Validation loss improved from 2.7780 to 2.7776. Saving model...\n",
      "\n",
      "LOG: Epoch [752/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3847\n",
      "Epoch [752/2000], Avg Train Loss: 3.3847\n",
      "Epoch [752/2000], Avg Val Loss: 2.7771\n",
      "Validation loss improved from 2.7776 to 2.7771. Saving model...\n",
      "\n",
      "LOG: Epoch [753/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4062\n",
      "Epoch [753/2000], Avg Train Loss: 3.4062\n",
      "Epoch [753/2000], Avg Val Loss: 2.7767\n",
      "Validation loss improved from 2.7771 to 2.7767. Saving model...\n",
      "\n",
      "LOG: Epoch [754/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3891\n",
      "Epoch [754/2000], Avg Train Loss: 3.3891\n",
      "Epoch [754/2000], Avg Val Loss: 2.7762\n",
      "Validation loss improved from 2.7767 to 2.7762. Saving model...\n",
      "\n",
      "LOG: Epoch [755/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4082\n",
      "Epoch [755/2000], Avg Train Loss: 3.4082\n",
      "Epoch [755/2000], Avg Val Loss: 2.7757\n",
      "Validation loss improved from 2.7762 to 2.7757. Saving model...\n",
      "\n",
      "LOG: Epoch [756/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4436\n",
      "Epoch [756/2000], Avg Train Loss: 3.4436\n",
      "Epoch [756/2000], Avg Val Loss: 2.7752\n",
      "Validation loss improved from 2.7757 to 2.7752. Saving model...\n",
      "\n",
      "LOG: Epoch [757/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4012\n",
      "Epoch [757/2000], Avg Train Loss: 3.4012\n",
      "Epoch [757/2000], Avg Val Loss: 2.7748\n",
      "Validation loss improved from 2.7752 to 2.7748. Saving model...\n",
      "\n",
      "LOG: Epoch [758/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3771\n",
      "Epoch [758/2000], Avg Train Loss: 3.3771\n",
      "Epoch [758/2000], Avg Val Loss: 2.7744\n",
      "Validation loss improved from 2.7748 to 2.7744. Saving model...\n",
      "\n",
      "LOG: Epoch [759/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4072\n",
      "Epoch [759/2000], Avg Train Loss: 3.4072\n",
      "Epoch [759/2000], Avg Val Loss: 2.7741\n",
      "Validation loss improved from 2.7744 to 2.7741. Saving model...\n",
      "\n",
      "LOG: Epoch [760/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3923\n",
      "Epoch [760/2000], Avg Train Loss: 3.3923\n",
      "Epoch [760/2000], Avg Val Loss: 2.7738\n",
      "Validation loss improved from 2.7741 to 2.7738. Saving model...\n",
      "\n",
      "LOG: Epoch [761/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3937\n",
      "Epoch [761/2000], Avg Train Loss: 3.3937\n",
      "Epoch [761/2000], Avg Val Loss: 2.7735\n",
      "Validation loss improved from 2.7738 to 2.7735. Saving model...\n",
      "\n",
      "LOG: Epoch [762/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3808\n",
      "Epoch [762/2000], Avg Train Loss: 3.3808\n",
      "Epoch [762/2000], Avg Val Loss: 2.7733\n",
      "Validation loss improved from 2.7735 to 2.7733. Saving model...\n",
      "\n",
      "LOG: Epoch [763/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4385\n",
      "Epoch [763/2000], Avg Train Loss: 3.4385\n",
      "Epoch [763/2000], Avg Val Loss: 2.7731\n",
      "Validation loss improved from 2.7733 to 2.7731. Saving model...\n",
      "\n",
      "LOG: Epoch [764/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3766\n",
      "Epoch [764/2000], Avg Train Loss: 3.3766\n",
      "Epoch [764/2000], Avg Val Loss: 2.7730\n",
      "Validation loss improved from 2.7731 to 2.7730. Saving model...\n",
      "\n",
      "LOG: Epoch [765/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3893\n",
      "Epoch [765/2000], Avg Train Loss: 3.3893\n",
      "Epoch [765/2000], Avg Val Loss: 2.7727\n",
      "Validation loss improved from 2.7730 to 2.7727. Saving model...\n",
      "\n",
      "LOG: Epoch [766/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4372\n",
      "Epoch [766/2000], Avg Train Loss: 3.4372\n",
      "Epoch [766/2000], Avg Val Loss: 2.7725\n",
      "Validation loss improved from 2.7727 to 2.7725. Saving model...\n",
      "\n",
      "LOG: Epoch [767/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3849\n",
      "Epoch [767/2000], Avg Train Loss: 3.3849\n",
      "Epoch [767/2000], Avg Val Loss: 2.7724\n",
      "Validation loss improved from 2.7725 to 2.7724. Saving model...\n",
      "\n",
      "LOG: Epoch [768/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3572\n",
      "Epoch [768/2000], Avg Train Loss: 3.3572\n",
      "Epoch [768/2000], Avg Val Loss: 2.7723\n",
      "Validation loss improved from 2.7724 to 2.7723. Saving model...\n",
      "\n",
      "LOG: Epoch [769/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3941\n",
      "Epoch [769/2000], Avg Train Loss: 3.3941\n",
      "Epoch [769/2000], Avg Val Loss: 2.7722\n",
      "Validation loss improved from 2.7723 to 2.7722. Saving model...\n",
      "\n",
      "LOG: Epoch [770/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3574\n",
      "Epoch [770/2000], Avg Train Loss: 3.3574\n",
      "Epoch [770/2000], Avg Val Loss: 2.7721\n",
      "Validation loss improved from 2.7722 to 2.7721. Saving model...\n",
      "\n",
      "LOG: Epoch [771/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4434\n",
      "Epoch [771/2000], Avg Train Loss: 3.4434\n",
      "Epoch [771/2000], Avg Val Loss: 2.7719\n",
      "Validation loss improved from 2.7721 to 2.7719. Saving model...\n",
      "\n",
      "LOG: Epoch [772/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3521\n",
      "Epoch [772/2000], Avg Train Loss: 3.3521\n",
      "Epoch [772/2000], Avg Val Loss: 2.7718\n",
      "Validation loss improved from 2.7719 to 2.7718. Saving model...\n",
      "\n",
      "LOG: Epoch [773/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3679\n",
      "Epoch [773/2000], Avg Train Loss: 3.3679\n",
      "Epoch [773/2000], Avg Val Loss: 2.7717\n",
      "Validation loss improved from 2.7718 to 2.7717. Saving model...\n",
      "\n",
      "LOG: Epoch [774/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4215\n",
      "Epoch [774/2000], Avg Train Loss: 3.4215\n",
      "Epoch [774/2000], Avg Val Loss: 2.7714\n",
      "Validation loss improved from 2.7717 to 2.7714. Saving model...\n",
      "\n",
      "LOG: Epoch [775/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3611\n",
      "Epoch [775/2000], Avg Train Loss: 3.3611\n",
      "Epoch [775/2000], Avg Val Loss: 2.7712\n",
      "Validation loss improved from 2.7714 to 2.7712. Saving model...\n",
      "\n",
      "LOG: Epoch [776/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3721\n",
      "Epoch [776/2000], Avg Train Loss: 3.3721\n",
      "Epoch [776/2000], Avg Val Loss: 2.7710\n",
      "Validation loss improved from 2.7712 to 2.7710. Saving model...\n",
      "\n",
      "LOG: Epoch [777/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4648\n",
      "Epoch [777/2000], Avg Train Loss: 3.4648\n",
      "Epoch [777/2000], Avg Val Loss: 2.7708\n",
      "Validation loss improved from 2.7710 to 2.7708. Saving model...\n",
      "\n",
      "LOG: Epoch [778/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4115\n",
      "Epoch [778/2000], Avg Train Loss: 3.4115\n",
      "Epoch [778/2000], Avg Val Loss: 2.7705\n",
      "Validation loss improved from 2.7708 to 2.7705. Saving model...\n",
      "\n",
      "LOG: Epoch [779/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3908\n",
      "Epoch [779/2000], Avg Train Loss: 3.3908\n",
      "Epoch [779/2000], Avg Val Loss: 2.7702\n",
      "Validation loss improved from 2.7705 to 2.7702. Saving model...\n",
      "\n",
      "LOG: Epoch [780/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4465\n",
      "Epoch [780/2000], Avg Train Loss: 3.4465\n",
      "Epoch [780/2000], Avg Val Loss: 2.7699\n",
      "Validation loss improved from 2.7702 to 2.7699. Saving model...\n",
      "\n",
      "LOG: Epoch [781/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3172\n",
      "Epoch [781/2000], Avg Train Loss: 3.3172\n",
      "Epoch [781/2000], Avg Val Loss: 2.7696\n",
      "Validation loss improved from 2.7699 to 2.7696. Saving model...\n",
      "\n",
      "LOG: Epoch [782/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3634\n",
      "Epoch [782/2000], Avg Train Loss: 3.3634\n",
      "Epoch [782/2000], Avg Val Loss: 2.7694\n",
      "Validation loss improved from 2.7696 to 2.7694. Saving model...\n",
      "\n",
      "LOG: Epoch [783/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3745\n",
      "Epoch [783/2000], Avg Train Loss: 3.3745\n",
      "Epoch [783/2000], Avg Val Loss: 2.7691\n",
      "Validation loss improved from 2.7694 to 2.7691. Saving model...\n",
      "\n",
      "LOG: Epoch [784/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4139\n",
      "Epoch [784/2000], Avg Train Loss: 3.4139\n",
      "Epoch [784/2000], Avg Val Loss: 2.7688\n",
      "Validation loss improved from 2.7691 to 2.7688. Saving model...\n",
      "\n",
      "LOG: Epoch [785/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4091\n",
      "Epoch [785/2000], Avg Train Loss: 3.4091\n",
      "Epoch [785/2000], Avg Val Loss: 2.7685\n",
      "Validation loss improved from 2.7688 to 2.7685. Saving model...\n",
      "\n",
      "LOG: Epoch [786/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3908\n",
      "Epoch [786/2000], Avg Train Loss: 3.3908\n",
      "Epoch [786/2000], Avg Val Loss: 2.7683\n",
      "Validation loss improved from 2.7685 to 2.7683. Saving model...\n",
      "\n",
      "LOG: Epoch [787/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3631\n",
      "Epoch [787/2000], Avg Train Loss: 3.3631\n",
      "Epoch [787/2000], Avg Val Loss: 2.7681\n",
      "Validation loss improved from 2.7683 to 2.7681. Saving model...\n",
      "\n",
      "LOG: Epoch [788/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3650\n",
      "Epoch [788/2000], Avg Train Loss: 3.3650\n",
      "Epoch [788/2000], Avg Val Loss: 2.7679\n",
      "Validation loss improved from 2.7681 to 2.7679. Saving model...\n",
      "\n",
      "LOG: Epoch [789/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3781\n",
      "Epoch [789/2000], Avg Train Loss: 3.3781\n",
      "Epoch [789/2000], Avg Val Loss: 2.7679\n",
      "Validation loss improved from 2.7679 to 2.7679. Saving model...\n",
      "\n",
      "LOG: Epoch [790/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4179\n",
      "Epoch [790/2000], Avg Train Loss: 3.4179\n",
      "Epoch [790/2000], Avg Val Loss: 2.7679\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [791/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3613\n",
      "Epoch [791/2000], Avg Train Loss: 3.3613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [791/2000], Avg Val Loss: 2.7679\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [792/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3652\n",
      "Epoch [792/2000], Avg Train Loss: 3.3652\n",
      "Epoch [792/2000], Avg Val Loss: 2.7679\n",
      "Validation loss improved from 2.7679 to 2.7679. Saving model...\n",
      "\n",
      "LOG: Epoch [793/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3247\n",
      "Epoch [793/2000], Avg Train Loss: 3.3247\n",
      "Epoch [793/2000], Avg Val Loss: 2.7678\n",
      "Validation loss improved from 2.7679 to 2.7678. Saving model...\n",
      "\n",
      "LOG: Epoch [794/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3354\n",
      "Epoch [794/2000], Avg Train Loss: 3.3354\n",
      "Epoch [794/2000], Avg Val Loss: 2.7677\n",
      "Validation loss improved from 2.7678 to 2.7677. Saving model...\n",
      "\n",
      "LOG: Epoch [795/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3712\n",
      "Epoch [795/2000], Avg Train Loss: 3.3712\n",
      "Epoch [795/2000], Avg Val Loss: 2.7676\n",
      "Validation loss improved from 2.7677 to 2.7676. Saving model...\n",
      "\n",
      "LOG: Epoch [796/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3419\n",
      "Epoch [796/2000], Avg Train Loss: 3.3419\n",
      "Epoch [796/2000], Avg Val Loss: 2.7674\n",
      "Validation loss improved from 2.7676 to 2.7674. Saving model...\n",
      "\n",
      "LOG: Epoch [797/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3585\n",
      "Epoch [797/2000], Avg Train Loss: 3.3585\n",
      "Epoch [797/2000], Avg Val Loss: 2.7672\n",
      "Validation loss improved from 2.7674 to 2.7672. Saving model...\n",
      "\n",
      "LOG: Epoch [798/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3424\n",
      "Epoch [798/2000], Avg Train Loss: 3.3424\n",
      "Epoch [798/2000], Avg Val Loss: 2.7671\n",
      "Validation loss improved from 2.7672 to 2.7671. Saving model...\n",
      "\n",
      "LOG: Epoch [799/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3786\n",
      "Epoch [799/2000], Avg Train Loss: 3.3786\n",
      "Epoch [799/2000], Avg Val Loss: 2.7669\n",
      "Validation loss improved from 2.7671 to 2.7669. Saving model...\n",
      "\n",
      "LOG: Epoch [800/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4060\n",
      "Epoch [800/2000], Avg Train Loss: 3.4060\n",
      "Epoch [800/2000], Avg Val Loss: 2.7668\n",
      "Validation loss improved from 2.7669 to 2.7668. Saving model...\n",
      "\n",
      "LOG: Epoch [801/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3541\n",
      "Epoch [801/2000], Avg Train Loss: 3.3541\n",
      "Epoch [801/2000], Avg Val Loss: 2.7667\n",
      "Validation loss improved from 2.7668 to 2.7667. Saving model...\n",
      "\n",
      "LOG: Epoch [802/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3534\n",
      "Epoch [802/2000], Avg Train Loss: 3.3534\n",
      "Epoch [802/2000], Avg Val Loss: 2.7666\n",
      "Validation loss improved from 2.7667 to 2.7666. Saving model...\n",
      "\n",
      "LOG: Epoch [803/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3357\n",
      "Epoch [803/2000], Avg Train Loss: 3.3357\n",
      "Epoch [803/2000], Avg Val Loss: 2.7665\n",
      "Validation loss improved from 2.7666 to 2.7665. Saving model...\n",
      "\n",
      "LOG: Epoch [804/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3241\n",
      "Epoch [804/2000], Avg Train Loss: 3.3241\n",
      "Epoch [804/2000], Avg Val Loss: 2.7662\n",
      "Validation loss improved from 2.7665 to 2.7662. Saving model...\n",
      "\n",
      "LOG: Epoch [805/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3509\n",
      "Epoch [805/2000], Avg Train Loss: 3.3509\n",
      "Epoch [805/2000], Avg Val Loss: 2.7659\n",
      "Validation loss improved from 2.7662 to 2.7659. Saving model...\n",
      "\n",
      "LOG: Epoch [806/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3405\n",
      "Epoch [806/2000], Avg Train Loss: 3.3405\n",
      "Epoch [806/2000], Avg Val Loss: 2.7657\n",
      "Validation loss improved from 2.7659 to 2.7657. Saving model...\n",
      "\n",
      "LOG: Epoch [807/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3968\n",
      "Epoch [807/2000], Avg Train Loss: 3.3968\n",
      "Epoch [807/2000], Avg Val Loss: 2.7653\n",
      "Validation loss improved from 2.7657 to 2.7653. Saving model...\n",
      "\n",
      "LOG: Epoch [808/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3342\n",
      "Epoch [808/2000], Avg Train Loss: 3.3342\n",
      "Epoch [808/2000], Avg Val Loss: 2.7650\n",
      "Validation loss improved from 2.7653 to 2.7650. Saving model...\n",
      "\n",
      "LOG: Epoch [809/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3582\n",
      "Epoch [809/2000], Avg Train Loss: 3.3582\n",
      "Epoch [809/2000], Avg Val Loss: 2.7646\n",
      "Validation loss improved from 2.7650 to 2.7646. Saving model...\n",
      "\n",
      "LOG: Epoch [810/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3284\n",
      "Epoch [810/2000], Avg Train Loss: 3.3284\n",
      "Epoch [810/2000], Avg Val Loss: 2.7643\n",
      "Validation loss improved from 2.7646 to 2.7643. Saving model...\n",
      "\n",
      "LOG: Epoch [811/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3170\n",
      "Epoch [811/2000], Avg Train Loss: 3.3170\n",
      "Epoch [811/2000], Avg Val Loss: 2.7639\n",
      "Validation loss improved from 2.7643 to 2.7639. Saving model...\n",
      "\n",
      "LOG: Epoch [812/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3142\n",
      "Epoch [812/2000], Avg Train Loss: 3.3142\n",
      "Epoch [812/2000], Avg Val Loss: 2.7635\n",
      "Validation loss improved from 2.7639 to 2.7635. Saving model...\n",
      "\n",
      "LOG: Epoch [813/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3234\n",
      "Epoch [813/2000], Avg Train Loss: 3.3234\n",
      "Epoch [813/2000], Avg Val Loss: 2.7630\n",
      "Validation loss improved from 2.7635 to 2.7630. Saving model...\n",
      "\n",
      "LOG: Epoch [814/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3377\n",
      "Epoch [814/2000], Avg Train Loss: 3.3377\n",
      "Epoch [814/2000], Avg Val Loss: 2.7627\n",
      "Validation loss improved from 2.7630 to 2.7627. Saving model...\n",
      "\n",
      "LOG: Epoch [815/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3554\n",
      "Epoch [815/2000], Avg Train Loss: 3.3554\n",
      "Epoch [815/2000], Avg Val Loss: 2.7623\n",
      "Validation loss improved from 2.7627 to 2.7623. Saving model...\n",
      "\n",
      "LOG: Epoch [816/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3416\n",
      "Epoch [816/2000], Avg Train Loss: 3.3416\n",
      "Epoch [816/2000], Avg Val Loss: 2.7619\n",
      "Validation loss improved from 2.7623 to 2.7619. Saving model...\n",
      "\n",
      "LOG: Epoch [817/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3486\n",
      "Epoch [817/2000], Avg Train Loss: 3.3486\n",
      "Epoch [817/2000], Avg Val Loss: 2.7614\n",
      "Validation loss improved from 2.7619 to 2.7614. Saving model...\n",
      "\n",
      "LOG: Epoch [818/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3449\n",
      "Epoch [818/2000], Avg Train Loss: 3.3449\n",
      "Epoch [818/2000], Avg Val Loss: 2.7609\n",
      "Validation loss improved from 2.7614 to 2.7609. Saving model...\n",
      "\n",
      "LOG: Epoch [819/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3704\n",
      "Epoch [819/2000], Avg Train Loss: 3.3704\n",
      "Epoch [819/2000], Avg Val Loss: 2.7605\n",
      "Validation loss improved from 2.7609 to 2.7605. Saving model...\n",
      "\n",
      "LOG: Epoch [820/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3509\n",
      "Epoch [820/2000], Avg Train Loss: 3.3509\n",
      "Epoch [820/2000], Avg Val Loss: 2.7602\n",
      "Validation loss improved from 2.7605 to 2.7602. Saving model...\n",
      "\n",
      "LOG: Epoch [821/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3252\n",
      "Epoch [821/2000], Avg Train Loss: 3.3252\n",
      "Epoch [821/2000], Avg Val Loss: 2.7598\n",
      "Validation loss improved from 2.7602 to 2.7598. Saving model...\n",
      "\n",
      "LOG: Epoch [822/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3171\n",
      "Epoch [822/2000], Avg Train Loss: 3.3171\n",
      "Epoch [822/2000], Avg Val Loss: 2.7594\n",
      "Validation loss improved from 2.7598 to 2.7594. Saving model...\n",
      "\n",
      "LOG: Epoch [823/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3863\n",
      "Epoch [823/2000], Avg Train Loss: 3.3863\n",
      "Epoch [823/2000], Avg Val Loss: 2.7590\n",
      "Validation loss improved from 2.7594 to 2.7590. Saving model...\n",
      "\n",
      "LOG: Epoch [824/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3346\n",
      "Epoch [824/2000], Avg Train Loss: 3.3346\n",
      "Epoch [824/2000], Avg Val Loss: 2.7587\n",
      "Validation loss improved from 2.7590 to 2.7587. Saving model...\n",
      "\n",
      "LOG: Epoch [825/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3701\n",
      "Epoch [825/2000], Avg Train Loss: 3.3701\n",
      "Epoch [825/2000], Avg Val Loss: 2.7583\n",
      "Validation loss improved from 2.7587 to 2.7583. Saving model...\n",
      "\n",
      "LOG: Epoch [826/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3466\n",
      "Epoch [826/2000], Avg Train Loss: 3.3466\n",
      "Epoch [826/2000], Avg Val Loss: 2.7579\n",
      "Validation loss improved from 2.7583 to 2.7579. Saving model...\n",
      "\n",
      "LOG: Epoch [827/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3519\n",
      "Epoch [827/2000], Avg Train Loss: 3.3519\n",
      "Epoch [827/2000], Avg Val Loss: 2.7576\n",
      "Validation loss improved from 2.7579 to 2.7576. Saving model...\n",
      "\n",
      "LOG: Epoch [828/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2951\n",
      "Epoch [828/2000], Avg Train Loss: 3.2951\n",
      "Epoch [828/2000], Avg Val Loss: 2.7574\n",
      "Validation loss improved from 2.7576 to 2.7574. Saving model...\n",
      "\n",
      "LOG: Epoch [829/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3234\n",
      "Epoch [829/2000], Avg Train Loss: 3.3234\n",
      "Epoch [829/2000], Avg Val Loss: 2.7571\n",
      "Validation loss improved from 2.7574 to 2.7571. Saving model...\n",
      "\n",
      "LOG: Epoch [830/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3019\n",
      "Epoch [830/2000], Avg Train Loss: 3.3019\n",
      "Epoch [830/2000], Avg Val Loss: 2.7569\n",
      "Validation loss improved from 2.7571 to 2.7569. Saving model...\n",
      "\n",
      "LOG: Epoch [831/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3078\n",
      "Epoch [831/2000], Avg Train Loss: 3.3078\n",
      "Epoch [831/2000], Avg Val Loss: 2.7566\n",
      "Validation loss improved from 2.7569 to 2.7566. Saving model...\n",
      "\n",
      "LOG: Epoch [832/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2995\n",
      "Epoch [832/2000], Avg Train Loss: 3.2995\n",
      "Epoch [832/2000], Avg Val Loss: 2.7564\n",
      "Validation loss improved from 2.7566 to 2.7564. Saving model...\n",
      "\n",
      "LOG: Epoch [833/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3320\n",
      "Epoch [833/2000], Avg Train Loss: 3.3320\n",
      "Epoch [833/2000], Avg Val Loss: 2.7563\n",
      "Validation loss improved from 2.7564 to 2.7563. Saving model...\n",
      "\n",
      "LOG: Epoch [834/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3200\n",
      "Epoch [834/2000], Avg Train Loss: 3.3200\n",
      "Epoch [834/2000], Avg Val Loss: 2.7562\n",
      "Validation loss improved from 2.7563 to 2.7562. Saving model...\n",
      "\n",
      "LOG: Epoch [835/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3411\n",
      "Epoch [835/2000], Avg Train Loss: 3.3411\n",
      "Epoch [835/2000], Avg Val Loss: 2.7561\n",
      "Validation loss improved from 2.7562 to 2.7561. Saving model...\n",
      "\n",
      "LOG: Epoch [836/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3150\n",
      "Epoch [836/2000], Avg Train Loss: 3.3150\n",
      "Epoch [836/2000], Avg Val Loss: 2.7560\n",
      "Validation loss improved from 2.7561 to 2.7560. Saving model...\n",
      "\n",
      "LOG: Epoch [837/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [837/2000], Avg Train Loss: 3.3287\n",
      "Epoch [837/2000], Avg Val Loss: 2.7559\n",
      "Validation loss improved from 2.7560 to 2.7559. Saving model...\n",
      "\n",
      "LOG: Epoch [838/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3483\n",
      "Epoch [838/2000], Avg Train Loss: 3.3483\n",
      "Epoch [838/2000], Avg Val Loss: 2.7559\n",
      "Validation loss improved from 2.7559 to 2.7559. Saving model...\n",
      "\n",
      "LOG: Epoch [839/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3254\n",
      "Epoch [839/2000], Avg Train Loss: 3.3254\n",
      "Epoch [839/2000], Avg Val Loss: 2.7558\n",
      "Validation loss improved from 2.7559 to 2.7558. Saving model...\n",
      "\n",
      "LOG: Epoch [840/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3341\n",
      "Epoch [840/2000], Avg Train Loss: 3.3341\n",
      "Epoch [840/2000], Avg Val Loss: 2.7558\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [841/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3279\n",
      "Epoch [841/2000], Avg Train Loss: 3.3279\n",
      "Epoch [841/2000], Avg Val Loss: 2.7558\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [842/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3237\n",
      "Epoch [842/2000], Avg Train Loss: 3.3237\n",
      "Epoch [842/2000], Avg Val Loss: 2.7558\n",
      "Validation loss improved from 2.7558 to 2.7558. Saving model...\n",
      "\n",
      "LOG: Epoch [843/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3480\n",
      "Epoch [843/2000], Avg Train Loss: 3.3480\n",
      "Epoch [843/2000], Avg Val Loss: 2.7558\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [844/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3273\n",
      "Epoch [844/2000], Avg Train Loss: 3.3273\n",
      "Epoch [844/2000], Avg Val Loss: 2.7558\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [845/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3719\n",
      "Epoch [845/2000], Avg Train Loss: 3.3719\n",
      "Epoch [845/2000], Avg Val Loss: 2.7557\n",
      "Validation loss improved from 2.7558 to 2.7557. Saving model...\n",
      "\n",
      "LOG: Epoch [846/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3032\n",
      "Epoch [846/2000], Avg Train Loss: 3.3032\n",
      "Epoch [846/2000], Avg Val Loss: 2.7556\n",
      "Validation loss improved from 2.7557 to 2.7556. Saving model...\n",
      "\n",
      "LOG: Epoch [847/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3117\n",
      "Epoch [847/2000], Avg Train Loss: 3.3117\n",
      "Epoch [847/2000], Avg Val Loss: 2.7554\n",
      "Validation loss improved from 2.7556 to 2.7554. Saving model...\n",
      "\n",
      "LOG: Epoch [848/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3170\n",
      "Epoch [848/2000], Avg Train Loss: 3.3170\n",
      "Epoch [848/2000], Avg Val Loss: 2.7552\n",
      "Validation loss improved from 2.7554 to 2.7552. Saving model...\n",
      "\n",
      "LOG: Epoch [849/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2978\n",
      "Epoch [849/2000], Avg Train Loss: 3.2978\n",
      "Epoch [849/2000], Avg Val Loss: 2.7549\n",
      "Validation loss improved from 2.7552 to 2.7549. Saving model...\n",
      "\n",
      "LOG: Epoch [850/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2823\n",
      "Epoch [850/2000], Avg Train Loss: 3.2823\n",
      "Epoch [850/2000], Avg Val Loss: 2.7547\n",
      "Validation loss improved from 2.7549 to 2.7547. Saving model...\n",
      "\n",
      "LOG: Epoch [851/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.4075\n",
      "Epoch [851/2000], Avg Train Loss: 3.4075\n",
      "Epoch [851/2000], Avg Val Loss: 2.7545\n",
      "Validation loss improved from 2.7547 to 2.7545. Saving model...\n",
      "\n",
      "LOG: Epoch [852/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2805\n",
      "Epoch [852/2000], Avg Train Loss: 3.2805\n",
      "Epoch [852/2000], Avg Val Loss: 2.7542\n",
      "Validation loss improved from 2.7545 to 2.7542. Saving model...\n",
      "\n",
      "LOG: Epoch [853/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3761\n",
      "Epoch [853/2000], Avg Train Loss: 3.3761\n",
      "Epoch [853/2000], Avg Val Loss: 2.7538\n",
      "Validation loss improved from 2.7542 to 2.7538. Saving model...\n",
      "\n",
      "LOG: Epoch [854/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3351\n",
      "Epoch [854/2000], Avg Train Loss: 3.3351\n",
      "Epoch [854/2000], Avg Val Loss: 2.7533\n",
      "Validation loss improved from 2.7538 to 2.7533. Saving model...\n",
      "\n",
      "LOG: Epoch [855/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2889\n",
      "Epoch [855/2000], Avg Train Loss: 3.2889\n",
      "Epoch [855/2000], Avg Val Loss: 2.7528\n",
      "Validation loss improved from 2.7533 to 2.7528. Saving model...\n",
      "\n",
      "LOG: Epoch [856/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2407\n",
      "Epoch [856/2000], Avg Train Loss: 3.2407\n",
      "Epoch [856/2000], Avg Val Loss: 2.7523\n",
      "Validation loss improved from 2.7528 to 2.7523. Saving model...\n",
      "\n",
      "LOG: Epoch [857/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3325\n",
      "Epoch [857/2000], Avg Train Loss: 3.3325\n",
      "Epoch [857/2000], Avg Val Loss: 2.7518\n",
      "Validation loss improved from 2.7523 to 2.7518. Saving model...\n",
      "\n",
      "LOG: Epoch [858/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3239\n",
      "Epoch [858/2000], Avg Train Loss: 3.3239\n",
      "Epoch [858/2000], Avg Val Loss: 2.7514\n",
      "Validation loss improved from 2.7518 to 2.7514. Saving model...\n",
      "\n",
      "LOG: Epoch [859/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3600\n",
      "Epoch [859/2000], Avg Train Loss: 3.3600\n",
      "Epoch [859/2000], Avg Val Loss: 2.7510\n",
      "Validation loss improved from 2.7514 to 2.7510. Saving model...\n",
      "\n",
      "LOG: Epoch [860/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3080\n",
      "Epoch [860/2000], Avg Train Loss: 3.3080\n",
      "Epoch [860/2000], Avg Val Loss: 2.7506\n",
      "Validation loss improved from 2.7510 to 2.7506. Saving model...\n",
      "\n",
      "LOG: Epoch [861/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2862\n",
      "Epoch [861/2000], Avg Train Loss: 3.2862\n",
      "Epoch [861/2000], Avg Val Loss: 2.7503\n",
      "Validation loss improved from 2.7506 to 2.7503. Saving model...\n",
      "\n",
      "LOG: Epoch [862/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2893\n",
      "Epoch [862/2000], Avg Train Loss: 3.2893\n",
      "Epoch [862/2000], Avg Val Loss: 2.7500\n",
      "Validation loss improved from 2.7503 to 2.7500. Saving model...\n",
      "\n",
      "LOG: Epoch [863/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3286\n",
      "Epoch [863/2000], Avg Train Loss: 3.3286\n",
      "Epoch [863/2000], Avg Val Loss: 2.7497\n",
      "Validation loss improved from 2.7500 to 2.7497. Saving model...\n",
      "\n",
      "LOG: Epoch [864/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3228\n",
      "Epoch [864/2000], Avg Train Loss: 3.3228\n",
      "Epoch [864/2000], Avg Val Loss: 2.7495\n",
      "Validation loss improved from 2.7497 to 2.7495. Saving model...\n",
      "\n",
      "LOG: Epoch [865/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3021\n",
      "Epoch [865/2000], Avg Train Loss: 3.3021\n",
      "Epoch [865/2000], Avg Val Loss: 2.7493\n",
      "Validation loss improved from 2.7495 to 2.7493. Saving model...\n",
      "\n",
      "LOG: Epoch [866/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2832\n",
      "Epoch [866/2000], Avg Train Loss: 3.2832\n",
      "Epoch [866/2000], Avg Val Loss: 2.7490\n",
      "Validation loss improved from 2.7493 to 2.7490. Saving model...\n",
      "\n",
      "LOG: Epoch [867/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3080\n",
      "Epoch [867/2000], Avg Train Loss: 3.3080\n",
      "Epoch [867/2000], Avg Val Loss: 2.7487\n",
      "Validation loss improved from 2.7490 to 2.7487. Saving model...\n",
      "\n",
      "LOG: Epoch [868/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3081\n",
      "Epoch [868/2000], Avg Train Loss: 3.3081\n",
      "Epoch [868/2000], Avg Val Loss: 2.7485\n",
      "Validation loss improved from 2.7487 to 2.7485. Saving model...\n",
      "\n",
      "LOG: Epoch [869/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2901\n",
      "Epoch [869/2000], Avg Train Loss: 3.2901\n",
      "Epoch [869/2000], Avg Val Loss: 2.7483\n",
      "Validation loss improved from 2.7485 to 2.7483. Saving model...\n",
      "\n",
      "LOG: Epoch [870/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2743\n",
      "Epoch [870/2000], Avg Train Loss: 3.2743\n",
      "Epoch [870/2000], Avg Val Loss: 2.7480\n",
      "Validation loss improved from 2.7483 to 2.7480. Saving model...\n",
      "\n",
      "LOG: Epoch [871/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2782\n",
      "Epoch [871/2000], Avg Train Loss: 3.2782\n",
      "Epoch [871/2000], Avg Val Loss: 2.7477\n",
      "Validation loss improved from 2.7480 to 2.7477. Saving model...\n",
      "\n",
      "LOG: Epoch [872/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3113\n",
      "Epoch [872/2000], Avg Train Loss: 3.3113\n",
      "Epoch [872/2000], Avg Val Loss: 2.7472\n",
      "Validation loss improved from 2.7477 to 2.7472. Saving model...\n",
      "\n",
      "LOG: Epoch [873/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3151\n",
      "Epoch [873/2000], Avg Train Loss: 3.3151\n",
      "Epoch [873/2000], Avg Val Loss: 2.7468\n",
      "Validation loss improved from 2.7472 to 2.7468. Saving model...\n",
      "\n",
      "LOG: Epoch [874/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3221\n",
      "Epoch [874/2000], Avg Train Loss: 3.3221\n",
      "Epoch [874/2000], Avg Val Loss: 2.7464\n",
      "Validation loss improved from 2.7468 to 2.7464. Saving model...\n",
      "\n",
      "LOG: Epoch [875/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2636\n",
      "Epoch [875/2000], Avg Train Loss: 3.2636\n",
      "Epoch [875/2000], Avg Val Loss: 2.7461\n",
      "Validation loss improved from 2.7464 to 2.7461. Saving model...\n",
      "\n",
      "LOG: Epoch [876/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3217\n",
      "Epoch [876/2000], Avg Train Loss: 3.3217\n",
      "Epoch [876/2000], Avg Val Loss: 2.7458\n",
      "Validation loss improved from 2.7461 to 2.7458. Saving model...\n",
      "\n",
      "LOG: Epoch [877/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2838\n",
      "Epoch [877/2000], Avg Train Loss: 3.2838\n",
      "Epoch [877/2000], Avg Val Loss: 2.7455\n",
      "Validation loss improved from 2.7458 to 2.7455. Saving model...\n",
      "\n",
      "LOG: Epoch [878/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3597\n",
      "Epoch [878/2000], Avg Train Loss: 3.3597\n",
      "Epoch [878/2000], Avg Val Loss: 2.7451\n",
      "Validation loss improved from 2.7455 to 2.7451. Saving model...\n",
      "\n",
      "LOG: Epoch [879/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.3181\n",
      "Epoch [879/2000], Avg Train Loss: 3.3181\n",
      "Epoch [879/2000], Avg Val Loss: 2.7449\n",
      "Validation loss improved from 2.7451 to 2.7449. Saving model...\n",
      "\n",
      "LOG: Epoch [880/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3096\n",
      "Epoch [880/2000], Avg Train Loss: 3.3096\n",
      "Epoch [880/2000], Avg Val Loss: 2.7447\n",
      "Validation loss improved from 2.7449 to 2.7447. Saving model...\n",
      "\n",
      "LOG: Epoch [881/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3015\n",
      "Epoch [881/2000], Avg Train Loss: 3.3015\n",
      "Epoch [881/2000], Avg Val Loss: 2.7444\n",
      "Validation loss improved from 2.7447 to 2.7444. Saving model...\n",
      "\n",
      "LOG: Epoch [882/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3147\n",
      "Epoch [882/2000], Avg Train Loss: 3.3147\n",
      "Epoch [882/2000], Avg Val Loss: 2.7442\n",
      "Validation loss improved from 2.7444 to 2.7442. Saving model...\n",
      "\n",
      "LOG: Epoch [883/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2428\n",
      "Epoch [883/2000], Avg Train Loss: 3.2428\n",
      "Epoch [883/2000], Avg Val Loss: 2.7439\n",
      "Validation loss improved from 2.7442 to 2.7439. Saving model...\n",
      "\n",
      "LOG: Epoch [884/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2703\n",
      "Epoch [884/2000], Avg Train Loss: 3.2703\n",
      "Epoch [884/2000], Avg Val Loss: 2.7437\n",
      "Validation loss improved from 2.7439 to 2.7437. Saving model...\n",
      "\n",
      "LOG: Epoch [885/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2838\n",
      "Epoch [885/2000], Avg Train Loss: 3.2838\n",
      "Epoch [885/2000], Avg Val Loss: 2.7434\n",
      "Validation loss improved from 2.7437 to 2.7434. Saving model...\n",
      "\n",
      "LOG: Epoch [886/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3040\n",
      "Epoch [886/2000], Avg Train Loss: 3.3040\n",
      "Epoch [886/2000], Avg Val Loss: 2.7432\n",
      "Validation loss improved from 2.7434 to 2.7432. Saving model...\n",
      "\n",
      "LOG: Epoch [887/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2974\n",
      "Epoch [887/2000], Avg Train Loss: 3.2974\n",
      "Epoch [887/2000], Avg Val Loss: 2.7429\n",
      "Validation loss improved from 2.7432 to 2.7429. Saving model...\n",
      "\n",
      "LOG: Epoch [888/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3579\n",
      "Epoch [888/2000], Avg Train Loss: 3.3579\n",
      "Epoch [888/2000], Avg Val Loss: 2.7425\n",
      "Validation loss improved from 2.7429 to 2.7425. Saving model...\n",
      "\n",
      "LOG: Epoch [889/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2623\n",
      "Epoch [889/2000], Avg Train Loss: 3.2623\n",
      "Epoch [889/2000], Avg Val Loss: 2.7421\n",
      "Validation loss improved from 2.7425 to 2.7421. Saving model...\n",
      "\n",
      "LOG: Epoch [890/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2733\n",
      "Epoch [890/2000], Avg Train Loss: 3.2733\n",
      "Epoch [890/2000], Avg Val Loss: 2.7417\n",
      "Validation loss improved from 2.7421 to 2.7417. Saving model...\n",
      "\n",
      "LOG: Epoch [891/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3031\n",
      "Epoch [891/2000], Avg Train Loss: 3.3031\n",
      "Epoch [891/2000], Avg Val Loss: 2.7414\n",
      "Validation loss improved from 2.7417 to 2.7414. Saving model...\n",
      "\n",
      "LOG: Epoch [892/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2827\n",
      "Epoch [892/2000], Avg Train Loss: 3.2827\n",
      "Epoch [892/2000], Avg Val Loss: 2.7411\n",
      "Validation loss improved from 2.7414 to 2.7411. Saving model...\n",
      "\n",
      "LOG: Epoch [893/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2932\n",
      "Epoch [893/2000], Avg Train Loss: 3.2932\n",
      "Epoch [893/2000], Avg Val Loss: 2.7409\n",
      "Validation loss improved from 2.7411 to 2.7409. Saving model...\n",
      "\n",
      "LOG: Epoch [894/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2308\n",
      "Epoch [894/2000], Avg Train Loss: 3.2308\n",
      "Epoch [894/2000], Avg Val Loss: 2.7407\n",
      "Validation loss improved from 2.7409 to 2.7407. Saving model...\n",
      "\n",
      "LOG: Epoch [895/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3321\n",
      "Epoch [895/2000], Avg Train Loss: 3.3321\n",
      "Epoch [895/2000], Avg Val Loss: 2.7406\n",
      "Validation loss improved from 2.7407 to 2.7406. Saving model...\n",
      "\n",
      "LOG: Epoch [896/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2337\n",
      "Epoch [896/2000], Avg Train Loss: 3.2337\n",
      "Epoch [896/2000], Avg Val Loss: 2.7404\n",
      "Validation loss improved from 2.7406 to 2.7404. Saving model...\n",
      "\n",
      "LOG: Epoch [897/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3003\n",
      "Epoch [897/2000], Avg Train Loss: 3.3003\n",
      "Epoch [897/2000], Avg Val Loss: 2.7402\n",
      "Validation loss improved from 2.7404 to 2.7402. Saving model...\n",
      "\n",
      "LOG: Epoch [898/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2425\n",
      "Epoch [898/2000], Avg Train Loss: 3.2425\n",
      "Epoch [898/2000], Avg Val Loss: 2.7400\n",
      "Validation loss improved from 2.7402 to 2.7400. Saving model...\n",
      "\n",
      "LOG: Epoch [899/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3108\n",
      "Epoch [899/2000], Avg Train Loss: 3.3108\n",
      "Epoch [899/2000], Avg Val Loss: 2.7398\n",
      "Validation loss improved from 2.7400 to 2.7398. Saving model...\n",
      "\n",
      "LOG: Epoch [900/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3830\n",
      "Epoch [900/2000], Avg Train Loss: 3.3830\n",
      "Epoch [900/2000], Avg Val Loss: 2.7396\n",
      "Validation loss improved from 2.7398 to 2.7396. Saving model...\n",
      "\n",
      "LOG: Epoch [901/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2572\n",
      "Epoch [901/2000], Avg Train Loss: 3.2572\n",
      "Epoch [901/2000], Avg Val Loss: 2.7395\n",
      "Validation loss improved from 2.7396 to 2.7395. Saving model...\n",
      "\n",
      "LOG: Epoch [902/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2646\n",
      "Epoch [902/2000], Avg Train Loss: 3.2646\n",
      "Epoch [902/2000], Avg Val Loss: 2.7395\n",
      "Validation loss improved from 2.7395 to 2.7395. Saving model...\n",
      "\n",
      "LOG: Epoch [903/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2975\n",
      "Epoch [903/2000], Avg Train Loss: 3.2975\n",
      "Epoch [903/2000], Avg Val Loss: 2.7392\n",
      "Validation loss improved from 2.7395 to 2.7392. Saving model...\n",
      "\n",
      "LOG: Epoch [904/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2596\n",
      "Epoch [904/2000], Avg Train Loss: 3.2596\n",
      "Epoch [904/2000], Avg Val Loss: 2.7390\n",
      "Validation loss improved from 2.7392 to 2.7390. Saving model...\n",
      "\n",
      "LOG: Epoch [905/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2734\n",
      "Epoch [905/2000], Avg Train Loss: 3.2734\n",
      "Epoch [905/2000], Avg Val Loss: 2.7387\n",
      "Validation loss improved from 2.7390 to 2.7387. Saving model...\n",
      "\n",
      "LOG: Epoch [906/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2581\n",
      "Epoch [906/2000], Avg Train Loss: 3.2581\n",
      "Epoch [906/2000], Avg Val Loss: 2.7384\n",
      "Validation loss improved from 2.7387 to 2.7384. Saving model...\n",
      "\n",
      "LOG: Epoch [907/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2330\n",
      "Epoch [907/2000], Avg Train Loss: 3.2330\n",
      "Epoch [907/2000], Avg Val Loss: 2.7381\n",
      "Validation loss improved from 2.7384 to 2.7381. Saving model...\n",
      "\n",
      "LOG: Epoch [908/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2876\n",
      "Epoch [908/2000], Avg Train Loss: 3.2876\n",
      "Epoch [908/2000], Avg Val Loss: 2.7377\n",
      "Validation loss improved from 2.7381 to 2.7377. Saving model...\n",
      "\n",
      "LOG: Epoch [909/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2696\n",
      "Epoch [909/2000], Avg Train Loss: 3.2696\n",
      "Epoch [909/2000], Avg Val Loss: 2.7374\n",
      "Validation loss improved from 2.7377 to 2.7374. Saving model...\n",
      "\n",
      "LOG: Epoch [910/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2276\n",
      "Epoch [910/2000], Avg Train Loss: 3.2276\n",
      "Epoch [910/2000], Avg Val Loss: 2.7368\n",
      "Validation loss improved from 2.7374 to 2.7368. Saving model...\n",
      "\n",
      "LOG: Epoch [911/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2087\n",
      "Epoch [911/2000], Avg Train Loss: 3.2087\n",
      "Epoch [911/2000], Avg Val Loss: 2.7363\n",
      "Validation loss improved from 2.7368 to 2.7363. Saving model...\n",
      "\n",
      "LOG: Epoch [912/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2832\n",
      "Epoch [912/2000], Avg Train Loss: 3.2832\n",
      "Epoch [912/2000], Avg Val Loss: 2.7357\n",
      "Validation loss improved from 2.7363 to 2.7357. Saving model...\n",
      "\n",
      "LOG: Epoch [913/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2804\n",
      "Epoch [913/2000], Avg Train Loss: 3.2804\n",
      "Epoch [913/2000], Avg Val Loss: 2.7351\n",
      "Validation loss improved from 2.7357 to 2.7351. Saving model...\n",
      "\n",
      "LOG: Epoch [914/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2371\n",
      "Epoch [914/2000], Avg Train Loss: 3.2371\n",
      "Epoch [914/2000], Avg Val Loss: 2.7346\n",
      "Validation loss improved from 2.7351 to 2.7346. Saving model...\n",
      "\n",
      "LOG: Epoch [915/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2437\n",
      "Epoch [915/2000], Avg Train Loss: 3.2437\n",
      "Epoch [915/2000], Avg Val Loss: 2.7340\n",
      "Validation loss improved from 2.7346 to 2.7340. Saving model...\n",
      "\n",
      "LOG: Epoch [916/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2411\n",
      "Epoch [916/2000], Avg Train Loss: 3.2411\n",
      "Epoch [916/2000], Avg Val Loss: 2.7336\n",
      "Validation loss improved from 2.7340 to 2.7336. Saving model...\n",
      "\n",
      "LOG: Epoch [917/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2499\n",
      "Epoch [917/2000], Avg Train Loss: 3.2499\n",
      "Epoch [917/2000], Avg Val Loss: 2.7331\n",
      "Validation loss improved from 2.7336 to 2.7331. Saving model...\n",
      "\n",
      "LOG: Epoch [918/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2306\n",
      "Epoch [918/2000], Avg Train Loss: 3.2306\n",
      "Epoch [918/2000], Avg Val Loss: 2.7325\n",
      "Validation loss improved from 2.7331 to 2.7325. Saving model...\n",
      "\n",
      "LOG: Epoch [919/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2780\n",
      "Epoch [919/2000], Avg Train Loss: 3.2780\n",
      "Epoch [919/2000], Avg Val Loss: 2.7321\n",
      "Validation loss improved from 2.7325 to 2.7321. Saving model...\n",
      "\n",
      "LOG: Epoch [920/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2546\n",
      "Epoch [920/2000], Avg Train Loss: 3.2546\n",
      "Epoch [920/2000], Avg Val Loss: 2.7317\n",
      "Validation loss improved from 2.7321 to 2.7317. Saving model...\n",
      "\n",
      "LOG: Epoch [921/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2650\n",
      "Epoch [921/2000], Avg Train Loss: 3.2650\n",
      "Epoch [921/2000], Avg Val Loss: 2.7313\n",
      "Validation loss improved from 2.7317 to 2.7313. Saving model...\n",
      "\n",
      "LOG: Epoch [922/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.2749\n",
      "Epoch [922/2000], Avg Train Loss: 3.2749\n",
      "Epoch [922/2000], Avg Val Loss: 2.7308\n",
      "Validation loss improved from 2.7313 to 2.7308. Saving model...\n",
      "\n",
      "LOG: Epoch [923/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2151\n",
      "Epoch [923/2000], Avg Train Loss: 3.2151\n",
      "Epoch [923/2000], Avg Val Loss: 2.7304\n",
      "Validation loss improved from 2.7308 to 2.7304. Saving model...\n",
      "\n",
      "LOG: Epoch [924/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2776\n",
      "Epoch [924/2000], Avg Train Loss: 3.2776\n",
      "Epoch [924/2000], Avg Val Loss: 2.7299\n",
      "Validation loss improved from 2.7304 to 2.7299. Saving model...\n",
      "\n",
      "LOG: Epoch [925/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2801\n",
      "Epoch [925/2000], Avg Train Loss: 3.2801\n",
      "Epoch [925/2000], Avg Val Loss: 2.7294\n",
      "Validation loss improved from 2.7299 to 2.7294. Saving model...\n",
      "\n",
      "LOG: Epoch [926/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2729\n",
      "Epoch [926/2000], Avg Train Loss: 3.2729\n",
      "Epoch [926/2000], Avg Val Loss: 2.7289\n",
      "Validation loss improved from 2.7294 to 2.7289. Saving model...\n",
      "\n",
      "LOG: Epoch [927/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2363\n",
      "Epoch [927/2000], Avg Train Loss: 3.2363\n",
      "Epoch [927/2000], Avg Val Loss: 2.7284\n",
      "Validation loss improved from 2.7289 to 2.7284. Saving model...\n",
      "\n",
      "LOG: Epoch [928/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2253\n",
      "Epoch [928/2000], Avg Train Loss: 3.2253\n",
      "Epoch [928/2000], Avg Val Loss: 2.7281\n",
      "Validation loss improved from 2.7284 to 2.7281. Saving model...\n",
      "\n",
      "LOG: Epoch [929/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2438\n",
      "Epoch [929/2000], Avg Train Loss: 3.2438\n",
      "Epoch [929/2000], Avg Val Loss: 2.7277\n",
      "Validation loss improved from 2.7281 to 2.7277. Saving model...\n",
      "\n",
      "LOG: Epoch [930/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2752\n",
      "Epoch [930/2000], Avg Train Loss: 3.2752\n",
      "Epoch [930/2000], Avg Val Loss: 2.7273\n",
      "Validation loss improved from 2.7277 to 2.7273. Saving model...\n",
      "\n",
      "LOG: Epoch [931/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3512\n",
      "Epoch [931/2000], Avg Train Loss: 3.3512\n",
      "Epoch [931/2000], Avg Val Loss: 2.7271\n",
      "Validation loss improved from 2.7273 to 2.7271. Saving model...\n",
      "\n",
      "LOG: Epoch [932/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2700\n",
      "Epoch [932/2000], Avg Train Loss: 3.2700\n",
      "Epoch [932/2000], Avg Val Loss: 2.7269\n",
      "Validation loss improved from 2.7271 to 2.7269. Saving model...\n",
      "\n",
      "LOG: Epoch [933/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2289\n",
      "Epoch [933/2000], Avg Train Loss: 3.2289\n",
      "Epoch [933/2000], Avg Val Loss: 2.7267\n",
      "Validation loss improved from 2.7269 to 2.7267. Saving model...\n",
      "\n",
      "LOG: Epoch [934/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2256\n",
      "Epoch [934/2000], Avg Train Loss: 3.2256\n",
      "Epoch [934/2000], Avg Val Loss: 2.7265\n",
      "Validation loss improved from 2.7267 to 2.7265. Saving model...\n",
      "\n",
      "LOG: Epoch [935/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2798\n",
      "Epoch [935/2000], Avg Train Loss: 3.2798\n",
      "Epoch [935/2000], Avg Val Loss: 2.7265\n",
      "Validation loss improved from 2.7265 to 2.7265. Saving model...\n",
      "\n",
      "LOG: Epoch [936/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2820\n",
      "Epoch [936/2000], Avg Train Loss: 3.2820\n",
      "Epoch [936/2000], Avg Val Loss: 2.7265\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [937/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1915\n",
      "Epoch [937/2000], Avg Train Loss: 3.1915\n",
      "Epoch [937/2000], Avg Val Loss: 2.7265\n",
      "Validation loss improved from 2.7265 to 2.7265. Saving model...\n",
      "\n",
      "LOG: Epoch [938/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2331\n",
      "Epoch [938/2000], Avg Train Loss: 3.2331\n",
      "Epoch [938/2000], Avg Val Loss: 2.7265\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [939/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2187\n",
      "Epoch [939/2000], Avg Train Loss: 3.2187\n",
      "Epoch [939/2000], Avg Val Loss: 2.7264\n",
      "Validation loss improved from 2.7265 to 2.7264. Saving model...\n",
      "\n",
      "LOG: Epoch [940/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2068\n",
      "Epoch [940/2000], Avg Train Loss: 3.2068\n",
      "Epoch [940/2000], Avg Val Loss: 2.7262\n",
      "Validation loss improved from 2.7264 to 2.7262. Saving model...\n",
      "\n",
      "LOG: Epoch [941/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2361\n",
      "Epoch [941/2000], Avg Train Loss: 3.2361\n",
      "Epoch [941/2000], Avg Val Loss: 2.7259\n",
      "Validation loss improved from 2.7262 to 2.7259. Saving model...\n",
      "\n",
      "LOG: Epoch [942/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1978\n",
      "Epoch [942/2000], Avg Train Loss: 3.1978\n",
      "Epoch [942/2000], Avg Val Loss: 2.7256\n",
      "Validation loss improved from 2.7259 to 2.7256. Saving model...\n",
      "\n",
      "LOG: Epoch [943/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2384\n",
      "Epoch [943/2000], Avg Train Loss: 3.2384\n",
      "Epoch [943/2000], Avg Val Loss: 2.7251\n",
      "Validation loss improved from 2.7256 to 2.7251. Saving model...\n",
      "\n",
      "LOG: Epoch [944/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2036\n",
      "Epoch [944/2000], Avg Train Loss: 3.2036\n",
      "Epoch [944/2000], Avg Val Loss: 2.7246\n",
      "Validation loss improved from 2.7251 to 2.7246. Saving model...\n",
      "\n",
      "LOG: Epoch [945/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2189\n",
      "Epoch [945/2000], Avg Train Loss: 3.2189\n",
      "Epoch [945/2000], Avg Val Loss: 2.7243\n",
      "Validation loss improved from 2.7246 to 2.7243. Saving model...\n",
      "\n",
      "LOG: Epoch [946/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2724\n",
      "Epoch [946/2000], Avg Train Loss: 3.2724\n",
      "Epoch [946/2000], Avg Val Loss: 2.7240\n",
      "Validation loss improved from 2.7243 to 2.7240. Saving model...\n",
      "\n",
      "LOG: Epoch [947/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.3109\n",
      "Epoch [947/2000], Avg Train Loss: 3.3109\n",
      "Epoch [947/2000], Avg Val Loss: 2.7236\n",
      "Validation loss improved from 2.7240 to 2.7236. Saving model...\n",
      "\n",
      "LOG: Epoch [948/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2995\n",
      "Epoch [948/2000], Avg Train Loss: 3.2995\n",
      "Epoch [948/2000], Avg Val Loss: 2.7233\n",
      "Validation loss improved from 2.7236 to 2.7233. Saving model...\n",
      "\n",
      "LOG: Epoch [949/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2527\n",
      "Epoch [949/2000], Avg Train Loss: 3.2527\n",
      "Epoch [949/2000], Avg Val Loss: 2.7229\n",
      "Validation loss improved from 2.7233 to 2.7229. Saving model...\n",
      "\n",
      "LOG: Epoch [950/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2751\n",
      "Epoch [950/2000], Avg Train Loss: 3.2751\n",
      "Epoch [950/2000], Avg Val Loss: 2.7225\n",
      "Validation loss improved from 2.7229 to 2.7225. Saving model...\n",
      "\n",
      "LOG: Epoch [951/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2870\n",
      "Epoch [951/2000], Avg Train Loss: 3.2870\n",
      "Epoch [951/2000], Avg Val Loss: 2.7222\n",
      "Validation loss improved from 2.7225 to 2.7222. Saving model...\n",
      "\n",
      "LOG: Epoch [952/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2117\n",
      "Epoch [952/2000], Avg Train Loss: 3.2117\n",
      "Epoch [952/2000], Avg Val Loss: 2.7219\n",
      "Validation loss improved from 2.7222 to 2.7219. Saving model...\n",
      "\n",
      "LOG: Epoch [953/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2400\n",
      "Epoch [953/2000], Avg Train Loss: 3.2400\n",
      "Epoch [953/2000], Avg Val Loss: 2.7217\n",
      "Validation loss improved from 2.7219 to 2.7217. Saving model...\n",
      "\n",
      "LOG: Epoch [954/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2371\n",
      "Epoch [954/2000], Avg Train Loss: 3.2371\n",
      "Epoch [954/2000], Avg Val Loss: 2.7216\n",
      "Validation loss improved from 2.7217 to 2.7216. Saving model...\n",
      "\n",
      "LOG: Epoch [955/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2680\n",
      "Epoch [955/2000], Avg Train Loss: 3.2680\n",
      "Epoch [955/2000], Avg Val Loss: 2.7214\n",
      "Validation loss improved from 2.7216 to 2.7214. Saving model...\n",
      "\n",
      "LOG: Epoch [956/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2251\n",
      "Epoch [956/2000], Avg Train Loss: 3.2251\n",
      "Epoch [956/2000], Avg Val Loss: 2.7212\n",
      "Validation loss improved from 2.7214 to 2.7212. Saving model...\n",
      "\n",
      "LOG: Epoch [957/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2775\n",
      "Epoch [957/2000], Avg Train Loss: 3.2775\n",
      "Epoch [957/2000], Avg Val Loss: 2.7208\n",
      "Validation loss improved from 2.7212 to 2.7208. Saving model...\n",
      "\n",
      "LOG: Epoch [958/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2032\n",
      "Epoch [958/2000], Avg Train Loss: 3.2032\n",
      "Epoch [958/2000], Avg Val Loss: 2.7204\n",
      "Validation loss improved from 2.7208 to 2.7204. Saving model...\n",
      "\n",
      "LOG: Epoch [959/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1818\n",
      "Epoch [959/2000], Avg Train Loss: 3.1818\n",
      "Epoch [959/2000], Avg Val Loss: 2.7200\n",
      "Validation loss improved from 2.7204 to 2.7200. Saving model...\n",
      "\n",
      "LOG: Epoch [960/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1696\n",
      "Epoch [960/2000], Avg Train Loss: 3.1696\n",
      "Epoch [960/2000], Avg Val Loss: 2.7197\n",
      "Validation loss improved from 2.7200 to 2.7197. Saving model...\n",
      "\n",
      "LOG: Epoch [961/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1909\n",
      "Epoch [961/2000], Avg Train Loss: 3.1909\n",
      "Epoch [961/2000], Avg Val Loss: 2.7194\n",
      "Validation loss improved from 2.7197 to 2.7194. Saving model...\n",
      "\n",
      "LOG: Epoch [962/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2316\n",
      "Epoch [962/2000], Avg Train Loss: 3.2316\n",
      "Epoch [962/2000], Avg Val Loss: 2.7191\n",
      "Validation loss improved from 2.7194 to 2.7191. Saving model...\n",
      "\n",
      "LOG: Epoch [963/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2194\n",
      "Epoch [963/2000], Avg Train Loss: 3.2194\n",
      "Epoch [963/2000], Avg Val Loss: 2.7188\n",
      "Validation loss improved from 2.7191 to 2.7188. Saving model...\n",
      "\n",
      "LOG: Epoch [964/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2220\n",
      "Epoch [964/2000], Avg Train Loss: 3.2220\n",
      "Epoch [964/2000], Avg Val Loss: 2.7185\n",
      "Validation loss improved from 2.7188 to 2.7185. Saving model...\n",
      "\n",
      "LOG: Epoch [965/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1914\n",
      "Epoch [965/2000], Avg Train Loss: 3.1914\n",
      "Epoch [965/2000], Avg Val Loss: 2.7182\n",
      "Validation loss improved from 2.7185 to 2.7182. Saving model...\n",
      "\n",
      "LOG: Epoch [966/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2340\n",
      "Epoch [966/2000], Avg Train Loss: 3.2340\n",
      "Epoch [966/2000], Avg Val Loss: 2.7180\n",
      "Validation loss improved from 2.7182 to 2.7180. Saving model...\n",
      "\n",
      "LOG: Epoch [967/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.2036\n",
      "Epoch [967/2000], Avg Train Loss: 3.2036\n",
      "Epoch [967/2000], Avg Val Loss: 2.7178\n",
      "Validation loss improved from 2.7180 to 2.7178. Saving model...\n",
      "\n",
      "LOG: Epoch [968/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2306\n",
      "Epoch [968/2000], Avg Train Loss: 3.2306\n",
      "Epoch [968/2000], Avg Val Loss: 2.7176\n",
      "Validation loss improved from 2.7178 to 2.7176. Saving model...\n",
      "\n",
      "LOG: Epoch [969/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2225\n",
      "Epoch [969/2000], Avg Train Loss: 3.2225\n",
      "Epoch [969/2000], Avg Val Loss: 2.7175\n",
      "Validation loss improved from 2.7176 to 2.7175. Saving model...\n",
      "\n",
      "LOG: Epoch [970/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2179\n",
      "Epoch [970/2000], Avg Train Loss: 3.2179\n",
      "Epoch [970/2000], Avg Val Loss: 2.7174\n",
      "Validation loss improved from 2.7175 to 2.7174. Saving model...\n",
      "\n",
      "LOG: Epoch [971/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2365\n",
      "Epoch [971/2000], Avg Train Loss: 3.2365\n",
      "Epoch [971/2000], Avg Val Loss: 2.7174\n",
      "Validation loss improved from 2.7174 to 2.7174. Saving model...\n",
      "\n",
      "LOG: Epoch [972/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2046\n",
      "Epoch [972/2000], Avg Train Loss: 3.2046\n",
      "Epoch [972/2000], Avg Val Loss: 2.7174\n",
      "Validation loss improved from 2.7174 to 2.7174. Saving model...\n",
      "\n",
      "LOG: Epoch [973/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2616\n",
      "Epoch [973/2000], Avg Train Loss: 3.2616\n",
      "Epoch [973/2000], Avg Val Loss: 2.7174\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [974/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2227\n",
      "Epoch [974/2000], Avg Train Loss: 3.2227\n",
      "Epoch [974/2000], Avg Val Loss: 2.7175\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [975/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1951\n",
      "Epoch [975/2000], Avg Train Loss: 3.1951\n",
      "Epoch [975/2000], Avg Val Loss: 2.7177\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [976/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2423\n",
      "Epoch [976/2000], Avg Train Loss: 3.2423\n",
      "Epoch [976/2000], Avg Val Loss: 2.7179\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [977/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2029\n",
      "Epoch [977/2000], Avg Train Loss: 3.2029\n",
      "Epoch [977/2000], Avg Val Loss: 2.7182\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [978/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2535\n",
      "Epoch [978/2000], Avg Train Loss: 3.2535\n",
      "Epoch [978/2000], Avg Val Loss: 2.7184\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [979/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2113\n",
      "Epoch [979/2000], Avg Train Loss: 3.2113\n",
      "Epoch [979/2000], Avg Val Loss: 2.7184\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [980/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2341\n",
      "Epoch [980/2000], Avg Train Loss: 3.2341\n",
      "Epoch [980/2000], Avg Val Loss: 2.7183\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [981/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2280\n",
      "Epoch [981/2000], Avg Train Loss: 3.2280\n",
      "Epoch [981/2000], Avg Val Loss: 2.7180\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [982/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2078\n",
      "Epoch [982/2000], Avg Train Loss: 3.2078\n",
      "Epoch [982/2000], Avg Val Loss: 2.7177\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [983/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2475\n",
      "Epoch [983/2000], Avg Train Loss: 3.2475\n",
      "Epoch [983/2000], Avg Val Loss: 2.7175\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [984/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2602\n",
      "Epoch [984/2000], Avg Train Loss: 3.2602\n",
      "Epoch [984/2000], Avg Val Loss: 2.7171\n",
      "Validation loss improved from 2.7174 to 2.7171. Saving model...\n",
      "\n",
      "LOG: Epoch [985/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1942\n",
      "Epoch [985/2000], Avg Train Loss: 3.1942\n",
      "Epoch [985/2000], Avg Val Loss: 2.7169\n",
      "Validation loss improved from 2.7171 to 2.7169. Saving model...\n",
      "\n",
      "LOG: Epoch [986/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1857\n",
      "Epoch [986/2000], Avg Train Loss: 3.1857\n",
      "Epoch [986/2000], Avg Val Loss: 2.7167\n",
      "Validation loss improved from 2.7169 to 2.7167. Saving model...\n",
      "\n",
      "LOG: Epoch [987/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2274\n",
      "Epoch [987/2000], Avg Train Loss: 3.2274\n",
      "Epoch [987/2000], Avg Val Loss: 2.7164\n",
      "Validation loss improved from 2.7167 to 2.7164. Saving model...\n",
      "\n",
      "LOG: Epoch [988/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2204\n",
      "Epoch [988/2000], Avg Train Loss: 3.2204\n",
      "Epoch [988/2000], Avg Val Loss: 2.7161\n",
      "Validation loss improved from 2.7164 to 2.7161. Saving model...\n",
      "\n",
      "LOG: Epoch [989/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2329\n",
      "Epoch [989/2000], Avg Train Loss: 3.2329\n",
      "Epoch [989/2000], Avg Val Loss: 2.7158\n",
      "Validation loss improved from 2.7161 to 2.7158. Saving model...\n",
      "\n",
      "LOG: Epoch [990/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2545\n",
      "Epoch [990/2000], Avg Train Loss: 3.2545\n",
      "Epoch [990/2000], Avg Val Loss: 2.7155\n",
      "Validation loss improved from 2.7158 to 2.7155. Saving model...\n",
      "\n",
      "LOG: Epoch [991/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1848\n",
      "Epoch [991/2000], Avg Train Loss: 3.1848\n",
      "Epoch [991/2000], Avg Val Loss: 2.7153\n",
      "Validation loss improved from 2.7155 to 2.7153. Saving model...\n",
      "\n",
      "LOG: Epoch [992/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2327\n",
      "Epoch [992/2000], Avg Train Loss: 3.2327\n",
      "Epoch [992/2000], Avg Val Loss: 2.7152\n",
      "Validation loss improved from 2.7153 to 2.7152. Saving model...\n",
      "\n",
      "LOG: Epoch [993/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1805\n",
      "Epoch [993/2000], Avg Train Loss: 3.1805\n",
      "Epoch [993/2000], Avg Val Loss: 2.7151\n",
      "Validation loss improved from 2.7152 to 2.7151. Saving model...\n",
      "\n",
      "LOG: Epoch [994/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1767\n",
      "Epoch [994/2000], Avg Train Loss: 3.1767\n",
      "Epoch [994/2000], Avg Val Loss: 2.7150\n",
      "Validation loss improved from 2.7151 to 2.7150. Saving model...\n",
      "\n",
      "LOG: Epoch [995/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1568\n",
      "Epoch [995/2000], Avg Train Loss: 3.1568\n",
      "Epoch [995/2000], Avg Val Loss: 2.7148\n",
      "Validation loss improved from 2.7150 to 2.7148. Saving model...\n",
      "\n",
      "LOG: Epoch [996/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2119\n",
      "Epoch [996/2000], Avg Train Loss: 3.2119\n",
      "Epoch [996/2000], Avg Val Loss: 2.7147\n",
      "Validation loss improved from 2.7148 to 2.7147. Saving model...\n",
      "\n",
      "LOG: Epoch [997/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2242\n",
      "Epoch [997/2000], Avg Train Loss: 3.2242\n",
      "Epoch [997/2000], Avg Val Loss: 2.7146\n",
      "Validation loss improved from 2.7147 to 2.7146. Saving model...\n",
      "\n",
      "LOG: Epoch [998/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1957\n",
      "Epoch [998/2000], Avg Train Loss: 3.1957\n",
      "Epoch [998/2000], Avg Val Loss: 2.7143\n",
      "Validation loss improved from 2.7146 to 2.7143. Saving model...\n",
      "\n",
      "LOG: Epoch [999/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2152\n",
      "Epoch [999/2000], Avg Train Loss: 3.2152\n",
      "Epoch [999/2000], Avg Val Loss: 2.7140\n",
      "Validation loss improved from 2.7143 to 2.7140. Saving model...\n",
      "\n",
      "LOG: Epoch [1000/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2330\n",
      "Epoch [1000/2000], Avg Train Loss: 3.2330\n",
      "Epoch [1000/2000], Avg Val Loss: 2.7138\n",
      "Validation loss improved from 2.7140 to 2.7138. Saving model...\n",
      "\n",
      "LOG: Epoch [1001/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1771\n",
      "Epoch [1001/2000], Avg Train Loss: 3.1771\n",
      "Epoch [1001/2000], Avg Val Loss: 2.7136\n",
      "Validation loss improved from 2.7138 to 2.7136. Saving model...\n",
      "\n",
      "LOG: Epoch [1002/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1843\n",
      "Epoch [1002/2000], Avg Train Loss: 3.1843\n",
      "Epoch [1002/2000], Avg Val Loss: 2.7134\n",
      "Validation loss improved from 2.7136 to 2.7134. Saving model...\n",
      "\n",
      "LOG: Epoch [1003/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1755\n",
      "Epoch [1003/2000], Avg Train Loss: 3.1755\n",
      "Epoch [1003/2000], Avg Val Loss: 2.7132\n",
      "Validation loss improved from 2.7134 to 2.7132. Saving model...\n",
      "\n",
      "LOG: Epoch [1004/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2205\n",
      "Epoch [1004/2000], Avg Train Loss: 3.2205\n",
      "Epoch [1004/2000], Avg Val Loss: 2.7131\n",
      "Validation loss improved from 2.7132 to 2.7131. Saving model...\n",
      "\n",
      "LOG: Epoch [1005/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1833\n",
      "Epoch [1005/2000], Avg Train Loss: 3.1833\n",
      "Epoch [1005/2000], Avg Val Loss: 2.7129\n",
      "Validation loss improved from 2.7131 to 2.7129. Saving model...\n",
      "\n",
      "LOG: Epoch [1006/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1745\n",
      "Epoch [1006/2000], Avg Train Loss: 3.1745\n",
      "Epoch [1006/2000], Avg Val Loss: 2.7127\n",
      "Validation loss improved from 2.7129 to 2.7127. Saving model...\n",
      "\n",
      "LOG: Epoch [1007/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2190\n",
      "Epoch [1007/2000], Avg Train Loss: 3.2190\n",
      "Epoch [1007/2000], Avg Val Loss: 2.7124\n",
      "Validation loss improved from 2.7127 to 2.7124. Saving model...\n",
      "\n",
      "LOG: Epoch [1008/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1487\n",
      "Epoch [1008/2000], Avg Train Loss: 3.1487\n",
      "Epoch [1008/2000], Avg Val Loss: 2.7120\n",
      "Validation loss improved from 2.7124 to 2.7120. Saving model...\n",
      "\n",
      "LOG: Epoch [1009/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1859\n",
      "Epoch [1009/2000], Avg Train Loss: 3.1859\n",
      "Epoch [1009/2000], Avg Val Loss: 2.7114\n",
      "Validation loss improved from 2.7120 to 2.7114. Saving model...\n",
      "\n",
      "LOG: Epoch [1010/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2443\n",
      "Epoch [1010/2000], Avg Train Loss: 3.2443\n",
      "Epoch [1010/2000], Avg Val Loss: 2.7108\n",
      "Validation loss improved from 2.7114 to 2.7108. Saving model...\n",
      "\n",
      "LOG: Epoch [1011/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2321\n",
      "Epoch [1011/2000], Avg Train Loss: 3.2321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1011/2000], Avg Val Loss: 2.7102\n",
      "Validation loss improved from 2.7108 to 2.7102. Saving model...\n",
      "\n",
      "LOG: Epoch [1012/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2257\n",
      "Epoch [1012/2000], Avg Train Loss: 3.2257\n",
      "Epoch [1012/2000], Avg Val Loss: 2.7097\n",
      "Validation loss improved from 2.7102 to 2.7097. Saving model...\n",
      "\n",
      "LOG: Epoch [1013/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1952\n",
      "Epoch [1013/2000], Avg Train Loss: 3.1952\n",
      "Epoch [1013/2000], Avg Val Loss: 2.7092\n",
      "Validation loss improved from 2.7097 to 2.7092. Saving model...\n",
      "\n",
      "LOG: Epoch [1014/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2101\n",
      "Epoch [1014/2000], Avg Train Loss: 3.2101\n",
      "Epoch [1014/2000], Avg Val Loss: 2.7086\n",
      "Validation loss improved from 2.7092 to 2.7086. Saving model...\n",
      "\n",
      "LOG: Epoch [1015/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2270\n",
      "Epoch [1015/2000], Avg Train Loss: 3.2270\n",
      "Epoch [1015/2000], Avg Val Loss: 2.7083\n",
      "Validation loss improved from 2.7086 to 2.7083. Saving model...\n",
      "\n",
      "LOG: Epoch [1016/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2083\n",
      "Epoch [1016/2000], Avg Train Loss: 3.2083\n",
      "Epoch [1016/2000], Avg Val Loss: 2.7080\n",
      "Validation loss improved from 2.7083 to 2.7080. Saving model...\n",
      "\n",
      "LOG: Epoch [1017/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2265\n",
      "Epoch [1017/2000], Avg Train Loss: 3.2265\n",
      "Epoch [1017/2000], Avg Val Loss: 2.7077\n",
      "Validation loss improved from 2.7080 to 2.7077. Saving model...\n",
      "\n",
      "LOG: Epoch [1018/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2185\n",
      "Epoch [1018/2000], Avg Train Loss: 3.2185\n",
      "Epoch [1018/2000], Avg Val Loss: 2.7073\n",
      "Validation loss improved from 2.7077 to 2.7073. Saving model...\n",
      "\n",
      "LOG: Epoch [1019/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1872\n",
      "Epoch [1019/2000], Avg Train Loss: 3.1872\n",
      "Epoch [1019/2000], Avg Val Loss: 2.7071\n",
      "Validation loss improved from 2.7073 to 2.7071. Saving model...\n",
      "\n",
      "LOG: Epoch [1020/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1501\n",
      "Epoch [1020/2000], Avg Train Loss: 3.1501\n",
      "Epoch [1020/2000], Avg Val Loss: 2.7067\n",
      "Validation loss improved from 2.7071 to 2.7067. Saving model...\n",
      "\n",
      "LOG: Epoch [1021/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2356\n",
      "Epoch [1021/2000], Avg Train Loss: 3.2356\n",
      "Epoch [1021/2000], Avg Val Loss: 2.7064\n",
      "Validation loss improved from 2.7067 to 2.7064. Saving model...\n",
      "\n",
      "LOG: Epoch [1022/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2073\n",
      "Epoch [1022/2000], Avg Train Loss: 3.2073\n",
      "Epoch [1022/2000], Avg Val Loss: 2.7060\n",
      "Validation loss improved from 2.7064 to 2.7060. Saving model...\n",
      "\n",
      "LOG: Epoch [1023/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2017\n",
      "Epoch [1023/2000], Avg Train Loss: 3.2017\n",
      "Epoch [1023/2000], Avg Val Loss: 2.7056\n",
      "Validation loss improved from 2.7060 to 2.7056. Saving model...\n",
      "\n",
      "LOG: Epoch [1024/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2148\n",
      "Epoch [1024/2000], Avg Train Loss: 3.2148\n",
      "Epoch [1024/2000], Avg Val Loss: 2.7052\n",
      "Validation loss improved from 2.7056 to 2.7052. Saving model...\n",
      "\n",
      "LOG: Epoch [1025/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1533\n",
      "Epoch [1025/2000], Avg Train Loss: 3.1533\n",
      "Epoch [1025/2000], Avg Val Loss: 2.7048\n",
      "Validation loss improved from 2.7052 to 2.7048. Saving model...\n",
      "\n",
      "LOG: Epoch [1026/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2102\n",
      "Epoch [1026/2000], Avg Train Loss: 3.2102\n",
      "Epoch [1026/2000], Avg Val Loss: 2.7044\n",
      "Validation loss improved from 2.7048 to 2.7044. Saving model...\n",
      "\n",
      "LOG: Epoch [1027/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1681\n",
      "Epoch [1027/2000], Avg Train Loss: 3.1681\n",
      "Epoch [1027/2000], Avg Val Loss: 2.7040\n",
      "Validation loss improved from 2.7044 to 2.7040. Saving model...\n",
      "\n",
      "LOG: Epoch [1028/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2186\n",
      "Epoch [1028/2000], Avg Train Loss: 3.2186\n",
      "Epoch [1028/2000], Avg Val Loss: 2.7035\n",
      "Validation loss improved from 2.7040 to 2.7035. Saving model...\n",
      "\n",
      "LOG: Epoch [1029/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1470\n",
      "Epoch [1029/2000], Avg Train Loss: 3.1470\n",
      "Epoch [1029/2000], Avg Val Loss: 2.7030\n",
      "Validation loss improved from 2.7035 to 2.7030. Saving model...\n",
      "\n",
      "LOG: Epoch [1030/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1628\n",
      "Epoch [1030/2000], Avg Train Loss: 3.1628\n",
      "Epoch [1030/2000], Avg Val Loss: 2.7022\n",
      "Validation loss improved from 2.7030 to 2.7022. Saving model...\n",
      "\n",
      "LOG: Epoch [1031/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1767\n",
      "Epoch [1031/2000], Avg Train Loss: 3.1767\n",
      "Epoch [1031/2000], Avg Val Loss: 2.7015\n",
      "Validation loss improved from 2.7022 to 2.7015. Saving model...\n",
      "\n",
      "LOG: Epoch [1032/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1692\n",
      "Epoch [1032/2000], Avg Train Loss: 3.1692\n",
      "Epoch [1032/2000], Avg Val Loss: 2.7008\n",
      "Validation loss improved from 2.7015 to 2.7008. Saving model...\n",
      "\n",
      "LOG: Epoch [1033/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1405\n",
      "Epoch [1033/2000], Avg Train Loss: 3.1405\n",
      "Epoch [1033/2000], Avg Val Loss: 2.7001\n",
      "Validation loss improved from 2.7008 to 2.7001. Saving model...\n",
      "\n",
      "LOG: Epoch [1034/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2139\n",
      "Epoch [1034/2000], Avg Train Loss: 3.2139\n",
      "Epoch [1034/2000], Avg Val Loss: 2.6994\n",
      "Validation loss improved from 2.7001 to 2.6994. Saving model...\n",
      "\n",
      "LOG: Epoch [1035/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2199\n",
      "Epoch [1035/2000], Avg Train Loss: 3.2199\n",
      "Epoch [1035/2000], Avg Val Loss: 2.6986\n",
      "Validation loss improved from 2.6994 to 2.6986. Saving model...\n",
      "\n",
      "LOG: Epoch [1036/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1801\n",
      "Epoch [1036/2000], Avg Train Loss: 3.1801\n",
      "Epoch [1036/2000], Avg Val Loss: 2.6980\n",
      "Validation loss improved from 2.6986 to 2.6980. Saving model...\n",
      "\n",
      "LOG: Epoch [1037/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1607\n",
      "Epoch [1037/2000], Avg Train Loss: 3.1607\n",
      "Epoch [1037/2000], Avg Val Loss: 2.6975\n",
      "Validation loss improved from 2.6980 to 2.6975. Saving model...\n",
      "\n",
      "LOG: Epoch [1038/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0925\n",
      "Epoch [1038/2000], Avg Train Loss: 3.0925\n",
      "Epoch [1038/2000], Avg Val Loss: 2.6970\n",
      "Validation loss improved from 2.6975 to 2.6970. Saving model...\n",
      "\n",
      "LOG: Epoch [1039/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1513\n",
      "Epoch [1039/2000], Avg Train Loss: 3.1513\n",
      "Epoch [1039/2000], Avg Val Loss: 2.6966\n",
      "Validation loss improved from 2.6970 to 2.6966. Saving model...\n",
      "\n",
      "LOG: Epoch [1040/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2245\n",
      "Epoch [1040/2000], Avg Train Loss: 3.2245\n",
      "Epoch [1040/2000], Avg Val Loss: 2.6961\n",
      "Validation loss improved from 2.6966 to 2.6961. Saving model...\n",
      "\n",
      "LOG: Epoch [1041/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1509\n",
      "Epoch [1041/2000], Avg Train Loss: 3.1509\n",
      "Epoch [1041/2000], Avg Val Loss: 2.6957\n",
      "Validation loss improved from 2.6961 to 2.6957. Saving model...\n",
      "\n",
      "LOG: Epoch [1042/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1770\n",
      "Epoch [1042/2000], Avg Train Loss: 3.1770\n",
      "Epoch [1042/2000], Avg Val Loss: 2.6955\n",
      "Validation loss improved from 2.6957 to 2.6955. Saving model...\n",
      "\n",
      "LOG: Epoch [1043/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1832\n",
      "Epoch [1043/2000], Avg Train Loss: 3.1832\n",
      "Epoch [1043/2000], Avg Val Loss: 2.6954\n",
      "Validation loss improved from 2.6955 to 2.6954. Saving model...\n",
      "\n",
      "LOG: Epoch [1044/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1175\n",
      "Epoch [1044/2000], Avg Train Loss: 3.1175\n",
      "Epoch [1044/2000], Avg Val Loss: 2.6953\n",
      "Validation loss improved from 2.6954 to 2.6953. Saving model...\n",
      "\n",
      "LOG: Epoch [1045/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1794\n",
      "Epoch [1045/2000], Avg Train Loss: 3.1794\n",
      "Epoch [1045/2000], Avg Val Loss: 2.6952\n",
      "Validation loss improved from 2.6953 to 2.6952. Saving model...\n",
      "\n",
      "LOG: Epoch [1046/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1623\n",
      "Epoch [1046/2000], Avg Train Loss: 3.1623\n",
      "Epoch [1046/2000], Avg Val Loss: 2.6951\n",
      "Validation loss improved from 2.6952 to 2.6951. Saving model...\n",
      "\n",
      "LOG: Epoch [1047/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0938\n",
      "Epoch [1047/2000], Avg Train Loss: 3.0938\n",
      "Epoch [1047/2000], Avg Val Loss: 2.6951\n",
      "Validation loss improved from 2.6951 to 2.6951. Saving model...\n",
      "\n",
      "LOG: Epoch [1048/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1794\n",
      "Epoch [1048/2000], Avg Train Loss: 3.1794\n",
      "Epoch [1048/2000], Avg Val Loss: 2.6951\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1049/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1297\n",
      "Epoch [1049/2000], Avg Train Loss: 3.1297\n",
      "Epoch [1049/2000], Avg Val Loss: 2.6951\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1050/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1316\n",
      "Epoch [1050/2000], Avg Train Loss: 3.1316\n",
      "Epoch [1050/2000], Avg Val Loss: 2.6951\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1051/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1845\n",
      "Epoch [1051/2000], Avg Train Loss: 3.1845\n",
      "Epoch [1051/2000], Avg Val Loss: 2.6951\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1052/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1991\n",
      "Epoch [1052/2000], Avg Train Loss: 3.1991\n",
      "Epoch [1052/2000], Avg Val Loss: 2.6950\n",
      "Validation loss improved from 2.6951 to 2.6950. Saving model...\n",
      "\n",
      "LOG: Epoch [1053/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1103\n",
      "Epoch [1053/2000], Avg Train Loss: 3.1103\n",
      "Epoch [1053/2000], Avg Val Loss: 2.6949\n",
      "Validation loss improved from 2.6950 to 2.6949. Saving model...\n",
      "\n",
      "LOG: Epoch [1054/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1478\n",
      "Epoch [1054/2000], Avg Train Loss: 3.1478\n",
      "Epoch [1054/2000], Avg Val Loss: 2.6948\n",
      "Validation loss improved from 2.6949 to 2.6948. Saving model...\n",
      "\n",
      "LOG: Epoch [1055/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.1821\n",
      "Epoch [1055/2000], Avg Train Loss: 3.1821\n",
      "Epoch [1055/2000], Avg Val Loss: 2.6946\n",
      "Validation loss improved from 2.6948 to 2.6946. Saving model...\n",
      "\n",
      "LOG: Epoch [1056/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1481\n",
      "Epoch [1056/2000], Avg Train Loss: 3.1481\n",
      "Epoch [1056/2000], Avg Val Loss: 2.6944\n",
      "Validation loss improved from 2.6946 to 2.6944. Saving model...\n",
      "\n",
      "LOG: Epoch [1057/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1192\n",
      "Epoch [1057/2000], Avg Train Loss: 3.1192\n",
      "Epoch [1057/2000], Avg Val Loss: 2.6941\n",
      "Validation loss improved from 2.6944 to 2.6941. Saving model...\n",
      "\n",
      "LOG: Epoch [1058/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1466\n",
      "Epoch [1058/2000], Avg Train Loss: 3.1466\n",
      "Epoch [1058/2000], Avg Val Loss: 2.6938\n",
      "Validation loss improved from 2.6941 to 2.6938. Saving model...\n",
      "\n",
      "LOG: Epoch [1059/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1299\n",
      "Epoch [1059/2000], Avg Train Loss: 3.1299\n",
      "Epoch [1059/2000], Avg Val Loss: 2.6935\n",
      "Validation loss improved from 2.6938 to 2.6935. Saving model...\n",
      "\n",
      "LOG: Epoch [1060/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1434\n",
      "Epoch [1060/2000], Avg Train Loss: 3.1434\n",
      "Epoch [1060/2000], Avg Val Loss: 2.6931\n",
      "Validation loss improved from 2.6935 to 2.6931. Saving model...\n",
      "\n",
      "LOG: Epoch [1061/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1310\n",
      "Epoch [1061/2000], Avg Train Loss: 3.1310\n",
      "Epoch [1061/2000], Avg Val Loss: 2.6927\n",
      "Validation loss improved from 2.6931 to 2.6927. Saving model...\n",
      "\n",
      "LOG: Epoch [1062/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1353\n",
      "Epoch [1062/2000], Avg Train Loss: 3.1353\n",
      "Epoch [1062/2000], Avg Val Loss: 2.6923\n",
      "Validation loss improved from 2.6927 to 2.6923. Saving model...\n",
      "\n",
      "LOG: Epoch [1063/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1835\n",
      "Epoch [1063/2000], Avg Train Loss: 3.1835\n",
      "Epoch [1063/2000], Avg Val Loss: 2.6920\n",
      "Validation loss improved from 2.6923 to 2.6920. Saving model...\n",
      "\n",
      "LOG: Epoch [1064/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1518\n",
      "Epoch [1064/2000], Avg Train Loss: 3.1518\n",
      "Epoch [1064/2000], Avg Val Loss: 2.6917\n",
      "Validation loss improved from 2.6920 to 2.6917. Saving model...\n",
      "\n",
      "LOG: Epoch [1065/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.2242\n",
      "Epoch [1065/2000], Avg Train Loss: 3.2242\n",
      "Epoch [1065/2000], Avg Val Loss: 2.6913\n",
      "Validation loss improved from 2.6917 to 2.6913. Saving model...\n",
      "\n",
      "LOG: Epoch [1066/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1888\n",
      "Epoch [1066/2000], Avg Train Loss: 3.1888\n",
      "Epoch [1066/2000], Avg Val Loss: 2.6909\n",
      "Validation loss improved from 2.6913 to 2.6909. Saving model...\n",
      "\n",
      "LOG: Epoch [1067/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1262\n",
      "Epoch [1067/2000], Avg Train Loss: 3.1262\n",
      "Epoch [1067/2000], Avg Val Loss: 2.6905\n",
      "Validation loss improved from 2.6909 to 2.6905. Saving model...\n",
      "\n",
      "LOG: Epoch [1068/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1136\n",
      "Epoch [1068/2000], Avg Train Loss: 3.1136\n",
      "Epoch [1068/2000], Avg Val Loss: 2.6902\n",
      "Validation loss improved from 2.6905 to 2.6902. Saving model...\n",
      "\n",
      "LOG: Epoch [1069/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1578\n",
      "Epoch [1069/2000], Avg Train Loss: 3.1578\n",
      "Epoch [1069/2000], Avg Val Loss: 2.6897\n",
      "Validation loss improved from 2.6902 to 2.6897. Saving model...\n",
      "\n",
      "LOG: Epoch [1070/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1602\n",
      "Epoch [1070/2000], Avg Train Loss: 3.1602\n",
      "Epoch [1070/2000], Avg Val Loss: 2.6892\n",
      "Validation loss improved from 2.6897 to 2.6892. Saving model...\n",
      "\n",
      "LOG: Epoch [1071/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1173\n",
      "Epoch [1071/2000], Avg Train Loss: 3.1173\n",
      "Epoch [1071/2000], Avg Val Loss: 2.6887\n",
      "Validation loss improved from 2.6892 to 2.6887. Saving model...\n",
      "\n",
      "LOG: Epoch [1072/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0993\n",
      "Epoch [1072/2000], Avg Train Loss: 3.0993\n",
      "Epoch [1072/2000], Avg Val Loss: 2.6882\n",
      "Validation loss improved from 2.6887 to 2.6882. Saving model...\n",
      "\n",
      "LOG: Epoch [1073/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1432\n",
      "Epoch [1073/2000], Avg Train Loss: 3.1432\n",
      "Epoch [1073/2000], Avg Val Loss: 2.6876\n",
      "Validation loss improved from 2.6882 to 2.6876. Saving model...\n",
      "\n",
      "LOG: Epoch [1074/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1315\n",
      "Epoch [1074/2000], Avg Train Loss: 3.1315\n",
      "Epoch [1074/2000], Avg Val Loss: 2.6871\n",
      "Validation loss improved from 2.6876 to 2.6871. Saving model...\n",
      "\n",
      "LOG: Epoch [1075/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1617\n",
      "Epoch [1075/2000], Avg Train Loss: 3.1617\n",
      "Epoch [1075/2000], Avg Val Loss: 2.6865\n",
      "Validation loss improved from 2.6871 to 2.6865. Saving model...\n",
      "\n",
      "LOG: Epoch [1076/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1752\n",
      "Epoch [1076/2000], Avg Train Loss: 3.1752\n",
      "Epoch [1076/2000], Avg Val Loss: 2.6859\n",
      "Validation loss improved from 2.6865 to 2.6859. Saving model...\n",
      "\n",
      "LOG: Epoch [1077/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1685\n",
      "Epoch [1077/2000], Avg Train Loss: 3.1685\n",
      "Epoch [1077/2000], Avg Val Loss: 2.6855\n",
      "Validation loss improved from 2.6859 to 2.6855. Saving model...\n",
      "\n",
      "LOG: Epoch [1078/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1563\n",
      "Epoch [1078/2000], Avg Train Loss: 3.1563\n",
      "Epoch [1078/2000], Avg Val Loss: 2.6851\n",
      "Validation loss improved from 2.6855 to 2.6851. Saving model...\n",
      "\n",
      "LOG: Epoch [1079/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1237\n",
      "Epoch [1079/2000], Avg Train Loss: 3.1237\n",
      "Epoch [1079/2000], Avg Val Loss: 2.6847\n",
      "Validation loss improved from 2.6851 to 2.6847. Saving model...\n",
      "\n",
      "LOG: Epoch [1080/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1532\n",
      "Epoch [1080/2000], Avg Train Loss: 3.1532\n",
      "Epoch [1080/2000], Avg Val Loss: 2.6843\n",
      "Validation loss improved from 2.6847 to 2.6843. Saving model...\n",
      "\n",
      "LOG: Epoch [1081/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1857\n",
      "Epoch [1081/2000], Avg Train Loss: 3.1857\n",
      "Epoch [1081/2000], Avg Val Loss: 2.6840\n",
      "Validation loss improved from 2.6843 to 2.6840. Saving model...\n",
      "\n",
      "LOG: Epoch [1082/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1276\n",
      "Epoch [1082/2000], Avg Train Loss: 3.1276\n",
      "Epoch [1082/2000], Avg Val Loss: 2.6838\n",
      "Validation loss improved from 2.6840 to 2.6838. Saving model...\n",
      "\n",
      "LOG: Epoch [1083/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1193\n",
      "Epoch [1083/2000], Avg Train Loss: 3.1193\n",
      "Epoch [1083/2000], Avg Val Loss: 2.6835\n",
      "Validation loss improved from 2.6838 to 2.6835. Saving model...\n",
      "\n",
      "LOG: Epoch [1084/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1368\n",
      "Epoch [1084/2000], Avg Train Loss: 3.1368\n",
      "Epoch [1084/2000], Avg Val Loss: 2.6834\n",
      "Validation loss improved from 2.6835 to 2.6834. Saving model...\n",
      "\n",
      "LOG: Epoch [1085/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1623\n",
      "Epoch [1085/2000], Avg Train Loss: 3.1623\n",
      "Epoch [1085/2000], Avg Val Loss: 2.6835\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1086/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0903\n",
      "Epoch [1086/2000], Avg Train Loss: 3.0903\n",
      "Epoch [1086/2000], Avg Val Loss: 2.6836\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1087/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1266\n",
      "Epoch [1087/2000], Avg Train Loss: 3.1266\n",
      "Epoch [1087/2000], Avg Val Loss: 2.6837\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1088/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1714\n",
      "Epoch [1088/2000], Avg Train Loss: 3.1714\n",
      "Epoch [1088/2000], Avg Val Loss: 2.6838\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1089/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1212\n",
      "Epoch [1089/2000], Avg Train Loss: 3.1212\n",
      "Epoch [1089/2000], Avg Val Loss: 2.6839\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1090/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1273\n",
      "Epoch [1090/2000], Avg Train Loss: 3.1273\n",
      "Epoch [1090/2000], Avg Val Loss: 2.6840\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1091/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1317\n",
      "Epoch [1091/2000], Avg Train Loss: 3.1317\n",
      "Epoch [1091/2000], Avg Val Loss: 2.6839\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1092/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1195\n",
      "Epoch [1092/2000], Avg Train Loss: 3.1195\n",
      "Epoch [1092/2000], Avg Val Loss: 2.6838\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1093/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1388\n",
      "Epoch [1093/2000], Avg Train Loss: 3.1388\n",
      "Epoch [1093/2000], Avg Val Loss: 2.6836\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1094/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1119\n",
      "Epoch [1094/2000], Avg Train Loss: 3.1119\n",
      "Epoch [1094/2000], Avg Val Loss: 2.6834\n",
      "Validation loss improved from 2.6834 to 2.6834. Saving model...\n",
      "\n",
      "LOG: Epoch [1095/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0921\n",
      "Epoch [1095/2000], Avg Train Loss: 3.0921\n",
      "Epoch [1095/2000], Avg Val Loss: 2.6832\n",
      "Validation loss improved from 2.6834 to 2.6832. Saving model...\n",
      "\n",
      "LOG: Epoch [1096/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1281\n",
      "Epoch [1096/2000], Avg Train Loss: 3.1281\n",
      "Epoch [1096/2000], Avg Val Loss: 2.6828\n",
      "Validation loss improved from 2.6832 to 2.6828. Saving model...\n",
      "\n",
      "LOG: Epoch [1097/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1414\n",
      "Epoch [1097/2000], Avg Train Loss: 3.1414\n",
      "Epoch [1097/2000], Avg Val Loss: 2.6826\n",
      "Validation loss improved from 2.6828 to 2.6826. Saving model...\n",
      "\n",
      "LOG: Epoch [1098/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1272\n",
      "Epoch [1098/2000], Avg Train Loss: 3.1272\n",
      "Epoch [1098/2000], Avg Val Loss: 2.6824\n",
      "Validation loss improved from 2.6826 to 2.6824. Saving model...\n",
      "\n",
      "LOG: Epoch [1099/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.0944\n",
      "Epoch [1099/2000], Avg Train Loss: 3.0944\n",
      "Epoch [1099/2000], Avg Val Loss: 2.6823\n",
      "Validation loss improved from 2.6824 to 2.6823. Saving model...\n",
      "\n",
      "LOG: Epoch [1100/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1518\n",
      "Epoch [1100/2000], Avg Train Loss: 3.1518\n",
      "Epoch [1100/2000], Avg Val Loss: 2.6820\n",
      "Validation loss improved from 2.6823 to 2.6820. Saving model...\n",
      "\n",
      "LOG: Epoch [1101/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0907\n",
      "Epoch [1101/2000], Avg Train Loss: 3.0907\n",
      "Epoch [1101/2000], Avg Val Loss: 2.6817\n",
      "Validation loss improved from 2.6820 to 2.6817. Saving model...\n",
      "\n",
      "LOG: Epoch [1102/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1547\n",
      "Epoch [1102/2000], Avg Train Loss: 3.1547\n",
      "Epoch [1102/2000], Avg Val Loss: 2.6815\n",
      "Validation loss improved from 2.6817 to 2.6815. Saving model...\n",
      "\n",
      "LOG: Epoch [1103/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1349\n",
      "Epoch [1103/2000], Avg Train Loss: 3.1349\n",
      "Epoch [1103/2000], Avg Val Loss: 2.6812\n",
      "Validation loss improved from 2.6815 to 2.6812. Saving model...\n",
      "\n",
      "LOG: Epoch [1104/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1403\n",
      "Epoch [1104/2000], Avg Train Loss: 3.1403\n",
      "Epoch [1104/2000], Avg Val Loss: 2.6810\n",
      "Validation loss improved from 2.6812 to 2.6810. Saving model...\n",
      "\n",
      "LOG: Epoch [1105/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1268\n",
      "Epoch [1105/2000], Avg Train Loss: 3.1268\n",
      "Epoch [1105/2000], Avg Val Loss: 2.6807\n",
      "Validation loss improved from 2.6810 to 2.6807. Saving model...\n",
      "\n",
      "LOG: Epoch [1106/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1634\n",
      "Epoch [1106/2000], Avg Train Loss: 3.1634\n",
      "Epoch [1106/2000], Avg Val Loss: 2.6805\n",
      "Validation loss improved from 2.6807 to 2.6805. Saving model...\n",
      "\n",
      "LOG: Epoch [1107/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0800\n",
      "Epoch [1107/2000], Avg Train Loss: 3.0800\n",
      "Epoch [1107/2000], Avg Val Loss: 2.6802\n",
      "Validation loss improved from 2.6805 to 2.6802. Saving model...\n",
      "\n",
      "LOG: Epoch [1108/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1243\n",
      "Epoch [1108/2000], Avg Train Loss: 3.1243\n",
      "Epoch [1108/2000], Avg Val Loss: 2.6799\n",
      "Validation loss improved from 2.6802 to 2.6799. Saving model...\n",
      "\n",
      "LOG: Epoch [1109/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0936\n",
      "Epoch [1109/2000], Avg Train Loss: 3.0936\n",
      "Epoch [1109/2000], Avg Val Loss: 2.6795\n",
      "Validation loss improved from 2.6799 to 2.6795. Saving model...\n",
      "\n",
      "LOG: Epoch [1110/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1500\n",
      "Epoch [1110/2000], Avg Train Loss: 3.1500\n",
      "Epoch [1110/2000], Avg Val Loss: 2.6792\n",
      "Validation loss improved from 2.6795 to 2.6792. Saving model...\n",
      "\n",
      "LOG: Epoch [1111/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1359\n",
      "Epoch [1111/2000], Avg Train Loss: 3.1359\n",
      "Epoch [1111/2000], Avg Val Loss: 2.6790\n",
      "Validation loss improved from 2.6792 to 2.6790. Saving model...\n",
      "\n",
      "LOG: Epoch [1112/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1310\n",
      "Epoch [1112/2000], Avg Train Loss: 3.1310\n",
      "Epoch [1112/2000], Avg Val Loss: 2.6788\n",
      "Validation loss improved from 2.6790 to 2.6788. Saving model...\n",
      "\n",
      "LOG: Epoch [1113/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1219\n",
      "Epoch [1113/2000], Avg Train Loss: 3.1219\n",
      "Epoch [1113/2000], Avg Val Loss: 2.6785\n",
      "Validation loss improved from 2.6788 to 2.6785. Saving model...\n",
      "\n",
      "LOG: Epoch [1114/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1573\n",
      "Epoch [1114/2000], Avg Train Loss: 3.1573\n",
      "Epoch [1114/2000], Avg Val Loss: 2.6783\n",
      "Validation loss improved from 2.6785 to 2.6783. Saving model...\n",
      "\n",
      "LOG: Epoch [1115/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1285\n",
      "Epoch [1115/2000], Avg Train Loss: 3.1285\n",
      "Epoch [1115/2000], Avg Val Loss: 2.6782\n",
      "Validation loss improved from 2.6783 to 2.6782. Saving model...\n",
      "\n",
      "LOG: Epoch [1116/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1167\n",
      "Epoch [1116/2000], Avg Train Loss: 3.1167\n",
      "Epoch [1116/2000], Avg Val Loss: 2.6780\n",
      "Validation loss improved from 2.6782 to 2.6780. Saving model...\n",
      "\n",
      "LOG: Epoch [1117/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1116\n",
      "Epoch [1117/2000], Avg Train Loss: 3.1116\n",
      "Epoch [1117/2000], Avg Val Loss: 2.6779\n",
      "Validation loss improved from 2.6780 to 2.6779. Saving model...\n",
      "\n",
      "LOG: Epoch [1118/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1537\n",
      "Epoch [1118/2000], Avg Train Loss: 3.1537\n",
      "Epoch [1118/2000], Avg Val Loss: 2.6778\n",
      "Validation loss improved from 2.6779 to 2.6778. Saving model...\n",
      "\n",
      "LOG: Epoch [1119/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1320\n",
      "Epoch [1119/2000], Avg Train Loss: 3.1320\n",
      "Epoch [1119/2000], Avg Val Loss: 2.6776\n",
      "Validation loss improved from 2.6778 to 2.6776. Saving model...\n",
      "\n",
      "LOG: Epoch [1120/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0910\n",
      "Epoch [1120/2000], Avg Train Loss: 3.0910\n",
      "Epoch [1120/2000], Avg Val Loss: 2.6776\n",
      "Validation loss improved from 2.6776 to 2.6776. Saving model...\n",
      "\n",
      "LOG: Epoch [1121/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0451\n",
      "Epoch [1121/2000], Avg Train Loss: 3.0451\n",
      "Epoch [1121/2000], Avg Val Loss: 2.6775\n",
      "Validation loss improved from 2.6776 to 2.6775. Saving model...\n",
      "\n",
      "LOG: Epoch [1122/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0689\n",
      "Epoch [1122/2000], Avg Train Loss: 3.0689\n",
      "Epoch [1122/2000], Avg Val Loss: 2.6774\n",
      "Validation loss improved from 2.6775 to 2.6774. Saving model...\n",
      "\n",
      "LOG: Epoch [1123/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1420\n",
      "Epoch [1123/2000], Avg Train Loss: 3.1420\n",
      "Epoch [1123/2000], Avg Val Loss: 2.6773\n",
      "Validation loss improved from 2.6774 to 2.6773. Saving model...\n",
      "\n",
      "LOG: Epoch [1124/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0771\n",
      "Epoch [1124/2000], Avg Train Loss: 3.0771\n",
      "Epoch [1124/2000], Avg Val Loss: 2.6772\n",
      "Validation loss improved from 2.6773 to 2.6772. Saving model...\n",
      "\n",
      "LOG: Epoch [1125/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0789\n",
      "Epoch [1125/2000], Avg Train Loss: 3.0789\n",
      "Epoch [1125/2000], Avg Val Loss: 2.6770\n",
      "Validation loss improved from 2.6772 to 2.6770. Saving model...\n",
      "\n",
      "LOG: Epoch [1126/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0894\n",
      "Epoch [1126/2000], Avg Train Loss: 3.0894\n",
      "Epoch [1126/2000], Avg Val Loss: 2.6768\n",
      "Validation loss improved from 2.6770 to 2.6768. Saving model...\n",
      "\n",
      "LOG: Epoch [1127/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1034\n",
      "Epoch [1127/2000], Avg Train Loss: 3.1034\n",
      "Epoch [1127/2000], Avg Val Loss: 2.6767\n",
      "Validation loss improved from 2.6768 to 2.6767. Saving model...\n",
      "\n",
      "LOG: Epoch [1128/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1076\n",
      "Epoch [1128/2000], Avg Train Loss: 3.1076\n",
      "Epoch [1128/2000], Avg Val Loss: 2.6765\n",
      "Validation loss improved from 2.6767 to 2.6765. Saving model...\n",
      "\n",
      "LOG: Epoch [1129/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1343\n",
      "Epoch [1129/2000], Avg Train Loss: 3.1343\n",
      "Epoch [1129/2000], Avg Val Loss: 2.6763\n",
      "Validation loss improved from 2.6765 to 2.6763. Saving model...\n",
      "\n",
      "LOG: Epoch [1130/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0869\n",
      "Epoch [1130/2000], Avg Train Loss: 3.0869\n",
      "Epoch [1130/2000], Avg Val Loss: 2.6761\n",
      "Validation loss improved from 2.6763 to 2.6761. Saving model...\n",
      "\n",
      "LOG: Epoch [1131/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0803\n",
      "Epoch [1131/2000], Avg Train Loss: 3.0803\n",
      "Epoch [1131/2000], Avg Val Loss: 2.6760\n",
      "Validation loss improved from 2.6761 to 2.6760. Saving model...\n",
      "\n",
      "LOG: Epoch [1132/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1143\n",
      "Epoch [1132/2000], Avg Train Loss: 3.1143\n",
      "Epoch [1132/2000], Avg Val Loss: 2.6755\n",
      "Validation loss improved from 2.6760 to 2.6755. Saving model...\n",
      "\n",
      "LOG: Epoch [1133/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1503\n",
      "Epoch [1133/2000], Avg Train Loss: 3.1503\n",
      "Epoch [1133/2000], Avg Val Loss: 2.6753\n",
      "Validation loss improved from 2.6755 to 2.6753. Saving model...\n",
      "\n",
      "LOG: Epoch [1134/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1154\n",
      "Epoch [1134/2000], Avg Train Loss: 3.1154\n",
      "Epoch [1134/2000], Avg Val Loss: 2.6751\n",
      "Validation loss improved from 2.6753 to 2.6751. Saving model...\n",
      "\n",
      "LOG: Epoch [1135/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0640\n",
      "Epoch [1135/2000], Avg Train Loss: 3.0640\n",
      "Epoch [1135/2000], Avg Val Loss: 2.6751\n",
      "Validation loss improved from 2.6751 to 2.6751. Saving model...\n",
      "\n",
      "LOG: Epoch [1136/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1142\n",
      "Epoch [1136/2000], Avg Train Loss: 3.1142\n",
      "Epoch [1136/2000], Avg Val Loss: 2.6750\n",
      "Validation loss improved from 2.6751 to 2.6750. Saving model...\n",
      "\n",
      "LOG: Epoch [1137/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0975\n",
      "Epoch [1137/2000], Avg Train Loss: 3.0975\n",
      "Epoch [1137/2000], Avg Val Loss: 2.6751\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1138/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0510\n",
      "Epoch [1138/2000], Avg Train Loss: 3.0510\n",
      "Epoch [1138/2000], Avg Val Loss: 2.6750\n",
      "Validation loss improved from 2.6750 to 2.6750. Saving model...\n",
      "\n",
      "LOG: Epoch [1139/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1009\n",
      "Epoch [1139/2000], Avg Train Loss: 3.1009\n",
      "Epoch [1139/2000], Avg Val Loss: 2.6748\n",
      "Validation loss improved from 2.6750 to 2.6748. Saving model...\n",
      "\n",
      "LOG: Epoch [1140/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1133\n",
      "Epoch [1140/2000], Avg Train Loss: 3.1133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1140/2000], Avg Val Loss: 2.6747\n",
      "Validation loss improved from 2.6748 to 2.6747. Saving model...\n",
      "\n",
      "LOG: Epoch [1141/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1015\n",
      "Epoch [1141/2000], Avg Train Loss: 3.1015\n",
      "Epoch [1141/2000], Avg Val Loss: 2.6744\n",
      "Validation loss improved from 2.6747 to 2.6744. Saving model...\n",
      "\n",
      "LOG: Epoch [1142/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1242\n",
      "Epoch [1142/2000], Avg Train Loss: 3.1242\n",
      "Epoch [1142/2000], Avg Val Loss: 2.6744\n",
      "Validation loss improved from 2.6744 to 2.6744. Saving model...\n",
      "\n",
      "LOG: Epoch [1143/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1034\n",
      "Epoch [1143/2000], Avg Train Loss: 3.1034\n",
      "Epoch [1143/2000], Avg Val Loss: 2.6745\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1144/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1155\n",
      "Epoch [1144/2000], Avg Train Loss: 3.1155\n",
      "Epoch [1144/2000], Avg Val Loss: 2.6745\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1145/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1250\n",
      "Epoch [1145/2000], Avg Train Loss: 3.1250\n",
      "Epoch [1145/2000], Avg Val Loss: 2.6746\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1146/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0597\n",
      "Epoch [1146/2000], Avg Train Loss: 3.0597\n",
      "Epoch [1146/2000], Avg Val Loss: 2.6747\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1147/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0620\n",
      "Epoch [1147/2000], Avg Train Loss: 3.0620\n",
      "Epoch [1147/2000], Avg Val Loss: 2.6747\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1148/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0684\n",
      "Epoch [1148/2000], Avg Train Loss: 3.0684\n",
      "Epoch [1148/2000], Avg Val Loss: 2.6745\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1149/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1145\n",
      "Epoch [1149/2000], Avg Train Loss: 3.1145\n",
      "Epoch [1149/2000], Avg Val Loss: 2.6743\n",
      "Validation loss improved from 2.6744 to 2.6743. Saving model...\n",
      "\n",
      "LOG: Epoch [1150/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0673\n",
      "Epoch [1150/2000], Avg Train Loss: 3.0673\n",
      "Epoch [1150/2000], Avg Val Loss: 2.6740\n",
      "Validation loss improved from 2.6743 to 2.6740. Saving model...\n",
      "\n",
      "LOG: Epoch [1151/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1100\n",
      "Epoch [1151/2000], Avg Train Loss: 3.1100\n",
      "Epoch [1151/2000], Avg Val Loss: 2.6734\n",
      "Validation loss improved from 2.6740 to 2.6734. Saving model...\n",
      "\n",
      "LOG: Epoch [1152/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1135\n",
      "Epoch [1152/2000], Avg Train Loss: 3.1135\n",
      "Epoch [1152/2000], Avg Val Loss: 2.6730\n",
      "Validation loss improved from 2.6734 to 2.6730. Saving model...\n",
      "\n",
      "LOG: Epoch [1153/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0581\n",
      "Epoch [1153/2000], Avg Train Loss: 3.0581\n",
      "Epoch [1153/2000], Avg Val Loss: 2.6725\n",
      "Validation loss improved from 2.6730 to 2.6725. Saving model...\n",
      "\n",
      "LOG: Epoch [1154/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1488\n",
      "Epoch [1154/2000], Avg Train Loss: 3.1488\n",
      "Epoch [1154/2000], Avg Val Loss: 2.6721\n",
      "Validation loss improved from 2.6725 to 2.6721. Saving model...\n",
      "\n",
      "LOG: Epoch [1155/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0651\n",
      "Epoch [1155/2000], Avg Train Loss: 3.0651\n",
      "Epoch [1155/2000], Avg Val Loss: 2.6716\n",
      "Validation loss improved from 2.6721 to 2.6716. Saving model...\n",
      "\n",
      "LOG: Epoch [1156/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0500\n",
      "Epoch [1156/2000], Avg Train Loss: 3.0500\n",
      "Epoch [1156/2000], Avg Val Loss: 2.6711\n",
      "Validation loss improved from 2.6716 to 2.6711. Saving model...\n",
      "\n",
      "LOG: Epoch [1157/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0537\n",
      "Epoch [1157/2000], Avg Train Loss: 3.0537\n",
      "Epoch [1157/2000], Avg Val Loss: 2.6705\n",
      "Validation loss improved from 2.6711 to 2.6705. Saving model...\n",
      "\n",
      "LOG: Epoch [1158/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1704\n",
      "Epoch [1158/2000], Avg Train Loss: 3.1704\n",
      "Epoch [1158/2000], Avg Val Loss: 2.6702\n",
      "Validation loss improved from 2.6705 to 2.6702. Saving model...\n",
      "\n",
      "LOG: Epoch [1159/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0804\n",
      "Epoch [1159/2000], Avg Train Loss: 3.0804\n",
      "Epoch [1159/2000], Avg Val Loss: 2.6697\n",
      "Validation loss improved from 2.6702 to 2.6697. Saving model...\n",
      "\n",
      "LOG: Epoch [1160/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0811\n",
      "Epoch [1160/2000], Avg Train Loss: 3.0811\n",
      "Epoch [1160/2000], Avg Val Loss: 2.6694\n",
      "Validation loss improved from 2.6697 to 2.6694. Saving model...\n",
      "\n",
      "LOG: Epoch [1161/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0270\n",
      "Epoch [1161/2000], Avg Train Loss: 3.0270\n",
      "Epoch [1161/2000], Avg Val Loss: 2.6691\n",
      "Validation loss improved from 2.6694 to 2.6691. Saving model...\n",
      "\n",
      "LOG: Epoch [1162/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1251\n",
      "Epoch [1162/2000], Avg Train Loss: 3.1251\n",
      "Epoch [1162/2000], Avg Val Loss: 2.6688\n",
      "Validation loss improved from 2.6691 to 2.6688. Saving model...\n",
      "\n",
      "LOG: Epoch [1163/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0772\n",
      "Epoch [1163/2000], Avg Train Loss: 3.0772\n",
      "Epoch [1163/2000], Avg Val Loss: 2.6686\n",
      "Validation loss improved from 2.6688 to 2.6686. Saving model...\n",
      "\n",
      "LOG: Epoch [1164/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0232\n",
      "Epoch [1164/2000], Avg Train Loss: 3.0232\n",
      "Epoch [1164/2000], Avg Val Loss: 2.6685\n",
      "Validation loss improved from 2.6686 to 2.6685. Saving model...\n",
      "\n",
      "LOG: Epoch [1165/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0341\n",
      "Epoch [1165/2000], Avg Train Loss: 3.0341\n",
      "Epoch [1165/2000], Avg Val Loss: 2.6683\n",
      "Validation loss improved from 2.6685 to 2.6683. Saving model...\n",
      "\n",
      "LOG: Epoch [1166/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0844\n",
      "Epoch [1166/2000], Avg Train Loss: 3.0844\n",
      "Epoch [1166/2000], Avg Val Loss: 2.6683\n",
      "Validation loss improved from 2.6683 to 2.6683. Saving model...\n",
      "\n",
      "LOG: Epoch [1167/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0302\n",
      "Epoch [1167/2000], Avg Train Loss: 3.0302\n",
      "Epoch [1167/2000], Avg Val Loss: 2.6683\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1168/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0691\n",
      "Epoch [1168/2000], Avg Train Loss: 3.0691\n",
      "Epoch [1168/2000], Avg Val Loss: 2.6683\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1169/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0339\n",
      "Epoch [1169/2000], Avg Train Loss: 3.0339\n",
      "Epoch [1169/2000], Avg Val Loss: 2.6681\n",
      "Validation loss improved from 2.6683 to 2.6681. Saving model...\n",
      "\n",
      "LOG: Epoch [1170/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0663\n",
      "Epoch [1170/2000], Avg Train Loss: 3.0663\n",
      "Epoch [1170/2000], Avg Val Loss: 2.6678\n",
      "Validation loss improved from 2.6681 to 2.6678. Saving model...\n",
      "\n",
      "LOG: Epoch [1171/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0362\n",
      "Epoch [1171/2000], Avg Train Loss: 3.0362\n",
      "Epoch [1171/2000], Avg Val Loss: 2.6676\n",
      "Validation loss improved from 2.6678 to 2.6676. Saving model...\n",
      "\n",
      "LOG: Epoch [1172/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0693\n",
      "Epoch [1172/2000], Avg Train Loss: 3.0693\n",
      "Epoch [1172/2000], Avg Val Loss: 2.6674\n",
      "Validation loss improved from 2.6676 to 2.6674. Saving model...\n",
      "\n",
      "LOG: Epoch [1173/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0892\n",
      "Epoch [1173/2000], Avg Train Loss: 3.0892\n",
      "Epoch [1173/2000], Avg Val Loss: 2.6673\n",
      "Validation loss improved from 2.6674 to 2.6673. Saving model...\n",
      "\n",
      "LOG: Epoch [1174/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0505\n",
      "Epoch [1174/2000], Avg Train Loss: 3.0505\n",
      "Epoch [1174/2000], Avg Val Loss: 2.6672\n",
      "Validation loss improved from 2.6673 to 2.6672. Saving model...\n",
      "\n",
      "LOG: Epoch [1175/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1237\n",
      "Epoch [1175/2000], Avg Train Loss: 3.1237\n",
      "Epoch [1175/2000], Avg Val Loss: 2.6671\n",
      "Validation loss improved from 2.6672 to 2.6671. Saving model...\n",
      "\n",
      "LOG: Epoch [1176/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0544\n",
      "Epoch [1176/2000], Avg Train Loss: 3.0544\n",
      "Epoch [1176/2000], Avg Val Loss: 2.6671\n",
      "Validation loss improved from 2.6671 to 2.6671. Saving model...\n",
      "\n",
      "LOG: Epoch [1177/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0621\n",
      "Epoch [1177/2000], Avg Train Loss: 3.0621\n",
      "Epoch [1177/2000], Avg Val Loss: 2.6671\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1178/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0631\n",
      "Epoch [1178/2000], Avg Train Loss: 3.0631\n",
      "Epoch [1178/2000], Avg Val Loss: 2.6671\n",
      "Validation loss improved from 2.6671 to 2.6671. Saving model...\n",
      "\n",
      "LOG: Epoch [1179/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0773\n",
      "Epoch [1179/2000], Avg Train Loss: 3.0773\n",
      "Epoch [1179/2000], Avg Val Loss: 2.6672\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1180/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0589\n",
      "Epoch [1180/2000], Avg Train Loss: 3.0589\n",
      "Epoch [1180/2000], Avg Val Loss: 2.6672\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1181/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0650\n",
      "Epoch [1181/2000], Avg Train Loss: 3.0650\n",
      "Epoch [1181/2000], Avg Val Loss: 2.6672\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1182/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0301\n",
      "Epoch [1182/2000], Avg Train Loss: 3.0301\n",
      "Epoch [1182/2000], Avg Val Loss: 2.6673\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1183/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0500\n",
      "Epoch [1183/2000], Avg Train Loss: 3.0500\n",
      "Epoch [1183/2000], Avg Val Loss: 2.6673\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1184/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0647\n",
      "Epoch [1184/2000], Avg Train Loss: 3.0647\n",
      "Epoch [1184/2000], Avg Val Loss: 2.6672\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1185/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0717\n",
      "Epoch [1185/2000], Avg Train Loss: 3.0717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1185/2000], Avg Val Loss: 2.6670\n",
      "Validation loss improved from 2.6671 to 2.6670. Saving model...\n",
      "\n",
      "LOG: Epoch [1186/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0872\n",
      "Epoch [1186/2000], Avg Train Loss: 3.0872\n",
      "Epoch [1186/2000], Avg Val Loss: 2.6667\n",
      "Validation loss improved from 2.6670 to 2.6667. Saving model...\n",
      "\n",
      "LOG: Epoch [1187/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0707\n",
      "Epoch [1187/2000], Avg Train Loss: 3.0707\n",
      "Epoch [1187/2000], Avg Val Loss: 2.6665\n",
      "Validation loss improved from 2.6667 to 2.6665. Saving model...\n",
      "\n",
      "LOG: Epoch [1188/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0704\n",
      "Epoch [1188/2000], Avg Train Loss: 3.0704\n",
      "Epoch [1188/2000], Avg Val Loss: 2.6663\n",
      "Validation loss improved from 2.6665 to 2.6663. Saving model...\n",
      "\n",
      "LOG: Epoch [1189/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0502\n",
      "Epoch [1189/2000], Avg Train Loss: 3.0502\n",
      "Epoch [1189/2000], Avg Val Loss: 2.6661\n",
      "Validation loss improved from 2.6663 to 2.6661. Saving model...\n",
      "\n",
      "LOG: Epoch [1190/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0684\n",
      "Epoch [1190/2000], Avg Train Loss: 3.0684\n",
      "Epoch [1190/2000], Avg Val Loss: 2.6658\n",
      "Validation loss improved from 2.6661 to 2.6658. Saving model...\n",
      "\n",
      "LOG: Epoch [1191/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0268\n",
      "Epoch [1191/2000], Avg Train Loss: 3.0268\n",
      "Epoch [1191/2000], Avg Val Loss: 2.6655\n",
      "Validation loss improved from 2.6658 to 2.6655. Saving model...\n",
      "\n",
      "LOG: Epoch [1192/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0698\n",
      "Epoch [1192/2000], Avg Train Loss: 3.0698\n",
      "Epoch [1192/2000], Avg Val Loss: 2.6651\n",
      "Validation loss improved from 2.6655 to 2.6651. Saving model...\n",
      "\n",
      "LOG: Epoch [1193/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0288\n",
      "Epoch [1193/2000], Avg Train Loss: 3.0288\n",
      "Epoch [1193/2000], Avg Val Loss: 2.6648\n",
      "Validation loss improved from 2.6651 to 2.6648. Saving model...\n",
      "\n",
      "LOG: Epoch [1194/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0511\n",
      "Epoch [1194/2000], Avg Train Loss: 3.0511\n",
      "Epoch [1194/2000], Avg Val Loss: 2.6644\n",
      "Validation loss improved from 2.6648 to 2.6644. Saving model...\n",
      "\n",
      "LOG: Epoch [1195/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1185\n",
      "Epoch [1195/2000], Avg Train Loss: 3.1185\n",
      "Epoch [1195/2000], Avg Val Loss: 2.6641\n",
      "Validation loss improved from 2.6644 to 2.6641. Saving model...\n",
      "\n",
      "LOG: Epoch [1196/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0493\n",
      "Epoch [1196/2000], Avg Train Loss: 3.0493\n",
      "Epoch [1196/2000], Avg Val Loss: 2.6636\n",
      "Validation loss improved from 2.6641 to 2.6636. Saving model...\n",
      "\n",
      "LOG: Epoch [1197/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0333\n",
      "Epoch [1197/2000], Avg Train Loss: 3.0333\n",
      "Epoch [1197/2000], Avg Val Loss: 2.6631\n",
      "Validation loss improved from 2.6636 to 2.6631. Saving model...\n",
      "\n",
      "LOG: Epoch [1198/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0964\n",
      "Epoch [1198/2000], Avg Train Loss: 3.0964\n",
      "Epoch [1198/2000], Avg Val Loss: 2.6625\n",
      "Validation loss improved from 2.6631 to 2.6625. Saving model...\n",
      "\n",
      "LOG: Epoch [1199/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1290\n",
      "Epoch [1199/2000], Avg Train Loss: 3.1290\n",
      "Epoch [1199/2000], Avg Val Loss: 2.6619\n",
      "Validation loss improved from 2.6625 to 2.6619. Saving model...\n",
      "\n",
      "LOG: Epoch [1200/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0464\n",
      "Epoch [1200/2000], Avg Train Loss: 3.0464\n",
      "Epoch [1200/2000], Avg Val Loss: 2.6613\n",
      "Validation loss improved from 2.6619 to 2.6613. Saving model...\n",
      "\n",
      "LOG: Epoch [1201/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0294\n",
      "Epoch [1201/2000], Avg Train Loss: 3.0294\n",
      "Epoch [1201/2000], Avg Val Loss: 2.6606\n",
      "Validation loss improved from 2.6613 to 2.6606. Saving model...\n",
      "\n",
      "LOG: Epoch [1202/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0679\n",
      "Epoch [1202/2000], Avg Train Loss: 3.0679\n",
      "Epoch [1202/2000], Avg Val Loss: 2.6598\n",
      "Validation loss improved from 2.6606 to 2.6598. Saving model...\n",
      "\n",
      "LOG: Epoch [1203/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0511\n",
      "Epoch [1203/2000], Avg Train Loss: 3.0511\n",
      "Epoch [1203/2000], Avg Val Loss: 2.6592\n",
      "Validation loss improved from 2.6598 to 2.6592. Saving model...\n",
      "\n",
      "LOG: Epoch [1204/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0574\n",
      "Epoch [1204/2000], Avg Train Loss: 3.0574\n",
      "Epoch [1204/2000], Avg Val Loss: 2.6588\n",
      "Validation loss improved from 2.6592 to 2.6588. Saving model...\n",
      "\n",
      "LOG: Epoch [1205/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0726\n",
      "Epoch [1205/2000], Avg Train Loss: 3.0726\n",
      "Epoch [1205/2000], Avg Val Loss: 2.6583\n",
      "Validation loss improved from 2.6588 to 2.6583. Saving model...\n",
      "\n",
      "LOG: Epoch [1206/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0462\n",
      "Epoch [1206/2000], Avg Train Loss: 3.0462\n",
      "Epoch [1206/2000], Avg Val Loss: 2.6581\n",
      "Validation loss improved from 2.6583 to 2.6581. Saving model...\n",
      "\n",
      "LOG: Epoch [1207/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0337\n",
      "Epoch [1207/2000], Avg Train Loss: 3.0337\n",
      "Epoch [1207/2000], Avg Val Loss: 2.6577\n",
      "Validation loss improved from 2.6581 to 2.6577. Saving model...\n",
      "\n",
      "LOG: Epoch [1208/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1138\n",
      "Epoch [1208/2000], Avg Train Loss: 3.1138\n",
      "Epoch [1208/2000], Avg Val Loss: 2.6574\n",
      "Validation loss improved from 2.6577 to 2.6574. Saving model...\n",
      "\n",
      "LOG: Epoch [1209/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0920\n",
      "Epoch [1209/2000], Avg Train Loss: 3.0920\n",
      "Epoch [1209/2000], Avg Val Loss: 2.6571\n",
      "Validation loss improved from 2.6574 to 2.6571. Saving model...\n",
      "\n",
      "LOG: Epoch [1210/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0471\n",
      "Epoch [1210/2000], Avg Train Loss: 3.0471\n",
      "Epoch [1210/2000], Avg Val Loss: 2.6567\n",
      "Validation loss improved from 2.6571 to 2.6567. Saving model...\n",
      "\n",
      "LOG: Epoch [1211/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0246\n",
      "Epoch [1211/2000], Avg Train Loss: 3.0246\n",
      "Epoch [1211/2000], Avg Val Loss: 2.6564\n",
      "Validation loss improved from 2.6567 to 2.6564. Saving model...\n",
      "\n",
      "LOG: Epoch [1212/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0728\n",
      "Epoch [1212/2000], Avg Train Loss: 3.0728\n",
      "Epoch [1212/2000], Avg Val Loss: 2.6560\n",
      "Validation loss improved from 2.6564 to 2.6560. Saving model...\n",
      "\n",
      "LOG: Epoch [1213/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0708\n",
      "Epoch [1213/2000], Avg Train Loss: 3.0708\n",
      "Epoch [1213/2000], Avg Val Loss: 2.6558\n",
      "Validation loss improved from 2.6560 to 2.6558. Saving model...\n",
      "\n",
      "LOG: Epoch [1214/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0231\n",
      "Epoch [1214/2000], Avg Train Loss: 3.0231\n",
      "Epoch [1214/2000], Avg Val Loss: 2.6555\n",
      "Validation loss improved from 2.6558 to 2.6555. Saving model...\n",
      "\n",
      "LOG: Epoch [1215/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0718\n",
      "Epoch [1215/2000], Avg Train Loss: 3.0718\n",
      "Epoch [1215/2000], Avg Val Loss: 2.6553\n",
      "Validation loss improved from 2.6555 to 2.6553. Saving model...\n",
      "\n",
      "LOG: Epoch [1216/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0220\n",
      "Epoch [1216/2000], Avg Train Loss: 3.0220\n",
      "Epoch [1216/2000], Avg Val Loss: 2.6550\n",
      "Validation loss improved from 2.6553 to 2.6550. Saving model...\n",
      "\n",
      "LOG: Epoch [1217/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0760\n",
      "Epoch [1217/2000], Avg Train Loss: 3.0760\n",
      "Epoch [1217/2000], Avg Val Loss: 2.6546\n",
      "Validation loss improved from 2.6550 to 2.6546. Saving model...\n",
      "\n",
      "LOG: Epoch [1218/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0691\n",
      "Epoch [1218/2000], Avg Train Loss: 3.0691\n",
      "Epoch [1218/2000], Avg Val Loss: 2.6543\n",
      "Validation loss improved from 2.6546 to 2.6543. Saving model...\n",
      "\n",
      "LOG: Epoch [1219/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1131\n",
      "Epoch [1219/2000], Avg Train Loss: 3.1131\n",
      "Epoch [1219/2000], Avg Val Loss: 2.6540\n",
      "Validation loss improved from 2.6543 to 2.6540. Saving model...\n",
      "\n",
      "LOG: Epoch [1220/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0887\n",
      "Epoch [1220/2000], Avg Train Loss: 3.0887\n",
      "Epoch [1220/2000], Avg Val Loss: 2.6538\n",
      "Validation loss improved from 2.6540 to 2.6538. Saving model...\n",
      "\n",
      "LOG: Epoch [1221/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.1167\n",
      "Epoch [1221/2000], Avg Train Loss: 3.1167\n",
      "Epoch [1221/2000], Avg Val Loss: 2.6536\n",
      "Validation loss improved from 2.6538 to 2.6536. Saving model...\n",
      "\n",
      "LOG: Epoch [1222/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0658\n",
      "Epoch [1222/2000], Avg Train Loss: 3.0658\n",
      "Epoch [1222/2000], Avg Val Loss: 2.6535\n",
      "Validation loss improved from 2.6536 to 2.6535. Saving model...\n",
      "\n",
      "LOG: Epoch [1223/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0042\n",
      "Epoch [1223/2000], Avg Train Loss: 3.0042\n",
      "Epoch [1223/2000], Avg Val Loss: 2.6535\n",
      "Validation loss improved from 2.6535 to 2.6535. Saving model...\n",
      "\n",
      "LOG: Epoch [1224/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0125\n",
      "Epoch [1224/2000], Avg Train Loss: 3.0125\n",
      "Epoch [1224/2000], Avg Val Loss: 2.6534\n",
      "Validation loss improved from 2.6535 to 2.6534. Saving model...\n",
      "\n",
      "LOG: Epoch [1225/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0726\n",
      "Epoch [1225/2000], Avg Train Loss: 3.0726\n",
      "Epoch [1225/2000], Avg Val Loss: 2.6533\n",
      "Validation loss improved from 2.6534 to 2.6533. Saving model...\n",
      "\n",
      "LOG: Epoch [1226/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0755\n",
      "Epoch [1226/2000], Avg Train Loss: 3.0755\n",
      "Epoch [1226/2000], Avg Val Loss: 2.6532\n",
      "Validation loss improved from 2.6533 to 2.6532. Saving model...\n",
      "\n",
      "LOG: Epoch [1227/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0826\n",
      "Epoch [1227/2000], Avg Train Loss: 3.0826\n",
      "Epoch [1227/2000], Avg Val Loss: 2.6531\n",
      "Validation loss improved from 2.6532 to 2.6531. Saving model...\n",
      "\n",
      "LOG: Epoch [1228/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0623\n",
      "Epoch [1228/2000], Avg Train Loss: 3.0623\n",
      "Epoch [1228/2000], Avg Val Loss: 2.6532\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1229/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0808\n",
      "Epoch [1229/2000], Avg Train Loss: 3.0808\n",
      "Epoch [1229/2000], Avg Val Loss: 2.6534\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1230/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0653\n",
      "Epoch [1230/2000], Avg Train Loss: 3.0653\n",
      "Epoch [1230/2000], Avg Val Loss: 2.6535\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1231/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0467\n",
      "Epoch [1231/2000], Avg Train Loss: 3.0467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1231/2000], Avg Val Loss: 2.6534\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1232/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0187\n",
      "Epoch [1232/2000], Avg Train Loss: 3.0187\n",
      "Epoch [1232/2000], Avg Val Loss: 2.6533\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1233/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0518\n",
      "Epoch [1233/2000], Avg Train Loss: 3.0518\n",
      "Epoch [1233/2000], Avg Val Loss: 2.6533\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1234/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0129\n",
      "Epoch [1234/2000], Avg Train Loss: 3.0129\n",
      "Epoch [1234/2000], Avg Val Loss: 2.6533\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1235/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0517\n",
      "Epoch [1235/2000], Avg Train Loss: 3.0517\n",
      "Epoch [1235/2000], Avg Val Loss: 2.6531\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1236/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0853\n",
      "Epoch [1236/2000], Avg Train Loss: 3.0853\n",
      "Epoch [1236/2000], Avg Val Loss: 2.6530\n",
      "Validation loss improved from 2.6531 to 2.6530. Saving model...\n",
      "\n",
      "LOG: Epoch [1237/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0676\n",
      "Epoch [1237/2000], Avg Train Loss: 3.0676\n",
      "Epoch [1237/2000], Avg Val Loss: 2.6529\n",
      "Validation loss improved from 2.6530 to 2.6529. Saving model...\n",
      "\n",
      "LOG: Epoch [1238/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0658\n",
      "Epoch [1238/2000], Avg Train Loss: 3.0658\n",
      "Epoch [1238/2000], Avg Val Loss: 2.6526\n",
      "Validation loss improved from 2.6529 to 2.6526. Saving model...\n",
      "\n",
      "LOG: Epoch [1239/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0066\n",
      "Epoch [1239/2000], Avg Train Loss: 3.0066\n",
      "Epoch [1239/2000], Avg Val Loss: 2.6522\n",
      "Validation loss improved from 2.6526 to 2.6522. Saving model...\n",
      "\n",
      "LOG: Epoch [1240/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0092\n",
      "Epoch [1240/2000], Avg Train Loss: 3.0092\n",
      "Epoch [1240/2000], Avg Val Loss: 2.6519\n",
      "Validation loss improved from 2.6522 to 2.6519. Saving model...\n",
      "\n",
      "LOG: Epoch [1241/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0668\n",
      "Epoch [1241/2000], Avg Train Loss: 3.0668\n",
      "Epoch [1241/2000], Avg Val Loss: 2.6517\n",
      "Validation loss improved from 2.6519 to 2.6517. Saving model...\n",
      "\n",
      "LOG: Epoch [1242/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0382\n",
      "Epoch [1242/2000], Avg Train Loss: 3.0382\n",
      "Epoch [1242/2000], Avg Val Loss: 2.6516\n",
      "Validation loss improved from 2.6517 to 2.6516. Saving model...\n",
      "\n",
      "LOG: Epoch [1243/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0160\n",
      "Epoch [1243/2000], Avg Train Loss: 3.0160\n",
      "Epoch [1243/2000], Avg Val Loss: 2.6514\n",
      "Validation loss improved from 2.6516 to 2.6514. Saving model...\n",
      "\n",
      "LOG: Epoch [1244/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0618\n",
      "Epoch [1244/2000], Avg Train Loss: 3.0618\n",
      "Epoch [1244/2000], Avg Val Loss: 2.6514\n",
      "Validation loss improved from 2.6514 to 2.6514. Saving model...\n",
      "\n",
      "LOG: Epoch [1245/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0182\n",
      "Epoch [1245/2000], Avg Train Loss: 3.0182\n",
      "Epoch [1245/2000], Avg Val Loss: 2.6512\n",
      "Validation loss improved from 2.6514 to 2.6512. Saving model...\n",
      "\n",
      "LOG: Epoch [1246/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0246\n",
      "Epoch [1246/2000], Avg Train Loss: 3.0246\n",
      "Epoch [1246/2000], Avg Val Loss: 2.6509\n",
      "Validation loss improved from 2.6512 to 2.6509. Saving model...\n",
      "\n",
      "LOG: Epoch [1247/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0653\n",
      "Epoch [1247/2000], Avg Train Loss: 3.0653\n",
      "Epoch [1247/2000], Avg Val Loss: 2.6506\n",
      "Validation loss improved from 2.6509 to 2.6506. Saving model...\n",
      "\n",
      "LOG: Epoch [1248/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0494\n",
      "Epoch [1248/2000], Avg Train Loss: 3.0494\n",
      "Epoch [1248/2000], Avg Val Loss: 2.6505\n",
      "Validation loss improved from 2.6506 to 2.6505. Saving model...\n",
      "\n",
      "LOG: Epoch [1249/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0863\n",
      "Epoch [1249/2000], Avg Train Loss: 3.0863\n",
      "Epoch [1249/2000], Avg Val Loss: 2.6505\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1250/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0232\n",
      "Epoch [1250/2000], Avg Train Loss: 3.0232\n",
      "Epoch [1250/2000], Avg Val Loss: 2.6505\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1251/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0340\n",
      "Epoch [1251/2000], Avg Train Loss: 3.0340\n",
      "Epoch [1251/2000], Avg Val Loss: 2.6505\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1252/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0340\n",
      "Epoch [1252/2000], Avg Train Loss: 3.0340\n",
      "Epoch [1252/2000], Avg Val Loss: 2.6504\n",
      "Validation loss improved from 2.6505 to 2.6504. Saving model...\n",
      "\n",
      "LOG: Epoch [1253/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9695\n",
      "Epoch [1253/2000], Avg Train Loss: 2.9695\n",
      "Epoch [1253/2000], Avg Val Loss: 2.6504\n",
      "Validation loss improved from 2.6504 to 2.6504. Saving model...\n",
      "\n",
      "LOG: Epoch [1254/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9937\n",
      "Epoch [1254/2000], Avg Train Loss: 2.9937\n",
      "Epoch [1254/2000], Avg Val Loss: 2.6504\n",
      "Validation loss improved from 2.6504 to 2.6504. Saving model...\n",
      "\n",
      "LOG: Epoch [1255/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0393\n",
      "Epoch [1255/2000], Avg Train Loss: 3.0393\n",
      "Epoch [1255/2000], Avg Val Loss: 2.6502\n",
      "Validation loss improved from 2.6504 to 2.6502. Saving model...\n",
      "\n",
      "LOG: Epoch [1256/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9785\n",
      "Epoch [1256/2000], Avg Train Loss: 2.9785\n",
      "Epoch [1256/2000], Avg Val Loss: 2.6503\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1257/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0040\n",
      "Epoch [1257/2000], Avg Train Loss: 3.0040\n",
      "Epoch [1257/2000], Avg Val Loss: 2.6503\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1258/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0199\n",
      "Epoch [1258/2000], Avg Train Loss: 3.0199\n",
      "Epoch [1258/2000], Avg Val Loss: 2.6502\n",
      "Validation loss improved from 2.6502 to 2.6502. Saving model...\n",
      "\n",
      "LOG: Epoch [1259/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0059\n",
      "Epoch [1259/2000], Avg Train Loss: 3.0059\n",
      "Epoch [1259/2000], Avg Val Loss: 2.6502\n",
      "Validation loss improved from 2.6502 to 2.6502. Saving model...\n",
      "\n",
      "LOG: Epoch [1260/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9741\n",
      "Epoch [1260/2000], Avg Train Loss: 2.9741\n",
      "Epoch [1260/2000], Avg Val Loss: 2.6500\n",
      "Validation loss improved from 2.6502 to 2.6500. Saving model...\n",
      "\n",
      "LOG: Epoch [1261/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0464\n",
      "Epoch [1261/2000], Avg Train Loss: 3.0464\n",
      "Epoch [1261/2000], Avg Val Loss: 2.6499\n",
      "Validation loss improved from 2.6500 to 2.6499. Saving model...\n",
      "\n",
      "LOG: Epoch [1262/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9828\n",
      "Epoch [1262/2000], Avg Train Loss: 2.9828\n",
      "Epoch [1262/2000], Avg Val Loss: 2.6499\n",
      "Validation loss improved from 2.6499 to 2.6499. Saving model...\n",
      "\n",
      "LOG: Epoch [1263/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0758\n",
      "Epoch [1263/2000], Avg Train Loss: 3.0758\n",
      "Epoch [1263/2000], Avg Val Loss: 2.6500\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1264/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0574\n",
      "Epoch [1264/2000], Avg Train Loss: 3.0574\n",
      "Epoch [1264/2000], Avg Val Loss: 2.6500\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1265/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0126\n",
      "Epoch [1265/2000], Avg Train Loss: 3.0126\n",
      "Epoch [1265/2000], Avg Val Loss: 2.6499\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1266/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0138\n",
      "Epoch [1266/2000], Avg Train Loss: 3.0138\n",
      "Epoch [1266/2000], Avg Val Loss: 2.6498\n",
      "Validation loss improved from 2.6499 to 2.6498. Saving model...\n",
      "\n",
      "LOG: Epoch [1267/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9792\n",
      "Epoch [1267/2000], Avg Train Loss: 2.9792\n",
      "Epoch [1267/2000], Avg Val Loss: 2.6497\n",
      "Validation loss improved from 2.6498 to 2.6497. Saving model...\n",
      "\n",
      "LOG: Epoch [1268/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0176\n",
      "Epoch [1268/2000], Avg Train Loss: 3.0176\n",
      "Epoch [1268/2000], Avg Val Loss: 2.6497\n",
      "Validation loss improved from 2.6497 to 2.6497. Saving model...\n",
      "\n",
      "LOG: Epoch [1269/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0686\n",
      "Epoch [1269/2000], Avg Train Loss: 3.0686\n",
      "Epoch [1269/2000], Avg Val Loss: 2.6495\n",
      "Validation loss improved from 2.6497 to 2.6495. Saving model...\n",
      "\n",
      "LOG: Epoch [1270/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0530\n",
      "Epoch [1270/2000], Avg Train Loss: 3.0530\n",
      "Epoch [1270/2000], Avg Val Loss: 2.6492\n",
      "Validation loss improved from 2.6495 to 2.6492. Saving model...\n",
      "\n",
      "LOG: Epoch [1271/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0463\n",
      "Epoch [1271/2000], Avg Train Loss: 3.0463\n",
      "Epoch [1271/2000], Avg Val Loss: 2.6490\n",
      "Validation loss improved from 2.6492 to 2.6490. Saving model...\n",
      "\n",
      "LOG: Epoch [1272/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0005\n",
      "Epoch [1272/2000], Avg Train Loss: 3.0005\n",
      "Epoch [1272/2000], Avg Val Loss: 2.6487\n",
      "Validation loss improved from 2.6490 to 2.6487. Saving model...\n",
      "\n",
      "LOG: Epoch [1273/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0170\n",
      "Epoch [1273/2000], Avg Train Loss: 3.0170\n",
      "Epoch [1273/2000], Avg Val Loss: 2.6483\n",
      "Validation loss improved from 2.6487 to 2.6483. Saving model...\n",
      "\n",
      "LOG: Epoch [1274/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.0445\n",
      "Epoch [1274/2000], Avg Train Loss: 3.0445\n",
      "Epoch [1274/2000], Avg Val Loss: 2.6479\n",
      "Validation loss improved from 2.6483 to 2.6479. Saving model...\n",
      "\n",
      "LOG: Epoch [1275/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0144\n",
      "Epoch [1275/2000], Avg Train Loss: 3.0144\n",
      "Epoch [1275/2000], Avg Val Loss: 2.6475\n",
      "Validation loss improved from 2.6479 to 2.6475. Saving model...\n",
      "\n",
      "LOG: Epoch [1276/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9823\n",
      "Epoch [1276/2000], Avg Train Loss: 2.9823\n",
      "Epoch [1276/2000], Avg Val Loss: 2.6470\n",
      "Validation loss improved from 2.6475 to 2.6470. Saving model...\n",
      "\n",
      "LOG: Epoch [1277/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0307\n",
      "Epoch [1277/2000], Avg Train Loss: 3.0307\n",
      "Epoch [1277/2000], Avg Val Loss: 2.6465\n",
      "Validation loss improved from 2.6470 to 2.6465. Saving model...\n",
      "\n",
      "LOG: Epoch [1278/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9829\n",
      "Epoch [1278/2000], Avg Train Loss: 2.9829\n",
      "Epoch [1278/2000], Avg Val Loss: 2.6459\n",
      "Validation loss improved from 2.6465 to 2.6459. Saving model...\n",
      "\n",
      "LOG: Epoch [1279/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9800\n",
      "Epoch [1279/2000], Avg Train Loss: 2.9800\n",
      "Epoch [1279/2000], Avg Val Loss: 2.6453\n",
      "Validation loss improved from 2.6459 to 2.6453. Saving model...\n",
      "\n",
      "LOG: Epoch [1280/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9606\n",
      "Epoch [1280/2000], Avg Train Loss: 2.9606\n",
      "Epoch [1280/2000], Avg Val Loss: 2.6447\n",
      "Validation loss improved from 2.6453 to 2.6447. Saving model...\n",
      "\n",
      "LOG: Epoch [1281/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9900\n",
      "Epoch [1281/2000], Avg Train Loss: 2.9900\n",
      "Epoch [1281/2000], Avg Val Loss: 2.6441\n",
      "Validation loss improved from 2.6447 to 2.6441. Saving model...\n",
      "\n",
      "LOG: Epoch [1282/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0273\n",
      "Epoch [1282/2000], Avg Train Loss: 3.0273\n",
      "Epoch [1282/2000], Avg Val Loss: 2.6435\n",
      "Validation loss improved from 2.6441 to 2.6435. Saving model...\n",
      "\n",
      "LOG: Epoch [1283/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9839\n",
      "Epoch [1283/2000], Avg Train Loss: 2.9839\n",
      "Epoch [1283/2000], Avg Val Loss: 2.6429\n",
      "Validation loss improved from 2.6435 to 2.6429. Saving model...\n",
      "\n",
      "LOG: Epoch [1284/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0803\n",
      "Epoch [1284/2000], Avg Train Loss: 3.0803\n",
      "Epoch [1284/2000], Avg Val Loss: 2.6424\n",
      "Validation loss improved from 2.6429 to 2.6424. Saving model...\n",
      "\n",
      "LOG: Epoch [1285/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0090\n",
      "Epoch [1285/2000], Avg Train Loss: 3.0090\n",
      "Epoch [1285/2000], Avg Val Loss: 2.6420\n",
      "Validation loss improved from 2.6424 to 2.6420. Saving model...\n",
      "\n",
      "LOG: Epoch [1286/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0169\n",
      "Epoch [1286/2000], Avg Train Loss: 3.0169\n",
      "Epoch [1286/2000], Avg Val Loss: 2.6416\n",
      "Validation loss improved from 2.6420 to 2.6416. Saving model...\n",
      "\n",
      "LOG: Epoch [1287/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0059\n",
      "Epoch [1287/2000], Avg Train Loss: 3.0059\n",
      "Epoch [1287/2000], Avg Val Loss: 2.6413\n",
      "Validation loss improved from 2.6416 to 2.6413. Saving model...\n",
      "\n",
      "LOG: Epoch [1288/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0417\n",
      "Epoch [1288/2000], Avg Train Loss: 3.0417\n",
      "Epoch [1288/2000], Avg Val Loss: 2.6409\n",
      "Validation loss improved from 2.6413 to 2.6409. Saving model...\n",
      "\n",
      "LOG: Epoch [1289/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9725\n",
      "Epoch [1289/2000], Avg Train Loss: 2.9725\n",
      "Epoch [1289/2000], Avg Val Loss: 2.6407\n",
      "Validation loss improved from 2.6409 to 2.6407. Saving model...\n",
      "\n",
      "LOG: Epoch [1290/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0463\n",
      "Epoch [1290/2000], Avg Train Loss: 3.0463\n",
      "Epoch [1290/2000], Avg Val Loss: 2.6406\n",
      "Validation loss improved from 2.6407 to 2.6406. Saving model...\n",
      "\n",
      "LOG: Epoch [1291/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0133\n",
      "Epoch [1291/2000], Avg Train Loss: 3.0133\n",
      "Epoch [1291/2000], Avg Val Loss: 2.6406\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1292/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9733\n",
      "Epoch [1292/2000], Avg Train Loss: 2.9733\n",
      "Epoch [1292/2000], Avg Val Loss: 2.6405\n",
      "Validation loss improved from 2.6406 to 2.6405. Saving model...\n",
      "\n",
      "LOG: Epoch [1293/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0356\n",
      "Epoch [1293/2000], Avg Train Loss: 3.0356\n",
      "Epoch [1293/2000], Avg Val Loss: 2.6406\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1294/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9721\n",
      "Epoch [1294/2000], Avg Train Loss: 2.9721\n",
      "Epoch [1294/2000], Avg Val Loss: 2.6407\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1295/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0313\n",
      "Epoch [1295/2000], Avg Train Loss: 3.0313\n",
      "Epoch [1295/2000], Avg Val Loss: 2.6409\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1296/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0510\n",
      "Epoch [1296/2000], Avg Train Loss: 3.0510\n",
      "Epoch [1296/2000], Avg Val Loss: 2.6409\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1297/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0512\n",
      "Epoch [1297/2000], Avg Train Loss: 3.0512\n",
      "Epoch [1297/2000], Avg Val Loss: 2.6408\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1298/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9773\n",
      "Epoch [1298/2000], Avg Train Loss: 2.9773\n",
      "Epoch [1298/2000], Avg Val Loss: 2.6406\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1299/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0716\n",
      "Epoch [1299/2000], Avg Train Loss: 3.0716\n",
      "Epoch [1299/2000], Avg Val Loss: 2.6405\n",
      "Validation loss improved from 2.6405 to 2.6405. Saving model...\n",
      "\n",
      "LOG: Epoch [1300/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0071\n",
      "Epoch [1300/2000], Avg Train Loss: 3.0071\n",
      "Epoch [1300/2000], Avg Val Loss: 2.6404\n",
      "Validation loss improved from 2.6405 to 2.6404. Saving model...\n",
      "\n",
      "LOG: Epoch [1301/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9510\n",
      "Epoch [1301/2000], Avg Train Loss: 2.9510\n",
      "Epoch [1301/2000], Avg Val Loss: 2.6402\n",
      "Validation loss improved from 2.6404 to 2.6402. Saving model...\n",
      "\n",
      "LOG: Epoch [1302/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0239\n",
      "Epoch [1302/2000], Avg Train Loss: 3.0239\n",
      "Epoch [1302/2000], Avg Val Loss: 2.6399\n",
      "Validation loss improved from 2.6402 to 2.6399. Saving model...\n",
      "\n",
      "LOG: Epoch [1303/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0067\n",
      "Epoch [1303/2000], Avg Train Loss: 3.0067\n",
      "Epoch [1303/2000], Avg Val Loss: 2.6397\n",
      "Validation loss improved from 2.6399 to 2.6397. Saving model...\n",
      "\n",
      "LOG: Epoch [1304/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9702\n",
      "Epoch [1304/2000], Avg Train Loss: 2.9702\n",
      "Epoch [1304/2000], Avg Val Loss: 2.6395\n",
      "Validation loss improved from 2.6397 to 2.6395. Saving model...\n",
      "\n",
      "LOG: Epoch [1305/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0242\n",
      "Epoch [1305/2000], Avg Train Loss: 3.0242\n",
      "Epoch [1305/2000], Avg Val Loss: 2.6393\n",
      "Validation loss improved from 2.6395 to 2.6393. Saving model...\n",
      "\n",
      "LOG: Epoch [1306/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0444\n",
      "Epoch [1306/2000], Avg Train Loss: 3.0444\n",
      "Epoch [1306/2000], Avg Val Loss: 2.6392\n",
      "Validation loss improved from 2.6393 to 2.6392. Saving model...\n",
      "\n",
      "LOG: Epoch [1307/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0121\n",
      "Epoch [1307/2000], Avg Train Loss: 3.0121\n",
      "Epoch [1307/2000], Avg Val Loss: 2.6390\n",
      "Validation loss improved from 2.6392 to 2.6390. Saving model...\n",
      "\n",
      "LOG: Epoch [1308/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9882\n",
      "Epoch [1308/2000], Avg Train Loss: 2.9882\n",
      "Epoch [1308/2000], Avg Val Loss: 2.6388\n",
      "Validation loss improved from 2.6390 to 2.6388. Saving model...\n",
      "\n",
      "LOG: Epoch [1309/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0239\n",
      "Epoch [1309/2000], Avg Train Loss: 3.0239\n",
      "Epoch [1309/2000], Avg Val Loss: 2.6386\n",
      "Validation loss improved from 2.6388 to 2.6386. Saving model...\n",
      "\n",
      "LOG: Epoch [1310/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0132\n",
      "Epoch [1310/2000], Avg Train Loss: 3.0132\n",
      "Epoch [1310/2000], Avg Val Loss: 2.6385\n",
      "Validation loss improved from 2.6386 to 2.6385. Saving model...\n",
      "\n",
      "LOG: Epoch [1311/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9981\n",
      "Epoch [1311/2000], Avg Train Loss: 2.9981\n",
      "Epoch [1311/2000], Avg Val Loss: 2.6382\n",
      "Validation loss improved from 2.6385 to 2.6382. Saving model...\n",
      "\n",
      "LOG: Epoch [1312/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0028\n",
      "Epoch [1312/2000], Avg Train Loss: 3.0028\n",
      "Epoch [1312/2000], Avg Val Loss: 2.6379\n",
      "Validation loss improved from 2.6382 to 2.6379. Saving model...\n",
      "\n",
      "LOG: Epoch [1313/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9991\n",
      "Epoch [1313/2000], Avg Train Loss: 2.9991\n",
      "Epoch [1313/2000], Avg Val Loss: 2.6373\n",
      "Validation loss improved from 2.6379 to 2.6373. Saving model...\n",
      "\n",
      "LOG: Epoch [1314/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9979\n",
      "Epoch [1314/2000], Avg Train Loss: 2.9979\n",
      "Epoch [1314/2000], Avg Val Loss: 2.6369\n",
      "Validation loss improved from 2.6373 to 2.6369. Saving model...\n",
      "\n",
      "LOG: Epoch [1315/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9610\n",
      "Epoch [1315/2000], Avg Train Loss: 2.9610\n",
      "Epoch [1315/2000], Avg Val Loss: 2.6366\n",
      "Validation loss improved from 2.6369 to 2.6366. Saving model...\n",
      "\n",
      "LOG: Epoch [1316/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0423\n",
      "Epoch [1316/2000], Avg Train Loss: 3.0423\n",
      "Epoch [1316/2000], Avg Val Loss: 2.6363\n",
      "Validation loss improved from 2.6366 to 2.6363. Saving model...\n",
      "\n",
      "LOG: Epoch [1317/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9688\n",
      "Epoch [1317/2000], Avg Train Loss: 2.9688\n",
      "Epoch [1317/2000], Avg Val Loss: 2.6360\n",
      "Validation loss improved from 2.6363 to 2.6360. Saving model...\n",
      "\n",
      "LOG: Epoch [1318/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9767\n",
      "Epoch [1318/2000], Avg Train Loss: 2.9767\n",
      "Epoch [1318/2000], Avg Val Loss: 2.6358\n",
      "Validation loss improved from 2.6360 to 2.6358. Saving model...\n",
      "\n",
      "LOG: Epoch [1319/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 3.0137\n",
      "Epoch [1319/2000], Avg Train Loss: 3.0137\n",
      "Epoch [1319/2000], Avg Val Loss: 2.6358\n",
      "Validation loss improved from 2.6358 to 2.6358. Saving model...\n",
      "\n",
      "LOG: Epoch [1320/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9674\n",
      "Epoch [1320/2000], Avg Train Loss: 2.9674\n",
      "Epoch [1320/2000], Avg Val Loss: 2.6358\n",
      "Validation loss improved from 2.6358 to 2.6358. Saving model...\n",
      "\n",
      "LOG: Epoch [1321/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9877\n",
      "Epoch [1321/2000], Avg Train Loss: 2.9877\n",
      "Epoch [1321/2000], Avg Val Loss: 2.6356\n",
      "Validation loss improved from 2.6358 to 2.6356. Saving model...\n",
      "\n",
      "LOG: Epoch [1322/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9864\n",
      "Epoch [1322/2000], Avg Train Loss: 2.9864\n",
      "Epoch [1322/2000], Avg Val Loss: 2.6355\n",
      "Validation loss improved from 2.6356 to 2.6355. Saving model...\n",
      "\n",
      "LOG: Epoch [1323/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9572\n",
      "Epoch [1323/2000], Avg Train Loss: 2.9572\n",
      "Epoch [1323/2000], Avg Val Loss: 2.6354\n",
      "Validation loss improved from 2.6355 to 2.6354. Saving model...\n",
      "\n",
      "LOG: Epoch [1324/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9950\n",
      "Epoch [1324/2000], Avg Train Loss: 2.9950\n",
      "Epoch [1324/2000], Avg Val Loss: 2.6355\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1325/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9464\n",
      "Epoch [1325/2000], Avg Train Loss: 2.9464\n",
      "Epoch [1325/2000], Avg Val Loss: 2.6354\n",
      "Validation loss improved from 2.6354 to 2.6354. Saving model...\n",
      "\n",
      "LOG: Epoch [1326/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0188\n",
      "Epoch [1326/2000], Avg Train Loss: 3.0188\n",
      "Epoch [1326/2000], Avg Val Loss: 2.6355\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1327/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9945\n",
      "Epoch [1327/2000], Avg Train Loss: 2.9945\n",
      "Epoch [1327/2000], Avg Val Loss: 2.6357\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1328/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9807\n",
      "Epoch [1328/2000], Avg Train Loss: 2.9807\n",
      "Epoch [1328/2000], Avg Val Loss: 2.6358\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1329/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0150\n",
      "Epoch [1329/2000], Avg Train Loss: 3.0150\n",
      "Epoch [1329/2000], Avg Val Loss: 2.6360\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1330/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0107\n",
      "Epoch [1330/2000], Avg Train Loss: 3.0107\n",
      "Epoch [1330/2000], Avg Val Loss: 2.6361\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1331/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9944\n",
      "Epoch [1331/2000], Avg Train Loss: 2.9944\n",
      "Epoch [1331/2000], Avg Val Loss: 2.6362\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1332/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0208\n",
      "Epoch [1332/2000], Avg Train Loss: 3.0208\n",
      "Epoch [1332/2000], Avg Val Loss: 2.6364\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1333/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0074\n",
      "Epoch [1333/2000], Avg Train Loss: 3.0074\n",
      "Epoch [1333/2000], Avg Val Loss: 2.6366\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1334/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9496\n",
      "Epoch [1334/2000], Avg Train Loss: 2.9496\n",
      "Epoch [1334/2000], Avg Val Loss: 2.6367\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1335/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9849\n",
      "Epoch [1335/2000], Avg Train Loss: 2.9849\n",
      "Epoch [1335/2000], Avg Val Loss: 2.6370\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1336/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0532\n",
      "Epoch [1336/2000], Avg Train Loss: 3.0532\n",
      "Epoch [1336/2000], Avg Val Loss: 2.6372\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1337/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9629\n",
      "Epoch [1337/2000], Avg Train Loss: 2.9629\n",
      "Epoch [1337/2000], Avg Val Loss: 2.6375\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1338/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9862\n",
      "Epoch [1338/2000], Avg Train Loss: 2.9862\n",
      "Epoch [1338/2000], Avg Val Loss: 2.6376\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1339/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0111\n",
      "Epoch [1339/2000], Avg Train Loss: 3.0111\n",
      "Epoch [1339/2000], Avg Val Loss: 2.6377\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1340/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9845\n",
      "Epoch [1340/2000], Avg Train Loss: 2.9845\n",
      "Epoch [1340/2000], Avg Val Loss: 2.6379\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1341/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9916\n",
      "Epoch [1341/2000], Avg Train Loss: 2.9916\n",
      "Epoch [1341/2000], Avg Val Loss: 2.6380\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1342/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9464\n",
      "Epoch [1342/2000], Avg Train Loss: 2.9464\n",
      "Epoch [1342/2000], Avg Val Loss: 2.6381\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1343/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9647\n",
      "Epoch [1343/2000], Avg Train Loss: 2.9647\n",
      "Epoch [1343/2000], Avg Val Loss: 2.6381\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1344/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9264\n",
      "Epoch [1344/2000], Avg Train Loss: 2.9264\n",
      "Epoch [1344/2000], Avg Val Loss: 2.6381\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1345/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9737\n",
      "Epoch [1345/2000], Avg Train Loss: 2.9737\n",
      "Epoch [1345/2000], Avg Val Loss: 2.6381\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1346/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0023\n",
      "Epoch [1346/2000], Avg Train Loss: 3.0023\n",
      "Epoch [1346/2000], Avg Val Loss: 2.6381\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1347/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0400\n",
      "Epoch [1347/2000], Avg Train Loss: 3.0400\n",
      "Epoch [1347/2000], Avg Val Loss: 2.6381\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1348/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9877\n",
      "Epoch [1348/2000], Avg Train Loss: 2.9877\n",
      "Epoch [1348/2000], Avg Val Loss: 2.6379\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1349/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9862\n",
      "Epoch [1349/2000], Avg Train Loss: 2.9862\n",
      "Epoch [1349/2000], Avg Val Loss: 2.6379\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1350/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9464\n",
      "Epoch [1350/2000], Avg Train Loss: 2.9464\n",
      "Epoch [1350/2000], Avg Val Loss: 2.6378\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1351/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9538\n",
      "Epoch [1351/2000], Avg Train Loss: 2.9538\n",
      "Epoch [1351/2000], Avg Val Loss: 2.6377\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1352/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9894\n",
      "Epoch [1352/2000], Avg Train Loss: 2.9894\n",
      "Epoch [1352/2000], Avg Val Loss: 2.6376\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1353/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9851\n",
      "Epoch [1353/2000], Avg Train Loss: 2.9851\n",
      "Epoch [1353/2000], Avg Val Loss: 2.6374\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1354/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9267\n",
      "Epoch [1354/2000], Avg Train Loss: 2.9267\n",
      "Epoch [1354/2000], Avg Val Loss: 2.6372\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1355/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9806\n",
      "Epoch [1355/2000], Avg Train Loss: 2.9806\n",
      "Epoch [1355/2000], Avg Val Loss: 2.6368\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1356/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9833\n",
      "Epoch [1356/2000], Avg Train Loss: 2.9833\n",
      "Epoch [1356/2000], Avg Val Loss: 2.6363\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1357/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9570\n",
      "Epoch [1357/2000], Avg Train Loss: 2.9570\n",
      "Epoch [1357/2000], Avg Val Loss: 2.6360\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1358/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9634\n",
      "Epoch [1358/2000], Avg Train Loss: 2.9634\n",
      "Epoch [1358/2000], Avg Val Loss: 2.6357\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1359/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9500\n",
      "Epoch [1359/2000], Avg Train Loss: 2.9500\n",
      "Epoch [1359/2000], Avg Val Loss: 2.6353\n",
      "Validation loss improved from 2.6354 to 2.6353. Saving model...\n",
      "\n",
      "LOG: Epoch [1360/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9915\n",
      "Epoch [1360/2000], Avg Train Loss: 2.9915\n",
      "Epoch [1360/2000], Avg Val Loss: 2.6352\n",
      "Validation loss improved from 2.6353 to 2.6352. Saving model...\n",
      "\n",
      "LOG: Epoch [1361/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9636\n",
      "Epoch [1361/2000], Avg Train Loss: 2.9636\n",
      "Epoch [1361/2000], Avg Val Loss: 2.6351\n",
      "Validation loss improved from 2.6352 to 2.6351. Saving model...\n",
      "\n",
      "LOG: Epoch [1362/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0046\n",
      "Epoch [1362/2000], Avg Train Loss: 3.0046\n",
      "Epoch [1362/2000], Avg Val Loss: 2.6350\n",
      "Validation loss improved from 2.6351 to 2.6350. Saving model...\n",
      "\n",
      "LOG: Epoch [1363/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9971\n",
      "Epoch [1363/2000], Avg Train Loss: 2.9971\n",
      "Epoch [1363/2000], Avg Val Loss: 2.6349\n",
      "Validation loss improved from 2.6350 to 2.6349. Saving model...\n",
      "\n",
      "LOG: Epoch [1364/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 2.9538\n",
      "Epoch [1364/2000], Avg Train Loss: 2.9538\n",
      "Epoch [1364/2000], Avg Val Loss: 2.6348\n",
      "Validation loss improved from 2.6349 to 2.6348. Saving model...\n",
      "\n",
      "LOG: Epoch [1365/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9067\n",
      "Epoch [1365/2000], Avg Train Loss: 2.9067\n",
      "Epoch [1365/2000], Avg Val Loss: 2.6349\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1366/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9349\n",
      "Epoch [1366/2000], Avg Train Loss: 2.9349\n",
      "Epoch [1366/2000], Avg Val Loss: 2.6349\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1367/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9627\n",
      "Epoch [1367/2000], Avg Train Loss: 2.9627\n",
      "Epoch [1367/2000], Avg Val Loss: 2.6349\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1368/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9205\n",
      "Epoch [1368/2000], Avg Train Loss: 2.9205\n",
      "Epoch [1368/2000], Avg Val Loss: 2.6348\n",
      "Validation loss improved from 2.6348 to 2.6348. Saving model...\n",
      "\n",
      "LOG: Epoch [1369/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9695\n",
      "Epoch [1369/2000], Avg Train Loss: 2.9695\n",
      "Epoch [1369/2000], Avg Val Loss: 2.6348\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1370/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9806\n",
      "Epoch [1370/2000], Avg Train Loss: 2.9806\n",
      "Epoch [1370/2000], Avg Val Loss: 2.6347\n",
      "Validation loss improved from 2.6348 to 2.6347. Saving model...\n",
      "\n",
      "LOG: Epoch [1371/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9407\n",
      "Epoch [1371/2000], Avg Train Loss: 2.9407\n",
      "Epoch [1371/2000], Avg Val Loss: 2.6347\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1372/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9780\n",
      "Epoch [1372/2000], Avg Train Loss: 2.9780\n",
      "Epoch [1372/2000], Avg Val Loss: 2.6346\n",
      "Validation loss improved from 2.6347 to 2.6346. Saving model...\n",
      "\n",
      "LOG: Epoch [1373/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9958\n",
      "Epoch [1373/2000], Avg Train Loss: 2.9958\n",
      "Epoch [1373/2000], Avg Val Loss: 2.6345\n",
      "Validation loss improved from 2.6346 to 2.6345. Saving model...\n",
      "\n",
      "LOG: Epoch [1374/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9761\n",
      "Epoch [1374/2000], Avg Train Loss: 2.9761\n",
      "Epoch [1374/2000], Avg Val Loss: 2.6344\n",
      "Validation loss improved from 2.6345 to 2.6344. Saving model...\n",
      "\n",
      "LOG: Epoch [1375/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9747\n",
      "Epoch [1375/2000], Avg Train Loss: 2.9747\n",
      "Epoch [1375/2000], Avg Val Loss: 2.6343\n",
      "Validation loss improved from 2.6344 to 2.6343. Saving model...\n",
      "\n",
      "LOG: Epoch [1376/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9649\n",
      "Epoch [1376/2000], Avg Train Loss: 2.9649\n",
      "Epoch [1376/2000], Avg Val Loss: 2.6344\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1377/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9872\n",
      "Epoch [1377/2000], Avg Train Loss: 2.9872\n",
      "Epoch [1377/2000], Avg Val Loss: 2.6343\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1378/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9515\n",
      "Epoch [1378/2000], Avg Train Loss: 2.9515\n",
      "Epoch [1378/2000], Avg Val Loss: 2.6342\n",
      "Validation loss improved from 2.6343 to 2.6342. Saving model...\n",
      "\n",
      "LOG: Epoch [1379/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9451\n",
      "Epoch [1379/2000], Avg Train Loss: 2.9451\n",
      "Epoch [1379/2000], Avg Val Loss: 2.6343\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1380/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8900\n",
      "Epoch [1380/2000], Avg Train Loss: 2.8900\n",
      "Epoch [1380/2000], Avg Val Loss: 2.6343\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1381/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9503\n",
      "Epoch [1381/2000], Avg Train Loss: 2.9503\n",
      "Epoch [1381/2000], Avg Val Loss: 2.6344\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1382/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9663\n",
      "Epoch [1382/2000], Avg Train Loss: 2.9663\n",
      "Epoch [1382/2000], Avg Val Loss: 2.6344\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1383/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9416\n",
      "Epoch [1383/2000], Avg Train Loss: 2.9416\n",
      "Epoch [1383/2000], Avg Val Loss: 2.6344\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1384/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9964\n",
      "Epoch [1384/2000], Avg Train Loss: 2.9964\n",
      "Epoch [1384/2000], Avg Val Loss: 2.6343\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1385/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9705\n",
      "Epoch [1385/2000], Avg Train Loss: 2.9705\n",
      "Epoch [1385/2000], Avg Val Loss: 2.6343\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1386/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0066\n",
      "Epoch [1386/2000], Avg Train Loss: 3.0066\n",
      "Epoch [1386/2000], Avg Val Loss: 2.6343\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1387/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9046\n",
      "Epoch [1387/2000], Avg Train Loss: 2.9046\n",
      "Epoch [1387/2000], Avg Val Loss: 2.6342\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1388/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9357\n",
      "Epoch [1388/2000], Avg Train Loss: 2.9357\n",
      "Epoch [1388/2000], Avg Val Loss: 2.6341\n",
      "Validation loss improved from 2.6342 to 2.6341. Saving model...\n",
      "\n",
      "LOG: Epoch [1389/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9847\n",
      "Epoch [1389/2000], Avg Train Loss: 2.9847\n",
      "Epoch [1389/2000], Avg Val Loss: 2.6340\n",
      "Validation loss improved from 2.6341 to 2.6340. Saving model...\n",
      "\n",
      "LOG: Epoch [1390/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9692\n",
      "Epoch [1390/2000], Avg Train Loss: 2.9692\n",
      "Epoch [1390/2000], Avg Val Loss: 2.6339\n",
      "Validation loss improved from 2.6340 to 2.6339. Saving model...\n",
      "\n",
      "LOG: Epoch [1391/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9378\n",
      "Epoch [1391/2000], Avg Train Loss: 2.9378\n",
      "Epoch [1391/2000], Avg Val Loss: 2.6339\n",
      "Validation loss improved from 2.6339 to 2.6339. Saving model...\n",
      "\n",
      "LOG: Epoch [1392/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9263\n",
      "Epoch [1392/2000], Avg Train Loss: 2.9263\n",
      "Epoch [1392/2000], Avg Val Loss: 2.6338\n",
      "Validation loss improved from 2.6339 to 2.6338. Saving model...\n",
      "\n",
      "LOG: Epoch [1393/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9693\n",
      "Epoch [1393/2000], Avg Train Loss: 2.9693\n",
      "Epoch [1393/2000], Avg Val Loss: 2.6337\n",
      "Validation loss improved from 2.6338 to 2.6337. Saving model...\n",
      "\n",
      "LOG: Epoch [1394/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9609\n",
      "Epoch [1394/2000], Avg Train Loss: 2.9609\n",
      "Epoch [1394/2000], Avg Val Loss: 2.6336\n",
      "Validation loss improved from 2.6337 to 2.6336. Saving model...\n",
      "\n",
      "LOG: Epoch [1395/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9292\n",
      "Epoch [1395/2000], Avg Train Loss: 2.9292\n",
      "Epoch [1395/2000], Avg Val Loss: 2.6335\n",
      "Validation loss improved from 2.6336 to 2.6335. Saving model...\n",
      "\n",
      "LOG: Epoch [1396/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9407\n",
      "Epoch [1396/2000], Avg Train Loss: 2.9407\n",
      "Epoch [1396/2000], Avg Val Loss: 2.6334\n",
      "Validation loss improved from 2.6335 to 2.6334. Saving model...\n",
      "\n",
      "LOG: Epoch [1397/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9552\n",
      "Epoch [1397/2000], Avg Train Loss: 2.9552\n",
      "Epoch [1397/2000], Avg Val Loss: 2.6334\n",
      "Validation loss improved from 2.6334 to 2.6334. Saving model...\n",
      "\n",
      "LOG: Epoch [1398/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9742\n",
      "Epoch [1398/2000], Avg Train Loss: 2.9742\n",
      "Epoch [1398/2000], Avg Val Loss: 2.6334\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1399/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9074\n",
      "Epoch [1399/2000], Avg Train Loss: 2.9074\n",
      "Epoch [1399/2000], Avg Val Loss: 2.6335\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1400/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9202\n",
      "Epoch [1400/2000], Avg Train Loss: 2.9202\n",
      "Epoch [1400/2000], Avg Val Loss: 2.6336\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1401/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9536\n",
      "Epoch [1401/2000], Avg Train Loss: 2.9536\n",
      "Epoch [1401/2000], Avg Val Loss: 2.6337\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1402/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9518\n",
      "Epoch [1402/2000], Avg Train Loss: 2.9518\n",
      "Epoch [1402/2000], Avg Val Loss: 2.6339\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1403/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9475\n",
      "Epoch [1403/2000], Avg Train Loss: 2.9475\n",
      "Epoch [1403/2000], Avg Val Loss: 2.6339\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1404/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9332\n",
      "Epoch [1404/2000], Avg Train Loss: 2.9332\n",
      "Epoch [1404/2000], Avg Val Loss: 2.6340\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1405/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9114\n",
      "Epoch [1405/2000], Avg Train Loss: 2.9114\n",
      "Epoch [1405/2000], Avg Val Loss: 2.6340\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1406/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9013\n",
      "Epoch [1406/2000], Avg Train Loss: 2.9013\n",
      "Epoch [1406/2000], Avg Val Loss: 2.6341\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1407/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9438\n",
      "Epoch [1407/2000], Avg Train Loss: 2.9438\n",
      "Epoch [1407/2000], Avg Val Loss: 2.6342\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1408/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9195\n",
      "Epoch [1408/2000], Avg Train Loss: 2.9195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1408/2000], Avg Val Loss: 2.6344\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1409/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8991\n",
      "Epoch [1409/2000], Avg Train Loss: 2.8991\n",
      "Epoch [1409/2000], Avg Val Loss: 2.6343\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1410/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9047\n",
      "Epoch [1410/2000], Avg Train Loss: 2.9047\n",
      "Epoch [1410/2000], Avg Val Loss: 2.6342\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1411/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9283\n",
      "Epoch [1411/2000], Avg Train Loss: 2.9283\n",
      "Epoch [1411/2000], Avg Val Loss: 2.6341\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1412/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9553\n",
      "Epoch [1412/2000], Avg Train Loss: 2.9553\n",
      "Epoch [1412/2000], Avg Val Loss: 2.6338\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1413/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9021\n",
      "Epoch [1413/2000], Avg Train Loss: 2.9021\n",
      "Epoch [1413/2000], Avg Val Loss: 2.6335\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1414/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9547\n",
      "Epoch [1414/2000], Avg Train Loss: 2.9547\n",
      "Epoch [1414/2000], Avg Val Loss: 2.6332\n",
      "Validation loss improved from 2.6334 to 2.6332. Saving model...\n",
      "\n",
      "LOG: Epoch [1415/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9001\n",
      "Epoch [1415/2000], Avg Train Loss: 2.9001\n",
      "Epoch [1415/2000], Avg Val Loss: 2.6330\n",
      "Validation loss improved from 2.6332 to 2.6330. Saving model...\n",
      "\n",
      "LOG: Epoch [1416/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9093\n",
      "Epoch [1416/2000], Avg Train Loss: 2.9093\n",
      "Epoch [1416/2000], Avg Val Loss: 2.6329\n",
      "Validation loss improved from 2.6330 to 2.6329. Saving model...\n",
      "\n",
      "LOG: Epoch [1417/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9759\n",
      "Epoch [1417/2000], Avg Train Loss: 2.9759\n",
      "Epoch [1417/2000], Avg Val Loss: 2.6327\n",
      "Validation loss improved from 2.6329 to 2.6327. Saving model...\n",
      "\n",
      "LOG: Epoch [1418/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9364\n",
      "Epoch [1418/2000], Avg Train Loss: 2.9364\n",
      "Epoch [1418/2000], Avg Val Loss: 2.6328\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1419/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8954\n",
      "Epoch [1419/2000], Avg Train Loss: 2.8954\n",
      "Epoch [1419/2000], Avg Val Loss: 2.6329\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1420/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9426\n",
      "Epoch [1420/2000], Avg Train Loss: 2.9426\n",
      "Epoch [1420/2000], Avg Val Loss: 2.6330\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1421/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9357\n",
      "Epoch [1421/2000], Avg Train Loss: 2.9357\n",
      "Epoch [1421/2000], Avg Val Loss: 2.6332\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1422/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9827\n",
      "Epoch [1422/2000], Avg Train Loss: 2.9827\n",
      "Epoch [1422/2000], Avg Val Loss: 2.6333\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1423/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9155\n",
      "Epoch [1423/2000], Avg Train Loss: 2.9155\n",
      "Epoch [1423/2000], Avg Val Loss: 2.6336\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1424/2000] - Training\n",
      "    Batch [1/1], Train Loss: 3.0023\n",
      "Epoch [1424/2000], Avg Train Loss: 3.0023\n",
      "Epoch [1424/2000], Avg Val Loss: 2.6337\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1425/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9668\n",
      "Epoch [1425/2000], Avg Train Loss: 2.9668\n",
      "Epoch [1425/2000], Avg Val Loss: 2.6339\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1426/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9282\n",
      "Epoch [1426/2000], Avg Train Loss: 2.9282\n",
      "Epoch [1426/2000], Avg Val Loss: 2.6341\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1427/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9549\n",
      "Epoch [1427/2000], Avg Train Loss: 2.9549\n",
      "Epoch [1427/2000], Avg Val Loss: 2.6344\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1428/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9368\n",
      "Epoch [1428/2000], Avg Train Loss: 2.9368\n",
      "Epoch [1428/2000], Avg Val Loss: 2.6347\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1429/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9504\n",
      "Epoch [1429/2000], Avg Train Loss: 2.9504\n",
      "Epoch [1429/2000], Avg Val Loss: 2.6349\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1430/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9323\n",
      "Epoch [1430/2000], Avg Train Loss: 2.9323\n",
      "Epoch [1430/2000], Avg Val Loss: 2.6351\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1431/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9066\n",
      "Epoch [1431/2000], Avg Train Loss: 2.9066\n",
      "Epoch [1431/2000], Avg Val Loss: 2.6353\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1432/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9182\n",
      "Epoch [1432/2000], Avg Train Loss: 2.9182\n",
      "Epoch [1432/2000], Avg Val Loss: 2.6353\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1433/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9349\n",
      "Epoch [1433/2000], Avg Train Loss: 2.9349\n",
      "Epoch [1433/2000], Avg Val Loss: 2.6353\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1434/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9721\n",
      "Epoch [1434/2000], Avg Train Loss: 2.9721\n",
      "Epoch [1434/2000], Avg Val Loss: 2.6351\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1435/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9897\n",
      "Epoch [1435/2000], Avg Train Loss: 2.9897\n",
      "Epoch [1435/2000], Avg Val Loss: 2.6351\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1436/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9386\n",
      "Epoch [1436/2000], Avg Train Loss: 2.9386\n",
      "Epoch [1436/2000], Avg Val Loss: 2.6350\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1437/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9252\n",
      "Epoch [1437/2000], Avg Train Loss: 2.9252\n",
      "Epoch [1437/2000], Avg Val Loss: 2.6348\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1438/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9654\n",
      "Epoch [1438/2000], Avg Train Loss: 2.9654\n",
      "Epoch [1438/2000], Avg Val Loss: 2.6344\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1439/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9066\n",
      "Epoch [1439/2000], Avg Train Loss: 2.9066\n",
      "Epoch [1439/2000], Avg Val Loss: 2.6340\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1440/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9138\n",
      "Epoch [1440/2000], Avg Train Loss: 2.9138\n",
      "Epoch [1440/2000], Avg Val Loss: 2.6337\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1441/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9857\n",
      "Epoch [1441/2000], Avg Train Loss: 2.9857\n",
      "Epoch [1441/2000], Avg Val Loss: 2.6334\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1442/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9664\n",
      "Epoch [1442/2000], Avg Train Loss: 2.9664\n",
      "Epoch [1442/2000], Avg Val Loss: 2.6333\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1443/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9221\n",
      "Epoch [1443/2000], Avg Train Loss: 2.9221\n",
      "Epoch [1443/2000], Avg Val Loss: 2.6332\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1444/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9385\n",
      "Epoch [1444/2000], Avg Train Loss: 2.9385\n",
      "Epoch [1444/2000], Avg Val Loss: 2.6331\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1445/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9295\n",
      "Epoch [1445/2000], Avg Train Loss: 2.9295\n",
      "Epoch [1445/2000], Avg Val Loss: 2.6329\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1446/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9478\n",
      "Epoch [1446/2000], Avg Train Loss: 2.9478\n",
      "Epoch [1446/2000], Avg Val Loss: 2.6330\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1447/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9870\n",
      "Epoch [1447/2000], Avg Train Loss: 2.9870\n",
      "Epoch [1447/2000], Avg Val Loss: 2.6332\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1448/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9266\n",
      "Epoch [1448/2000], Avg Train Loss: 2.9266\n",
      "Epoch [1448/2000], Avg Val Loss: 2.6333\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1449/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9444\n",
      "Epoch [1449/2000], Avg Train Loss: 2.9444\n",
      "Epoch [1449/2000], Avg Val Loss: 2.6334\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1450/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9659\n",
      "Epoch [1450/2000], Avg Train Loss: 2.9659\n",
      "Epoch [1450/2000], Avg Val Loss: 2.6333\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1451/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8899\n",
      "Epoch [1451/2000], Avg Train Loss: 2.8899\n",
      "Epoch [1451/2000], Avg Val Loss: 2.6334\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1452/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9367\n",
      "Epoch [1452/2000], Avg Train Loss: 2.9367\n",
      "Epoch [1452/2000], Avg Val Loss: 2.6334\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1453/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9043\n",
      "Epoch [1453/2000], Avg Train Loss: 2.9043\n",
      "Epoch [1453/2000], Avg Val Loss: 2.6332\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1454/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 2.8884\n",
      "Epoch [1454/2000], Avg Train Loss: 2.8884\n",
      "Epoch [1454/2000], Avg Val Loss: 2.6331\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1455/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9067\n",
      "Epoch [1455/2000], Avg Train Loss: 2.9067\n",
      "Epoch [1455/2000], Avg Val Loss: 2.6330\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1456/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9364\n",
      "Epoch [1456/2000], Avg Train Loss: 2.9364\n",
      "Epoch [1456/2000], Avg Val Loss: 2.6331\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1457/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9520\n",
      "Epoch [1457/2000], Avg Train Loss: 2.9520\n",
      "Epoch [1457/2000], Avg Val Loss: 2.6333\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1458/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8810\n",
      "Epoch [1458/2000], Avg Train Loss: 2.8810\n",
      "Epoch [1458/2000], Avg Val Loss: 2.6335\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1459/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8895\n",
      "Epoch [1459/2000], Avg Train Loss: 2.8895\n",
      "Epoch [1459/2000], Avg Val Loss: 2.6338\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1460/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9166\n",
      "Epoch [1460/2000], Avg Train Loss: 2.9166\n",
      "Epoch [1460/2000], Avg Val Loss: 2.6341\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1461/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9510\n",
      "Epoch [1461/2000], Avg Train Loss: 2.9510\n",
      "Epoch [1461/2000], Avg Val Loss: 2.6344\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1462/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9156\n",
      "Epoch [1462/2000], Avg Train Loss: 2.9156\n",
      "Epoch [1462/2000], Avg Val Loss: 2.6345\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1463/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9572\n",
      "Epoch [1463/2000], Avg Train Loss: 2.9572\n",
      "Epoch [1463/2000], Avg Val Loss: 2.6347\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1464/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9016\n",
      "Epoch [1464/2000], Avg Train Loss: 2.9016\n",
      "Epoch [1464/2000], Avg Val Loss: 2.6350\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1465/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9805\n",
      "Epoch [1465/2000], Avg Train Loss: 2.9805\n",
      "Epoch [1465/2000], Avg Val Loss: 2.6352\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1466/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9383\n",
      "Epoch [1466/2000], Avg Train Loss: 2.9383\n",
      "Epoch [1466/2000], Avg Val Loss: 2.6354\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1467/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9157\n",
      "Epoch [1467/2000], Avg Train Loss: 2.9157\n",
      "Epoch [1467/2000], Avg Val Loss: 2.6355\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1468/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9001\n",
      "Epoch [1468/2000], Avg Train Loss: 2.9001\n",
      "Epoch [1468/2000], Avg Val Loss: 2.6356\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1469/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9540\n",
      "Epoch [1469/2000], Avg Train Loss: 2.9540\n",
      "Epoch [1469/2000], Avg Val Loss: 2.6355\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1470/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9172\n",
      "Epoch [1470/2000], Avg Train Loss: 2.9172\n",
      "Epoch [1470/2000], Avg Val Loss: 2.6355\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1471/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9423\n",
      "Epoch [1471/2000], Avg Train Loss: 2.9423\n",
      "Epoch [1471/2000], Avg Val Loss: 2.6353\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1472/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9132\n",
      "Epoch [1472/2000], Avg Train Loss: 2.9132\n",
      "Epoch [1472/2000], Avg Val Loss: 2.6351\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1473/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9348\n",
      "Epoch [1473/2000], Avg Train Loss: 2.9348\n",
      "Epoch [1473/2000], Avg Val Loss: 2.6348\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1474/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9003\n",
      "Epoch [1474/2000], Avg Train Loss: 2.9003\n",
      "Epoch [1474/2000], Avg Val Loss: 2.6347\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1475/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9226\n",
      "Epoch [1475/2000], Avg Train Loss: 2.9226\n",
      "Epoch [1475/2000], Avg Val Loss: 2.6346\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1476/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9382\n",
      "Epoch [1476/2000], Avg Train Loss: 2.9382\n",
      "Epoch [1476/2000], Avg Val Loss: 2.6345\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1477/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9358\n",
      "Epoch [1477/2000], Avg Train Loss: 2.9358\n",
      "Epoch [1477/2000], Avg Val Loss: 2.6343\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1478/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8662\n",
      "Epoch [1478/2000], Avg Train Loss: 2.8662\n",
      "Epoch [1478/2000], Avg Val Loss: 2.6342\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1479/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8950\n",
      "Epoch [1479/2000], Avg Train Loss: 2.8950\n",
      "Epoch [1479/2000], Avg Val Loss: 2.6340\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1480/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9245\n",
      "Epoch [1480/2000], Avg Train Loss: 2.9245\n",
      "Epoch [1480/2000], Avg Val Loss: 2.6338\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1481/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9758\n",
      "Epoch [1481/2000], Avg Train Loss: 2.9758\n",
      "Epoch [1481/2000], Avg Val Loss: 2.6336\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1482/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9323\n",
      "Epoch [1482/2000], Avg Train Loss: 2.9323\n",
      "Epoch [1482/2000], Avg Val Loss: 2.6334\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1483/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9435\n",
      "Epoch [1483/2000], Avg Train Loss: 2.9435\n",
      "Epoch [1483/2000], Avg Val Loss: 2.6332\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1484/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8850\n",
      "Epoch [1484/2000], Avg Train Loss: 2.8850\n",
      "Epoch [1484/2000], Avg Val Loss: 2.6328\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1485/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9704\n",
      "Epoch [1485/2000], Avg Train Loss: 2.9704\n",
      "Epoch [1485/2000], Avg Val Loss: 2.6324\n",
      "Validation loss improved from 2.6327 to 2.6324. Saving model...\n",
      "\n",
      "LOG: Epoch [1486/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8870\n",
      "Epoch [1486/2000], Avg Train Loss: 2.8870\n",
      "Epoch [1486/2000], Avg Val Loss: 2.6320\n",
      "Validation loss improved from 2.6324 to 2.6320. Saving model...\n",
      "\n",
      "LOG: Epoch [1487/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9018\n",
      "Epoch [1487/2000], Avg Train Loss: 2.9018\n",
      "Epoch [1487/2000], Avg Val Loss: 2.6319\n",
      "Validation loss improved from 2.6320 to 2.6319. Saving model...\n",
      "\n",
      "LOG: Epoch [1488/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9348\n",
      "Epoch [1488/2000], Avg Train Loss: 2.9348\n",
      "Epoch [1488/2000], Avg Val Loss: 2.6317\n",
      "Validation loss improved from 2.6319 to 2.6317. Saving model...\n",
      "\n",
      "LOG: Epoch [1489/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9328\n",
      "Epoch [1489/2000], Avg Train Loss: 2.9328\n",
      "Epoch [1489/2000], Avg Val Loss: 2.6315\n",
      "Validation loss improved from 2.6317 to 2.6315. Saving model...\n",
      "\n",
      "LOG: Epoch [1490/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8684\n",
      "Epoch [1490/2000], Avg Train Loss: 2.8684\n",
      "Epoch [1490/2000], Avg Val Loss: 2.6313\n",
      "Validation loss improved from 2.6315 to 2.6313. Saving model...\n",
      "\n",
      "LOG: Epoch [1491/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8775\n",
      "Epoch [1491/2000], Avg Train Loss: 2.8775\n",
      "Epoch [1491/2000], Avg Val Loss: 2.6311\n",
      "Validation loss improved from 2.6313 to 2.6311. Saving model...\n",
      "\n",
      "LOG: Epoch [1492/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8522\n",
      "Epoch [1492/2000], Avg Train Loss: 2.8522\n",
      "Epoch [1492/2000], Avg Val Loss: 2.6309\n",
      "Validation loss improved from 2.6311 to 2.6309. Saving model...\n",
      "\n",
      "LOG: Epoch [1493/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9296\n",
      "Epoch [1493/2000], Avg Train Loss: 2.9296\n",
      "Epoch [1493/2000], Avg Val Loss: 2.6306\n",
      "Validation loss improved from 2.6309 to 2.6306. Saving model...\n",
      "\n",
      "LOG: Epoch [1494/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8554\n",
      "Epoch [1494/2000], Avg Train Loss: 2.8554\n",
      "Epoch [1494/2000], Avg Val Loss: 2.6305\n",
      "Validation loss improved from 2.6306 to 2.6305. Saving model...\n",
      "\n",
      "LOG: Epoch [1495/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9817\n",
      "Epoch [1495/2000], Avg Train Loss: 2.9817\n",
      "Epoch [1495/2000], Avg Val Loss: 2.6305\n",
      "Validation loss did not improve. Patience: 1/100\n",
      "\n",
      "LOG: Epoch [1496/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9091\n",
      "Epoch [1496/2000], Avg Train Loss: 2.9091\n",
      "Epoch [1496/2000], Avg Val Loss: 2.6306\n",
      "Validation loss did not improve. Patience: 2/100\n",
      "\n",
      "LOG: Epoch [1497/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 2.8965\n",
      "Epoch [1497/2000], Avg Train Loss: 2.8965\n",
      "Epoch [1497/2000], Avg Val Loss: 2.6306\n",
      "Validation loss did not improve. Patience: 3/100\n",
      "\n",
      "LOG: Epoch [1498/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9114\n",
      "Epoch [1498/2000], Avg Train Loss: 2.9114\n",
      "Epoch [1498/2000], Avg Val Loss: 2.6307\n",
      "Validation loss did not improve. Patience: 4/100\n",
      "\n",
      "LOG: Epoch [1499/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9276\n",
      "Epoch [1499/2000], Avg Train Loss: 2.9276\n",
      "Epoch [1499/2000], Avg Val Loss: 2.6309\n",
      "Validation loss did not improve. Patience: 5/100\n",
      "\n",
      "LOG: Epoch [1500/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9138\n",
      "Epoch [1500/2000], Avg Train Loss: 2.9138\n",
      "Epoch [1500/2000], Avg Val Loss: 2.6312\n",
      "Validation loss did not improve. Patience: 6/100\n",
      "\n",
      "LOG: Epoch [1501/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8568\n",
      "Epoch [1501/2000], Avg Train Loss: 2.8568\n",
      "Epoch [1501/2000], Avg Val Loss: 2.6315\n",
      "Validation loss did not improve. Patience: 7/100\n",
      "\n",
      "LOG: Epoch [1502/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8954\n",
      "Epoch [1502/2000], Avg Train Loss: 2.8954\n",
      "Epoch [1502/2000], Avg Val Loss: 2.6317\n",
      "Validation loss did not improve. Patience: 8/100\n",
      "\n",
      "LOG: Epoch [1503/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8770\n",
      "Epoch [1503/2000], Avg Train Loss: 2.8770\n",
      "Epoch [1503/2000], Avg Val Loss: 2.6317\n",
      "Validation loss did not improve. Patience: 9/100\n",
      "\n",
      "LOG: Epoch [1504/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8977\n",
      "Epoch [1504/2000], Avg Train Loss: 2.8977\n",
      "Epoch [1504/2000], Avg Val Loss: 2.6317\n",
      "Validation loss did not improve. Patience: 10/100\n",
      "\n",
      "LOG: Epoch [1505/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8628\n",
      "Epoch [1505/2000], Avg Train Loss: 2.8628\n",
      "Epoch [1505/2000], Avg Val Loss: 2.6318\n",
      "Validation loss did not improve. Patience: 11/100\n",
      "\n",
      "LOG: Epoch [1506/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8877\n",
      "Epoch [1506/2000], Avg Train Loss: 2.8877\n",
      "Epoch [1506/2000], Avg Val Loss: 2.6320\n",
      "Validation loss did not improve. Patience: 12/100\n",
      "\n",
      "LOG: Epoch [1507/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8681\n",
      "Epoch [1507/2000], Avg Train Loss: 2.8681\n",
      "Epoch [1507/2000], Avg Val Loss: 2.6323\n",
      "Validation loss did not improve. Patience: 13/100\n",
      "\n",
      "LOG: Epoch [1508/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9526\n",
      "Epoch [1508/2000], Avg Train Loss: 2.9526\n",
      "Epoch [1508/2000], Avg Val Loss: 2.6327\n",
      "Validation loss did not improve. Patience: 14/100\n",
      "\n",
      "LOG: Epoch [1509/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8586\n",
      "Epoch [1509/2000], Avg Train Loss: 2.8586\n",
      "Epoch [1509/2000], Avg Val Loss: 2.6331\n",
      "Validation loss did not improve. Patience: 15/100\n",
      "\n",
      "LOG: Epoch [1510/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9647\n",
      "Epoch [1510/2000], Avg Train Loss: 2.9647\n",
      "Epoch [1510/2000], Avg Val Loss: 2.6334\n",
      "Validation loss did not improve. Patience: 16/100\n",
      "\n",
      "LOG: Epoch [1511/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9190\n",
      "Epoch [1511/2000], Avg Train Loss: 2.9190\n",
      "Epoch [1511/2000], Avg Val Loss: 2.6337\n",
      "Validation loss did not improve. Patience: 17/100\n",
      "\n",
      "LOG: Epoch [1512/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9093\n",
      "Epoch [1512/2000], Avg Train Loss: 2.9093\n",
      "Epoch [1512/2000], Avg Val Loss: 2.6340\n",
      "Validation loss did not improve. Patience: 18/100\n",
      "\n",
      "LOG: Epoch [1513/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9207\n",
      "Epoch [1513/2000], Avg Train Loss: 2.9207\n",
      "Epoch [1513/2000], Avg Val Loss: 2.6341\n",
      "Validation loss did not improve. Patience: 19/100\n",
      "\n",
      "LOG: Epoch [1514/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8987\n",
      "Epoch [1514/2000], Avg Train Loss: 2.8987\n",
      "Epoch [1514/2000], Avg Val Loss: 2.6343\n",
      "Validation loss did not improve. Patience: 20/100\n",
      "\n",
      "LOG: Epoch [1515/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9186\n",
      "Epoch [1515/2000], Avg Train Loss: 2.9186\n",
      "Epoch [1515/2000], Avg Val Loss: 2.6346\n",
      "Validation loss did not improve. Patience: 21/100\n",
      "\n",
      "LOG: Epoch [1516/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9361\n",
      "Epoch [1516/2000], Avg Train Loss: 2.9361\n",
      "Epoch [1516/2000], Avg Val Loss: 2.6347\n",
      "Validation loss did not improve. Patience: 22/100\n",
      "\n",
      "LOG: Epoch [1517/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8623\n",
      "Epoch [1517/2000], Avg Train Loss: 2.8623\n",
      "Epoch [1517/2000], Avg Val Loss: 2.6348\n",
      "Validation loss did not improve. Patience: 23/100\n",
      "\n",
      "LOG: Epoch [1518/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9226\n",
      "Epoch [1518/2000], Avg Train Loss: 2.9226\n",
      "Epoch [1518/2000], Avg Val Loss: 2.6348\n",
      "Validation loss did not improve. Patience: 24/100\n",
      "\n",
      "LOG: Epoch [1519/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9156\n",
      "Epoch [1519/2000], Avg Train Loss: 2.9156\n",
      "Epoch [1519/2000], Avg Val Loss: 2.6347\n",
      "Validation loss did not improve. Patience: 25/100\n",
      "\n",
      "LOG: Epoch [1520/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9010\n",
      "Epoch [1520/2000], Avg Train Loss: 2.9010\n",
      "Epoch [1520/2000], Avg Val Loss: 2.6346\n",
      "Validation loss did not improve. Patience: 26/100\n",
      "\n",
      "LOG: Epoch [1521/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8879\n",
      "Epoch [1521/2000], Avg Train Loss: 2.8879\n",
      "Epoch [1521/2000], Avg Val Loss: 2.6346\n",
      "Validation loss did not improve. Patience: 27/100\n",
      "\n",
      "LOG: Epoch [1522/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8550\n",
      "Epoch [1522/2000], Avg Train Loss: 2.8550\n",
      "Epoch [1522/2000], Avg Val Loss: 2.6348\n",
      "Validation loss did not improve. Patience: 28/100\n",
      "\n",
      "LOG: Epoch [1523/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9555\n",
      "Epoch [1523/2000], Avg Train Loss: 2.9555\n",
      "Epoch [1523/2000], Avg Val Loss: 2.6352\n",
      "Validation loss did not improve. Patience: 29/100\n",
      "\n",
      "LOG: Epoch [1524/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8944\n",
      "Epoch [1524/2000], Avg Train Loss: 2.8944\n",
      "Epoch [1524/2000], Avg Val Loss: 2.6356\n",
      "Validation loss did not improve. Patience: 30/100\n",
      "\n",
      "LOG: Epoch [1525/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8954\n",
      "Epoch [1525/2000], Avg Train Loss: 2.8954\n",
      "Epoch [1525/2000], Avg Val Loss: 2.6360\n",
      "Validation loss did not improve. Patience: 31/100\n",
      "\n",
      "LOG: Epoch [1526/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8955\n",
      "Epoch [1526/2000], Avg Train Loss: 2.8955\n",
      "Epoch [1526/2000], Avg Val Loss: 2.6363\n",
      "Validation loss did not improve. Patience: 32/100\n",
      "\n",
      "LOG: Epoch [1527/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8867\n",
      "Epoch [1527/2000], Avg Train Loss: 2.8867\n",
      "Epoch [1527/2000], Avg Val Loss: 2.6365\n",
      "Validation loss did not improve. Patience: 33/100\n",
      "\n",
      "LOG: Epoch [1528/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8846\n",
      "Epoch [1528/2000], Avg Train Loss: 2.8846\n",
      "Epoch [1528/2000], Avg Val Loss: 2.6367\n",
      "Validation loss did not improve. Patience: 34/100\n",
      "\n",
      "LOG: Epoch [1529/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9069\n",
      "Epoch [1529/2000], Avg Train Loss: 2.9069\n",
      "Epoch [1529/2000], Avg Val Loss: 2.6367\n",
      "Validation loss did not improve. Patience: 35/100\n",
      "\n",
      "LOG: Epoch [1530/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8889\n",
      "Epoch [1530/2000], Avg Train Loss: 2.8889\n",
      "Epoch [1530/2000], Avg Val Loss: 2.6368\n",
      "Validation loss did not improve. Patience: 36/100\n",
      "\n",
      "LOG: Epoch [1531/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8762\n",
      "Epoch [1531/2000], Avg Train Loss: 2.8762\n",
      "Epoch [1531/2000], Avg Val Loss: 2.6366\n",
      "Validation loss did not improve. Patience: 37/100\n",
      "\n",
      "LOG: Epoch [1532/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9028\n",
      "Epoch [1532/2000], Avg Train Loss: 2.9028\n",
      "Epoch [1532/2000], Avg Val Loss: 2.6363\n",
      "Validation loss did not improve. Patience: 38/100\n",
      "\n",
      "LOG: Epoch [1533/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8591\n",
      "Epoch [1533/2000], Avg Train Loss: 2.8591\n",
      "Epoch [1533/2000], Avg Val Loss: 2.6361\n",
      "Validation loss did not improve. Patience: 39/100\n",
      "\n",
      "LOG: Epoch [1534/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9017\n",
      "Epoch [1534/2000], Avg Train Loss: 2.9017\n",
      "Epoch [1534/2000], Avg Val Loss: 2.6360\n",
      "Validation loss did not improve. Patience: 40/100\n",
      "\n",
      "LOG: Epoch [1535/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8963\n",
      "Epoch [1535/2000], Avg Train Loss: 2.8963\n",
      "Epoch [1535/2000], Avg Val Loss: 2.6358\n",
      "Validation loss did not improve. Patience: 41/100\n",
      "\n",
      "LOG: Epoch [1536/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9077\n",
      "Epoch [1536/2000], Avg Train Loss: 2.9077\n",
      "Epoch [1536/2000], Avg Val Loss: 2.6357\n",
      "Validation loss did not improve. Patience: 42/100\n",
      "\n",
      "LOG: Epoch [1537/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8742\n",
      "Epoch [1537/2000], Avg Train Loss: 2.8742\n",
      "Epoch [1537/2000], Avg Val Loss: 2.6355\n",
      "Validation loss did not improve. Patience: 43/100\n",
      "\n",
      "LOG: Epoch [1538/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8438\n",
      "Epoch [1538/2000], Avg Train Loss: 2.8438\n",
      "Epoch [1538/2000], Avg Val Loss: 2.6352\n",
      "Validation loss did not improve. Patience: 44/100\n",
      "\n",
      "LOG: Epoch [1539/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8699\n",
      "Epoch [1539/2000], Avg Train Loss: 2.8699\n",
      "Epoch [1539/2000], Avg Val Loss: 2.6350\n",
      "Validation loss did not improve. Patience: 45/100\n",
      "\n",
      "LOG: Epoch [1540/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8442\n",
      "Epoch [1540/2000], Avg Train Loss: 2.8442\n",
      "Epoch [1540/2000], Avg Val Loss: 2.6347\n",
      "Validation loss did not improve. Patience: 46/100\n",
      "\n",
      "LOG: Epoch [1541/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8767\n",
      "Epoch [1541/2000], Avg Train Loss: 2.8767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1541/2000], Avg Val Loss: 2.6344\n",
      "Validation loss did not improve. Patience: 47/100\n",
      "\n",
      "LOG: Epoch [1542/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8948\n",
      "Epoch [1542/2000], Avg Train Loss: 2.8948\n",
      "Epoch [1542/2000], Avg Val Loss: 2.6343\n",
      "Validation loss did not improve. Patience: 48/100\n",
      "\n",
      "LOG: Epoch [1543/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8604\n",
      "Epoch [1543/2000], Avg Train Loss: 2.8604\n",
      "Epoch [1543/2000], Avg Val Loss: 2.6342\n",
      "Validation loss did not improve. Patience: 49/100\n",
      "\n",
      "LOG: Epoch [1544/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8944\n",
      "Epoch [1544/2000], Avg Train Loss: 2.8944\n",
      "Epoch [1544/2000], Avg Val Loss: 2.6341\n",
      "Validation loss did not improve. Patience: 50/100\n",
      "\n",
      "LOG: Epoch [1545/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8569\n",
      "Epoch [1545/2000], Avg Train Loss: 2.8569\n",
      "Epoch [1545/2000], Avg Val Loss: 2.6342\n",
      "Validation loss did not improve. Patience: 51/100\n",
      "\n",
      "LOG: Epoch [1546/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8452\n",
      "Epoch [1546/2000], Avg Train Loss: 2.8452\n",
      "Epoch [1546/2000], Avg Val Loss: 2.6341\n",
      "Validation loss did not improve. Patience: 52/100\n",
      "\n",
      "LOG: Epoch [1547/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8985\n",
      "Epoch [1547/2000], Avg Train Loss: 2.8985\n",
      "Epoch [1547/2000], Avg Val Loss: 2.6341\n",
      "Validation loss did not improve. Patience: 53/100\n",
      "\n",
      "LOG: Epoch [1548/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8923\n",
      "Epoch [1548/2000], Avg Train Loss: 2.8923\n",
      "Epoch [1548/2000], Avg Val Loss: 2.6341\n",
      "Validation loss did not improve. Patience: 54/100\n",
      "\n",
      "LOG: Epoch [1549/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8940\n",
      "Epoch [1549/2000], Avg Train Loss: 2.8940\n",
      "Epoch [1549/2000], Avg Val Loss: 2.6341\n",
      "Validation loss did not improve. Patience: 55/100\n",
      "\n",
      "LOG: Epoch [1550/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8794\n",
      "Epoch [1550/2000], Avg Train Loss: 2.8794\n",
      "Epoch [1550/2000], Avg Val Loss: 2.6341\n",
      "Validation loss did not improve. Patience: 56/100\n",
      "\n",
      "LOG: Epoch [1551/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9034\n",
      "Epoch [1551/2000], Avg Train Loss: 2.9034\n",
      "Epoch [1551/2000], Avg Val Loss: 2.6341\n",
      "Validation loss did not improve. Patience: 57/100\n",
      "\n",
      "LOG: Epoch [1552/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8970\n",
      "Epoch [1552/2000], Avg Train Loss: 2.8970\n",
      "Epoch [1552/2000], Avg Val Loss: 2.6342\n",
      "Validation loss did not improve. Patience: 58/100\n",
      "\n",
      "LOG: Epoch [1553/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8859\n",
      "Epoch [1553/2000], Avg Train Loss: 2.8859\n",
      "Epoch [1553/2000], Avg Val Loss: 2.6342\n",
      "Validation loss did not improve. Patience: 59/100\n",
      "\n",
      "LOG: Epoch [1554/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9108\n",
      "Epoch [1554/2000], Avg Train Loss: 2.9108\n",
      "Epoch [1554/2000], Avg Val Loss: 2.6344\n",
      "Validation loss did not improve. Patience: 60/100\n",
      "\n",
      "LOG: Epoch [1555/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8855\n",
      "Epoch [1555/2000], Avg Train Loss: 2.8855\n",
      "Epoch [1555/2000], Avg Val Loss: 2.6344\n",
      "Validation loss did not improve. Patience: 61/100\n",
      "\n",
      "LOG: Epoch [1556/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9125\n",
      "Epoch [1556/2000], Avg Train Loss: 2.9125\n",
      "Epoch [1556/2000], Avg Val Loss: 2.6342\n",
      "Validation loss did not improve. Patience: 62/100\n",
      "\n",
      "LOG: Epoch [1557/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9086\n",
      "Epoch [1557/2000], Avg Train Loss: 2.9086\n",
      "Epoch [1557/2000], Avg Val Loss: 2.6342\n",
      "Validation loss did not improve. Patience: 63/100\n",
      "\n",
      "LOG: Epoch [1558/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8813\n",
      "Epoch [1558/2000], Avg Train Loss: 2.8813\n",
      "Epoch [1558/2000], Avg Val Loss: 2.6342\n",
      "Validation loss did not improve. Patience: 64/100\n",
      "\n",
      "LOG: Epoch [1559/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8253\n",
      "Epoch [1559/2000], Avg Train Loss: 2.8253\n",
      "Epoch [1559/2000], Avg Val Loss: 2.6343\n",
      "Validation loss did not improve. Patience: 65/100\n",
      "\n",
      "LOG: Epoch [1560/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8874\n",
      "Epoch [1560/2000], Avg Train Loss: 2.8874\n",
      "Epoch [1560/2000], Avg Val Loss: 2.6343\n",
      "Validation loss did not improve. Patience: 66/100\n",
      "\n",
      "LOG: Epoch [1561/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8807\n",
      "Epoch [1561/2000], Avg Train Loss: 2.8807\n",
      "Epoch [1561/2000], Avg Val Loss: 2.6343\n",
      "Validation loss did not improve. Patience: 67/100\n",
      "\n",
      "LOG: Epoch [1562/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8863\n",
      "Epoch [1562/2000], Avg Train Loss: 2.8863\n",
      "Epoch [1562/2000], Avg Val Loss: 2.6342\n",
      "Validation loss did not improve. Patience: 68/100\n",
      "\n",
      "LOG: Epoch [1563/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8609\n",
      "Epoch [1563/2000], Avg Train Loss: 2.8609\n",
      "Epoch [1563/2000], Avg Val Loss: 2.6342\n",
      "Validation loss did not improve. Patience: 69/100\n",
      "\n",
      "LOG: Epoch [1564/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9077\n",
      "Epoch [1564/2000], Avg Train Loss: 2.9077\n",
      "Epoch [1564/2000], Avg Val Loss: 2.6343\n",
      "Validation loss did not improve. Patience: 70/100\n",
      "\n",
      "LOG: Epoch [1565/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8645\n",
      "Epoch [1565/2000], Avg Train Loss: 2.8645\n",
      "Epoch [1565/2000], Avg Val Loss: 2.6345\n",
      "Validation loss did not improve. Patience: 71/100\n",
      "\n",
      "LOG: Epoch [1566/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9147\n",
      "Epoch [1566/2000], Avg Train Loss: 2.9147\n",
      "Epoch [1566/2000], Avg Val Loss: 2.6347\n",
      "Validation loss did not improve. Patience: 72/100\n",
      "\n",
      "LOG: Epoch [1567/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9019\n",
      "Epoch [1567/2000], Avg Train Loss: 2.9019\n",
      "Epoch [1567/2000], Avg Val Loss: 2.6350\n",
      "Validation loss did not improve. Patience: 73/100\n",
      "\n",
      "LOG: Epoch [1568/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8750\n",
      "Epoch [1568/2000], Avg Train Loss: 2.8750\n",
      "Epoch [1568/2000], Avg Val Loss: 2.6353\n",
      "Validation loss did not improve. Patience: 74/100\n",
      "\n",
      "LOG: Epoch [1569/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8259\n",
      "Epoch [1569/2000], Avg Train Loss: 2.8259\n",
      "Epoch [1569/2000], Avg Val Loss: 2.6355\n",
      "Validation loss did not improve. Patience: 75/100\n",
      "\n",
      "LOG: Epoch [1570/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8546\n",
      "Epoch [1570/2000], Avg Train Loss: 2.8546\n",
      "Epoch [1570/2000], Avg Val Loss: 2.6358\n",
      "Validation loss did not improve. Patience: 76/100\n",
      "\n",
      "LOG: Epoch [1571/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8657\n",
      "Epoch [1571/2000], Avg Train Loss: 2.8657\n",
      "Epoch [1571/2000], Avg Val Loss: 2.6360\n",
      "Validation loss did not improve. Patience: 77/100\n",
      "\n",
      "LOG: Epoch [1572/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8537\n",
      "Epoch [1572/2000], Avg Train Loss: 2.8537\n",
      "Epoch [1572/2000], Avg Val Loss: 2.6363\n",
      "Validation loss did not improve. Patience: 78/100\n",
      "\n",
      "LOG: Epoch [1573/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9047\n",
      "Epoch [1573/2000], Avg Train Loss: 2.9047\n",
      "Epoch [1573/2000], Avg Val Loss: 2.6366\n",
      "Validation loss did not improve. Patience: 79/100\n",
      "\n",
      "LOG: Epoch [1574/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8746\n",
      "Epoch [1574/2000], Avg Train Loss: 2.8746\n",
      "Epoch [1574/2000], Avg Val Loss: 2.6367\n",
      "Validation loss did not improve. Patience: 80/100\n",
      "\n",
      "LOG: Epoch [1575/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8606\n",
      "Epoch [1575/2000], Avg Train Loss: 2.8606\n",
      "Epoch [1575/2000], Avg Val Loss: 2.6369\n",
      "Validation loss did not improve. Patience: 81/100\n",
      "\n",
      "LOG: Epoch [1576/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8649\n",
      "Epoch [1576/2000], Avg Train Loss: 2.8649\n",
      "Epoch [1576/2000], Avg Val Loss: 2.6369\n",
      "Validation loss did not improve. Patience: 82/100\n",
      "\n",
      "LOG: Epoch [1577/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8898\n",
      "Epoch [1577/2000], Avg Train Loss: 2.8898\n",
      "Epoch [1577/2000], Avg Val Loss: 2.6370\n",
      "Validation loss did not improve. Patience: 83/100\n",
      "\n",
      "LOG: Epoch [1578/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8516\n",
      "Epoch [1578/2000], Avg Train Loss: 2.8516\n",
      "Epoch [1578/2000], Avg Val Loss: 2.6370\n",
      "Validation loss did not improve. Patience: 84/100\n",
      "\n",
      "LOG: Epoch [1579/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8541\n",
      "Epoch [1579/2000], Avg Train Loss: 2.8541\n",
      "Epoch [1579/2000], Avg Val Loss: 2.6373\n",
      "Validation loss did not improve. Patience: 85/100\n",
      "\n",
      "LOG: Epoch [1580/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8782\n",
      "Epoch [1580/2000], Avg Train Loss: 2.8782\n",
      "Epoch [1580/2000], Avg Val Loss: 2.6377\n",
      "Validation loss did not improve. Patience: 86/100\n",
      "\n",
      "LOG: Epoch [1581/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8580\n",
      "Epoch [1581/2000], Avg Train Loss: 2.8580\n",
      "Epoch [1581/2000], Avg Val Loss: 2.6382\n",
      "Validation loss did not improve. Patience: 87/100\n",
      "\n",
      "LOG: Epoch [1582/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 2.9229\n",
      "Epoch [1582/2000], Avg Train Loss: 2.9229\n",
      "Epoch [1582/2000], Avg Val Loss: 2.6387\n",
      "Validation loss did not improve. Patience: 88/100\n",
      "\n",
      "LOG: Epoch [1583/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8867\n",
      "Epoch [1583/2000], Avg Train Loss: 2.8867\n",
      "Epoch [1583/2000], Avg Val Loss: 2.6393\n",
      "Validation loss did not improve. Patience: 89/100\n",
      "\n",
      "LOG: Epoch [1584/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8636\n",
      "Epoch [1584/2000], Avg Train Loss: 2.8636\n",
      "Epoch [1584/2000], Avg Val Loss: 2.6397\n",
      "Validation loss did not improve. Patience: 90/100\n",
      "\n",
      "LOG: Epoch [1585/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9163\n",
      "Epoch [1585/2000], Avg Train Loss: 2.9163\n",
      "Epoch [1585/2000], Avg Val Loss: 2.6400\n",
      "Validation loss did not improve. Patience: 91/100\n",
      "\n",
      "LOG: Epoch [1586/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8714\n",
      "Epoch [1586/2000], Avg Train Loss: 2.8714\n",
      "Epoch [1586/2000], Avg Val Loss: 2.6403\n",
      "Validation loss did not improve. Patience: 92/100\n",
      "\n",
      "LOG: Epoch [1587/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8849\n",
      "Epoch [1587/2000], Avg Train Loss: 2.8849\n",
      "Epoch [1587/2000], Avg Val Loss: 2.6404\n",
      "Validation loss did not improve. Patience: 93/100\n",
      "\n",
      "LOG: Epoch [1588/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8678\n",
      "Epoch [1588/2000], Avg Train Loss: 2.8678\n",
      "Epoch [1588/2000], Avg Val Loss: 2.6405\n",
      "Validation loss did not improve. Patience: 94/100\n",
      "\n",
      "LOG: Epoch [1589/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8780\n",
      "Epoch [1589/2000], Avg Train Loss: 2.8780\n",
      "Epoch [1589/2000], Avg Val Loss: 2.6406\n",
      "Validation loss did not improve. Patience: 95/100\n",
      "\n",
      "LOG: Epoch [1590/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8781\n",
      "Epoch [1590/2000], Avg Train Loss: 2.8781\n",
      "Epoch [1590/2000], Avg Val Loss: 2.6408\n",
      "Validation loss did not improve. Patience: 96/100\n",
      "\n",
      "LOG: Epoch [1591/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9315\n",
      "Epoch [1591/2000], Avg Train Loss: 2.9315\n",
      "Epoch [1591/2000], Avg Val Loss: 2.6408\n",
      "Validation loss did not improve. Patience: 97/100\n",
      "\n",
      "LOG: Epoch [1592/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8929\n",
      "Epoch [1592/2000], Avg Train Loss: 2.8929\n",
      "Epoch [1592/2000], Avg Val Loss: 2.6407\n",
      "Validation loss did not improve. Patience: 98/100\n",
      "\n",
      "LOG: Epoch [1593/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.8939\n",
      "Epoch [1593/2000], Avg Train Loss: 2.8939\n",
      "Epoch [1593/2000], Avg Val Loss: 2.6406\n",
      "Validation loss did not improve. Patience: 99/100\n",
      "\n",
      "LOG: Epoch [1594/2000] - Training\n",
      "    Batch [1/1], Train Loss: 2.9239\n",
      "Epoch [1594/2000], Avg Train Loss: 2.9239\n",
      "Epoch [1594/2000], Avg Val Loss: 2.6407\n",
      "Validation loss did not improve. Patience: 100/100\n",
      "Early stopping triggered at epoch 1594. No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0EAAAIhCAYAAACIfrE3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACK30lEQVR4nO3dd3zT1f7H8XeS7tJBC6VllyWWKSKIoCCCbAdeF8OFekVRceJC4OJAva6fePHqFVAR8XrByVAQUESWIktQAcuSFoTSFlraps3390dNaJq0Tduk6Xg9H48+bL45+ebkNMW8e873c0yGYRgCAAAAgDrC7O8OAAAAAEBVIgQBAAAAqFMIQQAAAADqFEIQAAAAgDqFEAQAAACgTiEEAQAAAKhTCEEAAAAA6hRCEAAAAIA6hRAEAAAAoE4hBAEolclk8uhr9erVlXqeqVOnymQyVeixq1ev9kofqrubbrpJLVu2LPH+P//8U0FBQbruuutKbJOZmamwsDBddtllHj/v3LlzZTKZtG/fPo/7UpTJZNLUqVM9fj67w4cPa+rUqdqyZYvLfZV5v1RWy5YtNXz4cL88d3kdP35cjz76qJKSkhQWFqbIyEidf/75ev3112W1Wv3dPRf9+vUr8d8YT99vvmR/3x07dszfXQFQSQH+7gCA6m3dunVOt6dPn65Vq1Zp5cqVTseTkpIq9Ty33nqrBg8eXKHHduvWTevWrat0H2q6hg0b6rLLLtMnn3yiEydOqH79+i5tFixYoNOnT2vcuHGVeq7Jkyfr3nvvrdQ5ynL48GFNmzZNLVu2VNeuXZ3uq8z7pa745ZdfdOmll+rUqVN64IEHdMEFF+j06dP64osvdO+99+qjjz7SkiVLFBYW5u+uOmnVqpXef/99l+PBwcF+6A2A2ooQBKBU559/vtPthg0bymw2uxwvLjs7u1wfrpo2baqmTZtWqI/2v25DGjdunBYuXKj3339fEyZMcLl/9uzZatSokYYNG1ap52ndunWlHl9ZlXm/1AUFBQW66qqrlJmZqY0bN6pdu3aO+4YOHaq+ffvquuuu0/3336833nijyvplGIZycnIUGhpaYpvQ0FB+nwH4HMvhAFRav3791LFjR3377be64IILFBYWpltuuUWS9OGHH+rSSy9VQkKCQkNDdfbZZ+uRRx5RVlaW0zncLW+yLztatmyZunXrptDQULVv316zZ892auduOdxNN92kevXqac+ePRo6dKjq1aunZs2a6YEHHlBubq7T4w8dOqS//e1vioiIUHR0tEaPHq1NmzbJZDJp7ty5pb72P//8U3feeaeSkpJUr149xcXFqX///lqzZo1Tu3379slkMumf//ynXnrpJSUmJqpevXrq1auX1q9f73LeuXPn6qyzzlJwcLDOPvtsvfvuu6X2w27QoEFq2rSp5syZ43Lfrl27tGHDBt1www0KCAjQ8uXLdfnll6tp06YKCQlRmzZt9Pe//92jpT7ulsNlZmbqtttuU2xsrOrVq6fBgwfrt99+c3nsnj17dPPNN6tt27YKCwtTkyZNNGLECG3fvt3RZvXq1TrvvPMkSTfffLNjSZR9WZ2794vNZtPzzz+v9u3bKzg4WHFxcbrhhht06NAhp3b29+umTZt04YUXKiwsTK1atdKMGTNks9nKfO2eyMnJ0aOPPqrExEQFBQWpSZMmuuuuu5Senu7UbuXKlerXr59iY2MVGhqq5s2b66qrrlJ2drajzaxZs9SlSxfVq1dPERERat++vR577LFSn//jjz/Wzp079cgjjzgFILtrr71Wl156qd5++22lpqbKarUqLi5OY8eOdWmbnp6u0NBQ3X///Y5jmZmZevDBB51e38SJE11+r00mkyZMmKA33nhDZ599toKDg/XOO+94MoSlsi/RXL58uW6++WbFxMQoPDxcI0aM0O+//+7Sfvbs2erSpYtCQkIUExOjK6+8Urt27XJpt2HDBo0YMUKxsbEKCQlR69atNXHiRJd2R44c0fXXX6+oqCg1atRIt9xyizIyMpzafPTRR+rZs6eioqIc7zH7v4sA/I8QBMArUlJSNGbMGI0aNUpLlizRnXfeKUnavXu3hg4dqrffflvLli3TxIkT9d///lcjRozw6Lxbt27VAw88oPvuu0+ffvqpOnfurHHjxunbb78t87FWq1WXXXaZLrnkEn366ae65ZZb9PLLL+u5555ztMnKytLFF1+sVatW6bnnntN///tfNWrUSNdee61H/UtLS5MkTZkyRYsXL9acOXPUqlUr9evXz+01Sq+//rqWL1+uV155Re+//76ysrI0dOhQpw9Qc+fO1c0336yzzz5bCxcu1BNPPKHp06e7LEF0x2w266abbtLmzZu1detWp/vswcj+QWzv3r3q1auXZs2apa+++kpPPvmkNmzYoD59+pT7ehHDMHTFFVfovffe0wMPPKCPP/5Y559/voYMGeLS9vDhw4qNjdWMGTO0bNkyvf766woICFDPnj3166+/Sipc4mjv7xNPPKF169Zp3bp1uvXWW0vsw/jx4zVp0iQNHDhQn332maZPn65ly5bpggsucAl2qampGj16tMaMGaPPPvtMQ4YM0aOPPqp58+aV63WXNhb//Oc/NXbsWC1evFj333+/3nnnHfXv398Rwvft26dhw4YpKChIs2fP1rJlyzRjxgyFh4crLy9PUuHyxTvvvFN9+/bVxx9/rE8++UT33XefS9gobvny5ZKkK664osQ2V1xxhfLz87V69WoFBgZqzJgxWrhwoTIzM53affDBB8rJydHNN98sqXCWt2/fvnrnnXd0zz33aOnSpZo0aZLmzp2ryy67TIZhOD3+k08+0axZs/Tkk0/qyy+/1IUXXljmGObn57t8uQuo48aNk9ls1vz58/XKK69o48aN6tevn1PYfPbZZzVu3Dh16NBBixYt0quvvqpt27apV69e2r17t6OdvW8HDhzQSy+9pKVLl+qJJ57QkSNHXJ73qquuUrt27bRw4UI98sgjmj9/vu677z7H/evWrdO1116rVq1aacGCBVq8eLGefPJJ5efnl/naAVQRAwDK4cYbbzTCw8OdjvXt29eQZHz99delPtZmsxlWq9X45ptvDEnG1q1bHfdNmTLFKP5PUosWLYyQkBBj//79jmOnT582YmJijL///e+OY6tWrTIkGatWrXLqpyTjv//9r9M5hw4dapx11lmO26+//rohyVi6dKlTu7///e+GJGPOnDmlvqbi8vPzDavValxyySXGlVde6TienJxsSDI6depk5OfnO45v3LjRkGR88MEHhmEYRkFBgdG4cWOjW7duhs1mc7Tbt2+fERgYaLRo0aLMPvz++++GyWQy7rnnHscxq9VqxMfHG71793b7GPvPZv/+/YYk49NPP3XcN2fOHEOSkZyc7Dh24403OvVl6dKlhiTj1VdfdTrv008/bUgypkyZUmJ/8/Pzjby8PKNt27bGfffd5zi+adOmEn8Gxd8vu3btMiQZd955p1O7DRs2GJKMxx57zHHM/n7dsGGDU9ukpCRj0KBBJfbTrkWLFsawYcNKvH/ZsmWGJOP55593Ov7hhx8akow333zTMAzD+N///mdIMrZs2VLiuSZMmGBER0eX2afiBg8ebEgycnJySmxj/5k999xzhmEYxrZt25z6Z9ejRw/j3HPPddx+9tlnDbPZbGzatMmpnf31LFmyxHFMkhEVFWWkpaV51G/7z8bd17hx4xzt7O/Jor9jhmEYa9euNSQZTz31lGEYhnHixAkjNDTUGDp0qFO7AwcOGMHBwcaoUaMcx1q3bm20bt3aOH36dIn9s7/viv9s77zzTiMkJMTxO/vPf/7TkGSkp6d79LoBVD1mggB4Rf369dW/f3+X47///rtGjRql+Ph4WSwWBQYGqm/fvpLkdjlKcV27dlXz5s0dt0NCQtSuXTvt37+/zMeaTCaXGafOnTs7Pfabb75RRESEy0X2119/fZnnt3vjjTfUrVs3hYSEKCAgQIGBgfr666/dvr5hw4bJYrE49UeSo0+//vqrDh8+rFGjRjkt92rRooUuuOACj/qTmJioiy++WO+//75jRmHp0qVKTU11Wo5z9OhR3XHHHWrWrJmj3y1atJDk2c+mqFWrVkmSRo8e7XR81KhRLm3z8/P1zDPPKCkpSUFBQQoICFBQUJB2795d7uct/vw33XST0/EePXro7LPP1tdff+10PD4+Xj169HA6Vvy9UVH2Gbvifbn66qsVHh7u6EvXrl0VFBSk22+/Xe+8847bZVw9evRQenq6rr/+en366aderUpm/DVjY3+fderUSeeee67TUspdu3Zp48aNTu+bL774Qh07dlTXrl2dZmoGDRrktkpj//793RbpKEnr1q21adMml6/Jkye7tC3+frvgggvUokULx/th3bp1On36tMvPolmzZurfv7/jZ/Hbb79p7969GjdunEJCQsrsY/Hqip07d1ZOTo6OHj0qSY6lnNdcc43++9//6o8//vDsxQOoMoQgAF6RkJDgcuzUqVO68MILtWHDBj311FNavXq1Nm3apEWLFkmSTp8+XeZ5Y2NjXY4FBwd79NiwsDCXDzTBwcHKyclx3D5+/LgaNWrk8lh3x9x56aWXNH78ePXs2VMLFy7U+vXrtWnTJg0ePNhtH4u/HnvFK3vb48ePSyr8kF6cu2MlGTdunI4fP67PPvtMUuFSuHr16umaa66RVHj9zKWXXqpFixbp4Ycf1tdff62NGzc6rk/yZHyLOn78uAICAlxen7s+33///Zo8ebKuuOIKff7559qwYYM2bdqkLl26lPt5iz6/5P592LhxY8f9dpV5X3nSl4CAADVs2NDpuMlkUnx8vKMvrVu31ooVKxQXF6e77rpLrVu3VuvWrfXqq686HjN27FjNnj1b+/fv11VXXaW4uDj17NnTsdytJPY/HCQnJ5fYxl7yvFmzZo5jt9xyi9atW6dffvlFUuH7Jjg42OmPAkeOHNG2bdsUGBjo9BURESHDMFyCmrufSWlCQkLUvXt3ly97QC+qpN8T+xh7+r74888/JcnjYhtl/R5fdNFF+uSTT5Sfn68bbrhBTZs2VceOHfXBBx94dH4Avkd1OABe4W7PlpUrV+rw4cNavXq1Y/ZHksvF4f4UGxurjRs3uhxPTU316PHz5s1Tv379NGvWLKfjJ0+erHB/Snp+T/skSSNHjlT9+vU1e/Zs9e3bV1988YVuuOEG1atXT5K0Y8cObd26VXPnztWNN97oeNyePXsq3O/8/HwdP37c6QOiuz7PmzdPN9xwg5555hmn48eOHVN0dHSFn18qvDat+AfZw4cPq0GDBhU6b0X7kp+frz///NMpCBmGodTUVMcsgSRdeOGFuvDCC1VQUKAffvhBr732miZOnKhGjRo59nu6+eabdfPNNysrK0vffvutpkyZouHDh+u3335zGwwkaeDAgXrzzTf1ySef6JFHHnHb5pNPPlFAQID69evnOHb99dfr/vvv19y5c/X000/rvffe0xVXXOE0k9OgQQOFhoa6FCgpen9RvtzPqaTfkzZt2khyfl8UV/R9Yf85FS+iURmXX365Lr/8cuXm5mr9+vV69tlnNWrUKLVs2VK9evXy2vMAqBhmggD4jP3DT/H9Pf7973/7oztu9e3bVydPntTSpUudji9YsMCjx5tMJpfXt23bNpf9lTx11llnKSEhQR988IHTBeb79+/X999/7/F5QkJCNGrUKH311Vd67rnnZLVanZY0eftnc/HFF0uSy/4u8+fPd2nrbswWL17ssmSo+F/XS2Nfilm8sMGmTZu0a9cuXXLJJWWew1vsz1W8LwsXLlRWVpbbvlgsFvXs2VOvv/66JGnz5s0ubcLDwzVkyBA9/vjjysvL088//1xiH6688kolJSVpxowZbiv0ffjhh/rqq6906623Os2m1K9fX1dccYXeffddffHFFy5LKCVp+PDh2rt3r2JjY93O2FTlpqbF32/ff/+99u/f7wh2vXr1UmhoqMvP4tChQ1q5cqXjZ9GuXTu1bt1as2fPdqkeWVnBwcHq27evoyDLTz/95NXzA6gYZoIA+MwFF1yg+vXr64477tCUKVMUGBio999/36VqmT/deOONevnllzVmzBg99dRTatOmjZYuXaovv/xSUmG1tdIMHz5c06dP15QpU9S3b1/9+uuv+sc//qHExMQKVYIym82aPn26br31Vl155ZW67bbblJ6erqlTp5ZrOZxUuCTu9ddf10svvaT27ds7XVPUvn17tW7dWo888ogMw1BMTIw+//zzMpdZleTSSy/VRRddpIcfflhZWVnq3r271q5dq/fee8+l7fDhwzV37ly1b99enTt31o8//qgXXnjBZQandevWCg0N1fvvv6+zzz5b9erVU+PGjdW4cWOXc5511lm6/fbb9dprr8lsNmvIkCHat2+fJk+erGbNmjlV7vKG1NRU/e9//3M53rJlSw0cOFCDBg3SpEmTlJmZqd69e2vbtm2aMmWKzjnnHEcZ6jfeeEMrV67UsGHD1Lx5c+Xk5DhmVwYMGCBJuu222xQaGqrevXsrISFBqampevbZZxUVFeU0o1ScxWLRwoULNXDgQPXq1UsPPPCAevXqpdzcXH3++ed688031bdvX7344osuj73lllv04YcfasKECWratKmjL3YTJ07UwoULddFFF+m+++5T586dZbPZdODAAX311Vd64IEH1LNnzwqP7enTp92WjZdc9y374YcfdOutt+rqq6/WwYMH9fjjj6tJkyaO6pTR0dGaPHmyHnvsMd1www26/vrrdfz4cU2bNk0hISGaMmWK41yvv/66RowYofPPP1/33XefmjdvrgMHDujLL790u3lraZ588kkdOnRIl1xyiZo2bar09HS9+uqrTtdEAvAzv5ZlAFDjlFQdrkOHDm7bf//990avXr2MsLAwo2HDhsatt95qbN682aXqV0nV4dxV4erbt6/Rt29fx+2SqsMV72dJz3PgwAFj5MiRRr169YyIiAjjqquuMpYsWeJSJc2d3Nxc48EHHzSaNGlihISEGN26dTM++eQTl+pp9upwL7zwgss55KZ62n/+8x+jbdu2RlBQkNGuXTtj9uzZLuf0xDnnnOO2mpVhGMbOnTuNgQMHGhEREUb9+vWNq6++2jhw4IBLfzypDmcYhpGenm7ccsstRnR0tBEWFmYMHDjQ+OWXX1zOd+LECWPcuHFGXFycERYWZvTp08dYs2aNy8/VMAzjgw8+MNq3b28EBgY6ncfdz7GgoMB47rnnjHbt2hmBgYFGgwYNjDFjxhgHDx50alfS+9XT8W3RokWJFcxuvPFGwzAKqxhOmjTJaNGihREYGGgkJCQY48ePN06cOOE4z7p164wrr7zSaNGihREcHGzExsYaffv2NT777DNHm3feece4+OKLjUaNGhlBQUFG48aNjWuuucbYtm1bmf00DMM4duyY8cgjjxjt27c3QkJCjHr16hk9evQwZs6caeTl5bl9TEFBgdGsWTNDkvH444+7bXPq1CnjiSeeMM466ywjKCjIiIqKMjp16mTcd999RmpqqqOdJOOuu+7yqK+GUXp1OEmG1Wo1DOPMe/Krr74yxo4da0RHRzuqwO3evdvlvP/5z3+Mzp07O/p6+eWXGz///LNLu3Xr1hlDhgwxoqKijODgYKN169ZOFQvt77s///zT6XHFf0e++OILY8iQIUaTJk2MoKAgIy4uzhg6dKixZs0aj8cCgG+ZDKNYQX8AgJ555hk98cQTOnDggMcXSwOoGva9tDZt2qTu3bv7uzsAaiCWwwGo82bOnCmpcImY1WrVypUr9X//938aM2YMAQgAgFqIEASgzgsLC9PLL7+sffv2KTc3V82bN9ekSZP0xBNP+LtrAADAB1gOBwAAAKBOoUQ2AAAAgDqFEAQAAACgTiEEAQAAAKhTanRhBJvNpsOHDysiIsKx+zkAAACAuscwDJ08eVKNGzcuc7PzGh2CDh8+rGbNmvm7GwAAAACqiYMHD5a5xUWNDkERERGSCl9oZGSkX/titVr11Vdf6dJLL1VgYKBf+1IbMb6+xxj7FuPre4yxbzG+vscY+xbj63v+HuPMzEw1a9bMkRFKU6NDkH0JXGRkZLUIQWFhYYqMjOQXywcYX99jjH2L8fU9xti3GF/fY4x9i/H1veoyxp5cJkNhBAAAAAB1CiEIAAAAQJ1CCAIAAABQp9Toa4IAAABQ/RQUFMhqtfq7G06sVqsCAgKUk5OjgoICf3enVvL1GFssFgUEBHhlaxxCEAAAALzm1KlTOnTokAzD8HdXnBiGofj4eB08eJD9JX2kKsY4LCxMCQkJCgoKqtR5CEEAAADwioKCAh06dEhhYWFq2LBhtQobNptNp06dUr169crcSBMV48sxNgxDeXl5+vPPP5WcnKy2bdtW6jkIQQAAAPAKq9UqwzDUsGFDhYaG+rs7Tmw2m/Ly8hQSEkII8hFfj3FoaKgCAwO1f/9+x/NUFO8AAAAAeFV1mgFC7eKtcEUIAgAAAFCnEIIAAAAA1CmEIAAAAFQrBTZD6/Ye16db/tC6vcdVYKteleY80a9fP02cONHj9vv27ZPJZNKWLVt81iecQWEEAAAAVBvLdqRo2uc7lZKR4ziWEBWiKSOSNLhjgtefr6zrl2688UbNnTu33OddtGiRAgMDPW7frFkzpaSkqEGDBuV+rvLYt2+fEhMT9dNPP6lr164+fa7qjBAEAACAamHZjhSNn7dZxed9UjNyNH7eZs0a083rQSglJcXx/Ycffqgnn3xSv/76q+NY8Sp3VqvVo3ATExNTrn5YLBbFx8eX6zGoOJbDeUGBzdCG5DT9eMykDclpNXLKFgAAwNsMw1B2Xr5HXydzrJry2c8uAUiS49jUz3bqZI7Vo/N5ullrfHy84ysqKkomk8lxOycnR9HR0frvf/+rfv36KSQkRPPmzdPx48d1/fXXq2nTpgoLC1OnTp30wQcfOJ23+HK4li1b6plnntEtt9yiiIgINW/eXG+++abj/uLL4VavXi2TyaSvv/5a3bt3V1hYmC644AKngCZJTz31lOLi4hQREaFbb71VjzzySKVmeHJzc3XPPfcoLi5OISEh6tOnjzZt2uS4/8SJExo9erSjDHrbtm01Z84cSVJeXp4eeughNWnSRCEhIWrZsqWeffbZCvfFl5gJqiTnKVuL3t39g0+nbAEAAGqK09YCJT35pVfOZUhKzcxRp6lfedR+5z8GKSzIOx91J02apBdffFFz5sxRcHCwcnJydO6552rSpEmKjIzU4sWLNXbsWLVq1Uo9e/Ys8Twvvviipk+frscee0z/+9//NH78eF100UVq3759iY95/PHH9eKLL6phw4a64447dMstt2jt2rWSpPfff19PP/20/vWvf6l3795asGCBXnzxRSUmJlb4tT788MNauHCh3nnnHbVo0ULPP/+8Bg0apD179igmJkaTJ0/Wzp07tXTpUjVo0EB79uzR6dOnJUmvvfaali5dqgULFqhly5Y6ePCgDh48WOG++BIhqBL8MWULAACAqjVx4kSNHDnS6diDDz7o+P7uu+/WsmXL9NFHH5UagoYOHao777xTUmGwevnll7V69epSQ9DTTz+tvn37SpIeeeQRDRs2TDk5OQoJCdFrr72mcePG6eabb5YkPfnkk/rqq6906tSpCr3OrKwszZo1S3PnztWQIUMkSW+99ZaWL1+ut99+Ww899JAOHDigc845R927d5dUOMNld+DAAbVu3Vp9+vSRxWJRixYtKtSPqkAIqqACm6Fpn+8sccrWJGna5zs1MCleFjMbhgEAgLonNNCinf8Y5FHbjclpumnOpjLbzb35PPVILPt6m9BAi0fP6wn7B367goICzZgxQx9++KH++OMP5ebmKjc3V+Hh4aWep3Pnzo7v7cvujh496vFjEhIK/7h+9OhRNW/eXL/++qsjVNn16NFDK1eu9Oh1Fbd3715ZrVb17t3bcSwwMFA9evTQrl27JEnjx4/XVVddpc2bN+vSSy/VFVdcoQsuuEBSYRGJSy+9VGeffbYGDx6s4cOH69JLL61QX3yNa4IqaGNymlPVkuIMSSkZOdqYnFZ1nQIAAKhGTCaTwoICPPq6sG1DJUSFqKQ/HZtUWCXuwrYNPTpfWVXfyqN4uHnxxRf18ssv6+GHH9bKlSu1ZcsWDRo0SHl5eaWep3hBBZPJJJvN5vFj7K+p6GOKv05Pr4Vyx/5Yd+e0HxsyZIj279+viRMn6vDhw7rkkkscs2LdunXTli1bNG3aNJ0+fVrXXHON/va3v1W4P75ECKqgoydLDkAVaQcAAFCXWcwmTRmRJEkuQch+e8qIpGqxwmbNmjW6/PLLNWbMGHXp0kWtWrXS7t27q7wfZ511ljZu3Oh07Icffqjw+dq0aaOgoCB99913jmNWq1U//PCDzj77bMexhg0b6qabbtK8efP0yiuvOBV4iIyM1LXXXqu33npLH374oRYuXKi0tOo3KcByuAqKiwjxajsAAIC6bnDHBM0a081ln6D4alZ0qk2bNlq4cKG+//571a9fXy+99JJSU1OdgkJVuPvuu3Xbbbepe/fuuuCCC/Thhx9q27ZtatWqVZmPLV5lTpKSkpI0fvx4PfTQQ4qJiVHz5s31/PPPKzs7W+PGjZNUeN3Rueeeqw4dOig3N1dffPGF43W/8sorioqKUq9evRQQEKCPPvpI8fHxio6O9urr9gZCUAX1SIxRQlSIUjNy3F4XZFLhL6wna1YBAABQaHDHBA1MitfG5DQdPZmjuIjCz1PVYQbIbvLkyUpOTtagQYMUFham22+/XVdccYUyMjKqtB+jR4/W77//rgcffFA5OTm65pprdNNNN7nMDrlz3XXXuRxLTk7WjBkzZLPZNHbsWJ08eVLdu3fXl19+qfr160uSgoKC9Oijj2rfvn0KDQ3VhRdeqAULFkgqXDb46quv6t5775XFYtF5552nJUuWyGyufovPTEZlFg76WWZmpqKiopSRkaHIyMgqf357dThJTkHI/itKdTjvsVqtWrJkiYYOHVqu3ZfhOcbYtxhf32OMfYvx9b3aMMY5OTlKTk5WYmKiQkKq12oYm82mzMxMRUZGVssP5d4ycOBAxcfH67333qvy566KMS7tPVaebMBMUCXUlClbAAAA1D7Z2dl64403NGjQIFksFn3wwQdasWKFli9f7u+uVXuEoEqyT9k+8OFP+mRrigac3VD/HntetZqyBQAAQO1jMpm0ZMkSPfXUU8rNzdVZZ52lhQsXasCAAf7uWrVHCPICi9mkxAaFpRNjwoIIQAAAAPC50NBQrVixwt/dqJFq74LIKhYUUDiUefml13oHAAAA4F+EIC9xhKACQhAAAABQnRGCvCTIwkwQAAAAUBMQgrwk0FJ4HRAzQQAAAED1RgjykoC/QtDh9Byt23tcBbYau/0SAAAAUKsRgrxg2Y4UPbX4V0nSnj+zdP1b69XnuZVatiPFzz0DAAAAUBwhqJKW7UjR+HmblX7a6nQ8NSNH4+dtJggBAADUAf369dPEiRMdt1u2bKlXXnml1MeYTCZ98sknlX5ub52nLiEEVUKBzdC0z3fK3cI3+7Fpn+9kaRwAAIAnVj0rffO8+/u+eb7wfi8bMWJEiZuLrlu3TiaTSZs3by73eTdt2qTbb7+9st1zMnXqVHXt2tXleEpKioYMGeLV5ypu7ty5io6O9ulzVCVCUCVsTE5TSkZOifcbklIycrQxOa3qOgUAAFBTmS3Sqqddg9A3zxceN1u8/pTjxo3TypUrtX//fpf7Zs+era5du6pbt27lPm/Dhg0VFhbmjS6WKT4+XsHBwVXyXLUFIagSjp4sOQBVpB0AAECtYhhSXpbnX73uki56qDDwrHyq8NjKpwpvX/RQ4f2ensvwbCXO8OHDFRcXp7lz5zodz87O1ocffqhx48bp+PHjuv7669W0aVOFhYWpU6dO+uCDD0o9b/HlcLt379ZFF12kkJAQJSUlafny5S6PmTRpktq1a6ewsDC1atVKkydPltVaeMnF3LlzNW3aNG3dulUmk0kmk8nR5+LL4bZv367+/fsrNDRUsbGxuv3223Xq1CnH/TfddJOuuOIK/fOf/1RCQoJiY2N11113OZ6rIg4cOKArrrhCTZs2VXR0tK655hodOXLEcf/WrVt18cUXKyIiQpGRkTr33HP1ww8/SJL279+vESNGqH79+goPD1eHDh20ZMmSCvfFEwE+PXstFxcR4tV2AAAAtYo1W3qmccUe++0LhV8l3S7LY4eloPAymwUEBOiGG27Q3Llz9eSTT8pkKqz4+9FHHykvL0+jR49Wdna2zj33XE2aNEmRkZFavHixxo4dq1atWqlnz55lPofNZtPIkSPVoEEDrV+/XpmZmU7XD9lFRERo7ty5aty4sbZv367bbrtNERERevjhh3Xttddqx44dWrZsmVasWCFJioqKcjlHdna2Bg8erPPPP1+bNm3S0aNHdeutt2rChAlOQW/VqlVKSEjQqlWrtGfPHl177bXq2rWrbrvttjJfT3GGYeiKK65QeHi4vvjiCwUHB2vChAm69tprtXr1aknS6NGjdc4552jWrFmyWCzasmWLAgMDJUl33XWX8vLy9O233yo8PFw7d+5UvXr1yt2P8iAEVUKPxBglRIUoNSPH7XVBJknxUSHqkRhT1V0DAACAh2655Ra98MILWr16tS6++GJJhUvhRo4cqfr166t+/fp68MEHHe3vvvtuLVu2TB999JFHIWjFihXatWuX9u3bp6ZNm0qSnnnmGZfreJ544gnH9y1bttQDDzygDz/8UA8//LBCQ0NVr149BQQEKD4+vsTnev/993X69Gm9++67Cg8vDIEzZ87UiBEj9Nxzz6lRo0aSpPr162vmzJmyWCxq3769hg0bpq+//rpCIWjFihXatm2b9u7dq6ioKEVGRuq9995Thw4dtGnTJp133nk6cOCAHnroIbVv316S1LZtW8fjDxw4oKuuukqdOnWSJLVq1arcfSgvQlAlWMwmTRmRpPHzXC+WM/313ykjkmQxm1zuBwAAqPUCwwpnZMrru5cLZ30sQVJBXuFSuD73lf+5PdS+fXtdcMEFmj17ti6++GLt3btXa9as0VdffSVJKigo0IwZM/Thhx/qjz/+UG5urnJzcx0hoyy7du1S8+bNHQFIknr16uXS7n//+59eeeUV7dmzR6dOnVJ+fr4iIyM9fh325+rSpYtT33r37i2bzaZff/3VEYI6dOggi+XMNVYJCQnavn17uZ6r6HM2a9ZMzZo1U2ZmpiQpKSlJ0dHR2rVrl8477zzdf//9uvXWW/Xee+9pwIABuvrqq9W6dWtJ0j333KPx48frq6++0oABA3TVVVepc+fOFeqLp/x6TVB+fr6eeOIJJSYmKjQ0VK1atdI//vEP2Ww2f3arXAZ3TNCsMd3UKML5YrT4qBDNGtNNgzsm+KlnAAAAfmYyFS5JK8/XutcLA9DFj0uT/yz877cvFB4vz3lM5fsj9Lhx47Rw4UJlZmZqzpw5atGihS655BJJ0osvvqiXX35ZDz/8sFauXKktW7Zo0KBBysvL8+jchpvrk0zF+rd+/Xpdd911GjJkiL744gv99NNPevzxxz1+jqLPVfzc7p7TvhSt6H0V/Qxe0nMWPT516lT9/PPPGjZsmFauXKmkpCR9/PHHkqRbb71Vv//+u8aOHavt27ere/fueu211yrUF0/5NQQ999xzeuONNzRz5kzt2rVLzz//vF544QWfv2hvG9wxQV/f18dx+62x5+q7Sf0JQAAAAOVhrwJ38eNS34cLj/V9uPC2u6pxXnTNNdfIYrFo/vz5euedd3TzzTc7PsCvWbNGl19+ucaMGaMuXbqoVatW2r17t8fnTkpK0oEDB3T48JlZsXXr1jm1Wbt2rVq0aKHHH39c3bt3V9u2bV0q1gUFBamgoKDM59qyZYuysrKczm02m9WuXTuP+1we9td38OBBx7GdO3cqIyNDZ599tuNYu3btdN999+mrr77SyJEjNWfOHMd9zZo10x133KFFixbpgQce0FtvveWTvtr5dTncunXrdPnll2vYsGGSCtc+fvDBB45KETVJgMUsswzZZFJufs2ZyQIAAKg2bAXOAcjOfttWegCojHr16unaa6/VY489poyMDN10002O+9q0aaOFCxfq+++/V/369fXSSy8pNTXV6QN+aQYMGKCzzjpLN9xwg1588UVlZmbq8ccfd2rTpk0bHThwQAsWLNB5552nxYsXO2ZK7Fq2bKnk5GRt2bJFTZs2VUREhEtp7NGjR2vKlCm68cYbNXXqVP3555+6++67NXbsWMdSuIoqKCjQli1bnI4FBQVpwIAB6ty5s8aOHavp06c7CiP07dtX3bt31+nTp/XQQw/pb3/7mxITE3Xo0CFt2rRJV111lSRp4sSJGjJkiNq1a6cTJ05o5cqVHo9tRfk1BPXp00dvvPGGfvvtN7Vr105bt27Vd999V+Luuvb1l3b2NYdWq7VSJf0q68ufj2j6kl9k++tKoAkf/KT4xTv1xND2GtShcm82FLL/fP35c67tGGPfYnx9jzH2LcbX92rDGFutVhmGIZvNVrGlVX0nFf7X3WMvfLDk+zxgX5Jm7587N998s95++20NHDhQTZs2dbR7/PHH9fvvv2vQoEEKCwvTbbfdpssvv1wZGRlO5yp+7qK3Fy5cqNtuu009evRwlM8eOnSoY6xGjBihiRMnasKECcrNzdXQoUP1xBNPaNq0aY5zXHnllVq4cKEuvvhipaen6+2333aENft5QkJCtHTpUt13330677zzFBYWppEjR+rFF190nMcwDLd9tZ/HHZvNplOnTumcc85xOt6iRQv9/vvvWrRoke655x4NGzZMZrNZgwYN0v/93//JZrPJZDLp2LFjuuGGG3TkyBE1aNBAV155paZMmSKbzab8/HzdddddOnTokCIjIzVo0CC99NJLbvtis9lkGIasVqvTNU1S+X53TIa7RYpVxDAMPfbYY3ruuedksVhUUFCgp59+Wo8++qjb9lOnTtW0adNcjs+fP7/KNqMqbutxk2b/Zl9VWHQtZOGw3tLOpi6xfhtiAACAKmOvXNasWTMFBQX5uzuohfLy8nTw4EGlpqYqPz/f6b7s7GyNGjVKGRkZZRaU8GsIWrBggR566CG98MIL6tChg7Zs2aKJEyfqpZde0o033ujS3t1MULNmzXTs2LFyV87whgKboX4vfqvUzNwS20SHBWj9pIupEFdJVqtVy5cv18CBA10u5IN3MMa+xfj6HmPsW4yv79WGMc7JydHBgwfVsmVLhYRUr30SDcPQyZMnFRERUWLhAFROVYxxTk6O9u3bp2bNmrm8xzIzM9WgQQOPQpBfl8M99NBDeuSRR3TddddJkjp16qT9+/fr2WefdRuCgoODXdY9SoXVLfzxj8UPe4+XGoAkKT07X/9es1/3Dmhbajt4xl8/67qEMfYtxtf3GGPfYnx9ryaPcUFBgUwmk8xms8xmv9bfcmFfWmXvH7yvKsbYbDbLZDK5/T0pz++NX98B2dnZLgNksVhqTInsoydzPGo35/tkFdhYEgcAAABUB36dCRoxYoSefvppNW/eXB06dNBPP/2kl156Sbfccos/u+WxuAjPpnnTs63amJymXq1jfdwjAAAAAGXxawh67bXXNHnyZN155506evSoGjdurL///e968skn/dktj/VIjFF0aKDST5ddicLTWSMAAICazo+XnKOW89Z7y68hKCIiQq+88kqJJbGrO4vZpBsvaKFXv95TZtsG4a7XMgEAANQm9pLFeXl5Cg0N9XNvUBtlZ2dLKt/1P+74NQTVBj0SYyWVHYJEERIAAFDLBQQEKCwsTH/++acCAwOrVQECm82mvLw85eTkVKt+1Sa+HGPDMJSdna2jR48qOjraZY+g8iIEVdKxU6VXhytvOwAAgJrKZDIpISFBycnJ2r9/v7+748QwDJ0+fVqhoaGUyPaRqhjj6OhoxcfHV/o8hKBK8rQ4gqftAAAAarKgoCC1bdtWeXl5/u6KE6vVqm+//VYXXXRRjS1BXt35eowDAwMrPQNkRwiqpB6JMUqIClFqRo5KukwrOixQPRJjqrRfAAAA/mI2m6vdZqkWi0X5+fkKCQkhBPlITRpjFkRWksVs0pQRSX8FIPcxKD3bquU7U6uyWwAAAABKQAjygoFJ8YoOLTntmiRN+3wnG6YCAAAA1QAhyAs2Jqf9tVeQ+wvADEkpGTnamJxWpf0CAAAA4IoQ5AWeboTKhqkAAACA/xGCvMDTjVDZMBUAAADwP0KQN3haBp2S9AAAAIDfEYK8gA1TAQAAgJqDEOQFnm6Euu9Yto97AgAAAKAshCAv6JEYo0YRQSppnyC7BZsOUCYbAAAA8DNCkBdYzCZd272ZyrrohzLZAAAAgP8RgrwkM8fqUTvKZAMAAAD+RQjyggKboU+3pnjU1tPrhwAAAAD4BiHICzYmp+lEdtkzQbHhQeqRGFMFPQIAAABQEkKQF3i6xO3yro1lMbNZEAAAAOBPhCAv8HSJ28CkeB/3BAAAAEBZCEFe0CMxRvGRwSqtRHZCVAhL4QAAAIBqgBDkBRazSU8MbS/JfZFsk6QpI5JYCgcAAABUA4QgLxnUoZFuaWdTo8hgp+NxEcGaNaabBndM8FPPAAAAABRFCPKiLrGGVj9wkT647XyFBBQO7fzbzicAAQAAANUIIcjLLGaTerWOVWiQRZJkGCVfJwQAAACg6hGCfCTQUji0eQU2P/cEAAAAQFGEIB+xhyBrATNBAAAAQHVCCPKRQEthJbh8ZoIAAACAaoUQ5CMshwMAAACqJ0KQjwT8FYLyWQ4HAAAAVCuEIB8osBnKsxZIkrb/ka4CG0EIAAAAqC4IQV725c9H1Oe5ldp7LEuS9MKXv6nPcyu1bEeKn3sGAAAAQCIEedXW4ybdvWCrUjJynI6nZuRo/LzNBCEAAACgGiAEeUmBzdCifWa5W/hmPzbt850sjQMAAAD8jBDkJT/sP6H0PFOJ9xuSUjJytDE5reo6BQAAAMAFIchLjp7M9bBdTtmNAAAAAPgMIchL4iKCPWwX4uOeAAAAACgNIchLureor+ggQyUtiDNJSogKUY/EmKrsFgAAAIBiCEFeYjGbNLKlTZLcBiFD0pQRSbKYS75uCAAAAIDvEYK8qEusodeu66KosECX+6LdHAMAAABQ9QhBPpCRbXV7jL2CAAAAAP8jBHmRzZCeWvILewUBAAAA1RghyIv2ZpqUmllyqWz2CgIAAAD8jxDkRZmuq+DcYq8gAAAAwH8IQV4U6WHtA/YKAgAAAPyHEORFrSMNxUcGl7hXkCSZTNKJrLwq6xMAAAAAZ4QgLzKbpCeGtndbGMHOMKQ751MlDgAAAPAXQpCXDTg7TlGhAWW2o0ocAAAA4B+EIC/7Yf8JZZzOL7MdVeIAAAAA/yAEedmKXUc9bkuVOAAAAKDqlb1uCx6zGdKn2zy/1ocqcQAAAEDVYybIi/ZmmnQi27PNghKiQtQjMcbHPQIAAABQHCHIizzdLFWSpoxIksVcWjFtAAAAAL5ACPIiTzdLvW9AOw3umODbzgAAAABwixDkRZ5slhoVGqAJ/dtUWZ8AAAAAOCMEeZEnm6VmnM7X8p2pVdYnAAAAAM4IQV424Ow4RYeVvi6OjVIBAAAA/yEEedkP+08ovYwKcWyUCgAAAPgPIcjLjp7M9agdS+IAAAAA/yAEeVlcRLBH7T7dcpglcQAAAIAfEIK8rHuL+ooJL7tW9vGsPJbEAQAAAH5ACPIyi9mkK7s28ajt0ZM5Pu4NAAAAgOIIQT4wICneo3b7jmX7uCcAAAAAiiME+UCPxBjFR5Z9bdCCTQe4LggAAACoYn4NQS1btpTJZHL5uuuuu/zZrUqzmE26vkfzMttRKhsAAACoegH+fPJNmzapoKDAcXvHjh0aOHCgrr76aj/2yjsyT5e+V5Ad1wUBAAAAVcuvIahhw4ZOt2fMmKHWrVurb9++fuqRdxTYDH285Q+P2sZFhPi4NwAAAACK8msIKiovL0/z5s3T/fffL5PJ5LZNbm6ucnPPbEaamZkpSbJarbJaPZt58RX781utVm1OTlNaVtn9iQkP1DlNI/ze95qg6PjCNxhj32J8fY8x9i3G1/cYY99ifH3P32Ncnuc1GYZRLa7M/+9//6tRo0bpwIEDaty4sds2U6dO1bRp01yOz58/X2FhYb7uosd+PGbSu7stZbbrm1CgkS2rxfADAAAANVp2drZGjRqljIwMRUZGltq22oSgQYMGKSgoSJ9//nmJbdzNBDVr1kzHjh0r84X6mtVq1fLlyzVw4EBtPnRSY2b/UOZj5t3SXT0TY6qgdzVf0fENDCx7M1qUH2PsW4yv7zHGvsX4+h5j7FuMr+/5e4wzMzPVoEEDj0JQtVgOt3//fq1YsUKLFi0qtV1wcLCCg11LTwcGBlabN3NgYKB6tYlTQlSIUjNyVFLCjA4rbGcxu1/6B/eq08+6tmKMfYvx9T3G2LcYX99jjH2L8fU9f41xeZ6zWuwTNGfOHMXFxWnYsGH+7opXWMwmTRmRVGIAkqT0bKuW70ytsj4BAAAAKOT3EGSz2TRnzhzdeOONCgioFhNTXjEwKV7RYSWnUZOkaZ/vZLNUAAAAoIr5PQStWLFCBw4c0C233OLvrnjVxuQ0pWeXXKHCEJulAgAAAP7g96mXSy+9VNWkNoNXeboJKpulAgAAAFXL7zNBtZWnm6CyWSoAAABQtQhBPtIjMUYJUSEqqfabSVJCVIh6UCIbAAAAqFKEIB+xV4iT5BKE7LenjEiiRDYAAABQxQhBPjS4Y4Jmjemm+CjnJW/xUSGaNaabBndM8FPPAAAAgLqLEORjgzsm6LtJ/dW/fZwk6epzm+q7Sf0JQAAAAICfEIKqgMVsUtP6oZIKrwNiCRwAAADgP4SgKhJgLhxqK5ujAgAAAH5FCKoiAZbC2Z/8ApufewIAAADUbYSgKhLw1xK4fGaCAAAAAL8iBFWRAEvhUOcXEIIAAAAAfyIEVZFAx0wQy+EAAAAAfyIEVRH7TJCVmSAAAADArwhBVcR+TVAB1wQBAAAAfkUIqiL26nBWqsMBAAAAfhXg7w7UFY7lcPk2rdt7XEdP5iguIkQ9EmPYPBUAAACoQoSgKmIvjLD6tz/15c4jjuMJUSGaMiJJgzsm+KtrAAAAQJ3CcrgqsislU5KUm++8HC41I0fj523Wsh0p/ugWAAAAUOcQgqpAgc3QJ1sOu73P+Otr2uc7KZoAAAAAVAFCUBWYuXK3Mk5bS22TkpGjjclpVdQjAAAAoO4iBPnYsh0pennFbo/apmbm+Lg3AAAAAAhBPlRgMzT1s589bp92KteHvQEAAAAgEYJ8amNymlIzPQ82MeFBPuwNAAAAAIkQ5FNHT5ZveVt8VKiPegIAAADAjhDkQ3ERIR63rRccoB6JMT7sDQAAAACJEORTPRJjFB8Z7FHbQIvJx70BAAAAIBGCfMpiNmnqZR08ansi20qJbAAAAKAKEIJ8bHDHBI3r3dKjtuW9hggAAABA+RGCqsCApHiP2pXnGiIAAAAAFUMIqgInsjwrk30iK8/HPQEAAABACPKxApuh6Yt3edR2+uKdKrAZPu4RAAAAULcRgnxsY3KaUjI8u9YnJSOH4ggAAACAjxGCfGzFztRytac4AgAAAOBbhCAfKrAZ+njLH+V6DMURAAAAAN8K8HcHarONyWlKy7J61NYkKT4qRD0SY3zbKQAAAKCOYybIh8q7tG3KiCRZzCYf9QYAAACAxEyQT3m6tM1skm67MFGDOyb4uEcAAAAAmAnyoR6JMUqIClFZczuGIb35bbKW7Uipkn4BAAAAdRkhyIcsZpOmjEgqs519Z6Bpn7NPEAAAAOBrhCAfG9wxQbPGdFNMeGCp7QyxTxAAAABQFQhBVWBwxwRNHt7Bo7bsEwQAAAD4FiGoisRHelYkgX2CAAAAAN8iBFURT4okRIcFsk8QAAAA4GOEoCpiL5JQWtmD9Gyrlu9MrbI+AQAAAHURIagKDUyKV3RY6QUSHlm0nQpxAAAAgA8RgqrQxuQ0pWdbS22Tnm3VzJV7qqhHAAAAQN1DCKpCqZmeVX6bszaZ2SAAAADARwhBVSjtVK5H7dJPW9kvCAAAAPARQlAVigkP8rgt+wUBAAAAvkEIqkLxUaEet12+84gPewIAAADUXYSgKtQjMUbxkcEetV2yPUV5+TYf9wgAAACoewhBVchiNunJ4UketbUZ0nvr9vm2QwAAAEAdRAiqYvXDPZsJkqT9adk+7AkAAABQNxGCqlh5Ch60iAnzYU8AAACAuokQVMXiIkI8amc2SWN7tfRtZwAAAIA6iBBUxXokxighquwgNK5PooIC+PEAAAAA3san7CpmMZs0ZUSSTKW0GZgUp8eHeVZAAQAAAED5EIL8YHDHBM0a081lRsgkaeZ1XfXWDef5p2MAAABAHUAI8pPBHRP03aT+mjT4LMexdo3qaXjXJn7sFQAAAFD7EYL8yGI2qWuz+o7bgVwDBAAAAPgcn7r9LNBy5uqg03kFKrAZfuwNAAAAUPsRgvxo2Y4U3THvR8ftvX9mqc9zK7VsR4ofewUAAADUboQgP1m2I0Xj523WsVN5TsdTM3I0ft5mghAAAADgI4QgPyiwGZr2+U65W/hm/PU17fOdLI0DAAAAfMDvIeiPP/7QmDFjFBsbq7CwMHXt2lU//vhj2Q+swTYmpyklI6fUNikZOdqYnFZFPQIAAADqjgB/PvmJEyfUu3dvXXzxxVq6dKni4uK0d+9eRUdH+7NbPnf0ZOkByG75zlT1ah3r494AAAAAdYtfQ9Bzzz2nZs2aac6cOY5jLVu29F+HqkhcREjZjSR9uuWwHh+WJIvZVHZjAAAAAB7xawj67LPPNGjQIF199dX65ptv1KRJE91555267bbb3LbPzc1Vbm6u43ZmZqYkyWq1ymq1VkmfS2J/fk/6cU7TCNUPC9SJ7NLbHs/K07o9R9UzMcYrfazJyjO+qBjG2LcYX99jjH2L8fU9xti3GF/f8/cYl+d5TYZh+O3q+5CQwhmR+++/X1dffbU2btyoiRMn6t///rduuOEGl/ZTp07VtGnTXI7Pnz9fYWFhPu+vNy1KNuub1LIvybqhbYHObUCBBAAAAKA02dnZGjVqlDIyMhQZGVlqW7+GoKCgIHXv3l3ff/+949g999yjTZs2ad26dS7t3c0ENWvWTMeOHSvzhfqa1WrV8uXLNXDgQAUGBpbZfkNymsbM/qHMdvNu6c5MkMo/vig/xti3GF/fY4x9i/H1PcbYtxhf3/P3GGdmZqpBgwYehSC/LodLSEhQUlKS07Gzzz5bCxcudNs+ODhYwcHBLscDAwOrzZvZ0770ahOnhKiQUqvEmU1SZo6t2ry26qA6/axrK8bYtxhf32OMfYvx9T3G2LcYX9/z1xiX5zn9WiK7d+/e+vXXX52O/fbbb2rRooWfelR1LGaTLuuSUGobmyHdNZ+NUwEAAABv8msIuu+++7R+/Xo988wz2rNnj+bPn68333xTd911lz+7VSUKbIY+21p2uGHjVAAAAMC7/BqCzjvvPH388cf64IMP1LFjR02fPl2vvPKKRo8e7c9uVQlPNky1Y+NUAAAAwHv8ek2QJA0fPlzDhw/3dzeqnKcbpla0PQAAAAD3/DoTVJd5umGq3b5j2T7qCQAAAFC3EIL8pEdijCJCLB63X7DpANcFAQAAAF5ACPITi9mkZ6/o5HF7rgsCAAAAvIMQ5EfDuzbRgLMbetye64IAAACAyiME+dm4Pq09blve64gAAAAAuCIE+ZmnszvRYYHqkRjj494AAAAAtR8hyM88nd25+YJEWcwmH/cGAAAAqP0IQX7WIzFGCVEhKi3eRIcFakL/NlXWJwAAAKA2IwT5mcVs0pQRSZJUYhCaMbITs0AAAACAlxCCqoHBHRM0a0w3RYUFutwX7eYYAAAAgIojBFUjGdlWl2Pp2VbdMW+zlu1I8UOPAAAAgNqHEFQNFNgMTft8p4xS2jyyaLsKbKW1AAAAAOAJQlA1sDE5TSkZpZfKTs+2aubKPVXUIwAAAKD2IgRVA57uFTTn+2RmgwAAAIBKIgRVA57uFZSebdXG5DQf9wYAAACo3QhB1UCPxBhFh3pWBc7TWSMAAAAA7hGCqgGL2aSbe7f0qK2ns0YAAAAA3CMEVRMT+rdVeJCl1DYJUSHqkRhTRT0CAAAAaidCUDWxfGeqsvIKSm1zWZcEWcymKuoRAAAAUDtVKAQdPHhQhw4dctzeuHGjJk6cqDfffNNrHatLCmyGpn72c5ntPvzhENXhAAAAgEqqUAgaNWqUVq1aJUlKTU3VwIEDtXHjRj322GP6xz/+4dUO1gUbk9OUmplbZjv2CgIAAAAqr0IhaMeOHerRo4ck6b///a86duyo77//XvPnz9fcuXO92b86oTwV39grCAAAAKicCoUgq9Wq4OBgSdKKFSt02WWXSZLat2+vlJQU7/WujihPxTf2CgIAAAAqp0IhqEOHDnrjjTe0Zs0aLV++XIMHD5YkHT58WLGxsV7tYF3QIzFG8ZHBHrdnryAAAACg4ioUgp577jn9+9//Vr9+/XT99derS5cukqTPPvvMsUwOnrOYTZp6WQeP2+87lu3D3gAAAAC1W0BFHtSvXz8dO3ZMmZmZql+/vuP47bffrrCwMK91ri4Z3DFBM6/rqgkLtpTZ9uUVv+ms+Hoa3DHB9x0DAAAAapkKzQSdPn1aubm5jgC0f/9+vfLKK/r1118VFxfn1Q7WJbHluDZo2uc7KZAAAAAAVECFQtDll1+ud999V5KUnp6unj176sUXX9QVV1yhWbNmebWDdUl5rvVJycihQAIAAABQARUKQZs3b9aFF14oSfrf//6nRo0aaf/+/Xr33Xf1f//3f17tYF1SnipxEgUSAAAAgIqoUAjKzs5WRESEJOmrr77SyJEjZTabdf7552v//v1e7WBd0iMxRvXDPL9Mq7yhCQAAAEAFQ1CbNm30ySef6ODBg/ryyy916aWXSpKOHj2qyMhIr3awLrGYTbqxV0uP2tYLDlCPxBjfdggAAACohSoUgp588kk9+OCDatmypXr06KFevXpJKpwVOuecc7zawbomsWE9j9qdys3X8p2pPu4NAAAAUPtUqET23/72N/Xp00cpKSmOPYIk6ZJLLtGVV17ptc7VReVZ4jbt850amBQvi9nkwx4BAAAAtUuFQpAkxcfHKz4+XocOHZLJZFKTJk3YKNULeiTGKCEqRCkZZRc9sFeI69U6tgp6BgAAANQOFVoOZ7PZ9I9//ENRUVFq0aKFmjdvrujoaE2fPl02m83bfaxTLGaTpoxI8rg9FeIAAACA8qnQTNDjjz+ut99+WzNmzFDv3r1lGIbWrl2rqVOnKicnR08//bS3+1mnDEyKV0iAWTn5ZQdKKsQBAAAA5VOhEPTOO+/oP//5jy677DLHsS5duqhJkya68847CUGVNHPlbo8CkCSdyMrzcW8AAACA2qVCy+HS0tLUvn17l+Pt27dXWlpapTtVlxXYDM1Zu8/j9tMX71SBzfBdhwAAAIBapkIhqEuXLpo5c6bL8ZkzZ6pz586V7lRdtjE5TemnrR63txdHAAAAAOCZCi2He/755zVs2DCtWLFCvXr1kslk0vfff6+DBw9qyZIl3u5jnVKRQgcURwAAAAA8V6GZoL59++q3337TlVdeqfT0dKWlpWnkyJH6+eefNWfOHG/3sU6pSKEDiiMAAAAAnqvwPkGNGzd2KYCwdetWvfPOO5o9e3alO1ZX2fcJSs3IkadX+lAcAQAAAPBchWaC4DtF9wkyefgYiiMAAAAAniMEVUODOyZo1phuigoL9Kg9xREAAAAAzxGCqqnCDVMtHrenOAIAAADgmXJdEzRy5MhS709PT69MX1DExuQ0pWZ6HmwahAf7sDcAAABA7VGuEBQVFVXm/TfccEOlOoRC5Z7Z8fQCIgAAAKCOK1cIovx11Slv2euvdx1R7zYNfNQbAAAAoPbgmqBqyl4q21OfbjlMhTgAAADAA4SgaqpoqWxPHM/Ko0IcAAAA4AFCUDU2uGOC3hjTTWFBnlWJo0IcAAAAUDZCUDU3uGOC/j3mXI/aUiEOAAAAKBshqAb4cb9ny9w27WM5HAAAAFAWQlA1t2xHil75eo9Hbd9c8zvFEQAAAIAyEIKqsQKboWmf7/S4fXZegWau9CwwAQAAAHUVIaga25icppSM8hU7eOObPcwGAQAAAKUgBFVjFan2dtpq070LfvJBbwAAAIDagRBUjcVFeL5ZalFfbEvRkm0pXu4NAAAAUDsQgqqxHokxig4NrNBjJ3+6g2VxAAAAgBuEoGrMYjbp5t4tK/TY41l5mrs2WZ9u+UPr9h4nEAEAAAB/CfB3B1C6Cf3bas73+5SebS33Y6cv3uX4PiEqRFNGJGlwxwRvdg8AAACocZgJquYsZpNmjOwkUyXPk5qRo/HzNmvZDq4VAgAAQN3m1xA0depUmUwmp6/4+Hh/dqlaGtwxQbPGdKvw9UGSZF8MN+3znSyNAwAAQJ3m9+VwHTp00IoVKxy3LRaLH3tTfQ3umKCIkECN/s+GCp/DkJSSkaONyWnq1TrWe50DAAAAahC/h6CAgABmfzx0fqtYRYcGKv10+a8PKqoi+w8BAAAAtYXfQ9Du3bvVuHFjBQcHq2fPnnrmmWfUqlUrt21zc3OVm5vruJ2ZmSlJslqtslorFwwqy/78vu7H2J7N9Nrq3yt1jtiwAL+PV3lV1fjWZYyxbzG+vscY+xbj63uMsW8xvr7n7zEuz/OaDMPw2wUiS5cuVXZ2ttq1a6cjR47oqaee0i+//KKff/5ZsbGuy7WmTp2qadOmuRyfP3++wsLCqqLLfvdrukn/2lXRJYOGooOkKd0KZK5spQUAAACgGsnOztaoUaOUkZGhyMjIUtv6NQQVl5WVpdatW+vhhx/W/fff73K/u5mgZs2a6dixY2W+UF+zWq1avny5Bg4cqMDAihcwKMvn21J0/0fby/04e+Z57bouGtShkXc7VQWqanzrMsbYtxhf32OMfYvx9T3G2LcYX9/z9xhnZmaqQYMGHoUgvy+HKyo8PFydOnXS7t273d4fHBys4OBgl+OBgYHV5s3s674kRIdX6HHxtWSfoOr0s66tGGPfYnx9jzH2LcbX9xhj32J8fc9fY1ye56xW+wTl5uZq165dSkio2R/UfalHYoziI12DYFmGdoqv8QEIAAAA8Aa/hqAHH3xQ33zzjZKTk7Vhwwb97W9/U2Zmpm688UZ/dqtas5hNmnpZh3I/7u3v9mnJNjZKBQAAAPwagg4dOqTrr79eZ511lkaOHKmgoCCtX79eLVq08Ge3qr3BHRP0xphuCijnT2/ypzvYKBUAAAB1nl+vCVqwYIE/n75GG9wxQXNu6qGxszd6/JjjWXlslAoAAIA6r1pdE4TyOZlT/hrsa/f8yWwQAAAA6jRCUA1VYDM0ffGucj9u5qq96vPcSi3bwfVBAAAAqJsIQTXUxuQ0pWTkVOixKRk5Gj9vM0EIAAAAdRIhqIY6erJiAcjOkDTt850sjQMAAECdQwiqoeIiQip9jpSMHG1MTvNCbwAAAICagxBUQ/VIjFFCVOWDUGrGaS/0BgAAAKg5CEE1lMVs0pQRSZU+T1pWnhd6AwAAANQchKAabHDHBP1r1DkyVeIcMfWCvdYfAAAAoCYgBNVw9cODVZnSBmmncvXplj+0bu9xiiQAAACgTgjwdwdQOZWpEmc2yWmvoYSoEE0ZkaTBHRO80TUAAACgWmImqIarTJW44hM/qewfBAAAgDqAEFTD2avEVea6IDt7JmL/IAAAANRmhKAarmiVOG8FIfYPAgAAQG1GCKoFBndM0Kwx3RTvhX2D7CpzrREAAABQnVEYoZYY3DFBA5PitTE5TakZpzX50591Kje/wuerzLVGAAAAQHVGCKpFLGaTerWOlSSFBll0x7zNFT7XVz+nSiq85shi9sZCOwAAAKB6YDlcLTW4Y4JmXte1wo+f8/0+Xf/WevV5biXV4gAAAFCrEIJqseFdm6hL08hKnYOy2QAAAKhtCEG1XGKDepV6PGWzAQAAUNsQgmq5JtGhlT6HvWz2+r3HK98hAAAAwM8IQbXcBW0aeO1cd81nWRwAAABqPkJQLXd+q1hFhXqnCGD6aSvXBwEAAKDGIwTVchazSbf0TvTa+QxxfRAAAABqNkJQHdCyQbhXz5eSkaONyWlePScAAABQVQhBdUBcRIjXz3n0ZI7XzwkAAABUBUJQHdAjMUYx4YFePWeD8GCvng8AAACoKoSgOsBiNunKrk28es4HPtpKgQQAAADUSISgOmJAUrxXz5eamUOlOAAAANRIhKA6okdijBKivHttkCHpsY+3Ky/f5tXzAgAAAL5ECKojLGaTpoxI8vp507KsOv/Zr5kRAgAAQI3hnV00USMM7pigcb1b6u21+7x63rSsPN0xb7OGdmyklg3qqX5YkBpEBCs+MkQ9EmNkMZu8+nwAAABAZRCC6pgBSfFeD0F2S3YckXTE6VhCVIimjEjS4I4JPnlOAAAAoLxYDlfH2K8Nqqq5mZQMCigAAACgeiEE1TG+ujaoNIakaZ/vVIHNqNLnBQAAANwhBNVBgzsmaNaYboqPrLoNT1MycrQxOa3Kng8AAAAoCSGojhrcMUFrH7lE9w1oV2XP+e66ZGaDAAAA4HeEoDrMYjbp3gFt9caYbl7fQ8idpTuOqPO0L7Vk22GfPxcAAABQEqrDQYM7JmhgUrw2JqcpNeO0pi/epbSsPJ88V1Zuge6c/5OGbT+sSzskKC6CMtoAAACoWoQgSCqcFerVOlaSFBpk0fh5m+XLhWuLtx/R4u2F5bQpow0AAICqxHI4uLAXTqiKJXJS2WW0C2yGNiSn6cdjJm1ITuO6IgAAAFQKM0Fwq+gSuaeX7NSOPzJ9+nyGpCmf7lBESKCOncp1LJNbvjNV0z7fqZSMHEkWvbv7B2aOAAAAUCmEIJTIvkTui7sv1NOLd+qtNck+fb4jJ/M0+j8bHLejwwKVnm11aZf618zRrDHdCEIAAAAoN5bDwSOPD0vSrn8MVpCl6goYuAtAkhzXKrEBKwAAACqCEASPbTmYrryC6hE6DBVeSzR3LXsPAQAAoHwIQfDY0ZM5/u6Ci+mLd6nPcytLLKoAAAAAFEcIgsfiIqqmWlx5pWTk6I55m/Xqit+YFQIAAECZCEHwWI/EGCVEhai6bmv68ord6j2DWSEAAACUjhAEj1nMJk0ZkSRJLkHIfjvQ7N+IlJrpvOdQgc3Qur3H9emWP7Ru73FmigAAAECJbJSPfSPVM3v3FIr/a++ez7b8oSU7jvixh4Wmfb5TNps0fbFzP9ljCAAAAIQglFvRjVSPnsxxbGxqMZsUERzo9xBkrxx35/zNLvexxxAAAAAIQagQ+0aqxZ3fOrbETU6rA0OFS/emfb5TA5PiZfHz8j0AAABUPa4JgldZzCbNGNnJ390olX2maGNymr+7AgAAAD8gBMHrBndM0Btjuik+MtjfXSnV7O9+19o9xyiWAAAAUMewHA4+4e66oRNZeXrsk+3VZqnc8l1HtXzXUUWHBWrGyE4lXucEAACA2oUQBJ9xd93QoI7xmrlyj+asTVb66eoRhtKzrbpj3mZFhQYo43S+43hUaIBu6Z2o8f3a6Mf9JwhHAAAAtQQhCFXKYjbp3gFtNaF/G21MTlNqxmmlZeUpLTtPr6/a69e+FQ1A9tsvr9itl1fsdjpOmW0AAICajRAEvyg+S1RgM7Twx0NKzcz1Y688Yy+z/fqoc1Q/PJgZIgAAgBqGEIRqwWI2aeplHXTHPNe9faobexmFuz74SUaRmgpFZ4gKbAbXFwEAAFRThCBUG/aqco8sqj7FE0pjFCsql5KRozvmbdbwzgn6Yd8JpWbmOO5jCR0AAED1QQhCtWKvKrd+73Gt+/2YJJN6Jsbo7g9+UvrpPBVudVq9fbEtxeWYPSC9MaYbQQgAAMDPCEGodixmk3q3baDebRs4jj11eZImLNjiv055ySOLtmtgUjxL4wAAAPyIzVJRIwzq0Ei3tLMpOrRm5/b0bKv+7+vdWrf3uD7d8ofW7T3OZq0AAABVrGZ/okSd0iXW0MOjL9a/1+yvVvsMlderX+/Wq1+fKbsdEx6oK7s20YCkeAooAAAAVIFqMxP07LPPymQyaeLEif7uCqox+z5DP04eqA9uO1+39G6pmPAgf3erUtKyrHp77T5d/9Z6nff0ci3ZdtjfXQIAAKjVqsVM0KZNm/Tmm2+qc+fO/u4Kagj7PkO9Wsfq8WFJjo1Xj57M0YqdR7Rpf7q/u1ghaVlW3Tn/Jw3bflj/d/25zAoBAAD4gN9D0KlTpzR69Gi99dZbeuqpp/zdHdRAxTde/XvfNlqyLUV3zq/+ew6VZPH2I/p61zL982+dFRsRwn5DAAAAXuT3EHTXXXdp2LBhGjBgQJkhKDc3V7m5uY7bmZmZkiSr1Sqr1b/Xh9if39/9qK3KO74Dz26gmdd10VNLflFq5pn3TEx4oDo1idTm/Rk6mZvvk756S06+zaUiXligWYOSGql321jFR4aoe4v6XgtFvId9i/H1PcbYtxhf32OMfYvx9T1/j3F5ntdkGMW3fKw6CxYs0NNPP61NmzYpJCRE/fr1U9euXfXKK6+4bT916lRNmzbN5fj8+fMVFhbm496iJrIZ0t5MkzKtUmSg1DrSkNl05vi2NGnjn2blFNTM2ZXoIEMjW9rUJfbMr3FJrxkAAKA2y87O1qhRo5SRkaHIyMhS2/otBB08eFDdu3fXV199pS5dukhSmSHI3UxQs2bNdOzYsTJfqK9ZrVYtX75cAwcOVGBgoF/7Uhv5cnwLbIZ+2H9CK3Yd1Yc/HNJpq82r568Kd/drpcSG4dp/PFsf/nDIafYrPjJYTwxtr0EdGpV6Dt7DvsX4+h5j7FuMr+8xxr7F+Pqev8c4MzNTDRo08CgE+W053I8//qijR4/q3HPPdRwrKCjQt99+q5kzZyo3N1cWi8XpMcHBwQoODnY5V2BgYLV5M1envtRGvhjfQEl92jVSn3aNNGlIkpKmLJP/5kcr5rXVv5d435HMXN29YKtmjemmwR0TyjwX72HfYnx9jzH2LcbX9xhj32J8fc9fY1ye5/RbiexLLrlE27dv15YtWxxf3bt31+jRo7VlyxaXAARUhdAgi26/MNHf3fAqe56b9vlONmYFAACQH2eCIiIi1LFjR6dj4eHhio2NdTkOVKVHhyZJkt5ak6zakhkMSSkZOZr8yXZFhQUqJT1HTeqH6vzEWJnNJh07lavYsIBa83oBAABK4/fqcEB19OjQJD1waXu9t26f9qdlq0VMmOIiQ3TPBz9JOjO7UtPM33jQ6fbrq/Y63Y4Osiiw5REN79q0KrsFAABQpapVCFq9erW/uwA4BAWYNe7CVk7HAi0mTft8p1IycvzUK99Kz5MmLNiqxTuOaFSP5o5ZouJ7FBXYDG1MTmP/IgAAUCNVqxAEVHeDOyZoYFK8IwDsO5atDzYeUGrmmVAUGWJRZk6BH3tZGYVBZumOVC3dkep0T0JUiKaMSJLNJj3x6Q6lZeW53OdJ4QUAAAB/IwQB5WQxm9Srdazj9oT+bZxmRWyGodH/2eDHHvpGSkaO7pi3ucT7xs/b7HEFOgAAAH8iBAGVVDwUFdgMJUSFKDUjp8ZeO1QRhqTHPt6u01ab4uoFSyY5LaWT5HYJHUvrAABAVSMEAV5mMZs0ZUSSxs/bLJOciygUv13bpGVZdd+HW1yOR4cV1u1Pz7Y6jiVEhWh45wQt3PwHS+sAAECV8ts+QUBtNrhjgmaN6ab4qBCn4/FRIXpjTDf9a1Q3xYQHOd1nDwq1UXq21SkASYVL6N5ak+wUgOzHx8/brGU7UqqyiwAAoA5hJgjwkeJFFIov9RrU0fW+5TtTa3X1OU8ZKtzcdWBSPEvjAACA1xGCAB8qfr1QWfcVDU7Ld6Zq9tp9tX4JXUlSMnI0+7tkxUUGc60QAADwKkIQUM3Yw1Gv1rHqkRjjMjNkMklGHUlFTy/Z5fjefq1QabNrAAAAniAEAdWYuyV157aorx/3n9Dynan6ZMthl2tqait7ie56wQE6lZvvOE4hBQAAUF6EIKCac7dszj5T9PiwJG1MTlNqxmk9+vF25Vhtfupl1SkagCQptcgeRcwSAQAATxCCgBqsaEAKDjDrzvk/lfmY9nHh2nMsS/m1JC/ZVwY+8N8tksmkrNwCx30lzRKxNxEAAHUbIQioJYZ2bqy/H0rXv79NLrHNv0ado6GdG2vtnmMa/Z8NVdg738vKc0119iV0N1/QQk3rhymmXrAOHM/WBxsPKDXzzHVWLKkDAKBuIQQBtcijQ5PUpWl9PfHpjlI3ID2/VawSokLqTCnuOd/vL/V++5K6167rqiMnc7U/LVstYsI0tldLBQWwnRoAALUNIQioZYZ2TnC7B1HR5V4Ws0lTRiRp/LzNdbL8dnH2MZiwYIvT8aeX7NJtFybq4cFns3wOAIBahBAE1EKl7U9kN7hjgmaN6eZSgjshKliThyUpJSNH0xfvKuUMtZ/NkP79bbLmfr9fuUUuomL5HAAANRshCKjDipbgTknP0u8/b9GEay9SSHCQPt3yh7+7V23kFqsiYb/W6L4BbTWhf1tmhQAAqGFY7A7UcfZZoxGdE9Q2ynB8oI+LCPFzz6q/l1fsVrfpy/Xqit9UYGNhIQAANQUzQQDc6pEYo4SoEKVm5JR63dCEfq2199gpLd1xpMr6Vp1knLbq5RW79eaa33Vd92YakBTv2NA2NeO0jp3KVfppqwybTaZ0kwbZDAX6u9MAANRxhCAAbhUtnmCS3AYhe8ltSVq2I0VTP9vpVHq6LsnKLdDba/fp7bX7ShwvyaL3Z6zWjKs6OZYhpmacVlpWnmLqBSs+kqILAABUBUIQgBKVXDzBtTBA0euL7FXUTmTlafrinWWW4g4wq9Zs3iqVFIAKpZ+26o55mxUSYFaOmxcdEx6oK7s20YCkeAIRAAA+QggCUCp34aakD+fuqtLZy3Uv35mqT7Ycdrt/0cCkeK3fe1zzNuzTql/+dBsOapuSXmNaltUxo1R0fCjRDQCA9xCCAJTJk5LbZT22V+tYPT4sqcQP873bNlDvtg1UYDP0/e5jum3eD8qx1v4wVBp7FbrgALNThbr4yGBde16zv4oxFI7v+a1iCUYAAHiIEFQZq56VzBap78Ou933zvGQrkC5+tOr7BVRTnoQpi9mkC89qqNE9muvttfuqpmPVXPES3amZuXr16z2O2zNX7VF4sMWpMMOm5DSt+/2YioekApvhCKINwoMlk3TsVC4zTACAOoUQVBlmi7TqaWnfGmnUojPHv3m+8HjiRYVBiSAElNuApHhCUDkULcxQ3MxVexQdFqhruzfVZ1tTSrxGi01gAQB1BfsEVUbfh6Xo5lLyt7K8d7kS0jfJvPrpMwEo+Vtp/1p/9xKokewlukublzBJuu3CRMVHBldVt2qs9Gyr/v1tcqlFKlIzcjR+3mYt25GiApuhdXuP69Mtf2jd3uPsgwQAqFWYCaqsc8ZKq56W+cBa9dBaKVlnApD++h5AuXlSovv1v0p0PzLkbEfxhdnMHlWYfYwfWbTdpdx5ZWaJii7BY9kdAKA6IARVVt+HCwPPvjWSCj9EmOwB6OLHC//LkjigQjwt0V20+EKPxBhN/exnpWbm+qvbNV56tlWS1emYvUjDG2O6uQSh0kLOsh0pHpVYBwCgKhGCvCF9v+Nbx982HQHoaanlhVXeJaC2KE+Jbnft7Rf/f73riP77wyGdys2v4ldQuzyyaLsGJsVLUpmlzyVp/LzNLrN49mV3s9wEquKYRQIA+AIhqLK+eV5KP+B6/Kd5Z8KRycRsEFAJ5S3R7a597zYN9PiwJK3fe9ypalpaVp7u/uAnL/e49krPturiF1bqyMk8l6p1dql/zRrVCw5wu4zRfuyxj7erf/tGCgpwf3kqs0gAAF8hBFVG0Spw9iVwdvYAZL/P4KJiwN8sZpNjP6KiAi0ml2tgSroOCdKBEyUXV5DOjFtZs25pWVadM/0r3donUT0SY3U0M0dpWXmKDgvSur3H9L/Nf7g8prRleQAAeIoQVBm2AvcBqKjS7gNQLbhbcnciK093zd8siTDkS1m5BX/tebSnzLZF2ZflsTQOAFARlMiujIsfdczw2FqUcd2PfUkcgGrJvoTu8q5N1Kt1rIZ2LizKEB8V4tQuISpEt/Zu6Z9OwiE926o75/3o8/LdlAoHgNqJmaDKatFbSrxIRkGBtH+N+zYsiQNqpNKKMnRPjNEDH21VVm6Bv7tZZ32584i+3HlECVEhmjzsbEWGWPTjMZPq7z0uS0CAjp3KrVQxBa5JAoDaixBUWRc/Kn3zvCzfzii5jX1JXPoBac5Q6eYlVdM3AJVWUlGGwR0T1L99I3WbvrzEa19MkqJCA5R+mop0vpSSkaM759uLW1j07u4fne4vGlw8rTa3bEdKpSvblYaqdwDgX4Qgb/gr5PxZ72w1PLXLfZvoFmeKJVApDqgVggLM+ufVnd1+WLZ/nJ1xVWdJctm7KDosUJJ9Tx74kr1a3fDOCfpu9zGlnz4z5jHhgXrq8o4a2rmx41iBzdDUz3aWWtlu2uc7K3xNEjNMAOB/hCBvaNFbNkNqWNJyOKkwANmD0NYPCo8RhIAar6QNXeOLfajt1zZWMz9cplYduiohOlw9EmMkFe61k5px2lEVLS0rV2nZeXpv3X6dYqmdV9iDyxfbUlzuS8uy6s75P+nvh9L16NDCvY1mrtztVCnQnZSMHM1dm6ybeic6BSF3MzySHMf2HcvWKyt+89kMEwDAM4Qgb7j40cJlbnZFZ33sAoLPHEvfL+1fW3X9A+BTnmzoajGb1DbK0NDOCQoMDHQcL2n/oy5NozV+HtXpqsq/v01WjtWmrNx8t6W53Zm+eJf+812yI+y6m+HxdMbPUOHsYVkzTCyjAwDvIAR5ma3FhTK7mxHKz3W+nX6AZXFALVLeDV3LUtIME3znnXX7y25UjH3fotsuTNR/1iS7BNbyLHc0/jrfxuQ0t+8lltEBgPcQgrzEaH6B/jyedmZJXEiUlJNR8gNYFgegDMVnmBqEB2tD8nHNXpvstFTOXh0tIjhQr63arc0H0pVPKecq9daaZK+d6+hJ19Dr60INAFDXEIK8xHbRJOmnzwtv2JfDBQS7zgAVRRACUIbiM0y92zbQvQPalbgk6sKzGqrAZmjmyj2aszbZqQgAaoa4COe9qQpshqZ9XnKhBvsyur7t4jR/w37tT8tWi5gwje3VUkEBbAcIAO4QgrzoeL32irWclrloEYSyEIQAlFNZS+8sZpPuHdBWE/q3cSq8cCj9tD7dclhpWXmOtlSpq16iQwNlMwwV2AxHsN2YnFbqkkj7MrqkKcuctqN7avEuDe8cr1eu68Z1QwBQDCHIi35NGKl2x48W/lnOkwBkl75fWj+r8HuCEAAvcReWnhiWVGb1sg82HiizOhp8I/20VaP/s0FhQWYN6RivC1o31Opfj3j02OL7cRuSPt+Wqq9+Xqo7L26jCf3bEoYA4C+EIC8rGPuZzO9fWb4QJEm5GdKGWdKW+VLXUYQhAD5R0ixS0WP2GaSSQlF8ZLCuPa+ZfjtyUkt3ePYBHeWTnWfTws2HtXDz4UqfK7fA0MsrdmvO9/s0Y2SnEjeNlUTlOQB1BiHIF1r0Lqz+Vt4glJNR+LX2ZWn9v6Tz7yQMAahyxYNS0VBU/MPxsh0pmvrZznLPHDWKDFJ6dr5y821e7TtKlp5t1fh5m3X7RYn6bGuK0xK7sCCLzCY5FdyoHxaokec00YCkeEdIAoDaghDkCxc/WrgPUHlDkF1+buHXhlmFy+TycwqLLBCKAPhBadcgudsj6URWnqYvdl/aOyY8UE9d3lFDOzd2mo1oEB6sl5b/qh8PpPv41dRthgr3RCouO891Y94T2Va9vXaf3l67T/XDAjSmR3NlHDMpNjlNvdrEqcBm6L11+5wKMVjMJmaTANQIhCBfqehsUFFFS2wX5ErfzCj8KpFJMpklc4AU8Fd1ofy/PoTUa8QyOwA+4S4kDeoY71SUIaZesOIjnT8Uu6t89/nWw3rs4+06mZNfpa8BpTuRna/XVv8uyaJ3d/+gALPJpQz79MW7ZDFJBUUOx4QH6squTdS/fSPJJB3NzCnx/VAcG8MC8CVCkK/Yw8bWDyoXhMrFkIwCqaCgMDQVlXHAsxBlCXINUAEhUnxH6eYlPuk1gNqnopvHjujSWEM7JWhjcpqW70zV7LX7ZJLcloeG/5S0D1VBscNpWWdmk9wpabNXNoYF4GuEIF/ySxCqDKMwPBUPUAW5hcv7pkZJJosUVK/weNGQFBLFTBMAr7AHqF6tY9UjMcbth+HLuiTo0y2HlZp55t+rqBCLcq35yilgtqCmSMnI0R3zNuu+AW3VskG4YznlXfPZGBaAbxGCfM0eCjbMcl7eVlMZBYWV7IoqyC089s0M6dsXCEkAvMbdNUf2ZVEPDz7b6fg5TSO0dOlSNUw6X8ez8xUTGqSdqZn6cf8JhQdZdFnnxvpiR4oWbv6jxOczSWoYEaSjJ/NKbAPve3nFbsf3Jc38Fd0Ytn/7Rvpx/wmWygGoMEJQVbj4UWnfGunIjtoRhEpTWkj67uUz+yGx1A6Ah0paWlf8uNVqldkk9UyMUWBg4SawF57V0OkxFyc10sCkRi6zSyGBJt3ep5XuHXiWLGaTnl68U2+tcS0gAN8rbemjfWPYTlO/dKosaL/2yF7Jrmgg8uW1RVy3BNRchKCqcvMSadWzhfsA5WbU/jDkTklL7Y7skKbHFd62X4/EzBEAHyltdsnu8WFJOqdZfd3/0RblWCnjXd0UL61e9NqjhKgQTR52tqJCgzRvwz6t2X3MqfR3VEiABpwdp/joUJlUGKTPbxXr+Pl7Gmy4bgmo2QhBVeniRwu/Vj1buA9QvptQUBcVr4InucwcWfJzNMQwy1xvgnTJE37oJIDaxJPCDUM7J2hAUiOd/+zXSssqeXlcZLBFXZvX16Z9aTpNYPK7lIwc3Tn/pxLvz8jJ18KfzmxCO3PVHoUHW3Rd92aKDA1y2RzYXbBZsi1Fd87f7HJurlsCag5CkD8UDUNb5ks56X8tDzMRiooqMnNklhQkybbxTWnjm1xvBKBKBAWY9cyVHTV+XuEH3qJLtexzA89f3UWDOyaowGZo5so9ennFb1XeT1ROVm5BiRXs7MUbhnZspFYNI2Q2FQYnd+zvj6mf/ayBSfGS5NGskn32KSU9S79nmFRgMxTojRcGoESEIH+yhyE7eyg6lSrJVLhBqlT4gd9WIBk21fVCsWZPrzdic1kAXjK4Y4JmjenmsvQpvtgMgcVs0r0D2uqs+HoubVHzLdlxRNIRj9qmZubq3gU/6cf9J0pdLmcPznPWJiv9tPWvVhZ99M9vNKpnC0fFvB6JMZKk9XuPa93vxyQ3y/gAlA8hqDopHorKqy6HqOLXGxXkFlbkWz+LIgwAKs2T64hKa3siK0/TFzsHo/Bgi27rk6iTuQV6+zuKMNQ2X2xLcTlWdLmcJD2yaLvSs60u7Y6czHOqmBcdFqi8fJuy885c2zRz1R5FhwVqxshOLL0DKoAQVJtUNkTNGSod2iSXACWTZMsvrPxWkxQvPlFSEQaJcASgTOXZANZd20EdSw5R5zavryc+3eF07VG9YIsMQ8oq8sE3LMji9EEYNYv9z5D3/3druX6O7oKS/bh9n6Xx/dq4lA2XPFuOB9RFhCCcUVYIKFrQoXhIkmrG9UzuijBI0h8/SM82L/zePnPUtDvBCIDXlBaihnZOcBuSJNcPsct3ppa63M4kqVvzKP14oA5WIa0hvB1kX16xW69+vVu2Ios9osMKryoqGqCKLsezX4eUmnFaaVl5iqkXrPhI56BUUqU8SoOjNiAEwXNlzTTNGSqlbj9z2x6QAoIla1bhkrzqKj+38KsoZo0AVKGSQlLxY8WX28WEBumXIyd18ES2WsSEaWyvlgoKMOvZJTv1729LXmZ3T//WOq9lrDYkH5dkUoDZpAWbDjpVRkPNYSu22t3d7JF9Od7tFyXq0y2HlZrp+sdLe1CS5LYE+GVdEvTZ1hRKg6PGIwTBe0oLBu6W2hW4CR7VSXlmjeo1okIdgCpTPDAV3xRWkh4dmqQuTV2X2RX/wHphuzOPvfuSttqYnKavfk7RnO/3u3lmQ2fq4qGmseek0sKxvRpeSfe5e6z9MeN6t9SApHid26K+y9K84jNFzCbB3whBqBruAlJJM0fVfVmdu1mjjAOFhRi+e7nwNpu+AqgGSlpmV9KHTXu46tU6Vj1bxbrMBIRZpOxqPKkP/7JvWGs2Oc9MFQ/eJW00O3nY2aofHkwwQpUgBMF/3AUjd3snBQTLyM+VqbqHIw82fWXmCEBVK09Bh6KKL7uLDQvQnzvXK7DluXp66a8lfoBNzTittXuO6audR5SZk+/Nl4IaovjSPPtM0c0XtFBmTr4Wbv7D5THuNrllmR18iRCE6qWE646M2UNkPfSTAgMDCxdi1JRZI8m1fLdUOHO09uXCgGSfNcrPkerFSfftqPo+AoAbRQOU1WrVkl3SoA6NNKRzk1Jnl67s1lQFNkNz1yZr+uJd/uo+qhn3SyxLZr+G6fVR53g8Q+SNZXYs1asbCEGoEQrGfqalS5Zo6NChCgz8ax/tEmaNZDK5lseujuxL6ooGpMxDrtcb2UMSBRkAVBOezC5ZzCbd1DtR//kuWakZOeXepc5ikkwmk/KLTyugzrD/5O/64CcZRd4GMeGB+seIDoqNCHGqbrf/WJbeXb+/1GvgylKepXoSJchrMr+GoFmzZmnWrFnat2+fJKlDhw568sknNWTIEH92CzVFSdXq3O535GY2pjoyjMIldEXZ+/3HD4XV6orOHEmU8gZQbVnMJk0ZkaTx8zbLJM+26x7SMV5jzm+h81sVhqyZK/do9tpkZZw+U+0sOiywxL1zUPsYxd44aVlWTViwxaPH2pfi3TegrZrVD9HvGYUlvgOLtSuwGZq5co9eXvGb23MUX6oXFmSR2WTSqdwzSz6LB67SZpQoP+5/fg1BTZs21YwZM9SmTRtJ0jvvvKPLL79cP/30kzp06ODPrqEmK+taI+nMzFFgSM2YNZLczxxJZ6rVFZ05ys8pDIDn38l1RwD8anDHBM0a083lr+tlXTxvd++AtprQv41H+yUVPydg9/KK3X99Z9H/XvxWUy/r4FSoYepnP7stGV4Sd3s92QPXG2O6SXJfYryk8uPRoYHq07aBfth3wqlMvbu9nQhI3uHXEDRixAin208//bRmzZql9evXE4LgXbVx1siueLW6giJhac0LhUUZii+tk1heB6DKFC+yEBcR4lEZZTt3y+9KO2dqxmkdO5Wr9NNW/f5nltb/flwniswcEZbqttTMXN0xb7Ne+Vtn7TtxWq98vbvsB5XDPR/8pLwC1zdYaeXH009b9cW2FNe+/nVd1K0XJmrh5j/cLvUr/ntAOPJMtbkmqKCgQB999JGysrLUq1cvt21yc3OVm3vmw15mZqakwos1rVb/Tovbn9/f/aitfDa+Yz51OWT+9jmZty44syzNcb1RiEzFl6pVd7YC5+V1RcKdsf97Gc82K7yRnyuLpCGGWZadgbI16qiCsZ9VbV9rOf6N8D3G2Le8Mb7dm0dKiiy8YRQ43bYV5FdoT+3SzmlXYDP0w/4TOnoyV3ERwUrLytO9H24r93VKqF0m/m+bT87rLgBVlP1Mb60peX+m6NBApRdZLhofGawnhrbXoA6NvNYPT/n73+HyPK/JMIqvtKxa27dvV69evZSTk6N69epp/vz5Gjp0qNu2U6dO1bRp01yOz58/X2FhYb7uKuq4s1IWqdnxNQqxFoaKAnPhimKzka8Ao3Z96DIk2WRWgblwdsz81+uzmQJltYTpYOyF+jVhpB97CACVs/W4SYv2mZWed+Yv5tFBhka2tMmQ9NHvZp3KP3NfZICh9tE2BVlMOppt6LeTZpVv41g2moWvFH9vFX60v6WdTV1ivfcx32ZIezNNyrRKkYFSYoShvZkm7cmUJJPaRhpqE2XIn5NQ2dnZGjVqlDIyMhQZGVlqW7+HoLy8PB04cEDp6elauHCh/vOf/+ibb75RUlKSS1t3M0HNmjXTsWPHynyhvma1WrV8+XINHDjwTPUyeE11Hl/Le5fJdKRIWeuaPHPkIUOSYbJIQeFSfm7hBc/25YSSxEySi+r8Hq4tGGPfqo3jW3yGqHuL+k4Xrpd0nyQt3ZGqez70bCYhOMCskACzMtg3CVWofliAHh/aXvGRIS7vX/v1Rd//flwpGTlKiApVz5b1JUmb9p+QJPVMjFHPv5bWffnzET215Jcyr5uKDg3QyGa5evC6AX75dyIzM1MNGjTwKAT5fTlcUFCQozBC9+7dtWnTJr366qv697//7dI2ODhYwcHBLscDAwOrzT/I1akvtVG1HN9blro/vupZaf2/Cq/XcVxvlFNYwju/Bl1z5IZJkskokHIzzxwreh3Vge9lfrqBZLJI5r/+maGqnaRq+h6uZRhj36pN4xsoqU8790uGSrtPki47p5mCAgNcLnC3Cwkwq99ZDTW2V0tHpTv7dRv7jmXrg40HnC6ADwsya9DZjVQv65AG9umhzQcz9eaa391egA944kR2vh78X+EfaaNDA9SrVYwCLWb9knpSe/7Mcrku7o1vnZfc/eubZIUHmXV+q1h9/cufHj1n+ul8zf7NrG6/pWl416ZeeR3lUZ5/m/wegoozDMNptgeosUorxpC6vfD7ovsbSVLeSddaoDWZUSAV/PU/8OLFJvavlaZGnbltKfIHjqKBiSp3AKqposUZiu5XEx/p/uL0osUd3FW8sxXka8mSg+rVOlYXtY/X3Ze01fq9x7V27586nJ6jfceztPVQhsv/JkICzcqx2qriJaOGSj+dr6U/Hy3347LybB4HoKKeWvKLhnRuUq0LNPg1BD322GMaMmSImjVrppMnT2rBggVavXq1li1b5s9uAb5V2uzHyx2lU0edZ45qWinviipwU+HO/v03Mwq/7CzBZ0qBS2dCU0iU1HUUgQlAlfFk41hPH1e8MITFbFLvtg3Uu20Dx7G8fJveW7dP+9Oy1SImTGN7tZTFbNLG5DQdPpGtLYfSJZnUPCZUb3+3z2m2CagaJqVm5mpjclqFfjeqil9D0JEjRzR27FilpKQoKipKnTt31rJlyzRw4EB/dgvwn/t2uD9unz0qOnNk/74mlfP2loJc96EpN4PABKBWCwowa9yFrVyOF37YjNVV3Zs5jjWLCdP4eZupgge/OHqyegdwv4agt99+259PD9QcJc0eFd0E1mVpXVbhcrS6zqPAZJJM5sLrl4pfu1SvEWEJQI1U0ka19YLN6tOmoVo1rKf6YUFqEFG4hO/cFvX1r1V79NZ3vysr98z/P0wmz1dqBweYlVdgq1Uru1ExcREhZTfyo2p3TRCAcijpuiPJOSBJxWaRatiGsD5nnLl+qfi4ZBxwnV2SJJmk4L8qzxSfZWIjWgDVhLtNZUvbTHPiwHa6+5K2JW5Cm5aVp0Ppp/XplsNOG3dGhwbq5t4tNaF/WxXYDL23bp++2f2n1v+eprx85+uVyhOqUDOFBVnUIzHG390oFSEIqK1KC0iSy/VHRn6ObAU2mYPDZCpS9Q0lMZw3opXOBKjiRR9U+I/tZZL0kySZJEuQ66xTQAgBCoDXlfe6JXfti99+YlhSicHKYjZp3IWtNO7CViqwGVq/97jW/X5MUuF5z2sZox/3n9DynamavXZfZV8eqqHBHeKqdVEEiRAE1F3Frj/Kt1q1ZMkSDR06VIHzLj9TwU5ynkVimV2FOP+vwHBdpicV3nYToNyejVkoAH7kabByV9xBKgxVvVrHqkdijMtyveiwwjLH6dm1ayPyusPQ9Ms6+LsTZSIEAXBV1odoltr5WflmoUplskhB9Qq/LxqoKBwBoAqUtFxPktOxE1l5mr7YOSyV61oli0m5BazBqwr9EmwKCjD7uxtlIgQBKL+yltrZlVbVzpbPjFJ1YBS4D1TuKu15ik1yAZRDSbNKxY8N6hjvEozumr9ZkkqsgJcQFaIpI5I0MCle6/Yc1ZtLNmjj8UCP9lWKCQ/U1GFJ+jMrT/vTstWsfqjaxUVo0/40SSYFmE165evd5X25tVqnJpG6snmav7vhEUIQAN/x9MMuVe5ql/JsklsmKvcBKOQuLM0yu1a/iwkP1JVdm2hAUrzTtUo9E2N0PNHQm+Mv0Y8HMrV275/648RpSZLJZFJCdIhiwoId1fJKKiDRt32c4/v2CRF6ZNH2Upfu9WpVX9ec10L7j2XV6tDU/6wG+veYblqypGb8oYsQBMD/PJ1Zks7MLkmugSn3pEr+eyBqJs8r9zkXn6gElggCNUZ5q99JJV+nVJnntxd/yLcZOpWTL5PJpJaxhZvZFl0a1j4hwiW0mU2SrYb/r2tcnxaaPLyjrNaacx0XIQhAzVKepVRFA5NEgYdazmt1iLy6RJAiFoCvlbf6nS+e39NQVVJoW7I9RQ/9b6tHy/Skkq+Hig4NUI7Vppx8z85TWfXDAvX0FR01tHPjKnk+byIEAai9yrsc71SqXK5dkqSCPDHDhIrxQhGL4L/aFA1R+TlSvTiXKo8Aqj93oW1El8Ya2inBqZx4z8QYmc0mHc3M0bFTuUo/bZWpWJlx+95NMfXOLOGTpJkr9+jf3+5Vdp73/tjXukG4OjaJVIfGUWoYGVLqksGagBAEAOVZjmdXbJ8lp1kmN8vyit6qmf+7gN+UFKIyDpbz+qpysgSfCVySLAHBGmK1yvJ7A6nraJYFAl5W3mV6pc1+3TugrSb0b+M2VB07lVtixT135cntxSUGd0yo2AurpghBAFAR5fwLvNM+TDPPKVeAAvyi2F5W5oJcBUmF4cuTZYHFQpTj+4Bg6fw7CVGAj3kSqopX3HNXnrwmz/aUhhAEAFWtskuYSp2Fyqx09wCvKL4hsP37gtxyXlvFdVWAr3hanrw2IgQBQE3jretAVj0rrf9X4Qa3xQOVxKa3qCa8uDlwpRDGgNqEEAQAdVVFroXyhLtNcqXC2wVWsdwPNZMPw9hfZdktMjQsL1uWbRbKsgM+RggCAHiXN/8i7q5yn1QYqGwFkmGTPVRRfAI11l9l2c2SzJJUkF+JsuwVZAk+833RjYm5hgu1FCEIAFB9lWO2yqn4RGBgxZ6PJYKoq9xdv2X/vqqCmLdZgiVbvmNPOKcNlS3BUvOeUspWyfrX8sai2yGYLFJQ+Jk/uEiSucjH5qJFP+o1KnxcToZnM+D2DZmLL6uU3C+tLMcfg6qUm+InlvwcDTHMMtebIF3yRNX3qRwIQQAA2Hl7iWA5S6kD8KJif7QwFb8v+duSH2sUuBaaKSiy507Rc2ccKPO5Xc+d4b6tJ0srq8sfY9wUPzFLCpJUYLL4q1ceIwQBAOArlS1iYb++SnL9CzMhCkA1tCthpNpc+KCqewwiBAEAUF35q+JY0fAlSfk5MmSS1TAr0MiTyfDeLvQAao+Cix7RbyeT1MbfHfEAIQgAADhzE77yrVYt9fSaK/s1DDnprjNYeVmOazQA1CKWINkufFBaUjPKxROCAACAd3nr2qqiYUpyDlT5udXn2ggAUkGezGv+KSnJ3z3xCCEIAABUT77ay6oiKHIBlMny7Qy1Sxgpaai/u1ImQhAAAEBZKlvkoiRFyrIbAcGyWq0KNBXIRFl21FBnpyxSwZp2Uv9q8geMEhCCAAAA/KXIbFe5rrvypuq6D42X2V8Bmyl7iZt9gmz5Oco3zLLUgOv+CEEAAAB1WXVadugt9mBnknTOWKnvw44NlYdH7JRlwywp79RfG6AaUkCodMEEqe/D0jfPSz/Nk06nF37ADwiW4jtJ6QdLDoqWgDMpy775qT0cNO1+pthIhYqGmCSTubCvxc9dr5HUdVS1+fkV2IP8RUMpkQ0AAABUqVKCne3CB2UpbalW34cLv6q4X6haZn93AAAAAACqEiEIAAAAQJ1CCAIAAABQpxCCAAAAANQphCAAAAAAdQohCAAAAECdQggCAAAAUKcQggAAAADUKYQgAAAAAHUKIQgAAABAnUIIAgAAAFCnEIIAAAAA1CmEIAAAAAB1CiEIAAAAQJ0S4O8OVIZhGJKkzMxMP/dEslqtys7OVmZmpgIDA/3dnVqH8fU9xti3GF/fY4x9i/H1PcbYtxhf3/P3GNszgT0jlKZGh6CTJ09Kkpo1a+bnngAAAACoDk6ePKmoqKhS25gMT6JSNWWz2XT48GFFRETIZDL5tS+ZmZlq1qyZDh48qMjISL/2pTZifH2PMfYtxtf3GGPfYnx9jzH2LcbX9/w9xoZh6OTJk2rcuLHM5tKv+qnRM0Fms1lNmzb1dzecREZG8ovlQ4yv7zHGvsX4+h5j7FuMr+8xxr7F+PqeP8e4rBkgOwojAAAAAKhTCEEAAAAA6hRCkJcEBwdrypQpCg4O9ndXaiXG1/cYY99ifH2PMfYtxtf3GGPfYnx9ryaNcY0ujAAAAAAA5cVMEAAAAIA6hRAEAAAAoE4hBAEAAACoUwhBAAAAAOoUQpAX/Otf/1JiYqJCQkJ07rnnas2aNf7uUo3w7LPP6rzzzlNERITi4uJ0xRVX6Ndff3VqYxiGpk6dqsaNGys0NFT9+vXTzz//7NQmNzdXd999txo0aKDw8HBddtllOnToUFW+lBrh2Weflclk0sSJEx3HGN/K++OPPzRmzBjFxsYqLCxMXbt21Y8//ui4nzGuuPz8fD3xxBNKTExUaGioWrVqpX/84x+y2WyONoxv+Xz77bcaMWKEGjduLJPJpE8++cTpfm+N54kTJzR27FhFRUUpKipKY8eOVXp6uo9fnf+VNr5Wq1WTJk1Sp06dFB4ersaNG+uGG27Q4cOHnc7B+JaurPdwUX//+99lMpn0yiuvOB1njEvmyfju2rVLl112maKiohQREaHzzz9fBw4ccNxfU8aXEFRJH374oSZOnKjHH39cP/30ky688EINGTLE6c0A97755hvdddddWr9+vZYvX678/HxdeumlysrKcrR5/vnn9dJLL2nmzJnatGmT4uPjNXDgQJ08edLRZuLEifr444+1YMECfffddzp16pSGDx+ugoICf7ysamnTpk1688031blzZ6fjjG/lnDhxQr1791ZgYKCWLl2qnTt36sUXX1R0dLSjDWNccc8995zeeOMNzZw5U7t27dLzzz+vF154Qa+99pqjDeNbPllZWerSpYtmzpzp9n5vjeeoUaO0ZcsWLVu2TMuWLdOWLVs0duxYn78+fyttfLOzs7V582ZNnjxZmzdv1qJFi/Tbb7/psssuc2rH+JaurPew3SeffKINGzaocePGLvcxxiUra3z37t2rPn36qH379lq9erW2bt2qyZMnKyQkxNGmxoyvgUrp0aOHcccddzgda9++vfHII4/4qUc119GjRw1JxjfffGMYhmHYbDYjPj7emDFjhqNNTk6OERUVZbzxxhuGYRhGenq6ERgYaCxYsMDR5o8//jDMZrOxbNmyqn0B1dTJkyeNtm3bGsuXLzf69u1r3HvvvYZhML7eMGnSJKNPnz4l3s8YV86wYcOMW265xenYyJEjjTFjxhiGwfhWliTj448/dtz21nju3LnTkGSsX7/e0WbdunWGJOOXX37x8auqPoqPrzsbN240JBn79+83DIPxLa+SxvjQoUNGkyZNjB07dhgtWrQwXn75Zcd9jLHn3I3vtdde6/g32J2aNL7MBFVCXl6efvzxR1166aVOxy+99FJ9//33fupVzZWRkSFJiomJkSQlJycrNTXVaXyDg4PVt29fx/j++OOPslqtTm0aN26sjh078jP4y1133aVhw4ZpwIABTscZ38r77LPP1L17d1199dWKi4vTOeeco7feestxP2NcOX369NHXX3+t3377TZK0detWfffddxo6dKgkxtfbvDWe69atU1RUlHr27Oloc/755ysqKooxLyYjI0Mmk8kxe8z4Vp7NZtPYsWP10EMPqUOHDi73M8YVZ7PZtHjxYrVr106DBg1SXFycevbs6bRkriaNLyGoEo4dO6aCggI1atTI6XijRo2Umprqp17VTIZh6P7771efPn3UsWNHSXKMYWnjm5qaqqCgINWvX7/ENnXZggULtHnzZj377LMu9zG+lff7779r1qxZatu2rb788kvdcccduueee/Tuu+9KYowra9KkSbr++uvVvn17BQYG6pxzztHEiRN1/fXXS2J8vc1b45mamqq4uDiX88fFxTHmReTk5OiRRx7RqFGjFBkZKYnx9YbnnntOAQEBuueee9zezxhX3NGjR3Xq1CnNmDFDgwcP1ldffaUrr7xSI0eO1DfffCOpZo1vQJU9Uy1mMpmcbhuG4XIMpZswYYK2bdum7777zuW+iowvPwPp4MGDuvfee/XVV185rdUtjvGtOJvNpu7du+uZZ56RJJ1zzjn6+eefNWvWLN1www2OdoxxxXz44YeaN2+e5s+frw4dOmjLli2aOHGiGjdurBtvvNHRjvH1Lm+Mp7v2jPkZVqtV1113nWw2m/71r3+V2Z7x9cyPP/6oV199VZs3by73WDDGZbMXpbn88st13333SZK6du2q77//Xm+88Yb69u1b4mOr4/gyE1QJDRo0kMVicUmtR48edflLGkp2991367PPPtOqVavUtGlTx/H4+HhJKnV84+PjlZeXpxMnTpTYpq768ccfdfToUZ177rkKCAhQQECAvvnmG/3f//2fAgICHOPD+FZcQkKCkpKSnI6dffbZjsIovIcr56GHHtIjjzyi6667Tp06ddLYsWN13333OWY2GV/v8tZ4xsfH68iRIy7n//PPPxlzFQaga665RsnJyVq+fLljFkhifCtrzZo1Onr0qJo3b+74/97+/fv1wAMPqGXLlpIY48po0KCBAgICyvz/Xk0ZX0JQJQQFBencc8/V8uXLnY4vX75cF1xwgZ96VXMYhqEJEyZo0aJFWrlypRITE53uT0xMVHx8vNP45uXl6ZtvvnGM77nnnqvAwECnNikpKdqxY0ed/xlccskl2r59u7Zs2eL46t69u0aPHq0tW7aoVatWjG8l9e7d26Ws+2+//aYWLVpI4j1cWdnZ2TKbnf83ZbFYHH+NZHy9y1vj2atXL2VkZGjjxo2ONhs2bFBGRkadH3N7ANq9e7dWrFih2NhYp/sZ38oZO3astm3b5vT/vcaNG+uhhx7Sl19+KYkxroygoCCdd955pf5/r0aNb5WVYKilFixYYAQGBhpvv/22sXPnTmPixIlGeHi4sW/fPn93rdobP368ERUVZaxevdpISUlxfGVnZzvazJgxw4iKijIWLVpkbN++3bj++uuNhIQEIzMz09HmjjvuMJo2bWqsWLHC2Lx5s9G/f3+jS5cuRn5+vj9eVrVWtDqcYTC+lbVx40YjICDAePrpp43du3cb77//vhEWFmbMmzfP0YYxrrgbb7zRaNKkifHFF18YycnJxqJFi4wGDRoYDz/8sKMN41s+J0+eNH766Sfjp59+MiQZL730kvHTTz85qpN5azwHDx5sdO7c2Vi3bp2xbt06o1OnTsbw4cOr/PVWtdLG12q1GpdddpnRtGlTY8uWLU7/38vNzXWcg/EtXVnv4eKKV4czDMa4NGWN76JFi4zAwEDjzTffNHbv3m289tprhsViMdasWeM4R00ZX0KQF7z++utGixYtjKCgIKNbt26OEs8onSS3X3PmzHG0sdlsxpQpU4z4+HgjODjYuOiii4zt27c7nef06dPGhAkTjJiYGCM0NNQYPny4ceDAgSp+NTVD8RDE+Fbe559/bnTs2NEIDg422rdvb7z55ptO9zPGFZeZmWnce++9RvPmzY2QkBCjVatWxuOPP+70gZHxLZ9Vq1a5/Xf3xhtvNAzDe+N5/PhxY/To0UZERIQRERFhjB492jhx4kQVvUr/KW18k5OTS/z/3qpVqxznYHxLV9Z7uDh3IYgxLpkn4/v2228bbdq0MUJCQowuXboYn3zyidM5asr4mgzDMHw71wQAAAAA1QfXBAEAAACoUwhBAAAAAOoUQhAAAACAOoUQBAAAAKBOIQQBAAAAqFMIQQAAAADqFEIQAAAAgDqFEAQAAACgTiEEAQDqLJPJpE8++cTf3QAAVDFCEADAL2666SaZTCaXr8GDB/u7awCAWi7A3x0AANRdgwcP1pw5c5yOBQcH+6k3AIC6gpkgAIDfBAcHKz4+3umrfv36kgqXqs2aNUtDhgxRaGioEhMT9dFHHzk9fvv27erfv79CQ0MVGxur22+/XadOnXJqM3v2bHXo0EHBwcFKSEjQhAkTnO4/duyYrrzySoWFhalt27b67LPPfPuiAQB+RwgCAFRbkydP1lVXXaWtW7dqzJgxuv7667Vr1y5JUnZ2tgYPHqz69etr06ZN+uijj7RixQqnkDNr1izddddduv3227V9+3Z99tlnatOmjdNzTJs2Tddcc422bdumoUOHavTo0UpLS6vS1wkAqFomwzAMf3cCAFD33HTTTZo3b55CQkKcjk+aNEmTJ0+WyWTSHXfcoVmzZjnuO//889WtWzf961//0ltvvaVJkybp4MGDCg8PlyQtWbJEI0aM0OHDh9WoUSM1adJEN998s5566im3fTCZTHriiSc0ffp0SVJWVpYiIiK0ZMkSrk0CgFqMa4IAAH5z8cUXO4UcSYqJiXF836tXL6f7evXqpS1btkiSdu3apS5dujgCkCT17t1bNptNv/76q0wmkw4fPqxLLrmk1D507tzZ8X14eLgiIiJ09OjRir4kAEANQAgCAPhNeHi4y/K0sphMJkmSYRiO7921CQ0N9eh8gYGBLo+12Wzl6hMAoGbhmiAAQLW1fv16l9vt27eXJCUlJWnLli3Kyspy3L927VqZzWa1a9dOERERatmypb7++usq7TMAoPpjJggA4De5ublKTU11OhYQEKAGDRpIkj766CN1795dffr00fvvv6+NGzfq7bffliSNHj1aU6ZM0Y033qipU6fqzz//1N13362xY8eqUaNGkqSpU6fqjjvuUFxcnIYMGaKTJ09q7dq1uvvuu6v2hQIAqhVCEADAb5YtW6aEhASnY2eddZZ++eUXSYWV2xYsWKA777xT8fHxev/995WUlCRJCgsL05dffql7771X5513nsLCwnTVVVfppZdecpzrxhtvVE5Ojl5++WU9+OCDatCggf72t79V3QsEAFRLVIcDAFRLJpNJH3/8sa644gp/dwUAUMtwTRAAAACAOoUQBAAAAKBO4ZogAEC1xGptAICvMBMEAAAAoE4hBAEAAACoUwhBAAAAAOoUQhAAAACAOoUQBAAAAKBOIQQBAAAAqFMIQQAAAADqFEIQAAAAgDrl/wFo9ifXWSQuiwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_model = SupConNet().to(device)\n",
    "tscl_criterion = SupConLoss(temperature=0.07).to(device)\n",
    "tscl_optimizer = optim.Adam(tscl_model.parameters(), lr=1e-4, weight_decay=1e-5)  # Increased learning rate\n",
    "\n",
    "tscl_patience = 100\n",
    "tscl_best_val_loss = float('inf')\n",
    "tscl_epochs_without_improvement = 0\n",
    "\n",
    "tscl_num_epochs = 2000\n",
    "tscl_train_losses = []\n",
    "tscl_val_losses = []\n",
    "\n",
    "# TRAINING\n",
    "for tscl_epoch in range(tscl_num_epochs):\n",
    "    print(f\"\\nLOG: Epoch [{tscl_epoch + 1}/{tscl_num_epochs}] - Training\")\n",
    "    tscl_model.train()\n",
    "    tscl_total_loss = 0\n",
    "\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_train_loader):\n",
    "        vectors = vectors.to(device).float()  # moving input tensors to GPU\n",
    "        labels = labels.to(device)  # moving labels to GPU\n",
    "\n",
    "        # forward pass to get projections\n",
    "        projections = tscl_model(vectors)\n",
    "\n",
    "        # calc contrastive loss\n",
    "        loss = tscl_criterion(projections, labels)\n",
    "\n",
    "        # backprop and optimization\n",
    "        tscl_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        tscl_optimizer.step()\n",
    "\n",
    "        tscl_total_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 1 == 0:\n",
    "            print(f\"    Batch [{batch_idx + 1}/{len(tscl_train_loader)}], \"\n",
    "                  f\"Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # calc avg training loss for the epoch\n",
    "    tscl_avg_train_loss = tscl_total_loss / len(tscl_train_loader)\n",
    "    tscl_train_losses.append(tscl_avg_train_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {tscl_avg_train_loss:.4f}\")\n",
    "\n",
    "    # VALIDATION\n",
    "    tscl_model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (vectors, labels) in enumerate(tscl_val_loader):\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            projections = tscl_model(vectors)\n",
    "\n",
    "            loss = tscl_criterion(projections, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"    Batch [{batch_idx + 1}/{len(tscl_val_loader)}], \"\n",
    "                      f\"Val Loss: {loss.item():.4f}\")\n",
    "\n",
    "    tscl_avg_val_loss = total_val_loss / len(tscl_val_loader)\n",
    "    tscl_val_losses.append(tscl_avg_val_loss)\n",
    "    print(f\"Epoch [{tscl_epoch + 1}/{tscl_num_epochs}], \"\n",
    "          f\"Avg Val Loss: {tscl_avg_val_loss:.4f}\")\n",
    "\n",
    "    # early stopping logic\n",
    "    if tscl_avg_val_loss < tscl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_best_val_loss:.4f} to {tscl_avg_val_loss:.4f}. Saving model...\")\n",
    "        tscl_best_val_loss = tscl_avg_val_loss\n",
    "        tscl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        tscl_epochs_without_improvement += 1\n",
    "        print(f\"Validation loss did not improve. Patience: {tscl_epochs_without_improvement}/{tscl_patience}\")\n",
    "\n",
    "    # stopping training if validation loss hasn't improved for patience amount of epochs\n",
    "    if tscl_epochs_without_improvement >= tscl_patience:\n",
    "        print(f\"Early stopping triggered at epoch {tscl_epoch + 1}. No improvement for {tscl_patience} epochs.\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(tscl_train_losses) + 1), tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(1, len(tscl_val_losses) + 1), tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:42:07.503387Z",
     "iopub.status.busy": "2025-05-08T18:42:07.503387Z",
     "iopub.status.idle": "2025-05-08T18:42:07.625972Z",
     "shell.execute_reply": "2025-05-08T18:42:07.625972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/12], Loss: 5.2721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 4.9221\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "tscl_model.eval()\n",
    "total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(tscl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = tscl_model(vectors)\n",
    "        loss = criterion(projections, labels)\n",
    "        total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(tscl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "avg_test_loss = total_test_loss / len(tscl_test_loader)\n",
    "print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs = range(1, len(tscl_train_losses) + 1)\n",
    "plt.plot(epochs, tscl_train_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(epochs, tscl_val_losses, label=\"Validation Loss\", marker='x')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving representations learnt by Typical SCL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:42:07.628277Z",
     "iopub.status.busy": "2025-05-08T18:42:07.628277Z",
     "iopub.status.idle": "2025-05-08T18:42:07.688224Z",
     "shell.execute_reply": "2025-05-08T18:42:07.688224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'tscl_representations\\train'.\n",
      "\n",
      "Extracting SCL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'tscl_representations\\val'.\n",
      "\n",
      "Extracting SCL representations for the test dataset...\n",
      "  Processed batch 10/12 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'tscl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "tscl_rep_dir = \"tscl_representations\"\n",
    "os.makedirs(tscl_rep_dir, exist_ok=True)\n",
    "\n",
    "tscl_loaders = {\n",
    "    'train': tscl_train_loader,\n",
    "    'val': tscl_val_loader,\n",
    "    'test': tscl_test_loader\n",
    "}\n",
    "\n",
    "tscl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_split_name, tscl_loader in tscl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL representations for the {tscl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        tscl_split_dir = os.path.join(tscl_rep_dir, tscl_split_name)\n",
    "        os.makedirs(tscl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for tscl_batch_idx, (tscl_vectors, tscl_labels) in enumerate(tscl_loader):\n",
    "            tscl_vectors = tscl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            tscl_projections = tscl_model(tscl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            tscl_projections_np = tscl_projections.cpu().numpy()\n",
    "            tscl_labels_np = tscl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_encoded_batch_{tscl_batch_idx}.npy\"), tscl_projections_np)\n",
    "            np.save(os.path.join(tscl_split_dir, f\"scl_labels_batch_{tscl_batch_idx}.npy\"), tscl_labels_np)\n",
    "            \n",
    "            if (tscl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {tscl_batch_idx + 1}/{len(tscl_loader)} for {tscl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {tscl_split_name} dataset. Representations saved in '{tscl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying representations learnt by SCL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:42:07.690242Z",
     "iopub.status.busy": "2025-05-08T18:42:07.690242Z",
     "iopub.status.idle": "2025-05-08T18:42:07.694240Z",
     "shell.execute_reply": "2025-05-08T18:42:07.694240Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_tscl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    tscl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    tscl_all_reps = []\n",
    "    tscl_all_labels = []\n",
    "\n",
    "    for tscl_rep_file in tscl_rep_files:\n",
    "        #deriving label filenames\n",
    "        tscl_label_file = tscl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        tscl_reps = np.load(tscl_rep_file)\n",
    "        tscl_labels = np.load(tscl_label_file)\n",
    "\n",
    "        tscl_all_reps.append(tscl_reps)\n",
    "        tscl_all_labels.append(tscl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    tscl_all_reps = np.concatenate(tscl_all_reps, axis = 0)\n",
    "    tscl_all_labels = np.concatenate(tscl_all_labels, axis = 0)\n",
    "\n",
    "    return tscl_all_reps, tscl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:42:07.695976Z",
     "iopub.status.busy": "2025-05-08T18:42:07.695976Z",
     "iopub.status.idle": "2025-05-08T18:42:07.850618Z",
     "shell.execute_reply": "2025-05-08T18:42:07.850618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (140, 128)\n",
      "Train labels shape: (140,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (3038, 128)\n",
      "Test labels shape: (3038,)\n"
     ]
    }
   ],
   "source": [
    "tscl_lrm_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_lrm_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_lrm_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_lrm_train_reps, tscl_lrm_train_labels = load_tscl_reps_and_labels(tscl_lrm_train_dir)\n",
    "tscl_lrm_val_reps, tscl_lrm_val_labels = load_tscl_reps_and_labels(tscl_lrm_val_dir)\n",
    "tscl_lrm_test_reps, tscl_lrm_test_labels = load_tscl_reps_and_labels(tscl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", tscl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:42:07.853626Z",
     "iopub.status.busy": "2025-05-08T18:42:07.852627Z",
     "iopub.status.idle": "2025-05-08T18:42:07.887332Z",
     "shell.execute_reply": "2025-05-08T18:42:07.887332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 81.43%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      0.80      0.89         5\n",
      "           2       1.00      0.60      0.75         5\n",
      "           3       0.71      1.00      0.83         5\n",
      "           4       1.00      0.60      0.75         5\n",
      "           5       0.40      0.40      0.40         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.62      1.00      0.77         5\n",
      "           8       0.60      0.60      0.60         5\n",
      "           9       0.83      1.00      0.91         5\n",
      "          10       1.00      0.60      0.75         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       0.67      0.80      0.73         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.81        70\n",
      "   macro avg       0.85      0.81      0.81        70\n",
      "weighted avg       0.85      0.81      0.81        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 82.98%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       255\n",
      "           1       0.90      0.84      0.87        86\n",
      "           2       0.81      0.88      0.84       236\n",
      "           3       0.76      0.91      0.83       200\n",
      "           4       0.87      0.66      0.75       254\n",
      "           5       0.71      0.57      0.63       254\n",
      "           6       0.99      0.86      0.92       244\n",
      "           7       0.76      0.91      0.83       188\n",
      "           8       0.76      0.71      0.74       299\n",
      "           9       0.72      0.96      0.82       233\n",
      "          10       0.98      0.84      0.91       290\n",
      "          11       0.91      0.95      0.93       166\n",
      "          12       0.69      0.78      0.73       253\n",
      "          13       1.00      0.96      0.98        80\n",
      "\n",
      "    accuracy                           0.83      3038\n",
      "   macro avg       0.85      0.84      0.84      3038\n",
      "weighted avg       0.84      0.83      0.83      3038\n",
      "\n",
      "Saved CAE+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# training LRM on the tscl representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "tscl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "tscl_logistic_clf.fit(tscl_lrm_train_reps, tscl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# eval on val set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "tscl_lrm_val_predictions = tscl_logistic_clf.predict(tscl_lrm_val_reps)\n",
    "tscl_lrm_val_accuracy = accuracy_score(tscl_lrm_val_labels, tscl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {tscl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(tscl_lrm_val_labels, tscl_lrm_val_predictions))\n",
    "\n",
    "# eval on test\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "tscl_lrm_test_predictions = tscl_logistic_clf.predict(tscl_lrm_test_reps)\n",
    "tscl_lrm_test_accuracy = accuracy_score(tscl_lrm_test_labels, tscl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {tscl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(tscl_lrm_test_labels, tscl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_predictions.npy'), tscl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'tscl_lrm_true_labels.npy'), tscl_lrm_test_labels)\n",
    "print(f\"Saved CAE+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by Typical SCL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:42:07.889337Z",
     "iopub.status.busy": "2025-05-08T18:42:07.889337Z",
     "iopub.status.idle": "2025-05-08T18:42:07.893629Z",
     "shell.execute_reply": "2025-05-08T18:42:07.893629Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules(): \n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:42:07.896142Z",
     "iopub.status.busy": "2025-05-08T18:42:07.896142Z",
     "iopub.status.idle": "2025-05-08T18:42:07.906641Z",
     "shell.execute_reply": "2025-05-08T18:42:07.906641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (140, 128)\n",
      "Train labels shape: (140,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (3038, 128)\n",
      "Test labels shape: (3038,)\n"
     ]
    }
   ],
   "source": [
    "tscl_mlp_train_dir = os.path.join(\"tscl_representations\", \"train\")\n",
    "tscl_mlp_val_dir   = os.path.join(\"tscl_representations\", \"val\")\n",
    "tscl_mlp_test_dir  = os.path.join(\"tscl_representations\", \"test\")\n",
    "\n",
    "tscl_mlp_train_reps, tscl_mlp_train_labels = load_tscl_reps_and_labels(tscl_mlp_train_dir)\n",
    "tscl_mlp_val_reps, tscl_mlp_val_labels = load_tscl_reps_and_labels(tscl_mlp_val_dir)\n",
    "tscl_mlp_test_reps, tscl_mlp_test_labels = load_tscl_reps_and_labels(tscl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\",tscl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", tscl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", tscl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", tscl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", tscl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", tscl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:42:07.909652Z",
     "iopub.status.busy": "2025-05-08T18:42:07.909652Z",
     "iopub.status.idle": "2025-05-08T18:42:07.915152Z",
     "shell.execute_reply": "2025-05-08T18:42:07.914650Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "tscl_mlp_train_embeddings_torch = torch.tensor(tscl_mlp_train_reps, dtype=torch.float32)\n",
    "tscl_mlp_train_labels_torch = torch.tensor(tscl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_val_embeddings_torch = torch.tensor(tscl_mlp_val_reps, dtype=torch.float32)\n",
    "tscl_mlp_val_labels_torch = torch.tensor(tscl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "tscl_mlp_test_embeddings_torch = torch.tensor(tscl_mlp_test_reps, dtype=torch.float32)\n",
    "tscl_mlp_test_labels_torch = torch.tensor(tscl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "tscl_mlp_train_dataset = TensorDataset(tscl_mlp_train_embeddings_torch, tscl_mlp_train_labels_torch)\n",
    "tscl_mlp_val_dataset = TensorDataset(tscl_mlp_val_embeddings_torch, tscl_mlp_val_labels_torch)\n",
    "tscl_mlp_test_dataset = TensorDataset(tscl_mlp_test_embeddings_torch, tscl_mlp_test_labels_torch)\n",
    "\n",
    "tscl_mlp_batch_size = 64\n",
    "tscl_mlp_train_loader = DataLoader(tscl_mlp_train_dataset, batch_size=tscl_mlp_batch_size, shuffle=True)\n",
    "tscl_mlp_val_loader = DataLoader(tscl_mlp_val_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n",
    "tscl_mlp_test_loader = DataLoader(tscl_mlp_test_dataset, batch_size=tscl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:42:07.917161Z",
     "iopub.status.busy": "2025-05-08T18:42:07.917161Z",
     "iopub.status.idle": "2025-05-08T18:42:11.362238Z",
     "shell.execute_reply": "2025-05-08T18:42:11.362238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.6964  |  Val Loss: 2.6712\n",
      "Validation loss improved from inf to 2.6712.\n",
      "[Epoch 2/1000] Train Loss: 2.6645  |  Val Loss: 2.6469\n",
      "Validation loss improved from 2.6712 to 2.6469.\n",
      "[Epoch 3/1000] Train Loss: 2.6359  |  Val Loss: 2.6234\n",
      "Validation loss improved from 2.6469 to 2.6234.\n",
      "[Epoch 4/1000] Train Loss: 2.6101  |  Val Loss: 2.6017\n",
      "Validation loss improved from 2.6234 to 2.6017.\n",
      "[Epoch 5/1000] Train Loss: 2.5832  |  Val Loss: 2.5826\n",
      "Validation loss improved from 2.6017 to 2.5826.\n",
      "[Epoch 6/1000] Train Loss: 2.5600  |  Val Loss: 2.5654\n",
      "Validation loss improved from 2.5826 to 2.5654.\n",
      "[Epoch 7/1000] Train Loss: 2.5386  |  Val Loss: 2.5490\n",
      "Validation loss improved from 2.5654 to 2.5490.\n",
      "[Epoch 8/1000] Train Loss: 2.5198  |  Val Loss: 2.5323\n",
      "Validation loss improved from 2.5490 to 2.5323.\n",
      "[Epoch 9/1000] Train Loss: 2.5014  |  Val Loss: 2.5162\n",
      "Validation loss improved from 2.5323 to 2.5162.\n",
      "[Epoch 10/1000] Train Loss: 2.4832  |  Val Loss: 2.5005\n",
      "Validation loss improved from 2.5162 to 2.5005.\n",
      "[Epoch 11/1000] Train Loss: 2.4638  |  Val Loss: 2.4854\n",
      "Validation loss improved from 2.5005 to 2.4854.\n",
      "[Epoch 12/1000] Train Loss: 2.4469  |  Val Loss: 2.4702\n",
      "Validation loss improved from 2.4854 to 2.4702.\n",
      "[Epoch 13/1000] Train Loss: 2.4298  |  Val Loss: 2.4558\n",
      "Validation loss improved from 2.4702 to 2.4558.\n",
      "[Epoch 14/1000] Train Loss: 2.4137  |  Val Loss: 2.4415\n",
      "Validation loss improved from 2.4558 to 2.4415.\n",
      "[Epoch 15/1000] Train Loss: 2.3960  |  Val Loss: 2.4278\n",
      "Validation loss improved from 2.4415 to 2.4278.\n",
      "[Epoch 16/1000] Train Loss: 2.3812  |  Val Loss: 2.4138\n",
      "Validation loss improved from 2.4278 to 2.4138.\n",
      "[Epoch 17/1000] Train Loss: 2.3654  |  Val Loss: 2.4003\n",
      "Validation loss improved from 2.4138 to 2.4003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/1000] Train Loss: 2.3504  |  Val Loss: 2.3868\n",
      "Validation loss improved from 2.4003 to 2.3868.\n",
      "[Epoch 19/1000] Train Loss: 2.3366  |  Val Loss: 2.3738\n",
      "Validation loss improved from 2.3868 to 2.3738.\n",
      "[Epoch 20/1000] Train Loss: 2.3227  |  Val Loss: 2.3616\n",
      "Validation loss improved from 2.3738 to 2.3616.\n",
      "[Epoch 21/1000] Train Loss: 2.3094  |  Val Loss: 2.3501\n",
      "Validation loss improved from 2.3616 to 2.3501.\n",
      "[Epoch 22/1000] Train Loss: 2.2966  |  Val Loss: 2.3391\n",
      "Validation loss improved from 2.3501 to 2.3391.\n",
      "[Epoch 23/1000] Train Loss: 2.2847  |  Val Loss: 2.3283\n",
      "Validation loss improved from 2.3391 to 2.3283.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/1000] Train Loss: 2.2730  |  Val Loss: 2.3176\n",
      "Validation loss improved from 2.3283 to 2.3176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/1000] Train Loss: 2.2606  |  Val Loss: 2.3069\n",
      "Validation loss improved from 2.3176 to 2.3069.\n",
      "[Epoch 26/1000] Train Loss: 2.2494  |  Val Loss: 2.2964\n",
      "Validation loss improved from 2.3069 to 2.2964.\n",
      "[Epoch 27/1000] Train Loss: 2.2378  |  Val Loss: 2.2862\n",
      "Validation loss improved from 2.2964 to 2.2862.\n",
      "[Epoch 28/1000] Train Loss: 2.2262  |  Val Loss: 2.2759\n",
      "Validation loss improved from 2.2862 to 2.2759.\n",
      "[Epoch 29/1000] Train Loss: 2.2147  |  Val Loss: 2.2657\n",
      "Validation loss improved from 2.2759 to 2.2657.\n",
      "[Epoch 30/1000] Train Loss: 2.2037  |  Val Loss: 2.2557\n",
      "Validation loss improved from 2.2657 to 2.2557.\n",
      "[Epoch 31/1000] Train Loss: 2.1921  |  Val Loss: 2.2462\n",
      "Validation loss improved from 2.2557 to 2.2462.\n",
      "[Epoch 32/1000] Train Loss: 2.1813  |  Val Loss: 2.2368\n",
      "Validation loss improved from 2.2462 to 2.2368.\n",
      "[Epoch 33/1000] Train Loss: 2.1706  |  Val Loss: 2.2274\n",
      "Validation loss improved from 2.2368 to 2.2274.\n",
      "[Epoch 34/1000] Train Loss: 2.1597  |  Val Loss: 2.2181\n",
      "Validation loss improved from 2.2274 to 2.2181.\n",
      "[Epoch 35/1000] Train Loss: 2.1492  |  Val Loss: 2.2089\n",
      "Validation loss improved from 2.2181 to 2.2089.\n",
      "[Epoch 36/1000] Train Loss: 2.1384  |  Val Loss: 2.2001\n",
      "Validation loss improved from 2.2089 to 2.2001.\n",
      "[Epoch 37/1000] Train Loss: 2.1282  |  Val Loss: 2.1912\n",
      "Validation loss improved from 2.2001 to 2.1912.\n",
      "[Epoch 38/1000] Train Loss: 2.1176  |  Val Loss: 2.1823\n",
      "Validation loss improved from 2.1912 to 2.1823.\n",
      "[Epoch 39/1000] Train Loss: 2.1077  |  Val Loss: 2.1734\n",
      "Validation loss improved from 2.1823 to 2.1734.\n",
      "[Epoch 40/1000] Train Loss: 2.0970  |  Val Loss: 2.1649\n",
      "Validation loss improved from 2.1734 to 2.1649.\n",
      "[Epoch 41/1000] Train Loss: 2.0869  |  Val Loss: 2.1564\n",
      "Validation loss improved from 2.1649 to 2.1564.\n",
      "[Epoch 42/1000] Train Loss: 2.0770  |  Val Loss: 2.1481\n",
      "Validation loss improved from 2.1564 to 2.1481.\n",
      "[Epoch 43/1000] Train Loss: 2.0666  |  Val Loss: 2.1397\n",
      "Validation loss improved from 2.1481 to 2.1397.\n",
      "[Epoch 44/1000] Train Loss: 2.0564  |  Val Loss: 2.1317\n",
      "Validation loss improved from 2.1397 to 2.1317.\n",
      "[Epoch 45/1000] Train Loss: 2.0463  |  Val Loss: 2.1237\n",
      "Validation loss improved from 2.1317 to 2.1237.\n",
      "[Epoch 46/1000] Train Loss: 2.0362  |  Val Loss: 2.1158\n",
      "Validation loss improved from 2.1237 to 2.1158.\n",
      "[Epoch 47/1000] Train Loss: 2.0263  |  Val Loss: 2.1078\n",
      "Validation loss improved from 2.1158 to 2.1078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 48/1000] Train Loss: 2.0165  |  Val Loss: 2.1000\n",
      "Validation loss improved from 2.1078 to 2.1000.\n",
      "[Epoch 49/1000] Train Loss: 2.0066  |  Val Loss: 2.0922\n",
      "Validation loss improved from 2.1000 to 2.0922.\n",
      "[Epoch 50/1000] Train Loss: 1.9966  |  Val Loss: 2.0846\n",
      "Validation loss improved from 2.0922 to 2.0846.\n",
      "[Epoch 51/1000] Train Loss: 1.9867  |  Val Loss: 2.0771\n",
      "Validation loss improved from 2.0846 to 2.0771.\n",
      "[Epoch 52/1000] Train Loss: 1.9771  |  Val Loss: 2.0695\n",
      "Validation loss improved from 2.0771 to 2.0695.\n",
      "[Epoch 53/1000] Train Loss: 1.9674  |  Val Loss: 2.0619\n",
      "Validation loss improved from 2.0695 to 2.0619.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 54/1000] Train Loss: 1.9579  |  Val Loss: 2.0543\n",
      "Validation loss improved from 2.0619 to 2.0543.\n",
      "[Epoch 55/1000] Train Loss: 1.9483  |  Val Loss: 2.0467\n",
      "Validation loss improved from 2.0543 to 2.0467.\n",
      "[Epoch 56/1000] Train Loss: 1.9390  |  Val Loss: 2.0392\n",
      "Validation loss improved from 2.0467 to 2.0392.\n",
      "[Epoch 57/1000] Train Loss: 1.9297  |  Val Loss: 2.0320\n",
      "Validation loss improved from 2.0392 to 2.0320.\n",
      "[Epoch 58/1000] Train Loss: 1.9197  |  Val Loss: 2.0248\n",
      "Validation loss improved from 2.0320 to 2.0248.\n",
      "[Epoch 59/1000] Train Loss: 1.9104  |  Val Loss: 2.0176\n",
      "Validation loss improved from 2.0248 to 2.0176.\n",
      "[Epoch 60/1000] Train Loss: 1.9007  |  Val Loss: 2.0104\n",
      "Validation loss improved from 2.0176 to 2.0104.\n",
      "[Epoch 61/1000] Train Loss: 1.8908  |  Val Loss: 2.0031\n",
      "Validation loss improved from 2.0104 to 2.0031.\n",
      "[Epoch 62/1000] Train Loss: 1.8818  |  Val Loss: 1.9958\n",
      "Validation loss improved from 2.0031 to 1.9958.\n",
      "[Epoch 63/1000] Train Loss: 1.8722  |  Val Loss: 1.9884\n",
      "Validation loss improved from 1.9958 to 1.9884.\n",
      "[Epoch 64/1000] Train Loss: 1.8630  |  Val Loss: 1.9813\n",
      "Validation loss improved from 1.9884 to 1.9813.\n",
      "[Epoch 65/1000] Train Loss: 1.8535  |  Val Loss: 1.9743\n",
      "Validation loss improved from 1.9813 to 1.9743.\n",
      "[Epoch 66/1000] Train Loss: 1.8448  |  Val Loss: 1.9676\n",
      "Validation loss improved from 1.9743 to 1.9676.\n",
      "[Epoch 67/1000] Train Loss: 1.8354  |  Val Loss: 1.9608\n",
      "Validation loss improved from 1.9676 to 1.9608.\n",
      "[Epoch 68/1000] Train Loss: 1.8267  |  Val Loss: 1.9540\n",
      "Validation loss improved from 1.9608 to 1.9540.\n",
      "[Epoch 69/1000] Train Loss: 1.8178  |  Val Loss: 1.9469\n",
      "Validation loss improved from 1.9540 to 1.9469.\n",
      "[Epoch 70/1000] Train Loss: 1.8090  |  Val Loss: 1.9399\n",
      "Validation loss improved from 1.9469 to 1.9399.\n",
      "[Epoch 71/1000] Train Loss: 1.8005  |  Val Loss: 1.9329\n",
      "Validation loss improved from 1.9399 to 1.9329.\n",
      "[Epoch 72/1000] Train Loss: 1.7914  |  Val Loss: 1.9256\n",
      "Validation loss improved from 1.9329 to 1.9256.\n",
      "[Epoch 73/1000] Train Loss: 1.7831  |  Val Loss: 1.9183\n",
      "Validation loss improved from 1.9256 to 1.9183.\n",
      "[Epoch 74/1000] Train Loss: 1.7743  |  Val Loss: 1.9111\n",
      "Validation loss improved from 1.9183 to 1.9111.\n",
      "[Epoch 75/1000] Train Loss: 1.7658  |  Val Loss: 1.9042\n",
      "Validation loss improved from 1.9111 to 1.9042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 76/1000] Train Loss: 1.7572  |  Val Loss: 1.8974\n",
      "Validation loss improved from 1.9042 to 1.8974.\n",
      "[Epoch 77/1000] Train Loss: 1.7486  |  Val Loss: 1.8909\n",
      "Validation loss improved from 1.8974 to 1.8909.\n",
      "[Epoch 78/1000] Train Loss: 1.7400  |  Val Loss: 1.8843\n",
      "Validation loss improved from 1.8909 to 1.8843.\n",
      "[Epoch 79/1000] Train Loss: 1.7312  |  Val Loss: 1.8778\n",
      "Validation loss improved from 1.8843 to 1.8778.\n",
      "[Epoch 80/1000] Train Loss: 1.7227  |  Val Loss: 1.8713\n",
      "Validation loss improved from 1.8778 to 1.8713.\n",
      "[Epoch 81/1000] Train Loss: 1.7136  |  Val Loss: 1.8645\n",
      "Validation loss improved from 1.8713 to 1.8645.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 82/1000] Train Loss: 1.7052  |  Val Loss: 1.8575\n",
      "Validation loss improved from 1.8645 to 1.8575.\n",
      "[Epoch 83/1000] Train Loss: 1.6963  |  Val Loss: 1.8505\n",
      "Validation loss improved from 1.8575 to 1.8505.\n",
      "[Epoch 84/1000] Train Loss: 1.6877  |  Val Loss: 1.8438\n",
      "Validation loss improved from 1.8505 to 1.8438.\n",
      "[Epoch 85/1000] Train Loss: 1.6796  |  Val Loss: 1.8374\n",
      "Validation loss improved from 1.8438 to 1.8374.\n",
      "[Epoch 86/1000] Train Loss: 1.6706  |  Val Loss: 1.8308\n",
      "Validation loss improved from 1.8374 to 1.8308.\n",
      "[Epoch 87/1000] Train Loss: 1.6623  |  Val Loss: 1.8243\n",
      "Validation loss improved from 1.8308 to 1.8243.\n",
      "[Epoch 88/1000] Train Loss: 1.6539  |  Val Loss: 1.8180\n",
      "Validation loss improved from 1.8243 to 1.8180.\n",
      "[Epoch 89/1000] Train Loss: 1.6455  |  Val Loss: 1.8116\n",
      "Validation loss improved from 1.8180 to 1.8116.\n",
      "[Epoch 90/1000] Train Loss: 1.6367  |  Val Loss: 1.8050\n",
      "Validation loss improved from 1.8116 to 1.8050.\n",
      "[Epoch 91/1000] Train Loss: 1.6282  |  Val Loss: 1.7981\n",
      "Validation loss improved from 1.8050 to 1.7981.\n",
      "[Epoch 92/1000] Train Loss: 1.6197  |  Val Loss: 1.7909\n",
      "Validation loss improved from 1.7981 to 1.7909.\n",
      "[Epoch 93/1000] Train Loss: 1.6109  |  Val Loss: 1.7840\n",
      "Validation loss improved from 1.7909 to 1.7840.\n",
      "[Epoch 94/1000] Train Loss: 1.6025  |  Val Loss: 1.7772\n",
      "Validation loss improved from 1.7840 to 1.7772.\n",
      "[Epoch 95/1000] Train Loss: 1.5936  |  Val Loss: 1.7705\n",
      "Validation loss improved from 1.7772 to 1.7705.\n",
      "[Epoch 96/1000] Train Loss: 1.5851  |  Val Loss: 1.7638\n",
      "Validation loss improved from 1.7705 to 1.7638.\n",
      "[Epoch 97/1000] Train Loss: 1.5765  |  Val Loss: 1.7570\n",
      "Validation loss improved from 1.7638 to 1.7570.\n",
      "[Epoch 98/1000] Train Loss: 1.5678  |  Val Loss: 1.7501\n",
      "Validation loss improved from 1.7570 to 1.7501.\n",
      "[Epoch 99/1000] Train Loss: 1.5591  |  Val Loss: 1.7432\n",
      "Validation loss improved from 1.7501 to 1.7432.\n",
      "[Epoch 100/1000] Train Loss: 1.5499  |  Val Loss: 1.7364\n",
      "Validation loss improved from 1.7432 to 1.7364.\n",
      "[Epoch 101/1000] Train Loss: 1.5409  |  Val Loss: 1.7292\n",
      "Validation loss improved from 1.7364 to 1.7292.\n",
      "[Epoch 102/1000] Train Loss: 1.5320  |  Val Loss: 1.7218\n",
      "Validation loss improved from 1.7292 to 1.7218.\n",
      "[Epoch 103/1000] Train Loss: 1.5230  |  Val Loss: 1.7146\n",
      "Validation loss improved from 1.7218 to 1.7146.\n",
      "[Epoch 104/1000] Train Loss: 1.5140  |  Val Loss: 1.7077\n",
      "Validation loss improved from 1.7146 to 1.7077.\n",
      "[Epoch 105/1000] Train Loss: 1.5058  |  Val Loss: 1.7009\n",
      "Validation loss improved from 1.7077 to 1.7009.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 106/1000] Train Loss: 1.4963  |  Val Loss: 1.6939\n",
      "Validation loss improved from 1.7009 to 1.6939.\n",
      "[Epoch 107/1000] Train Loss: 1.4874  |  Val Loss: 1.6870\n",
      "Validation loss improved from 1.6939 to 1.6870.\n",
      "[Epoch 108/1000] Train Loss: 1.4787  |  Val Loss: 1.6803\n",
      "Validation loss improved from 1.6870 to 1.6803.\n",
      "[Epoch 109/1000] Train Loss: 1.4699  |  Val Loss: 1.6736\n",
      "Validation loss improved from 1.6803 to 1.6736.\n",
      "[Epoch 110/1000] Train Loss: 1.4610  |  Val Loss: 1.6668\n",
      "Validation loss improved from 1.6736 to 1.6668.\n",
      "[Epoch 111/1000] Train Loss: 1.4525  |  Val Loss: 1.6600\n",
      "Validation loss improved from 1.6668 to 1.6600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 112/1000] Train Loss: 1.4438  |  Val Loss: 1.6535\n",
      "Validation loss improved from 1.6600 to 1.6535.\n",
      "[Epoch 113/1000] Train Loss: 1.4355  |  Val Loss: 1.6472\n",
      "Validation loss improved from 1.6535 to 1.6472.\n",
      "[Epoch 114/1000] Train Loss: 1.4270  |  Val Loss: 1.6408\n",
      "Validation loss improved from 1.6472 to 1.6408.\n",
      "[Epoch 115/1000] Train Loss: 1.4183  |  Val Loss: 1.6342\n",
      "Validation loss improved from 1.6408 to 1.6342.\n",
      "[Epoch 116/1000] Train Loss: 1.4095  |  Val Loss: 1.6276\n",
      "Validation loss improved from 1.6342 to 1.6276.\n",
      "[Epoch 117/1000] Train Loss: 1.4009  |  Val Loss: 1.6208\n",
      "Validation loss improved from 1.6276 to 1.6208.\n",
      "[Epoch 118/1000] Train Loss: 1.3923  |  Val Loss: 1.6140\n",
      "Validation loss improved from 1.6208 to 1.6140.\n",
      "[Epoch 119/1000] Train Loss: 1.3836  |  Val Loss: 1.6071\n",
      "Validation loss improved from 1.6140 to 1.6071.\n",
      "[Epoch 120/1000] Train Loss: 1.3750  |  Val Loss: 1.6002\n",
      "Validation loss improved from 1.6071 to 1.6002.\n",
      "[Epoch 121/1000] Train Loss: 1.3664  |  Val Loss: 1.5933\n",
      "Validation loss improved from 1.6002 to 1.5933.\n",
      "[Epoch 122/1000] Train Loss: 1.3578  |  Val Loss: 1.5861\n",
      "Validation loss improved from 1.5933 to 1.5861.\n",
      "[Epoch 123/1000] Train Loss: 1.3488  |  Val Loss: 1.5790\n",
      "Validation loss improved from 1.5861 to 1.5790.\n",
      "[Epoch 124/1000] Train Loss: 1.3401  |  Val Loss: 1.5721\n",
      "Validation loss improved from 1.5790 to 1.5721.\n",
      "[Epoch 125/1000] Train Loss: 1.3314  |  Val Loss: 1.5652\n",
      "Validation loss improved from 1.5721 to 1.5652.\n",
      "[Epoch 126/1000] Train Loss: 1.3225  |  Val Loss: 1.5582\n",
      "Validation loss improved from 1.5652 to 1.5582.\n",
      "[Epoch 127/1000] Train Loss: 1.3136  |  Val Loss: 1.5511\n",
      "Validation loss improved from 1.5582 to 1.5511.\n",
      "[Epoch 128/1000] Train Loss: 1.3052  |  Val Loss: 1.5442\n",
      "Validation loss improved from 1.5511 to 1.5442.\n",
      "[Epoch 129/1000] Train Loss: 1.2964  |  Val Loss: 1.5373\n",
      "Validation loss improved from 1.5442 to 1.5373.\n",
      "[Epoch 130/1000] Train Loss: 1.2880  |  Val Loss: 1.5303\n",
      "Validation loss improved from 1.5373 to 1.5303.\n",
      "[Epoch 131/1000] Train Loss: 1.2792  |  Val Loss: 1.5235\n",
      "Validation loss improved from 1.5303 to 1.5235.\n",
      "[Epoch 132/1000] Train Loss: 1.2706  |  Val Loss: 1.5169\n",
      "Validation loss improved from 1.5235 to 1.5169.\n",
      "[Epoch 133/1000] Train Loss: 1.2619  |  Val Loss: 1.5105\n",
      "Validation loss improved from 1.5169 to 1.5105.\n",
      "[Epoch 134/1000] Train Loss: 1.2533  |  Val Loss: 1.5042\n",
      "Validation loss improved from 1.5105 to 1.5042.\n",
      "[Epoch 135/1000] Train Loss: 1.2444  |  Val Loss: 1.4981\n",
      "Validation loss improved from 1.5042 to 1.4981.\n",
      "[Epoch 136/1000] Train Loss: 1.2358  |  Val Loss: 1.4919\n",
      "Validation loss improved from 1.4981 to 1.4919.\n",
      "[Epoch 137/1000] Train Loss: 1.2272  |  Val Loss: 1.4860\n",
      "Validation loss improved from 1.4919 to 1.4860.\n",
      "[Epoch 138/1000] Train Loss: 1.2185  |  Val Loss: 1.4798\n",
      "Validation loss improved from 1.4860 to 1.4798.\n",
      "[Epoch 139/1000] Train Loss: 1.2099  |  Val Loss: 1.4733\n",
      "Validation loss improved from 1.4798 to 1.4733.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 140/1000] Train Loss: 1.2010  |  Val Loss: 1.4663\n",
      "Validation loss improved from 1.4733 to 1.4663.\n",
      "[Epoch 141/1000] Train Loss: 1.1925  |  Val Loss: 1.4590\n",
      "Validation loss improved from 1.4663 to 1.4590.\n",
      "[Epoch 142/1000] Train Loss: 1.1836  |  Val Loss: 1.4514\n",
      "Validation loss improved from 1.4590 to 1.4514.\n",
      "[Epoch 143/1000] Train Loss: 1.1748  |  Val Loss: 1.4437\n",
      "Validation loss improved from 1.4514 to 1.4437.\n",
      "[Epoch 144/1000] Train Loss: 1.1661  |  Val Loss: 1.4363\n",
      "Validation loss improved from 1.4437 to 1.4363.\n",
      "[Epoch 145/1000] Train Loss: 1.1578  |  Val Loss: 1.4292\n",
      "Validation loss improved from 1.4363 to 1.4292.\n",
      "[Epoch 146/1000] Train Loss: 1.1490  |  Val Loss: 1.4224\n",
      "Validation loss improved from 1.4292 to 1.4224.\n",
      "[Epoch 147/1000] Train Loss: 1.1409  |  Val Loss: 1.4157\n",
      "Validation loss improved from 1.4224 to 1.4157.\n",
      "[Epoch 148/1000] Train Loss: 1.1322  |  Val Loss: 1.4089\n",
      "Validation loss improved from 1.4157 to 1.4089.\n",
      "[Epoch 149/1000] Train Loss: 1.1238  |  Val Loss: 1.4022\n",
      "Validation loss improved from 1.4089 to 1.4022.\n",
      "[Epoch 150/1000] Train Loss: 1.1155  |  Val Loss: 1.3956\n",
      "Validation loss improved from 1.4022 to 1.3956.\n",
      "[Epoch 151/1000] Train Loss: 1.1072  |  Val Loss: 1.3888\n",
      "Validation loss improved from 1.3956 to 1.3888.\n",
      "[Epoch 152/1000] Train Loss: 1.0991  |  Val Loss: 1.3821\n",
      "Validation loss improved from 1.3888 to 1.3821.\n",
      "[Epoch 153/1000] Train Loss: 1.0910  |  Val Loss: 1.3754\n",
      "Validation loss improved from 1.3821 to 1.3754.\n",
      "[Epoch 154/1000] Train Loss: 1.0829  |  Val Loss: 1.3689\n",
      "Validation loss improved from 1.3754 to 1.3689.\n",
      "[Epoch 155/1000] Train Loss: 1.0750  |  Val Loss: 1.3625\n",
      "Validation loss improved from 1.3689 to 1.3625.\n",
      "[Epoch 156/1000] Train Loss: 1.0671  |  Val Loss: 1.3562\n",
      "Validation loss improved from 1.3625 to 1.3562.\n",
      "[Epoch 157/1000] Train Loss: 1.0592  |  Val Loss: 1.3500\n",
      "Validation loss improved from 1.3562 to 1.3500.\n",
      "[Epoch 158/1000] Train Loss: 1.0513  |  Val Loss: 1.3436\n",
      "Validation loss improved from 1.3500 to 1.3436.\n",
      "[Epoch 159/1000] Train Loss: 1.0434  |  Val Loss: 1.3374\n",
      "Validation loss improved from 1.3436 to 1.3374.\n",
      "[Epoch 160/1000] Train Loss: 1.0358  |  Val Loss: 1.3311\n",
      "Validation loss improved from 1.3374 to 1.3311.\n",
      "[Epoch 161/1000] Train Loss: 1.0278  |  Val Loss: 1.3245\n",
      "Validation loss improved from 1.3311 to 1.3245.\n",
      "[Epoch 162/1000] Train Loss: 1.0198  |  Val Loss: 1.3181\n",
      "Validation loss improved from 1.3245 to 1.3181.\n",
      "[Epoch 163/1000] Train Loss: 1.0122  |  Val Loss: 1.3118\n",
      "Validation loss improved from 1.3181 to 1.3118.\n",
      "[Epoch 164/1000] Train Loss: 1.0047  |  Val Loss: 1.3059\n",
      "Validation loss improved from 1.3118 to 1.3059.\n",
      "[Epoch 165/1000] Train Loss: 0.9971  |  Val Loss: 1.3001\n",
      "Validation loss improved from 1.3059 to 1.3001.\n",
      "[Epoch 166/1000] Train Loss: 0.9896  |  Val Loss: 1.2942\n",
      "Validation loss improved from 1.3001 to 1.2942.\n",
      "[Epoch 167/1000] Train Loss: 0.9821  |  Val Loss: 1.2881\n",
      "Validation loss improved from 1.2942 to 1.2881.\n",
      "[Epoch 168/1000] Train Loss: 0.9746  |  Val Loss: 1.2820\n",
      "Validation loss improved from 1.2881 to 1.2820.\n",
      "[Epoch 169/1000] Train Loss: 0.9673  |  Val Loss: 1.2761\n",
      "Validation loss improved from 1.2820 to 1.2761.\n",
      "[Epoch 170/1000] Train Loss: 0.9602  |  Val Loss: 1.2701\n",
      "Validation loss improved from 1.2761 to 1.2701.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 171/1000] Train Loss: 0.9531  |  Val Loss: 1.2640\n",
      "Validation loss improved from 1.2701 to 1.2640.\n",
      "[Epoch 172/1000] Train Loss: 0.9461  |  Val Loss: 1.2580\n",
      "Validation loss improved from 1.2640 to 1.2580.\n",
      "[Epoch 173/1000] Train Loss: 0.9392  |  Val Loss: 1.2519\n",
      "Validation loss improved from 1.2580 to 1.2519.\n",
      "[Epoch 174/1000] Train Loss: 0.9324  |  Val Loss: 1.2465\n",
      "Validation loss improved from 1.2519 to 1.2465.\n",
      "[Epoch 175/1000] Train Loss: 0.9255  |  Val Loss: 1.2408\n",
      "Validation loss improved from 1.2465 to 1.2408.\n",
      "[Epoch 176/1000] Train Loss: 0.9187  |  Val Loss: 1.2348\n",
      "Validation loss improved from 1.2408 to 1.2348.\n",
      "[Epoch 177/1000] Train Loss: 0.9120  |  Val Loss: 1.2289\n",
      "Validation loss improved from 1.2348 to 1.2289.\n",
      "[Epoch 178/1000] Train Loss: 0.9050  |  Val Loss: 1.2229\n",
      "Validation loss improved from 1.2289 to 1.2229.\n",
      "[Epoch 179/1000] Train Loss: 0.8985  |  Val Loss: 1.2172\n",
      "Validation loss improved from 1.2229 to 1.2172.\n",
      "[Epoch 180/1000] Train Loss: 0.8918  |  Val Loss: 1.2117\n",
      "Validation loss improved from 1.2172 to 1.2117.\n",
      "[Epoch 181/1000] Train Loss: 0.8851  |  Val Loss: 1.2055\n",
      "Validation loss improved from 1.2117 to 1.2055.\n",
      "[Epoch 182/1000] Train Loss: 0.8785  |  Val Loss: 1.1999\n",
      "Validation loss improved from 1.2055 to 1.1999.\n",
      "[Epoch 183/1000] Train Loss: 0.8717  |  Val Loss: 1.1945\n",
      "Validation loss improved from 1.1999 to 1.1945.\n",
      "[Epoch 184/1000] Train Loss: 0.8648  |  Val Loss: 1.1894\n",
      "Validation loss improved from 1.1945 to 1.1894.\n",
      "[Epoch 185/1000] Train Loss: 0.8583  |  Val Loss: 1.1847\n",
      "Validation loss improved from 1.1894 to 1.1847.\n",
      "[Epoch 186/1000] Train Loss: 0.8515  |  Val Loss: 1.1806\n",
      "Validation loss improved from 1.1847 to 1.1806.\n",
      "[Epoch 187/1000] Train Loss: 0.8451  |  Val Loss: 1.1765\n",
      "Validation loss improved from 1.1806 to 1.1765.\n",
      "[Epoch 188/1000] Train Loss: 0.8388  |  Val Loss: 1.1721\n",
      "Validation loss improved from 1.1765 to 1.1721.\n",
      "[Epoch 189/1000] Train Loss: 0.8325  |  Val Loss: 1.1677\n",
      "Validation loss improved from 1.1721 to 1.1677.\n",
      "[Epoch 190/1000] Train Loss: 0.8264  |  Val Loss: 1.1628\n",
      "Validation loss improved from 1.1677 to 1.1628.\n",
      "[Epoch 191/1000] Train Loss: 0.8204  |  Val Loss: 1.1574\n",
      "Validation loss improved from 1.1628 to 1.1574.\n",
      "[Epoch 192/1000] Train Loss: 0.8140  |  Val Loss: 1.1513\n",
      "Validation loss improved from 1.1574 to 1.1513.\n",
      "[Epoch 193/1000] Train Loss: 0.8077  |  Val Loss: 1.1452\n",
      "Validation loss improved from 1.1513 to 1.1452.\n",
      "[Epoch 194/1000] Train Loss: 0.8020  |  Val Loss: 1.1390\n",
      "Validation loss improved from 1.1452 to 1.1390.\n",
      "[Epoch 195/1000] Train Loss: 0.7954  |  Val Loss: 1.1334\n",
      "Validation loss improved from 1.1390 to 1.1334.\n",
      "[Epoch 196/1000] Train Loss: 0.7894  |  Val Loss: 1.1277\n",
      "Validation loss improved from 1.1334 to 1.1277.\n",
      "[Epoch 197/1000] Train Loss: 0.7838  |  Val Loss: 1.1223\n",
      "Validation loss improved from 1.1277 to 1.1223.\n",
      "[Epoch 198/1000] Train Loss: 0.7780  |  Val Loss: 1.1171\n",
      "Validation loss improved from 1.1223 to 1.1171.\n",
      "[Epoch 199/1000] Train Loss: 0.7721  |  Val Loss: 1.1122\n",
      "Validation loss improved from 1.1171 to 1.1122.\n",
      "[Epoch 200/1000] Train Loss: 0.7665  |  Val Loss: 1.1075\n",
      "Validation loss improved from 1.1122 to 1.1075.\n",
      "[Epoch 201/1000] Train Loss: 0.7609  |  Val Loss: 1.1035\n",
      "Validation loss improved from 1.1075 to 1.1035.\n",
      "[Epoch 202/1000] Train Loss: 0.7551  |  Val Loss: 1.0996\n",
      "Validation loss improved from 1.1035 to 1.0996.\n",
      "[Epoch 203/1000] Train Loss: 0.7493  |  Val Loss: 1.0957\n",
      "Validation loss improved from 1.0996 to 1.0957.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 204/1000] Train Loss: 0.7440  |  Val Loss: 1.0919\n",
      "Validation loss improved from 1.0957 to 1.0919.\n",
      "[Epoch 205/1000] Train Loss: 0.7380  |  Val Loss: 1.0875\n",
      "Validation loss improved from 1.0919 to 1.0875.\n",
      "[Epoch 206/1000] Train Loss: 0.7320  |  Val Loss: 1.0824\n",
      "Validation loss improved from 1.0875 to 1.0824.\n",
      "[Epoch 207/1000] Train Loss: 0.7264  |  Val Loss: 1.0776\n",
      "Validation loss improved from 1.0824 to 1.0776.\n",
      "[Epoch 208/1000] Train Loss: 0.7205  |  Val Loss: 1.0731\n",
      "Validation loss improved from 1.0776 to 1.0731.\n",
      "[Epoch 209/1000] Train Loss: 0.7152  |  Val Loss: 1.0690\n",
      "Validation loss improved from 1.0731 to 1.0690.\n",
      "[Epoch 210/1000] Train Loss: 0.7097  |  Val Loss: 1.0650\n",
      "Validation loss improved from 1.0690 to 1.0650.\n",
      "[Epoch 211/1000] Train Loss: 0.7045  |  Val Loss: 1.0607\n",
      "Validation loss improved from 1.0650 to 1.0607.\n",
      "[Epoch 212/1000] Train Loss: 0.6987  |  Val Loss: 1.0554\n",
      "Validation loss improved from 1.0607 to 1.0554.\n",
      "[Epoch 213/1000] Train Loss: 0.6935  |  Val Loss: 1.0498\n",
      "Validation loss improved from 1.0554 to 1.0498.\n",
      "[Epoch 214/1000] Train Loss: 0.6884  |  Val Loss: 1.0443\n",
      "Validation loss improved from 1.0498 to 1.0443.\n",
      "[Epoch 215/1000] Train Loss: 0.6827  |  Val Loss: 1.0396\n",
      "Validation loss improved from 1.0443 to 1.0396.\n",
      "[Epoch 216/1000] Train Loss: 0.6773  |  Val Loss: 1.0355\n",
      "Validation loss improved from 1.0396 to 1.0355.\n",
      "[Epoch 217/1000] Train Loss: 0.6719  |  Val Loss: 1.0315\n",
      "Validation loss improved from 1.0355 to 1.0315.\n",
      "[Epoch 218/1000] Train Loss: 0.6665  |  Val Loss: 1.0276\n",
      "Validation loss improved from 1.0315 to 1.0276.\n",
      "[Epoch 219/1000] Train Loss: 0.6612  |  Val Loss: 1.0237\n",
      "Validation loss improved from 1.0276 to 1.0237.\n",
      "[Epoch 220/1000] Train Loss: 0.6559  |  Val Loss: 1.0193\n",
      "Validation loss improved from 1.0237 to 1.0193.\n",
      "[Epoch 221/1000] Train Loss: 0.6510  |  Val Loss: 1.0146\n",
      "Validation loss improved from 1.0193 to 1.0146.\n",
      "[Epoch 222/1000] Train Loss: 0.6459  |  Val Loss: 1.0106\n",
      "Validation loss improved from 1.0146 to 1.0106.\n",
      "[Epoch 223/1000] Train Loss: 0.6406  |  Val Loss: 1.0067\n",
      "Validation loss improved from 1.0106 to 1.0067.\n",
      "[Epoch 224/1000] Train Loss: 0.6353  |  Val Loss: 1.0029\n",
      "Validation loss improved from 1.0067 to 1.0029.\n",
      "[Epoch 225/1000] Train Loss: 0.6303  |  Val Loss: 1.0000\n",
      "Validation loss improved from 1.0029 to 1.0000.\n",
      "[Epoch 226/1000] Train Loss: 0.6251  |  Val Loss: 0.9973\n",
      "Validation loss improved from 1.0000 to 0.9973.\n",
      "[Epoch 227/1000] Train Loss: 0.6199  |  Val Loss: 0.9946\n",
      "Validation loss improved from 0.9973 to 0.9946.\n",
      "[Epoch 228/1000] Train Loss: 0.6147  |  Val Loss: 0.9922\n",
      "Validation loss improved from 0.9946 to 0.9922.\n",
      "[Epoch 229/1000] Train Loss: 0.6097  |  Val Loss: 0.9892\n",
      "Validation loss improved from 0.9922 to 0.9892.\n",
      "[Epoch 230/1000] Train Loss: 0.6044  |  Val Loss: 0.9851\n",
      "Validation loss improved from 0.9892 to 0.9851.\n",
      "[Epoch 231/1000] Train Loss: 0.5994  |  Val Loss: 0.9804\n",
      "Validation loss improved from 0.9851 to 0.9804.\n",
      "[Epoch 232/1000] Train Loss: 0.5942  |  Val Loss: 0.9755\n",
      "Validation loss improved from 0.9804 to 0.9755.\n",
      "[Epoch 233/1000] Train Loss: 0.5895  |  Val Loss: 0.9711\n",
      "Validation loss improved from 0.9755 to 0.9711.\n",
      "[Epoch 234/1000] Train Loss: 0.5851  |  Val Loss: 0.9670\n",
      "Validation loss improved from 0.9711 to 0.9670.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 235/1000] Train Loss: 0.5802  |  Val Loss: 0.9637\n",
      "Validation loss improved from 0.9670 to 0.9637.\n",
      "[Epoch 236/1000] Train Loss: 0.5758  |  Val Loss: 0.9599\n",
      "Validation loss improved from 0.9637 to 0.9599.\n",
      "[Epoch 237/1000] Train Loss: 0.5709  |  Val Loss: 0.9558\n",
      "Validation loss improved from 0.9599 to 0.9558.\n",
      "[Epoch 238/1000] Train Loss: 0.5665  |  Val Loss: 0.9517\n",
      "Validation loss improved from 0.9558 to 0.9517.\n",
      "[Epoch 239/1000] Train Loss: 0.5619  |  Val Loss: 0.9481\n",
      "Validation loss improved from 0.9517 to 0.9481.\n",
      "[Epoch 240/1000] Train Loss: 0.5574  |  Val Loss: 0.9450\n",
      "Validation loss improved from 0.9481 to 0.9450.\n",
      "[Epoch 241/1000] Train Loss: 0.5530  |  Val Loss: 0.9423\n",
      "Validation loss improved from 0.9450 to 0.9423.\n",
      "[Epoch 242/1000] Train Loss: 0.5484  |  Val Loss: 0.9404\n",
      "Validation loss improved from 0.9423 to 0.9404.\n",
      "[Epoch 243/1000] Train Loss: 0.5437  |  Val Loss: 0.9387\n",
      "Validation loss improved from 0.9404 to 0.9387.\n",
      "[Epoch 244/1000] Train Loss: 0.5393  |  Val Loss: 0.9367\n",
      "Validation loss improved from 0.9387 to 0.9367.\n",
      "[Epoch 245/1000] Train Loss: 0.5350  |  Val Loss: 0.9348\n",
      "Validation loss improved from 0.9367 to 0.9348.\n",
      "[Epoch 246/1000] Train Loss: 0.5308  |  Val Loss: 0.9325\n",
      "Validation loss improved from 0.9348 to 0.9325.\n",
      "[Epoch 247/1000] Train Loss: 0.5263  |  Val Loss: 0.9292\n",
      "Validation loss improved from 0.9325 to 0.9292.\n",
      "[Epoch 248/1000] Train Loss: 0.5219  |  Val Loss: 0.9262\n",
      "Validation loss improved from 0.9292 to 0.9262.\n",
      "[Epoch 249/1000] Train Loss: 0.5175  |  Val Loss: 0.9234\n",
      "Validation loss improved from 0.9262 to 0.9234.\n",
      "[Epoch 250/1000] Train Loss: 0.5134  |  Val Loss: 0.9203\n",
      "Validation loss improved from 0.9234 to 0.9203.\n",
      "[Epoch 251/1000] Train Loss: 0.5093  |  Val Loss: 0.9174\n",
      "Validation loss improved from 0.9203 to 0.9174.\n",
      "[Epoch 252/1000] Train Loss: 0.5053  |  Val Loss: 0.9153\n",
      "Validation loss improved from 0.9174 to 0.9153.\n",
      "[Epoch 253/1000] Train Loss: 0.5014  |  Val Loss: 0.9141\n",
      "Validation loss improved from 0.9153 to 0.9141.\n",
      "[Epoch 254/1000] Train Loss: 0.4974  |  Val Loss: 0.9124\n",
      "Validation loss improved from 0.9141 to 0.9124.\n",
      "[Epoch 255/1000] Train Loss: 0.4933  |  Val Loss: 0.9090\n",
      "Validation loss improved from 0.9124 to 0.9090.\n",
      "[Epoch 256/1000] Train Loss: 0.4889  |  Val Loss: 0.9056\n",
      "Validation loss improved from 0.9090 to 0.9056.\n",
      "[Epoch 257/1000] Train Loss: 0.4851  |  Val Loss: 0.9027\n",
      "Validation loss improved from 0.9056 to 0.9027.\n",
      "[Epoch 258/1000] Train Loss: 0.4812  |  Val Loss: 0.8993\n",
      "Validation loss improved from 0.9027 to 0.8993.\n",
      "[Epoch 259/1000] Train Loss: 0.4771  |  Val Loss: 0.8953\n",
      "Validation loss improved from 0.8993 to 0.8953.\n",
      "[Epoch 260/1000] Train Loss: 0.4733  |  Val Loss: 0.8906\n",
      "Validation loss improved from 0.8953 to 0.8906.\n",
      "[Epoch 261/1000] Train Loss: 0.4697  |  Val Loss: 0.8858\n",
      "Validation loss improved from 0.8906 to 0.8858.\n",
      "[Epoch 262/1000] Train Loss: 0.4656  |  Val Loss: 0.8827\n",
      "Validation loss improved from 0.8858 to 0.8827.\n",
      "[Epoch 263/1000] Train Loss: 0.4620  |  Val Loss: 0.8801\n",
      "Validation loss improved from 0.8827 to 0.8801.\n",
      "[Epoch 264/1000] Train Loss: 0.4583  |  Val Loss: 0.8780\n",
      "Validation loss improved from 0.8801 to 0.8780.\n",
      "[Epoch 265/1000] Train Loss: 0.4546  |  Val Loss: 0.8763\n",
      "Validation loss improved from 0.8780 to 0.8763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 266/1000] Train Loss: 0.4509  |  Val Loss: 0.8742\n",
      "Validation loss improved from 0.8763 to 0.8742.\n",
      "[Epoch 267/1000] Train Loss: 0.4472  |  Val Loss: 0.8726\n",
      "Validation loss improved from 0.8742 to 0.8726.\n",
      "[Epoch 268/1000] Train Loss: 0.4439  |  Val Loss: 0.8711\n",
      "Validation loss improved from 0.8726 to 0.8711.\n",
      "[Epoch 269/1000] Train Loss: 0.4403  |  Val Loss: 0.8683\n",
      "Validation loss improved from 0.8711 to 0.8683.\n",
      "[Epoch 270/1000] Train Loss: 0.4368  |  Val Loss: 0.8656\n",
      "Validation loss improved from 0.8683 to 0.8656.\n",
      "[Epoch 271/1000] Train Loss: 0.4338  |  Val Loss: 0.8631\n",
      "Validation loss improved from 0.8656 to 0.8631.\n",
      "[Epoch 272/1000] Train Loss: 0.4306  |  Val Loss: 0.8604\n",
      "Validation loss improved from 0.8631 to 0.8604.\n",
      "[Epoch 273/1000] Train Loss: 0.4269  |  Val Loss: 0.8573\n",
      "Validation loss improved from 0.8604 to 0.8573.\n",
      "[Epoch 274/1000] Train Loss: 0.4235  |  Val Loss: 0.8548\n",
      "Validation loss improved from 0.8573 to 0.8548.\n",
      "[Epoch 275/1000] Train Loss: 0.4201  |  Val Loss: 0.8521\n",
      "Validation loss improved from 0.8548 to 0.8521.\n",
      "[Epoch 276/1000] Train Loss: 0.4167  |  Val Loss: 0.8493\n",
      "Validation loss improved from 0.8521 to 0.8493.\n",
      "[Epoch 277/1000] Train Loss: 0.4132  |  Val Loss: 0.8463\n",
      "Validation loss improved from 0.8493 to 0.8463.\n",
      "[Epoch 278/1000] Train Loss: 0.4102  |  Val Loss: 0.8433\n",
      "Validation loss improved from 0.8463 to 0.8433.\n",
      "[Epoch 279/1000] Train Loss: 0.4068  |  Val Loss: 0.8401\n",
      "Validation loss improved from 0.8433 to 0.8401.\n",
      "[Epoch 280/1000] Train Loss: 0.4034  |  Val Loss: 0.8369\n",
      "Validation loss improved from 0.8401 to 0.8369.\n",
      "[Epoch 281/1000] Train Loss: 0.4005  |  Val Loss: 0.8338\n",
      "Validation loss improved from 0.8369 to 0.8338.\n",
      "[Epoch 282/1000] Train Loss: 0.3975  |  Val Loss: 0.8308\n",
      "Validation loss improved from 0.8338 to 0.8308.\n",
      "[Epoch 283/1000] Train Loss: 0.3946  |  Val Loss: 0.8288\n",
      "Validation loss improved from 0.8308 to 0.8288.\n",
      "[Epoch 284/1000] Train Loss: 0.3912  |  Val Loss: 0.8272\n",
      "Validation loss improved from 0.8288 to 0.8272.\n",
      "[Epoch 285/1000] Train Loss: 0.3881  |  Val Loss: 0.8268\n",
      "Validation loss improved from 0.8272 to 0.8268.\n",
      "[Epoch 286/1000] Train Loss: 0.3851  |  Val Loss: 0.8275\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 287/1000] Train Loss: 0.3814  |  Val Loss: 0.8276\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 288/1000] Train Loss: 0.3786  |  Val Loss: 0.8279\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 289/1000] Train Loss: 0.3754  |  Val Loss: 0.8285\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 290/1000] Train Loss: 0.3726  |  Val Loss: 0.8303\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 291/1000] Train Loss: 0.3697  |  Val Loss: 0.8312\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 292/1000] Train Loss: 0.3672  |  Val Loss: 0.8311\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 293/1000] Train Loss: 0.3644  |  Val Loss: 0.8295\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 294/1000] Train Loss: 0.3617  |  Val Loss: 0.8268\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 295/1000] Train Loss: 0.3588  |  Val Loss: 0.8248\n",
      "Validation loss improved from 0.8268 to 0.8248.\n",
      "[Epoch 296/1000] Train Loss: 0.3561  |  Val Loss: 0.8239\n",
      "Validation loss improved from 0.8248 to 0.8239.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 297/1000] Train Loss: 0.3536  |  Val Loss: 0.8226\n",
      "Validation loss improved from 0.8239 to 0.8226.\n",
      "[Epoch 298/1000] Train Loss: 0.3511  |  Val Loss: 0.8205\n",
      "Validation loss improved from 0.8226 to 0.8205.\n",
      "[Epoch 299/1000] Train Loss: 0.3481  |  Val Loss: 0.8172\n",
      "Validation loss improved from 0.8205 to 0.8172.\n",
      "[Epoch 300/1000] Train Loss: 0.3455  |  Val Loss: 0.8135\n",
      "Validation loss improved from 0.8172 to 0.8135.\n",
      "[Epoch 301/1000] Train Loss: 0.3428  |  Val Loss: 0.8106\n",
      "Validation loss improved from 0.8135 to 0.8106.\n",
      "[Epoch 302/1000] Train Loss: 0.3404  |  Val Loss: 0.8087\n",
      "Validation loss improved from 0.8106 to 0.8087.\n",
      "[Epoch 303/1000] Train Loss: 0.3376  |  Val Loss: 0.8070\n",
      "Validation loss improved from 0.8087 to 0.8070.\n",
      "[Epoch 304/1000] Train Loss: 0.3353  |  Val Loss: 0.8061\n",
      "Validation loss improved from 0.8070 to 0.8061.\n",
      "[Epoch 305/1000] Train Loss: 0.3331  |  Val Loss: 0.8059\n",
      "Validation loss improved from 0.8061 to 0.8059.\n",
      "[Epoch 306/1000] Train Loss: 0.3307  |  Val Loss: 0.8074\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 307/1000] Train Loss: 0.3279  |  Val Loss: 0.8079\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 308/1000] Train Loss: 0.3256  |  Val Loss: 0.8078\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 309/1000] Train Loss: 0.3233  |  Val Loss: 0.8077\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 310/1000] Train Loss: 0.3213  |  Val Loss: 0.8079\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 311/1000] Train Loss: 0.3190  |  Val Loss: 0.8085\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 312/1000] Train Loss: 0.3171  |  Val Loss: 0.8094\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 313/1000] Train Loss: 0.3146  |  Val Loss: 0.8099\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 314/1000] Train Loss: 0.3126  |  Val Loss: 0.8094\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 315/1000] Train Loss: 0.3104  |  Val Loss: 0.8073\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 316/1000] Train Loss: 0.3082  |  Val Loss: 0.8059\n",
      "Validation loss improved from 0.8059 to 0.8059.\n",
      "[Epoch 317/1000] Train Loss: 0.3058  |  Val Loss: 0.8029\n",
      "Validation loss improved from 0.8059 to 0.8029.\n",
      "[Epoch 318/1000] Train Loss: 0.3034  |  Val Loss: 0.8005\n",
      "Validation loss improved from 0.8029 to 0.8005.\n",
      "[Epoch 319/1000] Train Loss: 0.3011  |  Val Loss: 0.7988\n",
      "Validation loss improved from 0.8005 to 0.7988.\n",
      "[Epoch 320/1000] Train Loss: 0.2990  |  Val Loss: 0.7969\n",
      "Validation loss improved from 0.7988 to 0.7969.\n",
      "[Epoch 321/1000] Train Loss: 0.2966  |  Val Loss: 0.7961\n",
      "Validation loss improved from 0.7969 to 0.7961.\n",
      "[Epoch 322/1000] Train Loss: 0.2945  |  Val Loss: 0.7955\n",
      "Validation loss improved from 0.7961 to 0.7955.\n",
      "[Epoch 323/1000] Train Loss: 0.2927  |  Val Loss: 0.7943\n",
      "Validation loss improved from 0.7955 to 0.7943.\n",
      "[Epoch 324/1000] Train Loss: 0.2907  |  Val Loss: 0.7919\n",
      "Validation loss improved from 0.7943 to 0.7919.\n",
      "[Epoch 325/1000] Train Loss: 0.2887  |  Val Loss: 0.7907\n",
      "Validation loss improved from 0.7919 to 0.7907.\n",
      "[Epoch 326/1000] Train Loss: 0.2867  |  Val Loss: 0.7899\n",
      "Validation loss improved from 0.7907 to 0.7899.\n",
      "[Epoch 327/1000] Train Loss: 0.2849  |  Val Loss: 0.7896\n",
      "Validation loss improved from 0.7899 to 0.7896.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 328/1000] Train Loss: 0.2829  |  Val Loss: 0.7866\n",
      "Validation loss improved from 0.7896 to 0.7866.\n",
      "[Epoch 329/1000] Train Loss: 0.2807  |  Val Loss: 0.7837\n",
      "Validation loss improved from 0.7866 to 0.7837.\n",
      "[Epoch 330/1000] Train Loss: 0.2788  |  Val Loss: 0.7809\n",
      "Validation loss improved from 0.7837 to 0.7809.\n",
      "[Epoch 331/1000] Train Loss: 0.2769  |  Val Loss: 0.7785\n",
      "Validation loss improved from 0.7809 to 0.7785.\n",
      "[Epoch 332/1000] Train Loss: 0.2755  |  Val Loss: 0.7778\n",
      "Validation loss improved from 0.7785 to 0.7778.\n",
      "[Epoch 333/1000] Train Loss: 0.2734  |  Val Loss: 0.7792\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 334/1000] Train Loss: 0.2720  |  Val Loss: 0.7808\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 335/1000] Train Loss: 0.2701  |  Val Loss: 0.7832\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 336/1000] Train Loss: 0.2682  |  Val Loss: 0.7850\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 337/1000] Train Loss: 0.2667  |  Val Loss: 0.7868\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 338/1000] Train Loss: 0.2648  |  Val Loss: 0.7877\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 339/1000] Train Loss: 0.2631  |  Val Loss: 0.7881\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 340/1000] Train Loss: 0.2612  |  Val Loss: 0.7857\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 341/1000] Train Loss: 0.2594  |  Val Loss: 0.7831\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 342/1000] Train Loss: 0.2577  |  Val Loss: 0.7813\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 343/1000] Train Loss: 0.2559  |  Val Loss: 0.7809\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 344/1000] Train Loss: 0.2542  |  Val Loss: 0.7804\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 345/1000] Train Loss: 0.2526  |  Val Loss: 0.7786\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 346/1000] Train Loss: 0.2509  |  Val Loss: 0.7765\n",
      "Validation loss improved from 0.7778 to 0.7765.\n",
      "[Epoch 347/1000] Train Loss: 0.2491  |  Val Loss: 0.7719\n",
      "Validation loss improved from 0.7765 to 0.7719.\n",
      "[Epoch 348/1000] Train Loss: 0.2476  |  Val Loss: 0.7674\n",
      "Validation loss improved from 0.7719 to 0.7674.\n",
      "[Epoch 349/1000] Train Loss: 0.2462  |  Val Loss: 0.7650\n",
      "Validation loss improved from 0.7674 to 0.7650.\n",
      "[Epoch 350/1000] Train Loss: 0.2447  |  Val Loss: 0.7649\n",
      "Validation loss improved from 0.7650 to 0.7649.\n",
      "[Epoch 351/1000] Train Loss: 0.2432  |  Val Loss: 0.7653\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 352/1000] Train Loss: 0.2416  |  Val Loss: 0.7658\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 353/1000] Train Loss: 0.2402  |  Val Loss: 0.7658\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 354/1000] Train Loss: 0.2388  |  Val Loss: 0.7656\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 355/1000] Train Loss: 0.2373  |  Val Loss: 0.7663\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 356/1000] Train Loss: 0.2358  |  Val Loss: 0.7678\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 357/1000] Train Loss: 0.2345  |  Val Loss: 0.7701\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 358/1000] Train Loss: 0.2331  |  Val Loss: 0.7724\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 359/1000] Train Loss: 0.2324  |  Val Loss: 0.7737\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 360/1000] Train Loss: 0.2310  |  Val Loss: 0.7743\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 361/1000] Train Loss: 0.2302  |  Val Loss: 0.7748\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 362/1000] Train Loss: 0.2289  |  Val Loss: 0.7724\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 363/1000] Train Loss: 0.2272  |  Val Loss: 0.7693\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 364/1000] Train Loss: 0.2257  |  Val Loss: 0.7670\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 365/1000] Train Loss: 0.2240  |  Val Loss: 0.7656\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 366/1000] Train Loss: 0.2228  |  Val Loss: 0.7629\n",
      "Validation loss improved from 0.7649 to 0.7629.\n",
      "[Epoch 367/1000] Train Loss: 0.2216  |  Val Loss: 0.7615\n",
      "Validation loss improved from 0.7629 to 0.7615.\n",
      "[Epoch 368/1000] Train Loss: 0.2205  |  Val Loss: 0.7607\n",
      "Validation loss improved from 0.7615 to 0.7607.\n",
      "[Epoch 369/1000] Train Loss: 0.2193  |  Val Loss: 0.7593\n",
      "Validation loss improved from 0.7607 to 0.7593.\n",
      "[Epoch 370/1000] Train Loss: 0.2179  |  Val Loss: 0.7569\n",
      "Validation loss improved from 0.7593 to 0.7569.\n",
      "[Epoch 371/1000] Train Loss: 0.2165  |  Val Loss: 0.7547\n",
      "Validation loss improved from 0.7569 to 0.7547.\n",
      "[Epoch 372/1000] Train Loss: 0.2152  |  Val Loss: 0.7532\n",
      "Validation loss improved from 0.7547 to 0.7532.\n",
      "[Epoch 373/1000] Train Loss: 0.2140  |  Val Loss: 0.7522\n",
      "Validation loss improved from 0.7532 to 0.7522.\n",
      "[Epoch 374/1000] Train Loss: 0.2129  |  Val Loss: 0.7523\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 375/1000] Train Loss: 0.2114  |  Val Loss: 0.7512\n",
      "Validation loss improved from 0.7522 to 0.7512.\n",
      "[Epoch 376/1000] Train Loss: 0.2103  |  Val Loss: 0.7504\n",
      "Validation loss improved from 0.7512 to 0.7504.\n",
      "[Epoch 377/1000] Train Loss: 0.2092  |  Val Loss: 0.7522\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 378/1000] Train Loss: 0.2081  |  Val Loss: 0.7549\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 379/1000] Train Loss: 0.2069  |  Val Loss: 0.7568\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 380/1000] Train Loss: 0.2057  |  Val Loss: 0.7587\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 381/1000] Train Loss: 0.2046  |  Val Loss: 0.7608\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 382/1000] Train Loss: 0.2034  |  Val Loss: 0.7622\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 383/1000] Train Loss: 0.2023  |  Val Loss: 0.7625\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 384/1000] Train Loss: 0.2011  |  Val Loss: 0.7618\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 385/1000] Train Loss: 0.1998  |  Val Loss: 0.7592\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 386/1000] Train Loss: 0.1990  |  Val Loss: 0.7569\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 387/1000] Train Loss: 0.1979  |  Val Loss: 0.7556\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 388/1000] Train Loss: 0.1971  |  Val Loss: 0.7547\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 389/1000] Train Loss: 0.1963  |  Val Loss: 0.7542\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 390/1000] Train Loss: 0.1952  |  Val Loss: 0.7537\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 391/1000] Train Loss: 0.1942  |  Val Loss: 0.7542\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 392/1000] Train Loss: 0.1927  |  Val Loss: 0.7554\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 393/1000] Train Loss: 0.1917  |  Val Loss: 0.7568\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 394/1000] Train Loss: 0.1905  |  Val Loss: 0.7574\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 395/1000] Train Loss: 0.1895  |  Val Loss: 0.7577\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 396/1000] Train Loss: 0.1885  |  Val Loss: 0.7573\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 397/1000] Train Loss: 0.1877  |  Val Loss: 0.7567\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 398/1000] Train Loss: 0.1869  |  Val Loss: 0.7565\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 399/1000] Train Loss: 0.1859  |  Val Loss: 0.7573\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 400/1000] Train Loss: 0.1848  |  Val Loss: 0.7587\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 401/1000] Train Loss: 0.1838  |  Val Loss: 0.7605\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 402/1000] Train Loss: 0.1827  |  Val Loss: 0.7617\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 403/1000] Train Loss: 0.1817  |  Val Loss: 0.7625\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 404/1000] Train Loss: 0.1808  |  Val Loss: 0.7636\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 405/1000] Train Loss: 0.1800  |  Val Loss: 0.7642\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 406/1000] Train Loss: 0.1790  |  Val Loss: 0.7640\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 407/1000] Train Loss: 0.1781  |  Val Loss: 0.7632\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 408/1000] Train Loss: 0.1771  |  Val Loss: 0.7609\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 409/1000] Train Loss: 0.1761  |  Val Loss: 0.7573\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 410/1000] Train Loss: 0.1753  |  Val Loss: 0.7551\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 411/1000] Train Loss: 0.1746  |  Val Loss: 0.7538\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 412/1000] Train Loss: 0.1738  |  Val Loss: 0.7531\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 413/1000] Train Loss: 0.1730  |  Val Loss: 0.7512\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 414/1000] Train Loss: 0.1721  |  Val Loss: 0.7506\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 415/1000] Train Loss: 0.1713  |  Val Loss: 0.7521\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 416/1000] Train Loss: 0.1706  |  Val Loss: 0.7524\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 417/1000] Train Loss: 0.1697  |  Val Loss: 0.7514\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 418/1000] Train Loss: 0.1687  |  Val Loss: 0.7515\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 419/1000] Train Loss: 0.1680  |  Val Loss: 0.7514\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 420/1000] Train Loss: 0.1671  |  Val Loss: 0.7524\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 421/1000] Train Loss: 0.1663  |  Val Loss: 0.7536\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 422/1000] Train Loss: 0.1657  |  Val Loss: 0.7568\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 423/1000] Train Loss: 0.1649  |  Val Loss: 0.7593\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 424/1000] Train Loss: 0.1648  |  Val Loss: 0.7617\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 425/1000] Train Loss: 0.1641  |  Val Loss: 0.7626\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 426/1000] Train Loss: 0.1634  |  Val Loss: 0.7617\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 427/1000] Train Loss: 0.1625  |  Val Loss: 0.7602\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 428/1000] Train Loss: 0.1613  |  Val Loss: 0.7595\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 429/1000] Train Loss: 0.1607  |  Val Loss: 0.7595\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 430/1000] Train Loss: 0.1597  |  Val Loss: 0.7607\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 431/1000] Train Loss: 0.1592  |  Val Loss: 0.7612\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 432/1000] Train Loss: 0.1584  |  Val Loss: 0.7609\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 433/1000] Train Loss: 0.1577  |  Val Loss: 0.7619\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 434/1000] Train Loss: 0.1570  |  Val Loss: 0.7630\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n",
      "[Epoch 435/1000] Train Loss: 0.1566  |  Val Loss: 0.7637\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 436/1000] Train Loss: 0.1558  |  Val Loss: 0.7626\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 437/1000] Train Loss: 0.1548  |  Val Loss: 0.7617\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 438/1000] Train Loss: 0.1541  |  Val Loss: 0.7611\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 439/1000] Train Loss: 0.1534  |  Val Loss: 0.7609\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 440/1000] Train Loss: 0.1525  |  Val Loss: 0.7605\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 441/1000] Train Loss: 0.1517  |  Val Loss: 0.7596\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n",
      "[Epoch 442/1000] Train Loss: 0.1510  |  Val Loss: 0.7589\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 443/1000] Train Loss: 0.1504  |  Val Loss: 0.7578\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 444/1000] Train Loss: 0.1496  |  Val Loss: 0.7585\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 445/1000] Train Loss: 0.1489  |  Val Loss: 0.7607\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 446/1000] Train Loss: 0.1480  |  Val Loss: 0.7636\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 447/1000] Train Loss: 0.1477  |  Val Loss: 0.7663\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 448/1000] Train Loss: 0.1474  |  Val Loss: 0.7681\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 449/1000] Train Loss: 0.1469  |  Val Loss: 0.7690\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 450/1000] Train Loss: 0.1464  |  Val Loss: 0.7692\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 451/1000] Train Loss: 0.1457  |  Val Loss: 0.7685\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 452/1000] Train Loss: 0.1448  |  Val Loss: 0.7686\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 453/1000] Train Loss: 0.1440  |  Val Loss: 0.7689\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 454/1000] Train Loss: 0.1431  |  Val Loss: 0.7710\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 455/1000] Train Loss: 0.1431  |  Val Loss: 0.7725\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 456/1000] Train Loss: 0.1422  |  Val Loss: 0.7731\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 457/1000] Train Loss: 0.1416  |  Val Loss: 0.7733\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 458/1000] Train Loss: 0.1409  |  Val Loss: 0.7723\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 459/1000] Train Loss: 0.1403  |  Val Loss: 0.7715\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 460/1000] Train Loss: 0.1397  |  Val Loss: 0.7707\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 461/1000] Train Loss: 0.1389  |  Val Loss: 0.7709\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 462/1000] Train Loss: 0.1382  |  Val Loss: 0.7694\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 463/1000] Train Loss: 0.1375  |  Val Loss: 0.7685\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n",
      "[Epoch 464/1000] Train Loss: 0.1369  |  Val Loss: 0.7676\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 465/1000] Train Loss: 0.1364  |  Val Loss: 0.7670\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 466/1000] Train Loss: 0.1358  |  Val Loss: 0.7661\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 467/1000] Train Loss: 0.1354  |  Val Loss: 0.7655\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 468/1000] Train Loss: 0.1348  |  Val Loss: 0.7650\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 469/1000] Train Loss: 0.1343  |  Val Loss: 0.7640\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n",
      "[Epoch 470/1000] Train Loss: 0.1339  |  Val Loss: 0.7612\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 471/1000] Train Loss: 0.1336  |  Val Loss: 0.7581\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 472/1000] Train Loss: 0.1332  |  Val Loss: 0.7569\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 473/1000] Train Loss: 0.1324  |  Val Loss: 0.7566\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 474/1000] Train Loss: 0.1318  |  Val Loss: 0.7560\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 475/1000] Train Loss: 0.1312  |  Val Loss: 0.7564\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 476/1000] Train Loss: 0.1305  |  Val Loss: 0.7573\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 476 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_input_dim = tscl_mlp_train_reps.shape[1]\n",
    "tscl_mlp_num_classes = len(torch.unique(tscl_mlp_train_labels_torch))\n",
    "tscl_mlp_model = MLPClassifier(tscl_mlp_input_dim, tscl_mlp_num_classes).to(device)\n",
    "\n",
    "tscl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "tscl_mlp_optimizer = optim.Adam(tscl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "tscl_mlp_num_epochs = 1000\n",
    "tscl_mlp_patience = 100\n",
    "\n",
    "tscl_mlp_train_losses = []\n",
    "tscl_mlp_val_losses = []\n",
    "\n",
    "tscl_mlp_best_val_loss = float('inf')\n",
    "tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for tscl_mlp_epoch in range(tscl_mlp_num_epochs):\n",
    "    # Training\n",
    "    tscl_mlp_model.train()\n",
    "    tscl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for tscl_mlp_embeddings_batch, tscl_mlp_labels_batch in tscl_mlp_train_loader:\n",
    "        tscl_mlp_embeddings_batch = tscl_mlp_embeddings_batch.to(device)\n",
    "        tscl_mlp_labels_batch = tscl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        tscl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        tscl_mlp_outputs = tscl_mlp_model(tscl_mlp_embeddings_batch)\n",
    "        tscl_mlp_loss = tscl_mlp_criterion(tscl_mlp_outputs, tscl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        tscl_mlp_loss.backward()\n",
    "        tscl_mlp_optimizer.step()\n",
    "        \n",
    "        tscl_mlp_train_running_loss += tscl_mlp_loss.item() * tscl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    tscl_mlp_epoch_train_loss = tscl_mlp_train_running_loss / len(tscl_mlp_train_loader.dataset)\n",
    "    tscl_mlp_train_losses.append(tscl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    tscl_mlp_model.eval()\n",
    "    tscl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for tscl_mlp_val_embeddings_batch, tscl_mlp_val_labels_batch in tscl_mlp_val_loader:\n",
    "            tscl_mlp_val_embeddings_batch = tscl_mlp_val_embeddings_batch.to(device)\n",
    "            tscl_mlp_val_labels_batch = tscl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            tscl_mlp_val_outputs = tscl_mlp_model(tscl_mlp_val_embeddings_batch)\n",
    "            tscl_mlp_val_loss = tscl_mlp_criterion(tscl_mlp_val_outputs, tscl_mlp_val_labels_batch)\n",
    "\n",
    "            tscl_mlp_val_running_loss += tscl_mlp_val_loss.item() * tscl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    tscl_mlp_epoch_val_loss = tscl_mlp_val_running_loss / len(tscl_mlp_val_loader.dataset)\n",
    "    tscl_mlp_val_losses.append(tscl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {tscl_mlp_epoch+1}/{tscl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {tscl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {tscl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if tscl_mlp_epoch_val_loss < tscl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {tscl_mlp_best_val_loss:.4f} to {tscl_mlp_epoch_val_loss:.4f}.\")\n",
    "        tscl_mlp_best_val_loss = tscl_mlp_epoch_val_loss\n",
    "        tscl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "    else:\n",
    "        # no improvement\n",
    "        tscl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {tscl_mlp_epochs_without_improvement}/{tscl_mlp_patience}\")\n",
    "        \n",
    "        if tscl_mlp_epochs_without_improvement >= tscl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {tscl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {tscl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(tscl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(tscl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:42:11.364302Z",
     "iopub.status.busy": "2025-05-08T18:42:11.364302Z",
     "iopub.status.idle": "2025-05-08T18:42:11.496008Z",
     "shell.execute_reply": "2025-05-08T18:42:11.496008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TSCL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.6007 | Test Accuracy: 81.34%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscl_mlp_model.eval()\n",
    "\n",
    "tscl_mlp_test_running_loss = 0.0\n",
    "tscl_mlp_test_correct = 0\n",
    "tscl_mlp_all_predictions = []\n",
    "tscl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tscl_mlp_test_embeddings_batch, tscl_mlp_test_labels_batch in tscl_mlp_test_loader:\n",
    "        tscl_mlp_test_embeddings_batch = tscl_mlp_test_embeddings_batch.to(device)\n",
    "        tscl_mlp_test_labels_batch = tscl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        tscl_mlp_test_outputs = tscl_mlp_model(tscl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        tscl_mlp_test_loss_batch = tscl_mlp_criterion(tscl_mlp_test_outputs, tscl_mlp_test_labels_batch)\n",
    "        tscl_mlp_test_running_loss += tscl_mlp_test_loss_batch.item() * tscl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, tscl_mlp_test_predicted = torch.max(tscl_mlp_test_outputs, dim=1)\n",
    "        tscl_mlp_test_correct += (tscl_mlp_test_predicted == tscl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        tscl_mlp_all_predictions.extend(tscl_mlp_test_predicted.cpu().numpy())\n",
    "        tscl_mlp_all_true_labels.extend(tscl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_predictions.npy'), np.array(tscl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'tscl_mlp_true_labels.npy'), np.array(tscl_mlp_all_true_labels))\n",
    "print(f\"Saved TSCL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "tscl_mlp_epoch_test_loss = tscl_mlp_test_running_loss / len(tscl_mlp_test_loader.dataset)\n",
    "tscl_mlp_test_accuracy = tscl_mlp_test_correct / len(tscl_mlp_test_loader.dataset)\n",
    "\n",
    "tscl_mlp_test_accuracy_pct = tscl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {tscl_mlp_epoch_test_loss:.4f} | Test Accuracy: {tscl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "tscl_mlp_num_epochs_run = len(tscl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         tscl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, tscl_mlp_num_epochs_run + 1),\n",
    "         [tscl_mlp_epoch_test_loss]*tscl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Supervised Contrastive Learning with Silhouette Distance Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:42:11.499013Z",
     "iopub.status.busy": "2025-05-08T18:42:11.499013Z",
     "iopub.status.idle": "2025-05-08T18:42:11.507653Z",
     "shell.execute_reply": "2025-05-08T18:42:11.507653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Loading encoded data (representations) from encoded_representations\\train...\n",
      "LOG: Loaded 140 samples with 64 features each\n",
      "LOG: Labels shape: (140,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\val...\n",
      "LOG: Loaded 70 samples with 64 features each\n",
      "LOG: Labels shape: (70,)\n",
      "LOG: Loading encoded data (representations) from encoded_representations\\test...\n",
      "LOG: Loaded 3038 samples with 64 features each\n",
      "LOG: Labels shape: (3038,)\n",
      "\n",
      "\n",
      "Train embeddings shape: (140, 64), \n",
      "Train labels shape: (140,)\n",
      "\n",
      "\n",
      "Val embeddings shape: (70, 64), \n",
      "Val labels shape: (70,)\n",
      "\n",
      "\n",
      "Test embeddings shape: (3038, 64), \n",
      "Test labels shape: (3038,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_encoded_train_dir = os.path.join(encoded_dir, 'train')\n",
    "sclsdl_encoded_val_dir = os.path.join(encoded_dir, 'val')\n",
    "sclsdl_encoded_test_dir = os.path.join(encoded_dir, 'test')\n",
    "\n",
    "sclsdl_train_embeddings, sclsdl_train_labels = load_encoded_data(sclsdl_encoded_train_dir)\n",
    "sclsdl_val_embeddings, sclsdl_val_labels = load_encoded_data(sclsdl_encoded_val_dir)\n",
    "sclsdl_test_embeddings, sclsdl_test_labels = load_encoded_data(sclsdl_encoded_test_dir)\n",
    "\n",
    "#shape verification\n",
    "print(f\"\\n\\nTrain embeddings shape: {sclsdl_train_embeddings.shape}, \\nTrain labels shape: {sclsdl_train_labels.shape}\")\n",
    "print(f\"\\n\\nVal embeddings shape: {sclsdl_val_embeddings.shape}, \\nVal labels shape: {sclsdl_val_labels.shape}\")\n",
    "print(f\"\\n\\nTest embeddings shape: {sclsdl_test_embeddings.shape}, \\nTest labels shape: {sclsdl_test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:42:11.509658Z",
     "iopub.status.busy": "2025-05-08T18:42:11.509658Z",
     "iopub.status.idle": "2025-05-08T18:42:11.519173Z",
     "shell.execute_reply": "2025-05-08T18:42:11.519173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in batch: {0: 10, 1: 10, 2: 10, 3: 10, 4: 10, 5: 10, 6: 10, 7: 10, 8: 10, 9: 10, 10: 10, 11: 10, 12: 10, 13: 10}\n",
      "Training batch size: 140\n"
     ]
    }
   ],
   "source": [
    "#flattening embeddings to (num_samples, 64)\n",
    "sclsdl_train_embeddings = sclsdl_train_embeddings.reshape(sclsdl_train_embeddings.shape[0], -1)\n",
    "sclsdl_val_embeddings = sclsdl_val_embeddings.reshape(sclsdl_val_embeddings.shape[0], -1)\n",
    "sclsdl_test_embeddings = sclsdl_test_embeddings.reshape(sclsdl_test_embeddings.shape[0], -1)\n",
    "\n",
    "#compute mean and std from training set\n",
    "sclsdl_train_mean = np.mean(sclsdl_train_embeddings, axis=0)\n",
    "sclsdl_train_std = np.std(sclsdl_train_embeddings, axis=0)\n",
    "\n",
    "#normalize all datasets from above training mean and std\n",
    "#sclsdl_train_embeddings = (sclsdl_train_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_val_embeddings = (sclsdl_val_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "#sclsdl_test_embeddings = (sclsdl_test_embeddings - sclsdl_train_mean) / sclsdl_train_std\n",
    "\n",
    "sclsdl_train_dataset = TensorDataset(torch.tensor(sclsdl_train_embeddings, dtype=torch.float32), torch.tensor(sclsdl_train_labels, dtype=torch.long))\n",
    "sclsdl_val_dataset = TensorDataset(torch.tensor(sclsdl_val_embeddings, dtype=torch.float32), torch.tensor(sclsdl_val_labels, dtype=torch.long))\n",
    "sclsdl_test_dataset = TensorDataset(torch.tensor(sclsdl_test_embeddings, dtype=torch.float32), torch.tensor(sclsdl_test_labels, dtype=torch.long))\n",
    "\n",
    "\n",
    "sclsdl_m = 20\n",
    "sclsdl_num_classes = len(np.unique(sclsdl_train_labels))\n",
    "\n",
    "# calc theoretical required batch size\n",
    "sclsdl_required_batch_size = sclsdl_m * sclsdl_num_classes\n",
    "\n",
    "if sclsdl_required_batch_size > len(sclsdl_train_dataset):\n",
    "    sclsdl_max_possible_m = len(sclsdl_train_dataset) // sclsdl_num_classes\n",
    "    sclsdl_m = max(1, sclsdl_max_possible_m)\n",
    "    sclsdl_batch_size_train = sclsdl_m * sclsdl_num_classes\n",
    "else:\n",
    "    sclsdl_batch_size_train = sclsdl_required_batch_size\n",
    "\n",
    "sclsdl_sampler = MPerClassSampler(labels = sclsdl_train_labels, m = sclsdl_m, batch_size = sclsdl_batch_size_train, length_before_new_iter=len(sclsdl_train_dataset))\n",
    "sclsdl_train_loader = DataLoader(sclsdl_train_dataset, batch_size=sclsdl_batch_size_train, sampler=sclsdl_sampler)\n",
    "\n",
    "#creating dataloaders for scl\n",
    "sclsdl_dataloader_bs = 64\n",
    "sclsdl_val_loader = DataLoader(sclsdl_val_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "sclsdl_test_loader = DataLoader(sclsdl_test_dataset, batch_size=sclsdl_dataloader_bs, shuffle=False)\n",
    "\n",
    "for sclsdl_X_batch, sclsdl_y_batch in sclsdl_train_loader:\n",
    "    sclsdl_unique, sclsdl_counts = np.unique(y_batch.numpy(), return_counts=True)\n",
    "    print(\"Class distribution in batch:\", dict(zip(sclsdl_unique, sclsdl_counts)))\n",
    "    print(f\"Training batch size: {sclsdl_batch_size_train}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:42:11.522367Z",
     "iopub.status.busy": "2025-05-08T18:42:11.521366Z",
     "iopub.status.idle": "2025-05-08T18:42:11.525875Z",
     "shell.execute_reply": "2025-05-08T18:42:11.525875Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupConNet(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SupConNet, self).__init__()\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.projection_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:42:11.528882Z",
     "iopub.status.busy": "2025-05-08T18:42:11.528882Z",
     "iopub.status.idle": "2025-05-08T18:42:11.535386Z",
     "shell.execute_reply": "2025-05-08T18:42:11.534883Z"
    }
   },
   "outputs": [],
   "source": [
    "class SilhouetteDistanceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SilhouetteDistanceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        return self.score(features, labels, True,True)\n",
    "\n",
    "    def score(self,X, labels,feature_norm=True, loss=False):\n",
    "        unique_labels = torch.unique(labels)\n",
    "        if feature_norm:\n",
    "            X= F.normalize(X, p=2, dim=1)\n",
    "\n",
    "\n",
    "        A, B = self._compute_distances(X, labels, unique_labels)\n",
    "\n",
    "        # A= scale*A\n",
    "        # B = (1-scale)*B\n",
    "        sil_samples = (B - A) / torch.clamp(torch.maximum(A, B), min=0.0001)\n",
    "\n",
    "        # nan values are for clusters of size 1, and should be 0\n",
    "        mean_sil_score = torch.mean(torch.nan_to_num(sil_samples))\n",
    "        if loss:\n",
    "            return (1 - mean_sil_score) / 2\n",
    "        else:\n",
    "            return mean_sil_score.item()\n",
    "\n",
    "\n",
    "    def _compute_distances(self,X, labels, unique_labels):\n",
    "        intra_dist = torch.zeros_like(labels, dtype=torch.float32)\n",
    "        inter_dist = torch.full_like(labels, torch.inf, dtype=torch.float32)\n",
    "\n",
    "        for i, label_a in enumerate(unique_labels):\n",
    "            cluster_indices_a = (labels == label_a)\n",
    "            subX_a = X[cluster_indices_a]\n",
    "\n",
    "\n",
    "            intra_distances_a = torch.cdist(subX_a, subX_a)\n",
    "            div = (subX_a.size(0) - 1) if subX_a.shape[0]>1 else 1\n",
    "            intra_dist[cluster_indices_a] = intra_distances_a.sum(dim=1) / div\n",
    "\n",
    "            for label_b in unique_labels[i + 1:]:\n",
    "                cluster_indices_b = (labels == label_b)\n",
    "                subX_b = X[cluster_indices_b]\n",
    "                inter_distances_ab = torch.cdist(subX_a, subX_b)\n",
    "                inter_distances_ba = torch.cdist(subX_b, subX_a)\n",
    "\n",
    "                inter_dist[cluster_indices_a] = torch.minimum(inter_distances_ab.mean(dim=1), inter_dist[cluster_indices_a])\n",
    "                inter_dist[cluster_indices_b] = torch.minimum(inter_distances_ba.mean(dim=1), inter_dist[cluster_indices_b])\n",
    "\n",
    "        return intra_dist, inter_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:42:11.537891Z",
     "iopub.status.busy": "2025-05-08T18:42:11.536890Z",
     "iopub.status.idle": "2025-05-08T18:50:17.479930Z",
     "shell.execute_reply": "2025-05-08T18:50:17.479930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Epoch [1/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4853\n",
      "LOG: Epoch [1/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4724\n",
      "    Batch [2/2], Val Loss: 0.2486\n",
      "Epoch [1/2000], Avg Train Loss: 0.4853, Avg Val Loss: 0.3605\n",
      "\n",
      "Validation loss improved from inf to 0.3605. Saving model...\n",
      "LOG: Epoch [2/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4908\n",
      "LOG: Epoch [2/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4717\n",
      "    Batch [2/2], Val Loss: 0.2514\n",
      "Epoch [2/2000], Avg Train Loss: 0.4908, Avg Val Loss: 0.3616\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [3/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4833\n",
      "LOG: Epoch [3/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4706\n",
      "    Batch [2/2], Val Loss: 0.2536\n",
      "Epoch [3/2000], Avg Train Loss: 0.4833, Avg Val Loss: 0.3621\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [4/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4847\n",
      "LOG: Epoch [4/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4693\n",
      "    Batch [2/2], Val Loss: 0.2557\n",
      "Epoch [4/2000], Avg Train Loss: 0.4847, Avg Val Loss: 0.3625\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [5/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4920\n",
      "LOG: Epoch [5/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4683\n",
      "    Batch [2/2], Val Loss: 0.2569\n",
      "Epoch [5/2000], Avg Train Loss: 0.4920, Avg Val Loss: 0.3626\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [6/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4791\n",
      "LOG: Epoch [6/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4677\n",
      "    Batch [2/2], Val Loss: 0.2577\n",
      "Epoch [6/2000], Avg Train Loss: 0.4791, Avg Val Loss: 0.3627\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [7/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4842\n",
      "LOG: Epoch [7/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4673\n",
      "    Batch [2/2], Val Loss: 0.2572\n",
      "Epoch [7/2000], Avg Train Loss: 0.4842, Avg Val Loss: 0.3623\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [8/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4833\n",
      "LOG: Epoch [8/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4675\n",
      "    Batch [2/2], Val Loss: 0.2551\n",
      "Epoch [8/2000], Avg Train Loss: 0.4833, Avg Val Loss: 0.3613\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [9/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4801\n",
      "LOG: Epoch [9/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4675\n",
      "    Batch [2/2], Val Loss: 0.2546\n",
      "Epoch [9/2000], Avg Train Loss: 0.4801, Avg Val Loss: 0.3610\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [10/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4800\n",
      "LOG: Epoch [10/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4665\n",
      "    Batch [2/2], Val Loss: 0.2536\n",
      "Epoch [10/2000], Avg Train Loss: 0.4800, Avg Val Loss: 0.3601\n",
      "\n",
      "Validation loss improved from 0.3605 to 0.3601. Saving model...\n",
      "LOG: Epoch [11/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4799\n",
      "LOG: Epoch [11/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4660\n",
      "    Batch [2/2], Val Loss: 0.2515\n",
      "Epoch [11/2000], Avg Train Loss: 0.4799, Avg Val Loss: 0.3588\n",
      "\n",
      "Validation loss improved from 0.3601 to 0.3588. Saving model...\n",
      "LOG: Epoch [12/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4824\n",
      "LOG: Epoch [12/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4656\n",
      "    Batch [2/2], Val Loss: 0.2477\n",
      "Epoch [12/2000], Avg Train Loss: 0.4824, Avg Val Loss: 0.3567\n",
      "\n",
      "Validation loss improved from 0.3588 to 0.3567. Saving model...\n",
      "LOG: Epoch [13/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4756\n",
      "LOG: Epoch [13/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4656\n",
      "    Batch [2/2], Val Loss: 0.2455\n",
      "Epoch [13/2000], Avg Train Loss: 0.4756, Avg Val Loss: 0.3555\n",
      "\n",
      "Validation loss improved from 0.3567 to 0.3555. Saving model...\n",
      "LOG: Epoch [14/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4664\n",
      "LOG: Epoch [14/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4657\n",
      "    Batch [2/2], Val Loss: 0.2430\n",
      "Epoch [14/2000], Avg Train Loss: 0.4664, Avg Val Loss: 0.3543\n",
      "\n",
      "Validation loss improved from 0.3555 to 0.3543. Saving model...\n",
      "LOG: Epoch [15/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4730\n",
      "LOG: Epoch [15/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4645\n",
      "    Batch [2/2], Val Loss: 0.2415\n",
      "Epoch [15/2000], Avg Train Loss: 0.4730, Avg Val Loss: 0.3530\n",
      "\n",
      "Validation loss improved from 0.3543 to 0.3530. Saving model...\n",
      "LOG: Epoch [16/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4764\n",
      "LOG: Epoch [16/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4626\n",
      "    Batch [2/2], Val Loss: 0.2398\n",
      "Epoch [16/2000], Avg Train Loss: 0.4764, Avg Val Loss: 0.3512\n",
      "\n",
      "Validation loss improved from 0.3530 to 0.3512. Saving model...\n",
      "LOG: Epoch [17/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4764\n",
      "LOG: Epoch [17/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4610\n",
      "    Batch [2/2], Val Loss: 0.2376\n",
      "Epoch [17/2000], Avg Train Loss: 0.4764, Avg Val Loss: 0.3493\n",
      "\n",
      "Validation loss improved from 0.3512 to 0.3493. Saving model...\n",
      "LOG: Epoch [18/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4658\n",
      "LOG: Epoch [18/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4593\n",
      "    Batch [2/2], Val Loss: 0.2348\n",
      "Epoch [18/2000], Avg Train Loss: 0.4658, Avg Val Loss: 0.3471\n",
      "\n",
      "Validation loss improved from 0.3493 to 0.3471. Saving model...\n",
      "LOG: Epoch [19/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4740\n",
      "LOG: Epoch [19/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4574\n",
      "    Batch [2/2], Val Loss: 0.2312\n",
      "Epoch [19/2000], Avg Train Loss: 0.4740, Avg Val Loss: 0.3443\n",
      "\n",
      "Validation loss improved from 0.3471 to 0.3443. Saving model...\n",
      "LOG: Epoch [20/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4693\n",
      "LOG: Epoch [20/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4557\n",
      "    Batch [2/2], Val Loss: 0.2255\n",
      "Epoch [20/2000], Avg Train Loss: 0.4693, Avg Val Loss: 0.3406\n",
      "\n",
      "Validation loss improved from 0.3443 to 0.3406. Saving model...\n",
      "LOG: Epoch [21/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4720\n",
      "LOG: Epoch [21/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4546\n",
      "    Batch [2/2], Val Loss: 0.2190\n",
      "Epoch [21/2000], Avg Train Loss: 0.4720, Avg Val Loss: 0.3368\n",
      "\n",
      "Validation loss improved from 0.3406 to 0.3368. Saving model...\n",
      "LOG: Epoch [22/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4687\n",
      "LOG: Epoch [22/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4532\n",
      "    Batch [2/2], Val Loss: 0.2132\n",
      "Epoch [22/2000], Avg Train Loss: 0.4687, Avg Val Loss: 0.3332\n",
      "\n",
      "Validation loss improved from 0.3368 to 0.3332. Saving model...\n",
      "LOG: Epoch [23/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4678\n",
      "LOG: Epoch [23/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4520\n",
      "    Batch [2/2], Val Loss: 0.2082\n",
      "Epoch [23/2000], Avg Train Loss: 0.4678, Avg Val Loss: 0.3301\n",
      "\n",
      "Validation loss improved from 0.3332 to 0.3301. Saving model...\n",
      "LOG: Epoch [24/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4689\n",
      "LOG: Epoch [24/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4513\n",
      "    Batch [2/2], Val Loss: 0.2031\n",
      "Epoch [24/2000], Avg Train Loss: 0.4689, Avg Val Loss: 0.3272\n",
      "\n",
      "Validation loss improved from 0.3301 to 0.3272. Saving model...\n",
      "LOG: Epoch [25/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4647\n",
      "LOG: Epoch [25/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4505\n",
      "    Batch [2/2], Val Loss: 0.1966\n",
      "Epoch [25/2000], Avg Train Loss: 0.4647, Avg Val Loss: 0.3235\n",
      "\n",
      "Validation loss improved from 0.3272 to 0.3235. Saving model...\n",
      "LOG: Epoch [26/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4727\n",
      "LOG: Epoch [26/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4488\n",
      "    Batch [2/2], Val Loss: 0.1888\n",
      "Epoch [26/2000], Avg Train Loss: 0.4727, Avg Val Loss: 0.3188\n",
      "\n",
      "Validation loss improved from 0.3235 to 0.3188. Saving model...\n",
      "LOG: Epoch [27/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4623\n",
      "LOG: Epoch [27/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4481\n",
      "    Batch [2/2], Val Loss: 0.1811\n",
      "Epoch [27/2000], Avg Train Loss: 0.4623, Avg Val Loss: 0.3146\n",
      "\n",
      "Validation loss improved from 0.3188 to 0.3146. Saving model...\n",
      "LOG: Epoch [28/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4659\n",
      "LOG: Epoch [28/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4473\n",
      "    Batch [2/2], Val Loss: 0.1744\n",
      "Epoch [28/2000], Avg Train Loss: 0.4659, Avg Val Loss: 0.3108\n",
      "\n",
      "Validation loss improved from 0.3146 to 0.3108. Saving model...\n",
      "LOG: Epoch [29/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4631\n",
      "LOG: Epoch [29/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4467\n",
      "    Batch [2/2], Val Loss: 0.1676\n",
      "Epoch [29/2000], Avg Train Loss: 0.4631, Avg Val Loss: 0.3071\n",
      "\n",
      "Validation loss improved from 0.3108 to 0.3071. Saving model...\n",
      "LOG: Epoch [30/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4649\n",
      "LOG: Epoch [30/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4456\n",
      "    Batch [2/2], Val Loss: 0.1616\n",
      "Epoch [30/2000], Avg Train Loss: 0.4649, Avg Val Loss: 0.3036\n",
      "\n",
      "Validation loss improved from 0.3071 to 0.3036. Saving model...\n",
      "LOG: Epoch [31/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4606\n",
      "LOG: Epoch [31/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4444\n",
      "    Batch [2/2], Val Loss: 0.1570\n",
      "Epoch [31/2000], Avg Train Loss: 0.4606, Avg Val Loss: 0.3007\n",
      "\n",
      "Validation loss improved from 0.3036 to 0.3007. Saving model...\n",
      "LOG: Epoch [32/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4632\n",
      "LOG: Epoch [32/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4436\n",
      "    Batch [2/2], Val Loss: 0.1528\n",
      "Epoch [32/2000], Avg Train Loss: 0.4632, Avg Val Loss: 0.2982\n",
      "\n",
      "Validation loss improved from 0.3007 to 0.2982. Saving model...\n",
      "LOG: Epoch [33/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4596\n",
      "LOG: Epoch [33/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4435\n",
      "    Batch [2/2], Val Loss: 0.1499\n",
      "Epoch [33/2000], Avg Train Loss: 0.4596, Avg Val Loss: 0.2967\n",
      "\n",
      "Validation loss improved from 0.2982 to 0.2967. Saving model...\n",
      "LOG: Epoch [34/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4636\n",
      "LOG: Epoch [34/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4433\n",
      "    Batch [2/2], Val Loss: 0.1473\n",
      "Epoch [34/2000], Avg Train Loss: 0.4636, Avg Val Loss: 0.2953\n",
      "\n",
      "Validation loss improved from 0.2967 to 0.2953. Saving model...\n",
      "LOG: Epoch [35/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4617\n",
      "LOG: Epoch [35/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4429\n",
      "    Batch [2/2], Val Loss: 0.1457\n",
      "Epoch [35/2000], Avg Train Loss: 0.4617, Avg Val Loss: 0.2943\n",
      "\n",
      "Validation loss improved from 0.2953 to 0.2943. Saving model...\n",
      "LOG: Epoch [36/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4597\n",
      "LOG: Epoch [36/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4428\n",
      "    Batch [2/2], Val Loss: 0.1443\n",
      "Epoch [36/2000], Avg Train Loss: 0.4597, Avg Val Loss: 0.2936\n",
      "\n",
      "Validation loss improved from 0.2943 to 0.2936. Saving model...\n",
      "LOG: Epoch [37/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4631\n",
      "LOG: Epoch [37/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4428\n",
      "    Batch [2/2], Val Loss: 0.1433\n",
      "Epoch [37/2000], Avg Train Loss: 0.4631, Avg Val Loss: 0.2931\n",
      "\n",
      "Validation loss improved from 0.2936 to 0.2931. Saving model...\n",
      "LOG: Epoch [38/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4553\n",
      "LOG: Epoch [38/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4428\n",
      "    Batch [2/2], Val Loss: 0.1425\n",
      "Epoch [38/2000], Avg Train Loss: 0.4553, Avg Val Loss: 0.2927\n",
      "\n",
      "Validation loss improved from 0.2931 to 0.2927. Saving model...\n",
      "LOG: Epoch [39/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4538\n",
      "LOG: Epoch [39/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4430\n",
      "    Batch [2/2], Val Loss: 0.1420\n",
      "Epoch [39/2000], Avg Train Loss: 0.4538, Avg Val Loss: 0.2925\n",
      "\n",
      "Validation loss improved from 0.2927 to 0.2925. Saving model...\n",
      "LOG: Epoch [40/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4562\n",
      "LOG: Epoch [40/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4432\n",
      "    Batch [2/2], Val Loss: 0.1419\n",
      "Epoch [40/2000], Avg Train Loss: 0.4562, Avg Val Loss: 0.2925\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [41/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4562\n",
      "LOG: Epoch [41/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4436\n",
      "    Batch [2/2], Val Loss: 0.1416\n",
      "Epoch [41/2000], Avg Train Loss: 0.4562, Avg Val Loss: 0.2926\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [42/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4536\n",
      "LOG: Epoch [42/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4439\n",
      "    Batch [2/2], Val Loss: 0.1415\n",
      "Epoch [42/2000], Avg Train Loss: 0.4536, Avg Val Loss: 0.2927\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [43/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4523\n",
      "LOG: Epoch [43/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4443\n",
      "    Batch [2/2], Val Loss: 0.1415\n",
      "Epoch [43/2000], Avg Train Loss: 0.4523, Avg Val Loss: 0.2929\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [44/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4516\n",
      "LOG: Epoch [44/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4446\n",
      "    Batch [2/2], Val Loss: 0.1412\n",
      "Epoch [44/2000], Avg Train Loss: 0.4516, Avg Val Loss: 0.2929\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [45/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4476\n",
      "LOG: Epoch [45/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4451\n",
      "    Batch [2/2], Val Loss: 0.1410\n",
      "Epoch [45/2000], Avg Train Loss: 0.4476, Avg Val Loss: 0.2931\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [46/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4555\n",
      "LOG: Epoch [46/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4455\n",
      "    Batch [2/2], Val Loss: 0.1410\n",
      "Epoch [46/2000], Avg Train Loss: 0.4555, Avg Val Loss: 0.2932\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [47/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4501\n",
      "LOG: Epoch [47/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4458\n",
      "    Batch [2/2], Val Loss: 0.1411\n",
      "Epoch [47/2000], Avg Train Loss: 0.4501, Avg Val Loss: 0.2934\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [48/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4497\n",
      "LOG: Epoch [48/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4461\n",
      "    Batch [2/2], Val Loss: 0.1413\n",
      "Epoch [48/2000], Avg Train Loss: 0.4497, Avg Val Loss: 0.2937\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [49/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4492\n",
      "LOG: Epoch [49/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4463\n",
      "    Batch [2/2], Val Loss: 0.1414\n",
      "Epoch [49/2000], Avg Train Loss: 0.4492, Avg Val Loss: 0.2938\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [50/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4445\n",
      "LOG: Epoch [50/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4464\n",
      "    Batch [2/2], Val Loss: 0.1414\n",
      "Epoch [50/2000], Avg Train Loss: 0.4445, Avg Val Loss: 0.2939\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [51/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4403\n",
      "LOG: Epoch [51/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4467\n",
      "    Batch [2/2], Val Loss: 0.1413\n",
      "Epoch [51/2000], Avg Train Loss: 0.4403, Avg Val Loss: 0.2940\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [52/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4469\n",
      "LOG: Epoch [52/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4469\n",
      "    Batch [2/2], Val Loss: 0.1410\n",
      "Epoch [52/2000], Avg Train Loss: 0.4469, Avg Val Loss: 0.2940\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [53/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4470\n",
      "LOG: Epoch [53/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4471\n",
      "    Batch [2/2], Val Loss: 0.1405\n",
      "Epoch [53/2000], Avg Train Loss: 0.4470, Avg Val Loss: 0.2938\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [54/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4444\n",
      "LOG: Epoch [54/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4474\n",
      "    Batch [2/2], Val Loss: 0.1399\n",
      "Epoch [54/2000], Avg Train Loss: 0.4444, Avg Val Loss: 0.2937\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [55/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4406\n",
      "LOG: Epoch [55/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4476\n",
      "    Batch [2/2], Val Loss: 0.1394\n",
      "Epoch [55/2000], Avg Train Loss: 0.4406, Avg Val Loss: 0.2935\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [56/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4421\n",
      "LOG: Epoch [56/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4478\n",
      "    Batch [2/2], Val Loss: 0.1390\n",
      "Epoch [56/2000], Avg Train Loss: 0.4421, Avg Val Loss: 0.2934\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [57/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4422\n",
      "LOG: Epoch [57/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4480\n",
      "    Batch [2/2], Val Loss: 0.1385\n",
      "Epoch [57/2000], Avg Train Loss: 0.4422, Avg Val Loss: 0.2933\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [58/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4462\n",
      "LOG: Epoch [58/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4483\n",
      "    Batch [2/2], Val Loss: 0.1381\n",
      "Epoch [58/2000], Avg Train Loss: 0.4462, Avg Val Loss: 0.2932\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [59/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4409\n",
      "LOG: Epoch [59/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4487\n",
      "    Batch [2/2], Val Loss: 0.1375\n",
      "Epoch [59/2000], Avg Train Loss: 0.4409, Avg Val Loss: 0.2931\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [60/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4408\n",
      "LOG: Epoch [60/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4490\n",
      "    Batch [2/2], Val Loss: 0.1372\n",
      "Epoch [60/2000], Avg Train Loss: 0.4408, Avg Val Loss: 0.2931\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [61/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4372\n",
      "LOG: Epoch [61/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4491\n",
      "    Batch [2/2], Val Loss: 0.1369\n",
      "Epoch [61/2000], Avg Train Loss: 0.4372, Avg Val Loss: 0.2930\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [62/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4450\n",
      "LOG: Epoch [62/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4491\n",
      "    Batch [2/2], Val Loss: 0.1367\n",
      "Epoch [62/2000], Avg Train Loss: 0.4450, Avg Val Loss: 0.2929\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [63/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4416\n",
      "LOG: Epoch [63/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4492\n",
      "    Batch [2/2], Val Loss: 0.1365\n",
      "Epoch [63/2000], Avg Train Loss: 0.4416, Avg Val Loss: 0.2928\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [64/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4362\n",
      "LOG: Epoch [64/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4492\n",
      "    Batch [2/2], Val Loss: 0.1366\n",
      "Epoch [64/2000], Avg Train Loss: 0.4362, Avg Val Loss: 0.2929\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [65/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4408\n",
      "LOG: Epoch [65/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4492\n",
      "    Batch [2/2], Val Loss: 0.1370\n",
      "Epoch [65/2000], Avg Train Loss: 0.4408, Avg Val Loss: 0.2931\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [66/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4393\n",
      "LOG: Epoch [66/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4480\n",
      "    Batch [2/2], Val Loss: 0.1350\n",
      "Epoch [66/2000], Avg Train Loss: 0.4393, Avg Val Loss: 0.2915\n",
      "\n",
      "Validation loss improved from 0.2925 to 0.2915. Saving model...\n",
      "LOG: Epoch [67/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4428\n",
      "LOG: Epoch [67/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4467\n",
      "    Batch [2/2], Val Loss: 0.1331\n",
      "Epoch [67/2000], Avg Train Loss: 0.4428, Avg Val Loss: 0.2899\n",
      "\n",
      "Validation loss improved from 0.2915 to 0.2899. Saving model...\n",
      "LOG: Epoch [68/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4379\n",
      "LOG: Epoch [68/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4457\n",
      "    Batch [2/2], Val Loss: 0.1313\n",
      "Epoch [68/2000], Avg Train Loss: 0.4379, Avg Val Loss: 0.2885\n",
      "\n",
      "Validation loss improved from 0.2899 to 0.2885. Saving model...\n",
      "LOG: Epoch [69/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4416\n",
      "LOG: Epoch [69/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4445\n",
      "    Batch [2/2], Val Loss: 0.1296\n",
      "Epoch [69/2000], Avg Train Loss: 0.4416, Avg Val Loss: 0.2871\n",
      "\n",
      "Validation loss improved from 0.2885 to 0.2871. Saving model...\n",
      "LOG: Epoch [70/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4360\n",
      "LOG: Epoch [70/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4435\n",
      "    Batch [2/2], Val Loss: 0.1280\n",
      "Epoch [70/2000], Avg Train Loss: 0.4360, Avg Val Loss: 0.2858\n",
      "\n",
      "Validation loss improved from 0.2871 to 0.2858. Saving model...\n",
      "LOG: Epoch [71/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4322\n",
      "LOG: Epoch [71/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4425\n",
      "    Batch [2/2], Val Loss: 0.1266\n",
      "Epoch [71/2000], Avg Train Loss: 0.4322, Avg Val Loss: 0.2846\n",
      "\n",
      "Validation loss improved from 0.2858 to 0.2846. Saving model...\n",
      "LOG: Epoch [72/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4403\n",
      "LOG: Epoch [72/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4417\n",
      "    Batch [2/2], Val Loss: 0.1254\n",
      "Epoch [72/2000], Avg Train Loss: 0.4403, Avg Val Loss: 0.2836\n",
      "\n",
      "Validation loss improved from 0.2846 to 0.2836. Saving model...\n",
      "LOG: Epoch [73/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4346\n",
      "LOG: Epoch [73/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4409\n",
      "    Batch [2/2], Val Loss: 0.1244\n",
      "Epoch [73/2000], Avg Train Loss: 0.4346, Avg Val Loss: 0.2827\n",
      "\n",
      "Validation loss improved from 0.2836 to 0.2827. Saving model...\n",
      "LOG: Epoch [74/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4402\n",
      "LOG: Epoch [74/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4402\n",
      "    Batch [2/2], Val Loss: 0.1235\n",
      "Epoch [74/2000], Avg Train Loss: 0.4402, Avg Val Loss: 0.2819\n",
      "\n",
      "Validation loss improved from 0.2827 to 0.2819. Saving model...\n",
      "LOG: Epoch [75/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4367\n",
      "LOG: Epoch [75/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4395\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [75/2000], Avg Train Loss: 0.4367, Avg Val Loss: 0.2811\n",
      "\n",
      "Validation loss improved from 0.2819 to 0.2811. Saving model...\n",
      "LOG: Epoch [76/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4358\n",
      "LOG: Epoch [76/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4389\n",
      "    Batch [2/2], Val Loss: 0.1222\n",
      "Epoch [76/2000], Avg Train Loss: 0.4358, Avg Val Loss: 0.2805\n",
      "\n",
      "Validation loss improved from 0.2811 to 0.2805. Saving model...\n",
      "LOG: Epoch [77/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4400\n",
      "LOG: Epoch [77/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4381\n",
      "    Batch [2/2], Val Loss: 0.1218\n",
      "Epoch [77/2000], Avg Train Loss: 0.4400, Avg Val Loss: 0.2800\n",
      "\n",
      "Validation loss improved from 0.2805 to 0.2800. Saving model...\n",
      "LOG: Epoch [78/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4357\n",
      "LOG: Epoch [78/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4373\n",
      "    Batch [2/2], Val Loss: 0.1214\n",
      "Epoch [78/2000], Avg Train Loss: 0.4357, Avg Val Loss: 0.2794\n",
      "\n",
      "Validation loss improved from 0.2800 to 0.2794. Saving model...\n",
      "LOG: Epoch [79/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4362\n",
      "LOG: Epoch [79/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4366\n",
      "    Batch [2/2], Val Loss: 0.1213\n",
      "Epoch [79/2000], Avg Train Loss: 0.4362, Avg Val Loss: 0.2789\n",
      "\n",
      "Validation loss improved from 0.2794 to 0.2789. Saving model...\n",
      "LOG: Epoch [80/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4365\n",
      "LOG: Epoch [80/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4359\n",
      "    Batch [2/2], Val Loss: 0.1213\n",
      "Epoch [80/2000], Avg Train Loss: 0.4365, Avg Val Loss: 0.2786\n",
      "\n",
      "Validation loss improved from 0.2789 to 0.2786. Saving model...\n",
      "LOG: Epoch [81/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4369\n",
      "LOG: Epoch [81/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4352\n",
      "    Batch [2/2], Val Loss: 0.1214\n",
      "Epoch [81/2000], Avg Train Loss: 0.4369, Avg Val Loss: 0.2783\n",
      "\n",
      "Validation loss improved from 0.2786 to 0.2783. Saving model...\n",
      "LOG: Epoch [82/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4336\n",
      "LOG: Epoch [82/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4346\n",
      "    Batch [2/2], Val Loss: 0.1216\n",
      "Epoch [82/2000], Avg Train Loss: 0.4336, Avg Val Loss: 0.2781\n",
      "\n",
      "Validation loss improved from 0.2783 to 0.2781. Saving model...\n",
      "LOG: Epoch [83/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4353\n",
      "LOG: Epoch [83/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4340\n",
      "    Batch [2/2], Val Loss: 0.1218\n",
      "Epoch [83/2000], Avg Train Loss: 0.4353, Avg Val Loss: 0.2779\n",
      "\n",
      "Validation loss improved from 0.2781 to 0.2779. Saving model...\n",
      "LOG: Epoch [84/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4436\n",
      "LOG: Epoch [84/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4335\n",
      "    Batch [2/2], Val Loss: 0.1220\n",
      "Epoch [84/2000], Avg Train Loss: 0.4436, Avg Val Loss: 0.2778\n",
      "\n",
      "Validation loss improved from 0.2779 to 0.2778. Saving model...\n",
      "LOG: Epoch [85/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4347\n",
      "LOG: Epoch [85/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4331\n",
      "    Batch [2/2], Val Loss: 0.1223\n",
      "Epoch [85/2000], Avg Train Loss: 0.4347, Avg Val Loss: 0.2777\n",
      "\n",
      "Validation loss improved from 0.2778 to 0.2777. Saving model...\n",
      "LOG: Epoch [86/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4363\n",
      "LOG: Epoch [86/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4326\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [86/2000], Avg Train Loss: 0.4363, Avg Val Loss: 0.2776\n",
      "\n",
      "Validation loss improved from 0.2777 to 0.2776. Saving model...\n",
      "LOG: Epoch [87/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4354\n",
      "LOG: Epoch [87/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4323\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [87/2000], Avg Train Loss: 0.4354, Avg Val Loss: 0.2776\n",
      "\n",
      "Validation loss improved from 0.2776 to 0.2776. Saving model...\n",
      "LOG: Epoch [88/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4342\n",
      "LOG: Epoch [88/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4319\n",
      "    Batch [2/2], Val Loss: 0.1233\n",
      "Epoch [88/2000], Avg Train Loss: 0.4342, Avg Val Loss: 0.2776\n",
      "\n",
      "Validation loss improved from 0.2776 to 0.2776. Saving model...\n",
      "LOG: Epoch [89/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4433\n",
      "LOG: Epoch [89/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4316\n",
      "    Batch [2/2], Val Loss: 0.1235\n",
      "Epoch [89/2000], Avg Train Loss: 0.4433, Avg Val Loss: 0.2776\n",
      "\n",
      "Validation loss improved from 0.2776 to 0.2776. Saving model...\n",
      "LOG: Epoch [90/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4417\n",
      "LOG: Epoch [90/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4314\n",
      "    Batch [2/2], Val Loss: 0.1238\n",
      "Epoch [90/2000], Avg Train Loss: 0.4417, Avg Val Loss: 0.2776\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [91/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4340\n",
      "LOG: Epoch [91/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4312\n",
      "    Batch [2/2], Val Loss: 0.1241\n",
      "Epoch [91/2000], Avg Train Loss: 0.4340, Avg Val Loss: 0.2776\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [92/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4355\n",
      "LOG: Epoch [92/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4310\n",
      "    Batch [2/2], Val Loss: 0.1243\n",
      "Epoch [92/2000], Avg Train Loss: 0.4355, Avg Val Loss: 0.2776\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [93/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4371\n",
      "LOG: Epoch [93/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4308\n",
      "    Batch [2/2], Val Loss: 0.1245\n",
      "Epoch [93/2000], Avg Train Loss: 0.4371, Avg Val Loss: 0.2777\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [94/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4345\n",
      "LOG: Epoch [94/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4306\n",
      "    Batch [2/2], Val Loss: 0.1247\n",
      "Epoch [94/2000], Avg Train Loss: 0.4345, Avg Val Loss: 0.2777\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [95/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4314\n",
      "LOG: Epoch [95/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4304\n",
      "    Batch [2/2], Val Loss: 0.1249\n",
      "Epoch [95/2000], Avg Train Loss: 0.4314, Avg Val Loss: 0.2777\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [96/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4374\n",
      "LOG: Epoch [96/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4302\n",
      "    Batch [2/2], Val Loss: 0.1251\n",
      "Epoch [96/2000], Avg Train Loss: 0.4374, Avg Val Loss: 0.2777\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [97/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4328\n",
      "LOG: Epoch [97/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4301\n",
      "    Batch [2/2], Val Loss: 0.1253\n",
      "Epoch [97/2000], Avg Train Loss: 0.4328, Avg Val Loss: 0.2777\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [98/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4300\n",
      "LOG: Epoch [98/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4299\n",
      "    Batch [2/2], Val Loss: 0.1254\n",
      "Epoch [98/2000], Avg Train Loss: 0.4300, Avg Val Loss: 0.2776\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [99/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4422\n",
      "LOG: Epoch [99/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4298\n",
      "    Batch [2/2], Val Loss: 0.1255\n",
      "Epoch [99/2000], Avg Train Loss: 0.4422, Avg Val Loss: 0.2776\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [100/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4414\n",
      "LOG: Epoch [100/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4297\n",
      "    Batch [2/2], Val Loss: 0.1255\n",
      "Epoch [100/2000], Avg Train Loss: 0.4414, Avg Val Loss: 0.2776\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [101/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4361\n",
      "LOG: Epoch [101/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4296\n",
      "    Batch [2/2], Val Loss: 0.1255\n",
      "Epoch [101/2000], Avg Train Loss: 0.4361, Avg Val Loss: 0.2775\n",
      "\n",
      "Validation loss improved from 0.2776 to 0.2775. Saving model...\n",
      "LOG: Epoch [102/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4341\n",
      "LOG: Epoch [102/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4294\n",
      "    Batch [2/2], Val Loss: 0.1255\n",
      "Epoch [102/2000], Avg Train Loss: 0.4341, Avg Val Loss: 0.2775\n",
      "\n",
      "Validation loss improved from 0.2775 to 0.2775. Saving model...\n",
      "LOG: Epoch [103/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4400\n",
      "LOG: Epoch [103/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4293\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [103/2000], Avg Train Loss: 0.4400, Avg Val Loss: 0.2774\n",
      "\n",
      "Validation loss improved from 0.2775 to 0.2774. Saving model...\n",
      "LOG: Epoch [104/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4367\n",
      "LOG: Epoch [104/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4292\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [104/2000], Avg Train Loss: 0.4367, Avg Val Loss: 0.2774\n",
      "\n",
      "Validation loss improved from 0.2774 to 0.2774. Saving model...\n",
      "LOG: Epoch [105/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4387\n",
      "LOG: Epoch [105/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4290\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [105/2000], Avg Train Loss: 0.4387, Avg Val Loss: 0.2773\n",
      "\n",
      "Validation loss improved from 0.2774 to 0.2773. Saving model...\n",
      "LOG: Epoch [106/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4354\n",
      "LOG: Epoch [106/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4289\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [106/2000], Avg Train Loss: 0.4354, Avg Val Loss: 0.2773\n",
      "\n",
      "Validation loss improved from 0.2773 to 0.2773. Saving model...\n",
      "LOG: Epoch [107/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4405\n",
      "LOG: Epoch [107/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4288\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [107/2000], Avg Train Loss: 0.4405, Avg Val Loss: 0.2772\n",
      "\n",
      "Validation loss improved from 0.2773 to 0.2772. Saving model...\n",
      "LOG: Epoch [108/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4382\n",
      "LOG: Epoch [108/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4287\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [108/2000], Avg Train Loss: 0.4382, Avg Val Loss: 0.2771\n",
      "\n",
      "Validation loss improved from 0.2772 to 0.2771. Saving model...\n",
      "LOG: Epoch [109/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4337\n",
      "LOG: Epoch [109/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4286\n",
      "    Batch [2/2], Val Loss: 0.1256\n",
      "Epoch [109/2000], Avg Train Loss: 0.4337, Avg Val Loss: 0.2771\n",
      "\n",
      "Validation loss improved from 0.2771 to 0.2771. Saving model...\n",
      "LOG: Epoch [110/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4354\n",
      "LOG: Epoch [110/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4285\n",
      "    Batch [2/2], Val Loss: 0.1255\n",
      "Epoch [110/2000], Avg Train Loss: 0.4354, Avg Val Loss: 0.2770\n",
      "\n",
      "Validation loss improved from 0.2771 to 0.2770. Saving model...\n",
      "LOG: Epoch [111/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4374\n",
      "LOG: Epoch [111/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4283\n",
      "    Batch [2/2], Val Loss: 0.1255\n",
      "Epoch [111/2000], Avg Train Loss: 0.4374, Avg Val Loss: 0.2769\n",
      "\n",
      "Validation loss improved from 0.2770 to 0.2769. Saving model...\n",
      "LOG: Epoch [112/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4325\n",
      "LOG: Epoch [112/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4282\n",
      "    Batch [2/2], Val Loss: 0.1255\n",
      "Epoch [112/2000], Avg Train Loss: 0.4325, Avg Val Loss: 0.2768\n",
      "\n",
      "Validation loss improved from 0.2769 to 0.2768. Saving model...\n",
      "LOG: Epoch [113/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4353\n",
      "LOG: Epoch [113/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4281\n",
      "    Batch [2/2], Val Loss: 0.1254\n",
      "Epoch [113/2000], Avg Train Loss: 0.4353, Avg Val Loss: 0.2768\n",
      "\n",
      "Validation loss improved from 0.2768 to 0.2768. Saving model...\n",
      "LOG: Epoch [114/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4348\n",
      "LOG: Epoch [114/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4280\n",
      "    Batch [2/2], Val Loss: 0.1253\n",
      "Epoch [114/2000], Avg Train Loss: 0.4348, Avg Val Loss: 0.2767\n",
      "\n",
      "Validation loss improved from 0.2768 to 0.2767. Saving model...\n",
      "LOG: Epoch [115/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4323\n",
      "LOG: Epoch [115/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4279\n",
      "    Batch [2/2], Val Loss: 0.1253\n",
      "Epoch [115/2000], Avg Train Loss: 0.4323, Avg Val Loss: 0.2766\n",
      "\n",
      "Validation loss improved from 0.2767 to 0.2766. Saving model...\n",
      "LOG: Epoch [116/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4385\n",
      "LOG: Epoch [116/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4279\n",
      "    Batch [2/2], Val Loss: 0.1252\n",
      "Epoch [116/2000], Avg Train Loss: 0.4385, Avg Val Loss: 0.2765\n",
      "\n",
      "Validation loss improved from 0.2766 to 0.2765. Saving model...\n",
      "LOG: Epoch [117/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4381\n",
      "LOG: Epoch [117/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4278\n",
      "    Batch [2/2], Val Loss: 0.1250\n",
      "Epoch [117/2000], Avg Train Loss: 0.4381, Avg Val Loss: 0.2764\n",
      "\n",
      "Validation loss improved from 0.2765 to 0.2764. Saving model...\n",
      "LOG: Epoch [118/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4379\n",
      "LOG: Epoch [118/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4276\n",
      "    Batch [2/2], Val Loss: 0.1250\n",
      "Epoch [118/2000], Avg Train Loss: 0.4379, Avg Val Loss: 0.2763\n",
      "\n",
      "Validation loss improved from 0.2764 to 0.2763. Saving model...\n",
      "LOG: Epoch [119/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4363\n",
      "LOG: Epoch [119/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4275\n",
      "    Batch [2/2], Val Loss: 0.1249\n",
      "Epoch [119/2000], Avg Train Loss: 0.4363, Avg Val Loss: 0.2762\n",
      "\n",
      "Validation loss improved from 0.2763 to 0.2762. Saving model...\n",
      "LOG: Epoch [120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4295\n",
      "LOG: Epoch [120/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4274\n",
      "    Batch [2/2], Val Loss: 0.1248\n",
      "Epoch [120/2000], Avg Train Loss: 0.4295, Avg Val Loss: 0.2761\n",
      "\n",
      "Validation loss improved from 0.2762 to 0.2761. Saving model...\n",
      "LOG: Epoch [121/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4352\n",
      "LOG: Epoch [121/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4273\n",
      "    Batch [2/2], Val Loss: 0.1247\n",
      "Epoch [121/2000], Avg Train Loss: 0.4352, Avg Val Loss: 0.2760\n",
      "\n",
      "Validation loss improved from 0.2761 to 0.2760. Saving model...\n",
      "LOG: Epoch [122/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4333\n",
      "LOG: Epoch [122/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4273\n",
      "    Batch [2/2], Val Loss: 0.1247\n",
      "Epoch [122/2000], Avg Train Loss: 0.4333, Avg Val Loss: 0.2760\n",
      "\n",
      "Validation loss improved from 0.2760 to 0.2760. Saving model...\n",
      "LOG: Epoch [123/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4394\n",
      "LOG: Epoch [123/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4272\n",
      "    Batch [2/2], Val Loss: 0.1246\n",
      "Epoch [123/2000], Avg Train Loss: 0.4394, Avg Val Loss: 0.2759\n",
      "\n",
      "Validation loss improved from 0.2760 to 0.2759. Saving model...\n",
      "LOG: Epoch [124/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4433\n",
      "LOG: Epoch [124/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4272\n",
      "    Batch [2/2], Val Loss: 0.1246\n",
      "Epoch [124/2000], Avg Train Loss: 0.4433, Avg Val Loss: 0.2759\n",
      "\n",
      "Validation loss improved from 0.2759 to 0.2759. Saving model...\n",
      "LOG: Epoch [125/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4372\n",
      "LOG: Epoch [125/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4271\n",
      "    Batch [2/2], Val Loss: 0.1245\n",
      "Epoch [125/2000], Avg Train Loss: 0.4372, Avg Val Loss: 0.2758\n",
      "\n",
      "Validation loss improved from 0.2759 to 0.2758. Saving model...\n",
      "LOG: Epoch [126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4395\n",
      "LOG: Epoch [126/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4270\n",
      "    Batch [2/2], Val Loss: 0.1244\n",
      "Epoch [126/2000], Avg Train Loss: 0.4395, Avg Val Loss: 0.2757\n",
      "\n",
      "Validation loss improved from 0.2758 to 0.2757. Saving model...\n",
      "LOG: Epoch [127/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4340\n",
      "LOG: Epoch [127/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4269\n",
      "    Batch [2/2], Val Loss: 0.1243\n",
      "Epoch [127/2000], Avg Train Loss: 0.4340, Avg Val Loss: 0.2756\n",
      "\n",
      "Validation loss improved from 0.2757 to 0.2756. Saving model...\n",
      "LOG: Epoch [128/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4342\n",
      "LOG: Epoch [128/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4269\n",
      "    Batch [2/2], Val Loss: 0.1241\n",
      "Epoch [128/2000], Avg Train Loss: 0.4342, Avg Val Loss: 0.2755\n",
      "\n",
      "Validation loss improved from 0.2756 to 0.2755. Saving model...\n",
      "LOG: Epoch [129/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4383\n",
      "LOG: Epoch [129/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4268\n",
      "    Batch [2/2], Val Loss: 0.1241\n",
      "Epoch [129/2000], Avg Train Loss: 0.4383, Avg Val Loss: 0.2754\n",
      "\n",
      "Validation loss improved from 0.2755 to 0.2754. Saving model...\n",
      "LOG: Epoch [130/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4421\n",
      "LOG: Epoch [130/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4267\n",
      "    Batch [2/2], Val Loss: 0.1240\n",
      "Epoch [130/2000], Avg Train Loss: 0.4421, Avg Val Loss: 0.2754\n",
      "\n",
      "Validation loss improved from 0.2754 to 0.2754. Saving model...\n",
      "LOG: Epoch [131/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4442\n",
      "LOG: Epoch [131/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4267\n",
      "    Batch [2/2], Val Loss: 0.1239\n",
      "Epoch [131/2000], Avg Train Loss: 0.4442, Avg Val Loss: 0.2753\n",
      "\n",
      "Validation loss improved from 0.2754 to 0.2753. Saving model...\n",
      "LOG: Epoch [132/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4330\n",
      "LOG: Epoch [132/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4266\n",
      "    Batch [2/2], Val Loss: 0.1239\n",
      "Epoch [132/2000], Avg Train Loss: 0.4330, Avg Val Loss: 0.2752\n",
      "\n",
      "Validation loss improved from 0.2753 to 0.2752. Saving model...\n",
      "LOG: Epoch [133/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4328\n",
      "LOG: Epoch [133/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4265\n",
      "    Batch [2/2], Val Loss: 0.1238\n",
      "Epoch [133/2000], Avg Train Loss: 0.4328, Avg Val Loss: 0.2752\n",
      "\n",
      "Validation loss improved from 0.2752 to 0.2752. Saving model...\n",
      "LOG: Epoch [134/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4343\n",
      "LOG: Epoch [134/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4265\n",
      "    Batch [2/2], Val Loss: 0.1238\n",
      "Epoch [134/2000], Avg Train Loss: 0.4343, Avg Val Loss: 0.2751\n",
      "\n",
      "Validation loss improved from 0.2752 to 0.2751. Saving model...\n",
      "LOG: Epoch [135/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4362\n",
      "LOG: Epoch [135/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4264\n",
      "    Batch [2/2], Val Loss: 0.1238\n",
      "Epoch [135/2000], Avg Train Loss: 0.4362, Avg Val Loss: 0.2751\n",
      "\n",
      "Validation loss improved from 0.2751 to 0.2751. Saving model...\n",
      "LOG: Epoch [136/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4337\n",
      "LOG: Epoch [136/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4264\n",
      "    Batch [2/2], Val Loss: 0.1238\n",
      "Epoch [136/2000], Avg Train Loss: 0.4337, Avg Val Loss: 0.2751\n",
      "\n",
      "Validation loss improved from 0.2751 to 0.2751. Saving model...\n",
      "LOG: Epoch [137/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4345\n",
      "LOG: Epoch [137/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4264\n",
      "    Batch [2/2], Val Loss: 0.1238\n",
      "Epoch [137/2000], Avg Train Loss: 0.4345, Avg Val Loss: 0.2751\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [138/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4386\n",
      "LOG: Epoch [138/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4264\n",
      "    Batch [2/2], Val Loss: 0.1238\n",
      "Epoch [138/2000], Avg Train Loss: 0.4386, Avg Val Loss: 0.2751\n",
      "\n",
      "Validation loss improved from 0.2751 to 0.2751. Saving model...\n",
      "LOG: Epoch [139/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4379\n",
      "LOG: Epoch [139/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4264\n",
      "    Batch [2/2], Val Loss: 0.1237\n",
      "Epoch [139/2000], Avg Train Loss: 0.4379, Avg Val Loss: 0.2751\n",
      "\n",
      "Validation loss improved from 0.2751 to 0.2751. Saving model...\n",
      "LOG: Epoch [140/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4324\n",
      "LOG: Epoch [140/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4264\n",
      "    Batch [2/2], Val Loss: 0.1237\n",
      "Epoch [140/2000], Avg Train Loss: 0.4324, Avg Val Loss: 0.2750\n",
      "\n",
      "Validation loss improved from 0.2751 to 0.2750. Saving model...\n",
      "LOG: Epoch [141/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4333\n",
      "LOG: Epoch [141/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4263\n",
      "    Batch [2/2], Val Loss: 0.1236\n",
      "Epoch [141/2000], Avg Train Loss: 0.4333, Avg Val Loss: 0.2750\n",
      "\n",
      "Validation loss improved from 0.2750 to 0.2750. Saving model...\n",
      "LOG: Epoch [142/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4317\n",
      "LOG: Epoch [142/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4263\n",
      "    Batch [2/2], Val Loss: 0.1236\n",
      "Epoch [142/2000], Avg Train Loss: 0.4317, Avg Val Loss: 0.2749\n",
      "\n",
      "Validation loss improved from 0.2750 to 0.2749. Saving model...\n",
      "LOG: Epoch [143/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4349\n",
      "LOG: Epoch [143/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4262\n",
      "    Batch [2/2], Val Loss: 0.1235\n",
      "Epoch [143/2000], Avg Train Loss: 0.4349, Avg Val Loss: 0.2749\n",
      "\n",
      "Validation loss improved from 0.2749 to 0.2749. Saving model...\n",
      "LOG: Epoch [144/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4297\n",
      "LOG: Epoch [144/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4261\n",
      "    Batch [2/2], Val Loss: 0.1234\n",
      "Epoch [144/2000], Avg Train Loss: 0.4297, Avg Val Loss: 0.2748\n",
      "\n",
      "Validation loss improved from 0.2749 to 0.2748. Saving model...\n",
      "LOG: Epoch [145/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4268\n",
      "LOG: Epoch [145/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4261\n",
      "    Batch [2/2], Val Loss: 0.1233\n",
      "Epoch [145/2000], Avg Train Loss: 0.4268, Avg Val Loss: 0.2747\n",
      "\n",
      "Validation loss improved from 0.2748 to 0.2747. Saving model...\n",
      "LOG: Epoch [146/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4301\n",
      "LOG: Epoch [146/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4261\n",
      "    Batch [2/2], Val Loss: 0.1233\n",
      "Epoch [146/2000], Avg Train Loss: 0.4301, Avg Val Loss: 0.2747\n",
      "\n",
      "Validation loss improved from 0.2747 to 0.2747. Saving model...\n",
      "LOG: Epoch [147/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4315\n",
      "LOG: Epoch [147/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4261\n",
      "    Batch [2/2], Val Loss: 0.1232\n",
      "Epoch [147/2000], Avg Train Loss: 0.4315, Avg Val Loss: 0.2746\n",
      "\n",
      "Validation loss improved from 0.2747 to 0.2746. Saving model...\n",
      "LOG: Epoch [148/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4333\n",
      "LOG: Epoch [148/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4260\n",
      "    Batch [2/2], Val Loss: 0.1232\n",
      "Epoch [148/2000], Avg Train Loss: 0.4333, Avg Val Loss: 0.2746\n",
      "\n",
      "Validation loss improved from 0.2746 to 0.2746. Saving model...\n",
      "LOG: Epoch [149/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4340\n",
      "LOG: Epoch [149/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4260\n",
      "    Batch [2/2], Val Loss: 0.1231\n",
      "Epoch [149/2000], Avg Train Loss: 0.4340, Avg Val Loss: 0.2746\n",
      "\n",
      "Validation loss improved from 0.2746 to 0.2746. Saving model...\n",
      "LOG: Epoch [150/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4324\n",
      "LOG: Epoch [150/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4260\n",
      "    Batch [2/2], Val Loss: 0.1231\n",
      "Epoch [150/2000], Avg Train Loss: 0.4324, Avg Val Loss: 0.2746\n",
      "\n",
      "Validation loss improved from 0.2746 to 0.2746. Saving model...\n",
      "LOG: Epoch [151/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4324\n",
      "LOG: Epoch [151/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4260\n",
      "    Batch [2/2], Val Loss: 0.1231\n",
      "Epoch [151/2000], Avg Train Loss: 0.4324, Avg Val Loss: 0.2745\n",
      "\n",
      "Validation loss improved from 0.2746 to 0.2745. Saving model...\n",
      "LOG: Epoch [152/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4267\n",
      "LOG: Epoch [152/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4260\n",
      "    Batch [2/2], Val Loss: 0.1231\n",
      "Epoch [152/2000], Avg Train Loss: 0.4267, Avg Val Loss: 0.2745\n",
      "\n",
      "Validation loss improved from 0.2745 to 0.2745. Saving model...\n",
      "LOG: Epoch [153/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4403\n",
      "LOG: Epoch [153/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4259\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [153/2000], Avg Train Loss: 0.4403, Avg Val Loss: 0.2745\n",
      "\n",
      "Validation loss improved from 0.2745 to 0.2745. Saving model...\n",
      "LOG: Epoch [154/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4336\n",
      "LOG: Epoch [154/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4259\n",
      "    Batch [2/2], Val Loss: 0.1230\n",
      "Epoch [154/2000], Avg Train Loss: 0.4336, Avg Val Loss: 0.2744\n",
      "\n",
      "Validation loss improved from 0.2745 to 0.2744. Saving model...\n",
      "LOG: Epoch [155/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4313\n",
      "LOG: Epoch [155/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4259\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [155/2000], Avg Train Loss: 0.4313, Avg Val Loss: 0.2744\n",
      "\n",
      "Validation loss improved from 0.2744 to 0.2744. Saving model...\n",
      "LOG: Epoch [156/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4294\n",
      "LOG: Epoch [156/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4259\n",
      "    Batch [2/2], Val Loss: 0.1229\n",
      "Epoch [156/2000], Avg Train Loss: 0.4294, Avg Val Loss: 0.2744\n",
      "\n",
      "Validation loss improved from 0.2744 to 0.2744. Saving model...\n",
      "LOG: Epoch [157/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4357\n",
      "LOG: Epoch [157/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4258\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [157/2000], Avg Train Loss: 0.4357, Avg Val Loss: 0.2743\n",
      "\n",
      "Validation loss improved from 0.2744 to 0.2743. Saving model...\n",
      "LOG: Epoch [158/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4335\n",
      "LOG: Epoch [158/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4258\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [158/2000], Avg Train Loss: 0.4335, Avg Val Loss: 0.2743\n",
      "\n",
      "Validation loss improved from 0.2743 to 0.2743. Saving model...\n",
      "LOG: Epoch [159/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4237\n",
      "LOG: Epoch [159/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4258\n",
      "    Batch [2/2], Val Loss: 0.1228\n",
      "Epoch [159/2000], Avg Train Loss: 0.4237, Avg Val Loss: 0.2743\n",
      "\n",
      "Validation loss improved from 0.2743 to 0.2743. Saving model...\n",
      "LOG: Epoch [160/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4354\n",
      "LOG: Epoch [160/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4258\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [160/2000], Avg Train Loss: 0.4354, Avg Val Loss: 0.2743\n",
      "\n",
      "Validation loss improved from 0.2743 to 0.2743. Saving model...\n",
      "LOG: Epoch [161/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4337\n",
      "LOG: Epoch [161/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4258\n",
      "    Batch [2/2], Val Loss: 0.1227\n",
      "Epoch [161/2000], Avg Train Loss: 0.4337, Avg Val Loss: 0.2742\n",
      "\n",
      "Validation loss improved from 0.2743 to 0.2742. Saving model...\n",
      "LOG: Epoch [162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4305\n",
      "LOG: Epoch [162/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4258\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [162/2000], Avg Train Loss: 0.4305, Avg Val Loss: 0.2742\n",
      "\n",
      "Validation loss improved from 0.2742 to 0.2742. Saving model...\n",
      "LOG: Epoch [163/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4356\n",
      "LOG: Epoch [163/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4258\n",
      "    Batch [2/2], Val Loss: 0.1226\n",
      "Epoch [163/2000], Avg Train Loss: 0.4356, Avg Val Loss: 0.2742\n",
      "\n",
      "Validation loss improved from 0.2742 to 0.2742. Saving model...\n",
      "LOG: Epoch [164/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4306\n",
      "LOG: Epoch [164/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4259\n",
      "    Batch [2/2], Val Loss: 0.1225\n",
      "Epoch [164/2000], Avg Train Loss: 0.4306, Avg Val Loss: 0.2742\n",
      "\n",
      "Validation loss improved from 0.2742 to 0.2742. Saving model...\n",
      "LOG: Epoch [165/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4302\n",
      "LOG: Epoch [165/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4259\n",
      "    Batch [2/2], Val Loss: 0.1225\n",
      "Epoch [165/2000], Avg Train Loss: 0.4302, Avg Val Loss: 0.2742\n",
      "\n",
      "Validation loss improved from 0.2742 to 0.2742. Saving model...\n",
      "LOG: Epoch [166/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4366\n",
      "LOG: Epoch [166/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4259\n",
      "    Batch [2/2], Val Loss: 0.1225\n",
      "Epoch [166/2000], Avg Train Loss: 0.4366, Avg Val Loss: 0.2742\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [167/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4282\n",
      "LOG: Epoch [167/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4259\n",
      "    Batch [2/2], Val Loss: 0.1224\n",
      "Epoch [167/2000], Avg Train Loss: 0.4282, Avg Val Loss: 0.2741\n",
      "\n",
      "Validation loss improved from 0.2742 to 0.2741. Saving model...\n",
      "LOG: Epoch [168/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4305\n",
      "LOG: Epoch [168/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4259\n",
      "    Batch [2/2], Val Loss: 0.1223\n",
      "Epoch [168/2000], Avg Train Loss: 0.4305, Avg Val Loss: 0.2741\n",
      "\n",
      "Validation loss improved from 0.2741 to 0.2741. Saving model...\n",
      "LOG: Epoch [169/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4331\n",
      "LOG: Epoch [169/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4259\n",
      "    Batch [2/2], Val Loss: 0.1223\n",
      "Epoch [169/2000], Avg Train Loss: 0.4331, Avg Val Loss: 0.2741\n",
      "\n",
      "Validation loss improved from 0.2741 to 0.2741. Saving model...\n",
      "LOG: Epoch [170/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4288\n",
      "LOG: Epoch [170/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4259\n",
      "    Batch [2/2], Val Loss: 0.1222\n",
      "Epoch [170/2000], Avg Train Loss: 0.4288, Avg Val Loss: 0.2740\n",
      "\n",
      "Validation loss improved from 0.2741 to 0.2740. Saving model...\n",
      "LOG: Epoch [171/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4329\n",
      "LOG: Epoch [171/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4258\n",
      "    Batch [2/2], Val Loss: 0.1221\n",
      "Epoch [171/2000], Avg Train Loss: 0.4329, Avg Val Loss: 0.2740\n",
      "\n",
      "Validation loss improved from 0.2740 to 0.2740. Saving model...\n",
      "LOG: Epoch [172/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4347\n",
      "LOG: Epoch [172/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4258\n",
      "    Batch [2/2], Val Loss: 0.1220\n",
      "Epoch [172/2000], Avg Train Loss: 0.4347, Avg Val Loss: 0.2739\n",
      "\n",
      "Validation loss improved from 0.2740 to 0.2739. Saving model...\n",
      "LOG: Epoch [173/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4348\n",
      "LOG: Epoch [173/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4257\n",
      "    Batch [2/2], Val Loss: 0.1219\n",
      "Epoch [173/2000], Avg Train Loss: 0.4348, Avg Val Loss: 0.2738\n",
      "\n",
      "Validation loss improved from 0.2739 to 0.2738. Saving model...\n",
      "LOG: Epoch [174/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4357\n",
      "LOG: Epoch [174/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4256\n",
      "    Batch [2/2], Val Loss: 0.1218\n",
      "Epoch [174/2000], Avg Train Loss: 0.4357, Avg Val Loss: 0.2737\n",
      "\n",
      "Validation loss improved from 0.2738 to 0.2737. Saving model...\n",
      "LOG: Epoch [175/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4298\n",
      "LOG: Epoch [175/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4256\n",
      "    Batch [2/2], Val Loss: 0.1217\n",
      "Epoch [175/2000], Avg Train Loss: 0.4298, Avg Val Loss: 0.2737\n",
      "\n",
      "Validation loss improved from 0.2737 to 0.2737. Saving model...\n",
      "LOG: Epoch [176/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4330\n",
      "LOG: Epoch [176/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4256\n",
      "    Batch [2/2], Val Loss: 0.1217\n",
      "Epoch [176/2000], Avg Train Loss: 0.4330, Avg Val Loss: 0.2736\n",
      "\n",
      "Validation loss improved from 0.2737 to 0.2736. Saving model...\n",
      "LOG: Epoch [177/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4317\n",
      "LOG: Epoch [177/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4256\n",
      "    Batch [2/2], Val Loss: 0.1216\n",
      "Epoch [177/2000], Avg Train Loss: 0.4317, Avg Val Loss: 0.2736\n",
      "\n",
      "Validation loss improved from 0.2736 to 0.2736. Saving model...\n",
      "LOG: Epoch [178/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4314\n",
      "LOG: Epoch [178/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4255\n",
      "    Batch [2/2], Val Loss: 0.1215\n",
      "Epoch [178/2000], Avg Train Loss: 0.4314, Avg Val Loss: 0.2735\n",
      "\n",
      "Validation loss improved from 0.2736 to 0.2735. Saving model...\n",
      "LOG: Epoch [179/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4350\n",
      "LOG: Epoch [179/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4256\n",
      "    Batch [2/2], Val Loss: 0.1215\n",
      "Epoch [179/2000], Avg Train Loss: 0.4350, Avg Val Loss: 0.2735\n",
      "\n",
      "Validation loss improved from 0.2735 to 0.2735. Saving model...\n",
      "LOG: Epoch [180/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4302\n",
      "LOG: Epoch [180/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4256\n",
      "    Batch [2/2], Val Loss: 0.1214\n",
      "Epoch [180/2000], Avg Train Loss: 0.4302, Avg Val Loss: 0.2735\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [181/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4276\n",
      "LOG: Epoch [181/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4257\n",
      "    Batch [2/2], Val Loss: 0.1214\n",
      "Epoch [181/2000], Avg Train Loss: 0.4276, Avg Val Loss: 0.2735\n",
      "\n",
      "Validation loss improved from 0.2735 to 0.2735. Saving model...\n",
      "LOG: Epoch [182/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4342\n",
      "LOG: Epoch [182/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4257\n",
      "    Batch [2/2], Val Loss: 0.1213\n",
      "Epoch [182/2000], Avg Train Loss: 0.4342, Avg Val Loss: 0.2735\n",
      "\n",
      "Validation loss improved from 0.2735 to 0.2735. Saving model...\n",
      "LOG: Epoch [183/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4199\n",
      "LOG: Epoch [183/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4256\n",
      "    Batch [2/2], Val Loss: 0.1213\n",
      "Epoch [183/2000], Avg Train Loss: 0.4199, Avg Val Loss: 0.2735\n",
      "\n",
      "Validation loss improved from 0.2735 to 0.2735. Saving model...\n",
      "LOG: Epoch [184/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4279\n",
      "LOG: Epoch [184/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4257\n",
      "    Batch [2/2], Val Loss: 0.1212\n",
      "Epoch [184/2000], Avg Train Loss: 0.4279, Avg Val Loss: 0.2734\n",
      "\n",
      "Validation loss improved from 0.2735 to 0.2734. Saving model...\n",
      "LOG: Epoch [185/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4303\n",
      "LOG: Epoch [185/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4256\n",
      "    Batch [2/2], Val Loss: 0.1212\n",
      "Epoch [185/2000], Avg Train Loss: 0.4303, Avg Val Loss: 0.2734\n",
      "\n",
      "Validation loss improved from 0.2734 to 0.2734. Saving model...\n",
      "LOG: Epoch [186/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4248\n",
      "LOG: Epoch [186/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4256\n",
      "    Batch [2/2], Val Loss: 0.1211\n",
      "Epoch [186/2000], Avg Train Loss: 0.4248, Avg Val Loss: 0.2734\n",
      "\n",
      "Validation loss improved from 0.2734 to 0.2734. Saving model...\n",
      "LOG: Epoch [187/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4319\n",
      "LOG: Epoch [187/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4256\n",
      "    Batch [2/2], Val Loss: 0.1210\n",
      "Epoch [187/2000], Avg Train Loss: 0.4319, Avg Val Loss: 0.2733\n",
      "\n",
      "Validation loss improved from 0.2734 to 0.2733. Saving model...\n",
      "LOG: Epoch [188/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4331\n",
      "LOG: Epoch [188/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4255\n",
      "    Batch [2/2], Val Loss: 0.1210\n",
      "Epoch [188/2000], Avg Train Loss: 0.4331, Avg Val Loss: 0.2732\n",
      "\n",
      "Validation loss improved from 0.2733 to 0.2732. Saving model...\n",
      "LOG: Epoch [189/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4295\n",
      "LOG: Epoch [189/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4255\n",
      "    Batch [2/2], Val Loss: 0.1209\n",
      "Epoch [189/2000], Avg Train Loss: 0.4295, Avg Val Loss: 0.2732\n",
      "\n",
      "Validation loss improved from 0.2732 to 0.2732. Saving model...\n",
      "LOG: Epoch [190/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4267\n",
      "LOG: Epoch [190/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4254\n",
      "    Batch [2/2], Val Loss: 0.1208\n",
      "Epoch [190/2000], Avg Train Loss: 0.4267, Avg Val Loss: 0.2731\n",
      "\n",
      "Validation loss improved from 0.2732 to 0.2731. Saving model...\n",
      "LOG: Epoch [191/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4303\n",
      "LOG: Epoch [191/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4254\n",
      "    Batch [2/2], Val Loss: 0.1207\n",
      "Epoch [191/2000], Avg Train Loss: 0.4303, Avg Val Loss: 0.2730\n",
      "\n",
      "Validation loss improved from 0.2731 to 0.2730. Saving model...\n",
      "LOG: Epoch [192/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4293\n",
      "LOG: Epoch [192/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4253\n",
      "    Batch [2/2], Val Loss: 0.1206\n",
      "Epoch [192/2000], Avg Train Loss: 0.4293, Avg Val Loss: 0.2730\n",
      "\n",
      "Validation loss improved from 0.2730 to 0.2730. Saving model...\n",
      "LOG: Epoch [193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4305\n",
      "LOG: Epoch [193/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4253\n",
      "    Batch [2/2], Val Loss: 0.1205\n",
      "Epoch [193/2000], Avg Train Loss: 0.4305, Avg Val Loss: 0.2729\n",
      "\n",
      "Validation loss improved from 0.2730 to 0.2729. Saving model...\n",
      "LOG: Epoch [194/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4333\n",
      "LOG: Epoch [194/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4252\n",
      "    Batch [2/2], Val Loss: 0.1204\n",
      "Epoch [194/2000], Avg Train Loss: 0.4333, Avg Val Loss: 0.2728\n",
      "\n",
      "Validation loss improved from 0.2729 to 0.2728. Saving model...\n",
      "LOG: Epoch [195/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4200\n",
      "LOG: Epoch [195/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4252\n",
      "    Batch [2/2], Val Loss: 0.1204\n",
      "Epoch [195/2000], Avg Train Loss: 0.4200, Avg Val Loss: 0.2728\n",
      "\n",
      "Validation loss improved from 0.2728 to 0.2728. Saving model...\n",
      "LOG: Epoch [196/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4346\n",
      "LOG: Epoch [196/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4251\n",
      "    Batch [2/2], Val Loss: 0.1204\n",
      "Epoch [196/2000], Avg Train Loss: 0.4346, Avg Val Loss: 0.2727\n",
      "\n",
      "Validation loss improved from 0.2728 to 0.2727. Saving model...\n",
      "LOG: Epoch [197/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4249\n",
      "LOG: Epoch [197/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4251\n",
      "    Batch [2/2], Val Loss: 0.1204\n",
      "Epoch [197/2000], Avg Train Loss: 0.4249, Avg Val Loss: 0.2727\n",
      "\n",
      "Validation loss improved from 0.2727 to 0.2727. Saving model...\n",
      "LOG: Epoch [198/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4355\n",
      "LOG: Epoch [198/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4250\n",
      "    Batch [2/2], Val Loss: 0.1203\n",
      "Epoch [198/2000], Avg Train Loss: 0.4355, Avg Val Loss: 0.2727\n",
      "\n",
      "Validation loss improved from 0.2727 to 0.2727. Saving model...\n",
      "LOG: Epoch [199/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4314\n",
      "LOG: Epoch [199/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4250\n",
      "    Batch [2/2], Val Loss: 0.1202\n",
      "Epoch [199/2000], Avg Train Loss: 0.4314, Avg Val Loss: 0.2726\n",
      "\n",
      "Validation loss improved from 0.2727 to 0.2726. Saving model...\n",
      "LOG: Epoch [200/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4295\n",
      "LOG: Epoch [200/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4250\n",
      "    Batch [2/2], Val Loss: 0.1201\n",
      "Epoch [200/2000], Avg Train Loss: 0.4295, Avg Val Loss: 0.2726\n",
      "\n",
      "Validation loss improved from 0.2726 to 0.2726. Saving model...\n",
      "LOG: Epoch [201/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4270\n",
      "LOG: Epoch [201/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4250\n",
      "    Batch [2/2], Val Loss: 0.1201\n",
      "Epoch [201/2000], Avg Train Loss: 0.4270, Avg Val Loss: 0.2725\n",
      "\n",
      "Validation loss improved from 0.2726 to 0.2725. Saving model...\n",
      "LOG: Epoch [202/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4271\n",
      "LOG: Epoch [202/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4250\n",
      "    Batch [2/2], Val Loss: 0.1200\n",
      "Epoch [202/2000], Avg Train Loss: 0.4271, Avg Val Loss: 0.2725\n",
      "\n",
      "Validation loss improved from 0.2725 to 0.2725. Saving model...\n",
      "LOG: Epoch [203/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4273\n",
      "LOG: Epoch [203/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4249\n",
      "    Batch [2/2], Val Loss: 0.1200\n",
      "Epoch [203/2000], Avg Train Loss: 0.4273, Avg Val Loss: 0.2725\n",
      "\n",
      "Validation loss improved from 0.2725 to 0.2725. Saving model...\n",
      "LOG: Epoch [204/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4281\n",
      "LOG: Epoch [204/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4249\n",
      "    Batch [2/2], Val Loss: 0.1200\n",
      "Epoch [204/2000], Avg Train Loss: 0.4281, Avg Val Loss: 0.2725\n",
      "\n",
      "Validation loss improved from 0.2725 to 0.2725. Saving model...\n",
      "LOG: Epoch [205/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4322\n",
      "LOG: Epoch [205/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4249\n",
      "    Batch [2/2], Val Loss: 0.1200\n",
      "Epoch [205/2000], Avg Train Loss: 0.4322, Avg Val Loss: 0.2724\n",
      "\n",
      "Validation loss improved from 0.2725 to 0.2724. Saving model...\n",
      "LOG: Epoch [206/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4315\n",
      "LOG: Epoch [206/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4248\n",
      "    Batch [2/2], Val Loss: 0.1200\n",
      "Epoch [206/2000], Avg Train Loss: 0.4315, Avg Val Loss: 0.2724\n",
      "\n",
      "Validation loss improved from 0.2724 to 0.2724. Saving model...\n",
      "LOG: Epoch [207/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4319\n",
      "LOG: Epoch [207/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4247\n",
      "    Batch [2/2], Val Loss: 0.1200\n",
      "Epoch [207/2000], Avg Train Loss: 0.4319, Avg Val Loss: 0.2724\n",
      "\n",
      "Validation loss improved from 0.2724 to 0.2724. Saving model...\n",
      "LOG: Epoch [208/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4262\n",
      "LOG: Epoch [208/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4247\n",
      "    Batch [2/2], Val Loss: 0.1200\n",
      "Epoch [208/2000], Avg Train Loss: 0.4262, Avg Val Loss: 0.2724\n",
      "\n",
      "Validation loss improved from 0.2724 to 0.2724. Saving model...\n",
      "LOG: Epoch [209/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4326\n",
      "LOG: Epoch [209/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4247\n",
      "    Batch [2/2], Val Loss: 0.1200\n",
      "Epoch [209/2000], Avg Train Loss: 0.4326, Avg Val Loss: 0.2723\n",
      "\n",
      "Validation loss improved from 0.2724 to 0.2723. Saving model...\n",
      "LOG: Epoch [210/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4284\n",
      "LOG: Epoch [210/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4246\n",
      "    Batch [2/2], Val Loss: 0.1200\n",
      "Epoch [210/2000], Avg Train Loss: 0.4284, Avg Val Loss: 0.2723\n",
      "\n",
      "Validation loss improved from 0.2723 to 0.2723. Saving model...\n",
      "LOG: Epoch [211/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4246\n",
      "LOG: Epoch [211/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4246\n",
      "    Batch [2/2], Val Loss: 0.1200\n",
      "Epoch [211/2000], Avg Train Loss: 0.4246, Avg Val Loss: 0.2723\n",
      "\n",
      "Validation loss improved from 0.2723 to 0.2723. Saving model...\n",
      "LOG: Epoch [212/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4283\n",
      "LOG: Epoch [212/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4246\n",
      "    Batch [2/2], Val Loss: 0.1200\n",
      "Epoch [212/2000], Avg Train Loss: 0.4283, Avg Val Loss: 0.2723\n",
      "\n",
      "Validation loss improved from 0.2723 to 0.2723. Saving model...\n",
      "LOG: Epoch [213/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4275\n",
      "LOG: Epoch [213/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4245\n",
      "    Batch [2/2], Val Loss: 0.1199\n",
      "Epoch [213/2000], Avg Train Loss: 0.4275, Avg Val Loss: 0.2722\n",
      "\n",
      "Validation loss improved from 0.2723 to 0.2722. Saving model...\n",
      "LOG: Epoch [214/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4291\n",
      "LOG: Epoch [214/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4244\n",
      "    Batch [2/2], Val Loss: 0.1199\n",
      "Epoch [214/2000], Avg Train Loss: 0.4291, Avg Val Loss: 0.2722\n",
      "\n",
      "Validation loss improved from 0.2722 to 0.2722. Saving model...\n",
      "LOG: Epoch [215/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4262\n",
      "LOG: Epoch [215/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4244\n",
      "    Batch [2/2], Val Loss: 0.1198\n",
      "Epoch [215/2000], Avg Train Loss: 0.4262, Avg Val Loss: 0.2721\n",
      "\n",
      "Validation loss improved from 0.2722 to 0.2721. Saving model...\n",
      "LOG: Epoch [216/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4280\n",
      "LOG: Epoch [216/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4243\n",
      "    Batch [2/2], Val Loss: 0.1198\n",
      "Epoch [216/2000], Avg Train Loss: 0.4280, Avg Val Loss: 0.2720\n",
      "\n",
      "Validation loss improved from 0.2721 to 0.2720. Saving model...\n",
      "LOG: Epoch [217/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4294\n",
      "LOG: Epoch [217/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4243\n",
      "    Batch [2/2], Val Loss: 0.1197\n",
      "Epoch [217/2000], Avg Train Loss: 0.4294, Avg Val Loss: 0.2720\n",
      "\n",
      "Validation loss improved from 0.2720 to 0.2720. Saving model...\n",
      "LOG: Epoch [218/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4306\n",
      "LOG: Epoch [218/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4242\n",
      "    Batch [2/2], Val Loss: 0.1196\n",
      "Epoch [218/2000], Avg Train Loss: 0.4306, Avg Val Loss: 0.2719\n",
      "\n",
      "Validation loss improved from 0.2720 to 0.2719. Saving model...\n",
      "LOG: Epoch [219/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4299\n",
      "LOG: Epoch [219/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4241\n",
      "    Batch [2/2], Val Loss: 0.1195\n",
      "Epoch [219/2000], Avg Train Loss: 0.4299, Avg Val Loss: 0.2718\n",
      "\n",
      "Validation loss improved from 0.2719 to 0.2718. Saving model...\n",
      "LOG: Epoch [220/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4248\n",
      "LOG: Epoch [220/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4240\n",
      "    Batch [2/2], Val Loss: 0.1194\n",
      "Epoch [220/2000], Avg Train Loss: 0.4248, Avg Val Loss: 0.2717\n",
      "\n",
      "Validation loss improved from 0.2718 to 0.2717. Saving model...\n",
      "LOG: Epoch [221/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4305\n",
      "LOG: Epoch [221/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4238\n",
      "    Batch [2/2], Val Loss: 0.1193\n",
      "Epoch [221/2000], Avg Train Loss: 0.4305, Avg Val Loss: 0.2716\n",
      "\n",
      "Validation loss improved from 0.2717 to 0.2716. Saving model...\n",
      "LOG: Epoch [222/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4319\n",
      "LOG: Epoch [222/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4237\n",
      "    Batch [2/2], Val Loss: 0.1192\n",
      "Epoch [222/2000], Avg Train Loss: 0.4319, Avg Val Loss: 0.2714\n",
      "\n",
      "Validation loss improved from 0.2716 to 0.2714. Saving model...\n",
      "LOG: Epoch [223/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4359\n",
      "LOG: Epoch [223/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4236\n",
      "    Batch [2/2], Val Loss: 0.1191\n",
      "Epoch [223/2000], Avg Train Loss: 0.4359, Avg Val Loss: 0.2713\n",
      "\n",
      "Validation loss improved from 0.2714 to 0.2713. Saving model...\n",
      "LOG: Epoch [224/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4304\n",
      "LOG: Epoch [224/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4235\n",
      "    Batch [2/2], Val Loss: 0.1189\n",
      "Epoch [224/2000], Avg Train Loss: 0.4304, Avg Val Loss: 0.2712\n",
      "\n",
      "Validation loss improved from 0.2713 to 0.2712. Saving model...\n",
      "LOG: Epoch [225/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4283\n",
      "LOG: Epoch [225/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4235\n",
      "    Batch [2/2], Val Loss: 0.1188\n",
      "Epoch [225/2000], Avg Train Loss: 0.4283, Avg Val Loss: 0.2712\n",
      "\n",
      "Validation loss improved from 0.2712 to 0.2712. Saving model...\n",
      "LOG: Epoch [226/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4290\n",
      "LOG: Epoch [226/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4234\n",
      "    Batch [2/2], Val Loss: 0.1187\n",
      "Epoch [226/2000], Avg Train Loss: 0.4290, Avg Val Loss: 0.2710\n",
      "\n",
      "Validation loss improved from 0.2712 to 0.2710. Saving model...\n",
      "LOG: Epoch [227/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4279\n",
      "LOG: Epoch [227/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4233\n",
      "    Batch [2/2], Val Loss: 0.1186\n",
      "Epoch [227/2000], Avg Train Loss: 0.4279, Avg Val Loss: 0.2709\n",
      "\n",
      "Validation loss improved from 0.2710 to 0.2709. Saving model...\n",
      "LOG: Epoch [228/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4325\n",
      "LOG: Epoch [228/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4232\n",
      "    Batch [2/2], Val Loss: 0.1185\n",
      "Epoch [228/2000], Avg Train Loss: 0.4325, Avg Val Loss: 0.2709\n",
      "\n",
      "Validation loss improved from 0.2709 to 0.2709. Saving model...\n",
      "LOG: Epoch [229/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4262\n",
      "LOG: Epoch [229/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4231\n",
      "    Batch [2/2], Val Loss: 0.1184\n",
      "Epoch [229/2000], Avg Train Loss: 0.4262, Avg Val Loss: 0.2708\n",
      "\n",
      "Validation loss improved from 0.2709 to 0.2708. Saving model...\n",
      "LOG: Epoch [230/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4259\n",
      "LOG: Epoch [230/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4231\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [230/2000], Avg Train Loss: 0.4259, Avg Val Loss: 0.2707\n",
      "\n",
      "Validation loss improved from 0.2708 to 0.2707. Saving model...\n",
      "LOG: Epoch [231/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4297\n",
      "LOG: Epoch [231/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4230\n",
      "    Batch [2/2], Val Loss: 0.1183\n",
      "Epoch [231/2000], Avg Train Loss: 0.4297, Avg Val Loss: 0.2706\n",
      "\n",
      "Validation loss improved from 0.2707 to 0.2706. Saving model...\n",
      "LOG: Epoch [232/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4289\n",
      "LOG: Epoch [232/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4230\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [232/2000], Avg Train Loss: 0.4289, Avg Val Loss: 0.2706\n",
      "\n",
      "Validation loss improved from 0.2706 to 0.2706. Saving model...\n",
      "LOG: Epoch [233/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4272\n",
      "LOG: Epoch [233/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4229\n",
      "    Batch [2/2], Val Loss: 0.1182\n",
      "Epoch [233/2000], Avg Train Loss: 0.4272, Avg Val Loss: 0.2705\n",
      "\n",
      "Validation loss improved from 0.2706 to 0.2705. Saving model...\n",
      "LOG: Epoch [234/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4288\n",
      "LOG: Epoch [234/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4229\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [234/2000], Avg Train Loss: 0.4288, Avg Val Loss: 0.2705\n",
      "\n",
      "Validation loss improved from 0.2705 to 0.2705. Saving model...\n",
      "LOG: Epoch [235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4334\n",
      "LOG: Epoch [235/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4228\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [235/2000], Avg Train Loss: 0.4334, Avg Val Loss: 0.2705\n",
      "\n",
      "Validation loss improved from 0.2705 to 0.2705. Saving model...\n",
      "LOG: Epoch [236/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4273\n",
      "LOG: Epoch [236/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4227\n",
      "    Batch [2/2], Val Loss: 0.1181\n",
      "Epoch [236/2000], Avg Train Loss: 0.4273, Avg Val Loss: 0.2704\n",
      "\n",
      "Validation loss improved from 0.2705 to 0.2704. Saving model...\n",
      "LOG: Epoch [237/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4293\n",
      "LOG: Epoch [237/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4227\n",
      "    Batch [2/2], Val Loss: 0.1180\n",
      "Epoch [237/2000], Avg Train Loss: 0.4293, Avg Val Loss: 0.2703\n",
      "\n",
      "Validation loss improved from 0.2704 to 0.2703. Saving model...\n",
      "LOG: Epoch [238/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4320\n",
      "LOG: Epoch [238/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4226\n",
      "    Batch [2/2], Val Loss: 0.1179\n",
      "Epoch [238/2000], Avg Train Loss: 0.4320, Avg Val Loss: 0.2703\n",
      "\n",
      "Validation loss improved from 0.2703 to 0.2703. Saving model...\n",
      "LOG: Epoch [239/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4269\n",
      "LOG: Epoch [239/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4226\n",
      "    Batch [2/2], Val Loss: 0.1178\n",
      "Epoch [239/2000], Avg Train Loss: 0.4269, Avg Val Loss: 0.2702\n",
      "\n",
      "Validation loss improved from 0.2703 to 0.2702. Saving model...\n",
      "LOG: Epoch [240/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4263\n",
      "LOG: Epoch [240/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4224\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [240/2000], Avg Train Loss: 0.4263, Avg Val Loss: 0.2701\n",
      "\n",
      "Validation loss improved from 0.2702 to 0.2701. Saving model...\n",
      "LOG: Epoch [241/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4336\n",
      "LOG: Epoch [241/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4223\n",
      "    Batch [2/2], Val Loss: 0.1177\n",
      "Epoch [241/2000], Avg Train Loss: 0.4336, Avg Val Loss: 0.2700\n",
      "\n",
      "Validation loss improved from 0.2701 to 0.2700. Saving model...\n",
      "LOG: Epoch [242/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4306\n",
      "LOG: Epoch [242/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4223\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [242/2000], Avg Train Loss: 0.4306, Avg Val Loss: 0.2700\n",
      "\n",
      "Validation loss improved from 0.2700 to 0.2700. Saving model...\n",
      "LOG: Epoch [243/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4356\n",
      "LOG: Epoch [243/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4222\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [243/2000], Avg Train Loss: 0.4356, Avg Val Loss: 0.2699\n",
      "\n",
      "Validation loss improved from 0.2700 to 0.2699. Saving model...\n",
      "LOG: Epoch [244/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4259\n",
      "LOG: Epoch [244/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4222\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [244/2000], Avg Train Loss: 0.4259, Avg Val Loss: 0.2699\n",
      "\n",
      "Validation loss improved from 0.2699 to 0.2699. Saving model...\n",
      "LOG: Epoch [245/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4277\n",
      "LOG: Epoch [245/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4221\n",
      "    Batch [2/2], Val Loss: 0.1176\n",
      "Epoch [245/2000], Avg Train Loss: 0.4277, Avg Val Loss: 0.2698\n",
      "\n",
      "Validation loss improved from 0.2699 to 0.2698. Saving model...\n",
      "LOG: Epoch [246/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4276\n",
      "LOG: Epoch [246/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4220\n",
      "    Batch [2/2], Val Loss: 0.1175\n",
      "Epoch [246/2000], Avg Train Loss: 0.4276, Avg Val Loss: 0.2698\n",
      "\n",
      "Validation loss improved from 0.2698 to 0.2698. Saving model...\n",
      "LOG: Epoch [247/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4241\n",
      "LOG: Epoch [247/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4219\n",
      "    Batch [2/2], Val Loss: 0.1175\n",
      "Epoch [247/2000], Avg Train Loss: 0.4241, Avg Val Loss: 0.2697\n",
      "\n",
      "Validation loss improved from 0.2698 to 0.2697. Saving model...\n",
      "LOG: Epoch [248/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4242\n",
      "LOG: Epoch [248/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4218\n",
      "    Batch [2/2], Val Loss: 0.1175\n",
      "Epoch [248/2000], Avg Train Loss: 0.4242, Avg Val Loss: 0.2696\n",
      "\n",
      "Validation loss improved from 0.2697 to 0.2696. Saving model...\n",
      "LOG: Epoch [249/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4277\n",
      "LOG: Epoch [249/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4217\n",
      "    Batch [2/2], Val Loss: 0.1174\n",
      "Epoch [249/2000], Avg Train Loss: 0.4277, Avg Val Loss: 0.2696\n",
      "\n",
      "Validation loss improved from 0.2696 to 0.2696. Saving model...\n",
      "LOG: Epoch [250/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4337\n",
      "LOG: Epoch [250/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4216\n",
      "    Batch [2/2], Val Loss: 0.1174\n",
      "Epoch [250/2000], Avg Train Loss: 0.4337, Avg Val Loss: 0.2695\n",
      "\n",
      "Validation loss improved from 0.2696 to 0.2695. Saving model...\n",
      "LOG: Epoch [251/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4307\n",
      "LOG: Epoch [251/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4215\n",
      "    Batch [2/2], Val Loss: 0.1173\n",
      "Epoch [251/2000], Avg Train Loss: 0.4307, Avg Val Loss: 0.2694\n",
      "\n",
      "Validation loss improved from 0.2695 to 0.2694. Saving model...\n",
      "LOG: Epoch [252/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4249\n",
      "LOG: Epoch [252/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4214\n",
      "    Batch [2/2], Val Loss: 0.1172\n",
      "Epoch [252/2000], Avg Train Loss: 0.4249, Avg Val Loss: 0.2693\n",
      "\n",
      "Validation loss improved from 0.2694 to 0.2693. Saving model...\n",
      "LOG: Epoch [253/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4303\n",
      "LOG: Epoch [253/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4213\n",
      "    Batch [2/2], Val Loss: 0.1172\n",
      "Epoch [253/2000], Avg Train Loss: 0.4303, Avg Val Loss: 0.2692\n",
      "\n",
      "Validation loss improved from 0.2693 to 0.2692. Saving model...\n",
      "LOG: Epoch [254/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4275\n",
      "LOG: Epoch [254/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4212\n",
      "    Batch [2/2], Val Loss: 0.1171\n",
      "Epoch [254/2000], Avg Train Loss: 0.4275, Avg Val Loss: 0.2692\n",
      "\n",
      "Validation loss improved from 0.2692 to 0.2692. Saving model...\n",
      "LOG: Epoch [255/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4320\n",
      "LOG: Epoch [255/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4210\n",
      "    Batch [2/2], Val Loss: 0.1171\n",
      "Epoch [255/2000], Avg Train Loss: 0.4320, Avg Val Loss: 0.2691\n",
      "\n",
      "Validation loss improved from 0.2692 to 0.2691. Saving model...\n",
      "LOG: Epoch [256/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4263\n",
      "LOG: Epoch [256/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4209\n",
      "    Batch [2/2], Val Loss: 0.1171\n",
      "Epoch [256/2000], Avg Train Loss: 0.4263, Avg Val Loss: 0.2690\n",
      "\n",
      "Validation loss improved from 0.2691 to 0.2690. Saving model...\n",
      "LOG: Epoch [257/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4235\n",
      "LOG: Epoch [257/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4208\n",
      "    Batch [2/2], Val Loss: 0.1170\n",
      "Epoch [257/2000], Avg Train Loss: 0.4235, Avg Val Loss: 0.2689\n",
      "\n",
      "Validation loss improved from 0.2690 to 0.2689. Saving model...\n",
      "LOG: Epoch [258/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4277\n",
      "LOG: Epoch [258/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4207\n",
      "    Batch [2/2], Val Loss: 0.1170\n",
      "Epoch [258/2000], Avg Train Loss: 0.4277, Avg Val Loss: 0.2689\n",
      "\n",
      "Validation loss improved from 0.2689 to 0.2689. Saving model...\n",
      "LOG: Epoch [259/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4274\n",
      "LOG: Epoch [259/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4206\n",
      "    Batch [2/2], Val Loss: 0.1169\n",
      "Epoch [259/2000], Avg Train Loss: 0.4274, Avg Val Loss: 0.2688\n",
      "\n",
      "Validation loss improved from 0.2689 to 0.2688. Saving model...\n",
      "LOG: Epoch [260/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4297\n",
      "LOG: Epoch [260/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4205\n",
      "    Batch [2/2], Val Loss: 0.1169\n",
      "Epoch [260/2000], Avg Train Loss: 0.4297, Avg Val Loss: 0.2687\n",
      "\n",
      "Validation loss improved from 0.2688 to 0.2687. Saving model...\n",
      "LOG: Epoch [261/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4280\n",
      "LOG: Epoch [261/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4204\n",
      "    Batch [2/2], Val Loss: 0.1168\n",
      "Epoch [261/2000], Avg Train Loss: 0.4280, Avg Val Loss: 0.2686\n",
      "\n",
      "Validation loss improved from 0.2687 to 0.2686. Saving model...\n",
      "LOG: Epoch [262/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4298\n",
      "LOG: Epoch [262/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4204\n",
      "    Batch [2/2], Val Loss: 0.1167\n",
      "Epoch [262/2000], Avg Train Loss: 0.4298, Avg Val Loss: 0.2685\n",
      "\n",
      "Validation loss improved from 0.2686 to 0.2685. Saving model...\n",
      "LOG: Epoch [263/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4279\n",
      "LOG: Epoch [263/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4202\n",
      "    Batch [2/2], Val Loss: 0.1166\n",
      "Epoch [263/2000], Avg Train Loss: 0.4279, Avg Val Loss: 0.2684\n",
      "\n",
      "Validation loss improved from 0.2685 to 0.2684. Saving model...\n",
      "LOG: Epoch [264/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4309\n",
      "LOG: Epoch [264/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4202\n",
      "    Batch [2/2], Val Loss: 0.1165\n",
      "Epoch [264/2000], Avg Train Loss: 0.4309, Avg Val Loss: 0.2683\n",
      "\n",
      "Validation loss improved from 0.2684 to 0.2683. Saving model...\n",
      "LOG: Epoch [265/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4191\n",
      "LOG: Epoch [265/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4201\n",
      "    Batch [2/2], Val Loss: 0.1164\n",
      "Epoch [265/2000], Avg Train Loss: 0.4191, Avg Val Loss: 0.2683\n",
      "\n",
      "Validation loss improved from 0.2683 to 0.2683. Saving model...\n",
      "LOG: Epoch [266/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4300\n",
      "LOG: Epoch [266/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4200\n",
      "    Batch [2/2], Val Loss: 0.1164\n",
      "Epoch [266/2000], Avg Train Loss: 0.4300, Avg Val Loss: 0.2682\n",
      "\n",
      "Validation loss improved from 0.2683 to 0.2682. Saving model...\n",
      "LOG: Epoch [267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4326\n",
      "LOG: Epoch [267/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4199\n",
      "    Batch [2/2], Val Loss: 0.1164\n",
      "Epoch [267/2000], Avg Train Loss: 0.4326, Avg Val Loss: 0.2681\n",
      "\n",
      "Validation loss improved from 0.2682 to 0.2681. Saving model...\n",
      "LOG: Epoch [268/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4219\n",
      "LOG: Epoch [268/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4198\n",
      "    Batch [2/2], Val Loss: 0.1163\n",
      "Epoch [268/2000], Avg Train Loss: 0.4219, Avg Val Loss: 0.2681\n",
      "\n",
      "Validation loss improved from 0.2681 to 0.2681. Saving model...\n",
      "LOG: Epoch [269/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4262\n",
      "LOG: Epoch [269/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4197\n",
      "    Batch [2/2], Val Loss: 0.1163\n",
      "Epoch [269/2000], Avg Train Loss: 0.4262, Avg Val Loss: 0.2680\n",
      "\n",
      "Validation loss improved from 0.2681 to 0.2680. Saving model...\n",
      "LOG: Epoch [270/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4260\n",
      "LOG: Epoch [270/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4197\n",
      "    Batch [2/2], Val Loss: 0.1163\n",
      "Epoch [270/2000], Avg Train Loss: 0.4260, Avg Val Loss: 0.2680\n",
      "\n",
      "Validation loss improved from 0.2680 to 0.2680. Saving model...\n",
      "LOG: Epoch [271/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4305\n",
      "LOG: Epoch [271/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4196\n",
      "    Batch [2/2], Val Loss: 0.1163\n",
      "Epoch [271/2000], Avg Train Loss: 0.4305, Avg Val Loss: 0.2680\n",
      "\n",
      "Validation loss improved from 0.2680 to 0.2680. Saving model...\n",
      "LOG: Epoch [272/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4278\n",
      "LOG: Epoch [272/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4196\n",
      "    Batch [2/2], Val Loss: 0.1163\n",
      "Epoch [272/2000], Avg Train Loss: 0.4278, Avg Val Loss: 0.2679\n",
      "\n",
      "Validation loss improved from 0.2680 to 0.2679. Saving model...\n",
      "LOG: Epoch [273/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4268\n",
      "LOG: Epoch [273/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4196\n",
      "    Batch [2/2], Val Loss: 0.1162\n",
      "Epoch [273/2000], Avg Train Loss: 0.4268, Avg Val Loss: 0.2679\n",
      "\n",
      "Validation loss improved from 0.2679 to 0.2679. Saving model...\n",
      "LOG: Epoch [274/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4257\n",
      "LOG: Epoch [274/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4195\n",
      "    Batch [2/2], Val Loss: 0.1162\n",
      "Epoch [274/2000], Avg Train Loss: 0.4257, Avg Val Loss: 0.2679\n",
      "\n",
      "Validation loss improved from 0.2679 to 0.2679. Saving model...\n",
      "LOG: Epoch [275/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4209\n",
      "LOG: Epoch [275/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4196\n",
      "    Batch [2/2], Val Loss: 0.1162\n",
      "Epoch [275/2000], Avg Train Loss: 0.4209, Avg Val Loss: 0.2679\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [276/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4347\n",
      "LOG: Epoch [276/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4196\n",
      "    Batch [2/2], Val Loss: 0.1162\n",
      "Epoch [276/2000], Avg Train Loss: 0.4347, Avg Val Loss: 0.2679\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [277/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4231\n",
      "LOG: Epoch [277/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4195\n",
      "    Batch [2/2], Val Loss: 0.1162\n",
      "Epoch [277/2000], Avg Train Loss: 0.4231, Avg Val Loss: 0.2678\n",
      "\n",
      "Validation loss improved from 0.2679 to 0.2678. Saving model...\n",
      "LOG: Epoch [278/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4254\n",
      "LOG: Epoch [278/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4194\n",
      "    Batch [2/2], Val Loss: 0.1161\n",
      "Epoch [278/2000], Avg Train Loss: 0.4254, Avg Val Loss: 0.2678\n",
      "\n",
      "Validation loss improved from 0.2678 to 0.2678. Saving model...\n",
      "LOG: Epoch [279/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4246\n",
      "LOG: Epoch [279/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4193\n",
      "    Batch [2/2], Val Loss: 0.1162\n",
      "Epoch [279/2000], Avg Train Loss: 0.4246, Avg Val Loss: 0.2678\n",
      "\n",
      "Validation loss improved from 0.2678 to 0.2678. Saving model...\n",
      "LOG: Epoch [280/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4203\n",
      "LOG: Epoch [280/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4193\n",
      "    Batch [2/2], Val Loss: 0.1162\n",
      "Epoch [280/2000], Avg Train Loss: 0.4203, Avg Val Loss: 0.2677\n",
      "\n",
      "Validation loss improved from 0.2678 to 0.2677. Saving model...\n",
      "LOG: Epoch [281/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4236\n",
      "LOG: Epoch [281/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4193\n",
      "    Batch [2/2], Val Loss: 0.1162\n",
      "Epoch [281/2000], Avg Train Loss: 0.4236, Avg Val Loss: 0.2677\n",
      "\n",
      "Validation loss improved from 0.2677 to 0.2677. Saving model...\n",
      "LOG: Epoch [282/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4235\n",
      "LOG: Epoch [282/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4192\n",
      "    Batch [2/2], Val Loss: 0.1162\n",
      "Epoch [282/2000], Avg Train Loss: 0.4235, Avg Val Loss: 0.2677\n",
      "\n",
      "Validation loss improved from 0.2677 to 0.2677. Saving model...\n",
      "LOG: Epoch [283/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4281\n",
      "LOG: Epoch [283/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4192\n",
      "    Batch [2/2], Val Loss: 0.1161\n",
      "Epoch [283/2000], Avg Train Loss: 0.4281, Avg Val Loss: 0.2677\n",
      "\n",
      "Validation loss improved from 0.2677 to 0.2677. Saving model...\n",
      "LOG: Epoch [284/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4283\n",
      "LOG: Epoch [284/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4191\n",
      "    Batch [2/2], Val Loss: 0.1161\n",
      "Epoch [284/2000], Avg Train Loss: 0.4283, Avg Val Loss: 0.2676\n",
      "\n",
      "Validation loss improved from 0.2677 to 0.2676. Saving model...\n",
      "LOG: Epoch [285/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4268\n",
      "LOG: Epoch [285/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4192\n",
      "    Batch [2/2], Val Loss: 0.1160\n",
      "Epoch [285/2000], Avg Train Loss: 0.4268, Avg Val Loss: 0.2676\n",
      "\n",
      "Validation loss improved from 0.2676 to 0.2676. Saving model...\n",
      "LOG: Epoch [286/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4249\n",
      "LOG: Epoch [286/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4192\n",
      "    Batch [2/2], Val Loss: 0.1159\n",
      "Epoch [286/2000], Avg Train Loss: 0.4249, Avg Val Loss: 0.2675\n",
      "\n",
      "Validation loss improved from 0.2676 to 0.2675. Saving model...\n",
      "LOG: Epoch [287/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4256\n",
      "LOG: Epoch [287/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4192\n",
      "    Batch [2/2], Val Loss: 0.1157\n",
      "Epoch [287/2000], Avg Train Loss: 0.4256, Avg Val Loss: 0.2675\n",
      "\n",
      "Validation loss improved from 0.2675 to 0.2675. Saving model...\n",
      "LOG: Epoch [288/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4248\n",
      "LOG: Epoch [288/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4192\n",
      "    Batch [2/2], Val Loss: 0.1156\n",
      "Epoch [288/2000], Avg Train Loss: 0.4248, Avg Val Loss: 0.2674\n",
      "\n",
      "Validation loss improved from 0.2675 to 0.2674. Saving model...\n",
      "LOG: Epoch [289/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4301\n",
      "LOG: Epoch [289/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4192\n",
      "    Batch [2/2], Val Loss: 0.1155\n",
      "Epoch [289/2000], Avg Train Loss: 0.4301, Avg Val Loss: 0.2674\n",
      "\n",
      "Validation loss improved from 0.2674 to 0.2674. Saving model...\n",
      "LOG: Epoch [290/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4231\n",
      "LOG: Epoch [290/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4192\n",
      "    Batch [2/2], Val Loss: 0.1154\n",
      "Epoch [290/2000], Avg Train Loss: 0.4231, Avg Val Loss: 0.2673\n",
      "\n",
      "Validation loss improved from 0.2674 to 0.2673. Saving model...\n",
      "LOG: Epoch [291/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4220\n",
      "LOG: Epoch [291/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4192\n",
      "    Batch [2/2], Val Loss: 0.1153\n",
      "Epoch [291/2000], Avg Train Loss: 0.4220, Avg Val Loss: 0.2673\n",
      "\n",
      "Validation loss improved from 0.2673 to 0.2673. Saving model...\n",
      "LOG: Epoch [292/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4228\n",
      "LOG: Epoch [292/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4191\n",
      "    Batch [2/2], Val Loss: 0.1153\n",
      "Epoch [292/2000], Avg Train Loss: 0.4228, Avg Val Loss: 0.2672\n",
      "\n",
      "Validation loss improved from 0.2673 to 0.2672. Saving model...\n",
      "LOG: Epoch [293/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4283\n",
      "LOG: Epoch [293/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4190\n",
      "    Batch [2/2], Val Loss: 0.1152\n",
      "Epoch [293/2000], Avg Train Loss: 0.4283, Avg Val Loss: 0.2671\n",
      "\n",
      "Validation loss improved from 0.2672 to 0.2671. Saving model...\n",
      "LOG: Epoch [294/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4210\n",
      "LOG: Epoch [294/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4190\n",
      "    Batch [2/2], Val Loss: 0.1151\n",
      "Epoch [294/2000], Avg Train Loss: 0.4210, Avg Val Loss: 0.2671\n",
      "\n",
      "Validation loss improved from 0.2671 to 0.2671. Saving model...\n",
      "LOG: Epoch [295/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4207\n",
      "LOG: Epoch [295/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4190\n",
      "    Batch [2/2], Val Loss: 0.1151\n",
      "Epoch [295/2000], Avg Train Loss: 0.4207, Avg Val Loss: 0.2670\n",
      "\n",
      "Validation loss improved from 0.2671 to 0.2670. Saving model...\n",
      "LOG: Epoch [296/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4240\n",
      "LOG: Epoch [296/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4190\n",
      "    Batch [2/2], Val Loss: 0.1150\n",
      "Epoch [296/2000], Avg Train Loss: 0.4240, Avg Val Loss: 0.2670\n",
      "\n",
      "Validation loss improved from 0.2670 to 0.2670. Saving model...\n",
      "LOG: Epoch [297/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4256\n",
      "LOG: Epoch [297/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4190\n",
      "    Batch [2/2], Val Loss: 0.1149\n",
      "Epoch [297/2000], Avg Train Loss: 0.4256, Avg Val Loss: 0.2669\n",
      "\n",
      "Validation loss improved from 0.2670 to 0.2669. Saving model...\n",
      "LOG: Epoch [298/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4286\n",
      "LOG: Epoch [298/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4189\n",
      "    Batch [2/2], Val Loss: 0.1148\n",
      "Epoch [298/2000], Avg Train Loss: 0.4286, Avg Val Loss: 0.2669\n",
      "\n",
      "Validation loss improved from 0.2669 to 0.2669. Saving model...\n",
      "LOG: Epoch [299/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4244\n",
      "LOG: Epoch [299/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4189\n",
      "    Batch [2/2], Val Loss: 0.1147\n",
      "Epoch [299/2000], Avg Train Loss: 0.4244, Avg Val Loss: 0.2668\n",
      "\n",
      "Validation loss improved from 0.2669 to 0.2668. Saving model...\n",
      "LOG: Epoch [300/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4241\n",
      "LOG: Epoch [300/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4188\n",
      "    Batch [2/2], Val Loss: 0.1146\n",
      "Epoch [300/2000], Avg Train Loss: 0.4241, Avg Val Loss: 0.2667\n",
      "\n",
      "Validation loss improved from 0.2668 to 0.2667. Saving model...\n",
      "LOG: Epoch [301/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4276\n",
      "LOG: Epoch [301/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4188\n",
      "    Batch [2/2], Val Loss: 0.1145\n",
      "Epoch [301/2000], Avg Train Loss: 0.4276, Avg Val Loss: 0.2666\n",
      "\n",
      "Validation loss improved from 0.2667 to 0.2666. Saving model...\n",
      "LOG: Epoch [302/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4276\n",
      "LOG: Epoch [302/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4188\n",
      "    Batch [2/2], Val Loss: 0.1145\n",
      "Epoch [302/2000], Avg Train Loss: 0.4276, Avg Val Loss: 0.2666\n",
      "\n",
      "Validation loss improved from 0.2666 to 0.2666. Saving model...\n",
      "LOG: Epoch [303/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4264\n",
      "LOG: Epoch [303/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4187\n",
      "    Batch [2/2], Val Loss: 0.1144\n",
      "Epoch [303/2000], Avg Train Loss: 0.4264, Avg Val Loss: 0.2666\n",
      "\n",
      "Validation loss improved from 0.2666 to 0.2666. Saving model...\n",
      "LOG: Epoch [304/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4290\n",
      "LOG: Epoch [304/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4188\n",
      "    Batch [2/2], Val Loss: 0.1143\n",
      "Epoch [304/2000], Avg Train Loss: 0.4290, Avg Val Loss: 0.2666\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [305/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4257\n",
      "LOG: Epoch [305/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4188\n",
      "    Batch [2/2], Val Loss: 0.1143\n",
      "Epoch [305/2000], Avg Train Loss: 0.4257, Avg Val Loss: 0.2666\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [306/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4183\n",
      "LOG: Epoch [306/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4189\n",
      "    Batch [2/2], Val Loss: 0.1143\n",
      "Epoch [306/2000], Avg Train Loss: 0.4183, Avg Val Loss: 0.2666\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [307/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4285\n",
      "LOG: Epoch [307/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4189\n",
      "    Batch [2/2], Val Loss: 0.1143\n",
      "Epoch [307/2000], Avg Train Loss: 0.4285, Avg Val Loss: 0.2666\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [308/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4321\n",
      "LOG: Epoch [308/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4190\n",
      "    Batch [2/2], Val Loss: 0.1143\n",
      "Epoch [308/2000], Avg Train Loss: 0.4321, Avg Val Loss: 0.2666\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [309/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4295\n",
      "LOG: Epoch [309/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4189\n",
      "    Batch [2/2], Val Loss: 0.1142\n",
      "Epoch [309/2000], Avg Train Loss: 0.4295, Avg Val Loss: 0.2666\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [310/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4248\n",
      "LOG: Epoch [310/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4189\n",
      "    Batch [2/2], Val Loss: 0.1142\n",
      "Epoch [310/2000], Avg Train Loss: 0.4248, Avg Val Loss: 0.2666\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [311/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4252\n",
      "LOG: Epoch [311/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4190\n",
      "    Batch [2/2], Val Loss: 0.1142\n",
      "Epoch [311/2000], Avg Train Loss: 0.4252, Avg Val Loss: 0.2666\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [312/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4244\n",
      "LOG: Epoch [312/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4190\n",
      "    Batch [2/2], Val Loss: 0.1141\n",
      "Epoch [312/2000], Avg Train Loss: 0.4244, Avg Val Loss: 0.2666\n",
      "\n",
      "Validation loss improved from 0.2666 to 0.2666. Saving model...\n",
      "LOG: Epoch [313/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4242\n",
      "LOG: Epoch [313/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4190\n",
      "    Batch [2/2], Val Loss: 0.1141\n",
      "Epoch [313/2000], Avg Train Loss: 0.4242, Avg Val Loss: 0.2665\n",
      "\n",
      "Validation loss improved from 0.2666 to 0.2665. Saving model...\n",
      "LOG: Epoch [314/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4264\n",
      "LOG: Epoch [314/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4190\n",
      "    Batch [2/2], Val Loss: 0.1140\n",
      "Epoch [314/2000], Avg Train Loss: 0.4264, Avg Val Loss: 0.2665\n",
      "\n",
      "Validation loss improved from 0.2665 to 0.2665. Saving model...\n",
      "LOG: Epoch [315/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4233\n",
      "LOG: Epoch [315/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4190\n",
      "    Batch [2/2], Val Loss: 0.1140\n",
      "Epoch [315/2000], Avg Train Loss: 0.4233, Avg Val Loss: 0.2665\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [316/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4234\n",
      "LOG: Epoch [316/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4190\n",
      "    Batch [2/2], Val Loss: 0.1140\n",
      "Epoch [316/2000], Avg Train Loss: 0.4234, Avg Val Loss: 0.2665\n",
      "\n",
      "Validation loss improved from 0.2665 to 0.2665. Saving model...\n",
      "LOG: Epoch [317/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4286\n",
      "LOG: Epoch [317/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4190\n",
      "    Batch [2/2], Val Loss: 0.1140\n",
      "Epoch [317/2000], Avg Train Loss: 0.4286, Avg Val Loss: 0.2665\n",
      "\n",
      "Validation loss improved from 0.2665 to 0.2665. Saving model...\n",
      "LOG: Epoch [318/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4235\n",
      "LOG: Epoch [318/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4190\n",
      "    Batch [2/2], Val Loss: 0.1139\n",
      "Epoch [318/2000], Avg Train Loss: 0.4235, Avg Val Loss: 0.2665\n",
      "\n",
      "Validation loss improved from 0.2665 to 0.2665. Saving model...\n",
      "LOG: Epoch [319/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4215\n",
      "LOG: Epoch [319/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4189\n",
      "    Batch [2/2], Val Loss: 0.1139\n",
      "Epoch [319/2000], Avg Train Loss: 0.4215, Avg Val Loss: 0.2664\n",
      "\n",
      "Validation loss improved from 0.2665 to 0.2664. Saving model...\n",
      "LOG: Epoch [320/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4203\n",
      "LOG: Epoch [320/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4189\n",
      "    Batch [2/2], Val Loss: 0.1139\n",
      "Epoch [320/2000], Avg Train Loss: 0.4203, Avg Val Loss: 0.2664\n",
      "\n",
      "Validation loss improved from 0.2664 to 0.2664. Saving model...\n",
      "LOG: Epoch [321/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4236\n",
      "LOG: Epoch [321/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4188\n",
      "    Batch [2/2], Val Loss: 0.1138\n",
      "Epoch [321/2000], Avg Train Loss: 0.4236, Avg Val Loss: 0.2663\n",
      "\n",
      "Validation loss improved from 0.2664 to 0.2663. Saving model...\n",
      "LOG: Epoch [322/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4219\n",
      "LOG: Epoch [322/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4188\n",
      "    Batch [2/2], Val Loss: 0.1138\n",
      "Epoch [322/2000], Avg Train Loss: 0.4219, Avg Val Loss: 0.2663\n",
      "\n",
      "Validation loss improved from 0.2663 to 0.2663. Saving model...\n",
      "LOG: Epoch [323/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4264\n",
      "LOG: Epoch [323/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4187\n",
      "    Batch [2/2], Val Loss: 0.1138\n",
      "Epoch [323/2000], Avg Train Loss: 0.4264, Avg Val Loss: 0.2663\n",
      "\n",
      "Validation loss improved from 0.2663 to 0.2663. Saving model...\n",
      "LOG: Epoch [324/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4204\n",
      "LOG: Epoch [324/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4186\n",
      "    Batch [2/2], Val Loss: 0.1138\n",
      "Epoch [324/2000], Avg Train Loss: 0.4204, Avg Val Loss: 0.2662\n",
      "\n",
      "Validation loss improved from 0.2663 to 0.2662. Saving model...\n",
      "LOG: Epoch [325/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4217\n",
      "LOG: Epoch [325/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4186\n",
      "    Batch [2/2], Val Loss: 0.1138\n",
      "Epoch [325/2000], Avg Train Loss: 0.4217, Avg Val Loss: 0.2662\n",
      "\n",
      "Validation loss improved from 0.2662 to 0.2662. Saving model...\n",
      "LOG: Epoch [326/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4250\n",
      "LOG: Epoch [326/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4185\n",
      "    Batch [2/2], Val Loss: 0.1138\n",
      "Epoch [326/2000], Avg Train Loss: 0.4250, Avg Val Loss: 0.2661\n",
      "\n",
      "Validation loss improved from 0.2662 to 0.2661. Saving model...\n",
      "LOG: Epoch [327/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4219\n",
      "LOG: Epoch [327/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4184\n",
      "    Batch [2/2], Val Loss: 0.1138\n",
      "Epoch [327/2000], Avg Train Loss: 0.4219, Avg Val Loss: 0.2661\n",
      "\n",
      "Validation loss improved from 0.2661 to 0.2661. Saving model...\n",
      "LOG: Epoch [328/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4253\n",
      "LOG: Epoch [328/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4184\n",
      "    Batch [2/2], Val Loss: 0.1138\n",
      "Epoch [328/2000], Avg Train Loss: 0.4253, Avg Val Loss: 0.2661\n",
      "\n",
      "Validation loss improved from 0.2661 to 0.2661. Saving model...\n",
      "LOG: Epoch [329/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4301\n",
      "LOG: Epoch [329/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4183\n",
      "    Batch [2/2], Val Loss: 0.1139\n",
      "Epoch [329/2000], Avg Train Loss: 0.4301, Avg Val Loss: 0.2661\n",
      "\n",
      "Validation loss improved from 0.2661 to 0.2661. Saving model...\n",
      "LOG: Epoch [330/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4203\n",
      "LOG: Epoch [330/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4182\n",
      "    Batch [2/2], Val Loss: 0.1140\n",
      "Epoch [330/2000], Avg Train Loss: 0.4203, Avg Val Loss: 0.2661\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [331/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4205\n",
      "LOG: Epoch [331/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4182\n",
      "    Batch [2/2], Val Loss: 0.1141\n",
      "Epoch [331/2000], Avg Train Loss: 0.4205, Avg Val Loss: 0.2661\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [332/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4228\n",
      "LOG: Epoch [332/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4181\n",
      "    Batch [2/2], Val Loss: 0.1141\n",
      "Epoch [332/2000], Avg Train Loss: 0.4228, Avg Val Loss: 0.2661\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [333/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4258\n",
      "LOG: Epoch [333/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4181\n",
      "    Batch [2/2], Val Loss: 0.1141\n",
      "Epoch [333/2000], Avg Train Loss: 0.4258, Avg Val Loss: 0.2661\n",
      "\n",
      "Validation loss improved from 0.2661 to 0.2661. Saving model...\n",
      "LOG: Epoch [334/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4220\n",
      "LOG: Epoch [334/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4180\n",
      "    Batch [2/2], Val Loss: 0.1141\n",
      "Epoch [334/2000], Avg Train Loss: 0.4220, Avg Val Loss: 0.2660\n",
      "\n",
      "Validation loss improved from 0.2661 to 0.2660. Saving model...\n",
      "LOG: Epoch [335/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4226\n",
      "LOG: Epoch [335/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4180\n",
      "    Batch [2/2], Val Loss: 0.1141\n",
      "Epoch [335/2000], Avg Train Loss: 0.4226, Avg Val Loss: 0.2660\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [336/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4216\n",
      "LOG: Epoch [336/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4181\n",
      "    Batch [2/2], Val Loss: 0.1141\n",
      "Epoch [336/2000], Avg Train Loss: 0.4216, Avg Val Loss: 0.2661\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [337/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4239\n",
      "LOG: Epoch [337/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4181\n",
      "    Batch [2/2], Val Loss: 0.1141\n",
      "Epoch [337/2000], Avg Train Loss: 0.4239, Avg Val Loss: 0.2661\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [338/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4214\n",
      "LOG: Epoch [338/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4181\n",
      "    Batch [2/2], Val Loss: 0.1140\n",
      "Epoch [338/2000], Avg Train Loss: 0.4214, Avg Val Loss: 0.2661\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [339/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4217\n",
      "LOG: Epoch [339/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4181\n",
      "    Batch [2/2], Val Loss: 0.1140\n",
      "Epoch [339/2000], Avg Train Loss: 0.4217, Avg Val Loss: 0.2661\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [340/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4250\n",
      "LOG: Epoch [340/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4181\n",
      "    Batch [2/2], Val Loss: 0.1141\n",
      "Epoch [340/2000], Avg Train Loss: 0.4250, Avg Val Loss: 0.2661\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [341/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4272\n",
      "LOG: Epoch [341/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4181\n",
      "    Batch [2/2], Val Loss: 0.1141\n",
      "Epoch [341/2000], Avg Train Loss: 0.4272, Avg Val Loss: 0.2661\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [342/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4227\n",
      "LOG: Epoch [342/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4181\n",
      "    Batch [2/2], Val Loss: 0.1142\n",
      "Epoch [342/2000], Avg Train Loss: 0.4227, Avg Val Loss: 0.2662\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [343/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4252\n",
      "LOG: Epoch [343/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4181\n",
      "    Batch [2/2], Val Loss: 0.1143\n",
      "Epoch [343/2000], Avg Train Loss: 0.4252, Avg Val Loss: 0.2662\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [344/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4242\n",
      "LOG: Epoch [344/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4181\n",
      "    Batch [2/2], Val Loss: 0.1143\n",
      "Epoch [344/2000], Avg Train Loss: 0.4242, Avg Val Loss: 0.2662\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [345/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4237\n",
      "LOG: Epoch [345/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4180\n",
      "    Batch [2/2], Val Loss: 0.1143\n",
      "Epoch [345/2000], Avg Train Loss: 0.4237, Avg Val Loss: 0.2662\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [346/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4198\n",
      "LOG: Epoch [346/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4180\n",
      "    Batch [2/2], Val Loss: 0.1143\n",
      "Epoch [346/2000], Avg Train Loss: 0.4198, Avg Val Loss: 0.2662\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [347/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4229\n",
      "LOG: Epoch [347/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4179\n",
      "    Batch [2/2], Val Loss: 0.1144\n",
      "Epoch [347/2000], Avg Train Loss: 0.4229, Avg Val Loss: 0.2662\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [348/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4250\n",
      "LOG: Epoch [348/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4179\n",
      "    Batch [2/2], Val Loss: 0.1144\n",
      "Epoch [348/2000], Avg Train Loss: 0.4250, Avg Val Loss: 0.2662\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [349/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4237\n",
      "LOG: Epoch [349/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4178\n",
      "    Batch [2/2], Val Loss: 0.1144\n",
      "Epoch [349/2000], Avg Train Loss: 0.4237, Avg Val Loss: 0.2661\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [350/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4189\n",
      "LOG: Epoch [350/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4178\n",
      "    Batch [2/2], Val Loss: 0.1144\n",
      "Epoch [350/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2661\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [351/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4201\n",
      "LOG: Epoch [351/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4177\n",
      "    Batch [2/2], Val Loss: 0.1144\n",
      "Epoch [351/2000], Avg Train Loss: 0.4201, Avg Val Loss: 0.2661\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [352/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4226\n",
      "LOG: Epoch [352/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4176\n",
      "    Batch [2/2], Val Loss: 0.1144\n",
      "Epoch [352/2000], Avg Train Loss: 0.4226, Avg Val Loss: 0.2660\n",
      "\n",
      "Validation loss improved from 0.2660 to 0.2660. Saving model...\n",
      "LOG: Epoch [353/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4193\n",
      "LOG: Epoch [353/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4176\n",
      "    Batch [2/2], Val Loss: 0.1143\n",
      "Epoch [353/2000], Avg Train Loss: 0.4193, Avg Val Loss: 0.2659\n",
      "\n",
      "Validation loss improved from 0.2660 to 0.2659. Saving model...\n",
      "LOG: Epoch [354/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4226\n",
      "LOG: Epoch [354/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4175\n",
      "    Batch [2/2], Val Loss: 0.1142\n",
      "Epoch [354/2000], Avg Train Loss: 0.4226, Avg Val Loss: 0.2658\n",
      "\n",
      "Validation loss improved from 0.2659 to 0.2658. Saving model...\n",
      "LOG: Epoch [355/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4239\n",
      "LOG: Epoch [355/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4173\n",
      "    Batch [2/2], Val Loss: 0.1141\n",
      "Epoch [355/2000], Avg Train Loss: 0.4239, Avg Val Loss: 0.2657\n",
      "\n",
      "Validation loss improved from 0.2658 to 0.2657. Saving model...\n",
      "LOG: Epoch [356/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4295\n",
      "LOG: Epoch [356/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4173\n",
      "    Batch [2/2], Val Loss: 0.1141\n",
      "Epoch [356/2000], Avg Train Loss: 0.4295, Avg Val Loss: 0.2657\n",
      "\n",
      "Validation loss improved from 0.2657 to 0.2657. Saving model...\n",
      "LOG: Epoch [357/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4195\n",
      "LOG: Epoch [357/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4172\n",
      "    Batch [2/2], Val Loss: 0.1139\n",
      "Epoch [357/2000], Avg Train Loss: 0.4195, Avg Val Loss: 0.2656\n",
      "\n",
      "Validation loss improved from 0.2657 to 0.2656. Saving model...\n",
      "LOG: Epoch [358/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4209\n",
      "LOG: Epoch [358/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4172\n",
      "    Batch [2/2], Val Loss: 0.1138\n",
      "Epoch [358/2000], Avg Train Loss: 0.4209, Avg Val Loss: 0.2655\n",
      "\n",
      "Validation loss improved from 0.2656 to 0.2655. Saving model...\n",
      "LOG: Epoch [359/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4187\n",
      "LOG: Epoch [359/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4171\n",
      "    Batch [2/2], Val Loss: 0.1137\n",
      "Epoch [359/2000], Avg Train Loss: 0.4187, Avg Val Loss: 0.2654\n",
      "\n",
      "Validation loss improved from 0.2655 to 0.2654. Saving model...\n",
      "LOG: Epoch [360/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4234\n",
      "LOG: Epoch [360/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4171\n",
      "    Batch [2/2], Val Loss: 0.1137\n",
      "Epoch [360/2000], Avg Train Loss: 0.4234, Avg Val Loss: 0.2654\n",
      "\n",
      "Validation loss improved from 0.2654 to 0.2654. Saving model...\n",
      "LOG: Epoch [361/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4221\n",
      "LOG: Epoch [361/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4171\n",
      "    Batch [2/2], Val Loss: 0.1136\n",
      "Epoch [361/2000], Avg Train Loss: 0.4221, Avg Val Loss: 0.2654\n",
      "\n",
      "Validation loss improved from 0.2654 to 0.2654. Saving model...\n",
      "LOG: Epoch [362/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4199\n",
      "LOG: Epoch [362/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4170\n",
      "    Batch [2/2], Val Loss: 0.1136\n",
      "Epoch [362/2000], Avg Train Loss: 0.4199, Avg Val Loss: 0.2653\n",
      "\n",
      "Validation loss improved from 0.2654 to 0.2653. Saving model...\n",
      "LOG: Epoch [363/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4242\n",
      "LOG: Epoch [363/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4170\n",
      "    Batch [2/2], Val Loss: 0.1135\n",
      "Epoch [363/2000], Avg Train Loss: 0.4242, Avg Val Loss: 0.2653\n",
      "\n",
      "Validation loss improved from 0.2653 to 0.2653. Saving model...\n",
      "LOG: Epoch [364/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4200\n",
      "LOG: Epoch [364/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4170\n",
      "    Batch [2/2], Val Loss: 0.1135\n",
      "Epoch [364/2000], Avg Train Loss: 0.4200, Avg Val Loss: 0.2653\n",
      "\n",
      "Validation loss improved from 0.2653 to 0.2653. Saving model...\n",
      "LOG: Epoch [365/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4231\n",
      "LOG: Epoch [365/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4170\n",
      "    Batch [2/2], Val Loss: 0.1135\n",
      "Epoch [365/2000], Avg Train Loss: 0.4231, Avg Val Loss: 0.2652\n",
      "\n",
      "Validation loss improved from 0.2653 to 0.2652. Saving model...\n",
      "LOG: Epoch [366/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4165\n",
      "LOG: Epoch [366/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4170\n",
      "    Batch [2/2], Val Loss: 0.1134\n",
      "Epoch [366/2000], Avg Train Loss: 0.4165, Avg Val Loss: 0.2652\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [367/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4308\n",
      "LOG: Epoch [367/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4171\n",
      "    Batch [2/2], Val Loss: 0.1135\n",
      "Epoch [367/2000], Avg Train Loss: 0.4308, Avg Val Loss: 0.2653\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [368/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4237\n",
      "LOG: Epoch [368/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4171\n",
      "    Batch [2/2], Val Loss: 0.1134\n",
      "Epoch [368/2000], Avg Train Loss: 0.4237, Avg Val Loss: 0.2653\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [369/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4198\n",
      "LOG: Epoch [369/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4172\n",
      "    Batch [2/2], Val Loss: 0.1134\n",
      "Epoch [369/2000], Avg Train Loss: 0.4198, Avg Val Loss: 0.2653\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [370/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4173\n",
      "LOG: Epoch [370/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4172\n",
      "    Batch [2/2], Val Loss: 0.1135\n",
      "Epoch [370/2000], Avg Train Loss: 0.4173, Avg Val Loss: 0.2653\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [371/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4212\n",
      "LOG: Epoch [371/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4173\n",
      "    Batch [2/2], Val Loss: 0.1135\n",
      "Epoch [371/2000], Avg Train Loss: 0.4212, Avg Val Loss: 0.2654\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [372/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4151\n",
      "LOG: Epoch [372/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4173\n",
      "    Batch [2/2], Val Loss: 0.1136\n",
      "Epoch [372/2000], Avg Train Loss: 0.4151, Avg Val Loss: 0.2654\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [373/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4242\n",
      "LOG: Epoch [373/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4173\n",
      "    Batch [2/2], Val Loss: 0.1136\n",
      "Epoch [373/2000], Avg Train Loss: 0.4242, Avg Val Loss: 0.2654\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [374/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4220\n",
      "LOG: Epoch [374/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4173\n",
      "    Batch [2/2], Val Loss: 0.1136\n",
      "Epoch [374/2000], Avg Train Loss: 0.4220, Avg Val Loss: 0.2655\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [375/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4168\n",
      "LOG: Epoch [375/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4173\n",
      "    Batch [2/2], Val Loss: 0.1136\n",
      "Epoch [375/2000], Avg Train Loss: 0.4168, Avg Val Loss: 0.2655\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [376/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4295\n",
      "LOG: Epoch [376/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4173\n",
      "    Batch [2/2], Val Loss: 0.1137\n",
      "Epoch [376/2000], Avg Train Loss: 0.4295, Avg Val Loss: 0.2655\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [377/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4227\n",
      "LOG: Epoch [377/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4173\n",
      "    Batch [2/2], Val Loss: 0.1137\n",
      "Epoch [377/2000], Avg Train Loss: 0.4227, Avg Val Loss: 0.2655\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [378/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4330\n",
      "LOG: Epoch [378/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4173\n",
      "    Batch [2/2], Val Loss: 0.1138\n",
      "Epoch [378/2000], Avg Train Loss: 0.4330, Avg Val Loss: 0.2655\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [379/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4235\n",
      "LOG: Epoch [379/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4173\n",
      "    Batch [2/2], Val Loss: 0.1137\n",
      "Epoch [379/2000], Avg Train Loss: 0.4235, Avg Val Loss: 0.2655\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [380/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4185\n",
      "LOG: Epoch [380/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4172\n",
      "    Batch [2/2], Val Loss: 0.1137\n",
      "Epoch [380/2000], Avg Train Loss: 0.4185, Avg Val Loss: 0.2655\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [381/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4209\n",
      "LOG: Epoch [381/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4172\n",
      "    Batch [2/2], Val Loss: 0.1137\n",
      "Epoch [381/2000], Avg Train Loss: 0.4209, Avg Val Loss: 0.2654\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [382/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4171\n",
      "LOG: Epoch [382/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4172\n",
      "    Batch [2/2], Val Loss: 0.1137\n",
      "Epoch [382/2000], Avg Train Loss: 0.4171, Avg Val Loss: 0.2654\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [383/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4226\n",
      "LOG: Epoch [383/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4172\n",
      "    Batch [2/2], Val Loss: 0.1137\n",
      "Epoch [383/2000], Avg Train Loss: 0.4226, Avg Val Loss: 0.2654\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [384/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4136\n",
      "LOG: Epoch [384/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4172\n",
      "    Batch [2/2], Val Loss: 0.1137\n",
      "Epoch [384/2000], Avg Train Loss: 0.4136, Avg Val Loss: 0.2654\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [385/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4180\n",
      "LOG: Epoch [385/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4171\n",
      "    Batch [2/2], Val Loss: 0.1136\n",
      "Epoch [385/2000], Avg Train Loss: 0.4180, Avg Val Loss: 0.2654\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [386/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4152\n",
      "LOG: Epoch [386/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4171\n",
      "    Batch [2/2], Val Loss: 0.1135\n",
      "Epoch [386/2000], Avg Train Loss: 0.4152, Avg Val Loss: 0.2653\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [387/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4178\n",
      "LOG: Epoch [387/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4170\n",
      "    Batch [2/2], Val Loss: 0.1134\n",
      "Epoch [387/2000], Avg Train Loss: 0.4178, Avg Val Loss: 0.2652\n",
      "\n",
      "Validation loss improved from 0.2652 to 0.2652. Saving model...\n",
      "LOG: Epoch [388/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4183\n",
      "LOG: Epoch [388/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4170\n",
      "    Batch [2/2], Val Loss: 0.1133\n",
      "Epoch [388/2000], Avg Train Loss: 0.4183, Avg Val Loss: 0.2651\n",
      "\n",
      "Validation loss improved from 0.2652 to 0.2651. Saving model...\n",
      "LOG: Epoch [389/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4176\n",
      "LOG: Epoch [389/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4169\n",
      "    Batch [2/2], Val Loss: 0.1131\n",
      "Epoch [389/2000], Avg Train Loss: 0.4176, Avg Val Loss: 0.2650\n",
      "\n",
      "Validation loss improved from 0.2651 to 0.2650. Saving model...\n",
      "LOG: Epoch [390/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4238\n",
      "LOG: Epoch [390/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4168\n",
      "    Batch [2/2], Val Loss: 0.1130\n",
      "Epoch [390/2000], Avg Train Loss: 0.4238, Avg Val Loss: 0.2649\n",
      "\n",
      "Validation loss improved from 0.2650 to 0.2649. Saving model...\n",
      "LOG: Epoch [391/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4259\n",
      "LOG: Epoch [391/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4167\n",
      "    Batch [2/2], Val Loss: 0.1129\n",
      "Epoch [391/2000], Avg Train Loss: 0.4259, Avg Val Loss: 0.2648\n",
      "\n",
      "Validation loss improved from 0.2649 to 0.2648. Saving model...\n",
      "LOG: Epoch [392/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4222\n",
      "LOG: Epoch [392/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4166\n",
      "    Batch [2/2], Val Loss: 0.1128\n",
      "Epoch [392/2000], Avg Train Loss: 0.4222, Avg Val Loss: 0.2647\n",
      "\n",
      "Validation loss improved from 0.2648 to 0.2647. Saving model...\n",
      "LOG: Epoch [393/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4200\n",
      "LOG: Epoch [393/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4165\n",
      "    Batch [2/2], Val Loss: 0.1127\n",
      "Epoch [393/2000], Avg Train Loss: 0.4200, Avg Val Loss: 0.2646\n",
      "\n",
      "Validation loss improved from 0.2647 to 0.2646. Saving model...\n",
      "LOG: Epoch [394/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4253\n",
      "LOG: Epoch [394/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4164\n",
      "    Batch [2/2], Val Loss: 0.1126\n",
      "Epoch [394/2000], Avg Train Loss: 0.4253, Avg Val Loss: 0.2645\n",
      "\n",
      "Validation loss improved from 0.2646 to 0.2645. Saving model...\n",
      "LOG: Epoch [395/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4239\n",
      "LOG: Epoch [395/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4163\n",
      "    Batch [2/2], Val Loss: 0.1125\n",
      "Epoch [395/2000], Avg Train Loss: 0.4239, Avg Val Loss: 0.2644\n",
      "\n",
      "Validation loss improved from 0.2645 to 0.2644. Saving model...\n",
      "LOG: Epoch [396/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4209\n",
      "LOG: Epoch [396/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4162\n",
      "    Batch [2/2], Val Loss: 0.1124\n",
      "Epoch [396/2000], Avg Train Loss: 0.4209, Avg Val Loss: 0.2643\n",
      "\n",
      "Validation loss improved from 0.2644 to 0.2643. Saving model...\n",
      "LOG: Epoch [397/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4169\n",
      "LOG: Epoch [397/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4161\n",
      "    Batch [2/2], Val Loss: 0.1123\n",
      "Epoch [397/2000], Avg Train Loss: 0.4169, Avg Val Loss: 0.2642\n",
      "\n",
      "Validation loss improved from 0.2643 to 0.2642. Saving model...\n",
      "LOG: Epoch [398/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4219\n",
      "LOG: Epoch [398/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4161\n",
      "    Batch [2/2], Val Loss: 0.1122\n",
      "Epoch [398/2000], Avg Train Loss: 0.4219, Avg Val Loss: 0.2642\n",
      "\n",
      "Validation loss improved from 0.2642 to 0.2642. Saving model...\n",
      "LOG: Epoch [399/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4175\n",
      "LOG: Epoch [399/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4161\n",
      "    Batch [2/2], Val Loss: 0.1122\n",
      "Epoch [399/2000], Avg Train Loss: 0.4175, Avg Val Loss: 0.2641\n",
      "\n",
      "Validation loss improved from 0.2642 to 0.2641. Saving model...\n",
      "LOG: Epoch [400/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4184\n",
      "LOG: Epoch [400/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4160\n",
      "    Batch [2/2], Val Loss: 0.1121\n",
      "Epoch [400/2000], Avg Train Loss: 0.4184, Avg Val Loss: 0.2641\n",
      "\n",
      "Validation loss improved from 0.2641 to 0.2641. Saving model...\n",
      "LOG: Epoch [401/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4166\n",
      "LOG: Epoch [401/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4160\n",
      "    Batch [2/2], Val Loss: 0.1120\n",
      "Epoch [401/2000], Avg Train Loss: 0.4166, Avg Val Loss: 0.2640\n",
      "\n",
      "Validation loss improved from 0.2641 to 0.2640. Saving model...\n",
      "LOG: Epoch [402/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4217\n",
      "LOG: Epoch [402/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4159\n",
      "    Batch [2/2], Val Loss: 0.1119\n",
      "Epoch [402/2000], Avg Train Loss: 0.4217, Avg Val Loss: 0.2639\n",
      "\n",
      "Validation loss improved from 0.2640 to 0.2639. Saving model...\n",
      "LOG: Epoch [403/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4292\n",
      "LOG: Epoch [403/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4159\n",
      "    Batch [2/2], Val Loss: 0.1119\n",
      "Epoch [403/2000], Avg Train Loss: 0.4292, Avg Val Loss: 0.2639\n",
      "\n",
      "Validation loss improved from 0.2639 to 0.2639. Saving model...\n",
      "LOG: Epoch [404/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4217\n",
      "LOG: Epoch [404/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4158\n",
      "    Batch [2/2], Val Loss: 0.1118\n",
      "Epoch [404/2000], Avg Train Loss: 0.4217, Avg Val Loss: 0.2638\n",
      "\n",
      "Validation loss improved from 0.2639 to 0.2638. Saving model...\n",
      "LOG: Epoch [405/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4204\n",
      "LOG: Epoch [405/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4157\n",
      "    Batch [2/2], Val Loss: 0.1117\n",
      "Epoch [405/2000], Avg Train Loss: 0.4204, Avg Val Loss: 0.2637\n",
      "\n",
      "Validation loss improved from 0.2638 to 0.2637. Saving model...\n",
      "LOG: Epoch [406/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4198\n",
      "LOG: Epoch [406/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4157\n",
      "    Batch [2/2], Val Loss: 0.1116\n",
      "Epoch [406/2000], Avg Train Loss: 0.4198, Avg Val Loss: 0.2636\n",
      "\n",
      "Validation loss improved from 0.2637 to 0.2636. Saving model...\n",
      "LOG: Epoch [407/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4206\n",
      "LOG: Epoch [407/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4156\n",
      "    Batch [2/2], Val Loss: 0.1115\n",
      "Epoch [407/2000], Avg Train Loss: 0.4206, Avg Val Loss: 0.2636\n",
      "\n",
      "Validation loss improved from 0.2636 to 0.2636. Saving model...\n",
      "LOG: Epoch [408/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4228\n",
      "LOG: Epoch [408/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4155\n",
      "    Batch [2/2], Val Loss: 0.1115\n",
      "Epoch [408/2000], Avg Train Loss: 0.4228, Avg Val Loss: 0.2635\n",
      "\n",
      "Validation loss improved from 0.2636 to 0.2635. Saving model...\n",
      "LOG: Epoch [409/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4197\n",
      "LOG: Epoch [409/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4155\n",
      "    Batch [2/2], Val Loss: 0.1114\n",
      "Epoch [409/2000], Avg Train Loss: 0.4197, Avg Val Loss: 0.2634\n",
      "\n",
      "Validation loss improved from 0.2635 to 0.2634. Saving model...\n",
      "LOG: Epoch [410/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4171\n",
      "LOG: Epoch [410/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4155\n",
      "    Batch [2/2], Val Loss: 0.1114\n",
      "Epoch [410/2000], Avg Train Loss: 0.4171, Avg Val Loss: 0.2634\n",
      "\n",
      "Validation loss improved from 0.2634 to 0.2634. Saving model...\n",
      "LOG: Epoch [411/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4249\n",
      "LOG: Epoch [411/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4155\n",
      "    Batch [2/2], Val Loss: 0.1114\n",
      "Epoch [411/2000], Avg Train Loss: 0.4249, Avg Val Loss: 0.2634\n",
      "\n",
      "Validation loss improved from 0.2634 to 0.2634. Saving model...\n",
      "LOG: Epoch [412/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4144\n",
      "LOG: Epoch [412/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4155\n",
      "    Batch [2/2], Val Loss: 0.1113\n",
      "Epoch [412/2000], Avg Train Loss: 0.4144, Avg Val Loss: 0.2634\n",
      "\n",
      "Validation loss improved from 0.2634 to 0.2634. Saving model...\n",
      "LOG: Epoch [413/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4156\n",
      "LOG: Epoch [413/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4155\n",
      "    Batch [2/2], Val Loss: 0.1113\n",
      "Epoch [413/2000], Avg Train Loss: 0.4156, Avg Val Loss: 0.2634\n",
      "\n",
      "Validation loss improved from 0.2634 to 0.2634. Saving model...\n",
      "LOG: Epoch [414/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4168\n",
      "LOG: Epoch [414/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4155\n",
      "    Batch [2/2], Val Loss: 0.1112\n",
      "Epoch [414/2000], Avg Train Loss: 0.4168, Avg Val Loss: 0.2634\n",
      "\n",
      "Validation loss improved from 0.2634 to 0.2634. Saving model...\n",
      "LOG: Epoch [415/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4209\n",
      "LOG: Epoch [415/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4155\n",
      "    Batch [2/2], Val Loss: 0.1112\n",
      "Epoch [415/2000], Avg Train Loss: 0.4209, Avg Val Loss: 0.2634\n",
      "\n",
      "Validation loss improved from 0.2634 to 0.2634. Saving model...\n",
      "LOG: Epoch [416/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4281\n",
      "LOG: Epoch [416/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4155\n",
      "    Batch [2/2], Val Loss: 0.1111\n",
      "Epoch [416/2000], Avg Train Loss: 0.4281, Avg Val Loss: 0.2633\n",
      "\n",
      "Validation loss improved from 0.2634 to 0.2633. Saving model...\n",
      "LOG: Epoch [417/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4189\n",
      "LOG: Epoch [417/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4155\n",
      "    Batch [2/2], Val Loss: 0.1111\n",
      "Epoch [417/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2633\n",
      "\n",
      "Validation loss improved from 0.2633 to 0.2633. Saving model...\n",
      "LOG: Epoch [418/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4150\n",
      "LOG: Epoch [418/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4154\n",
      "    Batch [2/2], Val Loss: 0.1110\n",
      "Epoch [418/2000], Avg Train Loss: 0.4150, Avg Val Loss: 0.2632\n",
      "\n",
      "Validation loss improved from 0.2633 to 0.2632. Saving model...\n",
      "LOG: Epoch [419/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4193\n",
      "LOG: Epoch [419/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4154\n",
      "    Batch [2/2], Val Loss: 0.1110\n",
      "Epoch [419/2000], Avg Train Loss: 0.4193, Avg Val Loss: 0.2632\n",
      "\n",
      "Validation loss improved from 0.2632 to 0.2632. Saving model...\n",
      "LOG: Epoch [420/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4208\n",
      "LOG: Epoch [420/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4153\n",
      "    Batch [2/2], Val Loss: 0.1110\n",
      "Epoch [420/2000], Avg Train Loss: 0.4208, Avg Val Loss: 0.2632\n",
      "\n",
      "Validation loss improved from 0.2632 to 0.2632. Saving model...\n",
      "LOG: Epoch [421/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4181\n",
      "LOG: Epoch [421/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4153\n",
      "    Batch [2/2], Val Loss: 0.1111\n",
      "Epoch [421/2000], Avg Train Loss: 0.4181, Avg Val Loss: 0.2632\n",
      "\n",
      "Validation loss improved from 0.2632 to 0.2632. Saving model...\n",
      "LOG: Epoch [422/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4189\n",
      "LOG: Epoch [422/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4153\n",
      "    Batch [2/2], Val Loss: 0.1111\n",
      "Epoch [422/2000], Avg Train Loss: 0.4189, Avg Val Loss: 0.2632\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [423/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4202\n",
      "LOG: Epoch [423/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4152\n",
      "    Batch [2/2], Val Loss: 0.1111\n",
      "Epoch [423/2000], Avg Train Loss: 0.4202, Avg Val Loss: 0.2632\n",
      "\n",
      "Validation loss improved from 0.2632 to 0.2632. Saving model...\n",
      "LOG: Epoch [424/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4151\n",
      "LOG: Epoch [424/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4152\n",
      "    Batch [2/2], Val Loss: 0.1111\n",
      "Epoch [424/2000], Avg Train Loss: 0.4151, Avg Val Loss: 0.2632\n",
      "\n",
      "Validation loss improved from 0.2632 to 0.2632. Saving model...\n",
      "LOG: Epoch [425/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4218\n",
      "LOG: Epoch [425/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4152\n",
      "    Batch [2/2], Val Loss: 0.1111\n",
      "Epoch [425/2000], Avg Train Loss: 0.4218, Avg Val Loss: 0.2632\n",
      "\n",
      "Validation loss improved from 0.2632 to 0.2632. Saving model...\n",
      "LOG: Epoch [426/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4183\n",
      "LOG: Epoch [426/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4152\n",
      "    Batch [2/2], Val Loss: 0.1111\n",
      "Epoch [426/2000], Avg Train Loss: 0.4183, Avg Val Loss: 0.2632\n",
      "\n",
      "Validation loss improved from 0.2632 to 0.2632. Saving model...\n",
      "LOG: Epoch [427/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4165\n",
      "LOG: Epoch [427/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4152\n",
      "    Batch [2/2], Val Loss: 0.1111\n",
      "Epoch [427/2000], Avg Train Loss: 0.4165, Avg Val Loss: 0.2632\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [428/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4208\n",
      "LOG: Epoch [428/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4151\n",
      "    Batch [2/2], Val Loss: 0.1111\n",
      "Epoch [428/2000], Avg Train Loss: 0.4208, Avg Val Loss: 0.2631\n",
      "\n",
      "Validation loss improved from 0.2632 to 0.2631. Saving model...\n",
      "LOG: Epoch [429/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4188\n",
      "LOG: Epoch [429/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4151\n",
      "    Batch [2/2], Val Loss: 0.1112\n",
      "Epoch [429/2000], Avg Train Loss: 0.4188, Avg Val Loss: 0.2631\n",
      "\n",
      "Validation loss improved from 0.2631 to 0.2631. Saving model...\n",
      "LOG: Epoch [430/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4181\n",
      "LOG: Epoch [430/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4150\n",
      "    Batch [2/2], Val Loss: 0.1111\n",
      "Epoch [430/2000], Avg Train Loss: 0.4181, Avg Val Loss: 0.2631\n",
      "\n",
      "Validation loss improved from 0.2631 to 0.2631. Saving model...\n",
      "LOG: Epoch [431/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4203\n",
      "LOG: Epoch [431/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4149\n",
      "    Batch [2/2], Val Loss: 0.1112\n",
      "Epoch [431/2000], Avg Train Loss: 0.4203, Avg Val Loss: 0.2630\n",
      "\n",
      "Validation loss improved from 0.2631 to 0.2630. Saving model...\n",
      "LOG: Epoch [432/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4207\n",
      "LOG: Epoch [432/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4149\n",
      "    Batch [2/2], Val Loss: 0.1112\n",
      "Epoch [432/2000], Avg Train Loss: 0.4207, Avg Val Loss: 0.2630\n",
      "\n",
      "Validation loss improved from 0.2630 to 0.2630. Saving model...\n",
      "LOG: Epoch [433/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4164\n",
      "LOG: Epoch [433/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4148\n",
      "    Batch [2/2], Val Loss: 0.1112\n",
      "Epoch [433/2000], Avg Train Loss: 0.4164, Avg Val Loss: 0.2630\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [434/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4112\n",
      "LOG: Epoch [434/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4148\n",
      "    Batch [2/2], Val Loss: 0.1112\n",
      "Epoch [434/2000], Avg Train Loss: 0.4112, Avg Val Loss: 0.2630\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [435/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4186\n",
      "LOG: Epoch [435/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4148\n",
      "    Batch [2/2], Val Loss: 0.1113\n",
      "Epoch [435/2000], Avg Train Loss: 0.4186, Avg Val Loss: 0.2631\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4184\n",
      "LOG: Epoch [436/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4148\n",
      "    Batch [2/2], Val Loss: 0.1113\n",
      "Epoch [436/2000], Avg Train Loss: 0.4184, Avg Val Loss: 0.2631\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [437/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4153\n",
      "LOG: Epoch [437/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4148\n",
      "    Batch [2/2], Val Loss: 0.1114\n",
      "Epoch [437/2000], Avg Train Loss: 0.4153, Avg Val Loss: 0.2631\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [438/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4202\n",
      "LOG: Epoch [438/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4149\n",
      "    Batch [2/2], Val Loss: 0.1114\n",
      "Epoch [438/2000], Avg Train Loss: 0.4202, Avg Val Loss: 0.2631\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [439/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4132\n",
      "LOG: Epoch [439/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4149\n",
      "    Batch [2/2], Val Loss: 0.1115\n",
      "Epoch [439/2000], Avg Train Loss: 0.4132, Avg Val Loss: 0.2632\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [440/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4172\n",
      "LOG: Epoch [440/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4149\n",
      "    Batch [2/2], Val Loss: 0.1114\n",
      "Epoch [440/2000], Avg Train Loss: 0.4172, Avg Val Loss: 0.2631\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [441/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4168\n",
      "LOG: Epoch [441/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4149\n",
      "    Batch [2/2], Val Loss: 0.1115\n",
      "Epoch [441/2000], Avg Train Loss: 0.4168, Avg Val Loss: 0.2632\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [442/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4203\n",
      "LOG: Epoch [442/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4149\n",
      "    Batch [2/2], Val Loss: 0.1115\n",
      "Epoch [442/2000], Avg Train Loss: 0.4203, Avg Val Loss: 0.2632\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [443/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4128\n",
      "LOG: Epoch [443/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4149\n",
      "    Batch [2/2], Val Loss: 0.1115\n",
      "Epoch [443/2000], Avg Train Loss: 0.4128, Avg Val Loss: 0.2632\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [444/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4127\n",
      "LOG: Epoch [444/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4149\n",
      "    Batch [2/2], Val Loss: 0.1114\n",
      "Epoch [444/2000], Avg Train Loss: 0.4127, Avg Val Loss: 0.2632\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [445/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4194\n",
      "LOG: Epoch [445/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4149\n",
      "    Batch [2/2], Val Loss: 0.1114\n",
      "Epoch [445/2000], Avg Train Loss: 0.4194, Avg Val Loss: 0.2632\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [446/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4180\n",
      "LOG: Epoch [446/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4149\n",
      "    Batch [2/2], Val Loss: 0.1114\n",
      "Epoch [446/2000], Avg Train Loss: 0.4180, Avg Val Loss: 0.2631\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [447/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4200\n",
      "LOG: Epoch [447/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4148\n",
      "    Batch [2/2], Val Loss: 0.1114\n",
      "Epoch [447/2000], Avg Train Loss: 0.4200, Avg Val Loss: 0.2631\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [448/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4250\n",
      "LOG: Epoch [448/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4148\n",
      "    Batch [2/2], Val Loss: 0.1114\n",
      "Epoch [448/2000], Avg Train Loss: 0.4250, Avg Val Loss: 0.2631\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [449/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4202\n",
      "LOG: Epoch [449/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4148\n",
      "    Batch [2/2], Val Loss: 0.1114\n",
      "Epoch [449/2000], Avg Train Loss: 0.4202, Avg Val Loss: 0.2631\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [450/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4200\n",
      "LOG: Epoch [450/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4147\n",
      "    Batch [2/2], Val Loss: 0.1114\n",
      "Epoch [450/2000], Avg Train Loss: 0.4200, Avg Val Loss: 0.2630\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4119\n",
      "LOG: Epoch [451/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4146\n",
      "    Batch [2/2], Val Loss: 0.1114\n",
      "Epoch [451/2000], Avg Train Loss: 0.4119, Avg Val Loss: 0.2630\n",
      "\n",
      "Validation loss improved from 0.2630 to 0.2630. Saving model...\n",
      "LOG: Epoch [452/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4169\n",
      "LOG: Epoch [452/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4146\n",
      "    Batch [2/2], Val Loss: 0.1113\n",
      "Epoch [452/2000], Avg Train Loss: 0.4169, Avg Val Loss: 0.2629\n",
      "\n",
      "Validation loss improved from 0.2630 to 0.2629. Saving model...\n",
      "LOG: Epoch [453/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4119\n",
      "LOG: Epoch [453/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4145\n",
      "    Batch [2/2], Val Loss: 0.1113\n",
      "Epoch [453/2000], Avg Train Loss: 0.4119, Avg Val Loss: 0.2629\n",
      "\n",
      "Validation loss improved from 0.2629 to 0.2629. Saving model...\n",
      "LOG: Epoch [454/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4226\n",
      "LOG: Epoch [454/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4145\n",
      "    Batch [2/2], Val Loss: 0.1113\n",
      "Epoch [454/2000], Avg Train Loss: 0.4226, Avg Val Loss: 0.2629\n",
      "\n",
      "Validation loss improved from 0.2629 to 0.2629. Saving model...\n",
      "LOG: Epoch [455/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4145\n",
      "LOG: Epoch [455/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4145\n",
      "    Batch [2/2], Val Loss: 0.1112\n",
      "Epoch [455/2000], Avg Train Loss: 0.4145, Avg Val Loss: 0.2628\n",
      "\n",
      "Validation loss improved from 0.2629 to 0.2628. Saving model...\n",
      "LOG: Epoch [456/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4156\n",
      "LOG: Epoch [456/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4145\n",
      "    Batch [2/2], Val Loss: 0.1112\n",
      "Epoch [456/2000], Avg Train Loss: 0.4156, Avg Val Loss: 0.2628\n",
      "\n",
      "Validation loss improved from 0.2628 to 0.2628. Saving model...\n",
      "LOG: Epoch [457/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4239\n",
      "LOG: Epoch [457/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4145\n",
      "    Batch [2/2], Val Loss: 0.1111\n",
      "Epoch [457/2000], Avg Train Loss: 0.4239, Avg Val Loss: 0.2628\n",
      "\n",
      "Validation loss improved from 0.2628 to 0.2628. Saving model...\n",
      "LOG: Epoch [458/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4174\n",
      "LOG: Epoch [458/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4145\n",
      "    Batch [2/2], Val Loss: 0.1111\n",
      "Epoch [458/2000], Avg Train Loss: 0.4174, Avg Val Loss: 0.2628\n",
      "\n",
      "Validation loss improved from 0.2628 to 0.2628. Saving model...\n",
      "LOG: Epoch [459/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4237\n",
      "LOG: Epoch [459/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4145\n",
      "    Batch [2/2], Val Loss: 0.1110\n",
      "Epoch [459/2000], Avg Train Loss: 0.4237, Avg Val Loss: 0.2628\n",
      "\n",
      "Validation loss improved from 0.2628 to 0.2628. Saving model...\n",
      "LOG: Epoch [460/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4137\n",
      "LOG: Epoch [460/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4145\n",
      "    Batch [2/2], Val Loss: 0.1110\n",
      "Epoch [460/2000], Avg Train Loss: 0.4137, Avg Val Loss: 0.2628\n",
      "\n",
      "Validation loss improved from 0.2628 to 0.2628. Saving model...\n",
      "LOG: Epoch [461/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4223\n",
      "LOG: Epoch [461/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4146\n",
      "    Batch [2/2], Val Loss: 0.1109\n",
      "Epoch [461/2000], Avg Train Loss: 0.4223, Avg Val Loss: 0.2628\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [462/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4146\n",
      "LOG: Epoch [462/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4147\n",
      "    Batch [2/2], Val Loss: 0.1109\n",
      "Epoch [462/2000], Avg Train Loss: 0.4146, Avg Val Loss: 0.2628\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [463/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4123\n",
      "LOG: Epoch [463/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4147\n",
      "    Batch [2/2], Val Loss: 0.1108\n",
      "Epoch [463/2000], Avg Train Loss: 0.4123, Avg Val Loss: 0.2628\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [464/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4113\n",
      "LOG: Epoch [464/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4148\n",
      "    Batch [2/2], Val Loss: 0.1107\n",
      "Epoch [464/2000], Avg Train Loss: 0.4113, Avg Val Loss: 0.2628\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [465/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4153\n",
      "LOG: Epoch [465/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4148\n",
      "    Batch [2/2], Val Loss: 0.1107\n",
      "Epoch [465/2000], Avg Train Loss: 0.4153, Avg Val Loss: 0.2627\n",
      "\n",
      "Validation loss improved from 0.2628 to 0.2627. Saving model...\n",
      "LOG: Epoch [466/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4195\n",
      "LOG: Epoch [466/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4148\n",
      "    Batch [2/2], Val Loss: 0.1106\n",
      "Epoch [466/2000], Avg Train Loss: 0.4195, Avg Val Loss: 0.2627\n",
      "\n",
      "Validation loss improved from 0.2627 to 0.2627. Saving model...\n",
      "LOG: Epoch [467/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4171\n",
      "LOG: Epoch [467/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4148\n",
      "    Batch [2/2], Val Loss: 0.1106\n",
      "Epoch [467/2000], Avg Train Loss: 0.4171, Avg Val Loss: 0.2627\n",
      "\n",
      "Validation loss improved from 0.2627 to 0.2627. Saving model...\n",
      "LOG: Epoch [468/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4116\n",
      "LOG: Epoch [468/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4148\n",
      "    Batch [2/2], Val Loss: 0.1106\n",
      "Epoch [468/2000], Avg Train Loss: 0.4116, Avg Val Loss: 0.2627\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [469/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4168\n",
      "LOG: Epoch [469/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4147\n",
      "    Batch [2/2], Val Loss: 0.1106\n",
      "Epoch [469/2000], Avg Train Loss: 0.4168, Avg Val Loss: 0.2627\n",
      "\n",
      "Validation loss improved from 0.2627 to 0.2627. Saving model...\n",
      "LOG: Epoch [470/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4174\n",
      "LOG: Epoch [470/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4147\n",
      "    Batch [2/2], Val Loss: 0.1106\n",
      "Epoch [470/2000], Avg Train Loss: 0.4174, Avg Val Loss: 0.2627\n",
      "\n",
      "Validation loss improved from 0.2627 to 0.2627. Saving model...\n",
      "LOG: Epoch [471/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4185\n",
      "LOG: Epoch [471/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4147\n",
      "    Batch [2/2], Val Loss: 0.1106\n",
      "Epoch [471/2000], Avg Train Loss: 0.4185, Avg Val Loss: 0.2626\n",
      "\n",
      "Validation loss improved from 0.2627 to 0.2626. Saving model...\n",
      "LOG: Epoch [472/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4108\n",
      "LOG: Epoch [472/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4147\n",
      "    Batch [2/2], Val Loss: 0.1105\n",
      "Epoch [472/2000], Avg Train Loss: 0.4108, Avg Val Loss: 0.2626\n",
      "\n",
      "Validation loss improved from 0.2626 to 0.2626. Saving model...\n",
      "LOG: Epoch [473/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4200\n",
      "LOG: Epoch [473/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4146\n",
      "    Batch [2/2], Val Loss: 0.1105\n",
      "Epoch [473/2000], Avg Train Loss: 0.4200, Avg Val Loss: 0.2625\n",
      "\n",
      "Validation loss improved from 0.2626 to 0.2625. Saving model...\n",
      "LOG: Epoch [474/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4193\n",
      "LOG: Epoch [474/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4145\n",
      "    Batch [2/2], Val Loss: 0.1105\n",
      "Epoch [474/2000], Avg Train Loss: 0.4193, Avg Val Loss: 0.2625\n",
      "\n",
      "Validation loss improved from 0.2625 to 0.2625. Saving model...\n",
      "LOG: Epoch [475/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4210\n",
      "LOG: Epoch [475/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4144\n",
      "    Batch [2/2], Val Loss: 0.1104\n",
      "Epoch [475/2000], Avg Train Loss: 0.4210, Avg Val Loss: 0.2624\n",
      "\n",
      "Validation loss improved from 0.2625 to 0.2624. Saving model...\n",
      "LOG: Epoch [476/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4200\n",
      "LOG: Epoch [476/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4144\n",
      "    Batch [2/2], Val Loss: 0.1105\n",
      "Epoch [476/2000], Avg Train Loss: 0.4200, Avg Val Loss: 0.2624\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [477/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4125\n",
      "LOG: Epoch [477/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4144\n",
      "    Batch [2/2], Val Loss: 0.1104\n",
      "Epoch [477/2000], Avg Train Loss: 0.4125, Avg Val Loss: 0.2624\n",
      "\n",
      "Validation loss improved from 0.2624 to 0.2624. Saving model...\n",
      "LOG: Epoch [478/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4180\n",
      "LOG: Epoch [478/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4143\n",
      "    Batch [2/2], Val Loss: 0.1104\n",
      "Epoch [478/2000], Avg Train Loss: 0.4180, Avg Val Loss: 0.2623\n",
      "\n",
      "Validation loss improved from 0.2624 to 0.2623. Saving model...\n",
      "LOG: Epoch [479/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4150\n",
      "LOG: Epoch [479/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4142\n",
      "    Batch [2/2], Val Loss: 0.1104\n",
      "Epoch [479/2000], Avg Train Loss: 0.4150, Avg Val Loss: 0.2623\n",
      "\n",
      "Validation loss improved from 0.2623 to 0.2623. Saving model...\n",
      "LOG: Epoch [480/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4157\n",
      "LOG: Epoch [480/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4142\n",
      "    Batch [2/2], Val Loss: 0.1104\n",
      "Epoch [480/2000], Avg Train Loss: 0.4157, Avg Val Loss: 0.2623\n",
      "\n",
      "Validation loss improved from 0.2623 to 0.2623. Saving model...\n",
      "LOG: Epoch [481/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4172\n",
      "LOG: Epoch [481/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4141\n",
      "    Batch [2/2], Val Loss: 0.1105\n",
      "Epoch [481/2000], Avg Train Loss: 0.4172, Avg Val Loss: 0.2623\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [482/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4166\n",
      "LOG: Epoch [482/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4140\n",
      "    Batch [2/2], Val Loss: 0.1105\n",
      "Epoch [482/2000], Avg Train Loss: 0.4166, Avg Val Loss: 0.2623\n",
      "\n",
      "Validation loss improved from 0.2623 to 0.2623. Saving model...\n",
      "LOG: Epoch [483/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4096\n",
      "LOG: Epoch [483/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4139\n",
      "    Batch [2/2], Val Loss: 0.1105\n",
      "Epoch [483/2000], Avg Train Loss: 0.4096, Avg Val Loss: 0.2622\n",
      "\n",
      "Validation loss improved from 0.2623 to 0.2622. Saving model...\n",
      "LOG: Epoch [484/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4250\n",
      "LOG: Epoch [484/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4138\n",
      "    Batch [2/2], Val Loss: 0.1106\n",
      "Epoch [484/2000], Avg Train Loss: 0.4250, Avg Val Loss: 0.2622\n",
      "\n",
      "Validation loss improved from 0.2622 to 0.2622. Saving model...\n",
      "LOG: Epoch [485/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4213\n",
      "LOG: Epoch [485/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4136\n",
      "    Batch [2/2], Val Loss: 0.1105\n",
      "Epoch [485/2000], Avg Train Loss: 0.4213, Avg Val Loss: 0.2621\n",
      "\n",
      "Validation loss improved from 0.2622 to 0.2621. Saving model...\n",
      "LOG: Epoch [486/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4184\n",
      "LOG: Epoch [486/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4135\n",
      "    Batch [2/2], Val Loss: 0.1104\n",
      "Epoch [486/2000], Avg Train Loss: 0.4184, Avg Val Loss: 0.2619\n",
      "\n",
      "Validation loss improved from 0.2621 to 0.2619. Saving model...\n",
      "LOG: Epoch [487/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4078\n",
      "LOG: Epoch [487/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4133\n",
      "    Batch [2/2], Val Loss: 0.1103\n",
      "Epoch [487/2000], Avg Train Loss: 0.4078, Avg Val Loss: 0.2618\n",
      "\n",
      "Validation loss improved from 0.2619 to 0.2618. Saving model...\n",
      "LOG: Epoch [488/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4157\n",
      "LOG: Epoch [488/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4132\n",
      "    Batch [2/2], Val Loss: 0.1102\n",
      "Epoch [488/2000], Avg Train Loss: 0.4157, Avg Val Loss: 0.2617\n",
      "\n",
      "Validation loss improved from 0.2618 to 0.2617. Saving model...\n",
      "LOG: Epoch [489/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4220\n",
      "LOG: Epoch [489/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4131\n",
      "    Batch [2/2], Val Loss: 0.1101\n",
      "Epoch [489/2000], Avg Train Loss: 0.4220, Avg Val Loss: 0.2616\n",
      "\n",
      "Validation loss improved from 0.2617 to 0.2616. Saving model...\n",
      "LOG: Epoch [490/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4176\n",
      "LOG: Epoch [490/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4131\n",
      "    Batch [2/2], Val Loss: 0.1100\n",
      "Epoch [490/2000], Avg Train Loss: 0.4176, Avg Val Loss: 0.2615\n",
      "\n",
      "Validation loss improved from 0.2616 to 0.2615. Saving model...\n",
      "LOG: Epoch [491/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4205\n",
      "LOG: Epoch [491/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4130\n",
      "    Batch [2/2], Val Loss: 0.1099\n",
      "Epoch [491/2000], Avg Train Loss: 0.4205, Avg Val Loss: 0.2615\n",
      "\n",
      "Validation loss improved from 0.2615 to 0.2615. Saving model...\n",
      "LOG: Epoch [492/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4147\n",
      "LOG: Epoch [492/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4130\n",
      "    Batch [2/2], Val Loss: 0.1097\n",
      "Epoch [492/2000], Avg Train Loss: 0.4147, Avg Val Loss: 0.2614\n",
      "\n",
      "Validation loss improved from 0.2615 to 0.2614. Saving model...\n",
      "LOG: Epoch [493/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4162\n",
      "LOG: Epoch [493/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4130\n",
      "    Batch [2/2], Val Loss: 0.1096\n",
      "Epoch [493/2000], Avg Train Loss: 0.4162, Avg Val Loss: 0.2613\n",
      "\n",
      "Validation loss improved from 0.2614 to 0.2613. Saving model...\n",
      "LOG: Epoch [494/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4090\n",
      "LOG: Epoch [494/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4129\n",
      "    Batch [2/2], Val Loss: 0.1095\n",
      "Epoch [494/2000], Avg Train Loss: 0.4090, Avg Val Loss: 0.2612\n",
      "\n",
      "Validation loss improved from 0.2613 to 0.2612. Saving model...\n",
      "LOG: Epoch [495/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4141\n",
      "LOG: Epoch [495/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4129\n",
      "    Batch [2/2], Val Loss: 0.1095\n",
      "Epoch [495/2000], Avg Train Loss: 0.4141, Avg Val Loss: 0.2612\n",
      "\n",
      "Validation loss improved from 0.2612 to 0.2612. Saving model...\n",
      "LOG: Epoch [496/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4127\n",
      "LOG: Epoch [496/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4128\n",
      "    Batch [2/2], Val Loss: 0.1093\n",
      "Epoch [496/2000], Avg Train Loss: 0.4127, Avg Val Loss: 0.2611\n",
      "\n",
      "Validation loss improved from 0.2612 to 0.2611. Saving model...\n",
      "LOG: Epoch [497/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4163\n",
      "LOG: Epoch [497/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4128\n",
      "    Batch [2/2], Val Loss: 0.1093\n",
      "Epoch [497/2000], Avg Train Loss: 0.4163, Avg Val Loss: 0.2610\n",
      "\n",
      "Validation loss improved from 0.2611 to 0.2610. Saving model...\n",
      "LOG: Epoch [498/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4199\n",
      "LOG: Epoch [498/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4127\n",
      "    Batch [2/2], Val Loss: 0.1092\n",
      "Epoch [498/2000], Avg Train Loss: 0.4199, Avg Val Loss: 0.2609\n",
      "\n",
      "Validation loss improved from 0.2610 to 0.2609. Saving model...\n",
      "LOG: Epoch [499/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4089\n",
      "LOG: Epoch [499/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4126\n",
      "    Batch [2/2], Val Loss: 0.1091\n",
      "Epoch [499/2000], Avg Train Loss: 0.4089, Avg Val Loss: 0.2608\n",
      "\n",
      "Validation loss improved from 0.2609 to 0.2608. Saving model...\n",
      "LOG: Epoch [500/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4131\n",
      "LOG: Epoch [500/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4125\n",
      "    Batch [2/2], Val Loss: 0.1090\n",
      "Epoch [500/2000], Avg Train Loss: 0.4131, Avg Val Loss: 0.2608\n",
      "\n",
      "Validation loss improved from 0.2608 to 0.2608. Saving model...\n",
      "LOG: Epoch [501/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4135\n",
      "LOG: Epoch [501/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4125\n",
      "    Batch [2/2], Val Loss: 0.1090\n",
      "Epoch [501/2000], Avg Train Loss: 0.4135, Avg Val Loss: 0.2607\n",
      "\n",
      "Validation loss improved from 0.2608 to 0.2607. Saving model...\n",
      "LOG: Epoch [502/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4126\n",
      "LOG: Epoch [502/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4124\n",
      "    Batch [2/2], Val Loss: 0.1089\n",
      "Epoch [502/2000], Avg Train Loss: 0.4126, Avg Val Loss: 0.2607\n",
      "\n",
      "Validation loss improved from 0.2607 to 0.2607. Saving model...\n",
      "LOG: Epoch [503/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4172\n",
      "LOG: Epoch [503/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4124\n",
      "    Batch [2/2], Val Loss: 0.1088\n",
      "Epoch [503/2000], Avg Train Loss: 0.4172, Avg Val Loss: 0.2606\n",
      "\n",
      "Validation loss improved from 0.2607 to 0.2606. Saving model...\n",
      "LOG: Epoch [504/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4169\n",
      "LOG: Epoch [504/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4124\n",
      "    Batch [2/2], Val Loss: 0.1087\n",
      "Epoch [504/2000], Avg Train Loss: 0.4169, Avg Val Loss: 0.2605\n",
      "\n",
      "Validation loss improved from 0.2606 to 0.2605. Saving model...\n",
      "LOG: Epoch [505/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4100\n",
      "LOG: Epoch [505/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4124\n",
      "    Batch [2/2], Val Loss: 0.1087\n",
      "Epoch [505/2000], Avg Train Loss: 0.4100, Avg Val Loss: 0.2605\n",
      "\n",
      "Validation loss improved from 0.2605 to 0.2605. Saving model...\n",
      "LOG: Epoch [506/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4192\n",
      "LOG: Epoch [506/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4124\n",
      "    Batch [2/2], Val Loss: 0.1086\n",
      "Epoch [506/2000], Avg Train Loss: 0.4192, Avg Val Loss: 0.2605\n",
      "\n",
      "Validation loss improved from 0.2605 to 0.2605. Saving model...\n",
      "LOG: Epoch [507/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4104\n",
      "LOG: Epoch [507/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4124\n",
      "    Batch [2/2], Val Loss: 0.1086\n",
      "Epoch [507/2000], Avg Train Loss: 0.4104, Avg Val Loss: 0.2605\n",
      "\n",
      "Validation loss improved from 0.2605 to 0.2605. Saving model...\n",
      "LOG: Epoch [508/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4190\n",
      "LOG: Epoch [508/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4124\n",
      "    Batch [2/2], Val Loss: 0.1086\n",
      "Epoch [508/2000], Avg Train Loss: 0.4190, Avg Val Loss: 0.2605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [509/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4179\n",
      "LOG: Epoch [509/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4124\n",
      "    Batch [2/2], Val Loss: 0.1085\n",
      "Epoch [509/2000], Avg Train Loss: 0.4179, Avg Val Loss: 0.2605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [510/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4131\n",
      "LOG: Epoch [510/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4125\n",
      "    Batch [2/2], Val Loss: 0.1085\n",
      "Epoch [510/2000], Avg Train Loss: 0.4131, Avg Val Loss: 0.2605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [511/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4159\n",
      "LOG: Epoch [511/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4125\n",
      "    Batch [2/2], Val Loss: 0.1085\n",
      "Epoch [511/2000], Avg Train Loss: 0.4159, Avg Val Loss: 0.2605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [512/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4130\n",
      "LOG: Epoch [512/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4125\n",
      "    Batch [2/2], Val Loss: 0.1084\n",
      "Epoch [512/2000], Avg Train Loss: 0.4130, Avg Val Loss: 0.2604\n",
      "\n",
      "Validation loss improved from 0.2605 to 0.2604. Saving model...\n",
      "LOG: Epoch [513/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4087\n",
      "LOG: Epoch [513/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4125\n",
      "    Batch [2/2], Val Loss: 0.1084\n",
      "Epoch [513/2000], Avg Train Loss: 0.4087, Avg Val Loss: 0.2605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [514/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4132\n",
      "LOG: Epoch [514/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4126\n",
      "    Batch [2/2], Val Loss: 0.1083\n",
      "Epoch [514/2000], Avg Train Loss: 0.4132, Avg Val Loss: 0.2604\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [515/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4135\n",
      "LOG: Epoch [515/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4125\n",
      "    Batch [2/2], Val Loss: 0.1084\n",
      "Epoch [515/2000], Avg Train Loss: 0.4135, Avg Val Loss: 0.2604\n",
      "\n",
      "Validation loss improved from 0.2604 to 0.2604. Saving model...\n",
      "LOG: Epoch [516/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4173\n",
      "LOG: Epoch [516/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4125\n",
      "    Batch [2/2], Val Loss: 0.1084\n",
      "Epoch [516/2000], Avg Train Loss: 0.4173, Avg Val Loss: 0.2604\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [517/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4164\n",
      "LOG: Epoch [517/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4125\n",
      "    Batch [2/2], Val Loss: 0.1085\n",
      "Epoch [517/2000], Avg Train Loss: 0.4164, Avg Val Loss: 0.2605\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [518/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4131\n",
      "LOG: Epoch [518/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4124\n",
      "    Batch [2/2], Val Loss: 0.1085\n",
      "Epoch [518/2000], Avg Train Loss: 0.4131, Avg Val Loss: 0.2604\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [519/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4135\n",
      "LOG: Epoch [519/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4123\n",
      "    Batch [2/2], Val Loss: 0.1085\n",
      "Epoch [519/2000], Avg Train Loss: 0.4135, Avg Val Loss: 0.2604\n",
      "\n",
      "Validation loss improved from 0.2604 to 0.2604. Saving model...\n",
      "LOG: Epoch [520/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4128\n",
      "LOG: Epoch [520/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4123\n",
      "    Batch [2/2], Val Loss: 0.1086\n",
      "Epoch [520/2000], Avg Train Loss: 0.4128, Avg Val Loss: 0.2604\n",
      "\n",
      "Validation loss improved from 0.2604 to 0.2604. Saving model...\n",
      "LOG: Epoch [521/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4180\n",
      "LOG: Epoch [521/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4122\n",
      "    Batch [2/2], Val Loss: 0.1087\n",
      "Epoch [521/2000], Avg Train Loss: 0.4180, Avg Val Loss: 0.2604\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [522/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4149\n",
      "LOG: Epoch [522/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4121\n",
      "    Batch [2/2], Val Loss: 0.1087\n",
      "Epoch [522/2000], Avg Train Loss: 0.4149, Avg Val Loss: 0.2604\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [523/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4114\n",
      "LOG: Epoch [523/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4120\n",
      "    Batch [2/2], Val Loss: 0.1087\n",
      "Epoch [523/2000], Avg Train Loss: 0.4114, Avg Val Loss: 0.2604\n",
      "\n",
      "Validation loss improved from 0.2604 to 0.2604. Saving model...\n",
      "LOG: Epoch [524/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4204\n",
      "LOG: Epoch [524/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4120\n",
      "    Batch [2/2], Val Loss: 0.1088\n",
      "Epoch [524/2000], Avg Train Loss: 0.4204, Avg Val Loss: 0.2604\n",
      "\n",
      "Validation loss improved from 0.2604 to 0.2604. Saving model...\n",
      "LOG: Epoch [525/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4144\n",
      "LOG: Epoch [525/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4120\n",
      "    Batch [2/2], Val Loss: 0.1088\n",
      "Epoch [525/2000], Avg Train Loss: 0.4144, Avg Val Loss: 0.2604\n",
      "\n",
      "Validation loss improved from 0.2604 to 0.2604. Saving model...\n",
      "LOG: Epoch [526/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4198\n",
      "LOG: Epoch [526/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4119\n",
      "    Batch [2/2], Val Loss: 0.1088\n",
      "Epoch [526/2000], Avg Train Loss: 0.4198, Avg Val Loss: 0.2603\n",
      "\n",
      "Validation loss improved from 0.2604 to 0.2603. Saving model...\n",
      "LOG: Epoch [527/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4101\n",
      "LOG: Epoch [527/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4119\n",
      "    Batch [2/2], Val Loss: 0.1088\n",
      "Epoch [527/2000], Avg Train Loss: 0.4101, Avg Val Loss: 0.2603\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [528/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4167\n",
      "LOG: Epoch [528/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4119\n",
      "    Batch [2/2], Val Loss: 0.1088\n",
      "Epoch [528/2000], Avg Train Loss: 0.4167, Avg Val Loss: 0.2603\n",
      "\n",
      "Validation loss improved from 0.2603 to 0.2603. Saving model...\n",
      "LOG: Epoch [529/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4129\n",
      "LOG: Epoch [529/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4119\n",
      "    Batch [2/2], Val Loss: 0.1087\n",
      "Epoch [529/2000], Avg Train Loss: 0.4129, Avg Val Loss: 0.2603\n",
      "\n",
      "Validation loss improved from 0.2603 to 0.2603. Saving model...\n",
      "LOG: Epoch [530/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4152\n",
      "LOG: Epoch [530/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4118\n",
      "    Batch [2/2], Val Loss: 0.1087\n",
      "Epoch [530/2000], Avg Train Loss: 0.4152, Avg Val Loss: 0.2603\n",
      "\n",
      "Validation loss improved from 0.2603 to 0.2603. Saving model...\n",
      "LOG: Epoch [531/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [531/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4117\n",
      "    Batch [2/2], Val Loss: 0.1087\n",
      "Epoch [531/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2602\n",
      "\n",
      "Validation loss improved from 0.2603 to 0.2602. Saving model...\n",
      "LOG: Epoch [532/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4134\n",
      "LOG: Epoch [532/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4117\n",
      "    Batch [2/2], Val Loss: 0.1087\n",
      "Epoch [532/2000], Avg Train Loss: 0.4134, Avg Val Loss: 0.2602\n",
      "\n",
      "Validation loss improved from 0.2602 to 0.2602. Saving model...\n",
      "LOG: Epoch [533/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4120\n",
      "LOG: Epoch [533/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4117\n",
      "    Batch [2/2], Val Loss: 0.1086\n",
      "Epoch [533/2000], Avg Train Loss: 0.4120, Avg Val Loss: 0.2602\n",
      "\n",
      "Validation loss improved from 0.2602 to 0.2602. Saving model...\n",
      "LOG: Epoch [534/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4185\n",
      "LOG: Epoch [534/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4117\n",
      "    Batch [2/2], Val Loss: 0.1086\n",
      "Epoch [534/2000], Avg Train Loss: 0.4185, Avg Val Loss: 0.2602\n",
      "\n",
      "Validation loss improved from 0.2602 to 0.2602. Saving model...\n",
      "LOG: Epoch [535/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4124\n",
      "LOG: Epoch [535/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4118\n",
      "    Batch [2/2], Val Loss: 0.1086\n",
      "Epoch [535/2000], Avg Train Loss: 0.4124, Avg Val Loss: 0.2602\n",
      "\n",
      "Validation loss improved from 0.2602 to 0.2602. Saving model...\n",
      "LOG: Epoch [536/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4106\n",
      "LOG: Epoch [536/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4118\n",
      "    Batch [2/2], Val Loss: 0.1085\n",
      "Epoch [536/2000], Avg Train Loss: 0.4106, Avg Val Loss: 0.2602\n",
      "\n",
      "Validation loss improved from 0.2602 to 0.2602. Saving model...\n",
      "LOG: Epoch [537/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4157\n",
      "LOG: Epoch [537/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4118\n",
      "    Batch [2/2], Val Loss: 0.1085\n",
      "Epoch [537/2000], Avg Train Loss: 0.4157, Avg Val Loss: 0.2602\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [538/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4161\n",
      "LOG: Epoch [538/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4118\n",
      "    Batch [2/2], Val Loss: 0.1084\n",
      "Epoch [538/2000], Avg Train Loss: 0.4161, Avg Val Loss: 0.2601\n",
      "\n",
      "Validation loss improved from 0.2602 to 0.2601. Saving model...\n",
      "LOG: Epoch [539/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4193\n",
      "LOG: Epoch [539/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4118\n",
      "    Batch [2/2], Val Loss: 0.1084\n",
      "Epoch [539/2000], Avg Train Loss: 0.4193, Avg Val Loss: 0.2601\n",
      "\n",
      "Validation loss improved from 0.2601 to 0.2601. Saving model...\n",
      "LOG: Epoch [540/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4192\n",
      "LOG: Epoch [540/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4117\n",
      "    Batch [2/2], Val Loss: 0.1084\n",
      "Epoch [540/2000], Avg Train Loss: 0.4192, Avg Val Loss: 0.2600\n",
      "\n",
      "Validation loss improved from 0.2601 to 0.2600. Saving model...\n",
      "LOG: Epoch [541/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4150\n",
      "LOG: Epoch [541/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4116\n",
      "    Batch [2/2], Val Loss: 0.1084\n",
      "Epoch [541/2000], Avg Train Loss: 0.4150, Avg Val Loss: 0.2600\n",
      "\n",
      "Validation loss improved from 0.2600 to 0.2600. Saving model...\n",
      "LOG: Epoch [542/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4127\n",
      "LOG: Epoch [542/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4116\n",
      "    Batch [2/2], Val Loss: 0.1083\n",
      "Epoch [542/2000], Avg Train Loss: 0.4127, Avg Val Loss: 0.2600\n",
      "\n",
      "Validation loss improved from 0.2600 to 0.2600. Saving model...\n",
      "LOG: Epoch [543/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4087\n",
      "LOG: Epoch [543/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4116\n",
      "    Batch [2/2], Val Loss: 0.1083\n",
      "Epoch [543/2000], Avg Train Loss: 0.4087, Avg Val Loss: 0.2599\n",
      "\n",
      "Validation loss improved from 0.2600 to 0.2599. Saving model...\n",
      "LOG: Epoch [544/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4131\n",
      "LOG: Epoch [544/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4115\n",
      "    Batch [2/2], Val Loss: 0.1083\n",
      "Epoch [544/2000], Avg Train Loss: 0.4131, Avg Val Loss: 0.2599\n",
      "\n",
      "Validation loss improved from 0.2599 to 0.2599. Saving model...\n",
      "LOG: Epoch [545/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4129\n",
      "LOG: Epoch [545/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4114\n",
      "    Batch [2/2], Val Loss: 0.1083\n",
      "Epoch [545/2000], Avg Train Loss: 0.4129, Avg Val Loss: 0.2598\n",
      "\n",
      "Validation loss improved from 0.2599 to 0.2598. Saving model...\n",
      "LOG: Epoch [546/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4092\n",
      "LOG: Epoch [546/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4113\n",
      "    Batch [2/2], Val Loss: 0.1083\n",
      "Epoch [546/2000], Avg Train Loss: 0.4092, Avg Val Loss: 0.2598\n",
      "\n",
      "Validation loss improved from 0.2598 to 0.2598. Saving model...\n",
      "LOG: Epoch [547/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4172\n",
      "LOG: Epoch [547/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4112\n",
      "    Batch [2/2], Val Loss: 0.1083\n",
      "Epoch [547/2000], Avg Train Loss: 0.4172, Avg Val Loss: 0.2598\n",
      "\n",
      "Validation loss improved from 0.2598 to 0.2598. Saving model...\n",
      "LOG: Epoch [548/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4109\n",
      "LOG: Epoch [548/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4112\n",
      "    Batch [2/2], Val Loss: 0.1083\n",
      "Epoch [548/2000], Avg Train Loss: 0.4109, Avg Val Loss: 0.2598\n",
      "\n",
      "Validation loss improved from 0.2598 to 0.2598. Saving model...\n",
      "LOG: Epoch [549/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [549/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4111\n",
      "    Batch [2/2], Val Loss: 0.1084\n",
      "Epoch [549/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2597\n",
      "\n",
      "Validation loss improved from 0.2598 to 0.2597. Saving model...\n",
      "LOG: Epoch [550/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4164\n",
      "LOG: Epoch [550/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4111\n",
      "    Batch [2/2], Val Loss: 0.1084\n",
      "Epoch [550/2000], Avg Train Loss: 0.4164, Avg Val Loss: 0.2597\n",
      "\n",
      "Validation loss improved from 0.2597 to 0.2597. Saving model...\n",
      "LOG: Epoch [551/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4120\n",
      "LOG: Epoch [551/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4110\n",
      "    Batch [2/2], Val Loss: 0.1084\n",
      "Epoch [551/2000], Avg Train Loss: 0.4120, Avg Val Loss: 0.2597\n",
      "\n",
      "Validation loss improved from 0.2597 to 0.2597. Saving model...\n",
      "LOG: Epoch [552/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4163\n",
      "LOG: Epoch [552/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4110\n",
      "    Batch [2/2], Val Loss: 0.1083\n",
      "Epoch [552/2000], Avg Train Loss: 0.4163, Avg Val Loss: 0.2597\n",
      "\n",
      "Validation loss improved from 0.2597 to 0.2597. Saving model...\n",
      "LOG: Epoch [553/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4075\n",
      "LOG: Epoch [553/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4110\n",
      "    Batch [2/2], Val Loss: 0.1083\n",
      "Epoch [553/2000], Avg Train Loss: 0.4075, Avg Val Loss: 0.2596\n",
      "\n",
      "Validation loss improved from 0.2597 to 0.2596. Saving model...\n",
      "LOG: Epoch [554/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4145\n",
      "LOG: Epoch [554/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4109\n",
      "    Batch [2/2], Val Loss: 0.1082\n",
      "Epoch [554/2000], Avg Train Loss: 0.4145, Avg Val Loss: 0.2595\n",
      "\n",
      "Validation loss improved from 0.2596 to 0.2595. Saving model...\n",
      "LOG: Epoch [555/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4153\n",
      "LOG: Epoch [555/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4108\n",
      "    Batch [2/2], Val Loss: 0.1081\n",
      "Epoch [555/2000], Avg Train Loss: 0.4153, Avg Val Loss: 0.2594\n",
      "\n",
      "Validation loss improved from 0.2595 to 0.2594. Saving model...\n",
      "LOG: Epoch [556/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4110\n",
      "LOG: Epoch [556/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4107\n",
      "    Batch [2/2], Val Loss: 0.1080\n",
      "Epoch [556/2000], Avg Train Loss: 0.4110, Avg Val Loss: 0.2593\n",
      "\n",
      "Validation loss improved from 0.2594 to 0.2593. Saving model...\n",
      "LOG: Epoch [557/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4136\n",
      "LOG: Epoch [557/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4106\n",
      "    Batch [2/2], Val Loss: 0.1079\n",
      "Epoch [557/2000], Avg Train Loss: 0.4136, Avg Val Loss: 0.2593\n",
      "\n",
      "Validation loss improved from 0.2593 to 0.2593. Saving model...\n",
      "LOG: Epoch [558/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4177\n",
      "LOG: Epoch [558/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4106\n",
      "    Batch [2/2], Val Loss: 0.1079\n",
      "Epoch [558/2000], Avg Train Loss: 0.4177, Avg Val Loss: 0.2592\n",
      "\n",
      "Validation loss improved from 0.2593 to 0.2592. Saving model...\n",
      "LOG: Epoch [559/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4112\n",
      "LOG: Epoch [559/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4106\n",
      "    Batch [2/2], Val Loss: 0.1079\n",
      "Epoch [559/2000], Avg Train Loss: 0.4112, Avg Val Loss: 0.2592\n",
      "\n",
      "Validation loss improved from 0.2592 to 0.2592. Saving model...\n",
      "LOG: Epoch [560/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4099\n",
      "LOG: Epoch [560/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4105\n",
      "    Batch [2/2], Val Loss: 0.1078\n",
      "Epoch [560/2000], Avg Train Loss: 0.4099, Avg Val Loss: 0.2592\n",
      "\n",
      "Validation loss improved from 0.2592 to 0.2592. Saving model...\n",
      "LOG: Epoch [561/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4092\n",
      "LOG: Epoch [561/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4104\n",
      "    Batch [2/2], Val Loss: 0.1078\n",
      "Epoch [561/2000], Avg Train Loss: 0.4092, Avg Val Loss: 0.2591\n",
      "\n",
      "Validation loss improved from 0.2592 to 0.2591. Saving model...\n",
      "LOG: Epoch [562/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4133\n",
      "LOG: Epoch [562/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4104\n",
      "    Batch [2/2], Val Loss: 0.1077\n",
      "Epoch [562/2000], Avg Train Loss: 0.4133, Avg Val Loss: 0.2590\n",
      "\n",
      "Validation loss improved from 0.2591 to 0.2590. Saving model...\n",
      "LOG: Epoch [563/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4153\n",
      "LOG: Epoch [563/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4104\n",
      "    Batch [2/2], Val Loss: 0.1076\n",
      "Epoch [563/2000], Avg Train Loss: 0.4153, Avg Val Loss: 0.2590\n",
      "\n",
      "Validation loss improved from 0.2590 to 0.2590. Saving model...\n",
      "LOG: Epoch [564/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4139\n",
      "LOG: Epoch [564/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4104\n",
      "    Batch [2/2], Val Loss: 0.1076\n",
      "Epoch [564/2000], Avg Train Loss: 0.4139, Avg Val Loss: 0.2590\n",
      "\n",
      "Validation loss improved from 0.2590 to 0.2590. Saving model...\n",
      "LOG: Epoch [565/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4097\n",
      "LOG: Epoch [565/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4104\n",
      "    Batch [2/2], Val Loss: 0.1075\n",
      "Epoch [565/2000], Avg Train Loss: 0.4097, Avg Val Loss: 0.2590\n",
      "\n",
      "Validation loss improved from 0.2590 to 0.2590. Saving model...\n",
      "LOG: Epoch [566/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4106\n",
      "LOG: Epoch [566/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4104\n",
      "    Batch [2/2], Val Loss: 0.1075\n",
      "Epoch [566/2000], Avg Train Loss: 0.4106, Avg Val Loss: 0.2590\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [567/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4104\n",
      "LOG: Epoch [567/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4104\n",
      "    Batch [2/2], Val Loss: 0.1075\n",
      "Epoch [567/2000], Avg Train Loss: 0.4104, Avg Val Loss: 0.2589\n",
      "\n",
      "Validation loss improved from 0.2590 to 0.2589. Saving model...\n",
      "LOG: Epoch [568/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4099\n",
      "LOG: Epoch [568/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4103\n",
      "    Batch [2/2], Val Loss: 0.1075\n",
      "Epoch [568/2000], Avg Train Loss: 0.4099, Avg Val Loss: 0.2589\n",
      "\n",
      "Validation loss improved from 0.2589 to 0.2589. Saving model...\n",
      "LOG: Epoch [569/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4141\n",
      "LOG: Epoch [569/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4103\n",
      "    Batch [2/2], Val Loss: 0.1075\n",
      "Epoch [569/2000], Avg Train Loss: 0.4141, Avg Val Loss: 0.2589\n",
      "\n",
      "Validation loss improved from 0.2589 to 0.2589. Saving model...\n",
      "LOG: Epoch [570/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4098\n",
      "LOG: Epoch [570/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4103\n",
      "    Batch [2/2], Val Loss: 0.1075\n",
      "Epoch [570/2000], Avg Train Loss: 0.4098, Avg Val Loss: 0.2589\n",
      "\n",
      "Validation loss improved from 0.2589 to 0.2589. Saving model...\n",
      "LOG: Epoch [571/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4192\n",
      "LOG: Epoch [571/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4102\n",
      "    Batch [2/2], Val Loss: 0.1074\n",
      "Epoch [571/2000], Avg Train Loss: 0.4192, Avg Val Loss: 0.2588\n",
      "\n",
      "Validation loss improved from 0.2589 to 0.2588. Saving model...\n",
      "LOG: Epoch [572/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4099\n",
      "LOG: Epoch [572/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4102\n",
      "    Batch [2/2], Val Loss: 0.1074\n",
      "Epoch [572/2000], Avg Train Loss: 0.4099, Avg Val Loss: 0.2588\n",
      "\n",
      "Validation loss improved from 0.2588 to 0.2588. Saving model...\n",
      "LOG: Epoch [573/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4087\n",
      "LOG: Epoch [573/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4102\n",
      "    Batch [2/2], Val Loss: 0.1073\n",
      "Epoch [573/2000], Avg Train Loss: 0.4087, Avg Val Loss: 0.2587\n",
      "\n",
      "Validation loss improved from 0.2588 to 0.2587. Saving model...\n",
      "LOG: Epoch [574/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4113\n",
      "LOG: Epoch [574/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4102\n",
      "    Batch [2/2], Val Loss: 0.1072\n",
      "Epoch [574/2000], Avg Train Loss: 0.4113, Avg Val Loss: 0.2587\n",
      "\n",
      "Validation loss improved from 0.2587 to 0.2587. Saving model...\n",
      "LOG: Epoch [575/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3996\n",
      "LOG: Epoch [575/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4102\n",
      "    Batch [2/2], Val Loss: 0.1072\n",
      "Epoch [575/2000], Avg Train Loss: 0.3996, Avg Val Loss: 0.2587\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [576/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4102\n",
      "LOG: Epoch [576/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4103\n",
      "    Batch [2/2], Val Loss: 0.1071\n",
      "Epoch [576/2000], Avg Train Loss: 0.4102, Avg Val Loss: 0.2587\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [577/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4149\n",
      "LOG: Epoch [577/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4104\n",
      "    Batch [2/2], Val Loss: 0.1071\n",
      "Epoch [577/2000], Avg Train Loss: 0.4149, Avg Val Loss: 0.2587\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4120\n",
      "LOG: Epoch [578/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4105\n",
      "    Batch [2/2], Val Loss: 0.1071\n",
      "Epoch [578/2000], Avg Train Loss: 0.4120, Avg Val Loss: 0.2588\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [579/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4108\n",
      "LOG: Epoch [579/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4105\n",
      "    Batch [2/2], Val Loss: 0.1070\n",
      "Epoch [579/2000], Avg Train Loss: 0.4108, Avg Val Loss: 0.2588\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [580/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4136\n",
      "LOG: Epoch [580/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4106\n",
      "    Batch [2/2], Val Loss: 0.1070\n",
      "Epoch [580/2000], Avg Train Loss: 0.4136, Avg Val Loss: 0.2588\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [581/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4082\n",
      "LOG: Epoch [581/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4106\n",
      "    Batch [2/2], Val Loss: 0.1069\n",
      "Epoch [581/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2588\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [582/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4162\n",
      "LOG: Epoch [582/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4107\n",
      "    Batch [2/2], Val Loss: 0.1070\n",
      "Epoch [582/2000], Avg Train Loss: 0.4162, Avg Val Loss: 0.2588\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [583/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4107\n",
      "LOG: Epoch [583/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4106\n",
      "    Batch [2/2], Val Loss: 0.1070\n",
      "Epoch [583/2000], Avg Train Loss: 0.4107, Avg Val Loss: 0.2588\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [584/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4100\n",
      "LOG: Epoch [584/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4106\n",
      "    Batch [2/2], Val Loss: 0.1070\n",
      "Epoch [584/2000], Avg Train Loss: 0.4100, Avg Val Loss: 0.2588\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [585/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4056\n",
      "LOG: Epoch [585/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4106\n",
      "    Batch [2/2], Val Loss: 0.1070\n",
      "Epoch [585/2000], Avg Train Loss: 0.4056, Avg Val Loss: 0.2588\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [586/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4097\n",
      "LOG: Epoch [586/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4106\n",
      "    Batch [2/2], Val Loss: 0.1069\n",
      "Epoch [586/2000], Avg Train Loss: 0.4097, Avg Val Loss: 0.2588\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [587/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4123\n",
      "LOG: Epoch [587/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4106\n",
      "    Batch [2/2], Val Loss: 0.1069\n",
      "Epoch [587/2000], Avg Train Loss: 0.4123, Avg Val Loss: 0.2588\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [588/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4148\n",
      "LOG: Epoch [588/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4106\n",
      "    Batch [2/2], Val Loss: 0.1069\n",
      "Epoch [588/2000], Avg Train Loss: 0.4148, Avg Val Loss: 0.2587\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [589/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [589/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4106\n",
      "    Batch [2/2], Val Loss: 0.1068\n",
      "Epoch [589/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2587\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [590/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [590/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4106\n",
      "    Batch [2/2], Val Loss: 0.1068\n",
      "Epoch [590/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2587\n",
      "\n",
      "Validation loss improved from 0.2587 to 0.2587. Saving model...\n",
      "LOG: Epoch [591/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [591/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4106\n",
      "    Batch [2/2], Val Loss: 0.1068\n",
      "Epoch [591/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2587\n",
      "\n",
      "Validation loss improved from 0.2587 to 0.2587. Saving model...\n",
      "LOG: Epoch [592/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4130\n",
      "LOG: Epoch [592/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4106\n",
      "    Batch [2/2], Val Loss: 0.1068\n",
      "Epoch [592/2000], Avg Train Loss: 0.4130, Avg Val Loss: 0.2587\n",
      "\n",
      "Validation loss improved from 0.2587 to 0.2587. Saving model...\n",
      "LOG: Epoch [593/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4064\n",
      "LOG: Epoch [593/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4105\n",
      "    Batch [2/2], Val Loss: 0.1067\n",
      "Epoch [593/2000], Avg Train Loss: 0.4064, Avg Val Loss: 0.2586\n",
      "\n",
      "Validation loss improved from 0.2587 to 0.2586. Saving model...\n",
      "LOG: Epoch [594/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4134\n",
      "LOG: Epoch [594/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4105\n",
      "    Batch [2/2], Val Loss: 0.1067\n",
      "Epoch [594/2000], Avg Train Loss: 0.4134, Avg Val Loss: 0.2586\n",
      "\n",
      "Validation loss improved from 0.2586 to 0.2586. Saving model...\n",
      "LOG: Epoch [595/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4107\n",
      "LOG: Epoch [595/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4105\n",
      "    Batch [2/2], Val Loss: 0.1067\n",
      "Epoch [595/2000], Avg Train Loss: 0.4107, Avg Val Loss: 0.2586\n",
      "\n",
      "Validation loss improved from 0.2586 to 0.2586. Saving model...\n",
      "LOG: Epoch [596/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4127\n",
      "LOG: Epoch [596/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4104\n",
      "    Batch [2/2], Val Loss: 0.1068\n",
      "Epoch [596/2000], Avg Train Loss: 0.4127, Avg Val Loss: 0.2586\n",
      "\n",
      "Validation loss improved from 0.2586 to 0.2586. Saving model...\n",
      "LOG: Epoch [597/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4145\n",
      "LOG: Epoch [597/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4104\n",
      "    Batch [2/2], Val Loss: 0.1068\n",
      "Epoch [597/2000], Avg Train Loss: 0.4145, Avg Val Loss: 0.2586\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [598/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [598/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4103\n",
      "    Batch [2/2], Val Loss: 0.1068\n",
      "Epoch [598/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2586\n",
      "\n",
      "Validation loss improved from 0.2586 to 0.2586. Saving model...\n",
      "LOG: Epoch [599/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4076\n",
      "LOG: Epoch [599/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4102\n",
      "    Batch [2/2], Val Loss: 0.1069\n",
      "Epoch [599/2000], Avg Train Loss: 0.4076, Avg Val Loss: 0.2585\n",
      "\n",
      "Validation loss improved from 0.2586 to 0.2585. Saving model...\n",
      "LOG: Epoch [600/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [600/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4102\n",
      "    Batch [2/2], Val Loss: 0.1069\n",
      "Epoch [600/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2585\n",
      "\n",
      "Validation loss improved from 0.2585 to 0.2585. Saving model...\n",
      "LOG: Epoch [601/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4173\n",
      "LOG: Epoch [601/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4101\n",
      "    Batch [2/2], Val Loss: 0.1069\n",
      "Epoch [601/2000], Avg Train Loss: 0.4173, Avg Val Loss: 0.2585\n",
      "\n",
      "Validation loss improved from 0.2585 to 0.2585. Saving model...\n",
      "LOG: Epoch [602/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4157\n",
      "LOG: Epoch [602/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4100\n",
      "    Batch [2/2], Val Loss: 0.1069\n",
      "Epoch [602/2000], Avg Train Loss: 0.4157, Avg Val Loss: 0.2585\n",
      "\n",
      "Validation loss improved from 0.2585 to 0.2585. Saving model...\n",
      "LOG: Epoch [603/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [603/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4099\n",
      "    Batch [2/2], Val Loss: 0.1069\n",
      "Epoch [603/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2584\n",
      "\n",
      "Validation loss improved from 0.2585 to 0.2584. Saving model...\n",
      "LOG: Epoch [604/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4121\n",
      "LOG: Epoch [604/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4099\n",
      "    Batch [2/2], Val Loss: 0.1070\n",
      "Epoch [604/2000], Avg Train Loss: 0.4121, Avg Val Loss: 0.2584\n",
      "\n",
      "Validation loss improved from 0.2584 to 0.2584. Saving model...\n",
      "LOG: Epoch [605/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4118\n",
      "LOG: Epoch [605/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4098\n",
      "    Batch [2/2], Val Loss: 0.1069\n",
      "Epoch [605/2000], Avg Train Loss: 0.4118, Avg Val Loss: 0.2584\n",
      "\n",
      "Validation loss improved from 0.2584 to 0.2584. Saving model...\n",
      "LOG: Epoch [606/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4088\n",
      "LOG: Epoch [606/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4097\n",
      "    Batch [2/2], Val Loss: 0.1068\n",
      "Epoch [606/2000], Avg Train Loss: 0.4088, Avg Val Loss: 0.2583\n",
      "\n",
      "Validation loss improved from 0.2584 to 0.2583. Saving model...\n",
      "LOG: Epoch [607/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4138\n",
      "LOG: Epoch [607/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4097\n",
      "    Batch [2/2], Val Loss: 0.1068\n",
      "Epoch [607/2000], Avg Train Loss: 0.4138, Avg Val Loss: 0.2583\n",
      "\n",
      "Validation loss improved from 0.2583 to 0.2583. Saving model...\n",
      "LOG: Epoch [608/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4123\n",
      "LOG: Epoch [608/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4097\n",
      "    Batch [2/2], Val Loss: 0.1067\n",
      "Epoch [608/2000], Avg Train Loss: 0.4123, Avg Val Loss: 0.2582\n",
      "\n",
      "Validation loss improved from 0.2583 to 0.2582. Saving model...\n",
      "LOG: Epoch [609/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4126\n",
      "LOG: Epoch [609/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4096\n",
      "    Batch [2/2], Val Loss: 0.1067\n",
      "Epoch [609/2000], Avg Train Loss: 0.4126, Avg Val Loss: 0.2582\n",
      "\n",
      "Validation loss improved from 0.2582 to 0.2582. Saving model...\n",
      "LOG: Epoch [610/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4108\n",
      "LOG: Epoch [610/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4096\n",
      "    Batch [2/2], Val Loss: 0.1067\n",
      "Epoch [610/2000], Avg Train Loss: 0.4108, Avg Val Loss: 0.2581\n",
      "\n",
      "Validation loss improved from 0.2582 to 0.2581. Saving model...\n",
      "LOG: Epoch [611/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4082\n",
      "LOG: Epoch [611/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4096\n",
      "    Batch [2/2], Val Loss: 0.1067\n",
      "Epoch [611/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2581\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [612/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4140\n",
      "LOG: Epoch [612/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4095\n",
      "    Batch [2/2], Val Loss: 0.1067\n",
      "Epoch [612/2000], Avg Train Loss: 0.4140, Avg Val Loss: 0.2581\n",
      "\n",
      "Validation loss improved from 0.2581 to 0.2581. Saving model...\n",
      "LOG: Epoch [613/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [613/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4095\n",
      "    Batch [2/2], Val Loss: 0.1067\n",
      "Epoch [613/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2581\n",
      "\n",
      "Validation loss improved from 0.2581 to 0.2581. Saving model...\n",
      "LOG: Epoch [614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4128\n",
      "LOG: Epoch [614/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4095\n",
      "    Batch [2/2], Val Loss: 0.1067\n",
      "Epoch [614/2000], Avg Train Loss: 0.4128, Avg Val Loss: 0.2581\n",
      "\n",
      "Validation loss improved from 0.2581 to 0.2581. Saving model...\n",
      "LOG: Epoch [615/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [615/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4094\n",
      "    Batch [2/2], Val Loss: 0.1066\n",
      "Epoch [615/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2580\n",
      "\n",
      "Validation loss improved from 0.2581 to 0.2580. Saving model...\n",
      "LOG: Epoch [616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4196\n",
      "LOG: Epoch [616/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4094\n",
      "    Batch [2/2], Val Loss: 0.1066\n",
      "Epoch [616/2000], Avg Train Loss: 0.4196, Avg Val Loss: 0.2580\n",
      "\n",
      "Validation loss improved from 0.2580 to 0.2580. Saving model...\n",
      "LOG: Epoch [617/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4075\n",
      "LOG: Epoch [617/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4094\n",
      "    Batch [2/2], Val Loss: 0.1066\n",
      "Epoch [617/2000], Avg Train Loss: 0.4075, Avg Val Loss: 0.2580\n",
      "\n",
      "Validation loss improved from 0.2580 to 0.2580. Saving model...\n",
      "LOG: Epoch [618/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4097\n",
      "LOG: Epoch [618/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4094\n",
      "    Batch [2/2], Val Loss: 0.1066\n",
      "Epoch [618/2000], Avg Train Loss: 0.4097, Avg Val Loss: 0.2580\n",
      "\n",
      "Validation loss improved from 0.2580 to 0.2580. Saving model...\n",
      "LOG: Epoch [619/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [619/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4093\n",
      "    Batch [2/2], Val Loss: 0.1066\n",
      "Epoch [619/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2579\n",
      "\n",
      "Validation loss improved from 0.2580 to 0.2579. Saving model...\n",
      "LOG: Epoch [620/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4096\n",
      "LOG: Epoch [620/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4092\n",
      "    Batch [2/2], Val Loss: 0.1065\n",
      "Epoch [620/2000], Avg Train Loss: 0.4096, Avg Val Loss: 0.2579\n",
      "\n",
      "Validation loss improved from 0.2579 to 0.2579. Saving model...\n",
      "LOG: Epoch [621/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4122\n",
      "LOG: Epoch [621/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4092\n",
      "    Batch [2/2], Val Loss: 0.1065\n",
      "Epoch [621/2000], Avg Train Loss: 0.4122, Avg Val Loss: 0.2578\n",
      "\n",
      "Validation loss improved from 0.2579 to 0.2578. Saving model...\n",
      "LOG: Epoch [622/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4154\n",
      "LOG: Epoch [622/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4092\n",
      "    Batch [2/2], Val Loss: 0.1065\n",
      "Epoch [622/2000], Avg Train Loss: 0.4154, Avg Val Loss: 0.2578\n",
      "\n",
      "Validation loss improved from 0.2578 to 0.2578. Saving model...\n",
      "LOG: Epoch [623/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4064\n",
      "LOG: Epoch [623/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4091\n",
      "    Batch [2/2], Val Loss: 0.1064\n",
      "Epoch [623/2000], Avg Train Loss: 0.4064, Avg Val Loss: 0.2578\n",
      "\n",
      "Validation loss improved from 0.2578 to 0.2578. Saving model...\n",
      "LOG: Epoch [624/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [624/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4090\n",
      "    Batch [2/2], Val Loss: 0.1064\n",
      "Epoch [624/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2577\n",
      "\n",
      "Validation loss improved from 0.2578 to 0.2577. Saving model...\n",
      "LOG: Epoch [625/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4092\n",
      "LOG: Epoch [625/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4090\n",
      "    Batch [2/2], Val Loss: 0.1064\n",
      "Epoch [625/2000], Avg Train Loss: 0.4092, Avg Val Loss: 0.2577\n",
      "\n",
      "Validation loss improved from 0.2577 to 0.2577. Saving model...\n",
      "LOG: Epoch [626/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4147\n",
      "LOG: Epoch [626/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4090\n",
      "    Batch [2/2], Val Loss: 0.1064\n",
      "Epoch [626/2000], Avg Train Loss: 0.4147, Avg Val Loss: 0.2577\n",
      "\n",
      "Validation loss improved from 0.2577 to 0.2577. Saving model...\n",
      "LOG: Epoch [627/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4156\n",
      "LOG: Epoch [627/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4089\n",
      "    Batch [2/2], Val Loss: 0.1064\n",
      "Epoch [627/2000], Avg Train Loss: 0.4156, Avg Val Loss: 0.2576\n",
      "\n",
      "Validation loss improved from 0.2577 to 0.2576. Saving model...\n",
      "LOG: Epoch [628/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4074\n",
      "LOG: Epoch [628/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4089\n",
      "    Batch [2/2], Val Loss: 0.1064\n",
      "Epoch [628/2000], Avg Train Loss: 0.4074, Avg Val Loss: 0.2577\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [629/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4111\n",
      "LOG: Epoch [629/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4089\n",
      "    Batch [2/2], Val Loss: 0.1064\n",
      "Epoch [629/2000], Avg Train Loss: 0.4111, Avg Val Loss: 0.2577\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [630/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4077\n",
      "LOG: Epoch [630/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4089\n",
      "    Batch [2/2], Val Loss: 0.1064\n",
      "Epoch [630/2000], Avg Train Loss: 0.4077, Avg Val Loss: 0.2576\n",
      "\n",
      "Validation loss improved from 0.2576 to 0.2576. Saving model...\n",
      "LOG: Epoch [631/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [631/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4089\n",
      "    Batch [2/2], Val Loss: 0.1064\n",
      "Epoch [631/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2576\n",
      "\n",
      "Validation loss improved from 0.2576 to 0.2576. Saving model...\n",
      "LOG: Epoch [632/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [632/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4088\n",
      "    Batch [2/2], Val Loss: 0.1064\n",
      "Epoch [632/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2576\n",
      "\n",
      "Validation loss improved from 0.2576 to 0.2576. Saving model...\n",
      "LOG: Epoch [633/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4173\n",
      "LOG: Epoch [633/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4087\n",
      "    Batch [2/2], Val Loss: 0.1064\n",
      "Epoch [633/2000], Avg Train Loss: 0.4173, Avg Val Loss: 0.2575\n",
      "\n",
      "Validation loss improved from 0.2576 to 0.2575. Saving model...\n",
      "LOG: Epoch [634/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4106\n",
      "LOG: Epoch [634/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4086\n",
      "    Batch [2/2], Val Loss: 0.1064\n",
      "Epoch [634/2000], Avg Train Loss: 0.4106, Avg Val Loss: 0.2575\n",
      "\n",
      "Validation loss improved from 0.2575 to 0.2575. Saving model...\n",
      "LOG: Epoch [635/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [635/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4085\n",
      "    Batch [2/2], Val Loss: 0.1064\n",
      "Epoch [635/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2574\n",
      "\n",
      "Validation loss improved from 0.2575 to 0.2574. Saving model...\n",
      "LOG: Epoch [636/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [636/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4084\n",
      "    Batch [2/2], Val Loss: 0.1063\n",
      "Epoch [636/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.2574\n",
      "\n",
      "Validation loss improved from 0.2574 to 0.2574. Saving model...\n",
      "LOG: Epoch [637/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4142\n",
      "LOG: Epoch [637/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4083\n",
      "    Batch [2/2], Val Loss: 0.1063\n",
      "Epoch [637/2000], Avg Train Loss: 0.4142, Avg Val Loss: 0.2573\n",
      "\n",
      "Validation loss improved from 0.2574 to 0.2573. Saving model...\n",
      "LOG: Epoch [638/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4078\n",
      "LOG: Epoch [638/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4081\n",
      "    Batch [2/2], Val Loss: 0.1062\n",
      "Epoch [638/2000], Avg Train Loss: 0.4078, Avg Val Loss: 0.2572\n",
      "\n",
      "Validation loss improved from 0.2573 to 0.2572. Saving model...\n",
      "LOG: Epoch [639/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [639/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4080\n",
      "    Batch [2/2], Val Loss: 0.1062\n",
      "Epoch [639/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2571\n",
      "\n",
      "Validation loss improved from 0.2572 to 0.2571. Saving model...\n",
      "LOG: Epoch [640/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4134\n",
      "LOG: Epoch [640/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4079\n",
      "    Batch [2/2], Val Loss: 0.1062\n",
      "Epoch [640/2000], Avg Train Loss: 0.4134, Avg Val Loss: 0.2570\n",
      "\n",
      "Validation loss improved from 0.2571 to 0.2570. Saving model...\n",
      "LOG: Epoch [641/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4085\n",
      "LOG: Epoch [641/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4078\n",
      "    Batch [2/2], Val Loss: 0.1062\n",
      "Epoch [641/2000], Avg Train Loss: 0.4085, Avg Val Loss: 0.2570\n",
      "\n",
      "Validation loss improved from 0.2570 to 0.2570. Saving model...\n",
      "LOG: Epoch [642/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [642/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4078\n",
      "    Batch [2/2], Val Loss: 0.1061\n",
      "Epoch [642/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2570\n",
      "\n",
      "Validation loss improved from 0.2570 to 0.2570. Saving model...\n",
      "LOG: Epoch [643/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [643/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4077\n",
      "    Batch [2/2], Val Loss: 0.1061\n",
      "Epoch [643/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.2569\n",
      "\n",
      "Validation loss improved from 0.2570 to 0.2569. Saving model...\n",
      "LOG: Epoch [644/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4008\n",
      "LOG: Epoch [644/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4075\n",
      "    Batch [2/2], Val Loss: 0.1062\n",
      "Epoch [644/2000], Avg Train Loss: 0.4008, Avg Val Loss: 0.2569\n",
      "\n",
      "Validation loss improved from 0.2569 to 0.2569. Saving model...\n",
      "LOG: Epoch [645/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4085\n",
      "LOG: Epoch [645/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4074\n",
      "    Batch [2/2], Val Loss: 0.1061\n",
      "Epoch [645/2000], Avg Train Loss: 0.4085, Avg Val Loss: 0.2568\n",
      "\n",
      "Validation loss improved from 0.2569 to 0.2568. Saving model...\n",
      "LOG: Epoch [646/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4114\n",
      "LOG: Epoch [646/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4074\n",
      "    Batch [2/2], Val Loss: 0.1061\n",
      "Epoch [646/2000], Avg Train Loss: 0.4114, Avg Val Loss: 0.2567\n",
      "\n",
      "Validation loss improved from 0.2568 to 0.2567. Saving model...\n",
      "LOG: Epoch [647/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [647/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4073\n",
      "    Batch [2/2], Val Loss: 0.1061\n",
      "Epoch [647/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2567\n",
      "\n",
      "Validation loss improved from 0.2567 to 0.2567. Saving model...\n",
      "LOG: Epoch [648/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [648/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4072\n",
      "    Batch [2/2], Val Loss: 0.1061\n",
      "Epoch [648/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2567\n",
      "\n",
      "Validation loss improved from 0.2567 to 0.2567. Saving model...\n",
      "LOG: Epoch [649/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4003\n",
      "LOG: Epoch [649/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4072\n",
      "    Batch [2/2], Val Loss: 0.1061\n",
      "Epoch [649/2000], Avg Train Loss: 0.4003, Avg Val Loss: 0.2566\n",
      "\n",
      "Validation loss improved from 0.2567 to 0.2566. Saving model...\n",
      "LOG: Epoch [650/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [650/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4071\n",
      "    Batch [2/2], Val Loss: 0.1060\n",
      "Epoch [650/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2566\n",
      "\n",
      "Validation loss improved from 0.2566 to 0.2566. Saving model...\n",
      "LOG: Epoch [651/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4091\n",
      "LOG: Epoch [651/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4071\n",
      "    Batch [2/2], Val Loss: 0.1060\n",
      "Epoch [651/2000], Avg Train Loss: 0.4091, Avg Val Loss: 0.2565\n",
      "\n",
      "Validation loss improved from 0.2566 to 0.2565. Saving model...\n",
      "LOG: Epoch [652/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4060\n",
      "LOG: Epoch [652/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4070\n",
      "    Batch [2/2], Val Loss: 0.1060\n",
      "Epoch [652/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.2565\n",
      "\n",
      "Validation loss improved from 0.2565 to 0.2565. Saving model...\n",
      "LOG: Epoch [653/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4086\n",
      "LOG: Epoch [653/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4071\n",
      "    Batch [2/2], Val Loss: 0.1060\n",
      "Epoch [653/2000], Avg Train Loss: 0.4086, Avg Val Loss: 0.2565\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [654/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4081\n",
      "LOG: Epoch [654/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4070\n",
      "    Batch [2/2], Val Loss: 0.1059\n",
      "Epoch [654/2000], Avg Train Loss: 0.4081, Avg Val Loss: 0.2565\n",
      "\n",
      "Validation loss improved from 0.2565 to 0.2565. Saving model...\n",
      "LOG: Epoch [655/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4114\n",
      "LOG: Epoch [655/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4070\n",
      "    Batch [2/2], Val Loss: 0.1059\n",
      "Epoch [655/2000], Avg Train Loss: 0.4114, Avg Val Loss: 0.2564\n",
      "\n",
      "Validation loss improved from 0.2565 to 0.2564. Saving model...\n",
      "LOG: Epoch [656/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4038\n",
      "LOG: Epoch [656/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4070\n",
      "    Batch [2/2], Val Loss: 0.1058\n",
      "Epoch [656/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.2564\n",
      "\n",
      "Validation loss improved from 0.2564 to 0.2564. Saving model...\n",
      "LOG: Epoch [657/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [657/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4070\n",
      "    Batch [2/2], Val Loss: 0.1058\n",
      "Epoch [657/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2564\n",
      "\n",
      "Validation loss improved from 0.2564 to 0.2564. Saving model...\n",
      "LOG: Epoch [658/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4082\n",
      "LOG: Epoch [658/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4070\n",
      "    Batch [2/2], Val Loss: 0.1058\n",
      "Epoch [658/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2564\n",
      "\n",
      "Validation loss improved from 0.2564 to 0.2564. Saving model...\n",
      "LOG: Epoch [659/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4076\n",
      "LOG: Epoch [659/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4070\n",
      "    Batch [2/2], Val Loss: 0.1057\n",
      "Epoch [659/2000], Avg Train Loss: 0.4076, Avg Val Loss: 0.2564\n",
      "\n",
      "Validation loss improved from 0.2564 to 0.2564. Saving model...\n",
      "LOG: Epoch [660/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [660/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4070\n",
      "    Batch [2/2], Val Loss: 0.1057\n",
      "Epoch [660/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.2563\n",
      "\n",
      "Validation loss improved from 0.2564 to 0.2563. Saving model...\n",
      "LOG: Epoch [661/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4079\n",
      "LOG: Epoch [661/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4070\n",
      "    Batch [2/2], Val Loss: 0.1056\n",
      "Epoch [661/2000], Avg Train Loss: 0.4079, Avg Val Loss: 0.2563\n",
      "\n",
      "Validation loss improved from 0.2563 to 0.2563. Saving model...\n",
      "LOG: Epoch [662/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4057\n",
      "LOG: Epoch [662/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4069\n",
      "    Batch [2/2], Val Loss: 0.1055\n",
      "Epoch [662/2000], Avg Train Loss: 0.4057, Avg Val Loss: 0.2562\n",
      "\n",
      "Validation loss improved from 0.2563 to 0.2562. Saving model...\n",
      "LOG: Epoch [663/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [663/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4069\n",
      "    Batch [2/2], Val Loss: 0.1054\n",
      "Epoch [663/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2562\n",
      "\n",
      "Validation loss improved from 0.2562 to 0.2562. Saving model...\n",
      "LOG: Epoch [664/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [664/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4068\n",
      "    Batch [2/2], Val Loss: 0.1053\n",
      "Epoch [664/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2561\n",
      "\n",
      "Validation loss improved from 0.2562 to 0.2561. Saving model...\n",
      "LOG: Epoch [665/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [665/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4068\n",
      "    Batch [2/2], Val Loss: 0.1053\n",
      "Epoch [665/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2560\n",
      "\n",
      "Validation loss improved from 0.2561 to 0.2560. Saving model...\n",
      "LOG: Epoch [666/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3989\n",
      "LOG: Epoch [666/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4067\n",
      "    Batch [2/2], Val Loss: 0.1052\n",
      "Epoch [666/2000], Avg Train Loss: 0.3989, Avg Val Loss: 0.2559\n",
      "\n",
      "Validation loss improved from 0.2560 to 0.2559. Saving model...\n",
      "LOG: Epoch [667/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4082\n",
      "LOG: Epoch [667/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4066\n",
      "    Batch [2/2], Val Loss: 0.1051\n",
      "Epoch [667/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2558\n",
      "\n",
      "Validation loss improved from 0.2559 to 0.2558. Saving model...\n",
      "LOG: Epoch [668/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [668/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4065\n",
      "    Batch [2/2], Val Loss: 0.1050\n",
      "Epoch [668/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2558\n",
      "\n",
      "Validation loss improved from 0.2558 to 0.2558. Saving model...\n",
      "LOG: Epoch [669/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4132\n",
      "LOG: Epoch [669/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4065\n",
      "    Batch [2/2], Val Loss: 0.1049\n",
      "Epoch [669/2000], Avg Train Loss: 0.4132, Avg Val Loss: 0.2557\n",
      "\n",
      "Validation loss improved from 0.2558 to 0.2557. Saving model...\n",
      "LOG: Epoch [670/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4008\n",
      "LOG: Epoch [670/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1049\n",
      "Epoch [670/2000], Avg Train Loss: 0.4008, Avg Val Loss: 0.2557\n",
      "\n",
      "Validation loss improved from 0.2557 to 0.2557. Saving model...\n",
      "LOG: Epoch [671/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3968\n",
      "LOG: Epoch [671/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1048\n",
      "Epoch [671/2000], Avg Train Loss: 0.3968, Avg Val Loss: 0.2556\n",
      "\n",
      "Validation loss improved from 0.2557 to 0.2556. Saving model...\n",
      "LOG: Epoch [672/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [672/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4063\n",
      "    Batch [2/2], Val Loss: 0.1048\n",
      "Epoch [672/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2555\n",
      "\n",
      "Validation loss improved from 0.2556 to 0.2555. Saving model...\n",
      "LOG: Epoch [673/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4059\n",
      "LOG: Epoch [673/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4063\n",
      "    Batch [2/2], Val Loss: 0.1047\n",
      "Epoch [673/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2555\n",
      "\n",
      "Validation loss improved from 0.2555 to 0.2555. Saving model...\n",
      "LOG: Epoch [674/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4114\n",
      "LOG: Epoch [674/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4063\n",
      "    Batch [2/2], Val Loss: 0.1047\n",
      "Epoch [674/2000], Avg Train Loss: 0.4114, Avg Val Loss: 0.2555\n",
      "\n",
      "Validation loss improved from 0.2555 to 0.2555. Saving model...\n",
      "LOG: Epoch [675/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [675/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4063\n",
      "    Batch [2/2], Val Loss: 0.1046\n",
      "Epoch [675/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2555\n",
      "\n",
      "Validation loss improved from 0.2555 to 0.2555. Saving model...\n",
      "LOG: Epoch [676/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4060\n",
      "LOG: Epoch [676/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [676/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.2555\n",
      "\n",
      "Validation loss improved from 0.2555 to 0.2555. Saving model...\n",
      "LOG: Epoch [677/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4103\n",
      "LOG: Epoch [677/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [677/2000], Avg Train Loss: 0.4103, Avg Val Loss: 0.2554\n",
      "\n",
      "Validation loss improved from 0.2555 to 0.2554. Saving model...\n",
      "LOG: Epoch [678/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3999\n",
      "LOG: Epoch [678/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4063\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [678/2000], Avg Train Loss: 0.3999, Avg Val Loss: 0.2554\n",
      "\n",
      "Validation loss improved from 0.2554 to 0.2554. Saving model...\n",
      "LOG: Epoch [679/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4101\n",
      "LOG: Epoch [679/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4063\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [679/2000], Avg Train Loss: 0.4101, Avg Val Loss: 0.2554\n",
      "\n",
      "Validation loss improved from 0.2554 to 0.2554. Saving model...\n",
      "LOG: Epoch [680/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4101\n",
      "LOG: Epoch [680/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4063\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [680/2000], Avg Train Loss: 0.4101, Avg Val Loss: 0.2554\n",
      "\n",
      "Validation loss improved from 0.2554 to 0.2554. Saving model...\n",
      "LOG: Epoch [681/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4083\n",
      "LOG: Epoch [681/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4063\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [681/2000], Avg Train Loss: 0.4083, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [682/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [682/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4063\n",
      "    Batch [2/2], Val Loss: 0.1046\n",
      "Epoch [682/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [683/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [683/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4063\n",
      "    Batch [2/2], Val Loss: 0.1046\n",
      "Epoch [683/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [684/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4081\n",
      "LOG: Epoch [684/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4063\n",
      "    Batch [2/2], Val Loss: 0.1046\n",
      "Epoch [684/2000], Avg Train Loss: 0.4081, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [685/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [685/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4062\n",
      "    Batch [2/2], Val Loss: 0.1046\n",
      "Epoch [685/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [686/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [686/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4062\n",
      "    Batch [2/2], Val Loss: 0.1046\n",
      "Epoch [686/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [687/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4087\n",
      "LOG: Epoch [687/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4062\n",
      "    Batch [2/2], Val Loss: 0.1047\n",
      "Epoch [687/2000], Avg Train Loss: 0.4087, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [688/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4127\n",
      "LOG: Epoch [688/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4062\n",
      "    Batch [2/2], Val Loss: 0.1048\n",
      "Epoch [688/2000], Avg Train Loss: 0.4127, Avg Val Loss: 0.2555\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [689/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4070\n",
      "LOG: Epoch [689/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4063\n",
      "    Batch [2/2], Val Loss: 0.1048\n",
      "Epoch [689/2000], Avg Train Loss: 0.4070, Avg Val Loss: 0.2555\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [690/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4111\n",
      "LOG: Epoch [690/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4063\n",
      "    Batch [2/2], Val Loss: 0.1048\n",
      "Epoch [690/2000], Avg Train Loss: 0.4111, Avg Val Loss: 0.2556\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [691/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [691/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4063\n",
      "    Batch [2/2], Val Loss: 0.1049\n",
      "Epoch [691/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2556\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [692/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4114\n",
      "LOG: Epoch [692/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4063\n",
      "    Batch [2/2], Val Loss: 0.1049\n",
      "Epoch [692/2000], Avg Train Loss: 0.4114, Avg Val Loss: 0.2556\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [693/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4059\n",
      "LOG: Epoch [693/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1049\n",
      "Epoch [693/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2556\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [694/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [694/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1049\n",
      "Epoch [694/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2557\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [695/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4103\n",
      "LOG: Epoch [695/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1050\n",
      "Epoch [695/2000], Avg Train Loss: 0.4103, Avg Val Loss: 0.2557\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [696/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4108\n",
      "LOG: Epoch [696/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1050\n",
      "Epoch [696/2000], Avg Train Loss: 0.4108, Avg Val Loss: 0.2557\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [697/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [697/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1050\n",
      "Epoch [697/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2557\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [698/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [698/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1051\n",
      "Epoch [698/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.2557\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [699/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4080\n",
      "LOG: Epoch [699/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1051\n",
      "Epoch [699/2000], Avg Train Loss: 0.4080, Avg Val Loss: 0.2557\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [700/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [700/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1050\n",
      "Epoch [700/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2557\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [701/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4101\n",
      "LOG: Epoch [701/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1050\n",
      "Epoch [701/2000], Avg Train Loss: 0.4101, Avg Val Loss: 0.2557\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [702/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3990\n",
      "LOG: Epoch [702/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1050\n",
      "Epoch [702/2000], Avg Train Loss: 0.3990, Avg Val Loss: 0.2557\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [703/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4004\n",
      "LOG: Epoch [703/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1050\n",
      "Epoch [703/2000], Avg Train Loss: 0.4004, Avg Val Loss: 0.2557\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [704/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4062\n",
      "LOG: Epoch [704/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4064\n",
      "    Batch [2/2], Val Loss: 0.1050\n",
      "Epoch [704/2000], Avg Train Loss: 0.4062, Avg Val Loss: 0.2557\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [705/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4084\n",
      "LOG: Epoch [705/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4063\n",
      "    Batch [2/2], Val Loss: 0.1049\n",
      "Epoch [705/2000], Avg Train Loss: 0.4084, Avg Val Loss: 0.2556\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [706/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [706/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4062\n",
      "    Batch [2/2], Val Loss: 0.1049\n",
      "Epoch [706/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2556\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [707/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4059\n",
      "LOG: Epoch [707/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4062\n",
      "    Batch [2/2], Val Loss: 0.1048\n",
      "Epoch [707/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2555\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [708/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3988\n",
      "LOG: Epoch [708/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4062\n",
      "    Batch [2/2], Val Loss: 0.1048\n",
      "Epoch [708/2000], Avg Train Loss: 0.3988, Avg Val Loss: 0.2555\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [709/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4002\n",
      "LOG: Epoch [709/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4062\n",
      "    Batch [2/2], Val Loss: 0.1048\n",
      "Epoch [709/2000], Avg Train Loss: 0.4002, Avg Val Loss: 0.2555\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [710/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4102\n",
      "LOG: Epoch [710/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4062\n",
      "    Batch [2/2], Val Loss: 0.1047\n",
      "Epoch [710/2000], Avg Train Loss: 0.4102, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [711/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4071\n",
      "LOG: Epoch [711/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4062\n",
      "    Batch [2/2], Val Loss: 0.1047\n",
      "Epoch [711/2000], Avg Train Loss: 0.4071, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [712/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4101\n",
      "LOG: Epoch [712/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4061\n",
      "    Batch [2/2], Val Loss: 0.1047\n",
      "Epoch [712/2000], Avg Train Loss: 0.4101, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [713/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4088\n",
      "LOG: Epoch [713/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4061\n",
      "    Batch [2/2], Val Loss: 0.1047\n",
      "Epoch [713/2000], Avg Train Loss: 0.4088, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [714/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [714/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4061\n",
      "    Batch [2/2], Val Loss: 0.1046\n",
      "Epoch [714/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2554\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [715/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [715/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4061\n",
      "    Batch [2/2], Val Loss: 0.1046\n",
      "Epoch [715/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2554\n",
      "\n",
      "Validation loss improved from 0.2554 to 0.2554. Saving model...\n",
      "LOG: Epoch [716/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4084\n",
      "LOG: Epoch [716/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4061\n",
      "    Batch [2/2], Val Loss: 0.1046\n",
      "Epoch [716/2000], Avg Train Loss: 0.4084, Avg Val Loss: 0.2553\n",
      "\n",
      "Validation loss improved from 0.2554 to 0.2553. Saving model...\n",
      "LOG: Epoch [717/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [717/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4061\n",
      "    Batch [2/2], Val Loss: 0.1046\n",
      "Epoch [717/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2553\n",
      "\n",
      "Validation loss improved from 0.2553 to 0.2553. Saving model...\n",
      "LOG: Epoch [718/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4048\n",
      "LOG: Epoch [718/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4061\n",
      "    Batch [2/2], Val Loss: 0.1046\n",
      "Epoch [718/2000], Avg Train Loss: 0.4048, Avg Val Loss: 0.2553\n",
      "\n",
      "Validation loss improved from 0.2553 to 0.2553. Saving model...\n",
      "LOG: Epoch [719/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [719/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4060\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [719/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2553\n",
      "\n",
      "Validation loss improved from 0.2553 to 0.2553. Saving model...\n",
      "LOG: Epoch [720/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4083\n",
      "LOG: Epoch [720/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4060\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [720/2000], Avg Train Loss: 0.4083, Avg Val Loss: 0.2553\n",
      "\n",
      "Validation loss improved from 0.2553 to 0.2553. Saving model...\n",
      "LOG: Epoch [721/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [721/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4060\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [721/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2553\n",
      "\n",
      "Validation loss improved from 0.2553 to 0.2553. Saving model...\n",
      "LOG: Epoch [722/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [722/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4060\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [722/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2553\n",
      "\n",
      "Validation loss improved from 0.2553 to 0.2553. Saving model...\n",
      "LOG: Epoch [723/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4115\n",
      "LOG: Epoch [723/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4060\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [723/2000], Avg Train Loss: 0.4115, Avg Val Loss: 0.2553\n",
      "\n",
      "Validation loss improved from 0.2553 to 0.2553. Saving model...\n",
      "LOG: Epoch [724/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4037\n",
      "LOG: Epoch [724/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4060\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [724/2000], Avg Train Loss: 0.4037, Avg Val Loss: 0.2553\n",
      "\n",
      "Validation loss improved from 0.2553 to 0.2553. Saving model...\n",
      "LOG: Epoch [725/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [725/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4060\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [725/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2553\n",
      "\n",
      "Validation loss improved from 0.2553 to 0.2553. Saving model...\n",
      "LOG: Epoch [726/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [726/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4060\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [726/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2552\n",
      "\n",
      "Validation loss improved from 0.2553 to 0.2552. Saving model...\n",
      "LOG: Epoch [727/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [727/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4060\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [727/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2552\n",
      "\n",
      "Validation loss improved from 0.2552 to 0.2552. Saving model...\n",
      "LOG: Epoch [728/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4116\n",
      "LOG: Epoch [728/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4060\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [728/2000], Avg Train Loss: 0.4116, Avg Val Loss: 0.2552\n",
      "\n",
      "Validation loss improved from 0.2552 to 0.2552. Saving model...\n",
      "LOG: Epoch [729/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [729/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4060\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [729/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2552\n",
      "\n",
      "Validation loss improved from 0.2552 to 0.2552. Saving model...\n",
      "LOG: Epoch [730/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4097\n",
      "LOG: Epoch [730/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4060\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [730/2000], Avg Train Loss: 0.4097, Avg Val Loss: 0.2552\n",
      "\n",
      "Validation loss improved from 0.2552 to 0.2552. Saving model...\n",
      "LOG: Epoch [731/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [731/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4060\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [731/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2552\n",
      "\n",
      "Validation loss improved from 0.2552 to 0.2552. Saving model...\n",
      "LOG: Epoch [732/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4000\n",
      "LOG: Epoch [732/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1045\n",
      "Epoch [732/2000], Avg Train Loss: 0.4000, Avg Val Loss: 0.2552\n",
      "\n",
      "Validation loss improved from 0.2552 to 0.2552. Saving model...\n",
      "LOG: Epoch [733/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4085\n",
      "LOG: Epoch [733/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [733/2000], Avg Train Loss: 0.4085, Avg Val Loss: 0.2552\n",
      "\n",
      "Validation loss improved from 0.2552 to 0.2552. Saving model...\n",
      "LOG: Epoch [734/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4084\n",
      "LOG: Epoch [734/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [734/2000], Avg Train Loss: 0.4084, Avg Val Loss: 0.2552\n",
      "\n",
      "Validation loss improved from 0.2552 to 0.2552. Saving model...\n",
      "LOG: Epoch [735/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4007\n",
      "LOG: Epoch [735/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [735/2000], Avg Train Loss: 0.4007, Avg Val Loss: 0.2552\n",
      "\n",
      "Validation loss improved from 0.2552 to 0.2552. Saving model...\n",
      "LOG: Epoch [736/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4012\n",
      "LOG: Epoch [736/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [736/2000], Avg Train Loss: 0.4012, Avg Val Loss: 0.2552\n",
      "\n",
      "Validation loss improved from 0.2552 to 0.2552. Saving model...\n",
      "LOG: Epoch [737/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4118\n",
      "LOG: Epoch [737/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [737/2000], Avg Train Loss: 0.4118, Avg Val Loss: 0.2552\n",
      "\n",
      "Validation loss improved from 0.2552 to 0.2552. Saving model...\n",
      "LOG: Epoch [738/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [738/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [738/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2552 to 0.2551. Saving model...\n",
      "LOG: Epoch [739/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4056\n",
      "LOG: Epoch [739/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [739/2000], Avg Train Loss: 0.4056, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [740/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [740/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [740/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [741/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4082\n",
      "LOG: Epoch [741/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [741/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [742/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [742/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [742/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [743/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [743/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [743/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [744/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [744/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [744/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [745/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4078\n",
      "LOG: Epoch [745/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [745/2000], Avg Train Loss: 0.4078, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [746/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4129\n",
      "LOG: Epoch [746/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [746/2000], Avg Train Loss: 0.4129, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [747/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [747/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [747/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [748/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [748/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1044\n",
      "Epoch [748/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [749/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [749/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [749/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [750/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4094\n",
      "LOG: Epoch [750/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [750/2000], Avg Train Loss: 0.4094, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [751/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4060\n",
      "LOG: Epoch [751/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [751/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [752/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4064\n",
      "LOG: Epoch [752/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [752/2000], Avg Train Loss: 0.4064, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [753/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [753/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [753/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [754/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [754/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [754/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [755/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [755/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [755/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [756/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4003\n",
      "LOG: Epoch [756/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [756/2000], Avg Train Loss: 0.4003, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [757/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [757/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [757/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [758/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4056\n",
      "LOG: Epoch [758/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [758/2000], Avg Train Loss: 0.4056, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [759/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4056\n",
      "LOG: Epoch [759/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [759/2000], Avg Train Loss: 0.4056, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [760/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3968\n",
      "LOG: Epoch [760/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [760/2000], Avg Train Loss: 0.3968, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [761/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4006\n",
      "LOG: Epoch [761/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [761/2000], Avg Train Loss: 0.4006, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [762/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [762/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [762/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [763/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [763/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [763/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [764/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4077\n",
      "LOG: Epoch [764/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [764/2000], Avg Train Loss: 0.4077, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [765/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4054\n",
      "LOG: Epoch [765/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [765/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [766/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4059\n",
      "LOG: Epoch [766/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [766/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [767/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [767/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [767/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [768/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [768/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [768/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [769/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [769/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [769/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [770/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4095\n",
      "LOG: Epoch [770/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [770/2000], Avg Train Loss: 0.4095, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [771/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4057\n",
      "LOG: Epoch [771/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [771/2000], Avg Train Loss: 0.4057, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [772/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4049\n",
      "LOG: Epoch [772/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [772/2000], Avg Train Loss: 0.4049, Avg Val Loss: 0.2551\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2551. Saving model...\n",
      "LOG: Epoch [773/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [773/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [773/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [774/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3983\n",
      "LOG: Epoch [774/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [774/2000], Avg Train Loss: 0.3983, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [775/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [775/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [775/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [776/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [776/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [776/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [777/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4008\n",
      "LOG: Epoch [777/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [777/2000], Avg Train Loss: 0.4008, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [778/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4000\n",
      "LOG: Epoch [778/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [778/2000], Avg Train Loss: 0.4000, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2551 to 0.2550. Saving model...\n",
      "LOG: Epoch [779/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4056\n",
      "LOG: Epoch [779/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [779/2000], Avg Train Loss: 0.4056, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [780/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [780/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [780/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [781/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [781/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [781/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [782/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4054\n",
      "LOG: Epoch [782/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [782/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [783/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4088\n",
      "LOG: Epoch [783/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [783/2000], Avg Train Loss: 0.4088, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [784/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [784/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [784/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2551\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [785/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [785/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [785/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [786/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4090\n",
      "LOG: Epoch [786/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [786/2000], Avg Train Loss: 0.4090, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [787/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [787/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4059\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [787/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [788/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4010\n",
      "LOG: Epoch [788/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [788/2000], Avg Train Loss: 0.4010, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [789/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3984\n",
      "LOG: Epoch [789/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [789/2000], Avg Train Loss: 0.3984, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [790/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [790/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [790/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [791/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4104\n",
      "LOG: Epoch [791/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [791/2000], Avg Train Loss: 0.4104, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [792/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [792/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [792/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [793/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [793/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [793/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [794/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4006\n",
      "LOG: Epoch [794/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [794/2000], Avg Train Loss: 0.4006, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [795/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4008\n",
      "LOG: Epoch [795/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [795/2000], Avg Train Loss: 0.4008, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [796/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4044\n",
      "LOG: Epoch [796/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [796/2000], Avg Train Loss: 0.4044, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [797/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [797/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [797/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [798/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [798/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [798/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [799/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [799/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [799/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [800/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [800/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [800/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [801/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3985\n",
      "LOG: Epoch [801/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [801/2000], Avg Train Loss: 0.3985, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [802/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [802/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [802/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [803/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4105\n",
      "LOG: Epoch [803/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [803/2000], Avg Train Loss: 0.4105, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [804/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [804/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4058\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [804/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [805/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [805/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [805/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [806/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4057\n",
      "LOG: Epoch [806/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [806/2000], Avg Train Loss: 0.4057, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [807/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [807/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [807/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [808/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [808/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [808/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [809/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [809/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [809/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [810/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4109\n",
      "LOG: Epoch [810/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [810/2000], Avg Train Loss: 0.4109, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [811/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [811/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [811/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [812/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3993\n",
      "LOG: Epoch [812/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [812/2000], Avg Train Loss: 0.3993, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [813/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4060\n",
      "LOG: Epoch [813/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1043\n",
      "Epoch [813/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [814/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3976\n",
      "LOG: Epoch [814/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [814/2000], Avg Train Loss: 0.3976, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [815/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4126\n",
      "LOG: Epoch [815/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [815/2000], Avg Train Loss: 0.4126, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [816/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [816/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [816/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [817/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3989\n",
      "LOG: Epoch [817/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [817/2000], Avg Train Loss: 0.3989, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [818/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [818/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [818/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [819/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [819/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [819/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [820/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4064\n",
      "LOG: Epoch [820/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [820/2000], Avg Train Loss: 0.4064, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [821/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4092\n",
      "LOG: Epoch [821/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [821/2000], Avg Train Loss: 0.4092, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [822/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4090\n",
      "LOG: Epoch [822/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [822/2000], Avg Train Loss: 0.4090, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [823/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3952\n",
      "LOG: Epoch [823/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [823/2000], Avg Train Loss: 0.3952, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [824/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4062\n",
      "LOG: Epoch [824/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [824/2000], Avg Train Loss: 0.4062, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [825/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [825/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [825/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2550\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [826/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4125\n",
      "LOG: Epoch [826/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [826/2000], Avg Train Loss: 0.4125, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [827/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [827/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [827/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [828/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4020\n",
      "LOG: Epoch [828/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [828/2000], Avg Train Loss: 0.4020, Avg Val Loss: 0.2550\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2550. Saving model...\n",
      "LOG: Epoch [829/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [829/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [829/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2550 to 0.2549. Saving model...\n",
      "LOG: Epoch [830/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [830/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [830/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2549. Saving model...\n",
      "LOG: Epoch [831/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4089\n",
      "LOG: Epoch [831/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [831/2000], Avg Train Loss: 0.4089, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2549. Saving model...\n",
      "LOG: Epoch [832/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4038\n",
      "LOG: Epoch [832/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [832/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2549. Saving model...\n",
      "LOG: Epoch [833/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [833/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [833/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2549. Saving model...\n",
      "LOG: Epoch [834/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [834/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4057\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [834/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2549. Saving model...\n",
      "LOG: Epoch [835/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [835/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [835/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2549. Saving model...\n",
      "LOG: Epoch [836/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3988\n",
      "LOG: Epoch [836/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1042\n",
      "Epoch [836/2000], Avg Train Loss: 0.3988, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2549. Saving model...\n",
      "LOG: Epoch [837/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4076\n",
      "LOG: Epoch [837/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [837/2000], Avg Train Loss: 0.4076, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2549. Saving model...\n",
      "LOG: Epoch [838/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [838/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [838/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2549. Saving model...\n",
      "LOG: Epoch [839/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4105\n",
      "LOG: Epoch [839/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [839/2000], Avg Train Loss: 0.4105, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2549. Saving model...\n",
      "LOG: Epoch [840/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [840/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [840/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2549. Saving model...\n",
      "LOG: Epoch [841/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4089\n",
      "LOG: Epoch [841/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [841/2000], Avg Train Loss: 0.4089, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2549. Saving model...\n",
      "LOG: Epoch [842/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [842/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [842/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2549\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2549. Saving model...\n",
      "LOG: Epoch [843/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [843/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [843/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2549 to 0.2548. Saving model...\n",
      "LOG: Epoch [844/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4074\n",
      "LOG: Epoch [844/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [844/2000], Avg Train Loss: 0.4074, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [845/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [845/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [845/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [846/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4010\n",
      "LOG: Epoch [846/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [846/2000], Avg Train Loss: 0.4010, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [847/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4048\n",
      "LOG: Epoch [847/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [847/2000], Avg Train Loss: 0.4048, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [848/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [848/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [848/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [849/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4037\n",
      "LOG: Epoch [849/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [849/2000], Avg Train Loss: 0.4037, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [850/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4048\n",
      "LOG: Epoch [850/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [850/2000], Avg Train Loss: 0.4048, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [851/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4071\n",
      "LOG: Epoch [851/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [851/2000], Avg Train Loss: 0.4071, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [852/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3981\n",
      "LOG: Epoch [852/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [852/2000], Avg Train Loss: 0.3981, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [853/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4075\n",
      "LOG: Epoch [853/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1041\n",
      "Epoch [853/2000], Avg Train Loss: 0.4075, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [854/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [854/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [854/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [855/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [855/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [855/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [856/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [856/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [856/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [857/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3981\n",
      "LOG: Epoch [857/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [857/2000], Avg Train Loss: 0.3981, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [858/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3976\n",
      "LOG: Epoch [858/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [858/2000], Avg Train Loss: 0.3976, Avg Val Loss: 0.2548\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [859/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [859/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [859/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [860/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [860/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [860/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [861/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [861/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [861/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [862/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3976\n",
      "LOG: Epoch [862/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [862/2000], Avg Train Loss: 0.3976, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [863/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [863/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [863/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [864/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4064\n",
      "LOG: Epoch [864/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [864/2000], Avg Train Loss: 0.4064, Avg Val Loss: 0.2548\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [865/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [865/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [865/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [866/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4038\n",
      "LOG: Epoch [866/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [866/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [867/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [867/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [867/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [868/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [868/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [868/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2548\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [869/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4048\n",
      "LOG: Epoch [869/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [869/2000], Avg Train Loss: 0.4048, Avg Val Loss: 0.2548\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [870/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [870/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [870/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [871/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4001\n",
      "LOG: Epoch [871/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [871/2000], Avg Train Loss: 0.4001, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [872/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [872/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [872/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [873/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [873/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [873/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2548\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [874/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4074\n",
      "LOG: Epoch [874/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [874/2000], Avg Train Loss: 0.4074, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [875/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [875/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4056\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [875/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [876/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4083\n",
      "LOG: Epoch [876/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4055\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [876/2000], Avg Train Loss: 0.4083, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [877/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [877/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4055\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [877/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2548\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2548. Saving model...\n",
      "LOG: Epoch [878/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4070\n",
      "LOG: Epoch [878/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4055\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [878/2000], Avg Train Loss: 0.4070, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2548 to 0.2547. Saving model...\n",
      "LOG: Epoch [879/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4010\n",
      "LOG: Epoch [879/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4055\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [879/2000], Avg Train Loss: 0.4010, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [880/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [880/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4055\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [880/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [881/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [881/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4055\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [881/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [882/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [882/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4055\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [882/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [883/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4049\n",
      "LOG: Epoch [883/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4055\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [883/2000], Avg Train Loss: 0.4049, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [884/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3996\n",
      "LOG: Epoch [884/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4055\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [884/2000], Avg Train Loss: 0.3996, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [885/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [885/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4055\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [885/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [886/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [886/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4055\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [886/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [887/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3999\n",
      "LOG: Epoch [887/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4055\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [887/2000], Avg Train Loss: 0.3999, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [888/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [888/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [888/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [889/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [889/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [889/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [890/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4090\n",
      "LOG: Epoch [890/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [890/2000], Avg Train Loss: 0.4090, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [891/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3981\n",
      "LOG: Epoch [891/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [891/2000], Avg Train Loss: 0.3981, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [892/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4079\n",
      "LOG: Epoch [892/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [892/2000], Avg Train Loss: 0.4079, Avg Val Loss: 0.2547\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [893/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4062\n",
      "LOG: Epoch [893/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [893/2000], Avg Train Loss: 0.4062, Avg Val Loss: 0.2547\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [894/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4070\n",
      "LOG: Epoch [894/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [894/2000], Avg Train Loss: 0.4070, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [895/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [895/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [895/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [896/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [896/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [896/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [897/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [897/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [897/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [898/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [898/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [898/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [899/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4100\n",
      "LOG: Epoch [899/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [899/2000], Avg Train Loss: 0.4100, Avg Val Loss: 0.2547\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [900/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3991\n",
      "LOG: Epoch [900/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [900/2000], Avg Train Loss: 0.3991, Avg Val Loss: 0.2547\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [901/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [901/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [901/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2547\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [902/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3996\n",
      "LOG: Epoch [902/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [902/2000], Avg Train Loss: 0.3996, Avg Val Loss: 0.2547\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [903/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4010\n",
      "LOG: Epoch [903/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [903/2000], Avg Train Loss: 0.4010, Avg Val Loss: 0.2547\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [904/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [904/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1040\n",
      "Epoch [904/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2547\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [905/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4059\n",
      "LOG: Epoch [905/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [905/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2547\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [906/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4044\n",
      "LOG: Epoch [906/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [906/2000], Avg Train Loss: 0.4044, Avg Val Loss: 0.2547\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [907/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [907/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [907/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2547\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [908/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4084\n",
      "LOG: Epoch [908/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [908/2000], Avg Train Loss: 0.4084, Avg Val Loss: 0.2547\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [909/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4106\n",
      "LOG: Epoch [909/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [909/2000], Avg Train Loss: 0.4106, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [910/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4058\n",
      "LOG: Epoch [910/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [910/2000], Avg Train Loss: 0.4058, Avg Val Loss: 0.2547\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2547. Saving model...\n",
      "LOG: Epoch [911/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [911/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [911/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2547 to 0.2546. Saving model...\n",
      "LOG: Epoch [912/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4005\n",
      "LOG: Epoch [912/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [912/2000], Avg Train Loss: 0.4005, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [913/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [913/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [913/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [914/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4077\n",
      "LOG: Epoch [914/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [914/2000], Avg Train Loss: 0.4077, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [915/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [915/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [915/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [916/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [916/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [916/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [917/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [917/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [917/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [918/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [918/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [918/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [919/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4089\n",
      "LOG: Epoch [919/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1039\n",
      "Epoch [919/2000], Avg Train Loss: 0.4089, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [920/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [920/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1038\n",
      "Epoch [920/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [921/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [921/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1038\n",
      "Epoch [921/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [922/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4057\n",
      "LOG: Epoch [922/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1038\n",
      "Epoch [922/2000], Avg Train Loss: 0.4057, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [923/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [923/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1038\n",
      "Epoch [923/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [924/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [924/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1038\n",
      "Epoch [924/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [925/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4007\n",
      "LOG: Epoch [925/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1038\n",
      "Epoch [925/2000], Avg Train Loss: 0.4007, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [926/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4083\n",
      "LOG: Epoch [926/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1038\n",
      "Epoch [926/2000], Avg Train Loss: 0.4083, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [927/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [927/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1038\n",
      "Epoch [927/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [928/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [928/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1038\n",
      "Epoch [928/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [929/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [929/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1038\n",
      "Epoch [929/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [930/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4049\n",
      "LOG: Epoch [930/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1038\n",
      "Epoch [930/2000], Avg Train Loss: 0.4049, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [931/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4084\n",
      "LOG: Epoch [931/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4054\n",
      "    Batch [2/2], Val Loss: 0.1038\n",
      "Epoch [931/2000], Avg Train Loss: 0.4084, Avg Val Loss: 0.2546\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2546. Saving model...\n",
      "LOG: Epoch [932/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [932/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1038\n",
      "Epoch [932/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2546 to 0.2545. Saving model...\n",
      "LOG: Epoch [933/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4060\n",
      "LOG: Epoch [933/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [933/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [934/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [934/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [934/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [935/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [935/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [935/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [936/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3998\n",
      "LOG: Epoch [936/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [936/2000], Avg Train Loss: 0.3998, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [937/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4070\n",
      "LOG: Epoch [937/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [937/2000], Avg Train Loss: 0.4070, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [938/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3986\n",
      "LOG: Epoch [938/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [938/2000], Avg Train Loss: 0.3986, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [939/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3988\n",
      "LOG: Epoch [939/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [939/2000], Avg Train Loss: 0.3988, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [940/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [940/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [940/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [941/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [941/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [941/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [942/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [942/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [942/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [943/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3966\n",
      "LOG: Epoch [943/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [943/2000], Avg Train Loss: 0.3966, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [944/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4140\n",
      "LOG: Epoch [944/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [944/2000], Avg Train Loss: 0.4140, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [945/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [945/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [945/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [946/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [946/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [946/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2545\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [947/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [947/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [947/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2545\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [948/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [948/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [948/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2545\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [949/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [949/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [949/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2545\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [950/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [950/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [950/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2545\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [951/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [951/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1037\n",
      "Epoch [951/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [952/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4076\n",
      "LOG: Epoch [952/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [952/2000], Avg Train Loss: 0.4076, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [953/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4005\n",
      "LOG: Epoch [953/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [953/2000], Avg Train Loss: 0.4005, Avg Val Loss: 0.2545\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2545. Saving model...\n",
      "LOG: Epoch [954/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [954/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [954/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2545\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [955/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4108\n",
      "LOG: Epoch [955/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [955/2000], Avg Train Loss: 0.4108, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2545 to 0.2544. Saving model...\n",
      "LOG: Epoch [956/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4054\n",
      "LOG: Epoch [956/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [956/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [957/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4008\n",
      "LOG: Epoch [957/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4053\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [957/2000], Avg Train Loss: 0.4008, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [958/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [958/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [958/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [959/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4010\n",
      "LOG: Epoch [959/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [959/2000], Avg Train Loss: 0.4010, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [960/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4037\n",
      "LOG: Epoch [960/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [960/2000], Avg Train Loss: 0.4037, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [961/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4038\n",
      "LOG: Epoch [961/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [961/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [962/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3939\n",
      "LOG: Epoch [962/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [962/2000], Avg Train Loss: 0.3939, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [963/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3991\n",
      "LOG: Epoch [963/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [963/2000], Avg Train Loss: 0.3991, Avg Val Loss: 0.2544\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [964/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [964/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [964/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [965/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [965/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [965/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2544\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [966/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4057\n",
      "LOG: Epoch [966/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [966/2000], Avg Train Loss: 0.4057, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [967/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4004\n",
      "LOG: Epoch [967/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [967/2000], Avg Train Loss: 0.4004, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [968/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4037\n",
      "LOG: Epoch [968/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [968/2000], Avg Train Loss: 0.4037, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [969/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [969/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [969/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [970/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [970/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [970/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [971/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4083\n",
      "LOG: Epoch [971/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [971/2000], Avg Train Loss: 0.4083, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [972/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [972/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [972/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [973/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4008\n",
      "LOG: Epoch [973/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [973/2000], Avg Train Loss: 0.4008, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [974/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [974/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [974/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [975/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [975/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [975/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [976/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3972\n",
      "LOG: Epoch [976/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [976/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [977/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4012\n",
      "LOG: Epoch [977/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [977/2000], Avg Train Loss: 0.4012, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [978/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [978/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [978/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [979/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [979/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [979/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [980/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4081\n",
      "LOG: Epoch [980/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [980/2000], Avg Train Loss: 0.4081, Avg Val Loss: 0.2544\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [981/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3964\n",
      "LOG: Epoch [981/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [981/2000], Avg Train Loss: 0.3964, Avg Val Loss: 0.2544\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [982/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4062\n",
      "LOG: Epoch [982/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [982/2000], Avg Train Loss: 0.4062, Avg Val Loss: 0.2544\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [983/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3976\n",
      "LOG: Epoch [983/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [983/2000], Avg Train Loss: 0.3976, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [984/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4064\n",
      "LOG: Epoch [984/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [984/2000], Avg Train Loss: 0.4064, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [985/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4062\n",
      "LOG: Epoch [985/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [985/2000], Avg Train Loss: 0.4062, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [986/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4079\n",
      "LOG: Epoch [986/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [986/2000], Avg Train Loss: 0.4079, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [987/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [987/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [987/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [988/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [988/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [988/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [989/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4059\n",
      "LOG: Epoch [989/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1036\n",
      "Epoch [989/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2544\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [990/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4002\n",
      "LOG: Epoch [990/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [990/2000], Avg Train Loss: 0.4002, Avg Val Loss: 0.2544\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [991/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [991/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [991/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [992/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4121\n",
      "LOG: Epoch [992/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [992/2000], Avg Train Loss: 0.4121, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [993/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [993/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [993/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [994/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4133\n",
      "LOG: Epoch [994/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [994/2000], Avg Train Loss: 0.4133, Avg Val Loss: 0.2544\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2544. Saving model...\n",
      "LOG: Epoch [995/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4110\n",
      "LOG: Epoch [995/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [995/2000], Avg Train Loss: 0.4110, Avg Val Loss: 0.2544\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [996/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [996/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [996/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2544\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [997/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4059\n",
      "LOG: Epoch [997/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [997/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2544\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [998/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4128\n",
      "LOG: Epoch [998/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [998/2000], Avg Train Loss: 0.4128, Avg Val Loss: 0.2544\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [999/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [999/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [999/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2544\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1000/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [1000/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1000/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2544 to 0.2543. Saving model...\n",
      "LOG: Epoch [1001/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [1001/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1001/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1002/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [1002/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1002/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1003/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [1003/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1003/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1004/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3983\n",
      "LOG: Epoch [1004/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1004/2000], Avg Train Loss: 0.3983, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1005/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3924\n",
      "LOG: Epoch [1005/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1005/2000], Avg Train Loss: 0.3924, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1006/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [1006/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4052\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1006/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1007/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [1007/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1007/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1008/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [1008/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1008/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1009/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4038\n",
      "LOG: Epoch [1009/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1009/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1010/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [1010/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1010/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1011/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [1011/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1011/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1012/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3969\n",
      "LOG: Epoch [1012/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1012/2000], Avg Train Loss: 0.3969, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1013/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [1013/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1013/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1014/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [1014/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4051\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1014/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1015/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [1015/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1015/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1016/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4006\n",
      "LOG: Epoch [1016/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1016/2000], Avg Train Loss: 0.4006, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1017/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4075\n",
      "LOG: Epoch [1017/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1017/2000], Avg Train Loss: 0.4075, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1018/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [1018/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1018/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1019/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [1019/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1019/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1020/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [1020/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1020/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1021/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [1021/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1021/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2543\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2543. Saving model...\n",
      "LOG: Epoch [1022/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [1022/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1022/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2543 to 0.2542. Saving model...\n",
      "LOG: Epoch [1023/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [1023/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1023/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1024/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4075\n",
      "LOG: Epoch [1024/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1024/2000], Avg Train Loss: 0.4075, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1025/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [1025/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1025/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1026/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [1026/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1026/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1027/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [1027/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1027/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1028/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3990\n",
      "LOG: Epoch [1028/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1028/2000], Avg Train Loss: 0.3990, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1029/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [1029/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1029/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1030/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4089\n",
      "LOG: Epoch [1030/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1035\n",
      "Epoch [1030/2000], Avg Train Loss: 0.4089, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1031/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [1031/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1031/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1032/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4048\n",
      "LOG: Epoch [1032/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1032/2000], Avg Train Loss: 0.4048, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1033/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [1033/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1033/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1034/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [1034/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1034/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1035/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3968\n",
      "LOG: Epoch [1035/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1035/2000], Avg Train Loss: 0.3968, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1036/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [1036/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1036/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1037/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4094\n",
      "LOG: Epoch [1037/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1037/2000], Avg Train Loss: 0.4094, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1038/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [1038/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1038/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1039/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [1039/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1039/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1040/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3944\n",
      "LOG: Epoch [1040/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1040/2000], Avg Train Loss: 0.3944, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1041/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3987\n",
      "LOG: Epoch [1041/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1041/2000], Avg Train Loss: 0.3987, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1042/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [1042/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1042/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1043/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4000\n",
      "LOG: Epoch [1043/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1043/2000], Avg Train Loss: 0.4000, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1044/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [1044/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1044/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1045/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4054\n",
      "LOG: Epoch [1045/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1045/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1046/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [1046/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1046/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1047/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4086\n",
      "LOG: Epoch [1047/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1047/2000], Avg Train Loss: 0.4086, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1048/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [1048/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1048/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1049/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3984\n",
      "LOG: Epoch [1049/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1049/2000], Avg Train Loss: 0.3984, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1050/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [1050/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1050/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1051/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3983\n",
      "LOG: Epoch [1051/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1051/2000], Avg Train Loss: 0.3983, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1052/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [1052/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1052/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1053/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [1053/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1053/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1054/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [1054/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1054/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1055/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [1055/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1055/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1056/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [1056/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1056/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1057/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [1057/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1034\n",
      "Epoch [1057/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2542\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1058/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4100\n",
      "LOG: Epoch [1058/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1058/2000], Avg Train Loss: 0.4100, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1059/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4020\n",
      "LOG: Epoch [1059/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1059/2000], Avg Train Loss: 0.4020, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1060/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1060/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1060/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1061/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [1061/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1061/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2542\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2542. Saving model...\n",
      "LOG: Epoch [1062/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4013\n",
      "LOG: Epoch [1062/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1062/2000], Avg Train Loss: 0.4013, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2542 to 0.2541. Saving model...\n",
      "LOG: Epoch [1063/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4004\n",
      "LOG: Epoch [1063/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4050\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1063/2000], Avg Train Loss: 0.4004, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1064/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [1064/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1064/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1065/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [1065/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1065/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1066/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3991\n",
      "LOG: Epoch [1066/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1066/2000], Avg Train Loss: 0.3991, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1067/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [1067/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1067/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1068/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [1068/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1068/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1069/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [1069/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1069/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1070/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [1070/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1070/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1071/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4071\n",
      "LOG: Epoch [1071/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1071/2000], Avg Train Loss: 0.4071, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1072/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3961\n",
      "LOG: Epoch [1072/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1072/2000], Avg Train Loss: 0.3961, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1073/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3983\n",
      "LOG: Epoch [1073/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1073/2000], Avg Train Loss: 0.3983, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1074/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [1074/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1074/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1075/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4085\n",
      "LOG: Epoch [1075/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1075/2000], Avg Train Loss: 0.4085, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1076/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3982\n",
      "LOG: Epoch [1076/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1076/2000], Avg Train Loss: 0.3982, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1077/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [1077/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1077/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1078/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [1078/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1078/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1079/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [1079/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1079/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1080/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [1080/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1080/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1081/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [1081/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1081/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1082/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [1082/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1082/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2541\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2541. Saving model...\n",
      "LOG: Epoch [1083/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [1083/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1083/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2541 to 0.2540. Saving model...\n",
      "LOG: Epoch [1084/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [1084/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1084/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1085/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3956\n",
      "LOG: Epoch [1085/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1085/2000], Avg Train Loss: 0.3956, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1086/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [1086/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1086/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1087/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4087\n",
      "LOG: Epoch [1087/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1087/2000], Avg Train Loss: 0.4087, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1088/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4084\n",
      "LOG: Epoch [1088/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1088/2000], Avg Train Loss: 0.4084, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1089/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3993\n",
      "LOG: Epoch [1089/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1089/2000], Avg Train Loss: 0.3993, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1090/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4090\n",
      "LOG: Epoch [1090/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1090/2000], Avg Train Loss: 0.4090, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1091/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3952\n",
      "LOG: Epoch [1091/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1091/2000], Avg Train Loss: 0.3952, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1092/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3968\n",
      "LOG: Epoch [1092/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1092/2000], Avg Train Loss: 0.3968, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1093/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4077\n",
      "LOG: Epoch [1093/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1093/2000], Avg Train Loss: 0.4077, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1094/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4071\n",
      "LOG: Epoch [1094/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1094/2000], Avg Train Loss: 0.4071, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1095/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4054\n",
      "LOG: Epoch [1095/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1095/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1096/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1096/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1096/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1097/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [1097/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1097/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1098/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4083\n",
      "LOG: Epoch [1098/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1098/2000], Avg Train Loss: 0.4083, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1099/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [1099/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4049\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1099/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1100/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4078\n",
      "LOG: Epoch [1100/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1100/2000], Avg Train Loss: 0.4078, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1101/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3982\n",
      "LOG: Epoch [1101/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1101/2000], Avg Train Loss: 0.3982, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1102/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4060\n",
      "LOG: Epoch [1102/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1102/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1103/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [1103/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1103/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1104/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4084\n",
      "LOG: Epoch [1104/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1104/2000], Avg Train Loss: 0.4084, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1105/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [1105/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1105/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1106/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4077\n",
      "LOG: Epoch [1106/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1106/2000], Avg Train Loss: 0.4077, Avg Val Loss: 0.2541\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1107/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3993\n",
      "LOG: Epoch [1107/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1033\n",
      "Epoch [1107/2000], Avg Train Loss: 0.3993, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1108/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4079\n",
      "LOG: Epoch [1108/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1108/2000], Avg Train Loss: 0.4079, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1109/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [1109/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1109/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1110/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3999\n",
      "LOG: Epoch [1110/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1110/2000], Avg Train Loss: 0.3999, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1111/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [1111/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1111/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1112/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [1112/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1112/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1113/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [1113/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1113/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1114/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [1114/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1114/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1115/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3981\n",
      "LOG: Epoch [1115/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1115/2000], Avg Train Loss: 0.3981, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1116/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [1116/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1116/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1117/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [1117/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1117/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1118/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4079\n",
      "LOG: Epoch [1118/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1118/2000], Avg Train Loss: 0.4079, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1119/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4020\n",
      "LOG: Epoch [1119/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1119/2000], Avg Train Loss: 0.4020, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1120/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [1120/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1120/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1121/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4081\n",
      "LOG: Epoch [1121/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1121/2000], Avg Train Loss: 0.4081, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1122/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4038\n",
      "LOG: Epoch [1122/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1122/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1123/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4005\n",
      "LOG: Epoch [1123/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1123/2000], Avg Train Loss: 0.4005, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1124/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4075\n",
      "LOG: Epoch [1124/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1124/2000], Avg Train Loss: 0.4075, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1125/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4007\n",
      "LOG: Epoch [1125/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1125/2000], Avg Train Loss: 0.4007, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1126/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [1126/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1126/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1127/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4100\n",
      "LOG: Epoch [1127/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1127/2000], Avg Train Loss: 0.4100, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1128/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4074\n",
      "LOG: Epoch [1128/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1128/2000], Avg Train Loss: 0.4074, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1129/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4038\n",
      "LOG: Epoch [1129/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1129/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1130/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3969\n",
      "LOG: Epoch [1130/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1130/2000], Avg Train Loss: 0.3969, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1131/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [1131/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1131/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1132/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [1132/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1132/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1133/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [1133/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1133/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1134/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [1134/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1134/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1135/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [1135/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1135/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1136/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [1136/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1136/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1137/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4123\n",
      "LOG: Epoch [1137/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1137/2000], Avg Train Loss: 0.4123, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1138/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3950\n",
      "LOG: Epoch [1138/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1138/2000], Avg Train Loss: 0.3950, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1139/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [1139/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1139/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1140/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [1140/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1140/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1141/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4096\n",
      "LOG: Epoch [1141/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1141/2000], Avg Train Loss: 0.4096, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1142/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4012\n",
      "LOG: Epoch [1142/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1142/2000], Avg Train Loss: 0.4012, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1143/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4123\n",
      "LOG: Epoch [1143/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1143/2000], Avg Train Loss: 0.4123, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1144/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4020\n",
      "LOG: Epoch [1144/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1144/2000], Avg Train Loss: 0.4020, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1145/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [1145/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1145/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1146/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3913\n",
      "LOG: Epoch [1146/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1146/2000], Avg Train Loss: 0.3913, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1147/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3956\n",
      "LOG: Epoch [1147/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1147/2000], Avg Train Loss: 0.3956, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1148/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3999\n",
      "LOG: Epoch [1148/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1148/2000], Avg Train Loss: 0.3999, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1149/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3991\n",
      "LOG: Epoch [1149/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1149/2000], Avg Train Loss: 0.3991, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1150/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4058\n",
      "LOG: Epoch [1150/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1150/2000], Avg Train Loss: 0.4058, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1151/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3974\n",
      "LOG: Epoch [1151/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1151/2000], Avg Train Loss: 0.3974, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1152/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4064\n",
      "LOG: Epoch [1152/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1152/2000], Avg Train Loss: 0.4064, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1153/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4003\n",
      "LOG: Epoch [1153/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1153/2000], Avg Train Loss: 0.4003, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1154/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [1154/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1154/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1155/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [1155/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1155/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1156/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4000\n",
      "LOG: Epoch [1156/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1156/2000], Avg Train Loss: 0.4000, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1157/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4012\n",
      "LOG: Epoch [1157/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1157/2000], Avg Train Loss: 0.4012, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1158/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [1158/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1158/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1159/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3969\n",
      "LOG: Epoch [1159/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1159/2000], Avg Train Loss: 0.3969, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1160/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [1160/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1160/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1161/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [1161/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1161/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1162/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [1162/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1162/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1163/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3992\n",
      "LOG: Epoch [1163/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1163/2000], Avg Train Loss: 0.3992, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1164/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [1164/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1164/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1165/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [1165/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1165/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1166/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [1166/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1166/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1167/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4007\n",
      "LOG: Epoch [1167/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1167/2000], Avg Train Loss: 0.4007, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1168/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [1168/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1168/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1169/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [1169/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1169/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1170/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [1170/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1170/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1171/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4013\n",
      "LOG: Epoch [1171/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1171/2000], Avg Train Loss: 0.4013, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1172/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [1172/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1172/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1173/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4002\n",
      "LOG: Epoch [1173/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1173/2000], Avg Train Loss: 0.4002, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1174/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [1174/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1174/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1175/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [1175/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1175/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1176/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [1176/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1176/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1177/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4091\n",
      "LOG: Epoch [1177/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1177/2000], Avg Train Loss: 0.4091, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1178/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [1178/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1178/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1179/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [1179/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1179/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1180/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3992\n",
      "LOG: Epoch [1180/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1180/2000], Avg Train Loss: 0.3992, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1181/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4090\n",
      "LOG: Epoch [1181/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1181/2000], Avg Train Loss: 0.4090, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1182/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4056\n",
      "LOG: Epoch [1182/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1182/2000], Avg Train Loss: 0.4056, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1183/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [1183/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1183/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1184/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [1184/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1184/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1185/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4096\n",
      "LOG: Epoch [1185/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1185/2000], Avg Train Loss: 0.4096, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1186/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [1186/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1186/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1187/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [1187/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1187/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1188/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4094\n",
      "LOG: Epoch [1188/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1188/2000], Avg Train Loss: 0.4094, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1189/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [1189/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1189/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1190/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [1190/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1190/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1191/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [1191/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1191/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1192/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4002\n",
      "LOG: Epoch [1192/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1192/2000], Avg Train Loss: 0.4002, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1193/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3991\n",
      "LOG: Epoch [1193/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1193/2000], Avg Train Loss: 0.3991, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1194/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [1194/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1194/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1195/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3978\n",
      "LOG: Epoch [1195/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1195/2000], Avg Train Loss: 0.3978, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1196/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [1196/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1196/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1197/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [1197/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1197/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1198/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [1198/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1198/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1199/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3990\n",
      "LOG: Epoch [1199/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1199/2000], Avg Train Loss: 0.3990, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1200/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [1200/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1200/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1201/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [1201/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1201/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1202/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [1202/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1202/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1203/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3985\n",
      "LOG: Epoch [1203/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1203/2000], Avg Train Loss: 0.3985, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1204/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3986\n",
      "LOG: Epoch [1204/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1204/2000], Avg Train Loss: 0.3986, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1205/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4070\n",
      "LOG: Epoch [1205/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1205/2000], Avg Train Loss: 0.4070, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1206/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3993\n",
      "LOG: Epoch [1206/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1206/2000], Avg Train Loss: 0.3993, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1207/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [1207/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1207/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1208/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3987\n",
      "LOG: Epoch [1208/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1208/2000], Avg Train Loss: 0.3987, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1209/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4099\n",
      "LOG: Epoch [1209/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1209/2000], Avg Train Loss: 0.4099, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1210/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4038\n",
      "LOG: Epoch [1210/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1210/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1211/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [1211/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1211/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1212/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4056\n",
      "LOG: Epoch [1212/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1212/2000], Avg Train Loss: 0.4056, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1213/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [1213/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1213/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1214/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [1214/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1214/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1215/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3992\n",
      "LOG: Epoch [1215/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1215/2000], Avg Train Loss: 0.3992, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1216/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3985\n",
      "LOG: Epoch [1216/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1216/2000], Avg Train Loss: 0.3985, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1217/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [1217/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1217/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1218/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4081\n",
      "LOG: Epoch [1218/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1218/2000], Avg Train Loss: 0.4081, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1219/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4013\n",
      "LOG: Epoch [1219/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1219/2000], Avg Train Loss: 0.4013, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1220/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3972\n",
      "LOG: Epoch [1220/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1220/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1221/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [1221/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1221/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1222/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [1222/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1222/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1223/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [1223/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1223/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1224/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4001\n",
      "LOG: Epoch [1224/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1224/2000], Avg Train Loss: 0.4001, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1225/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3966\n",
      "LOG: Epoch [1225/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1225/2000], Avg Train Loss: 0.3966, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1226/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4005\n",
      "LOG: Epoch [1226/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1226/2000], Avg Train Loss: 0.4005, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1227/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [1227/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1227/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1228/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4074\n",
      "LOG: Epoch [1228/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1228/2000], Avg Train Loss: 0.4074, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1229/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [1229/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1229/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1230/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [1230/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1230/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1231/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4093\n",
      "LOG: Epoch [1231/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1231/2000], Avg Train Loss: 0.4093, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1232/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4089\n",
      "LOG: Epoch [1232/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1232/2000], Avg Train Loss: 0.4089, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1233/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4044\n",
      "LOG: Epoch [1233/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1233/2000], Avg Train Loss: 0.4044, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1234/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [1234/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1234/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1235/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [1235/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1235/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1236/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [1236/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1236/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1237/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4083\n",
      "LOG: Epoch [1237/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1237/2000], Avg Train Loss: 0.4083, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1238/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [1238/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1238/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1239/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [1239/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1239/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1240/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [1240/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1240/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1241/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4020\n",
      "LOG: Epoch [1241/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1241/2000], Avg Train Loss: 0.4020, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1242/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [1242/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1242/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1243/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [1243/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1243/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1244/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [1244/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1244/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1245/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4062\n",
      "LOG: Epoch [1245/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1245/2000], Avg Train Loss: 0.4062, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1246/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [1246/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1246/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1247/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [1247/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1247/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1248/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4064\n",
      "LOG: Epoch [1248/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1248/2000], Avg Train Loss: 0.4064, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1249/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [1249/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1249/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1250/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [1250/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1250/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1251/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [1251/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1251/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1252/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4085\n",
      "LOG: Epoch [1252/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1252/2000], Avg Train Loss: 0.4085, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1253/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [1253/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1253/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1254/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [1254/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1254/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1255/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3991\n",
      "LOG: Epoch [1255/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1255/2000], Avg Train Loss: 0.3991, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1256/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [1256/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1256/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1257/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [1257/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1257/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1258/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3977\n",
      "LOG: Epoch [1258/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1258/2000], Avg Train Loss: 0.3977, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1259/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4090\n",
      "LOG: Epoch [1259/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1259/2000], Avg Train Loss: 0.4090, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1260/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [1260/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1260/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1261/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [1261/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1261/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1262/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3993\n",
      "LOG: Epoch [1262/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1262/2000], Avg Train Loss: 0.3993, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1263/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [1263/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1263/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1264/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3982\n",
      "LOG: Epoch [1264/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1264/2000], Avg Train Loss: 0.3982, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1265/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [1265/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1265/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1266/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4005\n",
      "LOG: Epoch [1266/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1266/2000], Avg Train Loss: 0.4005, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1267/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [1267/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1267/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1268/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4092\n",
      "LOG: Epoch [1268/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1268/2000], Avg Train Loss: 0.4092, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1269/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4104\n",
      "LOG: Epoch [1269/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1269/2000], Avg Train Loss: 0.4104, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1270/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [1270/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1270/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1271/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3987\n",
      "LOG: Epoch [1271/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1271/2000], Avg Train Loss: 0.3987, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1272/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [1272/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1272/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1273/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4002\n",
      "LOG: Epoch [1273/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1273/2000], Avg Train Loss: 0.4002, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1274/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4096\n",
      "LOG: Epoch [1274/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1274/2000], Avg Train Loss: 0.4096, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1275/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4076\n",
      "LOG: Epoch [1275/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1275/2000], Avg Train Loss: 0.4076, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1276/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4012\n",
      "LOG: Epoch [1276/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1276/2000], Avg Train Loss: 0.4012, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1277/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4090\n",
      "LOG: Epoch [1277/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1277/2000], Avg Train Loss: 0.4090, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1278/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [1278/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1278/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1279/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4114\n",
      "LOG: Epoch [1279/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1279/2000], Avg Train Loss: 0.4114, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1280/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [1280/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1280/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1281/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3981\n",
      "LOG: Epoch [1281/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1281/2000], Avg Train Loss: 0.3981, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1282/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4008\n",
      "LOG: Epoch [1282/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1282/2000], Avg Train Loss: 0.4008, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1283/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3990\n",
      "LOG: Epoch [1283/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1283/2000], Avg Train Loss: 0.3990, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1284/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4102\n",
      "LOG: Epoch [1284/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1284/2000], Avg Train Loss: 0.4102, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1285/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3972\n",
      "LOG: Epoch [1285/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1285/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1286/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3996\n",
      "LOG: Epoch [1286/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1286/2000], Avg Train Loss: 0.3996, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1287/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4070\n",
      "LOG: Epoch [1287/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1287/2000], Avg Train Loss: 0.4070, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1288/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [1288/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1288/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1289/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3983\n",
      "LOG: Epoch [1289/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1289/2000], Avg Train Loss: 0.3983, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1290/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [1290/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1290/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1291/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3998\n",
      "LOG: Epoch [1291/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1291/2000], Avg Train Loss: 0.3998, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1292/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4092\n",
      "LOG: Epoch [1292/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1292/2000], Avg Train Loss: 0.4092, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1293/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [1293/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1293/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1294/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [1294/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1294/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1295/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4012\n",
      "LOG: Epoch [1295/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1295/2000], Avg Train Loss: 0.4012, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1296/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4093\n",
      "LOG: Epoch [1296/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1296/2000], Avg Train Loss: 0.4093, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1297/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4074\n",
      "LOG: Epoch [1297/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1297/2000], Avg Train Loss: 0.4074, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1298/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4091\n",
      "LOG: Epoch [1298/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1298/2000], Avg Train Loss: 0.4091, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1299/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [1299/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1299/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1300/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3984\n",
      "LOG: Epoch [1300/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1300/2000], Avg Train Loss: 0.3984, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1301/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [1301/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1301/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1302/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [1302/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1302/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1303/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [1303/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1303/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1304/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [1304/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1304/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1305/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4080\n",
      "LOG: Epoch [1305/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1305/2000], Avg Train Loss: 0.4080, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1306/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4057\n",
      "LOG: Epoch [1306/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1306/2000], Avg Train Loss: 0.4057, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1307/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [1307/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1307/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1308/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4058\n",
      "LOG: Epoch [1308/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1308/2000], Avg Train Loss: 0.4058, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1309/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4099\n",
      "LOG: Epoch [1309/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1309/2000], Avg Train Loss: 0.4099, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1310/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [1310/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1310/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1311/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3982\n",
      "LOG: Epoch [1311/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1311/2000], Avg Train Loss: 0.3982, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1312/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [1312/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1312/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1313/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3971\n",
      "LOG: Epoch [1313/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1313/2000], Avg Train Loss: 0.3971, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1314/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4048\n",
      "LOG: Epoch [1314/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1314/2000], Avg Train Loss: 0.4048, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1315/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [1315/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1315/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1316/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1316/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1316/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1317/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3993\n",
      "LOG: Epoch [1317/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1317/2000], Avg Train Loss: 0.3993, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1318/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4112\n",
      "LOG: Epoch [1318/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1318/2000], Avg Train Loss: 0.4112, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1319/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3995\n",
      "LOG: Epoch [1319/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1319/2000], Avg Train Loss: 0.3995, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1320/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [1320/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1320/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1321/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [1321/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1321/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1322/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3986\n",
      "LOG: Epoch [1322/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1322/2000], Avg Train Loss: 0.3986, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1323/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4010\n",
      "LOG: Epoch [1323/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1323/2000], Avg Train Loss: 0.4010, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1324/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4064\n",
      "LOG: Epoch [1324/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1324/2000], Avg Train Loss: 0.4064, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1325/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [1325/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1325/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1326/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3991\n",
      "LOG: Epoch [1326/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1326/2000], Avg Train Loss: 0.3991, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1327/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4012\n",
      "LOG: Epoch [1327/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1327/2000], Avg Train Loss: 0.4012, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1328/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [1328/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1328/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1329/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [1329/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1329/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1330/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3969\n",
      "LOG: Epoch [1330/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1330/2000], Avg Train Loss: 0.3969, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1331/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [1331/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1331/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1332/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [1332/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1332/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1333/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3992\n",
      "LOG: Epoch [1333/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1333/2000], Avg Train Loss: 0.3992, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1334/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4054\n",
      "LOG: Epoch [1334/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1334/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1335/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [1335/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1335/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1336/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4037\n",
      "LOG: Epoch [1336/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1336/2000], Avg Train Loss: 0.4037, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1337/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3998\n",
      "LOG: Epoch [1337/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1337/2000], Avg Train Loss: 0.3998, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1338/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4010\n",
      "LOG: Epoch [1338/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1338/2000], Avg Train Loss: 0.4010, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1339/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [1339/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1339/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1340/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [1340/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1340/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1341/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [1341/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1341/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1342/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4010\n",
      "LOG: Epoch [1342/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1342/2000], Avg Train Loss: 0.4010, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1343/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3935\n",
      "LOG: Epoch [1343/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1343/2000], Avg Train Loss: 0.3935, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1344/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [1344/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1344/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1345/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [1345/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1345/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1346/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4080\n",
      "LOG: Epoch [1346/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1346/2000], Avg Train Loss: 0.4080, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1347/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [1347/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1347/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1348/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [1348/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1348/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1349/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [1349/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1349/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1350/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [1350/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1350/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1351/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3992\n",
      "LOG: Epoch [1351/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1351/2000], Avg Train Loss: 0.3992, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1352/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [1352/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1352/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1353/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [1353/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1353/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1354/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4103\n",
      "LOG: Epoch [1354/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1354/2000], Avg Train Loss: 0.4103, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1355/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [1355/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1355/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1356/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [1356/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1356/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1357/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [1357/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1357/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1358/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [1358/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1358/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1359/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [1359/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1359/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1360/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4049\n",
      "LOG: Epoch [1360/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1360/2000], Avg Train Loss: 0.4049, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1361/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3999\n",
      "LOG: Epoch [1361/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1361/2000], Avg Train Loss: 0.3999, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1362/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [1362/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1362/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1363/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [1363/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1363/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1364/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4058\n",
      "LOG: Epoch [1364/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1364/2000], Avg Train Loss: 0.4058, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1365/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [1365/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1365/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1366/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [1366/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1366/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1367/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [1367/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1367/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1368/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3996\n",
      "LOG: Epoch [1368/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1368/2000], Avg Train Loss: 0.3996, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1369/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [1369/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1369/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1370/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [1370/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1370/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1371/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [1371/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1371/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1372/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3975\n",
      "LOG: Epoch [1372/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1372/2000], Avg Train Loss: 0.3975, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1373/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4060\n",
      "LOG: Epoch [1373/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1373/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1374/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3914\n",
      "LOG: Epoch [1374/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1374/2000], Avg Train Loss: 0.3914, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1375/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4056\n",
      "LOG: Epoch [1375/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1375/2000], Avg Train Loss: 0.4056, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1376/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [1376/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1376/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1377/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4087\n",
      "LOG: Epoch [1377/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1377/2000], Avg Train Loss: 0.4087, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1378/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1378/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1378/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1379/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3946\n",
      "LOG: Epoch [1379/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1379/2000], Avg Train Loss: 0.3946, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1380/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4070\n",
      "LOG: Epoch [1380/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1380/2000], Avg Train Loss: 0.4070, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1381/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3972\n",
      "LOG: Epoch [1381/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1381/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1382/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [1382/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1382/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1383/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [1383/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1383/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1384/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4037\n",
      "LOG: Epoch [1384/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1384/2000], Avg Train Loss: 0.4037, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1385/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3984\n",
      "LOG: Epoch [1385/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1385/2000], Avg Train Loss: 0.3984, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1386/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4075\n",
      "LOG: Epoch [1386/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1386/2000], Avg Train Loss: 0.4075, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1387/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [1387/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1387/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1388/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [1388/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1388/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1389/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3951\n",
      "LOG: Epoch [1389/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1389/2000], Avg Train Loss: 0.3951, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1390/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4091\n",
      "LOG: Epoch [1390/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1390/2000], Avg Train Loss: 0.4091, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1391/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [1391/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1391/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1392/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4081\n",
      "LOG: Epoch [1392/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1392/2000], Avg Train Loss: 0.4081, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1393/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [1393/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1393/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1394/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3960\n",
      "LOG: Epoch [1394/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1394/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1395/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3980\n",
      "LOG: Epoch [1395/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1395/2000], Avg Train Loss: 0.3980, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1396/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4058\n",
      "LOG: Epoch [1396/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1396/2000], Avg Train Loss: 0.4058, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1397/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [1397/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1397/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1398/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [1398/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1398/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1399/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3972\n",
      "LOG: Epoch [1399/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1399/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1400/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [1400/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1400/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1401/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [1401/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1401/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1402/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4012\n",
      "LOG: Epoch [1402/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1402/2000], Avg Train Loss: 0.4012, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1403/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [1403/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1403/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1404/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [1404/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1404/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1405/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [1405/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1405/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1406/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [1406/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1406/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1407/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3978\n",
      "LOG: Epoch [1407/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1407/2000], Avg Train Loss: 0.3978, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1408/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [1408/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1408/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1409/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [1409/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1409/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1410/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [1410/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1410/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1411/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4059\n",
      "LOG: Epoch [1411/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1411/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1412/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [1412/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1412/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1413/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [1413/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1413/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1414/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [1414/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1414/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1415/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4048\n",
      "LOG: Epoch [1415/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1415/2000], Avg Train Loss: 0.4048, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1416/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4059\n",
      "LOG: Epoch [1416/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1416/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1417/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3990\n",
      "LOG: Epoch [1417/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1417/2000], Avg Train Loss: 0.3990, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1418/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3983\n",
      "LOG: Epoch [1418/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1418/2000], Avg Train Loss: 0.3983, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1419/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4037\n",
      "LOG: Epoch [1419/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1419/2000], Avg Train Loss: 0.4037, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1420/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [1420/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1420/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1421/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [1421/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1421/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1422/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4077\n",
      "LOG: Epoch [1422/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1422/2000], Avg Train Loss: 0.4077, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1423/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [1423/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1423/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1424/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [1424/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1424/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1425/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4020\n",
      "LOG: Epoch [1425/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1425/2000], Avg Train Loss: 0.4020, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1426/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [1426/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1426/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1427/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [1427/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1427/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1428/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [1428/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1428/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1429/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [1429/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1429/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1430/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4048\n",
      "LOG: Epoch [1430/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1430/2000], Avg Train Loss: 0.4048, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1431/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4003\n",
      "LOG: Epoch [1431/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1431/2000], Avg Train Loss: 0.4003, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1432/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [1432/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1432/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1433/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4002\n",
      "LOG: Epoch [1433/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1433/2000], Avg Train Loss: 0.4002, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1434/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [1434/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1434/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1435/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3985\n",
      "LOG: Epoch [1435/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1435/2000], Avg Train Loss: 0.3985, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1436/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [1436/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1436/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1437/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4020\n",
      "LOG: Epoch [1437/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1437/2000], Avg Train Loss: 0.4020, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1438/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [1438/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1438/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1439/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4102\n",
      "LOG: Epoch [1439/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1439/2000], Avg Train Loss: 0.4102, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1440/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3955\n",
      "LOG: Epoch [1440/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1440/2000], Avg Train Loss: 0.3955, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1441/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [1441/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1441/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1442/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [1442/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1442/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1443/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4062\n",
      "LOG: Epoch [1443/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1443/2000], Avg Train Loss: 0.4062, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1444/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [1444/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1444/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1445/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4078\n",
      "LOG: Epoch [1445/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1445/2000], Avg Train Loss: 0.4078, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1446/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4004\n",
      "LOG: Epoch [1446/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1446/2000], Avg Train Loss: 0.4004, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1447/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [1447/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1447/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1448/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3977\n",
      "LOG: Epoch [1448/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1448/2000], Avg Train Loss: 0.3977, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1449/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [1449/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1449/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1450/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [1450/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1450/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1451/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4091\n",
      "LOG: Epoch [1451/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1451/2000], Avg Train Loss: 0.4091, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1452/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [1452/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1452/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1453/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4064\n",
      "LOG: Epoch [1453/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1453/2000], Avg Train Loss: 0.4064, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1454/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [1454/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1454/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1455/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3992\n",
      "LOG: Epoch [1455/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1455/2000], Avg Train Loss: 0.3992, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1456/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [1456/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1456/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1457/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3990\n",
      "LOG: Epoch [1457/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1457/2000], Avg Train Loss: 0.3990, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1458/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [1458/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1458/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1459/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [1459/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1459/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1460/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3999\n",
      "LOG: Epoch [1460/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1460/2000], Avg Train Loss: 0.3999, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1461/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [1461/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1461/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1462/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [1462/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1462/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1463/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4056\n",
      "LOG: Epoch [1463/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1463/2000], Avg Train Loss: 0.4056, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1464/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [1464/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1464/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1465/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [1465/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1465/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1466/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4048\n",
      "LOG: Epoch [1466/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1466/2000], Avg Train Loss: 0.4048, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1467/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [1467/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1467/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1468/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4003\n",
      "LOG: Epoch [1468/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1468/2000], Avg Train Loss: 0.4003, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1469/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [1469/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1469/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1470/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [1470/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1470/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1471/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [1471/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1471/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1472/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [1472/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1472/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1473/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4097\n",
      "LOG: Epoch [1473/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1473/2000], Avg Train Loss: 0.4097, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1474/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [1474/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1474/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1475/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3930\n",
      "LOG: Epoch [1475/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1475/2000], Avg Train Loss: 0.3930, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1476/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [1476/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1476/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1477/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [1477/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1477/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1478/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [1478/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1478/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1479/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [1479/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1479/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1480/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [1480/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1480/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1481/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3990\n",
      "LOG: Epoch [1481/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1481/2000], Avg Train Loss: 0.3990, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1482/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [1482/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1482/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1483/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3975\n",
      "LOG: Epoch [1483/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1483/2000], Avg Train Loss: 0.3975, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1484/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [1484/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1484/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1485/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [1485/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1485/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1486/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [1486/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1486/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1487/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4037\n",
      "LOG: Epoch [1487/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1487/2000], Avg Train Loss: 0.4037, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1488/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4010\n",
      "LOG: Epoch [1488/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1488/2000], Avg Train Loss: 0.4010, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1489/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4123\n",
      "LOG: Epoch [1489/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1489/2000], Avg Train Loss: 0.4123, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1490/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [1490/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1490/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1491/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3996\n",
      "LOG: Epoch [1491/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1491/2000], Avg Train Loss: 0.3996, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1492/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4092\n",
      "LOG: Epoch [1492/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1492/2000], Avg Train Loss: 0.4092, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1493/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3999\n",
      "LOG: Epoch [1493/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1493/2000], Avg Train Loss: 0.3999, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1494/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4048\n",
      "LOG: Epoch [1494/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1494/2000], Avg Train Loss: 0.4048, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1495/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [1495/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1495/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1496/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4007\n",
      "LOG: Epoch [1496/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1496/2000], Avg Train Loss: 0.4007, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1497/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4103\n",
      "LOG: Epoch [1497/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1497/2000], Avg Train Loss: 0.4103, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1498/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [1498/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1498/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1499/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4008\n",
      "LOG: Epoch [1499/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1499/2000], Avg Train Loss: 0.4008, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1500/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4062\n",
      "LOG: Epoch [1500/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1500/2000], Avg Train Loss: 0.4062, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1501/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [1501/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1501/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1502/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [1502/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1502/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1503/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [1503/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1503/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1504/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4037\n",
      "LOG: Epoch [1504/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1504/2000], Avg Train Loss: 0.4037, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1505/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4103\n",
      "LOG: Epoch [1505/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1505/2000], Avg Train Loss: 0.4103, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1506/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [1506/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1506/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1507/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [1507/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1507/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1508/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [1508/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1508/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1509/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [1509/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1509/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1510/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3976\n",
      "LOG: Epoch [1510/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1510/2000], Avg Train Loss: 0.3976, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1511/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3970\n",
      "LOG: Epoch [1511/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1511/2000], Avg Train Loss: 0.3970, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1512/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4078\n",
      "LOG: Epoch [1512/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1512/2000], Avg Train Loss: 0.4078, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1513/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4001\n",
      "LOG: Epoch [1513/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1513/2000], Avg Train Loss: 0.4001, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1514/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3954\n",
      "LOG: Epoch [1514/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1514/2000], Avg Train Loss: 0.3954, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1515/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [1515/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1515/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1516/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [1516/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1516/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1517/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [1517/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1517/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1518/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [1518/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1518/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1519/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [1519/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1519/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1520/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [1520/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1520/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1521/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [1521/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1521/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1522/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [1522/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1522/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1523/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [1523/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1523/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1524/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4057\n",
      "LOG: Epoch [1524/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1524/2000], Avg Train Loss: 0.4057, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1525/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4097\n",
      "LOG: Epoch [1525/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1525/2000], Avg Train Loss: 0.4097, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1526/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4078\n",
      "LOG: Epoch [1526/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1526/2000], Avg Train Loss: 0.4078, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1527/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [1527/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1527/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1528/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3934\n",
      "LOG: Epoch [1528/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1528/2000], Avg Train Loss: 0.3934, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1529/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4003\n",
      "LOG: Epoch [1529/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1529/2000], Avg Train Loss: 0.4003, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1530/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4082\n",
      "LOG: Epoch [1530/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1530/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1531/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4037\n",
      "LOG: Epoch [1531/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1531/2000], Avg Train Loss: 0.4037, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1532/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3996\n",
      "LOG: Epoch [1532/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1532/2000], Avg Train Loss: 0.3996, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1533/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [1533/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1533/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1534/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4102\n",
      "LOG: Epoch [1534/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1534/2000], Avg Train Loss: 0.4102, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1535/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1535/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1535/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1536/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4038\n",
      "LOG: Epoch [1536/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1536/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1537/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [1537/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1537/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1538/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [1538/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1538/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1539/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4013\n",
      "LOG: Epoch [1539/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1539/2000], Avg Train Loss: 0.4013, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1540/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3992\n",
      "LOG: Epoch [1540/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1540/2000], Avg Train Loss: 0.3992, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1541/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3974\n",
      "LOG: Epoch [1541/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1541/2000], Avg Train Loss: 0.3974, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1542/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [1542/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1542/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1543/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [1543/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1543/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1544/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [1544/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1544/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1545/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [1545/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1545/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1546/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [1546/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1546/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1547/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1547/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1547/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1548/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4143\n",
      "LOG: Epoch [1548/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1548/2000], Avg Train Loss: 0.4143, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1549/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4010\n",
      "LOG: Epoch [1549/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1549/2000], Avg Train Loss: 0.4010, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1550/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [1550/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1550/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1551/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3992\n",
      "LOG: Epoch [1551/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1551/2000], Avg Train Loss: 0.3992, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1552/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4059\n",
      "LOG: Epoch [1552/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1552/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1553/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [1553/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1553/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1554/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4079\n",
      "LOG: Epoch [1554/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1554/2000], Avg Train Loss: 0.4079, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1555/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3961\n",
      "LOG: Epoch [1555/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1555/2000], Avg Train Loss: 0.3961, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1556/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4032\n",
      "LOG: Epoch [1556/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1556/2000], Avg Train Loss: 0.4032, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1557/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [1557/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1557/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1558/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [1558/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1558/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1559/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [1559/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1559/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1560/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1560/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1560/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1561/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4082\n",
      "LOG: Epoch [1561/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1561/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1562/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4049\n",
      "LOG: Epoch [1562/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1562/2000], Avg Train Loss: 0.4049, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1563/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [1563/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1563/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1564/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4071\n",
      "LOG: Epoch [1564/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1564/2000], Avg Train Loss: 0.4071, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1565/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [1565/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1565/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1566/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [1566/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1566/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1567/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4071\n",
      "LOG: Epoch [1567/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1567/2000], Avg Train Loss: 0.4071, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1568/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3966\n",
      "LOG: Epoch [1568/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1568/2000], Avg Train Loss: 0.3966, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1569/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4082\n",
      "LOG: Epoch [1569/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1569/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1570/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4128\n",
      "LOG: Epoch [1570/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1570/2000], Avg Train Loss: 0.4128, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1571/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4071\n",
      "LOG: Epoch [1571/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1571/2000], Avg Train Loss: 0.4071, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1572/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4074\n",
      "LOG: Epoch [1572/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1572/2000], Avg Train Loss: 0.4074, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1573/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4092\n",
      "LOG: Epoch [1573/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1573/2000], Avg Train Loss: 0.4092, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1574/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [1574/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1574/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1575/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [1575/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1575/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1576/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [1576/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1576/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1577/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [1577/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1577/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1578/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [1578/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1578/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1579/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [1579/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1579/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1580/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [1580/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1580/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1581/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [1581/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1581/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1582/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3983\n",
      "LOG: Epoch [1582/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1582/2000], Avg Train Loss: 0.3983, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1583/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [1583/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1583/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1584/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [1584/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1584/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1585/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4001\n",
      "LOG: Epoch [1585/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1585/2000], Avg Train Loss: 0.4001, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1586/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [1586/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1586/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1587/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4075\n",
      "LOG: Epoch [1587/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1587/2000], Avg Train Loss: 0.4075, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1588/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [1588/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1588/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1589/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1589/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1589/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1590/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3999\n",
      "LOG: Epoch [1590/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1590/2000], Avg Train Loss: 0.3999, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1591/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1591/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1591/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1592/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4054\n",
      "LOG: Epoch [1592/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1592/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1593/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [1593/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1593/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1594/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3957\n",
      "LOG: Epoch [1594/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1594/2000], Avg Train Loss: 0.3957, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1595/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [1595/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1595/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1596/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [1596/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1596/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1597/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4074\n",
      "LOG: Epoch [1597/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1597/2000], Avg Train Loss: 0.4074, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1598/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [1598/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1598/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1599/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [1599/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1599/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1600/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3955\n",
      "LOG: Epoch [1600/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1600/2000], Avg Train Loss: 0.3955, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1601/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [1601/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1601/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1602/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3989\n",
      "LOG: Epoch [1602/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1602/2000], Avg Train Loss: 0.3989, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1603/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3993\n",
      "LOG: Epoch [1603/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1603/2000], Avg Train Loss: 0.3993, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1604/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [1604/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1604/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1605/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [1605/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1605/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1606/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4000\n",
      "LOG: Epoch [1606/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1606/2000], Avg Train Loss: 0.4000, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1607/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4064\n",
      "LOG: Epoch [1607/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1607/2000], Avg Train Loss: 0.4064, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1608/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4060\n",
      "LOG: Epoch [1608/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1608/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1609/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [1609/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1609/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1610/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [1610/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1610/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1611/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4087\n",
      "LOG: Epoch [1611/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1611/2000], Avg Train Loss: 0.4087, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1612/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [1612/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1612/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1613/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [1613/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1613/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1614/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [1614/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1614/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1615/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1615/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1615/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1616/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4020\n",
      "LOG: Epoch [1616/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1616/2000], Avg Train Loss: 0.4020, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1617/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [1617/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1617/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1618/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [1618/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1618/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1619/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [1619/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1619/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1620/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [1620/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1620/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1621/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4136\n",
      "LOG: Epoch [1621/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1621/2000], Avg Train Loss: 0.4136, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1622/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4037\n",
      "LOG: Epoch [1622/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1622/2000], Avg Train Loss: 0.4037, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1623/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4005\n",
      "LOG: Epoch [1623/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1623/2000], Avg Train Loss: 0.4005, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1624/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4071\n",
      "LOG: Epoch [1624/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1624/2000], Avg Train Loss: 0.4071, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1625/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [1625/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1625/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1626/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [1626/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1626/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1627/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4013\n",
      "LOG: Epoch [1627/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1627/2000], Avg Train Loss: 0.4013, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1628/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4128\n",
      "LOG: Epoch [1628/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1628/2000], Avg Train Loss: 0.4128, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1629/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4012\n",
      "LOG: Epoch [1629/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1629/2000], Avg Train Loss: 0.4012, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1630/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [1630/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1630/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1631/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3992\n",
      "LOG: Epoch [1631/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1631/2000], Avg Train Loss: 0.3992, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1632/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4002\n",
      "LOG: Epoch [1632/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1632/2000], Avg Train Loss: 0.4002, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1633/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3950\n",
      "LOG: Epoch [1633/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1633/2000], Avg Train Loss: 0.3950, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1634/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4060\n",
      "LOG: Epoch [1634/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1634/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1635/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [1635/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1635/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1636/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4071\n",
      "LOG: Epoch [1636/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1636/2000], Avg Train Loss: 0.4071, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1637/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [1637/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1637/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1638/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [1638/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1638/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1639/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3989\n",
      "LOG: Epoch [1639/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1639/2000], Avg Train Loss: 0.3989, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1640/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4077\n",
      "LOG: Epoch [1640/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1640/2000], Avg Train Loss: 0.4077, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1641/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [1641/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1641/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1642/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [1642/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1642/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1643/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [1643/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1643/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1644/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4111\n",
      "LOG: Epoch [1644/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1644/2000], Avg Train Loss: 0.4111, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1645/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3980\n",
      "LOG: Epoch [1645/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1645/2000], Avg Train Loss: 0.3980, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1646/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [1646/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1646/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1647/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3947\n",
      "LOG: Epoch [1647/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1647/2000], Avg Train Loss: 0.3947, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1648/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3992\n",
      "LOG: Epoch [1648/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1648/2000], Avg Train Loss: 0.3992, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1649/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [1649/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1649/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1650/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [1650/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1650/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1651/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4090\n",
      "LOG: Epoch [1651/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1651/2000], Avg Train Loss: 0.4090, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1652/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4088\n",
      "LOG: Epoch [1652/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1652/2000], Avg Train Loss: 0.4088, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1653/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4005\n",
      "LOG: Epoch [1653/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1653/2000], Avg Train Loss: 0.4005, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1654/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3995\n",
      "LOG: Epoch [1654/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1654/2000], Avg Train Loss: 0.3995, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1655/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [1655/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1655/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1656/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [1656/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1656/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1657/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4083\n",
      "LOG: Epoch [1657/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1657/2000], Avg Train Loss: 0.4083, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1658/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4059\n",
      "LOG: Epoch [1658/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1658/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1659/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [1659/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1659/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1660/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [1660/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1660/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1661/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3975\n",
      "LOG: Epoch [1661/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1661/2000], Avg Train Loss: 0.3975, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1662/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [1662/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1662/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1663/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [1663/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1663/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1664/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [1664/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1664/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1665/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3987\n",
      "LOG: Epoch [1665/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1665/2000], Avg Train Loss: 0.3987, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1666/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4013\n",
      "LOG: Epoch [1666/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1666/2000], Avg Train Loss: 0.4013, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1667/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [1667/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1667/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1668/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3988\n",
      "LOG: Epoch [1668/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1668/2000], Avg Train Loss: 0.3988, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1669/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [1669/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1669/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1670/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3977\n",
      "LOG: Epoch [1670/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1670/2000], Avg Train Loss: 0.3977, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1671/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4012\n",
      "LOG: Epoch [1671/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1671/2000], Avg Train Loss: 0.4012, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1672/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [1672/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1672/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1673/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4054\n",
      "LOG: Epoch [1673/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1673/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1674/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [1674/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1674/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1675/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3971\n",
      "LOG: Epoch [1675/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1675/2000], Avg Train Loss: 0.3971, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1676/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3965\n",
      "LOG: Epoch [1676/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1676/2000], Avg Train Loss: 0.3965, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1677/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4044\n",
      "LOG: Epoch [1677/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1677/2000], Avg Train Loss: 0.4044, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1678/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3995\n",
      "LOG: Epoch [1678/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1678/2000], Avg Train Loss: 0.3995, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1679/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [1679/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1679/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1680/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1680/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1680/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1681/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4013\n",
      "LOG: Epoch [1681/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1681/2000], Avg Train Loss: 0.4013, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1682/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [1682/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1682/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1683/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [1683/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1683/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1684/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4076\n",
      "LOG: Epoch [1684/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1684/2000], Avg Train Loss: 0.4076, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1685/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4049\n",
      "LOG: Epoch [1685/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1685/2000], Avg Train Loss: 0.4049, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1686/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [1686/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1686/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1687/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [1687/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1687/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1688/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [1688/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1688/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1689/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4003\n",
      "LOG: Epoch [1689/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1689/2000], Avg Train Loss: 0.4003, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1690/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [1690/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1690/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1691/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [1691/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1691/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1692/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [1692/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1692/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1693/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [1693/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1693/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1694/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [1694/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1694/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1695/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [1695/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1695/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1696/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4082\n",
      "LOG: Epoch [1696/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1696/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1697/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4054\n",
      "LOG: Epoch [1697/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1697/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1698/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4022\n",
      "LOG: Epoch [1698/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1698/2000], Avg Train Loss: 0.4022, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1699/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4089\n",
      "LOG: Epoch [1699/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1699/2000], Avg Train Loss: 0.4089, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1700/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [1700/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1700/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1701/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [1701/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1701/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1702/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [1702/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1702/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1703/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4057\n",
      "LOG: Epoch [1703/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1703/2000], Avg Train Loss: 0.4057, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1704/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [1704/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1704/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1705/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4076\n",
      "LOG: Epoch [1705/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1705/2000], Avg Train Loss: 0.4076, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1706/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4006\n",
      "LOG: Epoch [1706/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1706/2000], Avg Train Loss: 0.4006, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1707/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3995\n",
      "LOG: Epoch [1707/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1707/2000], Avg Train Loss: 0.3995, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1708/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3984\n",
      "LOG: Epoch [1708/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1708/2000], Avg Train Loss: 0.3984, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1709/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [1709/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1709/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1710/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [1710/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1710/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1711/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3955\n",
      "LOG: Epoch [1711/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1711/2000], Avg Train Loss: 0.3955, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1712/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [1712/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1712/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1713/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4091\n",
      "LOG: Epoch [1713/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1713/2000], Avg Train Loss: 0.4091, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1714/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [1714/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1714/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1715/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [1715/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1715/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1716/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4028\n",
      "LOG: Epoch [1716/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1716/2000], Avg Train Loss: 0.4028, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1717/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [1717/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1717/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1718/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [1718/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1718/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1719/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4024\n",
      "LOG: Epoch [1719/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1719/2000], Avg Train Loss: 0.4024, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1720/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4106\n",
      "LOG: Epoch [1720/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1720/2000], Avg Train Loss: 0.4106, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1721/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [1721/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1721/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1722/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4099\n",
      "LOG: Epoch [1722/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1722/2000], Avg Train Loss: 0.4099, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1723/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [1723/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1723/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1724/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [1724/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1724/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1725/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4059\n",
      "LOG: Epoch [1725/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1725/2000], Avg Train Loss: 0.4059, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1726/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3980\n",
      "LOG: Epoch [1726/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1726/2000], Avg Train Loss: 0.3980, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1727/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4079\n",
      "LOG: Epoch [1727/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1727/2000], Avg Train Loss: 0.4079, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1728/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [1728/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1728/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1729/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4077\n",
      "LOG: Epoch [1729/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1729/2000], Avg Train Loss: 0.4077, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1730/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [1730/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1730/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1731/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4078\n",
      "LOG: Epoch [1731/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1731/2000], Avg Train Loss: 0.4078, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1732/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4095\n",
      "LOG: Epoch [1732/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1732/2000], Avg Train Loss: 0.4095, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1733/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4105\n",
      "LOG: Epoch [1733/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1733/2000], Avg Train Loss: 0.4105, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1734/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4092\n",
      "LOG: Epoch [1734/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1734/2000], Avg Train Loss: 0.4092, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1735/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [1735/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1735/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1736/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [1736/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1736/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1737/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [1737/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1737/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1738/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [1738/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1738/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1739/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [1739/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1739/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1740/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [1740/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1740/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1741/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [1741/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1741/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1742/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4044\n",
      "LOG: Epoch [1742/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1742/2000], Avg Train Loss: 0.4044, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1743/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3982\n",
      "LOG: Epoch [1743/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1743/2000], Avg Train Loss: 0.3982, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1744/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3981\n",
      "LOG: Epoch [1744/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1744/2000], Avg Train Loss: 0.3981, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1745/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4071\n",
      "LOG: Epoch [1745/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1745/2000], Avg Train Loss: 0.4071, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1746/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4060\n",
      "LOG: Epoch [1746/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1746/2000], Avg Train Loss: 0.4060, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1747/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4049\n",
      "LOG: Epoch [1747/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1747/2000], Avg Train Loss: 0.4049, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1748/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [1748/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1748/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1749/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3972\n",
      "LOG: Epoch [1749/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1749/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1750/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4044\n",
      "LOG: Epoch [1750/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1750/2000], Avg Train Loss: 0.4044, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1751/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4020\n",
      "LOG: Epoch [1751/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1751/2000], Avg Train Loss: 0.4020, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1752/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [1752/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1752/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1753/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4004\n",
      "LOG: Epoch [1753/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1753/2000], Avg Train Loss: 0.4004, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1754/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [1754/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1754/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1755/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3984\n",
      "LOG: Epoch [1755/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1755/2000], Avg Train Loss: 0.3984, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1756/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3984\n",
      "LOG: Epoch [1756/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1756/2000], Avg Train Loss: 0.3984, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1757/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [1757/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1757/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1758/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4006\n",
      "LOG: Epoch [1758/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1758/2000], Avg Train Loss: 0.4006, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1759/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3999\n",
      "LOG: Epoch [1759/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1759/2000], Avg Train Loss: 0.3999, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1760/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3978\n",
      "LOG: Epoch [1760/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1760/2000], Avg Train Loss: 0.3978, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1761/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4040\n",
      "LOG: Epoch [1761/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1761/2000], Avg Train Loss: 0.4040, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1762/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [1762/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1762/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1763/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4073\n",
      "LOG: Epoch [1763/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1763/2000], Avg Train Loss: 0.4073, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1764/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4006\n",
      "LOG: Epoch [1764/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1764/2000], Avg Train Loss: 0.4006, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1765/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [1765/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1765/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1766/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [1766/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1766/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1767/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [1767/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1767/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1768/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4006\n",
      "LOG: Epoch [1768/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1768/2000], Avg Train Loss: 0.4006, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1769/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [1769/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1769/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1770/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [1770/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1770/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1771/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [1771/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1771/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1772/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4074\n",
      "LOG: Epoch [1772/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1772/2000], Avg Train Loss: 0.4074, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1773/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [1773/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1773/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1774/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3983\n",
      "LOG: Epoch [1774/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1774/2000], Avg Train Loss: 0.3983, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1775/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4087\n",
      "LOG: Epoch [1775/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1775/2000], Avg Train Loss: 0.4087, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1776/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4082\n",
      "LOG: Epoch [1776/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1776/2000], Avg Train Loss: 0.4082, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1777/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [1777/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1777/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1778/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [1778/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1778/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1779/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [1779/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1779/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1780/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4002\n",
      "LOG: Epoch [1780/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1780/2000], Avg Train Loss: 0.4002, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1781/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4048\n",
      "LOG: Epoch [1781/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1781/2000], Avg Train Loss: 0.4048, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1782/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4010\n",
      "LOG: Epoch [1782/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1782/2000], Avg Train Loss: 0.4010, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1783/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4081\n",
      "LOG: Epoch [1783/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1783/2000], Avg Train Loss: 0.4081, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1784/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [1784/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1784/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1785/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [1785/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1785/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1786/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [1786/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1786/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1787/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [1787/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1787/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1788/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3986\n",
      "LOG: Epoch [1788/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1788/2000], Avg Train Loss: 0.3986, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1789/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [1789/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1789/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1790/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [1790/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1790/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1791/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4093\n",
      "LOG: Epoch [1791/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1791/2000], Avg Train Loss: 0.4093, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1792/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [1792/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1792/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1793/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [1793/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1793/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1794/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3995\n",
      "LOG: Epoch [1794/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1794/2000], Avg Train Loss: 0.3995, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1795/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3972\n",
      "LOG: Epoch [1795/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1795/2000], Avg Train Loss: 0.3972, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1796/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4084\n",
      "LOG: Epoch [1796/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1796/2000], Avg Train Loss: 0.4084, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1797/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4110\n",
      "LOG: Epoch [1797/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1797/2000], Avg Train Loss: 0.4110, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1798/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4049\n",
      "LOG: Epoch [1798/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1798/2000], Avg Train Loss: 0.4049, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1799/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [1799/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1799/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1800/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [1800/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1800/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1801/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [1801/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1801/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1802/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [1802/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1802/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1803/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3998\n",
      "LOG: Epoch [1803/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1803/2000], Avg Train Loss: 0.3998, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1804/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4009\n",
      "LOG: Epoch [1804/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1804/2000], Avg Train Loss: 0.4009, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1805/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3931\n",
      "LOG: Epoch [1805/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1805/2000], Avg Train Loss: 0.3931, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1806/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [1806/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1806/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1807/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1807/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1807/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1808/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4029\n",
      "LOG: Epoch [1808/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1808/2000], Avg Train Loss: 0.4029, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1809/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4100\n",
      "LOG: Epoch [1809/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1809/2000], Avg Train Loss: 0.4100, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1810/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3982\n",
      "LOG: Epoch [1810/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1810/2000], Avg Train Loss: 0.3982, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1811/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [1811/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1811/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1812/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4077\n",
      "LOG: Epoch [1812/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1812/2000], Avg Train Loss: 0.4077, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1813/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [1813/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1813/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1814/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4048\n",
      "LOG: Epoch [1814/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1814/2000], Avg Train Loss: 0.4048, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1815/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [1815/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1815/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1816/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3989\n",
      "LOG: Epoch [1816/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1816/2000], Avg Train Loss: 0.3989, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1817/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4099\n",
      "LOG: Epoch [1817/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1817/2000], Avg Train Loss: 0.4099, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1818/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4104\n",
      "LOG: Epoch [1818/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1818/2000], Avg Train Loss: 0.4104, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1819/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [1819/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1819/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1820/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3992\n",
      "LOG: Epoch [1820/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1820/2000], Avg Train Loss: 0.3992, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1821/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4012\n",
      "LOG: Epoch [1821/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1821/2000], Avg Train Loss: 0.4012, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1822/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3975\n",
      "LOG: Epoch [1822/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1822/2000], Avg Train Loss: 0.3975, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1823/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4003\n",
      "LOG: Epoch [1823/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1823/2000], Avg Train Loss: 0.4003, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1824/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [1824/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1824/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1825/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3969\n",
      "LOG: Epoch [1825/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1825/2000], Avg Train Loss: 0.3969, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1826/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3954\n",
      "LOG: Epoch [1826/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1826/2000], Avg Train Loss: 0.3954, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1827/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [1827/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1827/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1828/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [1828/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1828/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1829/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [1829/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1829/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1830/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4061\n",
      "LOG: Epoch [1830/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1830/2000], Avg Train Loss: 0.4061, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1831/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4037\n",
      "LOG: Epoch [1831/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1831/2000], Avg Train Loss: 0.4037, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1832/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4038\n",
      "LOG: Epoch [1832/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1832/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1833/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [1833/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1833/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1834/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4058\n",
      "LOG: Epoch [1834/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1834/2000], Avg Train Loss: 0.4058, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1835/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [1835/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1835/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1836/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [1836/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1836/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1837/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [1837/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1837/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1838/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [1838/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1838/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1839/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3999\n",
      "LOG: Epoch [1839/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1839/2000], Avg Train Loss: 0.3999, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1840/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [1840/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1840/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1841/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3973\n",
      "LOG: Epoch [1841/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1841/2000], Avg Train Loss: 0.3973, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1842/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4056\n",
      "LOG: Epoch [1842/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1842/2000], Avg Train Loss: 0.4056, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1843/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [1843/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1843/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1844/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [1844/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1844/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1845/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [1845/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1845/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1846/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [1846/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1846/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1847/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4072\n",
      "LOG: Epoch [1847/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1847/2000], Avg Train Loss: 0.4072, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1848/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [1848/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1848/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1849/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4068\n",
      "LOG: Epoch [1849/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1849/2000], Avg Train Loss: 0.4068, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1850/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4091\n",
      "LOG: Epoch [1850/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1850/2000], Avg Train Loss: 0.4091, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1851/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4001\n",
      "LOG: Epoch [1851/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1851/2000], Avg Train Loss: 0.4001, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1852/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [1852/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1852/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1853/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4104\n",
      "LOG: Epoch [1853/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1853/2000], Avg Train Loss: 0.4104, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1854/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [1854/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1854/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1855/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [1855/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1855/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1856/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4053\n",
      "LOG: Epoch [1856/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1856/2000], Avg Train Loss: 0.4053, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1857/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [1857/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1857/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1858/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4011\n",
      "LOG: Epoch [1858/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1858/2000], Avg Train Loss: 0.4011, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "LOG: Epoch [1859/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4054\n",
      "LOG: Epoch [1859/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1859/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "LOG: Epoch [1860/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [1860/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1860/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "LOG: Epoch [1861/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4027\n",
      "LOG: Epoch [1861/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1861/2000], Avg Train Loss: 0.4027, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "LOG: Epoch [1862/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [1862/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1862/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "LOG: Epoch [1863/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3977\n",
      "LOG: Epoch [1863/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1863/2000], Avg Train Loss: 0.3977, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "LOG: Epoch [1864/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [1864/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1864/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "LOG: Epoch [1865/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4124\n",
      "LOG: Epoch [1865/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1865/2000], Avg Train Loss: 0.4124, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "LOG: Epoch [1866/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [1866/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1866/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "LOG: Epoch [1867/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3991\n",
      "LOG: Epoch [1867/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1867/2000], Avg Train Loss: 0.3991, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "LOG: Epoch [1868/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [1868/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1868/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "LOG: Epoch [1869/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [1869/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1869/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "LOG: Epoch [1870/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3986\n",
      "LOG: Epoch [1870/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1870/2000], Avg Train Loss: 0.3986, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "LOG: Epoch [1871/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [1871/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1871/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "LOG: Epoch [1872/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3992\n",
      "LOG: Epoch [1872/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1872/2000], Avg Train Loss: 0.3992, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "LOG: Epoch [1873/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [1873/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1873/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1874/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [1874/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1874/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1875/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4076\n",
      "LOG: Epoch [1875/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1875/2000], Avg Train Loss: 0.4076, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1876/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4005\n",
      "LOG: Epoch [1876/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1876/2000], Avg Train Loss: 0.4005, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1877/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3999\n",
      "LOG: Epoch [1877/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1877/2000], Avg Train Loss: 0.3999, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1878/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4020\n",
      "LOG: Epoch [1878/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1878/2000], Avg Train Loss: 0.4020, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1879/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4087\n",
      "LOG: Epoch [1879/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1879/2000], Avg Train Loss: 0.4087, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1880/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [1880/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1880/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1881/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [1881/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1881/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1882/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [1882/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1882/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1883/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [1883/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1883/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1884/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4008\n",
      "LOG: Epoch [1884/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1884/2000], Avg Train Loss: 0.4008, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1885/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4052\n",
      "LOG: Epoch [1885/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1885/2000], Avg Train Loss: 0.4052, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1886/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [1886/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1886/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1887/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4093\n",
      "LOG: Epoch [1887/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1887/2000], Avg Train Loss: 0.4093, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1888/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4044\n",
      "LOG: Epoch [1888/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1888/2000], Avg Train Loss: 0.4044, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1889/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [1889/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1889/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1890/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4044\n",
      "LOG: Epoch [1890/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1890/2000], Avg Train Loss: 0.4044, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1891/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4005\n",
      "LOG: Epoch [1891/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1891/2000], Avg Train Loss: 0.4005, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1892/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4085\n",
      "LOG: Epoch [1892/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1892/2000], Avg Train Loss: 0.4085, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1893/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [1893/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1893/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1894/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [1894/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1894/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1895/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4001\n",
      "LOG: Epoch [1895/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1895/2000], Avg Train Loss: 0.4001, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1896/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [1896/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1896/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1897/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [1897/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1897/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1898/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4044\n",
      "LOG: Epoch [1898/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1898/2000], Avg Train Loss: 0.4044, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1899/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4035\n",
      "LOG: Epoch [1899/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1899/2000], Avg Train Loss: 0.4035, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1900/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4054\n",
      "LOG: Epoch [1900/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1900/2000], Avg Train Loss: 0.4054, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1901/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [1901/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1901/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1902/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4117\n",
      "LOG: Epoch [1902/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1902/2000], Avg Train Loss: 0.4117, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1903/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [1903/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1903/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1904/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [1904/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1904/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1905/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4039\n",
      "LOG: Epoch [1905/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1905/2000], Avg Train Loss: 0.4039, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1906/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3960\n",
      "LOG: Epoch [1906/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1906/2000], Avg Train Loss: 0.3960, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1907/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3993\n",
      "LOG: Epoch [1907/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1907/2000], Avg Train Loss: 0.3993, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1908/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [1908/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1908/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1909/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4077\n",
      "LOG: Epoch [1909/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1909/2000], Avg Train Loss: 0.4077, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1910/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1910/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1910/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1911/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4038\n",
      "LOG: Epoch [1911/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1911/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1912/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3947\n",
      "LOG: Epoch [1912/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1912/2000], Avg Train Loss: 0.3947, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1913/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4075\n",
      "LOG: Epoch [1913/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1913/2000], Avg Train Loss: 0.4075, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1914/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4004\n",
      "LOG: Epoch [1914/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1914/2000], Avg Train Loss: 0.4004, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1915/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4086\n",
      "LOG: Epoch [1915/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1915/2000], Avg Train Loss: 0.4086, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1916/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3994\n",
      "LOG: Epoch [1916/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1916/2000], Avg Train Loss: 0.3994, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1917/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4020\n",
      "LOG: Epoch [1917/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1917/2000], Avg Train Loss: 0.4020, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1918/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [1918/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1918/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1919/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4004\n",
      "LOG: Epoch [1919/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1919/2000], Avg Train Loss: 0.4004, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1920/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4014\n",
      "LOG: Epoch [1920/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1920/2000], Avg Train Loss: 0.4014, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1921/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4001\n",
      "LOG: Epoch [1921/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1921/2000], Avg Train Loss: 0.4001, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1922/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3991\n",
      "LOG: Epoch [1922/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1922/2000], Avg Train Loss: 0.3991, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1923/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4120\n",
      "LOG: Epoch [1923/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1923/2000], Avg Train Loss: 0.4120, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1924/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [1924/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1924/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1925/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4069\n",
      "LOG: Epoch [1925/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1925/2000], Avg Train Loss: 0.4069, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1926/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3988\n",
      "LOG: Epoch [1926/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1926/2000], Avg Train Loss: 0.3988, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1927/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3985\n",
      "LOG: Epoch [1927/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1927/2000], Avg Train Loss: 0.3985, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1928/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [1928/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1928/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1929/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3985\n",
      "LOG: Epoch [1929/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1929/2000], Avg Train Loss: 0.3985, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1930/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [1930/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1930/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1931/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1931/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1931/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1932/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4034\n",
      "LOG: Epoch [1932/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1932/2000], Avg Train Loss: 0.4034, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1933/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4123\n",
      "LOG: Epoch [1933/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1933/2000], Avg Train Loss: 0.4123, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1934/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4055\n",
      "LOG: Epoch [1934/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1934/2000], Avg Train Loss: 0.4055, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [1935/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3984\n",
      "LOG: Epoch [1935/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1935/2000], Avg Train Loss: 0.3984, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "LOG: Epoch [1936/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4000\n",
      "LOG: Epoch [1936/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1936/2000], Avg Train Loss: 0.4000, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "LOG: Epoch [1937/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3950\n",
      "LOG: Epoch [1937/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1937/2000], Avg Train Loss: 0.3950, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "LOG: Epoch [1938/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [1938/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1938/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "LOG: Epoch [1939/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4013\n",
      "LOG: Epoch [1939/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1939/2000], Avg Train Loss: 0.4013, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "LOG: Epoch [1940/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4067\n",
      "LOG: Epoch [1940/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1940/2000], Avg Train Loss: 0.4067, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "LOG: Epoch [1941/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3993\n",
      "LOG: Epoch [1941/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1941/2000], Avg Train Loss: 0.3993, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "LOG: Epoch [1942/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4045\n",
      "LOG: Epoch [1942/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1942/2000], Avg Train Loss: 0.4045, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "LOG: Epoch [1943/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3957\n",
      "LOG: Epoch [1943/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1943/2000], Avg Train Loss: 0.3957, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "LOG: Epoch [1944/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4031\n",
      "LOG: Epoch [1944/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1944/2000], Avg Train Loss: 0.4031, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "LOG: Epoch [1945/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4044\n",
      "LOG: Epoch [1945/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1945/2000], Avg Train Loss: 0.4044, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "LOG: Epoch [1946/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4017\n",
      "LOG: Epoch [1946/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1946/2000], Avg Train Loss: 0.4017, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "LOG: Epoch [1947/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1947/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1947/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "LOG: Epoch [1948/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3941\n",
      "LOG: Epoch [1948/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1948/2000], Avg Train Loss: 0.3941, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "LOG: Epoch [1949/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [1949/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1949/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "LOG: Epoch [1950/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [1950/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1950/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "LOG: Epoch [1951/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4036\n",
      "LOG: Epoch [1951/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1951/2000], Avg Train Loss: 0.4036, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "LOG: Epoch [1952/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4007\n",
      "LOG: Epoch [1952/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1952/2000], Avg Train Loss: 0.4007, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "LOG: Epoch [1953/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4003\n",
      "LOG: Epoch [1953/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1953/2000], Avg Train Loss: 0.4003, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "LOG: Epoch [1954/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4079\n",
      "LOG: Epoch [1954/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1954/2000], Avg Train Loss: 0.4079, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "LOG: Epoch [1955/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1955/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1955/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "LOG: Epoch [1956/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4094\n",
      "LOG: Epoch [1956/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1956/2000], Avg Train Loss: 0.4094, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "LOG: Epoch [1957/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [1957/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1957/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "LOG: Epoch [1958/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [1958/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1958/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1959/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4007\n",
      "LOG: Epoch [1959/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1959/2000], Avg Train Loss: 0.4007, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1960/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3998\n",
      "LOG: Epoch [1960/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1960/2000], Avg Train Loss: 0.3998, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1961/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4047\n",
      "LOG: Epoch [1961/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1961/2000], Avg Train Loss: 0.4047, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1962/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4033\n",
      "LOG: Epoch [1962/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1962/2000], Avg Train Loss: 0.4033, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1963/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3962\n",
      "LOG: Epoch [1963/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1963/2000], Avg Train Loss: 0.3962, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1964/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4113\n",
      "LOG: Epoch [1964/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1964/2000], Avg Train Loss: 0.4113, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1965/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4025\n",
      "LOG: Epoch [1965/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1965/2000], Avg Train Loss: 0.4025, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1966/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4066\n",
      "LOG: Epoch [1966/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1966/2000], Avg Train Loss: 0.4066, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1967/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3975\n",
      "LOG: Epoch [1967/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1967/2000], Avg Train Loss: 0.3975, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1968/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [1968/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1968/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1969/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4063\n",
      "LOG: Epoch [1969/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1969/2000], Avg Train Loss: 0.4063, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1970/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4043\n",
      "LOG: Epoch [1970/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1970/2000], Avg Train Loss: 0.4043, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1971/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4026\n",
      "LOG: Epoch [1971/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1971/2000], Avg Train Loss: 0.4026, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1972/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4056\n",
      "LOG: Epoch [1972/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1972/2000], Avg Train Loss: 0.4056, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1973/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4030\n",
      "LOG: Epoch [1973/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1973/2000], Avg Train Loss: 0.4030, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1974/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [1974/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1974/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1975/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4023\n",
      "LOG: Epoch [1975/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1975/2000], Avg Train Loss: 0.4023, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1976/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4038\n",
      "LOG: Epoch [1976/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1976/2000], Avg Train Loss: 0.4038, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1977/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4050\n",
      "LOG: Epoch [1977/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1977/2000], Avg Train Loss: 0.4050, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1978/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3974\n",
      "LOG: Epoch [1978/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1978/2000], Avg Train Loss: 0.3974, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1979/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4015\n",
      "LOG: Epoch [1979/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1979/2000], Avg Train Loss: 0.4015, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1980/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4042\n",
      "LOG: Epoch [1980/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1980/2000], Avg Train Loss: 0.4042, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1981/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4021\n",
      "LOG: Epoch [1981/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1981/2000], Avg Train Loss: 0.4021, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1982/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4020\n",
      "LOG: Epoch [1982/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1982/2000], Avg Train Loss: 0.4020, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1983/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4020\n",
      "LOG: Epoch [1983/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1983/2000], Avg Train Loss: 0.4020, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1984/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4057\n",
      "LOG: Epoch [1984/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1984/2000], Avg Train Loss: 0.4057, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1985/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4099\n",
      "LOG: Epoch [1985/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1985/2000], Avg Train Loss: 0.4099, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1986/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4051\n",
      "LOG: Epoch [1986/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1986/2000], Avg Train Loss: 0.4051, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1987/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4058\n",
      "LOG: Epoch [1987/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1987/2000], Avg Train Loss: 0.4058, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1988/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4041\n",
      "LOG: Epoch [1988/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1988/2000], Avg Train Loss: 0.4041, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1989/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4000\n",
      "LOG: Epoch [1989/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1989/2000], Avg Train Loss: 0.4000, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1990/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4006\n",
      "LOG: Epoch [1990/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1990/2000], Avg Train Loss: 0.4006, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1991/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4019\n",
      "LOG: Epoch [1991/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1991/2000], Avg Train Loss: 0.4019, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1992/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3997\n",
      "LOG: Epoch [1992/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1992/2000], Avg Train Loss: 0.3997, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1993/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4049\n",
      "LOG: Epoch [1993/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1993/2000], Avg Train Loss: 0.4049, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1994/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4064\n",
      "LOG: Epoch [1994/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1994/2000], Avg Train Loss: 0.4064, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1995/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.3961\n",
      "LOG: Epoch [1995/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1995/2000], Avg Train Loss: 0.3961, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1996/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4065\n",
      "LOG: Epoch [1996/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1996/2000], Avg Train Loss: 0.4065, Avg Val Loss: 0.2540\n",
      "\n",
      "Validation loss improved from 0.2540 to 0.2540. Saving model...\n",
      "LOG: Epoch [1997/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4018\n",
      "LOG: Epoch [1997/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1997/2000], Avg Train Loss: 0.4018, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "LOG: Epoch [1998/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4046\n",
      "LOG: Epoch [1998/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1998/2000], Avg Train Loss: 0.4046, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "LOG: Epoch [1999/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4013\n",
      "LOG: Epoch [1999/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [1999/2000], Avg Train Loss: 0.4013, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "LOG: Epoch [2000/2000] - Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch [1/1], Train Loss: 0.4016\n",
      "LOG: Epoch [2000/2000] - Validation\n",
      "    Batch [1/2], Val Loss: 0.4048\n",
      "    Batch [2/2], Val Loss: 0.1032\n",
      "Epoch [2000/2000], Avg Train Loss: 0.4016, Avg Val Loss: 0.2540\n",
      "\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_model = SupConNet().to(device)\n",
    "sclsdl_criterion = SilhouetteDistanceLoss()\n",
    "sclsdl_optimizer = optim.AdamW(sclsdl_model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "sclsdl_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    sclsdl_optimizer, \n",
    "    mode='min',\n",
    "    patience=25,\n",
    "    factor=0.1\n",
    ")\n",
    "\n",
    "sclsdl_num_epochs = 2000\n",
    "\n",
    "sclsdl_patience = 100\n",
    "sclsdl_best_val_loss = float('inf')\n",
    "sclsdl_epochs_without_improvement = 0\n",
    "\n",
    "sclsdl_train_loss_history = []\n",
    "sclsdl_val_loss_history = []\n",
    "\n",
    "for sclsdl_epoch in range(sclsdl_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_model.train()\n",
    "    sclsdl_running_train_loss = 0.0\n",
    "    \n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Training\")\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_train_loader):\n",
    "\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_train_projections = sclsdl_model(vectors)\n",
    "\n",
    "        sclsdl_loss = sclsdl_criterion(sclsdl_train_projections, labels)\n",
    "\n",
    "        # Backprop and optimize\n",
    "        sclsdl_optimizer.zero_grad()\n",
    "        sclsdl_loss.backward()\n",
    "        sclsdl_optimizer.step()\n",
    "\n",
    "        sclsdl_running_train_loss += sclsdl_loss.item()\n",
    "        print(f\"    Batch [{batch_idx+1}/{len(sclsdl_train_loader)}], Train Loss: {sclsdl_loss.item():.4f}\")\n",
    "\n",
    "    sclsdl_train_epoch_loss = sclsdl_running_train_loss / len(sclsdl_train_loader)\n",
    "    sclsdl_train_loss_history.append(sclsdl_train_epoch_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_model.eval()\n",
    "    sclsdl_running_val_loss = 0.0\n",
    "    print(f\"LOG: Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}] - Validation\")\n",
    "    with torch.no_grad():\n",
    "        for val_batch_idx, (vectors, labels) in enumerate(sclsdl_val_loader):\n",
    "\n",
    "            vectors = vectors.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            sclsdl_val_projections = sclsdl_model(vectors)\n",
    "            sclsdl_val_batch_loss = sclsdl_criterion(sclsdl_val_projections, labels).item()\n",
    "            sclsdl_running_val_loss += sclsdl_val_batch_loss\n",
    "            print(f\"    Batch [{val_batch_idx+1}/{len(sclsdl_val_loader)}], Val Loss: {sclsdl_val_batch_loss:.4f}\")\n",
    "\n",
    "    sclsdl_val_epoch_loss = sclsdl_running_val_loss / len(sclsdl_val_loader)\n",
    "    sclsdl_val_loss_history.append(sclsdl_val_epoch_loss)\n",
    "    \n",
    "    sclsdl_scheduler.step(sclsdl_val_epoch_loss)\n",
    "\n",
    "    print(f\"Epoch [{sclsdl_epoch+1}/{sclsdl_num_epochs}], \"\n",
    "          f\"Avg Train Loss: {sclsdl_train_epoch_loss:.4f}, \"\n",
    "          f\"Avg Val Loss: {sclsdl_val_epoch_loss:.4f}\\n\")\n",
    "    \n",
    "    #early stopping logic\n",
    "    if sclsdl_val_epoch_loss < sclsdl_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_best_val_loss:.4f} to {sclsdl_val_epoch_loss:.4f}. Saving model...\")\n",
    "        sclsdl_best_val_loss = sclsdl_val_epoch_loss\n",
    "        sclsdl_epochs_without_improvement = 0\n",
    "    else:\n",
    "        sclsdl_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! Patience: {sclsdl_epochs_without_improvement}/{sclsdl_patience}\")\n",
    "\n",
    "    #stop training if val loss not improving\n",
    "    if sclsdl_epochs_without_improvement >= sclsdl_patience:\n",
    "        print(f\"!! Early stopping triggered at epoch {sclsdl_epoch + 1}!!\\nNo improvement for {sclsdl_patience} epochs\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Silhouette Distance Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:50:17.482935Z",
     "iopub.status.busy": "2025-05-08T18:50:17.481935Z",
     "iopub.status.idle": "2025-05-08T18:50:17.734000Z",
     "shell.execute_reply": "2025-05-08T18:50:17.734000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [10/48], Loss: 0.3087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch [20/48], Loss: 0.2200\n",
      "Test Batch [30/48], Loss: 0.2526\n",
      "Test Batch [40/48], Loss: 0.5000\n",
      "\n",
      "Test Loss: 0.2969\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "sclsdl_model.eval()\n",
    "sclsdl_total_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (vectors, labels) in enumerate(sclsdl_test_loader):\n",
    "        vectors = vectors.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        projections = sclsdl_model(vectors)\n",
    "        loss = sclsdl_criterion(projections, labels)\n",
    "        sclsdl_total_test_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Test Batch [{batch_idx + 1}/{len(sclsdl_test_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "sclsdl_avg_test_loss = sclsdl_total_test_loss / len(sclsdl_test_loader)\n",
    "print(f\"\\nTest Loss: {sclsdl_avg_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sclsdl_num_epochs_run = len(sclsdl_train_loss_history)\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_train_loss_history, label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_num_epochs_run + 1), sclsdl_val_loss_history, label='Val Loss')\n",
    "# test loss = horizontal dashed line\n",
    "plt.axhline(y=sclsdl_avg_test_loss, color='r', linestyle='--', label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the representations learnt by SCL w/ SDL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:50:17.736006Z",
     "iopub.status.busy": "2025-05-08T18:50:17.736006Z",
     "iopub.status.idle": "2025-05-08T18:50:18.158084Z",
     "shell.execute_reply": "2025-05-08T18:50:18.158084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting SCL_SDL representations for the train dataset...\n",
      "Completed extraction for the train dataset. Representations saved in 'sclsdl_representations\\train'.\n",
      "\n",
      "Extracting SCL_SDL representations for the val dataset...\n",
      "Completed extraction for the val dataset. Representations saved in 'sclsdl_representations\\val'.\n",
      "\n",
      "Extracting SCL_SDL representations for the test dataset...\n",
      "  Processed batch 10/48 for test dataset.\n",
      "  Processed batch 20/48 for test dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed batch 30/48 for test dataset.\n",
      "  Processed batch 40/48 for test dataset.\n",
      "Completed extraction for the test dataset. Representations saved in 'sclsdl_representations\\test'.\n",
      "SCL representations extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# dir to save the SCL representations\n",
    "sclsdl_rep_dir = \"sclsdl_representations\"\n",
    "os.makedirs(sclsdl_rep_dir, exist_ok=True)\n",
    "\n",
    "sclsdl_loaders = {\n",
    "    'train': sclsdl_train_loader,\n",
    "    'val': sclsdl_val_loader,\n",
    "    'test': sclsdl_test_loader\n",
    "}\n",
    "\n",
    "sclsdl_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_split_name, sclsdl_loader in sclsdl_loaders.items():\n",
    "        print(f\"\\nExtracting SCL_SDL representations for the {sclsdl_split_name} dataset...\")\n",
    "        # creating subfolder for the split\n",
    "        sclsdl_split_dir = os.path.join(sclsdl_rep_dir, sclsdl_split_name)\n",
    "        os.makedirs(sclsdl_split_dir, exist_ok=True)\n",
    "        \n",
    "        # processing the data batch-wise\n",
    "        for sclsdl_batch_idx, (sclsdl_vectors, sclsdl_labels) in enumerate(sclsdl_loader):\n",
    "            sclsdl_vectors = sclsdl_vectors.to(device).float()\n",
    "            # computing projections using the trained SCL model\n",
    "            sclsdl_projections = sclsdl_model(sclsdl_vectors)\n",
    "            \n",
    "            # converting projections and labels to np arrays\n",
    "            sclsdl_projections_np = sclsdl_projections.cpu().numpy()\n",
    "            sclsdl_labels_np = sclsdl_labels.cpu().numpy()\n",
    "            \n",
    "            # saving the batch projections and labels\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_encoded_batch_{sclsdl_batch_idx}.npy\"), sclsdl_projections_np)\n",
    "            np.save(os.path.join(sclsdl_split_dir, f\"scl_labels_batch_{sclsdl_batch_idx}.npy\"), sclsdl_labels_np)\n",
    "            \n",
    "            if (sclsdl_batch_idx + 1) % 10 == 0:\n",
    "                print(f\"  Processed batch {sclsdl_batch_idx + 1}/{len(sclsdl_loader)} for {sclsdl_split_name} dataset.\")\n",
    "\n",
    "        print(f\"Completed extraction for the {sclsdl_split_name} dataset. Representations saved in '{sclsdl_split_dir}'.\")\n",
    "\n",
    "print(\"SCL representations extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying the representations learnt by SCL w/ SDL Model with LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:50:18.160088Z",
     "iopub.status.busy": "2025-05-08T18:50:18.160088Z",
     "iopub.status.idle": "2025-05-08T18:50:18.164087Z",
     "shell.execute_reply": "2025-05-08T18:50:18.164087Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_sclsdl_reps_and_labels(split_dir):\n",
    "    #gather all the scl_encoded_batch npy files in sorted order\n",
    "    sclsdl_rep_files = sorted(glob.glob(os.path.join(split_dir, \"scl_encoded_batch_*.npy\")))\n",
    "\n",
    "    sclsdl_all_reps = []\n",
    "    sclsdl_all_labels = []\n",
    "\n",
    "    for sclsdl_rep_file in sclsdl_rep_files:\n",
    "        #deriving label filenames\n",
    "        sclsdl_label_file = sclsdl_rep_file.replace(\"scl_encoded_batch_\", \"scl_labels_batch_\")\n",
    "\n",
    "        sclsdl_reps = np.load(sclsdl_rep_file)\n",
    "        sclsdl_labels = np.load(sclsdl_label_file)\n",
    "\n",
    "        sclsdl_all_reps.append(sclsdl_reps)\n",
    "        sclsdl_all_labels.append(sclsdl_labels)\n",
    "\n",
    "    #concat along first dim\n",
    "    sclsdl_all_reps = np.concatenate(sclsdl_all_reps, axis = 0)\n",
    "    sclsdl_all_labels = np.concatenate(sclsdl_all_labels, axis = 0)\n",
    "\n",
    "    return sclsdl_all_reps, sclsdl_all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:50:18.165372Z",
     "iopub.status.busy": "2025-05-08T18:50:18.165372Z",
     "iopub.status.idle": "2025-05-08T18:50:18.659159Z",
     "shell.execute_reply": "2025-05-08T18:50:18.659159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (140, 128)\n",
      "Train labels shape: (140,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (3038, 128)\n",
      "Test labels shape: (3038,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_lrm_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_lrm_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_lrm_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_lrm_train_reps, sclsdl_lrm_train_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_train_dir)\n",
    "sclsdl_lrm_val_reps, sclsdl_lrm_val_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_val_dir)\n",
    "sclsdl_lrm_test_reps, sclsdl_lrm_test_labels = load_sclsdl_reps_and_labels(sclsdl_lrm_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_lrm_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_lrm_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_lrm_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_lrm_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_lrm_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_lrm_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:50:18.662168Z",
     "iopub.status.busy": "2025-05-08T18:50:18.661168Z",
     "iopub.status.idle": "2025-05-08T18:50:18.692163Z",
     "shell.execute_reply": "2025-05-08T18:50:18.692163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOG: Training Logistic Regression model on SCL SDL representations...\n",
      "LOG: Logistic Regression training complete.\n",
      "\n",
      "LOG: Evaluating on the validation set...\n",
      "Validation Accuracy: 81.43%\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       1.00      0.60      0.75         5\n",
      "           3       0.83      1.00      0.91         5\n",
      "           4       1.00      0.60      0.75         5\n",
      "           5       1.00      0.60      0.75         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.71      1.00      0.83         5\n",
      "           8       0.67      0.80      0.73         5\n",
      "           9       0.50      1.00      0.67         5\n",
      "          10       1.00      0.20      0.33         5\n",
      "          11       0.83      1.00      0.91         5\n",
      "          12       0.60      0.60      0.60         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.81        70\n",
      "   macro avg       0.87      0.81      0.80        70\n",
      "weighted avg       0.87      0.81      0.80        70\n",
      "\n",
      "\n",
      "LOG: Evaluating on the test set...\n",
      "Test Accuracy: 82.92%\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       255\n",
      "           1       0.82      0.91      0.86        86\n",
      "           2       0.85      0.89      0.87       236\n",
      "           3       0.70      0.94      0.80       200\n",
      "           4       0.85      0.69      0.76       254\n",
      "           5       0.70      0.51      0.59       254\n",
      "           6       0.99      0.88      0.93       244\n",
      "           7       0.72      0.91      0.80       188\n",
      "           8       0.72      0.69      0.71       299\n",
      "           9       0.75      0.96      0.84       233\n",
      "          10       0.94      0.76      0.84       290\n",
      "          11       0.92      0.97      0.94       166\n",
      "          12       0.81      0.84      0.83       253\n",
      "          13       1.00      0.94      0.97        80\n",
      "\n",
      "    accuracy                           0.83      3038\n",
      "   macro avg       0.84      0.85      0.84      3038\n",
      "weighted avg       0.84      0.83      0.83      3038\n",
      "\n",
      "Saved SCL_SDL+LRM predictions and true labels to model_predictions\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression Model on the SCLSDL representations\n",
    "print(\"\\nLOG: Training Logistic Regression model on SCL SDL representations...\")\n",
    "sclsdl_logistic_clf = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced')\n",
    "sclsdl_logistic_clf.fit(sclsdl_lrm_train_reps, sclsdl_lrm_train_labels)\n",
    "print(\"LOG: Logistic Regression training complete.\")\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "print(\"\\nLOG: Evaluating on the validation set...\")\n",
    "sclsdl_lrm_val_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_val_reps)\n",
    "sclsdl_lrm_val_accuracy = accuracy_score(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions)\n",
    "print(f\"Validation Accuracy: {sclsdl_lrm_val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Classification Report:\\n\", classification_report(sclsdl_lrm_val_labels, sclsdl_lrm_val_predictions))\n",
    "\n",
    "# Evaluate on Test Set\n",
    "print(\"\\nLOG: Evaluating on the test set...\")\n",
    "sclsdl_lrm_test_predictions = sclsdl_logistic_clf.predict(sclsdl_lrm_test_reps)\n",
    "sclsdl_lrm_test_accuracy = accuracy_score(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions)\n",
    "print(f\"Test Accuracy: {sclsdl_lrm_test_accuracy * 100:.2f}%\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(sclsdl_lrm_test_labels, sclsdl_lrm_test_predictions))\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_predictions.npy'), sclsdl_lrm_test_predictions)\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_lrm_true_labels.npy'), sclsdl_lrm_test_labels)\n",
    "print(f\"Saved SCL_SDL+LRM predictions and true labels to {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the representations learnt by SCL w/ SDL Model with MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:50:18.695425Z",
     "iopub.status.busy": "2025-05-08T18:50:18.694424Z",
     "iopub.status.idle": "2025-05-08T18:50:18.715618Z",
     "shell.execute_reply": "2025-05-08T18:50:18.715618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reps shape: (140, 128)\n",
      "Train labels shape: (140,)\n",
      "Val reps shape: (70, 128)\n",
      "Val labels shape: (70,)\n",
      "Test reps shape: (3038, 128)\n",
      "Test labels shape: (3038,)\n"
     ]
    }
   ],
   "source": [
    "sclsdl_mlp_train_dir = os.path.join(\"sclsdl_representations\", \"train\")\n",
    "sclsdl_mlp_val_dir   = os.path.join(\"sclsdl_representations\", \"val\")\n",
    "sclsdl_mlp_test_dir  = os.path.join(\"sclsdl_representations\", \"test\")\n",
    "\n",
    "sclsdl_mlp_train_reps, sclsdl_mlp_train_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_train_dir)\n",
    "sclsdl_mlp_val_reps, sclsdl_mlp_val_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_val_dir)\n",
    "sclsdl_mlp_test_reps, sclsdl_mlp_test_labels = load_sclsdl_reps_and_labels(sclsdl_mlp_test_dir)\n",
    "\n",
    "print(\"Train reps shape:\", sclsdl_mlp_train_reps.shape)\n",
    "print(\"Train labels shape:\", sclsdl_mlp_train_labels.shape)\n",
    "\n",
    "print(\"Val reps shape:\", sclsdl_mlp_val_reps.shape)\n",
    "print(\"Val labels shape:\", sclsdl_mlp_val_labels.shape)\n",
    "\n",
    "print(\"Test reps shape:\", sclsdl_mlp_test_reps.shape)\n",
    "print(\"Test labels shape:\", sclsdl_mlp_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:50:18.718134Z",
     "iopub.status.busy": "2025-05-08T18:50:18.718134Z",
     "iopub.status.idle": "2025-05-08T18:50:18.722455Z",
     "shell.execute_reply": "2025-05-08T18:50:18.722455Z"
    }
   },
   "outputs": [],
   "source": [
    "#converting arrays to torch tensors\n",
    "sclsdl_mlp_train_embeddings_torch = torch.tensor(sclsdl_mlp_train_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_train_labels_torch = torch.tensor(sclsdl_mlp_train_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_val_embeddings_torch = torch.tensor(sclsdl_mlp_val_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_val_labels_torch = torch.tensor(sclsdl_mlp_val_labels, dtype=torch.long)\n",
    "\n",
    "sclsdl_mlp_test_embeddings_torch = torch.tensor(sclsdl_mlp_test_reps, dtype=torch.float32)\n",
    "sclsdl_mlp_test_labels_torch = torch.tensor(sclsdl_mlp_test_labels, dtype=torch.long)\n",
    "\n",
    "#building datasets for mlp\n",
    "sclsdl_mlp_train_dataset = TensorDataset(sclsdl_mlp_train_embeddings_torch, sclsdl_mlp_train_labels_torch)\n",
    "sclsdl_mlp_val_dataset = TensorDataset(sclsdl_mlp_val_embeddings_torch, sclsdl_mlp_val_labels_torch)\n",
    "sclsdl_mlp_test_dataset = TensorDataset(sclsdl_mlp_test_embeddings_torch, sclsdl_mlp_test_labels_torch)\n",
    "\n",
    "sclsdl_mlp_batch_size = 64\n",
    "sclsdl_mlp_train_loader = DataLoader(sclsdl_mlp_train_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=True)\n",
    "sclsdl_mlp_val_loader = DataLoader(sclsdl_mlp_val_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n",
    "sclsdl_mlp_test_loader = DataLoader(sclsdl_mlp_test_dataset, batch_size=sclsdl_mlp_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:50:18.725460Z",
     "iopub.status.busy": "2025-05-08T18:50:18.725460Z",
     "iopub.status.idle": "2025-05-08T18:50:23.665183Z",
     "shell.execute_reply": "2025-05-08T18:50:23.665183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/1000] Train Loss: 2.7166  |  Val Loss: 2.7013\n",
      "Validation loss improved from inf to 2.7013.\n",
      "[Epoch 2/1000] Train Loss: 2.6996  |  Val Loss: 2.6875\n",
      "Validation loss improved from 2.7013 to 2.6875.\n",
      "[Epoch 3/1000] Train Loss: 2.6846  |  Val Loss: 2.6744\n",
      "Validation loss improved from 2.6875 to 2.6744.\n",
      "[Epoch 4/1000] Train Loss: 2.6690  |  Val Loss: 2.6615\n",
      "Validation loss improved from 2.6744 to 2.6615.\n",
      "[Epoch 5/1000] Train Loss: 2.6537  |  Val Loss: 2.6483\n",
      "Validation loss improved from 2.6615 to 2.6483.\n",
      "[Epoch 6/1000] Train Loss: 2.6404  |  Val Loss: 2.6356\n",
      "Validation loss improved from 2.6483 to 2.6356.\n",
      "[Epoch 7/1000] Train Loss: 2.6253  |  Val Loss: 2.6238\n",
      "Validation loss improved from 2.6356 to 2.6238.\n",
      "[Epoch 8/1000] Train Loss: 2.6118  |  Val Loss: 2.6121\n",
      "Validation loss improved from 2.6238 to 2.6121.\n",
      "[Epoch 9/1000] Train Loss: 2.5988  |  Val Loss: 2.6006\n",
      "Validation loss improved from 2.6121 to 2.6006.\n",
      "[Epoch 10/1000] Train Loss: 2.5864  |  Val Loss: 2.5891\n",
      "Validation loss improved from 2.6006 to 2.5891.\n",
      "[Epoch 11/1000] Train Loss: 2.5742  |  Val Loss: 2.5781\n",
      "Validation loss improved from 2.5891 to 2.5781.\n",
      "[Epoch 12/1000] Train Loss: 2.5618  |  Val Loss: 2.5672\n",
      "Validation loss improved from 2.5781 to 2.5672.\n",
      "[Epoch 13/1000] Train Loss: 2.5499  |  Val Loss: 2.5564\n",
      "Validation loss improved from 2.5672 to 2.5564.\n",
      "[Epoch 14/1000] Train Loss: 2.5379  |  Val Loss: 2.5456\n",
      "Validation loss improved from 2.5564 to 2.5456.\n",
      "[Epoch 15/1000] Train Loss: 2.5261  |  Val Loss: 2.5347\n",
      "Validation loss improved from 2.5456 to 2.5347.\n",
      "[Epoch 16/1000] Train Loss: 2.5142  |  Val Loss: 2.5234\n",
      "Validation loss improved from 2.5347 to 2.5234.\n",
      "[Epoch 17/1000] Train Loss: 2.5028  |  Val Loss: 2.5126\n",
      "Validation loss improved from 2.5234 to 2.5126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/1000] Train Loss: 2.4902  |  Val Loss: 2.5024\n",
      "Validation loss improved from 2.5126 to 2.5024.\n",
      "[Epoch 19/1000] Train Loss: 2.4783  |  Val Loss: 2.4924\n",
      "Validation loss improved from 2.5024 to 2.4924.\n",
      "[Epoch 20/1000] Train Loss: 2.4668  |  Val Loss: 2.4821\n",
      "Validation loss improved from 2.4924 to 2.4821.\n",
      "[Epoch 21/1000] Train Loss: 2.4558  |  Val Loss: 2.4715\n",
      "Validation loss improved from 2.4821 to 2.4715.\n",
      "[Epoch 22/1000] Train Loss: 2.4449  |  Val Loss: 2.4617\n",
      "Validation loss improved from 2.4715 to 2.4617.\n",
      "[Epoch 23/1000] Train Loss: 2.4343  |  Val Loss: 2.4526\n",
      "Validation loss improved from 2.4617 to 2.4526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/1000] Train Loss: 2.4238  |  Val Loss: 2.4438\n",
      "Validation loss improved from 2.4526 to 2.4438.\n",
      "[Epoch 25/1000] Train Loss: 2.4137  |  Val Loss: 2.4350\n",
      "Validation loss improved from 2.4438 to 2.4350.\n",
      "[Epoch 26/1000] Train Loss: 2.4037  |  Val Loss: 2.4263\n",
      "Validation loss improved from 2.4350 to 2.4263.\n",
      "[Epoch 27/1000] Train Loss: 2.3936  |  Val Loss: 2.4174\n",
      "Validation loss improved from 2.4263 to 2.4174.\n",
      "[Epoch 28/1000] Train Loss: 2.3837  |  Val Loss: 2.4085\n",
      "Validation loss improved from 2.4174 to 2.4085.\n",
      "[Epoch 29/1000] Train Loss: 2.3737  |  Val Loss: 2.3996\n",
      "Validation loss improved from 2.4085 to 2.3996.\n",
      "[Epoch 30/1000] Train Loss: 2.3636  |  Val Loss: 2.3908\n",
      "Validation loss improved from 2.3996 to 2.3908.\n",
      "[Epoch 31/1000] Train Loss: 2.3540  |  Val Loss: 2.3819\n",
      "Validation loss improved from 2.3908 to 2.3819.\n",
      "[Epoch 32/1000] Train Loss: 2.3442  |  Val Loss: 2.3732\n",
      "Validation loss improved from 2.3819 to 2.3732.\n",
      "[Epoch 33/1000] Train Loss: 2.3342  |  Val Loss: 2.3648\n",
      "Validation loss improved from 2.3732 to 2.3648.\n",
      "[Epoch 34/1000] Train Loss: 2.3244  |  Val Loss: 2.3565\n",
      "Validation loss improved from 2.3648 to 2.3565.\n",
      "[Epoch 35/1000] Train Loss: 2.3148  |  Val Loss: 2.3482\n",
      "Validation loss improved from 2.3565 to 2.3482.\n",
      "[Epoch 36/1000] Train Loss: 2.3050  |  Val Loss: 2.3400\n",
      "Validation loss improved from 2.3482 to 2.3400.\n",
      "[Epoch 37/1000] Train Loss: 2.2953  |  Val Loss: 2.3320\n",
      "Validation loss improved from 2.3400 to 2.3320.\n",
      "[Epoch 38/1000] Train Loss: 2.2854  |  Val Loss: 2.3237\n",
      "Validation loss improved from 2.3320 to 2.3237.\n",
      "[Epoch 39/1000] Train Loss: 2.2755  |  Val Loss: 2.3150\n",
      "Validation loss improved from 2.3237 to 2.3150.\n",
      "[Epoch 40/1000] Train Loss: 2.2652  |  Val Loss: 2.3060\n",
      "Validation loss improved from 2.3150 to 2.3060.\n",
      "[Epoch 41/1000] Train Loss: 2.2552  |  Val Loss: 2.2970\n",
      "Validation loss improved from 2.3060 to 2.2970.\n",
      "[Epoch 42/1000] Train Loss: 2.2446  |  Val Loss: 2.2883\n",
      "Validation loss improved from 2.2970 to 2.2883.\n",
      "[Epoch 43/1000] Train Loss: 2.2343  |  Val Loss: 2.2795\n",
      "Validation loss improved from 2.2883 to 2.2795.\n",
      "[Epoch 44/1000] Train Loss: 2.2238  |  Val Loss: 2.2706\n",
      "Validation loss improved from 2.2795 to 2.2706.\n",
      "[Epoch 45/1000] Train Loss: 2.2129  |  Val Loss: 2.2616\n",
      "Validation loss improved from 2.2706 to 2.2616.\n",
      "[Epoch 46/1000] Train Loss: 2.2022  |  Val Loss: 2.2526\n",
      "Validation loss improved from 2.2616 to 2.2526.\n",
      "[Epoch 47/1000] Train Loss: 2.1916  |  Val Loss: 2.2432\n",
      "Validation loss improved from 2.2526 to 2.2432.\n",
      "[Epoch 48/1000] Train Loss: 2.1804  |  Val Loss: 2.2338\n",
      "Validation loss improved from 2.2432 to 2.2338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 49/1000] Train Loss: 2.1691  |  Val Loss: 2.2244\n",
      "Validation loss improved from 2.2338 to 2.2244.\n",
      "[Epoch 50/1000] Train Loss: 2.1585  |  Val Loss: 2.2152\n",
      "Validation loss improved from 2.2244 to 2.2152.\n",
      "[Epoch 51/1000] Train Loss: 2.1473  |  Val Loss: 2.2062\n",
      "Validation loss improved from 2.2152 to 2.2062.\n",
      "[Epoch 52/1000] Train Loss: 2.1363  |  Val Loss: 2.1970\n",
      "Validation loss improved from 2.2062 to 2.1970.\n",
      "[Epoch 53/1000] Train Loss: 2.1256  |  Val Loss: 2.1876\n",
      "Validation loss improved from 2.1970 to 2.1876.\n",
      "[Epoch 54/1000] Train Loss: 2.1146  |  Val Loss: 2.1783\n",
      "Validation loss improved from 2.1876 to 2.1783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 55/1000] Train Loss: 2.1036  |  Val Loss: 2.1693\n",
      "Validation loss improved from 2.1783 to 2.1693.\n",
      "[Epoch 56/1000] Train Loss: 2.0929  |  Val Loss: 2.1602\n",
      "Validation loss improved from 2.1693 to 2.1602.\n",
      "[Epoch 57/1000] Train Loss: 2.0819  |  Val Loss: 2.1510\n",
      "Validation loss improved from 2.1602 to 2.1510.\n",
      "[Epoch 58/1000] Train Loss: 2.0716  |  Val Loss: 2.1414\n",
      "Validation loss improved from 2.1510 to 2.1414.\n",
      "[Epoch 59/1000] Train Loss: 2.0604  |  Val Loss: 2.1323\n",
      "Validation loss improved from 2.1414 to 2.1323.\n",
      "[Epoch 60/1000] Train Loss: 2.0496  |  Val Loss: 2.1236\n",
      "Validation loss improved from 2.1323 to 2.1236.\n",
      "[Epoch 61/1000] Train Loss: 2.0395  |  Val Loss: 2.1152\n",
      "Validation loss improved from 2.1236 to 2.1152.\n",
      "[Epoch 62/1000] Train Loss: 2.0289  |  Val Loss: 2.1067\n",
      "Validation loss improved from 2.1152 to 2.1067.\n",
      "[Epoch 63/1000] Train Loss: 2.0186  |  Val Loss: 2.0983\n",
      "Validation loss improved from 2.1067 to 2.0983.\n",
      "[Epoch 64/1000] Train Loss: 2.0081  |  Val Loss: 2.0899\n",
      "Validation loss improved from 2.0983 to 2.0899.\n",
      "[Epoch 65/1000] Train Loss: 1.9978  |  Val Loss: 2.0814\n",
      "Validation loss improved from 2.0899 to 2.0814.\n",
      "[Epoch 66/1000] Train Loss: 1.9871  |  Val Loss: 2.0730\n",
      "Validation loss improved from 2.0814 to 2.0730.\n",
      "[Epoch 67/1000] Train Loss: 1.9768  |  Val Loss: 2.0645\n",
      "Validation loss improved from 2.0730 to 2.0645.\n",
      "[Epoch 68/1000] Train Loss: 1.9662  |  Val Loss: 2.0562\n",
      "Validation loss improved from 2.0645 to 2.0562.\n",
      "[Epoch 69/1000] Train Loss: 1.9558  |  Val Loss: 2.0480\n",
      "Validation loss improved from 2.0562 to 2.0480.\n",
      "[Epoch 70/1000] Train Loss: 1.9450  |  Val Loss: 2.0398\n",
      "Validation loss improved from 2.0480 to 2.0398.\n",
      "[Epoch 71/1000] Train Loss: 1.9345  |  Val Loss: 2.0314\n",
      "Validation loss improved from 2.0398 to 2.0314.\n",
      "[Epoch 72/1000] Train Loss: 1.9239  |  Val Loss: 2.0230\n",
      "Validation loss improved from 2.0314 to 2.0230.\n",
      "[Epoch 73/1000] Train Loss: 1.9134  |  Val Loss: 2.0145\n",
      "Validation loss improved from 2.0230 to 2.0145.\n",
      "[Epoch 74/1000] Train Loss: 1.9030  |  Val Loss: 2.0059\n",
      "Validation loss improved from 2.0145 to 2.0059.\n",
      "[Epoch 75/1000] Train Loss: 1.8920  |  Val Loss: 1.9977\n",
      "Validation loss improved from 2.0059 to 1.9977.\n",
      "[Epoch 76/1000] Train Loss: 1.8820  |  Val Loss: 1.9896\n",
      "Validation loss improved from 1.9977 to 1.9896.\n",
      "[Epoch 77/1000] Train Loss: 1.8716  |  Val Loss: 1.9815\n",
      "Validation loss improved from 1.9896 to 1.9815.\n",
      "[Epoch 78/1000] Train Loss: 1.8613  |  Val Loss: 1.9735\n",
      "Validation loss improved from 1.9815 to 1.9735.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 79/1000] Train Loss: 1.8511  |  Val Loss: 1.9655\n",
      "Validation loss improved from 1.9735 to 1.9655.\n",
      "[Epoch 80/1000] Train Loss: 1.8409  |  Val Loss: 1.9573\n",
      "Validation loss improved from 1.9655 to 1.9573.\n",
      "[Epoch 81/1000] Train Loss: 1.8305  |  Val Loss: 1.9492\n",
      "Validation loss improved from 1.9573 to 1.9492.\n",
      "[Epoch 82/1000] Train Loss: 1.8205  |  Val Loss: 1.9414\n",
      "Validation loss improved from 1.9492 to 1.9414.\n",
      "[Epoch 83/1000] Train Loss: 1.8105  |  Val Loss: 1.9337\n",
      "Validation loss improved from 1.9414 to 1.9337.\n",
      "[Epoch 84/1000] Train Loss: 1.8005  |  Val Loss: 1.9257\n",
      "Validation loss improved from 1.9337 to 1.9257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 85/1000] Train Loss: 1.7904  |  Val Loss: 1.9175\n",
      "Validation loss improved from 1.9257 to 1.9175.\n",
      "[Epoch 86/1000] Train Loss: 1.7805  |  Val Loss: 1.9094\n",
      "Validation loss improved from 1.9175 to 1.9094.\n",
      "[Epoch 87/1000] Train Loss: 1.7704  |  Val Loss: 1.9015\n",
      "Validation loss improved from 1.9094 to 1.9015.\n",
      "[Epoch 88/1000] Train Loss: 1.7606  |  Val Loss: 1.8934\n",
      "Validation loss improved from 1.9015 to 1.8934.\n",
      "[Epoch 89/1000] Train Loss: 1.7512  |  Val Loss: 1.8851\n",
      "Validation loss improved from 1.8934 to 1.8851.\n",
      "[Epoch 90/1000] Train Loss: 1.7409  |  Val Loss: 1.8769\n",
      "Validation loss improved from 1.8851 to 1.8769.\n",
      "[Epoch 91/1000] Train Loss: 1.7308  |  Val Loss: 1.8687\n",
      "Validation loss improved from 1.8769 to 1.8687.\n",
      "[Epoch 92/1000] Train Loss: 1.7211  |  Val Loss: 1.8606\n",
      "Validation loss improved from 1.8687 to 1.8606.\n",
      "[Epoch 93/1000] Train Loss: 1.7112  |  Val Loss: 1.8522\n",
      "Validation loss improved from 1.8606 to 1.8522.\n",
      "[Epoch 94/1000] Train Loss: 1.7012  |  Val Loss: 1.8440\n",
      "Validation loss improved from 1.8522 to 1.8440.\n",
      "[Epoch 95/1000] Train Loss: 1.6915  |  Val Loss: 1.8357\n",
      "Validation loss improved from 1.8440 to 1.8357.\n",
      "[Epoch 96/1000] Train Loss: 1.6815  |  Val Loss: 1.8276\n",
      "Validation loss improved from 1.8357 to 1.8276.\n",
      "[Epoch 97/1000] Train Loss: 1.6717  |  Val Loss: 1.8195\n",
      "Validation loss improved from 1.8276 to 1.8195.\n",
      "[Epoch 98/1000] Train Loss: 1.6623  |  Val Loss: 1.8116\n",
      "Validation loss improved from 1.8195 to 1.8116.\n",
      "[Epoch 99/1000] Train Loss: 1.6527  |  Val Loss: 1.8039\n",
      "Validation loss improved from 1.8116 to 1.8039.\n",
      "[Epoch 100/1000] Train Loss: 1.6432  |  Val Loss: 1.7964\n",
      "Validation loss improved from 1.8039 to 1.7964.\n",
      "[Epoch 101/1000] Train Loss: 1.6336  |  Val Loss: 1.7889\n",
      "Validation loss improved from 1.7964 to 1.7889.\n",
      "[Epoch 102/1000] Train Loss: 1.6237  |  Val Loss: 1.7812\n",
      "Validation loss improved from 1.7889 to 1.7812.\n",
      "[Epoch 103/1000] Train Loss: 1.6141  |  Val Loss: 1.7734\n",
      "Validation loss improved from 1.7812 to 1.7734.\n",
      "[Epoch 104/1000] Train Loss: 1.6043  |  Val Loss: 1.7658\n",
      "Validation loss improved from 1.7734 to 1.7658.\n",
      "[Epoch 105/1000] Train Loss: 1.5945  |  Val Loss: 1.7582\n",
      "Validation loss improved from 1.7658 to 1.7582.\n",
      "[Epoch 106/1000] Train Loss: 1.5852  |  Val Loss: 1.7506\n",
      "Validation loss improved from 1.7582 to 1.7506.\n",
      "[Epoch 107/1000] Train Loss: 1.5758  |  Val Loss: 1.7430\n",
      "Validation loss improved from 1.7506 to 1.7430.\n",
      "[Epoch 108/1000] Train Loss: 1.5665  |  Val Loss: 1.7354\n",
      "Validation loss improved from 1.7430 to 1.7354.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 109/1000] Train Loss: 1.5573  |  Val Loss: 1.7281\n",
      "Validation loss improved from 1.7354 to 1.7281.\n",
      "[Epoch 110/1000] Train Loss: 1.5476  |  Val Loss: 1.7209\n",
      "Validation loss improved from 1.7281 to 1.7209.\n",
      "[Epoch 111/1000] Train Loss: 1.5385  |  Val Loss: 1.7139\n",
      "Validation loss improved from 1.7209 to 1.7139.\n",
      "[Epoch 112/1000] Train Loss: 1.5292  |  Val Loss: 1.7071\n",
      "Validation loss improved from 1.7139 to 1.7071.\n",
      "[Epoch 113/1000] Train Loss: 1.5201  |  Val Loss: 1.7002\n",
      "Validation loss improved from 1.7071 to 1.7002.\n",
      "[Epoch 114/1000] Train Loss: 1.5112  |  Val Loss: 1.6932\n",
      "Validation loss improved from 1.7002 to 1.6932.\n",
      "[Epoch 115/1000] Train Loss: 1.5020  |  Val Loss: 1.6860\n",
      "Validation loss improved from 1.6932 to 1.6860.\n",
      "[Epoch 116/1000] Train Loss: 1.4932  |  Val Loss: 1.6789\n",
      "Validation loss improved from 1.6860 to 1.6789.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 117/1000] Train Loss: 1.4844  |  Val Loss: 1.6718\n",
      "Validation loss improved from 1.6789 to 1.6718.\n",
      "[Epoch 118/1000] Train Loss: 1.4754  |  Val Loss: 1.6645\n",
      "Validation loss improved from 1.6718 to 1.6645.\n",
      "[Epoch 119/1000] Train Loss: 1.4664  |  Val Loss: 1.6570\n",
      "Validation loss improved from 1.6645 to 1.6570.\n",
      "[Epoch 120/1000] Train Loss: 1.4573  |  Val Loss: 1.6495\n",
      "Validation loss improved from 1.6570 to 1.6495.\n",
      "[Epoch 121/1000] Train Loss: 1.4482  |  Val Loss: 1.6423\n",
      "Validation loss improved from 1.6495 to 1.6423.\n",
      "[Epoch 122/1000] Train Loss: 1.4392  |  Val Loss: 1.6354\n",
      "Validation loss improved from 1.6423 to 1.6354.\n",
      "[Epoch 123/1000] Train Loss: 1.4303  |  Val Loss: 1.6286\n",
      "Validation loss improved from 1.6354 to 1.6286.\n",
      "[Epoch 124/1000] Train Loss: 1.4215  |  Val Loss: 1.6217\n",
      "Validation loss improved from 1.6286 to 1.6217.\n",
      "[Epoch 125/1000] Train Loss: 1.4125  |  Val Loss: 1.6150\n",
      "Validation loss improved from 1.6217 to 1.6150.\n",
      "[Epoch 126/1000] Train Loss: 1.4036  |  Val Loss: 1.6082\n",
      "Validation loss improved from 1.6150 to 1.6082.\n",
      "[Epoch 127/1000] Train Loss: 1.3951  |  Val Loss: 1.6014\n",
      "Validation loss improved from 1.6082 to 1.6014.\n",
      "[Epoch 128/1000] Train Loss: 1.3863  |  Val Loss: 1.5945\n",
      "Validation loss improved from 1.6014 to 1.5945.\n",
      "[Epoch 129/1000] Train Loss: 1.3776  |  Val Loss: 1.5879\n",
      "Validation loss improved from 1.5945 to 1.5879.\n",
      "[Epoch 130/1000] Train Loss: 1.3691  |  Val Loss: 1.5819\n",
      "Validation loss improved from 1.5879 to 1.5819.\n",
      "[Epoch 131/1000] Train Loss: 1.3604  |  Val Loss: 1.5758\n",
      "Validation loss improved from 1.5819 to 1.5758.\n",
      "[Epoch 132/1000] Train Loss: 1.3517  |  Val Loss: 1.5696\n",
      "Validation loss improved from 1.5758 to 1.5696.\n",
      "[Epoch 133/1000] Train Loss: 1.3431  |  Val Loss: 1.5634\n",
      "Validation loss improved from 1.5696 to 1.5634.\n",
      "[Epoch 134/1000] Train Loss: 1.3346  |  Val Loss: 1.5569\n",
      "Validation loss improved from 1.5634 to 1.5569.\n",
      "[Epoch 135/1000] Train Loss: 1.3259  |  Val Loss: 1.5502\n",
      "Validation loss improved from 1.5569 to 1.5502.\n",
      "[Epoch 136/1000] Train Loss: 1.3172  |  Val Loss: 1.5435\n",
      "Validation loss improved from 1.5502 to 1.5435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 137/1000] Train Loss: 1.3089  |  Val Loss: 1.5368\n",
      "Validation loss improved from 1.5435 to 1.5368.\n",
      "[Epoch 138/1000] Train Loss: 1.3002  |  Val Loss: 1.5303\n",
      "Validation loss improved from 1.5368 to 1.5303.\n",
      "[Epoch 139/1000] Train Loss: 1.2916  |  Val Loss: 1.5235\n",
      "Validation loss improved from 1.5303 to 1.5235.\n",
      "[Epoch 140/1000] Train Loss: 1.2832  |  Val Loss: 1.5166\n",
      "Validation loss improved from 1.5235 to 1.5166.\n",
      "[Epoch 141/1000] Train Loss: 1.2749  |  Val Loss: 1.5093\n",
      "Validation loss improved from 1.5166 to 1.5093.\n",
      "[Epoch 142/1000] Train Loss: 1.2669  |  Val Loss: 1.5023\n",
      "Validation loss improved from 1.5093 to 1.5023.\n",
      "[Epoch 143/1000] Train Loss: 1.2584  |  Val Loss: 1.4957\n",
      "Validation loss improved from 1.5023 to 1.4957.\n",
      "[Epoch 144/1000] Train Loss: 1.2501  |  Val Loss: 1.4893\n",
      "Validation loss improved from 1.4957 to 1.4893.\n",
      "[Epoch 145/1000] Train Loss: 1.2419  |  Val Loss: 1.4831\n",
      "Validation loss improved from 1.4893 to 1.4831.\n",
      "[Epoch 146/1000] Train Loss: 1.2338  |  Val Loss: 1.4774\n",
      "Validation loss improved from 1.4831 to 1.4774.\n",
      "[Epoch 147/1000] Train Loss: 1.2254  |  Val Loss: 1.4714\n",
      "Validation loss improved from 1.4774 to 1.4714.\n",
      "[Epoch 148/1000] Train Loss: 1.2172  |  Val Loss: 1.4649\n",
      "Validation loss improved from 1.4714 to 1.4649.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 149/1000] Train Loss: 1.2089  |  Val Loss: 1.4578\n",
      "Validation loss improved from 1.4649 to 1.4578.\n",
      "[Epoch 150/1000] Train Loss: 1.2008  |  Val Loss: 1.4506\n",
      "Validation loss improved from 1.4578 to 1.4506.\n",
      "[Epoch 151/1000] Train Loss: 1.1925  |  Val Loss: 1.4436\n",
      "Validation loss improved from 1.4506 to 1.4436.\n",
      "[Epoch 152/1000] Train Loss: 1.1845  |  Val Loss: 1.4370\n",
      "Validation loss improved from 1.4436 to 1.4370.\n",
      "[Epoch 153/1000] Train Loss: 1.1763  |  Val Loss: 1.4304\n",
      "Validation loss improved from 1.4370 to 1.4304.\n",
      "[Epoch 154/1000] Train Loss: 1.1683  |  Val Loss: 1.4237\n",
      "Validation loss improved from 1.4304 to 1.4237.\n",
      "[Epoch 155/1000] Train Loss: 1.1606  |  Val Loss: 1.4169\n",
      "Validation loss improved from 1.4237 to 1.4169.\n",
      "[Epoch 156/1000] Train Loss: 1.1528  |  Val Loss: 1.4099\n",
      "Validation loss improved from 1.4169 to 1.4099.\n",
      "[Epoch 157/1000] Train Loss: 1.1446  |  Val Loss: 1.4031\n",
      "Validation loss improved from 1.4099 to 1.4031.\n",
      "[Epoch 158/1000] Train Loss: 1.1367  |  Val Loss: 1.3963\n",
      "Validation loss improved from 1.4031 to 1.3963.\n",
      "[Epoch 159/1000] Train Loss: 1.1290  |  Val Loss: 1.3898\n",
      "Validation loss improved from 1.3963 to 1.3898.\n",
      "[Epoch 160/1000] Train Loss: 1.1210  |  Val Loss: 1.3837\n",
      "Validation loss improved from 1.3898 to 1.3837.\n",
      "[Epoch 161/1000] Train Loss: 1.1132  |  Val Loss: 1.3780\n",
      "Validation loss improved from 1.3837 to 1.3780.\n",
      "[Epoch 162/1000] Train Loss: 1.1053  |  Val Loss: 1.3726\n",
      "Validation loss improved from 1.3780 to 1.3726.\n",
      "[Epoch 163/1000] Train Loss: 1.0977  |  Val Loss: 1.3678\n",
      "Validation loss improved from 1.3726 to 1.3678.\n",
      "[Epoch 164/1000] Train Loss: 1.0902  |  Val Loss: 1.3627\n",
      "Validation loss improved from 1.3678 to 1.3627.\n",
      "[Epoch 165/1000] Train Loss: 1.0823  |  Val Loss: 1.3576\n",
      "Validation loss improved from 1.3627 to 1.3576.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 166/1000] Train Loss: 1.0752  |  Val Loss: 1.3526\n",
      "Validation loss improved from 1.3576 to 1.3526.\n",
      "[Epoch 167/1000] Train Loss: 1.0676  |  Val Loss: 1.3473\n",
      "Validation loss improved from 1.3526 to 1.3473.\n",
      "[Epoch 168/1000] Train Loss: 1.0600  |  Val Loss: 1.3418\n",
      "Validation loss improved from 1.3473 to 1.3418.\n",
      "[Epoch 169/1000] Train Loss: 1.0524  |  Val Loss: 1.3366\n",
      "Validation loss improved from 1.3418 to 1.3366.\n",
      "[Epoch 170/1000] Train Loss: 1.0450  |  Val Loss: 1.3315\n",
      "Validation loss improved from 1.3366 to 1.3315.\n",
      "[Epoch 171/1000] Train Loss: 1.0377  |  Val Loss: 1.3262\n",
      "Validation loss improved from 1.3315 to 1.3262.\n",
      "[Epoch 172/1000] Train Loss: 1.0305  |  Val Loss: 1.3211\n",
      "Validation loss improved from 1.3262 to 1.3211.\n",
      "[Epoch 173/1000] Train Loss: 1.0232  |  Val Loss: 1.3161\n",
      "Validation loss improved from 1.3211 to 1.3161.\n",
      "[Epoch 174/1000] Train Loss: 1.0162  |  Val Loss: 1.3110\n",
      "Validation loss improved from 1.3161 to 1.3110.\n",
      "[Epoch 175/1000] Train Loss: 1.0093  |  Val Loss: 1.3054\n",
      "Validation loss improved from 1.3110 to 1.3054.\n",
      "[Epoch 176/1000] Train Loss: 1.0024  |  Val Loss: 1.2988\n",
      "Validation loss improved from 1.3054 to 1.2988.\n",
      "[Epoch 177/1000] Train Loss: 0.9959  |  Val Loss: 1.2921\n",
      "Validation loss improved from 1.2988 to 1.2921.\n",
      "[Epoch 178/1000] Train Loss: 0.9890  |  Val Loss: 1.2858\n",
      "Validation loss improved from 1.2921 to 1.2858.\n",
      "[Epoch 179/1000] Train Loss: 0.9821  |  Val Loss: 1.2802\n",
      "Validation loss improved from 1.2858 to 1.2802.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 180/1000] Train Loss: 0.9750  |  Val Loss: 1.2753\n",
      "Validation loss improved from 1.2802 to 1.2753.\n",
      "[Epoch 181/1000] Train Loss: 0.9684  |  Val Loss: 1.2708\n",
      "Validation loss improved from 1.2753 to 1.2708.\n",
      "[Epoch 182/1000] Train Loss: 0.9613  |  Val Loss: 1.2663\n",
      "Validation loss improved from 1.2708 to 1.2663.\n",
      "[Epoch 183/1000] Train Loss: 0.9546  |  Val Loss: 1.2619\n",
      "Validation loss improved from 1.2663 to 1.2619.\n",
      "[Epoch 184/1000] Train Loss: 0.9478  |  Val Loss: 1.2570\n",
      "Validation loss improved from 1.2619 to 1.2570.\n",
      "[Epoch 185/1000] Train Loss: 0.9411  |  Val Loss: 1.2524\n",
      "Validation loss improved from 1.2570 to 1.2524.\n",
      "[Epoch 186/1000] Train Loss: 0.9344  |  Val Loss: 1.2485\n",
      "Validation loss improved from 1.2524 to 1.2485.\n",
      "[Epoch 187/1000] Train Loss: 0.9281  |  Val Loss: 1.2448\n",
      "Validation loss improved from 1.2485 to 1.2448.\n",
      "[Epoch 188/1000] Train Loss: 0.9215  |  Val Loss: 1.2408\n",
      "Validation loss improved from 1.2448 to 1.2408.\n",
      "[Epoch 189/1000] Train Loss: 0.9154  |  Val Loss: 1.2372\n",
      "Validation loss improved from 1.2408 to 1.2372.\n",
      "[Epoch 190/1000] Train Loss: 0.9091  |  Val Loss: 1.2336\n",
      "Validation loss improved from 1.2372 to 1.2336.\n",
      "[Epoch 191/1000] Train Loss: 0.9026  |  Val Loss: 1.2296\n",
      "Validation loss improved from 1.2336 to 1.2296.\n",
      "[Epoch 192/1000] Train Loss: 0.8967  |  Val Loss: 1.2255\n",
      "Validation loss improved from 1.2296 to 1.2255.\n",
      "[Epoch 193/1000] Train Loss: 0.8905  |  Val Loss: 1.2211\n",
      "Validation loss improved from 1.2255 to 1.2211.\n",
      "[Epoch 194/1000] Train Loss: 0.8845  |  Val Loss: 1.2158\n",
      "Validation loss improved from 1.2211 to 1.2158.\n",
      "[Epoch 195/1000] Train Loss: 0.8787  |  Val Loss: 1.2101\n",
      "Validation loss improved from 1.2158 to 1.2101.\n",
      "[Epoch 196/1000] Train Loss: 0.8728  |  Val Loss: 1.2051\n",
      "Validation loss improved from 1.2101 to 1.2051.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 197/1000] Train Loss: 0.8669  |  Val Loss: 1.2002\n",
      "Validation loss improved from 1.2051 to 1.2002.\n",
      "[Epoch 198/1000] Train Loss: 0.8611  |  Val Loss: 1.1963\n",
      "Validation loss improved from 1.2002 to 1.1963.\n",
      "[Epoch 199/1000] Train Loss: 0.8554  |  Val Loss: 1.1927\n",
      "Validation loss improved from 1.1963 to 1.1927.\n",
      "[Epoch 200/1000] Train Loss: 0.8495  |  Val Loss: 1.1892\n",
      "Validation loss improved from 1.1927 to 1.1892.\n",
      "[Epoch 201/1000] Train Loss: 0.8441  |  Val Loss: 1.1858\n",
      "Validation loss improved from 1.1892 to 1.1858.\n",
      "[Epoch 202/1000] Train Loss: 0.8385  |  Val Loss: 1.1812\n",
      "Validation loss improved from 1.1858 to 1.1812.\n",
      "[Epoch 203/1000] Train Loss: 0.8331  |  Val Loss: 1.1761\n",
      "Validation loss improved from 1.1812 to 1.1761.\n",
      "[Epoch 204/1000] Train Loss: 0.8275  |  Val Loss: 1.1706\n",
      "Validation loss improved from 1.1761 to 1.1706.\n",
      "[Epoch 205/1000] Train Loss: 0.8220  |  Val Loss: 1.1652\n",
      "Validation loss improved from 1.1706 to 1.1652.\n",
      "[Epoch 206/1000] Train Loss: 0.8167  |  Val Loss: 1.1597\n",
      "Validation loss improved from 1.1652 to 1.1597.\n",
      "[Epoch 207/1000] Train Loss: 0.8107  |  Val Loss: 1.1549\n",
      "Validation loss improved from 1.1597 to 1.1549.\n",
      "[Epoch 208/1000] Train Loss: 0.8053  |  Val Loss: 1.1507\n",
      "Validation loss improved from 1.1549 to 1.1507.\n",
      "[Epoch 209/1000] Train Loss: 0.7999  |  Val Loss: 1.1471\n",
      "Validation loss improved from 1.1507 to 1.1471.\n",
      "[Epoch 210/1000] Train Loss: 0.7944  |  Val Loss: 1.1438\n",
      "Validation loss improved from 1.1471 to 1.1438.\n",
      "[Epoch 211/1000] Train Loss: 0.7893  |  Val Loss: 1.1414\n",
      "Validation loss improved from 1.1438 to 1.1414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 212/1000] Train Loss: 0.7843  |  Val Loss: 1.1386\n",
      "Validation loss improved from 1.1414 to 1.1386.\n",
      "[Epoch 213/1000] Train Loss: 0.7792  |  Val Loss: 1.1358\n",
      "Validation loss improved from 1.1386 to 1.1358.\n",
      "[Epoch 214/1000] Train Loss: 0.7745  |  Val Loss: 1.1331\n",
      "Validation loss improved from 1.1358 to 1.1331.\n",
      "[Epoch 215/1000] Train Loss: 0.7695  |  Val Loss: 1.1297\n",
      "Validation loss improved from 1.1331 to 1.1297.\n",
      "[Epoch 216/1000] Train Loss: 0.7645  |  Val Loss: 1.1263\n",
      "Validation loss improved from 1.1297 to 1.1263.\n",
      "[Epoch 217/1000] Train Loss: 0.7597  |  Val Loss: 1.1227\n",
      "Validation loss improved from 1.1263 to 1.1227.\n",
      "[Epoch 218/1000] Train Loss: 0.7548  |  Val Loss: 1.1181\n",
      "Validation loss improved from 1.1227 to 1.1181.\n",
      "[Epoch 219/1000] Train Loss: 0.7496  |  Val Loss: 1.1132\n",
      "Validation loss improved from 1.1181 to 1.1132.\n",
      "[Epoch 220/1000] Train Loss: 0.7449  |  Val Loss: 1.1092\n",
      "Validation loss improved from 1.1132 to 1.1092.\n",
      "[Epoch 221/1000] Train Loss: 0.7401  |  Val Loss: 1.1055\n",
      "Validation loss improved from 1.1092 to 1.1055.\n",
      "[Epoch 222/1000] Train Loss: 0.7353  |  Val Loss: 1.1017\n",
      "Validation loss improved from 1.1055 to 1.1017.\n",
      "[Epoch 223/1000] Train Loss: 0.7304  |  Val Loss: 1.0983\n",
      "Validation loss improved from 1.1017 to 1.0983.\n",
      "[Epoch 224/1000] Train Loss: 0.7254  |  Val Loss: 1.0951\n",
      "Validation loss improved from 1.0983 to 1.0951.\n",
      "[Epoch 225/1000] Train Loss: 0.7208  |  Val Loss: 1.0926\n",
      "Validation loss improved from 1.0951 to 1.0926.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 226/1000] Train Loss: 0.7160  |  Val Loss: 1.0903\n",
      "Validation loss improved from 1.0926 to 1.0903.\n",
      "[Epoch 227/1000] Train Loss: 0.7113  |  Val Loss: 1.0878\n",
      "Validation loss improved from 1.0903 to 1.0878.\n",
      "[Epoch 228/1000] Train Loss: 0.7068  |  Val Loss: 1.0855\n",
      "Validation loss improved from 1.0878 to 1.0855.\n",
      "[Epoch 229/1000] Train Loss: 0.7022  |  Val Loss: 1.0823\n",
      "Validation loss improved from 1.0855 to 1.0823.\n",
      "[Epoch 230/1000] Train Loss: 0.6978  |  Val Loss: 1.0780\n",
      "Validation loss improved from 1.0823 to 1.0780.\n",
      "[Epoch 231/1000] Train Loss: 0.6932  |  Val Loss: 1.0741\n",
      "Validation loss improved from 1.0780 to 1.0741.\n",
      "[Epoch 232/1000] Train Loss: 0.6887  |  Val Loss: 1.0691\n",
      "Validation loss improved from 1.0741 to 1.0691.\n",
      "[Epoch 233/1000] Train Loss: 0.6840  |  Val Loss: 1.0644\n",
      "Validation loss improved from 1.0691 to 1.0644.\n",
      "[Epoch 234/1000] Train Loss: 0.6793  |  Val Loss: 1.0601\n",
      "Validation loss improved from 1.0644 to 1.0601.\n",
      "[Epoch 235/1000] Train Loss: 0.6748  |  Val Loss: 1.0559\n",
      "Validation loss improved from 1.0601 to 1.0559.\n",
      "[Epoch 236/1000] Train Loss: 0.6706  |  Val Loss: 1.0522\n",
      "Validation loss improved from 1.0559 to 1.0522.\n",
      "[Epoch 237/1000] Train Loss: 0.6664  |  Val Loss: 1.0484\n",
      "Validation loss improved from 1.0522 to 1.0484.\n",
      "[Epoch 238/1000] Train Loss: 0.6622  |  Val Loss: 1.0445\n",
      "Validation loss improved from 1.0484 to 1.0445.\n",
      "[Epoch 239/1000] Train Loss: 0.6577  |  Val Loss: 1.0408\n",
      "Validation loss improved from 1.0445 to 1.0408.\n",
      "[Epoch 240/1000] Train Loss: 0.6537  |  Val Loss: 1.0376\n",
      "Validation loss improved from 1.0408 to 1.0376.\n",
      "[Epoch 241/1000] Train Loss: 0.6489  |  Val Loss: 1.0337\n",
      "Validation loss improved from 1.0376 to 1.0337.\n",
      "[Epoch 242/1000] Train Loss: 0.6447  |  Val Loss: 1.0297\n",
      "Validation loss improved from 1.0337 to 1.0297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 243/1000] Train Loss: 0.6400  |  Val Loss: 1.0267\n",
      "Validation loss improved from 1.0297 to 1.0267.\n",
      "[Epoch 244/1000] Train Loss: 0.6357  |  Val Loss: 1.0241\n",
      "Validation loss improved from 1.0267 to 1.0241.\n",
      "[Epoch 245/1000] Train Loss: 0.6315  |  Val Loss: 1.0200\n",
      "Validation loss improved from 1.0241 to 1.0200.\n",
      "[Epoch 246/1000] Train Loss: 0.6271  |  Val Loss: 1.0164\n",
      "Validation loss improved from 1.0200 to 1.0164.\n",
      "[Epoch 247/1000] Train Loss: 0.6230  |  Val Loss: 1.0131\n",
      "Validation loss improved from 1.0164 to 1.0131.\n",
      "[Epoch 248/1000] Train Loss: 0.6191  |  Val Loss: 1.0095\n",
      "Validation loss improved from 1.0131 to 1.0095.\n",
      "[Epoch 249/1000] Train Loss: 0.6150  |  Val Loss: 1.0059\n",
      "Validation loss improved from 1.0095 to 1.0059.\n",
      "[Epoch 250/1000] Train Loss: 0.6114  |  Val Loss: 1.0021\n",
      "Validation loss improved from 1.0059 to 1.0021.\n",
      "[Epoch 251/1000] Train Loss: 0.6072  |  Val Loss: 0.9992\n",
      "Validation loss improved from 1.0021 to 0.9992.\n",
      "[Epoch 252/1000] Train Loss: 0.6033  |  Val Loss: 0.9965\n",
      "Validation loss improved from 0.9992 to 0.9965.\n",
      "[Epoch 253/1000] Train Loss: 0.5996  |  Val Loss: 0.9934\n",
      "Validation loss improved from 0.9965 to 0.9934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 254/1000] Train Loss: 0.5954  |  Val Loss: 0.9898\n",
      "Validation loss improved from 0.9934 to 0.9898.\n",
      "[Epoch 255/1000] Train Loss: 0.5913  |  Val Loss: 0.9861\n",
      "Validation loss improved from 0.9898 to 0.9861.\n",
      "[Epoch 256/1000] Train Loss: 0.5872  |  Val Loss: 0.9829\n",
      "Validation loss improved from 0.9861 to 0.9829.\n",
      "[Epoch 257/1000] Train Loss: 0.5834  |  Val Loss: 0.9800\n",
      "Validation loss improved from 0.9829 to 0.9800.\n",
      "[Epoch 258/1000] Train Loss: 0.5796  |  Val Loss: 0.9772\n",
      "Validation loss improved from 0.9800 to 0.9772.\n",
      "[Epoch 259/1000] Train Loss: 0.5759  |  Val Loss: 0.9740\n",
      "Validation loss improved from 0.9772 to 0.9740.\n",
      "[Epoch 260/1000] Train Loss: 0.5719  |  Val Loss: 0.9710\n",
      "Validation loss improved from 0.9740 to 0.9710.\n",
      "[Epoch 261/1000] Train Loss: 0.5682  |  Val Loss: 0.9683\n",
      "Validation loss improved from 0.9710 to 0.9683.\n",
      "[Epoch 262/1000] Train Loss: 0.5643  |  Val Loss: 0.9660\n",
      "Validation loss improved from 0.9683 to 0.9660.\n",
      "[Epoch 263/1000] Train Loss: 0.5607  |  Val Loss: 0.9639\n",
      "Validation loss improved from 0.9660 to 0.9639.\n",
      "[Epoch 264/1000] Train Loss: 0.5569  |  Val Loss: 0.9625\n",
      "Validation loss improved from 0.9639 to 0.9625.\n",
      "[Epoch 265/1000] Train Loss: 0.5532  |  Val Loss: 0.9607\n",
      "Validation loss improved from 0.9625 to 0.9607.\n",
      "[Epoch 266/1000] Train Loss: 0.5496  |  Val Loss: 0.9590\n",
      "Validation loss improved from 0.9607 to 0.9590.\n",
      "[Epoch 267/1000] Train Loss: 0.5458  |  Val Loss: 0.9573\n",
      "Validation loss improved from 0.9590 to 0.9573.\n",
      "[Epoch 268/1000] Train Loss: 0.5420  |  Val Loss: 0.9554\n",
      "Validation loss improved from 0.9573 to 0.9554.\n",
      "[Epoch 269/1000] Train Loss: 0.5387  |  Val Loss: 0.9540\n",
      "Validation loss improved from 0.9554 to 0.9540.\n",
      "[Epoch 270/1000] Train Loss: 0.5358  |  Val Loss: 0.9528\n",
      "Validation loss improved from 0.9540 to 0.9528.\n",
      "[Epoch 271/1000] Train Loss: 0.5322  |  Val Loss: 0.9512\n",
      "Validation loss improved from 0.9528 to 0.9512.\n",
      "[Epoch 272/1000] Train Loss: 0.5289  |  Val Loss: 0.9486\n",
      "Validation loss improved from 0.9512 to 0.9486.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 273/1000] Train Loss: 0.5253  |  Val Loss: 0.9459\n",
      "Validation loss improved from 0.9486 to 0.9459.\n",
      "[Epoch 274/1000] Train Loss: 0.5219  |  Val Loss: 0.9429\n",
      "Validation loss improved from 0.9459 to 0.9429.\n",
      "[Epoch 275/1000] Train Loss: 0.5184  |  Val Loss: 0.9403\n",
      "Validation loss improved from 0.9429 to 0.9403.\n",
      "[Epoch 276/1000] Train Loss: 0.5148  |  Val Loss: 0.9374\n",
      "Validation loss improved from 0.9403 to 0.9374.\n",
      "[Epoch 277/1000] Train Loss: 0.5111  |  Val Loss: 0.9345\n",
      "Validation loss improved from 0.9374 to 0.9345.\n",
      "[Epoch 278/1000] Train Loss: 0.5074  |  Val Loss: 0.9326\n",
      "Validation loss improved from 0.9345 to 0.9326.\n",
      "[Epoch 279/1000] Train Loss: 0.5042  |  Val Loss: 0.9311\n",
      "Validation loss improved from 0.9326 to 0.9311.\n",
      "[Epoch 280/1000] Train Loss: 0.5008  |  Val Loss: 0.9297\n",
      "Validation loss improved from 0.9311 to 0.9297.\n",
      "[Epoch 281/1000] Train Loss: 0.4974  |  Val Loss: 0.9282\n",
      "Validation loss improved from 0.9297 to 0.9282.\n",
      "[Epoch 282/1000] Train Loss: 0.4940  |  Val Loss: 0.9263\n",
      "Validation loss improved from 0.9282 to 0.9263.\n",
      "[Epoch 283/1000] Train Loss: 0.4908  |  Val Loss: 0.9234\n",
      "Validation loss improved from 0.9263 to 0.9234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 284/1000] Train Loss: 0.4872  |  Val Loss: 0.9205\n",
      "Validation loss improved from 0.9234 to 0.9205.\n",
      "[Epoch 285/1000] Train Loss: 0.4843  |  Val Loss: 0.9178\n",
      "Validation loss improved from 0.9205 to 0.9178.\n",
      "[Epoch 286/1000] Train Loss: 0.4809  |  Val Loss: 0.9158\n",
      "Validation loss improved from 0.9178 to 0.9158.\n",
      "[Epoch 287/1000] Train Loss: 0.4777  |  Val Loss: 0.9142\n",
      "Validation loss improved from 0.9158 to 0.9142.\n",
      "[Epoch 288/1000] Train Loss: 0.4746  |  Val Loss: 0.9126\n",
      "Validation loss improved from 0.9142 to 0.9126.\n",
      "[Epoch 289/1000] Train Loss: 0.4714  |  Val Loss: 0.9109\n",
      "Validation loss improved from 0.9126 to 0.9109.\n",
      "[Epoch 290/1000] Train Loss: 0.4685  |  Val Loss: 0.9098\n",
      "Validation loss improved from 0.9109 to 0.9098.\n",
      "[Epoch 291/1000] Train Loss: 0.4656  |  Val Loss: 0.9081\n",
      "Validation loss improved from 0.9098 to 0.9081.\n",
      "[Epoch 292/1000] Train Loss: 0.4627  |  Val Loss: 0.9061\n",
      "Validation loss improved from 0.9081 to 0.9061.\n",
      "[Epoch 293/1000] Train Loss: 0.4596  |  Val Loss: 0.9038\n",
      "Validation loss improved from 0.9061 to 0.9038.\n",
      "[Epoch 294/1000] Train Loss: 0.4568  |  Val Loss: 0.9013\n",
      "Validation loss improved from 0.9038 to 0.9013.\n",
      "[Epoch 295/1000] Train Loss: 0.4539  |  Val Loss: 0.8982\n",
      "Validation loss improved from 0.9013 to 0.8982.\n",
      "[Epoch 296/1000] Train Loss: 0.4511  |  Val Loss: 0.8959\n",
      "Validation loss improved from 0.8982 to 0.8959.\n",
      "[Epoch 297/1000] Train Loss: 0.4481  |  Val Loss: 0.8938\n",
      "Validation loss improved from 0.8959 to 0.8938.\n",
      "[Epoch 298/1000] Train Loss: 0.4452  |  Val Loss: 0.8924\n",
      "Validation loss improved from 0.8938 to 0.8924.\n",
      "[Epoch 299/1000] Train Loss: 0.4424  |  Val Loss: 0.8909\n",
      "Validation loss improved from 0.8924 to 0.8909.\n",
      "[Epoch 300/1000] Train Loss: 0.4397  |  Val Loss: 0.8896\n",
      "Validation loss improved from 0.8909 to 0.8896.\n",
      "[Epoch 301/1000] Train Loss: 0.4367  |  Val Loss: 0.8893\n",
      "Validation loss improved from 0.8896 to 0.8893.\n",
      "[Epoch 302/1000] Train Loss: 0.4335  |  Val Loss: 0.8886\n",
      "Validation loss improved from 0.8893 to 0.8886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 303/1000] Train Loss: 0.4308  |  Val Loss: 0.8873\n",
      "Validation loss improved from 0.8886 to 0.8873.\n",
      "[Epoch 304/1000] Train Loss: 0.4279  |  Val Loss: 0.8859\n",
      "Validation loss improved from 0.8873 to 0.8859.\n",
      "[Epoch 305/1000] Train Loss: 0.4252  |  Val Loss: 0.8850\n",
      "Validation loss improved from 0.8859 to 0.8850.\n",
      "[Epoch 306/1000] Train Loss: 0.4226  |  Val Loss: 0.8840\n",
      "Validation loss improved from 0.8850 to 0.8840.\n",
      "[Epoch 307/1000] Train Loss: 0.4198  |  Val Loss: 0.8824\n",
      "Validation loss improved from 0.8840 to 0.8824.\n",
      "[Epoch 308/1000] Train Loss: 0.4171  |  Val Loss: 0.8802\n",
      "Validation loss improved from 0.8824 to 0.8802.\n",
      "[Epoch 309/1000] Train Loss: 0.4145  |  Val Loss: 0.8767\n",
      "Validation loss improved from 0.8802 to 0.8767.\n",
      "[Epoch 310/1000] Train Loss: 0.4120  |  Val Loss: 0.8740\n",
      "Validation loss improved from 0.8767 to 0.8740.\n",
      "[Epoch 311/1000] Train Loss: 0.4093  |  Val Loss: 0.8726\n",
      "Validation loss improved from 0.8740 to 0.8726.\n",
      "[Epoch 312/1000] Train Loss: 0.4069  |  Val Loss: 0.8713\n",
      "Validation loss improved from 0.8726 to 0.8713.\n",
      "[Epoch 313/1000] Train Loss: 0.4043  |  Val Loss: 0.8696\n",
      "Validation loss improved from 0.8713 to 0.8696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 314/1000] Train Loss: 0.4021  |  Val Loss: 0.8676\n",
      "Validation loss improved from 0.8696 to 0.8676.\n",
      "[Epoch 315/1000] Train Loss: 0.3997  |  Val Loss: 0.8662\n",
      "Validation loss improved from 0.8676 to 0.8662.\n",
      "[Epoch 316/1000] Train Loss: 0.3973  |  Val Loss: 0.8650\n",
      "Validation loss improved from 0.8662 to 0.8650.\n",
      "[Epoch 317/1000] Train Loss: 0.3951  |  Val Loss: 0.8642\n",
      "Validation loss improved from 0.8650 to 0.8642.\n",
      "[Epoch 318/1000] Train Loss: 0.3927  |  Val Loss: 0.8631\n",
      "Validation loss improved from 0.8642 to 0.8631.\n",
      "[Epoch 319/1000] Train Loss: 0.3904  |  Val Loss: 0.8602\n",
      "Validation loss improved from 0.8631 to 0.8602.\n",
      "[Epoch 320/1000] Train Loss: 0.3881  |  Val Loss: 0.8569\n",
      "Validation loss improved from 0.8602 to 0.8569.\n",
      "[Epoch 321/1000] Train Loss: 0.3857  |  Val Loss: 0.8536\n",
      "Validation loss improved from 0.8569 to 0.8536.\n",
      "[Epoch 322/1000] Train Loss: 0.3832  |  Val Loss: 0.8511\n",
      "Validation loss improved from 0.8536 to 0.8511.\n",
      "[Epoch 323/1000] Train Loss: 0.3808  |  Val Loss: 0.8488\n",
      "Validation loss improved from 0.8511 to 0.8488.\n",
      "[Epoch 324/1000] Train Loss: 0.3787  |  Val Loss: 0.8472\n",
      "Validation loss improved from 0.8488 to 0.8472.\n",
      "[Epoch 325/1000] Train Loss: 0.3764  |  Val Loss: 0.8461\n",
      "Validation loss improved from 0.8472 to 0.8461.\n",
      "[Epoch 326/1000] Train Loss: 0.3740  |  Val Loss: 0.8450\n",
      "Validation loss improved from 0.8461 to 0.8450.\n",
      "[Epoch 327/1000] Train Loss: 0.3718  |  Val Loss: 0.8439\n",
      "Validation loss improved from 0.8450 to 0.8439.\n",
      "[Epoch 328/1000] Train Loss: 0.3699  |  Val Loss: 0.8437\n",
      "Validation loss improved from 0.8439 to 0.8437.\n",
      "[Epoch 329/1000] Train Loss: 0.3679  |  Val Loss: 0.8427\n",
      "Validation loss improved from 0.8437 to 0.8427.\n",
      "[Epoch 330/1000] Train Loss: 0.3658  |  Val Loss: 0.8415\n",
      "Validation loss improved from 0.8427 to 0.8415.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 331/1000] Train Loss: 0.3638  |  Val Loss: 0.8404\n",
      "Validation loss improved from 0.8415 to 0.8404.\n",
      "[Epoch 332/1000] Train Loss: 0.3618  |  Val Loss: 0.8396\n",
      "Validation loss improved from 0.8404 to 0.8396.\n",
      "[Epoch 333/1000] Train Loss: 0.3597  |  Val Loss: 0.8391\n",
      "Validation loss improved from 0.8396 to 0.8391.\n",
      "[Epoch 334/1000] Train Loss: 0.3576  |  Val Loss: 0.8386\n",
      "Validation loss improved from 0.8391 to 0.8386.\n",
      "[Epoch 335/1000] Train Loss: 0.3558  |  Val Loss: 0.8375\n",
      "Validation loss improved from 0.8386 to 0.8375.\n",
      "[Epoch 336/1000] Train Loss: 0.3538  |  Val Loss: 0.8354\n",
      "Validation loss improved from 0.8375 to 0.8354.\n",
      "[Epoch 337/1000] Train Loss: 0.3514  |  Val Loss: 0.8340\n",
      "Validation loss improved from 0.8354 to 0.8340.\n",
      "[Epoch 338/1000] Train Loss: 0.3494  |  Val Loss: 0.8323\n",
      "Validation loss improved from 0.8340 to 0.8323.\n",
      "[Epoch 339/1000] Train Loss: 0.3472  |  Val Loss: 0.8302\n",
      "Validation loss improved from 0.8323 to 0.8302.\n",
      "[Epoch 340/1000] Train Loss: 0.3449  |  Val Loss: 0.8264\n",
      "Validation loss improved from 0.8302 to 0.8264.\n",
      "[Epoch 341/1000] Train Loss: 0.3429  |  Val Loss: 0.8234\n",
      "Validation loss improved from 0.8264 to 0.8234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 342/1000] Train Loss: 0.3406  |  Val Loss: 0.8208\n",
      "Validation loss improved from 0.8234 to 0.8208.\n",
      "[Epoch 343/1000] Train Loss: 0.3388  |  Val Loss: 0.8176\n",
      "Validation loss improved from 0.8208 to 0.8176.\n",
      "[Epoch 344/1000] Train Loss: 0.3370  |  Val Loss: 0.8142\n",
      "Validation loss improved from 0.8176 to 0.8142.\n",
      "[Epoch 345/1000] Train Loss: 0.3353  |  Val Loss: 0.8106\n",
      "Validation loss improved from 0.8142 to 0.8106.\n",
      "[Epoch 346/1000] Train Loss: 0.3334  |  Val Loss: 0.8077\n",
      "Validation loss improved from 0.8106 to 0.8077.\n",
      "[Epoch 347/1000] Train Loss: 0.3318  |  Val Loss: 0.8054\n",
      "Validation loss improved from 0.8077 to 0.8054.\n",
      "[Epoch 348/1000] Train Loss: 0.3298  |  Val Loss: 0.8043\n",
      "Validation loss improved from 0.8054 to 0.8043.\n",
      "[Epoch 349/1000] Train Loss: 0.3279  |  Val Loss: 0.8034\n",
      "Validation loss improved from 0.8043 to 0.8034.\n",
      "[Epoch 350/1000] Train Loss: 0.3261  |  Val Loss: 0.8028\n",
      "Validation loss improved from 0.8034 to 0.8028.\n",
      "[Epoch 351/1000] Train Loss: 0.3242  |  Val Loss: 0.8035\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 352/1000] Train Loss: 0.3220  |  Val Loss: 0.8045\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 353/1000] Train Loss: 0.3203  |  Val Loss: 0.8053\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 354/1000] Train Loss: 0.3187  |  Val Loss: 0.8052\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 355/1000] Train Loss: 0.3172  |  Val Loss: 0.8048\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 356/1000] Train Loss: 0.3153  |  Val Loss: 0.8036\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 357/1000] Train Loss: 0.3132  |  Val Loss: 0.8008\n",
      "Validation loss improved from 0.8028 to 0.8008.\n",
      "[Epoch 358/1000] Train Loss: 0.3119  |  Val Loss: 0.7984\n",
      "Validation loss improved from 0.8008 to 0.7984.\n",
      "[Epoch 359/1000] Train Loss: 0.3099  |  Val Loss: 0.7966\n",
      "Validation loss improved from 0.7984 to 0.7966.\n",
      "[Epoch 360/1000] Train Loss: 0.3082  |  Val Loss: 0.7953\n",
      "Validation loss improved from 0.7966 to 0.7953.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 361/1000] Train Loss: 0.3066  |  Val Loss: 0.7952\n",
      "Validation loss improved from 0.7953 to 0.7952.\n",
      "[Epoch 362/1000] Train Loss: 0.3053  |  Val Loss: 0.7947\n",
      "Validation loss improved from 0.7952 to 0.7947.\n",
      "[Epoch 363/1000] Train Loss: 0.3036  |  Val Loss: 0.7933\n",
      "Validation loss improved from 0.7947 to 0.7933.\n",
      "[Epoch 364/1000] Train Loss: 0.3020  |  Val Loss: 0.7923\n",
      "Validation loss improved from 0.7933 to 0.7923.\n",
      "[Epoch 365/1000] Train Loss: 0.3005  |  Val Loss: 0.7918\n",
      "Validation loss improved from 0.7923 to 0.7918.\n",
      "[Epoch 366/1000] Train Loss: 0.2988  |  Val Loss: 0.7921\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 367/1000] Train Loss: 0.2977  |  Val Loss: 0.7928\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 368/1000] Train Loss: 0.2961  |  Val Loss: 0.7920\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 369/1000] Train Loss: 0.2944  |  Val Loss: 0.7906\n",
      "Validation loss improved from 0.7918 to 0.7906.\n",
      "[Epoch 370/1000] Train Loss: 0.2934  |  Val Loss: 0.7888\n",
      "Validation loss improved from 0.7906 to 0.7888.\n",
      "[Epoch 371/1000] Train Loss: 0.2922  |  Val Loss: 0.7863\n",
      "Validation loss improved from 0.7888 to 0.7863.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 372/1000] Train Loss: 0.2908  |  Val Loss: 0.7849\n",
      "Validation loss improved from 0.7863 to 0.7849.\n",
      "[Epoch 373/1000] Train Loss: 0.2892  |  Val Loss: 0.7838\n",
      "Validation loss improved from 0.7849 to 0.7838.\n",
      "[Epoch 374/1000] Train Loss: 0.2875  |  Val Loss: 0.7821\n",
      "Validation loss improved from 0.7838 to 0.7821.\n",
      "[Epoch 375/1000] Train Loss: 0.2860  |  Val Loss: 0.7807\n",
      "Validation loss improved from 0.7821 to 0.7807.\n",
      "[Epoch 376/1000] Train Loss: 0.2843  |  Val Loss: 0.7782\n",
      "Validation loss improved from 0.7807 to 0.7782.\n",
      "[Epoch 377/1000] Train Loss: 0.2829  |  Val Loss: 0.7759\n",
      "Validation loss improved from 0.7782 to 0.7759.\n",
      "[Epoch 378/1000] Train Loss: 0.2815  |  Val Loss: 0.7740\n",
      "Validation loss improved from 0.7759 to 0.7740.\n",
      "[Epoch 379/1000] Train Loss: 0.2799  |  Val Loss: 0.7728\n",
      "Validation loss improved from 0.7740 to 0.7728.\n",
      "[Epoch 380/1000] Train Loss: 0.2784  |  Val Loss: 0.7722\n",
      "Validation loss improved from 0.7728 to 0.7722.\n",
      "[Epoch 381/1000] Train Loss: 0.2769  |  Val Loss: 0.7719\n",
      "Validation loss improved from 0.7722 to 0.7719.\n",
      "[Epoch 382/1000] Train Loss: 0.2754  |  Val Loss: 0.7719\n",
      "Validation loss improved from 0.7719 to 0.7719.\n",
      "[Epoch 383/1000] Train Loss: 0.2738  |  Val Loss: 0.7721\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 384/1000] Train Loss: 0.2724  |  Val Loss: 0.7728\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 385/1000] Train Loss: 0.2712  |  Val Loss: 0.7737\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 386/1000] Train Loss: 0.2700  |  Val Loss: 0.7740\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 387/1000] Train Loss: 0.2686  |  Val Loss: 0.7740\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 388/1000] Train Loss: 0.2673  |  Val Loss: 0.7729\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 389/1000] Train Loss: 0.2658  |  Val Loss: 0.7708\n",
      "Validation loss improved from 0.7719 to 0.7708.\n",
      "[Epoch 390/1000] Train Loss: 0.2645  |  Val Loss: 0.7685\n",
      "Validation loss improved from 0.7708 to 0.7685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 391/1000] Train Loss: 0.2632  |  Val Loss: 0.7663\n",
      "Validation loss improved from 0.7685 to 0.7663.\n",
      "[Epoch 392/1000] Train Loss: 0.2621  |  Val Loss: 0.7645\n",
      "Validation loss improved from 0.7663 to 0.7645.\n",
      "[Epoch 393/1000] Train Loss: 0.2607  |  Val Loss: 0.7634\n",
      "Validation loss improved from 0.7645 to 0.7634.\n",
      "[Epoch 394/1000] Train Loss: 0.2594  |  Val Loss: 0.7625\n",
      "Validation loss improved from 0.7634 to 0.7625.\n",
      "[Epoch 395/1000] Train Loss: 0.2582  |  Val Loss: 0.7621\n",
      "Validation loss improved from 0.7625 to 0.7621.\n",
      "[Epoch 396/1000] Train Loss: 0.2570  |  Val Loss: 0.7620\n",
      "Validation loss improved from 0.7621 to 0.7620.\n",
      "[Epoch 397/1000] Train Loss: 0.2557  |  Val Loss: 0.7626\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 398/1000] Train Loss: 0.2545  |  Val Loss: 0.7630\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 399/1000] Train Loss: 0.2531  |  Val Loss: 0.7628\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 400/1000] Train Loss: 0.2518  |  Val Loss: 0.7623\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 401/1000] Train Loss: 0.2505  |  Val Loss: 0.7615\n",
      "Validation loss improved from 0.7620 to 0.7615.\n",
      "[Epoch 402/1000] Train Loss: 0.2496  |  Val Loss: 0.7609\n",
      "Validation loss improved from 0.7615 to 0.7609.\n",
      "[Epoch 403/1000] Train Loss: 0.2484  |  Val Loss: 0.7604\n",
      "Validation loss improved from 0.7609 to 0.7604.\n",
      "[Epoch 404/1000] Train Loss: 0.2471  |  Val Loss: 0.7610\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 405/1000] Train Loss: 0.2458  |  Val Loss: 0.7611\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 406/1000] Train Loss: 0.2447  |  Val Loss: 0.7602\n",
      "Validation loss improved from 0.7604 to 0.7602.\n",
      "[Epoch 407/1000] Train Loss: 0.2437  |  Val Loss: 0.7601\n",
      "Validation loss improved from 0.7602 to 0.7601.\n",
      "[Epoch 408/1000] Train Loss: 0.2424  |  Val Loss: 0.7594\n",
      "Validation loss improved from 0.7601 to 0.7594.\n",
      "[Epoch 409/1000] Train Loss: 0.2412  |  Val Loss: 0.7584\n",
      "Validation loss improved from 0.7594 to 0.7584.\n",
      "[Epoch 410/1000] Train Loss: 0.2400  |  Val Loss: 0.7578\n",
      "Validation loss improved from 0.7584 to 0.7578.\n",
      "[Epoch 411/1000] Train Loss: 0.2388  |  Val Loss: 0.7577\n",
      "Validation loss improved from 0.7578 to 0.7577.\n",
      "[Epoch 412/1000] Train Loss: 0.2376  |  Val Loss: 0.7572\n",
      "Validation loss improved from 0.7577 to 0.7572.\n",
      "[Epoch 413/1000] Train Loss: 0.2364  |  Val Loss: 0.7559\n",
      "Validation loss improved from 0.7572 to 0.7559.\n",
      "[Epoch 414/1000] Train Loss: 0.2351  |  Val Loss: 0.7541\n",
      "Validation loss improved from 0.7559 to 0.7541.\n",
      "[Epoch 415/1000] Train Loss: 0.2340  |  Val Loss: 0.7525\n",
      "Validation loss improved from 0.7541 to 0.7525.\n",
      "[Epoch 416/1000] Train Loss: 0.2329  |  Val Loss: 0.7494\n",
      "Validation loss improved from 0.7525 to 0.7494.\n",
      "[Epoch 417/1000] Train Loss: 0.2319  |  Val Loss: 0.7463\n",
      "Validation loss improved from 0.7494 to 0.7463.\n",
      "[Epoch 418/1000] Train Loss: 0.2308  |  Val Loss: 0.7434\n",
      "Validation loss improved from 0.7463 to 0.7434.\n",
      "[Epoch 419/1000] Train Loss: 0.2301  |  Val Loss: 0.7412\n",
      "Validation loss improved from 0.7434 to 0.7412.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 420/1000] Train Loss: 0.2290  |  Val Loss: 0.7410\n",
      "Validation loss improved from 0.7412 to 0.7410.\n",
      "[Epoch 421/1000] Train Loss: 0.2281  |  Val Loss: 0.7405\n",
      "Validation loss improved from 0.7410 to 0.7405.\n",
      "[Epoch 422/1000] Train Loss: 0.2272  |  Val Loss: 0.7395\n",
      "Validation loss improved from 0.7405 to 0.7395.\n",
      "[Epoch 423/1000] Train Loss: 0.2263  |  Val Loss: 0.7399\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 424/1000] Train Loss: 0.2248  |  Val Loss: 0.7406\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 425/1000] Train Loss: 0.2238  |  Val Loss: 0.7414\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 426/1000] Train Loss: 0.2227  |  Val Loss: 0.7422\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 427/1000] Train Loss: 0.2217  |  Val Loss: 0.7428\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 428/1000] Train Loss: 0.2206  |  Val Loss: 0.7433\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 429/1000] Train Loss: 0.2194  |  Val Loss: 0.7434\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 430/1000] Train Loss: 0.2186  |  Val Loss: 0.7444\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 431/1000] Train Loss: 0.2177  |  Val Loss: 0.7448\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 432/1000] Train Loss: 0.2168  |  Val Loss: 0.7441\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 433/1000] Train Loss: 0.2161  |  Val Loss: 0.7436\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 434/1000] Train Loss: 0.2150  |  Val Loss: 0.7434\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 435/1000] Train Loss: 0.2140  |  Val Loss: 0.7428\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 436/1000] Train Loss: 0.2131  |  Val Loss: 0.7422\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 437/1000] Train Loss: 0.2123  |  Val Loss: 0.7420\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 438/1000] Train Loss: 0.2112  |  Val Loss: 0.7428\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 439/1000] Train Loss: 0.2103  |  Val Loss: 0.7449\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 440/1000] Train Loss: 0.2093  |  Val Loss: 0.7467\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 441/1000] Train Loss: 0.2083  |  Val Loss: 0.7477\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 442/1000] Train Loss: 0.2074  |  Val Loss: 0.7486\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 443/1000] Train Loss: 0.2067  |  Val Loss: 0.7499\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 444/1000] Train Loss: 0.2057  |  Val Loss: 0.7504\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 445/1000] Train Loss: 0.2050  |  Val Loss: 0.7507\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 446/1000] Train Loss: 0.2043  |  Val Loss: 0.7504\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 447/1000] Train Loss: 0.2035  |  Val Loss: 0.7499\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 448/1000] Train Loss: 0.2023  |  Val Loss: 0.7479\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 449/1000] Train Loss: 0.2013  |  Val Loss: 0.7456\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 450/1000] Train Loss: 0.2003  |  Val Loss: 0.7419\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 451/1000] Train Loss: 0.1994  |  Val Loss: 0.7380\n",
      "Validation loss improved from 0.7395 to 0.7380.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 452/1000] Train Loss: 0.1982  |  Val Loss: 0.7358\n",
      "Validation loss improved from 0.7380 to 0.7358.\n",
      "[Epoch 453/1000] Train Loss: 0.1973  |  Val Loss: 0.7349\n",
      "Validation loss improved from 0.7358 to 0.7349.\n",
      "[Epoch 454/1000] Train Loss: 0.1965  |  Val Loss: 0.7348\n",
      "Validation loss improved from 0.7349 to 0.7348.\n",
      "[Epoch 455/1000] Train Loss: 0.1960  |  Val Loss: 0.7357\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 456/1000] Train Loss: 0.1951  |  Val Loss: 0.7360\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 457/1000] Train Loss: 0.1942  |  Val Loss: 0.7358\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 458/1000] Train Loss: 0.1936  |  Val Loss: 0.7362\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 459/1000] Train Loss: 0.1930  |  Val Loss: 0.7352\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 460/1000] Train Loss: 0.1922  |  Val Loss: 0.7337\n",
      "Validation loss improved from 0.7348 to 0.7337.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 461/1000] Train Loss: 0.1913  |  Val Loss: 0.7323\n",
      "Validation loss improved from 0.7337 to 0.7323.\n",
      "[Epoch 462/1000] Train Loss: 0.1904  |  Val Loss: 0.7313\n",
      "Validation loss improved from 0.7323 to 0.7313.\n",
      "[Epoch 463/1000] Train Loss: 0.1893  |  Val Loss: 0.7309\n",
      "Validation loss improved from 0.7313 to 0.7309.\n",
      "[Epoch 464/1000] Train Loss: 0.1884  |  Val Loss: 0.7308\n",
      "Validation loss improved from 0.7309 to 0.7308.\n",
      "[Epoch 465/1000] Train Loss: 0.1873  |  Val Loss: 0.7299\n",
      "Validation loss improved from 0.7308 to 0.7299.\n",
      "[Epoch 466/1000] Train Loss: 0.1863  |  Val Loss: 0.7290\n",
      "Validation loss improved from 0.7299 to 0.7290.\n",
      "[Epoch 467/1000] Train Loss: 0.1857  |  Val Loss: 0.7284\n",
      "Validation loss improved from 0.7290 to 0.7284.\n",
      "[Epoch 468/1000] Train Loss: 0.1847  |  Val Loss: 0.7273\n",
      "Validation loss improved from 0.7284 to 0.7273.\n",
      "[Epoch 469/1000] Train Loss: 0.1839  |  Val Loss: 0.7259\n",
      "Validation loss improved from 0.7273 to 0.7259.\n",
      "[Epoch 470/1000] Train Loss: 0.1832  |  Val Loss: 0.7232\n",
      "Validation loss improved from 0.7259 to 0.7232.\n",
      "[Epoch 471/1000] Train Loss: 0.1823  |  Val Loss: 0.7224\n",
      "Validation loss improved from 0.7232 to 0.7224.\n",
      "[Epoch 472/1000] Train Loss: 0.1815  |  Val Loss: 0.7219\n",
      "Validation loss improved from 0.7224 to 0.7219.\n",
      "[Epoch 473/1000] Train Loss: 0.1807  |  Val Loss: 0.7209\n",
      "Validation loss improved from 0.7219 to 0.7209.\n",
      "[Epoch 474/1000] Train Loss: 0.1801  |  Val Loss: 0.7194\n",
      "Validation loss improved from 0.7209 to 0.7194.\n",
      "[Epoch 475/1000] Train Loss: 0.1792  |  Val Loss: 0.7180\n",
      "Validation loss improved from 0.7194 to 0.7180.\n",
      "[Epoch 476/1000] Train Loss: 0.1785  |  Val Loss: 0.7161\n",
      "Validation loss improved from 0.7180 to 0.7161.\n",
      "[Epoch 477/1000] Train Loss: 0.1778  |  Val Loss: 0.7142\n",
      "Validation loss improved from 0.7161 to 0.7142.\n",
      "[Epoch 478/1000] Train Loss: 0.1773  |  Val Loss: 0.7116\n",
      "Validation loss improved from 0.7142 to 0.7116.\n",
      "[Epoch 479/1000] Train Loss: 0.1766  |  Val Loss: 0.7099\n",
      "Validation loss improved from 0.7116 to 0.7099.\n",
      "[Epoch 480/1000] Train Loss: 0.1758  |  Val Loss: 0.7090\n",
      "Validation loss improved from 0.7099 to 0.7090.\n",
      "[Epoch 481/1000] Train Loss: 0.1747  |  Val Loss: 0.7096\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 482/1000] Train Loss: 0.1741  |  Val Loss: 0.7091\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 483/1000] Train Loss: 0.1736  |  Val Loss: 0.7087\n",
      "Validation loss improved from 0.7090 to 0.7087.\n",
      "[Epoch 484/1000] Train Loss: 0.1727  |  Val Loss: 0.7090\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 485/1000] Train Loss: 0.1719  |  Val Loss: 0.7098\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 486/1000] Train Loss: 0.1711  |  Val Loss: 0.7103\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 487/1000] Train Loss: 0.1703  |  Val Loss: 0.7095\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 488/1000] Train Loss: 0.1696  |  Val Loss: 0.7097\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 489/1000] Train Loss: 0.1688  |  Val Loss: 0.7089\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 490/1000] Train Loss: 0.1679  |  Val Loss: 0.7066\n",
      "Validation loss improved from 0.7087 to 0.7066.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 491/1000] Train Loss: 0.1674  |  Val Loss: 0.7045\n",
      "Validation loss improved from 0.7066 to 0.7045.\n",
      "[Epoch 492/1000] Train Loss: 0.1666  |  Val Loss: 0.7014\n",
      "Validation loss improved from 0.7045 to 0.7014.\n",
      "[Epoch 493/1000] Train Loss: 0.1661  |  Val Loss: 0.6997\n",
      "Validation loss improved from 0.7014 to 0.6997.\n",
      "[Epoch 494/1000] Train Loss: 0.1656  |  Val Loss: 0.6994\n",
      "Validation loss improved from 0.6997 to 0.6994.\n",
      "[Epoch 495/1000] Train Loss: 0.1649  |  Val Loss: 0.6997\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 496/1000] Train Loss: 0.1639  |  Val Loss: 0.7013\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 497/1000] Train Loss: 0.1629  |  Val Loss: 0.7042\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 498/1000] Train Loss: 0.1620  |  Val Loss: 0.7072\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 499/1000] Train Loss: 0.1613  |  Val Loss: 0.7103\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 500/1000] Train Loss: 0.1606  |  Val Loss: 0.7127\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 501/1000] Train Loss: 0.1602  |  Val Loss: 0.7130\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 502/1000] Train Loss: 0.1595  |  Val Loss: 0.7117\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 503/1000] Train Loss: 0.1587  |  Val Loss: 0.7111\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 504/1000] Train Loss: 0.1580  |  Val Loss: 0.7081\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 505/1000] Train Loss: 0.1574  |  Val Loss: 0.7050\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 506/1000] Train Loss: 0.1566  |  Val Loss: 0.7015\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 507/1000] Train Loss: 0.1560  |  Val Loss: 0.6990\n",
      "Validation loss improved from 0.6994 to 0.6990.\n",
      "[Epoch 508/1000] Train Loss: 0.1554  |  Val Loss: 0.6971\n",
      "Validation loss improved from 0.6990 to 0.6971.\n",
      "[Epoch 509/1000] Train Loss: 0.1548  |  Val Loss: 0.6966\n",
      "Validation loss improved from 0.6971 to 0.6966.\n",
      "[Epoch 510/1000] Train Loss: 0.1543  |  Val Loss: 0.6973\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 511/1000] Train Loss: 0.1535  |  Val Loss: 0.6983\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 512/1000] Train Loss: 0.1531  |  Val Loss: 0.6985\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 513/1000] Train Loss: 0.1525  |  Val Loss: 0.6973\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 514/1000] Train Loss: 0.1519  |  Val Loss: 0.6962\n",
      "Validation loss improved from 0.6966 to 0.6962.\n",
      "[Epoch 515/1000] Train Loss: 0.1511  |  Val Loss: 0.6958\n",
      "Validation loss improved from 0.6962 to 0.6958.\n",
      "[Epoch 516/1000] Train Loss: 0.1506  |  Val Loss: 0.6954\n",
      "Validation loss improved from 0.6958 to 0.6954.\n",
      "[Epoch 517/1000] Train Loss: 0.1500  |  Val Loss: 0.6948\n",
      "Validation loss improved from 0.6954 to 0.6948.\n",
      "[Epoch 518/1000] Train Loss: 0.1494  |  Val Loss: 0.6937\n",
      "Validation loss improved from 0.6948 to 0.6937.\n",
      "[Epoch 519/1000] Train Loss: 0.1488  |  Val Loss: 0.6937\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 520/1000] Train Loss: 0.1482  |  Val Loss: 0.6940\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 521/1000] Train Loss: 0.1477  |  Val Loss: 0.6951\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 522/1000] Train Loss: 0.1469  |  Val Loss: 0.6953\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 523/1000] Train Loss: 0.1461  |  Val Loss: 0.6951\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 524/1000] Train Loss: 0.1458  |  Val Loss: 0.6953\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n",
      "[Epoch 525/1000] Train Loss: 0.1451  |  Val Loss: 0.6967\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 526/1000] Train Loss: 0.1444  |  Val Loss: 0.6991\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 527/1000] Train Loss: 0.1439  |  Val Loss: 0.7005\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 528/1000] Train Loss: 0.1433  |  Val Loss: 0.7001\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 529/1000] Train Loss: 0.1427  |  Val Loss: 0.7010\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 530/1000] Train Loss: 0.1422  |  Val Loss: 0.7018\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 531/1000] Train Loss: 0.1417  |  Val Loss: 0.7015\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 532/1000] Train Loss: 0.1410  |  Val Loss: 0.7011\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 533/1000] Train Loss: 0.1407  |  Val Loss: 0.7010\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 534/1000] Train Loss: 0.1401  |  Val Loss: 0.7008\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 535/1000] Train Loss: 0.1394  |  Val Loss: 0.7014\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 536/1000] Train Loss: 0.1387  |  Val Loss: 0.7027\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 537/1000] Train Loss: 0.1379  |  Val Loss: 0.7046\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 538/1000] Train Loss: 0.1374  |  Val Loss: 0.7066\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 539/1000] Train Loss: 0.1367  |  Val Loss: 0.7080\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 540/1000] Train Loss: 0.1360  |  Val Loss: 0.7099\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 541/1000] Train Loss: 0.1355  |  Val Loss: 0.7109\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 542/1000] Train Loss: 0.1350  |  Val Loss: 0.7111\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 543/1000] Train Loss: 0.1343  |  Val Loss: 0.7117\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 544/1000] Train Loss: 0.1341  |  Val Loss: 0.7116\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 545/1000] Train Loss: 0.1339  |  Val Loss: 0.7117\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 546/1000] Train Loss: 0.1337  |  Val Loss: 0.7123\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 547/1000] Train Loss: 0.1334  |  Val Loss: 0.7122\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 548/1000] Train Loss: 0.1331  |  Val Loss: 0.7125\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n",
      "[Epoch 549/1000] Train Loss: 0.1326  |  Val Loss: 0.7128\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 550/1000] Train Loss: 0.1321  |  Val Loss: 0.7132\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 551/1000] Train Loss: 0.1313  |  Val Loss: 0.7130\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 552/1000] Train Loss: 0.1306  |  Val Loss: 0.7122\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 553/1000] Train Loss: 0.1296  |  Val Loss: 0.7123\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n",
      "[Epoch 554/1000] Train Loss: 0.1291  |  Val Loss: 0.7124\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 555/1000] Train Loss: 0.1284  |  Val Loss: 0.7122\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 556/1000] Train Loss: 0.1278  |  Val Loss: 0.7115\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 557/1000] Train Loss: 0.1272  |  Val Loss: 0.7109\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 558/1000] Train Loss: 0.1266  |  Val Loss: 0.7108\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 559/1000] Train Loss: 0.1262  |  Val Loss: 0.7097\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 560/1000] Train Loss: 0.1255  |  Val Loss: 0.7061\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 561/1000] Train Loss: 0.1250  |  Val Loss: 0.7025\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 562/1000] Train Loss: 0.1243  |  Val Loss: 0.7001\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 563/1000] Train Loss: 0.1237  |  Val Loss: 0.6972\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 564/1000] Train Loss: 0.1232  |  Val Loss: 0.6944\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 565/1000] Train Loss: 0.1228  |  Val Loss: 0.6928\n",
      "Validation loss improved from 0.6937 to 0.6928.\n",
      "[Epoch 566/1000] Train Loss: 0.1223  |  Val Loss: 0.6916\n",
      "Validation loss improved from 0.6928 to 0.6916.\n",
      "[Epoch 567/1000] Train Loss: 0.1219  |  Val Loss: 0.6903\n",
      "Validation loss improved from 0.6916 to 0.6903.\n",
      "[Epoch 568/1000] Train Loss: 0.1213  |  Val Loss: 0.6881\n",
      "Validation loss improved from 0.6903 to 0.6881.\n",
      "[Epoch 569/1000] Train Loss: 0.1211  |  Val Loss: 0.6863\n",
      "Validation loss improved from 0.6881 to 0.6863.\n",
      "[Epoch 570/1000] Train Loss: 0.1205  |  Val Loss: 0.6855\n",
      "Validation loss improved from 0.6863 to 0.6855.\n",
      "[Epoch 571/1000] Train Loss: 0.1200  |  Val Loss: 0.6837\n",
      "Validation loss improved from 0.6855 to 0.6837.\n",
      "[Epoch 572/1000] Train Loss: 0.1195  |  Val Loss: 0.6823\n",
      "Validation loss improved from 0.6837 to 0.6823.\n",
      "[Epoch 573/1000] Train Loss: 0.1192  |  Val Loss: 0.6805\n",
      "Validation loss improved from 0.6823 to 0.6805.\n",
      "[Epoch 574/1000] Train Loss: 0.1191  |  Val Loss: 0.6784\n",
      "Validation loss improved from 0.6805 to 0.6784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 575/1000] Train Loss: 0.1190  |  Val Loss: 0.6782\n",
      "Validation loss improved from 0.6784 to 0.6782.\n",
      "[Epoch 576/1000] Train Loss: 0.1183  |  Val Loss: 0.6796\n",
      "!! Validation loss did NOT improve !! Patience: 1/100\n",
      "[Epoch 577/1000] Train Loss: 0.1176  |  Val Loss: 0.6818\n",
      "!! Validation loss did NOT improve !! Patience: 2/100\n",
      "[Epoch 578/1000] Train Loss: 0.1170  |  Val Loss: 0.6849\n",
      "!! Validation loss did NOT improve !! Patience: 3/100\n",
      "[Epoch 579/1000] Train Loss: 0.1162  |  Val Loss: 0.6878\n",
      "!! Validation loss did NOT improve !! Patience: 4/100\n",
      "[Epoch 580/1000] Train Loss: 0.1161  |  Val Loss: 0.6913\n",
      "!! Validation loss did NOT improve !! Patience: 5/100\n",
      "[Epoch 581/1000] Train Loss: 0.1157  |  Val Loss: 0.6938\n",
      "!! Validation loss did NOT improve !! Patience: 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 582/1000] Train Loss: 0.1155  |  Val Loss: 0.6963\n",
      "!! Validation loss did NOT improve !! Patience: 7/100\n",
      "[Epoch 583/1000] Train Loss: 0.1150  |  Val Loss: 0.6979\n",
      "!! Validation loss did NOT improve !! Patience: 8/100\n",
      "[Epoch 584/1000] Train Loss: 0.1147  |  Val Loss: 0.6994\n",
      "!! Validation loss did NOT improve !! Patience: 9/100\n",
      "[Epoch 585/1000] Train Loss: 0.1140  |  Val Loss: 0.6999\n",
      "!! Validation loss did NOT improve !! Patience: 10/100\n",
      "[Epoch 586/1000] Train Loss: 0.1134  |  Val Loss: 0.6984\n",
      "!! Validation loss did NOT improve !! Patience: 11/100\n",
      "[Epoch 587/1000] Train Loss: 0.1129  |  Val Loss: 0.6965\n",
      "!! Validation loss did NOT improve !! Patience: 12/100\n",
      "[Epoch 588/1000] Train Loss: 0.1124  |  Val Loss: 0.6933\n",
      "!! Validation loss did NOT improve !! Patience: 13/100\n",
      "[Epoch 589/1000] Train Loss: 0.1117  |  Val Loss: 0.6910\n",
      "!! Validation loss did NOT improve !! Patience: 14/100\n",
      "[Epoch 590/1000] Train Loss: 0.1112  |  Val Loss: 0.6890\n",
      "!! Validation loss did NOT improve !! Patience: 15/100\n",
      "[Epoch 591/1000] Train Loss: 0.1108  |  Val Loss: 0.6874\n",
      "!! Validation loss did NOT improve !! Patience: 16/100\n",
      "[Epoch 592/1000] Train Loss: 0.1104  |  Val Loss: 0.6863\n",
      "!! Validation loss did NOT improve !! Patience: 17/100\n",
      "[Epoch 593/1000] Train Loss: 0.1099  |  Val Loss: 0.6856\n",
      "!! Validation loss did NOT improve !! Patience: 18/100\n",
      "[Epoch 594/1000] Train Loss: 0.1095  |  Val Loss: 0.6850\n",
      "!! Validation loss did NOT improve !! Patience: 19/100\n",
      "[Epoch 595/1000] Train Loss: 0.1090  |  Val Loss: 0.6856\n",
      "!! Validation loss did NOT improve !! Patience: 20/100\n",
      "[Epoch 596/1000] Train Loss: 0.1086  |  Val Loss: 0.6872\n",
      "!! Validation loss did NOT improve !! Patience: 21/100\n",
      "[Epoch 597/1000] Train Loss: 0.1080  |  Val Loss: 0.6887\n",
      "!! Validation loss did NOT improve !! Patience: 22/100\n",
      "[Epoch 598/1000] Train Loss: 0.1077  |  Val Loss: 0.6888\n",
      "!! Validation loss did NOT improve !! Patience: 23/100\n",
      "[Epoch 599/1000] Train Loss: 0.1072  |  Val Loss: 0.6885\n",
      "!! Validation loss did NOT improve !! Patience: 24/100\n",
      "[Epoch 600/1000] Train Loss: 0.1068  |  Val Loss: 0.6872\n",
      "!! Validation loss did NOT improve !! Patience: 25/100\n",
      "[Epoch 601/1000] Train Loss: 0.1062  |  Val Loss: 0.6861\n",
      "!! Validation loss did NOT improve !! Patience: 26/100\n",
      "[Epoch 602/1000] Train Loss: 0.1059  |  Val Loss: 0.6848\n",
      "!! Validation loss did NOT improve !! Patience: 27/100\n",
      "[Epoch 603/1000] Train Loss: 0.1054  |  Val Loss: 0.6852\n",
      "!! Validation loss did NOT improve !! Patience: 28/100\n",
      "[Epoch 604/1000] Train Loss: 0.1049  |  Val Loss: 0.6862\n",
      "!! Validation loss did NOT improve !! Patience: 29/100\n",
      "[Epoch 605/1000] Train Loss: 0.1047  |  Val Loss: 0.6876\n",
      "!! Validation loss did NOT improve !! Patience: 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 606/1000] Train Loss: 0.1043  |  Val Loss: 0.6883\n",
      "!! Validation loss did NOT improve !! Patience: 31/100\n",
      "[Epoch 607/1000] Train Loss: 0.1037  |  Val Loss: 0.6884\n",
      "!! Validation loss did NOT improve !! Patience: 32/100\n",
      "[Epoch 608/1000] Train Loss: 0.1033  |  Val Loss: 0.6877\n",
      "!! Validation loss did NOT improve !! Patience: 33/100\n",
      "[Epoch 609/1000] Train Loss: 0.1030  |  Val Loss: 0.6863\n",
      "!! Validation loss did NOT improve !! Patience: 34/100\n",
      "[Epoch 610/1000] Train Loss: 0.1026  |  Val Loss: 0.6858\n",
      "!! Validation loss did NOT improve !! Patience: 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 611/1000] Train Loss: 0.1023  |  Val Loss: 0.6844\n",
      "!! Validation loss did NOT improve !! Patience: 36/100\n",
      "[Epoch 612/1000] Train Loss: 0.1020  |  Val Loss: 0.6829\n",
      "!! Validation loss did NOT improve !! Patience: 37/100\n",
      "[Epoch 613/1000] Train Loss: 0.1017  |  Val Loss: 0.6824\n",
      "!! Validation loss did NOT improve !! Patience: 38/100\n",
      "[Epoch 614/1000] Train Loss: 0.1011  |  Val Loss: 0.6831\n",
      "!! Validation loss did NOT improve !! Patience: 39/100\n",
      "[Epoch 615/1000] Train Loss: 0.1009  |  Val Loss: 0.6838\n",
      "!! Validation loss did NOT improve !! Patience: 40/100\n",
      "[Epoch 616/1000] Train Loss: 0.1004  |  Val Loss: 0.6845\n",
      "!! Validation loss did NOT improve !! Patience: 41/100\n",
      "[Epoch 617/1000] Train Loss: 0.0998  |  Val Loss: 0.6850\n",
      "!! Validation loss did NOT improve !! Patience: 42/100\n",
      "[Epoch 618/1000] Train Loss: 0.0994  |  Val Loss: 0.6853\n",
      "!! Validation loss did NOT improve !! Patience: 43/100\n",
      "[Epoch 619/1000] Train Loss: 0.0991  |  Val Loss: 0.6842\n",
      "!! Validation loss did NOT improve !! Patience: 44/100\n",
      "[Epoch 620/1000] Train Loss: 0.0986  |  Val Loss: 0.6836\n",
      "!! Validation loss did NOT improve !! Patience: 45/100\n",
      "[Epoch 621/1000] Train Loss: 0.0983  |  Val Loss: 0.6842\n",
      "!! Validation loss did NOT improve !! Patience: 46/100\n",
      "[Epoch 622/1000] Train Loss: 0.0980  |  Val Loss: 0.6856\n",
      "!! Validation loss did NOT improve !! Patience: 47/100\n",
      "[Epoch 623/1000] Train Loss: 0.0975  |  Val Loss: 0.6865\n",
      "!! Validation loss did NOT improve !! Patience: 48/100\n",
      "[Epoch 624/1000] Train Loss: 0.0971  |  Val Loss: 0.6870\n",
      "!! Validation loss did NOT improve !! Patience: 49/100\n",
      "[Epoch 625/1000] Train Loss: 0.0964  |  Val Loss: 0.6877\n",
      "!! Validation loss did NOT improve !! Patience: 50/100\n",
      "[Epoch 626/1000] Train Loss: 0.0965  |  Val Loss: 0.6889\n",
      "!! Validation loss did NOT improve !! Patience: 51/100\n",
      "[Epoch 627/1000] Train Loss: 0.0960  |  Val Loss: 0.6898\n",
      "!! Validation loss did NOT improve !! Patience: 52/100\n",
      "[Epoch 628/1000] Train Loss: 0.0955  |  Val Loss: 0.6897\n",
      "!! Validation loss did NOT improve !! Patience: 53/100\n",
      "[Epoch 629/1000] Train Loss: 0.0952  |  Val Loss: 0.6897\n",
      "!! Validation loss did NOT improve !! Patience: 54/100\n",
      "[Epoch 630/1000] Train Loss: 0.0948  |  Val Loss: 0.6899\n",
      "!! Validation loss did NOT improve !! Patience: 55/100\n",
      "[Epoch 631/1000] Train Loss: 0.0945  |  Val Loss: 0.6898\n",
      "!! Validation loss did NOT improve !! Patience: 56/100\n",
      "[Epoch 632/1000] Train Loss: 0.0941  |  Val Loss: 0.6903\n",
      "!! Validation loss did NOT improve !! Patience: 57/100\n",
      "[Epoch 633/1000] Train Loss: 0.0936  |  Val Loss: 0.6913\n",
      "!! Validation loss did NOT improve !! Patience: 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 634/1000] Train Loss: 0.0932  |  Val Loss: 0.6934\n",
      "!! Validation loss did NOT improve !! Patience: 59/100\n",
      "[Epoch 635/1000] Train Loss: 0.0928  |  Val Loss: 0.6963\n",
      "!! Validation loss did NOT improve !! Patience: 60/100\n",
      "[Epoch 636/1000] Train Loss: 0.0926  |  Val Loss: 0.6979\n",
      "!! Validation loss did NOT improve !! Patience: 61/100\n",
      "[Epoch 637/1000] Train Loss: 0.0922  |  Val Loss: 0.6975\n",
      "!! Validation loss did NOT improve !! Patience: 62/100\n",
      "[Epoch 638/1000] Train Loss: 0.0916  |  Val Loss: 0.6951\n",
      "!! Validation loss did NOT improve !! Patience: 63/100\n",
      "[Epoch 639/1000] Train Loss: 0.0914  |  Val Loss: 0.6922\n",
      "!! Validation loss did NOT improve !! Patience: 64/100\n",
      "[Epoch 640/1000] Train Loss: 0.0908  |  Val Loss: 0.6909\n",
      "!! Validation loss did NOT improve !! Patience: 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 641/1000] Train Loss: 0.0905  |  Val Loss: 0.6887\n",
      "!! Validation loss did NOT improve !! Patience: 66/100\n",
      "[Epoch 642/1000] Train Loss: 0.0902  |  Val Loss: 0.6868\n",
      "!! Validation loss did NOT improve !! Patience: 67/100\n",
      "[Epoch 643/1000] Train Loss: 0.0901  |  Val Loss: 0.6867\n",
      "!! Validation loss did NOT improve !! Patience: 68/100\n",
      "[Epoch 644/1000] Train Loss: 0.0899  |  Val Loss: 0.6878\n",
      "!! Validation loss did NOT improve !! Patience: 69/100\n",
      "[Epoch 645/1000] Train Loss: 0.0897  |  Val Loss: 0.6892\n",
      "!! Validation loss did NOT improve !! Patience: 70/100\n",
      "[Epoch 646/1000] Train Loss: 0.0892  |  Val Loss: 0.6901\n",
      "!! Validation loss did NOT improve !! Patience: 71/100\n",
      "[Epoch 647/1000] Train Loss: 0.0888  |  Val Loss: 0.6923\n",
      "!! Validation loss did NOT improve !! Patience: 72/100\n",
      "[Epoch 648/1000] Train Loss: 0.0885  |  Val Loss: 0.6955\n",
      "!! Validation loss did NOT improve !! Patience: 73/100\n",
      "[Epoch 649/1000] Train Loss: 0.0880  |  Val Loss: 0.6966\n",
      "!! Validation loss did NOT improve !! Patience: 74/100\n",
      "[Epoch 650/1000] Train Loss: 0.0878  |  Val Loss: 0.6962\n",
      "!! Validation loss did NOT improve !! Patience: 75/100\n",
      "[Epoch 651/1000] Train Loss: 0.0878  |  Val Loss: 0.6957\n",
      "!! Validation loss did NOT improve !! Patience: 76/100\n",
      "[Epoch 652/1000] Train Loss: 0.0873  |  Val Loss: 0.6940\n",
      "!! Validation loss did NOT improve !! Patience: 77/100\n",
      "[Epoch 653/1000] Train Loss: 0.0871  |  Val Loss: 0.6928\n",
      "!! Validation loss did NOT improve !! Patience: 78/100\n",
      "[Epoch 654/1000] Train Loss: 0.0866  |  Val Loss: 0.6931\n",
      "!! Validation loss did NOT improve !! Patience: 79/100\n",
      "[Epoch 655/1000] Train Loss: 0.0865  |  Val Loss: 0.6942\n",
      "!! Validation loss did NOT improve !! Patience: 80/100\n",
      "[Epoch 656/1000] Train Loss: 0.0862  |  Val Loss: 0.6940\n",
      "!! Validation loss did NOT improve !! Patience: 81/100\n",
      "[Epoch 657/1000] Train Loss: 0.0856  |  Val Loss: 0.6924\n",
      "!! Validation loss did NOT improve !! Patience: 82/100\n",
      "[Epoch 658/1000] Train Loss: 0.0849  |  Val Loss: 0.6894\n",
      "!! Validation loss did NOT improve !! Patience: 83/100\n",
      "[Epoch 659/1000] Train Loss: 0.0846  |  Val Loss: 0.6870\n",
      "!! Validation loss did NOT improve !! Patience: 84/100\n",
      "[Epoch 660/1000] Train Loss: 0.0843  |  Val Loss: 0.6854\n",
      "!! Validation loss did NOT improve !! Patience: 85/100\n",
      "[Epoch 661/1000] Train Loss: 0.0840  |  Val Loss: 0.6844\n",
      "!! Validation loss did NOT improve !! Patience: 86/100\n",
      "[Epoch 662/1000] Train Loss: 0.0837  |  Val Loss: 0.6835\n",
      "!! Validation loss did NOT improve !! Patience: 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 663/1000] Train Loss: 0.0834  |  Val Loss: 0.6832\n",
      "!! Validation loss did NOT improve !! Patience: 88/100\n",
      "[Epoch 664/1000] Train Loss: 0.0830  |  Val Loss: 0.6829\n",
      "!! Validation loss did NOT improve !! Patience: 89/100\n",
      "[Epoch 665/1000] Train Loss: 0.0827  |  Val Loss: 0.6834\n",
      "!! Validation loss did NOT improve !! Patience: 90/100\n",
      "[Epoch 666/1000] Train Loss: 0.0824  |  Val Loss: 0.6839\n",
      "!! Validation loss did NOT improve !! Patience: 91/100\n",
      "[Epoch 667/1000] Train Loss: 0.0820  |  Val Loss: 0.6845\n",
      "!! Validation loss did NOT improve !! Patience: 92/100\n",
      "[Epoch 668/1000] Train Loss: 0.0817  |  Val Loss: 0.6848\n",
      "!! Validation loss did NOT improve !! Patience: 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 669/1000] Train Loss: 0.0813  |  Val Loss: 0.6847\n",
      "!! Validation loss did NOT improve !! Patience: 94/100\n",
      "[Epoch 670/1000] Train Loss: 0.0811  |  Val Loss: 0.6847\n",
      "!! Validation loss did NOT improve !! Patience: 95/100\n",
      "[Epoch 671/1000] Train Loss: 0.0809  |  Val Loss: 0.6860\n",
      "!! Validation loss did NOT improve !! Patience: 96/100\n",
      "[Epoch 672/1000] Train Loss: 0.0806  |  Val Loss: 0.6876\n",
      "!! Validation loss did NOT improve !! Patience: 97/100\n",
      "[Epoch 673/1000] Train Loss: 0.0801  |  Val Loss: 0.6880\n",
      "!! Validation loss did NOT improve !! Patience: 98/100\n",
      "[Epoch 674/1000] Train Loss: 0.0797  |  Val Loss: 0.6887\n",
      "!! Validation loss did NOT improve !! Patience: 99/100\n",
      "[Epoch 675/1000] Train Loss: 0.0794  |  Val Loss: 0.6887\n",
      "!! Validation loss did NOT improve !! Patience: 100/100\n",
      "!! Early stopping triggered at epoch 675 !!\n",
      "No improvement for 100 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_input_dim = sclsdl_mlp_train_reps.shape[1]\n",
    "sclsdl_mlp_num_classes = len(torch.unique(sclsdl_mlp_train_labels_torch))\n",
    "sclsdl_mlp_model = MLPClassifier(sclsdl_mlp_input_dim, sclsdl_mlp_num_classes).to(device)\n",
    "\n",
    "sclsdl_mlp_criterion = nn.CrossEntropyLoss()\n",
    "sclsdl_mlp_optimizer = optim.Adam(sclsdl_mlp_model.parameters(), lr=1e-4)\n",
    "\n",
    "sclsdl_mlp_num_epochs = 1000\n",
    "sclsdl_mlp_patience = 100\n",
    "\n",
    "sclsdl_mlp_train_losses = []\n",
    "sclsdl_mlp_val_losses = []\n",
    "\n",
    "sclsdl_mlp_best_val_loss = float('inf')\n",
    "sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "for sclsdl_mlp_epoch in range(sclsdl_mlp_num_epochs):\n",
    "    # Training\n",
    "    sclsdl_mlp_model.train()\n",
    "    sclsdl_mlp_train_running_loss = 0.0\n",
    "    \n",
    "    for sclsdl_mlp_embeddings_batch, sclsdl_mlp_labels_batch in sclsdl_mlp_train_loader:\n",
    "        sclsdl_mlp_embeddings_batch = sclsdl_mlp_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_labels_batch = sclsdl_mlp_labels_batch.to(device)\n",
    "        \n",
    "        sclsdl_mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        sclsdl_mlp_outputs = sclsdl_mlp_model(sclsdl_mlp_embeddings_batch)\n",
    "        sclsdl_mlp_loss = sclsdl_mlp_criterion(sclsdl_mlp_outputs, sclsdl_mlp_labels_batch)\n",
    "        \n",
    "        # Backward & Update\n",
    "        sclsdl_mlp_loss.backward()\n",
    "        sclsdl_mlp_optimizer.step()\n",
    "        \n",
    "        sclsdl_mlp_train_running_loss += sclsdl_mlp_loss.item() * sclsdl_mlp_embeddings_batch.size(0)\n",
    "    \n",
    "    sclsdl_mlp_epoch_train_loss = sclsdl_mlp_train_running_loss / len(sclsdl_mlp_train_loader.dataset)\n",
    "    sclsdl_mlp_train_losses.append(sclsdl_mlp_epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    sclsdl_mlp_model.eval()\n",
    "    sclsdl_mlp_val_running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sclsdl_mlp_val_embeddings_batch, sclsdl_mlp_val_labels_batch in sclsdl_mlp_val_loader:\n",
    "            sclsdl_mlp_val_embeddings_batch = sclsdl_mlp_val_embeddings_batch.to(device)\n",
    "            sclsdl_mlp_val_labels_batch = sclsdl_mlp_val_labels_batch.to(device)\n",
    "\n",
    "            sclsdl_mlp_val_outputs = sclsdl_mlp_model(sclsdl_mlp_val_embeddings_batch)\n",
    "            sclsdl_mlp_val_loss = sclsdl_mlp_criterion(sclsdl_mlp_val_outputs, sclsdl_mlp_val_labels_batch)\n",
    "\n",
    "            sclsdl_mlp_val_running_loss += sclsdl_mlp_val_loss.item() * sclsdl_mlp_val_embeddings_batch.size(0)\n",
    "\n",
    "    sclsdl_mlp_epoch_val_loss = sclsdl_mlp_val_running_loss / len(sclsdl_mlp_val_loader.dataset)\n",
    "    sclsdl_mlp_val_losses.append(sclsdl_mlp_epoch_val_loss)\n",
    "\n",
    "    print(f\"[Epoch {sclsdl_mlp_epoch+1}/{sclsdl_mlp_num_epochs}] \"\n",
    "          f\"Train Loss: {sclsdl_mlp_epoch_train_loss:.4f}  |  \"\n",
    "          f\"Val Loss: {sclsdl_mlp_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if sclsdl_mlp_epoch_val_loss < sclsdl_mlp_best_val_loss:\n",
    "        print(f\"Validation loss improved from {sclsdl_mlp_best_val_loss:.4f} to {sclsdl_mlp_epoch_val_loss:.4f}.\")\n",
    "        sclsdl_mlp_best_val_loss = sclsdl_mlp_epoch_val_loss\n",
    "        sclsdl_mlp_epochs_without_improvement = 0\n",
    "\n",
    "\n",
    "    else:\n",
    "        sclsdl_mlp_epochs_without_improvement += 1\n",
    "        print(f\"!! Validation loss did NOT improve !! \"\n",
    "              f\"Patience: {sclsdl_mlp_epochs_without_improvement}/{sclsdl_mlp_patience}\")\n",
    "        \n",
    "        if sclsdl_mlp_epochs_without_improvement >= sclsdl_mlp_patience:\n",
    "            print(f\"!! Early stopping triggered at epoch {sclsdl_mlp_epoch+1} !!\\n\"\n",
    "                  f\"No improvement for {sclsdl_mlp_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(sclsdl_mlp_train_losses, label='Train Loss')\n",
    "plt.plot(sclsdl_mlp_val_losses,   label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:50:23.667711Z",
     "iopub.status.busy": "2025-05-08T18:50:23.667711Z",
     "iopub.status.idle": "2025-05-08T18:50:23.824351Z",
     "shell.execute_reply": "2025-05-08T18:50:23.824351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SCL_SDL+MLP predictions and true labels to model_predictions\n",
      "Test Loss: 0.4986 | Test Accuracy: 82.82%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclsdl_mlp_model.eval()\n",
    "\n",
    "sclsdl_mlp_test_running_loss = 0.0\n",
    "sclsdl_mlp_test_correct = 0\n",
    "sclsdl_mlp_all_predictions = []\n",
    "sclsdl_mlp_all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sclsdl_mlp_test_embeddings_batch, sclsdl_mlp_test_labels_batch in sclsdl_mlp_test_loader:\n",
    "        sclsdl_mlp_test_embeddings_batch = sclsdl_mlp_test_embeddings_batch.to(device)\n",
    "        sclsdl_mlp_test_labels_batch = sclsdl_mlp_test_labels_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        sclsdl_mlp_test_outputs = sclsdl_mlp_model(sclsdl_mlp_test_embeddings_batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        sclsdl_mlp_test_loss_batch = sclsdl_mlp_criterion(sclsdl_mlp_test_outputs, sclsdl_mlp_test_labels_batch)\n",
    "        sclsdl_mlp_test_running_loss += sclsdl_mlp_test_loss_batch.item() * sclsdl_mlp_test_embeddings_batch.size(0)\n",
    "\n",
    "        _, sclsdl_mlp_test_predicted = torch.max(sclsdl_mlp_test_outputs, dim=1)\n",
    "        sclsdl_mlp_test_correct += (sclsdl_mlp_test_predicted == sclsdl_mlp_test_labels_batch).sum().item()\n",
    "\n",
    "        sclsdl_mlp_all_predictions.extend(sclsdl_mlp_test_predicted.cpu().numpy())\n",
    "        sclsdl_mlp_all_true_labels.extend(sclsdl_mlp_test_labels_batch.cpu().numpy())\n",
    "\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_predictions.npy'), np.array(sclsdl_mlp_all_predictions))\n",
    "np.save(os.path.join(predictions_dir, 'sclsdl_mlp_true_labels.npy'), np.array(sclsdl_mlp_all_true_labels))\n",
    "print(f\"Saved SCL_SDL+MLP predictions and true labels to {predictions_dir}\")\n",
    "\n",
    "sclsdl_mlp_epoch_test_loss = sclsdl_mlp_test_running_loss / len(sclsdl_mlp_test_loader.dataset)\n",
    "sclsdl_mlp_test_accuracy = sclsdl_mlp_test_correct / len(sclsdl_mlp_test_loader.dataset)\n",
    "\n",
    "sclsdl_mlp_test_accuracy_pct = sclsdl_mlp_test_accuracy * 100.0\n",
    "\n",
    "print(f\"Test Loss: {sclsdl_mlp_epoch_test_loss:.4f} | Test Accuracy: {sclsdl_mlp_test_accuracy_pct:.2f}%\")\n",
    "\n",
    "sclsdl_mlp_num_epochs_run = len(sclsdl_mlp_train_losses)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_train_losses,\n",
    "         label='Train Loss')\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         sclsdl_mlp_val_losses,\n",
    "         label='Val Loss')\n",
    "\n",
    "plt.plot(range(1, sclsdl_mlp_num_epochs_run + 1),\n",
    "         [sclsdl_mlp_epoch_test_loss]*sclsdl_mlp_num_epochs_run,\n",
    "         'r--',\n",
    "         label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Results and Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:50:23.827076Z",
     "iopub.status.busy": "2025-05-08T18:50:23.827076Z",
     "iopub.status.idle": "2025-05-08T18:50:23.832437Z",
     "shell.execute_reply": "2025-05-08T18:50:23.832437Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_conf_matrix(model_name, class_names = None, cm_save_dir='confusion_matrices'):\n",
    "    os.makedirs(cm_save_dir, exist_ok = True)\n",
    "\n",
    "    #loading predictions and true labels\n",
    "    predictions_path = os.path.join(predictions_dir, f'{model_name}_predictions.npy')\n",
    "    true_labels_path = os.path.join(predictions_dir, f'{model_name}_true_labels.npy')\n",
    "\n",
    "    if not os.path.exists(predictions_path) or not os.path.exists(true_labels_path):\n",
    "        print(f\"Error: Files not found for model {model_name}\")\n",
    "        return\n",
    "    \n",
    "    cm_predictions = np.load(predictions_path)\n",
    "    cm_true_labels = np.load(true_labels_path)\n",
    "\n",
    "    conf_matrix = confusion_matrix(cm_true_labels, cm_predictions)\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    conf_matrix_normalised = conf_matrix.astype('float') / conf_matrix.sum(axis = 1)[:, np.newaxis]\n",
    "    sns.heatmap(conf_matrix_normalised, annot=conf_matrix, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "    plt.title(f\"{model_name.upper()} Confusion Matrix\", fontsize=16)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    cm_save_path = os.path.join(cm_save_dir, f'{model_name}_confusion_matrix.png')\n",
    "    plt.savefig(cm_save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved confusion matrix to: {cm_save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
    "    print(f\"Classification Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:50:23.835445Z",
     "iopub.status.busy": "2025-05-08T18:50:23.835445Z",
     "iopub.status.idle": "2025-05-08T18:50:28.769791Z",
     "shell.execute_reply": "2025-05-08T18:50:28.769791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving confusion matrices to: confusion_matrices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\e2e_cnn_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAMWCAYAAABIgshOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC4bUlEQVR4nOzdeVxN+ePH8fctbaJFUbLECCNLyBaSnQzDIIx1MHZj38LYyTL2fTf2LDPGGPvYxvolMYPGTqi0KrTX/f3h1x1Xt7pXt3vOh/fz8biPxzj33HNfnRo+ffqck0KpVCpBRERERESyYyR1ABERERERacbBOhERERGRTHGwTkREREQkUxysExERERHJFAfrREREREQyxcE6EREREZFMcbBORERERCRTHKwTEREREckUB+tERERERDLFwToRkQTOnDmDRo0awcrKCgqFAgqFAk+ePDHY+0+bNg0KhQLTpk0z2Ht+zho2bAiFQoEzZ85InUJEguFgnUiDUqVKqQZQ2T22bNmieo1SqcT58+cxduxY1KlTBzY2NjA1NYWTkxM6dOiA06dPZ/l+Gf+Q5/TQ18Dqn3/+wfDhw1GlShXY2trC1NQUDg4OaNasGRYvXoyoqCi1/c+cOaNqKFq0KBISEjQe9/nz56r9svsYlyxZkmXb999/n6uPNT09Hbt374aPjw+cnZ2RP39+WFpaomzZsujevTsOHToEpVL5UcfWl9u3b6NFixY4c+YM7O3tUa9ePdSrVw/m5uaSdslNxjcUCoUCDg4OSE1NzXLfqKgomJqaavx/Mze2bNmCadOmGfQbKSKi9+WTOoBIzsqWLYsiRYpk+byDg4Pqv0+dOoWmTZsCAIyMjODi4gJLS0vcv38fv/zyC3755RdMnjwZM2fOzPJ4JUqUQMmSJbN8PrvntJGWloaRI0di5cqVSE9PR758+eDi4oKCBQvi5cuXOHnyJE6ePInp06dj3759qo/nfWFhYVi9ejVGjRr10R1z585F//79kT9//tx8OJk8fPgQ7du3x99//w0AsLW1Rfny5aFUKvH06VPs2LEDO3bsgLu7O86fPy/Z4Hjjxo1ITk7GDz/8gGXLlknSYG9vj/Lly8Pe3l6S99dVeHg4jh8/jlatWml8fvfu3UhJSdH7+27ZsgVnz55Fw4YNUapUqY8+TsmSJVG+fHm9f80T0WdASUSZODs7KwEoN2/erPVrTpw4oXRxcVGuWrVKGR0drdqelJSk9PX1VQJQAlD+/vvvmV7r5eWlBKCcOnWqHuqz1qlTJyUAZcGCBZVLly5VxsbGqj3/+PFj5YQJE5T58+dXLl68WLX99OnTSgBKY2NjJQBlkSJFlG/fvs10/GfPnqk+zg9lfIwZx1iwYIHGxr59+37UuXjy5ImycOHCSgDKGjVqKE+fPq1MS0tTPZ+amqo8ffq0slmzZkoAypiYGJ2Or0/e3t5KAMrDhw9L1iCCqVOnKgEoy5cvrwSg7NKlS5b71q5dW6lQKJRly5bV+f/d7GR83Z4+fVovxyMi0hWXwRDpSa1atRAUFIRBgwbB1tZWtd3U1BRz5syBt7c3AGD9+vWS9G3YsAF79uyBhYUFTp8+jWHDhsHKykptn1KlSsHPzw9Xr16Fi4tLpmOUKlUKHh4eCA8Px8qVKz+q49tvvwUAzJ8/H2/fvv2oY2jSrVs3REREwMvLC+fOnUPDhg1hZPTfX3HGxsZo2LAhjh8/jpUrV8LY2Fhv762rjGVEFhYWkjWIpF69eihVqhR+++03vH79OtPzDx48wJUrV+Dl5ZXrnz4REckNB+tEemJlZYV8+bJeWdasWTMAwL179wyVpJKWlobZs2cDAKZMmQJ3d/ds93d1dUXr1q01Pjd9+nQA7wbbb9680bmlRYsWqFu3LiIiIrBixQqdX6/JqVOncOHCBZiYmGDr1q05DoIHDx6MggULqm1LSUnB8uXLUatWLVhZWcHS0hJubm6YPXs24uPjMx3jyZMnUCgUqqUR27dvR40aNZA/f34UKlQIPj4+ePTokdprvvvuO7WLDBs1aqRaY/3dd98BeLfs4v0/fyjj+oGGDRtmeu78+fP45ptv4OjoCBMTExQqVAgVKlTA999/j8uXL6vtm9MFphcvXkT79u3h4OAAU1NTFC9eHD179kRQUJDG/d+/gPLff/+Fj48P7O3tYWFhAXd3d+zZs0fj67ShUCjQrVs3JCQkYP/+/Zme37ZtGwCge/fuWR4jISEBu3btQpcuXVC+fHkUKFAABQoUQNWqVTFr1qxM3zhmnOezZ88CUP9cvb8m/sOvg/Xr16NmzZooWLCg2rUbmi4w/euvv2BsbAxLS0vcvXs3U/OdO3dgYWEBY2Nj/PXXX1qdKyL69HCwTmQgiYmJAKSZTb1y5QqePHmCfPnyoX///rk6VrNmzVC/fn1ERkZi+fLlH3WMjAH/ggULPmrA/6Hdu3cDAFq3bv1RM6sJCQlo2bIlhg0bhqtXr6J48eJwcXHBrVu3MHnyZNSrVy/TRbfv8/X1RY8ePRAZGYly5cohPj4e+/btU52nDOXKlUO9evVUP9GoVKmS6uLScuXK6dz9vt9++w1eXl44cOAAUlNTUaVKFTg4OODZs2fYuHGj6hxpY/Xq1ahfvz5+/fVXAICbmxvevn2Lbdu2oXr16vjjjz+yfG1AQABq1qyJY8eOoVSpUihYsCCuX7+Ozp07Y/v27R/98fXo0QMANB5jx44dMDc3R8eOHbPt6tq1K/bv34/4+HhUqFABTk5OuH37Nn788Uc0aNBA7cJpa2vrLD9X9erVU7teJcOgQYPQv39/vHz5El9++SVsbGyy/Zg8PT0xevRoxMfHo3v37moX0KakpKBHjx5ITEzE2LFj4enpme2xiOgTJvU6HCI5+pg169lJT09XVqtWTQlAOXTo0EzP5/Wa9QULFigBKKtWrfpRr89Ys16mTBmlUqlU/vnnn0oAykKFCinj4uJU+2mzZn3btm1KpVKpbNCggRKAcvbs2Wr7fcya9YoVKyoBKJcsWfIRH51SOXr0aCUApZOTkzIgIEC1/f79+8ovv/xSCUDZqVMntdc8fvxYCUCZL18+pZWVldr689DQUGWVKlWUAJTjx4/P9H7ZrYPevHmzEoCyV69eGlszPhdeXl5q2ytVqqQEoFy1apUyNTVVtT09PV15+vRp5cGDB9X2z1gP/uF5DgwMVObLl08JQDl//nzVuv/ExETl4MGDlQCU1tbWypCQEI0fk4mJiXLo0KHKhIQE1fuPHz9edX7fb8tJRmPfvn2VSqVSWbNmTaWRkZHy+fPnqn0uXLig9vlp0qSJxv93nzx5otyzZ4/y9evXattDQ0OVHTt2VAJQTps2LVNDTmvWM74OjI2NlZaWlsrffvtN9Vx8fHyOx0lKSlJ9rUyePFm1PeM6Fzc3N2VSUlLWJ4mIPnmcWSfKRu/evbO9leKrV6+0Os769esRGBgIU1NTjBgxIsv9pk+fnu373bhx46M+jhcvXgAASpcu/VGv/1Djxo3h5eWF6OhoLF269KOOkTG7vnDhQsTFxeWqJzcfX1xcHFavXg0AWLlyJapXr656zsXFBVu3bgUA7N27Fw8fPsz0+tTUVEydOlV1TQIAODo6YtasWQCAI0eO6Nz0Me7fvw9bW1sMGjRIbT1+xpKZNm3aaHWcn376CampqWjbti3Gjh2rWvdvZmaGFStWoGLFioiNjVWdsw+5urpi6dKlqjvtKBQKzJw5E46OjggJCVHdqedjdO/eHenp6dixY4dqmzZLYADA2dkZPj4+KFCggNp2R0dHbN26FaampmrH1VVaWhpmzJiBr7/+WrVNm5+imZqaYvv27TAzM4Ofnx8uXbqEixcvYv78+TA3N8eOHTtgamr60V1EJD4O1omyUbZsWbUffX/4yG6Neobr169j+PDhAIBZs2ahTJkyWe5bokSJbN/vw4GGtjIuyrO0tPyo12uSMdhetGgRYmNjdX59w4YN0bBhQ0RHR2d733Vt5ObjO3/+POLj41GyZEm0bds20/M1a9aEh4cHlEolTpw4ofEYffv21fg6AJnWreeVEiVK4NWrV1k2auv48eMAgB9++CHTcwqFAsOGDVPb70N9+vRRu7AXAExMTODm5gYgd+fj22+/Rb58+VRLYZKTk7Fnzx7Y29ujZcuWOb4+PT0dv/32G4YMGQJvb294enqifv36aNasGRQKBe7fv6/x+gRt9ezZ86NeV7lyZcyaNQtpaWno0aMHevTogbS0NMyZMwcVK1b86B4i+jTwPutE2Zg4cWKWF/pp4/Hjx2jdujUSExPRtWtXjBkzJtv9+/Tpkye/UTLjYkp93n3Fy8sLjRs3xqlTp7BkyRJMnTpV52PMmDEDDRo0wOLFizFs2LAc1/hmpWDBgnj16tVHfXwZF/x++eWXGn+ZEwBUrFgRly5d0nhxsL29PaytrTNtz7g/vz7W5Gtj5MiRGDJkCJo3bw53d3c0bdoU9evXh5eXV6aLabPy6tUrREREAHg3Q65JxuAxqwuls/pmVB/no3DhwmjevDkOHz6Mmzdv4vHjx4iOjsaQIUNgYmKS7WtfvXqFVq1a4dKlS9nuFxMT81H3Qre3t8/VPetHjRqFP/74Q3UBauPGjbP9KRwRfT44s06UR8LCwtCsWTOEhobiq6++Ut3lQwrFihUD8O6bB32aMWMGAGDx4sVaLwl6n6enJ5o2bYpXr15h8eLFH92Rm48vY/CozS+/0nTbwKxm8z+cXc5rgwcPxtatW+Hm5oaAgADMmzcPbdq0QZEiRdC/f3+tfvrx/kA6q/OR3bkAcj4fylz+9tj3LzTNmGHP2JadUaNG4dKlSyhfvjz279+PFy9eICkpCUqlEkqlUvU19LG/WCm3P7UyMjKCl5eX6s8Zdw4iIuJgnSgPREdHo1mzZnj48CG8vLywd+/eHGf+8lLdunUBALdu3UJ0dLTejluvXj00a9YMsbGxWLhw4UcdI2M5zZIlSxATE/NRx8j4+DJus6eLjKVF4eHhWe7z8uVLANB6hjo3MgZoWQ1qs/vpQY8ePXDjxg2EhoZi9+7d6Nu3L/Lly4f169fnuKYbgNoyq6zOhyHPhSZt27aFlZUVtm3bhkOHDqFs2bKoXbt2tq9JTU1V3Tryt99+Q/v27eHk5KRaC56amoqwsLA8b8/OjRs34Ofnp/qmZty4cWp3EiKizxcH60R69ubNG7Rq1Qq3bt1CzZo18fvvv0v+y29q166NUqVKITU1FevWrdPrsTNm15cuXfpR3wjUrVsXLVq0QFxc3EcP+Dt37gwAOHToEIKDg3V6bcYtE4OCgrIcIN++fVtt37yUMUObsRzlQw8ePMjxGI6OjujcuTM2bNiAK1euwMjICIcOHUJoaGi2r7OxsUHhwoUBvLvHtyaGPBeaWFhYoH379nj58iWSkpK0+iYkIiICb9++RaFChVC+fPlMz9+6dQtpaWkaX2uI2e3ExER0794dycnJmDFjBjp27IiwsDAMHDgwz9+biOSPg3UiPUpKSkLbtm1x5coVVKxYEUePHpVsBvJ9xsbG8PX1BQDMnDkT169fz3b/oKAgHDp0SKtj16lTB97e3nj9+jV++umnj+rLGPAvW7Ys2/uZZ6VJkybw8PBASkoKevXqpbqnfVbWrFmjWsZRv3595M+fH8+ePcNvv/2Wad9r167h0qVLUCgUql9slZe++OILAO9mWt+/7zbw7gLJzZs363Q8V1dX1Zr6kJCQHPdv0aIFAGi8h75SqVRtz9hPCv3790eTJk3QpEkTrZbAZHyzHBcXp3Yv9Qzz58/P8bWaXqcvEydOxO3bt1GnTh1MmDABa9asgaOjI/bv36+6GxERfb44WCfSk7S0NHTp0gWnTp1CmTJlcOLECRQqVEjqLJX+/fujQ4cOiI+PR6NGjbB8+fJM646fPXuGyZMno0aNGlrN4GbIWMqyc+fOj2qrVasWWrVqhdevX+P333//qGPs2LEDdnZ2OHPmDDw9PXHmzBmkp6ernk9PT8f58+fRsmVLDBo0SDWTamVlhUGDBgEAhg4disDAQNVrHj58iF69egEAOnXqlO2dfPTFzc0NTk5OCA0NxdSpU1Wz/YmJiRgxYoTGGe+4uDh06dIl08eclpaGZcuWISYmBpaWlhpnlT80evRo5MuXD7/99hsWLlyoOl5ycjKGDx+OW7duwdraWnXOpODh4YGTJ0/i5MmTWt2u08bGBhUrVkRqaipGjhyJ5ORkAO/Oz7x58+Dv75/l7REzvnn6mCVW2jh9+jSWLFmC/PnzY+vWrTA2NoadnR02bdoE4N1deXT9aRERfVp4NxiibMyZMwcbNmzI8vlOnTqpbmW3Z88eHDhwAMC7i8V8fHw0vqZo0aLYu3evxuc2bdqEkydPZvl+DRo0wJw5c7Ssz2z37t0YPnw4Vq9ejWHDhmH06NFwcXFBwYIFER4ejidPngAAChUqhCpVqmh93Jo1a6J169Zaz8ZrMmPGDBw+fDjL5Qg5KV26NC5duoT27dvj2rVraNSoEQoVKgRnZ2colUo8ffpUtSa+du3aakuTMn7acPr0aVSvXh2urq4wMTFRLY9wc3PDypUrP/pj04WxsTHmzZuHHj16YM6cOVi/fj2cnZ1x7949pKenw8/PL9NdhdLT0+Hv7w9/f39YWlrCxcUFJiYmePLkCSIjI6FQKLBkyRKtbv1ZtWpVLFu2DEOGDMGYMWOwYMEClCxZEvfv38erV69gZmaGHTt2wNHRMa9OQZ7w8/ND27ZtsXbtWuzduxdffPGF6vz8+OOP2Lp1K54+fZrpdZ07d8bKlSsxb948/Prrr3B0dIRCocCECRO0ul1kdmJjY/Hdd99BqVRi4cKFKFu2rOo5b29vDBw4EGvWrEGvXr1w6tQpXnBK9JniYJ0oG/fv38f9+/ezfL5GjRqq/05KStLqdc7Ozlke79mzZ3j27FmWz+fm1nAAkC9fPqxcuRIDBgzA+vXrcfr0aTx//hzx8fGwtbVFkyZN8PXXX6Nnz54630Zx+vTpuRqsu7u74+uvv8bBgwc/+hhly5bFjRs34O/vj/379+Pq1asICgqCQqGAk5MTWrVqhe7du6NFixZqAx8LCwscO3YMq1evxrZt2xAUFIT09HS4urqic+fOGDly5Efdzu9jde/eHWZmZpg3bx5u376NR48eoUmTJpg1a5bGCz8LFiyIbdu24fjx47h69SqePHmC5ORklChRAi1btsSYMWNU9znXxqBBg1ClShX89NNPuHDhAm7cuIHChQujdevW8PX1zfK2jnLWpk0bHDlyBDNmzEBgYCDu3r2LihUrYsmSJejWrVuWy008PT2xc+dOLFmyBLdv31bdsjI3t3TNMHToUAQHB6Nly5Ya16cvXLgQf/75J86cOYNFixZh9OjRuX5PIhKPQpnb+2gREREREVGe4Jp1IiIiIiKZ4mCdiIiIiEimuGadSDBhYWHo2LGj1vtPmjQJ3t7eeVhEREREeYWDdSLBJCYm4sKFC1rvn/EbJ4mIiOjjnTt3DgsWLEBAQABCQ0Px66+/ol27dtm+5uzZsxg1ahRu374NJycnjBs3TudfeMZlMESCKVWqFJRKpdYPfdy1goiI6HP39u1buLm5YcWKFVrt//jxY7Rq1Qqenp4IDAzExIkTMWzYMOzfv1+n9+XdYIiIiIiIdKBQKHKcWR8/fjwOHjyIoKAg1baBAwfi5s2buHTpktbvxZl1IiIiIvosJSUlIS4uTu3x/u9NyY1Lly6hefPmattatGiBa9euISUlRevjfLJr1i2qDZU6QSsxV7X7UQoRERHRxzCX2WhPTmO08W3tMX36dLVtU6dOxbRp03J97LCwMDg4OKhtc3BwQGpqKiIjI1G0aFGtjiOzTx8RERERkWH4+vpi1KhRatvMzMz0dvz3f1s2AGSsPv9we3Y4WCciIiKiz5KZmZleB+fvc3R0RFhYmNq28PBw5MuXD3Z2dlofh4N1IiIiIjIcxedxyaSHhwd+//13tW3Hjx9HjRo1YGJiovVxPo+zRURERESUC2/evMGNGzdw48YNAO9uzXjjxg0EBwcDeLekpmfPnqr9Bw4ciKdPn2LUqFEICgrCpk2bsHHjRowZM0an9+XMOhERERFRDq5du4ZGjRqp/pyx1r1Xr17YsmULQkNDVQN3AChdujQOHz6MkSNHYuXKlXBycsKyZcvQoUMHnd73k73PupyuNM4O7wZDREREeUl2d4NxHy51gkpCwFKpE3LEZTBERERERDLFwToRERERkUzJ7AcjRERERPRJ+0zuBqMvPFtERERERDLFmXUiIiIiMhwdfnsncWadiIiIiEi2OFgnIiIiIpIpLoMhIiIiIsPhBaY64dkiIiIiIpIpDtaJiIiIiGSKy2CIiIiIyHB4NxidcGadiIiIiEimPuvB+pg+zXF++1iEn/8JT//0w55F/VDWuYjaPuumd0dC4Aq1x9mfR6vtc2z98Ez7bJ3b25AfCgDAf9cOeDdvjJrVKqOLT3tcD7hm8IaciNAIiNEpQiMgRqcIjYAYnSI0AmJ0itAIiNEpQiMgTmeuKYzk8xCAGJV5xLO6C9b4n4NXz5/QetAKGBsb49Dqochvbqq237ELt1Gqqa/q0e6H1ZmOtXH/BbV9hs7aZagPAwBw9MhhzJ/rh379B8F/3wFUr+6OwQP6ITQkxKAd2RGhERCjU4RGQIxOERoBMTpFaATE6BShERCjU4RGQJxOMrzPerDedugqbP/9CoIeheGfey8wYNp2lCxaCNVcS6jtl5ycipdRr1WPmLj4TMdKSExW2yfuTaKhPgwAwLafN+ObDh3QvqMPvihTBuN8J8GxqCP2+Bv2m4bsiNAIiNEpQiMgRqcIjYAYnSI0AmJ0itAIiNEpQiMgTicZ3mc9WP+QVQFzAEBMrPpg3LNGWTz90w9/H5iClT9+i8K2BTK9tnOrGnh2ai4C9k2C38hvUCC/mUGaASAlORlBd27Do259te0edevh5o1Ag3VkR4RGQIxOERoBMTpFaATE6BShERCjU4RGQIxOERoBcTr1RqGQz0MAvBvMe+aN7oAL1x/gzsNQ1bbjF+7glxOBCA6NRqlidpgyuDWOrBuGul3nIzklFQCw+/BVPAmJwsvIOFR0ccKMH9qgcrliaD1ohUG6Y17FIC0tDXZ2dmrb7ezsERkZYZCGnIjQCIjRKUIjIEanCI2AGJ0iNAJidIrQCIjRKUIjIE4nSUP2g/Vnz55h6tSp2LRpU5b7JCUlISkpSW2bMj0NCiNjrd9n8YROqFzWCU16L1bbvu/4ddV/33kYiut3gnH38Ax4e1bEb6duAgA2/3pRbZ8HweG4uHM8qn5ZHDf+fa51Q24pPvgOUalUZtomNREaATE6RWgExOgUoREQo1OERkCMThEaATE6RWgExOkkw5L9Mpjo6Gj8/PPP2e7j5+cHa2trtUfqywCt32PReB+09qqMFv2W4UX4q2z3DYuMQ3BoNFxKFs5yn8CgZ0hOSYVLySJZ7qNPtja2MDY2RmRkpNr26Ogo2NnZG6QhJyI0AmJ0itAIiNEpQiMgRqcIjYAYnSI0AmJ0itAIiNOpN1LfAYZ3g9HNwYMHs32cPn06x2P4+voiNjZW7ZHPwV2r91883gdtG7uh5YBleBoSleP+hawtUdzBFqGRcVnu41qmKExN8iE0MlarhtwyMTVFBdeKuHzxgtr2yxcvwq1qNYM05ESERkCMThEaATE6RWgExOgUoREQo1OERkCMThEaAXE6SRqSL4Np164dFAoFlEpllvvk9CMgMzMzmJmpX9CpzRKYJb6d0Nm7BnxGrsObt4lwsCsIAIh9k4jEpBRYWphi8sCvcODPGwiNiIWzkx1m/NAGUa/e4OD/L4EpXdweXVrVwLHzdxAZ8wYVyjhi7sj2CAx6hks3HuXYoC89evXGpAnj4FqpEtzcqmH/Xn+EhobCp3MXgzXkRIRGQIxOERoBMTpFaATE6BShERCjU4RGQIxOERoBcTrJ8CQfrBctWhQrV65Eu3btND5/48YNuLtrN0uuqwGdGgAATmwYoba935Rt2P77FaSlK1HRxQldW9eCTUELhEXG4ezVe+gxfhPexL9bI5+SkopGtcpjyLeNUCC/KZ6HvcLR87cwe+0RpKdn/Q2IvrX0boXYVzFYt3oVIiLC4VK2HFauWQcnp2IGa8iJCI2AGJ0iNAJidIrQCIjRKUIjIEanCI2AGJ0iNALidOoF1+HrRKHMbkrbAL7++mtUrVoVM2bM0Pj8zZs3Ua1aNaSnp+t0XItqQ/WRl+dirhrmjjFERET0eTKXfGpWnUW9SVInqCRcmC11Qo4k//SNHTsWb9++zfJ5FxcXrdatExEREZEABLmwUy4kH6x7enpm+7ylpSW8vLwMVENEREREJB/81oaIiIiISKYkn1knIiIios8ILzDVCWfWiYiIiIhkioN1IiIiIiKZ4jIYIiIiIjIc3g1GJzxbREREREQyxcE6EREREZFMcRkMERERERkOl8HohGeLiIiIiEimOLNORERERIZjxPus64Iz60REREREMsXBOhERERGRTHEZDBEREREZDi8w1QnPFhERERGRTHGwTkREREQkU1wGQ0RERESGo+DdYHTBmXUiIiIiIpniYJ2IiIiISKY+2WUwMVdXSJ2gFduaQ6VOyJEo55KIiIgEwLvB6IRni4iIiIhIpj7ZmXUiIiIikiFeYKoTzqwTEREREckUB+tERERERDLFZTBEREREZDi8wFQnPFtERERERDLFwToRERERkUxxGQwRERERGQ7vBqMTzqwTEREREckUZ9aJiIiIyHB4galOeLaIiIiIiGSKg3UiIiIiIpniMhgiIiIiMhxeYKoTzqwTEREREckUB+tERERERDLFZTBEREREZDi8G4xOeLaIiIiIiGSKg3UiIiIiIpniYF0L/rt2wLt5Y9SsVhldfNrjesA1SXuMjY0wdXBrBB2ahuhLi3Dn92nw7d8Sig+uri5f2gF7lwxA2LkFCD//E87+PBolHG0lqn5HbucyKyJ0itAIiNEpQiMgRqcIjYAYnSI0AmJ0itAIiNOZawqFfB4C4GA9B0ePHMb8uX7o138Q/PcdQPXq7hg8oB9CQ0Ikaxr9XTN837E+Rs7di6rtZ2HS0gMY2bMpBnfxUu1Turg9/tw0Cvceh6FFv6Wo1dkPfuuPIjEpRbJuOZ5LTUToFKEREKNThEZAjE4RGgExOkVoBMToFKEREKeTDE+hVCqVUkfkhcRU/RynWxcfVHB1xeQp01Xb2rXxRqPGTTF85OhcH9+25lCdX7N/6UCER8dh0PSdqm27fvoe8QnJ6PvjVgDA1rm9kZKSpvpzbsRcXZHrYwB5fy71RYROERoBMTpFaATE6BShERCjU4RGQIxOERqBvO00l9ntRCxa62dcoQ8Jh3QfhxkaZ9azkZKcjKA7t+FRt77ado+69XDzRqBEVcClGw/RqFZ5uJQsAgCoXK4YPKp+gWMXbgMAFAoFWtaviPvB4Ti4cgie/umHc1vHoE3DKpI1y/VcfkiEThEaATE6RWgExOgUoREQo1OERkCMThEaAXE6SRoy+15LXmJexSAtLQ12dnZq2+3s7BEZGSFRFfDT5hOwKmCBm79ORlqaEsbGCkxdeQh7jgYAAIoUKoCCluYY07sZpq88hMlLD6B5PVfsXvg9WvRfhvMBDwzeLNdz+SEROkVoBMToFKEREKNThEZAjE4RGgExOkVoBMTpJGnIYrCekJCAgIAAFCpUCK6urmrPJSYmYs+ePejZs2eWr09KSkJSUpLaNqWxGczMzPTS9+GFm0qlMtM2Q/Jp4Y5vW9XEdxN/xp2HoahSvhgWjOmI0IhY7Pj9CoyM3v3A5NCZf7B8x2kAwN/3XqC22xfo17G+JIP1DHI7l1kRoVOERkCMThEaATE6RWgExOgUoREQo1OERkCczlzjfdZ1IvnZunfvHipUqIAGDRqgcuXKaNiwIUJDQ1XPx8bGonfv3tkew8/PD9bW1mqPBfP8ct1ma2MLY2NjREZGqm2Pjo6CnZ19ro//seaMaIefNp/A3mMBuP0gBLv+uIrlO05hbO9mAIDImDdISUlD0KNQtdfdfRQm2d1g5HouPyRCpwiNgBidIjQCYnSK0AiI0SlCIyBGpwiNgDidJA3JB+vjx49H5cqVER4ejrt378LKygr16tVDcHCw1sfw9fVFbGys2mPseN9ct5mYmqKCa0VcvnhBbfvlixfhVrVaro//sSzMTZGuTFfblpauVM2op6SmIeDOU5RzdlDbp6xzEQSHxhis831yPZcfEqFThEZAjE4RGgExOkVoBMToFKEREKNThEZAnE6ShuTLYC5evIiTJ0/C3t4e9vb2OHjwIIYMGQJPT0+cPn0alpaWOR7DzCzzkhd93Q2mR6/emDRhHFwrVYKbWzXs3+uP0NBQ+HTuop83+AiHz/2D8X1b4FloDO48DEXVL4tjWPdG2HrgsmqfxT+fxLZ5fXD++gOcvXYPzeu6olWDSmjRb6lk3XI8l5qI0ClCIyBGpwiNgBidIjQCYnSK0AiI0SlCIyBOp158ikt78pDkg/WEhATky6eesXLlShgZGcHLyws7d+7M4pWG0dK7FWJfxWDd6lWIiAiHS9lyWLlmHZyciknWNGreXkwd3BpLJ3ZGYdsCCI2IxcZ9FzBn3RHVPgdP/40fZu/G2D7NsXBcR9x7Go5vx27AxRuPJOuW47nURIROERoBMTpFaATE6BShERCjU4RGQIxOERoBcTrJ8CS/z3qtWrXwww8/oEePHpmeGzp0KHbs2IG4uDikpaXpdFx9zazntY+5z7qh6es+60RERGR4srvP+terpU5QSTg4SOqEHEm+Zv2bb77Brl27ND63YsUKfPvtt/hEf28TERER0edHYSSfhwAkn1nPK5xZ1x/OrBMREYlLdjPrbddKnaCS8NsAqRNyJLNPHxERERF90niBqU7EmP8nIiIiIvoMcbBORERERCRTXAZDRERERIYjyIWdcsGzRUREREQkUxysExERERHJFJfBEBEREZHh8G4wOuHMOhERERGRTHFmnYiIiIgMRsGZdZ1wZp2IiIiISKY4WCciIiIikikugyEiIiIig+EyGN1wZp2IiIiISKY4WCciIiIikikugyEiIiIiw+EqGJ1wZp2IiIiISKY4WCciIiIikikugyEiIiIig+HdYHTDwbrEYq6ukDohR7Z1RkqdoJWYy4ulTiCiPJSerpQ6IUdGRhyEEJF+cbBORERERAbDmXXdcM06EREREZFMcbBORERERCRTXAZDRERERAbDZTC64cw6EREREZFMcbBORERERCRTXAZDRERERAbDZTC64cw6EREREZFMcbBORERERCRTXAZDRERERIbDVTA64cw6EREREZFMcWadiIiIiAyGF5jqhjPrREREREQyxcE6EREREZFMcRkMERERERkMl8HohjPrREREREQyxcE6EREREZFMcRkMERERERkMl8HohjPrWvDftQPezRujZrXK6OLTHtcDrkmdpJGUnWO+a4LzP49E+Fk/PD0+A3t+6oOyzoXV9pnUvwVu7JuAyL/mIuTUbPyxchBqViypts/yiT64fWASos/PQ/CJmdizsA/KORcx2MeRQYTPuQiNgBidIjQCYnTKvXGP/y50av816tdxR/067ujZrTPO/3VO6iyN5H4uM4jQKUIjIE4nGRYH6zk4euQw5s/1Q7/+g+C/7wCqV3fH4AH9EBoSInWaGqk7PauXwZq95+HVeylaD1kDY2MjHFoxEPnNTVX7PHgagZHzf0GNLgvQ5PvleBoajd9XDoS9jaVqn8Cg5+g/fReq+szF10PXQqFQ4NDKgTAyMtx34VKfS22I0AiI0SlCIyBGpwiNDg4O+GHEaOzYvQ87du9Drdp1MHLYEDx8cF/qNDUinEtAjE4RGgFxOsnwFEqlUil1RF5ITNXPcbp18UEFV1dMnjJdta1dG280atwUw0eO1s+b6EFedtrWGanza+xtLPHs5Cw07bccFwIfadynoKUZws/OhfegVThzVfM/lJVciuLq7nFwbTsLj19EZfueMZcX69ypiQifcxEaATE6RWgExOjM68b09Lz558qrXm2MGD0W37TvmOtj6WtiQYTPNyBGpwiNQN52msts0bNdz11SJ6hEbf1W6oQccWY9GynJyQi6cxsedeurbfeoWw83bwRKVJWZHDutClgAAGLi4jU+b5LPGH2/8cCr1wn4557mWYP85qbo+XVtPH4ehecvX+VVqho5nssPidAIiNEpQiMgRqcIjR9KS0vD0SN/ICEhHlXcqkqdoyLKuRShU4RGQJxOkobMvteSl5hXMUhLS4OdnZ3adjs7e0RGRkhUlZkcO+eNaosLgY9w52GY2nbv+q7YOqcn8pubICwyDq2HrEZU7Fu1ffp3rIfZw9qgQH4z/Pv4Jb4ashopqWkG6ZbjufyQCI2AGJ0iNAJidIrQmOH+vbvo1f1bJCcnwSJ/fixcsgJlyrhInaUiyrkUoVOERkCcTr3h9aU6kcXMelBQEDZv3ox///0XAPDvv/9i0KBB6NOnD06dOpXj65OSkhAXF6f2SEpK0lvfh1ctK5VKWV7JLJfOxeM6oLKLE3pN2prpubPXHqB215/QqM8yHL/0L7b79UJh2wJq++w+EoA63X5C037L8eBZBLbP7QUzU8N+XymXc5kdERoBMTpFaATE6BShsVTp0ti971f8vGM3fDp1wZTJE/Dw4QOpszIR4VwCYnSK0AiI00mGJflg/ejRo6hatSrGjBmDatWq4ejRo2jQoAEePHiA4OBgtGjRIscBu5+fH6ytrdUeC+b55brN1sYWxsbGiIyMVNseHR0FOzv7XB9fX+TUuWhse7RuUBEtBq7Ei/DYTM/HJybj0fNI/O/WUwya6Y/UtHT0altbbZ+4t4l4+CwSFwIfoeu4LShfqgjaNqpskH45ncusiNAIiNEpQiMgRqcIjRlMTExRsqQzKlasjGEjRqNcuS+xa3vmyQWpiHIuRegUoREQp5OkIflgfcaMGRg7diyioqKwefNmdO3aFf369cOJEydw8uRJjBs3DnPnzs32GL6+voiNjVV7jB3vm+s2E1NTVHCtiMsXL6htv3zxItyqVsv18fVFLp2Lx7VH20aV0XLQKjwNidbqNQoFcpw1VygUMDUxzMy6XM5ldkRoBMToFKEREKNThMasKZGcnCx1hIoo51KEThEaAXE69UWhUMjmIQLJ16zfvn0bW7e+m9Ho1KkTevTogQ4dOqie//bbb7Fx48Zsj2FmZgYzMzO1bfq6G0yPXr0xacI4uFaqBDe3ati/1x+hoaHw6dxFP2+gJ1J3LhnfAZ1busNn9Ea8iU+Cg11BAEDsm0QkJqUgv7kpxvdpij/O3UZYZBwKWVuiv089FCtig19O3gQAlCpmh47NquLPy3cRGfMGTkWsMbpXEyQkpuDYhSCDfByA9OdSGyI0AmJ0itAIiNEpQuPypYtQr34DODo64u3btzh29DCuXf0fVq5eL3WaGhHOJSBGpwiNgDidZHiSD9bfZ2RkBHNzc9jY2Ki2FSxYELGxmZdTGEpL71aIfRWDdatXISIiHC5ly2HlmnVwciomWZMmUncO8Hl3BfuJdUPVtvebthPbD11FWno6ypdyQPfWNWFnUwDRsW9x7U4wmvZbjqBH7y5CTUpKQb1qX2Dot16wtbJAeNRrnA98hEZ9lyIi5o1BPg5A+nOpDREaATE6RWgExOgUoTEqKgqTJ45DZEQEChQsiLJly2Pl6vWoU7ee1GlqRDiXgBidIjQC4nSS4Ul+n3U3NzfMmzcPLVu2BADcunULX375JfLle/d9xPnz59GzZ088eqT5Xt1Z0dfMOn3cfdaloK/7rBORPOXVfdb1yZC/wI1IW3K7z3rh3v5SJ6hEbO4sdUKOJP/0DRo0CGlp/92Wr1KlSmrPHzlyBI0bNzZ0FhERERGR5CQfrA8cODDb52fPnm2gEiIiIiLKa6Jc2CkXkt8NhoiIiIiINONgnYiIiIhIpiRfBkNEREREnxGugtEJZ9aJiIiIiGSKg3UiIiIiIi2tWrUKpUuXhrm5Odzd3fHXX39lu/+OHTvg5uaG/Pnzo2jRoujduzeioqK0fj8O1omIiIjIYBQKhWweuvL398eIESMwadIkBAYGwtPTE97e3ggODta4f8bvC+rbty9u376NvXv34urVq/j++++1fk8O1omIiIiItLBo0SL07dsX33//PSpUqIAlS5agRIkSWL16tcb9L1++jFKlSmHYsGEoXbo06tevjwEDBuDatWtavycH60RERET0WUpKSkJcXJzaIykpSeO+ycnJCAgIQPPmzdW2N2/eHBcvXtT4mrp16+L58+c4fPgwlEolXr58iX379uGrr77SupGDdSIiIiIyGKmXvrz/8PPzg7W1tdrDz89PY3dkZCTS0tLg4OCgtt3BwQFhYWEaX1O3bl3s2LEDnTt3hqmpKRwdHWFjY4Ply5drfb44WCciIiKiz5Kvry9iY2PVHr6+vtm+5sO17kqlMsv173fu3MGwYcMwZcoUBAQE4OjRo3j8+DEGDhyodSPvs05EREREBvMxF3bmFTMzM5iZmWm1r729PYyNjTPNooeHh2eabc/g5+eHevXqYezYsQCAKlWqwNLSEp6enpg1axaKFi2a4/tyZp2IiIiIKAempqZwd3fHiRMn1LafOHECdevW1fia+Ph4GBmpD7eNjY0BvJuR1wYH60REREREWhg1ahQ2bNiATZs2ISgoCCNHjkRwcLBqWYuvry969uyp2r9Nmzb45ZdfsHr1ajx69AgXLlzAsGHDUKtWLTg5OWn1nlwGQ0REREQGI6dlMLrq3LkzoqKiMGPGDISGhqJSpUo4fPgwnJ2dAQChoaFq91z/7rvv8Pr1a6xYsQKjR4+GjY0NGjdujHnz5mn9ngqltnPwgklMlbrg02FbZ6TUCVqJubxY6gQiykPp6fL/58rISNxBCH26zGU2Nes04BepE1RC1raXOiFHXAZDRERERCRTMvtei4iIiIg+afwBlE44s05EREREJFOcWaccibIW3LbmUKkTchRzdYXUCUTC4npwIvoccbBORERERAYj8t1gpMBlMEREREREMsWZdSIiIiIyGM6s64Yz60REREREMsXBOhERERGRTHEZDBEREREZDJfB6IYz60REREREMsXBOhERERGRTHEZDBEREREZDlfB6IQz60REREREMsXBOhERERGRTHEZDBEREREZDO8GoxvOrBMRERERyRRn1omIiIjIYDizrhvOrBMRERERyRQH60REREREMsVlMERERERkMFwGoxvOrBMRERERyRQH61rw37UD3s0bo2a1yuji0x7XA65JnaSRCJ1SNo7p0xznt49F+Pmf8PRPP+xZ1A9lnYtk2m/SgFZ4dHw2oi8twrH1w1HhC0e1501N8mHReB88OzUXkRcXYu+SAShWxMZAH8V/RPh8A2J0itAIiNEpQiMgRqcIjYAYnSI0AuJ0kmFxsJ6Do0cOY/5cP/TrPwj++w6genV3DB7QD6EhIVKnqRGhU+pGz+ouWON/Dl49f0LrQStgbGyMQ6uHIr+5qWqf0d81xbDujTBy7h7U774AL6Pi8MeaH1Agv5lqnwVjO+DrRlXQ03czmvRejAIWpti/bCCMjAz3Yz2pz6W2ROgUoREQo1OERkCMThEaATE6RWgExOnUB4VCIZuHCBRKpVIpdUReSEzVz3G6dfFBBVdXTJ4yXbWtXRtvNGrcFMNHjtbPm+iBCJ153Whbc6hO+9vbFsCzU3PRtO9iXLj+EADw6PhsrNx5Ggu3nATwbhb96Z9zMHnpb9i4/wKsCpjj2am56Dt5K/Ydvw4AKFrYGvePzES7H1bj5KWgbN8z5uqKj/jIMhPh8w2I0SlCIyBGpwiNgBidIjQCYnSK0Ajkbae5zK5QLD3iD6kTVB4v+UrqhBzJcmZdLt8/pCQnI+jObXjUra+23aNuPdy8EShRVWYidMqx0aqAOQAgJjYeAFCqmB2KFrbGyUv/qvZJTknFXwEPUMftCwBAtQolYWqST21QHhoRi9sPQ1DHrbRBuuV4LjURoVOERkCMThEaATE6RWgExOgUoREQp1NvFDJ6CECWg3UzMzMEBWU/Q2kIMa9ikJaWBjs7O7Xtdnb2iIyMkKgqMxE65dg4b3QHXLj+AHcehgIAHO2tAADh0a/V9guPeg0Hu3fPOdpZISk5Ba9eJ2S5T16T47nURIROERoBMTpFaATE6BShERCjU4RGQJxOkoakPxgZNWqUxu1paWmYO3eu6ot20aJF2R4nKSkJSUlJatuUxmYwMzPL4hW6+XBNk1KplOU6JxE65dK4eEInVC7rhCa9F2d67sOf7CgUOf+0R6FQwNA/D5LLucyJCJ0iNAJidIrQCIjRKUIjIEanCI2AOJ1kWJIO1pcsWQI3NzfY2NiobVcqlQgKCoKlpaVWX6R+fn6YPn262rZJP07F5CnTctVna2MLY2NjREZGqm2Pjo6CnZ19ro6tTyJ0yqlx0XgftPaqjKZ9l+BF+CvV9rDIOACAg52V6r8BoHChgqrZ9rCoOJiZmsCmoIXa7HrhQgVw+eYjg/TL6VxmR4ROERoBMTpFaATE6BShERCjU4RGQJxOfeE3ILqRdBnM7NmzERsbix9//BGnT59WPYyNjbFlyxacPn0ap06dyvE4vr6+iI2NVXuMHe+b6z4TU1NUcK2IyxcvqG2/fPEi3KpWy/Xx9UWETrk0Lh7vg7aN3dBywDI8DYlSe+7JiyiERsSiSZ0vVdtM8hnD091FNRAPDApGckqq2j6O9laoWMYJl28+NsjHIJdzmRMROkVoBMToFKEREKNThEZAjE4RGgFxOkkaks6s+/r6omnTpujevTvatGkDPz8/mJiY6HwcM7PMS170dTeYHr16Y9KEcXCtVAlubtWwf68/QkND4dO5i37eQE9E6JS6cYlvJ3T2rgGfkevw5m0iHOwKAgBi3yQiMSkFALBy52mM7dscD4LD8SA4AuP6tkBCYgr8j7y7123cm0RsOXAJc0e1R1TsW8TExsNv5De49SAEp678m+V765vU51JbInSK0AiI0SlCIyBGpwiNgBidIjQC4nSS4Ul+M5+aNWsiICAAQ4YMQY0aNbB9+3ZZ/XikpXcrxL6KwbrVqxAREQ6XsuWwcs06ODkVkzpNjQidUjcO6NQAAHBiwwi17f2mbMP2368AABZuOQlzM1Ms8e0MW6v8uHrrCVoPWoE38f9dEzHup/1IS0vH9nl9YWFmgtP/u4v+w7chPd1wq9alPpfaEqFThEZAjE4RGgExOkVoBMToFKEREKdTH+Q0zhOBrO6zvnv3bowYMQIRERH4559/4Orq+tHH0tfMOolD1/usS0Ff91knIiLSltzus15m9BGpE1QeLvSWOiFHsvr0denSBfXr10dAQACcnZ2lziEiIiIikpSsBusAULx4cRQvXlzqDCIiIiLKA1wFoxtZ/lIkIiIiIiKS4cw6EREREX26eIGpbjizTkREREQkUxysExERERHJFJfBEBEREZHBcBWMbjizTkREREQkUxysExERERHJFJfBEBEREZHB8G4wuuHMOhERERGRTHGwTkREREQkU1wGQ0REREQGw1UwuuHMOhERERGRTHFmnYiIiIgMxsiIU+u64Mw6EREREZFMcbBORERERCRTXAZDRERERAbDC0x1w5l1IiIiIiKZ4mCdiIiIiEimuAxGYkql1AU5E+XHVc/+WiJ1Qo5sO66TOkErL3b0lTohR/nNjKVO+GSI8PcQIM7fRUSUPQX/Z9YJZ9aJiIiIiGSKg3UiIiIiIpniMhgiIiIiMhiugtENZ9aJiIiIiGSKM+tEREREZDC8wFQ3nFknIiIiIpIpDtaJiIiIiGSKy2CIiIiIyGC4DEY3nFknIiIiIpIpDtaJiIiIiGSKy2CIiIiIyGC4CkY3nFknIiIiIpIpzqwTERERkcHwAlPdcGadiIiIiEimOFgnIiIiIpIpLoMhIiIiIoPhKhjdcGadiIiIiEimOFgnIiIiIpIpDta14L9rB7ybN0bNapXRxac9rgdckzopk4BrVzFsyEA0a1QfVSuVx6k/T0qdpJHczuWN69cwbsRgfN2iIeq5V8S503+qPT9r6kTUc6+o9ujX69s8bRrToSrOL2iH8F3f4emWHtjj2xxlnaxVz+czVmBWz1q4urQjInf3xqNN3bBheEMUtc2f5TEP/NgSCQf6o01t5zzrDgy4hjHDB6NNcy94VHfF2dPqX4Mb1qxA5/ZfoVFddzT3qoMfBvbB7X9u5lmPLuT2dZkVuXeK8vcQIP9zCYjRCIjRKUIjIE5nbikUCtk8RMDBeg6OHjmM+XP90K//IPjvO4Dq1d0xeEA/hIaESJ2mJiEhHuXKl8eEiVOkTsmSHM9lQkICXMqVx6jxk7Lcp07d+jh47IzqsXDZ6jxt8qxYFGuO3IHXuN/QetofMDZS4NC0Vshv9u4Sk/xm+VD1C3vM3XMdHqN+QZe5J1DWyRp7J7XQeLwf2lSGMk+L30lMjEfZcuUxevxkjc+XcC6F0eMnYfueA1izaRuKOhXD8CH9EBMTbYC6rMnx61ITETpF+HsIEONcitAIiNEpQiMgTicZHgfrOdj282Z806ED2nf0wRdlymCc7yQ4FnXEHv9dUqepqe/phaHDRqJJs+ZSp2RJjufSo54n+g8ejoaNm2W5j4mJKezsC6seVtY2edrUdsYRbD91D0HPYvDPk2gMWH4WJYsURLUy9gCAuPgUtJ52GPsvPML9kFj87144Rq2/CHeXwihhb6l2rMqlCmFY28oYuPxsnjYDgEe9BhgwZDgaNtF8Llt4t0at2nVRrHgJfFGmLIaPGo+3b97gwb27ed6WHTl+XWoiQqcIfw8BYpxLERoBMTpFaATE6STD42A9GynJyQi6cxsedeurbfeoWw83bwRKVCUmkc9lYMBVfNXUE12+aYW5M6cgJjrKoO9vld8UABDzJinbfdLTlXj1Nlm1zcLUGD+PboKR6y7g5auEPO/URUpKMg78sgcFChRE2XJfStchyNelKJ0iEOFcitAIiNEpQiMgTqe+KBTyeYiAt27MRsyrGKSlpcHOzk5tu52dPSIjIySqEpOo57JOPU80btoCjkWdEBLyHOtXL8cPA/tg0/a9MDU1NUjDvD4euHAnFHeCYzQ+b2ZijJk9a8H/3AO8TkhRbZ/fty4u//sSh/731CCd2jh/7gym+I5GYmIi7OwLY+nqDbCxtZWsR5SvS1E6RSDCuRShERCjU4RGQJxOkobsBusxMTH4+eefcf/+fRQtWhS9evVCiRIlsn1NUlISkpLUZx2VxmYwMzPTS9OHFyAolUphLkqQG9HOZdPm3qr//sKlLL6sUAkdWjfFxfNns106oy+L+9dD5VKF0MT3oMbn8xkrsG1MExgpFBi+9rxq+1c1ndGwshPqjNqf5426cK9ZCz/v+gWxr17ht1/3YvL4UdiwdTcKFbLL+cV5SJSvS1E6RSDCuRShERCjU4RGQJzO3PoUP6a8JPkyGCcnJ0RFvVtW8PjxY7i6umLevHm4f/8+1q5di8qVK+Pff//N9hh+fn6wtrZWeyyY55frNlsbWxgbGyMyMlJte3R0FOzs7HN9/M/Jp3Iu7QsXhmNRJzwPzvvZ6kX96qJ1LWe0mHwIL6LeZno+n7ECO8Y2hXORgmg97Q+1WfWGVZzwhaMVwnZ8h9f7v8fr/d8DAHaNa4Zjs1rneXtWLCzyo0RJZ1Sq4oZJU2fB2NgYvx+Q7hsKUb4uRekUgQjnUoRGQIxOERoBcTpJGpIP1sPCwpCWlgYAmDhxIr788ks8fPgQx48fx4MHD+Dp6Ykff/wx22P4+voiNjZW7TF2vG+u20xMTVHBtSIuX7ygtv3yxYtwq1ot18f/nHwq5zL21SuEvwyDnX3hPH2fxf3qoW2d0mj54yE8DX+d6fmMgXqZotb4auofiH6t/pOln/bfQM0R+1B75H7VAwDGbbqE/svy/mJTbSmVSqQkJ+e8Yx4R5etSlE4RiHAuRWgExOgUoREQp5OkIatlMFeuXMGGDRuQP/+7+0WbmZlh8uTJ6NixY7avMzPLvOQlMVU/TT169cakCePgWqkS3NyqYf9ef4SGhsKncxf9vIGexMe/RXBwsOrPL148x7//BsHa2hpFizpJWPYfOZ7L+Pi3eP7sv/MWEvIc9+4GwcrKGlbW1ti0dhUaNmkGO/vCCA15gbUrl8LaxhYNGjXNs6YlA+qhcwMX+Mw5jjcJKXCwsQAAxMYnIzE5DcZGCuwc1wzVytij/ayjMDZSqPaJfpOElNR0vHyVoPGi0meRbzQO/vUh07l88UJ1Lq1tbLBlw1p4ejWGnb094mJjsX/vLkSEv0TjZppvOWkocvy61ESEThH+HgLEOJciNAJidIrQCIjTqQ9cBaMbWQzWM9YuJSUlwcHBQe05BwcHRERId3FFS+9WiH0Vg3WrVyEiIhwuZcth5Zp1cHIqJlmTJrdv3UK/Pj1Vf144/90yoDZtv8HM2XOlylIjx3P5753b+GFAb9Wfly+aDwDwbt0WY32n4OGDezjyx0G8eR0HO/vCqF6jFmb4/QRLS8usDplrA7wrAgBOzG6jtr3fsjPYfuoeitlbok3tUgCA/y1R/0a2+eTf8det0Dxry86/d25jSP/vVH9etmgeAKBVm3YYN3Eqnj55jMOHhiP2VQysrW1QoWIlrN64DV+UKStJbwY5fl1qIkKnCH8PAWKcSxEaATE6RWgExOkkw1MolUpD/L6ULBkZGaFSpUrIly8f7t+/j61bt+Kbb75RPX/u3Dl07doVz58/1+m4+ppZz2vSnn3tiPId8BsBPuklum+SOkErL3b0lTohR/nNjKVO+GSI8PcQIM7fRURyYy6Lqdn/1JpzRuoElf9NbCh1Qo4k//RNnTpV7c8ZS2Ay/P777/D09DRkEhERERHlEd4NRjeyG6x/aMGCBQYqISIiIiKSF8nvBkNERERERJpJPrNORERERJ8ProLRDWfWiYiIiIhkijPrRERERGQwvMBUN5xZJyIiIiKSKQ7WiYiIiIhkistgiIiIiMhguApGN5xZJyIiIiKSKQ7WiYiIiIhkistgiIiIiMhgeDcY3XBmnYiIiIhIpjizTkREREQGw4l13XBmnYiIiIhIpjhYJyIiIiKSKS6DISIiIiKD4QWmuuHMOhERERGRTHGwTkREREQkU1wGQ0REREQGw2UwuuFgXWL8etUfSzP5fzmH7OwrdYJWKo78TeqEHD1a2V7qhE9GcFS81AlacbbPL3UCEZHBcRkMEREREZFMyX8qkoiIiIg+GVxVoBvOrBMRERERyRRn1omIiIjIYHiBqW44s05EREREJFMcrBMRERERyRSXwRARERGRwXAVjG44s05EREREJFMcrBMRERERyRSXwRARERGRwfBuMLrhzDoRERERkUxxsE5EREREJFNcBkNEREREBsNVMLrhzDoRERERkUxxZp2IiIiIDMaIU+s64cw6EREREZFMcbBORERERCRTXAZDRERERAbDVTC64cy6Fvx37YB388aoWa0yuvi0x/WAa1InaSRCpwiNAdeuYtiQgWjWqD6qViqPU3+elDoJgQHXMHr4YLRu5oU61Vxx9vR/TakpKVixdCG6+bRFQw93tG7mhemTJyAiPDzPeoa2LIfDvo1wb2kb/L2gFTYNqoMyDgUy7Te6dQVcn+eNh8vbYt8oT5QrWlDt+W6epbBvlCfuLmmDkLXtYWVhkmfN2RHh6xKQd+fe7RvxtVc1rF++QLVNqVRi5+Y1+K59M3RsVgcTh3+P4McPJaz8j5zPZQYRGgExOkVoBMTpJMPiYD0HR48cxvy5fujXfxD89x1A9eruGDygH0JDQqROUyNCpwiNAJCQEI9y5ctjwsQpUqeoJCTEo2y58hg9YXKm5xITE3E36A569xuIn3ftw9yFyxAc/ARjRwzJsx6PcoWx5cxDtJ57Bl2WXoCxkQK7hteHhamxap8hLcqhf1MXTNp9E638TiMiLhG7R9SHpdl/P9CzMDXGmdsvsfzI3TxrzYkoX5dy7rwfdBvHfv8FpcqUVdv+y64t+G3PdvQfMQEL126HbSE7TBk9EPHxbyUqfUfO5zKDCI2AGJ0iNALidJLhcbCeg20/b8Y3HTqgfUcffFGmDMb5ToJjUUfs8d8ldZoaETpFaASA+p5eGDpsJJo0ay51ikrd+g0wcMhwNGrSLNNzBQoWxPI1G9G0uTecS5VGpSpuGD1+Ev4Nuo2w0Lz5S77bsgvYcykY90Jf487zWIz8OQDF7fKjirONap/vm7hg2ZG7OBIYgrshcRi+JQAWpsb4plYJ1T4b/nyIFcfuIeBxdJ50akOUr0u5dibEx2PhrIkYOvZHFChopdquVCpxcO9OdOrRF3UbNIHzFy4Y4TsTSUmJOHfyiITF8j2X7xOhERCjU4RGQJxOfVAoFLJ5iICD9WykJCcj6M5teNStr7bdo2493LwRKFFVZiJ0itD4KXnz+jUUCgUKvjd4yksZy1devU0BAJS0zw8Ha3OcvfNStU9yajou34tEjTKFDNKkDVG+LuXcuWaJH2p4eKJqjTpq21+GvkBMdCSq1vBQbTMxNUVFN3cE3bpp6EwVOZ/LDCI0AmJ0itAIiNNJ0uBgPRsxr2KQlpYGOzs7te12dvaIjIyQqCozETpFaPxUJCUlYdWyxWju/RUsC2ReR54XpvlUwZX7kbgbEgcAKGJlDgCIiEtS2y/idZLqOTkQ5etSrp3n/jyKR/f+Rc9+P2R6LiY6EgBgU0j9mzMbWzu8io4ySJ8mcj2X7xOhERCjU4RGQJxOkobkg/XAwEA8fvxY9eft27ejXr16KFGiBOrXr4/du3fneIykpCTExcWpPZKSknJ8nbY+/DGJUqmU5Y9OROgUoVFkqSkp+HHCaKQr0zHO1zBr7ud864YKxawweMPVTM8plep/VgBQZtpLeqJ8XcqpMyI8DOuXL8CoybNgamaW5X6Z+pRKWdwKQk7nMisiNAJidIrQCIjTmVtGCvk8RCD5YL1v37548uQJAGDDhg3o378/atSogUmTJqFmzZro168fNm3alO0x/Pz8YG1trfZYMM8v1222NrYwNjZGZGSk2vbo6CjY2dnn+vj6IkKnCI2iS01JwaTxoxDy4gWWr95okFn1WV3c0LxKUXRc9BdCXyWotofHJQIAilirD+LsC5oh4v+fkwNRvi7l2PnwbhBiY6Ixsn83tGtcA+0a18CtGwE4tH8X2jWuARvbdzOEMVHqs+ivXkXDxla6pVByPJcfEqEREKNThEZAnE6ShuSD9bt376JMmTIAgFWrVmHJkiVYunQpBg4ciMWLF2Pt2rVYuHBhtsfw9fVFbGys2mPseN9ct5mYmqKCa0VcvnhBbfvlixfhVrVaro+vLyJ0itAosoyB+rPgp1i+ZiOsbWzy/D1nd3GDd1Un+Cz+C8+i4tWeC46Mx8vYRDSoUES1zcRYgTrl7HHtoXQXk35IlK9LOXZWca+F5Zv3YumG3aqHS3lXeDVthaUbdsPRqThsC9njxrXLqtekpKTg9s0AVKjkJkkzIM9z+SERGgExOkVoBMTp1BepLyrN7QWmq1atQunSpWFubg53d3f89ddf2e6flJSESZMmwdnZGWZmZihTpkyOE9Hvk/yXIllYWCAiIgIlS5bEixcvULt2bbXna9eurbZMRhMzMzOYffBj2MRU/fT16NUbkyaMg2ulSnBzq4b9e/0RGhoKn85d9PMGeiJCpwiNABAf/xbBwcGqP7948Rz//hsEa2trFC3qJFnT82f/NYW8eIF7d4NgZWUN+8JF4Dt2BO7+G4SFS1chPT0NUf+/xtHK2homJqZ675nzbVV8U6s4eq+6jDeJqShs9e7/v9cJKUhMSQcAbPjzAX7wLo9H4W/xOPwNhnmXR0JyGn793zPVcQpbmaGIlTlKF373U4Avi1nhbWIqXkTH41V8it67NRHl61JunfnzW8L5Cxe1beYWFihoba3a/rVPV+zbsRFOxUvCqXhJ7N2+EWZm5mjQ1FuKZBW5nUtNRGgExOgUoREQp/Nz5+/vjxEjRmDVqlWoV68e1q5dC29vb9y5cwclS5bU+JpOnTrh5cuX2LhxI1xcXBAeHo7UVO0HqpIP1r29vbF69Wps2LABXl5e2LdvH9zc/pt12bNnD1xcXLI5Qt5q6d0Ksa9isG71KkREhMOlbDmsXLMOTk7FJGvSRIROERoB4PatW+jXp6fqzwvnv1tS1abtN5g5e64kTUF3bmNIv+9Uf166cB4AoFWbdvh+4BD8dfY0AKBHl/Zqr1u5fgvca9TSe893Db8AAPwypoHa9hFbrmHPpXffVKw8dg/mJsbw61oV1vlNEPg4Gt8uvYC3Sf/9BdWzwRcY3aaC6s8HxnplOk5eE+XrUpTO97X/9jskJSVhzWI/vHkTh3IVKmH6T6uRP7+lpF0inEsRGgExOkVoBMTp/NwtWrQIffv2xffffw8AWLJkCY4dO4bVq1fDzy/zEuyjR4/i7NmzePToEQr9/wX3pUqV0uk9FUrlh5eAGVZISAjq1auHkiVLokaNGli9ejXc3d1RoUIF3L17F5cvX8avv/6KVq1a6XRcfc2skzik/UrWTmJKmtQJWqk48jepE3L0aGX7nHcirTyNjM95Jxlwts8vdQKRkMwln5pV99Xa/0mdoPLLd26ZbkqiacUGACQnJyN//vzYu3cvvvnmG9X24cOH48aNGzh79mym1wwePBj37t1DjRo1sG3bNlhaWuLrr7/GzJkzYWFhoVWj5GvWnZycEBgYCA8PDxw9ehRKpRL/+9//cPz4cRQvXhwXLlzQeaBORERERJQTTTcp0TRDDgCRkZFIS0uDg4OD2nYHBweEhYVpfM2jR49w/vx53Lp1C7/++iuWLFmCffv2YcgQ7X/LuCy+17KxscHcuXMxd640SwyIiIiI6PPj6+uLUaNGqW3TNKv+Pl1usZmeng6FQoEdO3bA2toawLulNB07dsTKlSu1ml2XxWCdiIiIiD4PCsjnBudZLXnRxN7eHsbGxplm0cPDwzPNtmcoWrQoihUrphqoA0CFChWgVCrx/PlzlC1bNsf3lXwZDBERERGR3JmamsLd3R0nTpxQ237ixAnUrVtX42vq1auHkJAQvHnzRrXt3r17MDIyQvHixbV6Xw7WiYiIiMhgpP6tpbn5DaajRo3Chg0bsGnTJgQFBWHkyJEIDg7GwIEDAbxbVtOz5393lOvatSvs7OzQu3dv3LlzB+fOncPYsWPRp08frS8w5TIYIiIiIiItdO7cGVFRUZgxYwZCQ0NRqVIlHD58GM7OzgCA0NBQtd/VUqBAAZw4cQI//PADatSoATs7O3Tq1AmzZs3S+j0lv3VjXuGtGz8/Inwl89aN+sNbN+oPb91I9GmT260bv153VeoElYP9a0qdkCOZffqIiIiI6FOW1Z1TSDOuWSciIiIikikO1omIiIiIZIrLYIiIiIjIYLgKRjecWSciIiIikikO1omIiIiIZIrLYIiIiIjIYIy4DkYnnFknIiIiIpIpzqwTERERkcFwYl03nFknIiIiIpIpDtaJiIiIiGSKy2CIiIiIyGAUXAejE86sExERERHJFGfW6ZMhwjfqFqbGUido5dHK9lIn5Mi25lCpE7QSc3WF1Ak5crbPL3UCERFlgYN1IiIiIjIYESbX5ITLYIiIiIiIZIqDdSIiIiIimeIyGCIiIiIyGCOug9EJZ9aJiIiIiGSKM+tEREREZDCcV9cNZ9aJiIiIiGSKg3UiIiIiIpnSahlMcHCwTgctWbLkR8UQERER0adNwQtMdaLVYL1UqVI6ndi0tLSPDiIiIiIione0Gqxv2rSJ3wURERERERmYVoP17777Lo8ziIiIiOhzYMT5X53k6gLThIQEvHjxAqmpqfrqISIiIiKi//dRg/XTp0/Dw8MDBQsWhLOzM/7++28AwJAhQ/DLL7/oNZCIiIiI6HOl82D91KlTaN68ORITEzFmzBikp6ernrO3t8eWLVv02UdEREREnxCFQiGbhwh0HqxPmTIFrVq1QmBgIGbNmqX2nJubG27cuKGvNiIiIiKiz5pWF5i+LzAwEHv37gWQ+T6ZhQsXRnh4uH7KiIiIiOiTI8iEtmzoPLOeL18+pKSkaHwuPDwcBQsWzHUUERERERF9xGC9Zs2a2LZtm8bn9u3bBw8Pj1xHyY3/rh3wbt4YNatVRhef9rgecE3qJI1E6BShERCjU4RGQNrOMX2a4/z2sQg//xOe/umHPYv6oaxzkSz3Xz6pCxICV2Bo14ZZ7nNgxSAkBK5Am4ZV8qA4eyJ8zkVoBMToFKEREKNThEZAnE4yLJ0H6xMmTMCvv/6Kb775BgcPHoRCocCVK1cwdOhQ7Nu3D+PGjcuLTskcPXIY8+f6oV//QfDfdwDVq7tj8IB+CA0JkTpNjQidIjQCYnSK0AhI3+lZ3QVr/M/Bq+dPaD1oBYyNjXFo9VDkNzfNtG+bhlVQs3IphIS/yvJ4P3RrBKUyD4OzIfW51IYIjYAYnSI0AmJ0itAIiNOpD1JfVPrJX2DatGlT/Pzzz/jrr7/QoUMHKJVKDBkyBDt37sSWLVtQv379vOiUzLafN+ObDh3QvqMPvihTBuN8J8GxqCP2+O+SOk2NCJ0iNAJidIrQCEjf2XboKmz//QqCHoXhn3svMGDadpQsWgjVXEuo7edU2BqLJ/ig98QtSElN03isyuWKYVj3xhg4bbsh0jOR+lxqQ4RGQIxOERoBMTpFaATE6STD+6j7rHfv3h3Pnj3D8ePHsX37dhw9ehTPnj1Dt27d9N0nqZTkZATduQ2PuurfgHjUrYebNwIlqspMhE4RGgExOkVoBOTZaVXAHAAQExuv2qZQKLBxVk8s/vlPBD0K0/g6C3MT/Oz3HUbO24OXUa8N0vo+OZ7LD4nQCIjRKUIjIEanCI2AOJ0kDZ3vBpPBwsICTZs2zXXADz/8gE6dOsHT0zPXx9K3mFcxSEtLg52dndp2Ozt7REZGSFSVmQidIjQCYnSK0AjIs3Pe6A64cP0B7jwMVW0b3bsZUtPSsXLXmSxfN390B1y++RiHzvxjgMrM5HguPyRCIyBGpwiNgBidIjQC4nTqi5EYq09k46MG63FxcVi5ciVOnz6NqKgo2NnZoVGjRhg0aBBsbGx0OtbKlSuxatUqlClTBn379kWvXr3g6Oio0zGSkpKQlJSktk1pbAYzMzOdjpOVD9c0KZVKWa5zEqFThEZAjE4RGgH5dC6e0AmVyzqhSe/Fqm3VKpTAkG8bom7XeVm+7iuvymhYqxzqdJlriMxsyeVcZkeERkCMThEaATE6RWgExOkkw9J5Gczjx49RpUoVTJo0Cffv34epqSnu37+PSZMmwc3NDY8ePdI54vjx42jVqhV++uknlCxZEm3btsWhQ4fUfjtqdvz8/GBtba32WDDPT+eOD9na2MLY2BiRkZFq26Ojo2BnZ5/r4+uLCJ0iNAJidIrQCMirc9F4H7T2qowW/ZbhxXsXkNarVgZFChXAvcMz8PrqUry+uhTOTnaYO6o9/v1jOgCgYc1y+KK4PcLOLVDtAwC7fvoex9YPN0i/nM5lVkRoBMToFKEREKNThEZAnE59kfqi0k/+AtPhw4cjMTERFy5cwOPHj3Hp0iU8fvwY58+fR1JSEkaMGKFzROXKlbFkyRKEhIRg+/btSEpKQrt27VCiRAlMmjQJDx48yPb1vr6+iI2NVXuMHe+rc8eHTExNUcG1Ii5fvKC2/fLFi3CrWi3Xx9cXETpFaATE6BShEZBP5+LxPmjb2A0tByzD05Aoted2/nEVNTv5oXaXuapHSPgrLN56Em0GrwQA/LT5eKZ9AGDcwv3oP9UwF5vK5VxmR4RGQIxOERoBMTpFaATE6SRp6LwM5tSpU1i6dGmm+6nXrVsXs2bN+qjBegYTExN06tQJnTp1QnBwMDZt2oQtW7Zg7ty5SEvTfIcGADAzy7zkJTH1ozPU9OjVG5MmjINrpUpwc6uG/Xv9ERoaCp/OXfTzBnoiQqcIjYAYnSI0AtJ3LvHthM7eNeAzch3evE2Eg927X9oW+yYRiUkpiI59i+jYt2qvSUlNw8vIONx/+u63Mb+Meq3xotJnoTGZBv95SepzqQ0RGgExOkVoBMToFKEREKeTDE/nwbqZmRlKlCih8bmSJUvqbZ14yZIlMW3aNEydOhUnT57UyzE/RkvvVoh9FYN1q1chIiIcLmXLYeWadXByKiZZkyYidIrQCIjRKUIjIH3ngE4NAAAnNoxQ295vyjZs//2KQRr0RepzqQ0RGgExOkVoBMToFKEREKdTH8RYfCIfCqVSt1/x0adPHxgbG2P9+vWZnuvXrx+Sk5Px888/a3280qVL49q1a5mugM4tfc2sE5E82dYcKnWCVmKurpA6gYg+c+Yffe+/vNFntzR31tJkU5fKUifkSKtP3/Xr11X/3bVrV/Tt2xc+Pj7o2rUrHB0dERYWhh07duDatWvYuHGjTgGPHz/WrZiIiIiI6DOh1WC9Ro0aalfMKpVKPHv2DL/88ovaNgBo3rx5tuvLiYiIiOjzZSTIXVjkQqvB+ubNm/O6g4iIiIiIPqDVYL1Xr1553UFERERERB+Q2SUHRERERPQp4yoY3XzUYD06Oho7d+5EUFAQEhIS1J5TKBQ6X2RKRERERESZ6TxYDw4ORs2aNREfH4/4+HjY29sjOjoaaWlpsLW1hbW1dV50EhEREdEnQMGpdZ0Y6fqCCRMmoGLFinj58iWUSiWOHDmCt2/fYvny5TA3N8cff/yRF51ERERERJ8dnQfrly5dwqBBg2Bubg7g3S0bTU1NMWTIEPTt2xdjx47VeyQRERER0edI58H6y5cvUbRoURgZGcHY2BhxcXGq57y8vHD+/Hm9BhIRERHRp0OhkM9DBDoP1h0cHBAdHQ0AKFWqFK5du6Z67smTJ8iXjzeYISIiIiLSB51H1nXq1EFgYCC+/vprtG/fHjNmzEBSUhJMTU2xYMECNG7cOC86iYiIiIg+OzoP1seMGYMnT54AAKZMmYKgoCBMnToVSqUSDRo0wJIlS/ScSERERESfCiNR1p/IhM6DdXd3d7i7uwMALC0tcfDgQcTFxUGhUKBgwYJ6DyQiIiIi+lzpvGZdEysrKxQsWBDnzp3jMhgiIiIiIj3R69WgEREROHv2rD4PSURERESfEK6C0Y1eZtaJiIiIiEj/eJ9FIiIiIjIYBafWdcKZdSIiIiIimeJgnYiIiIhIprRaBlOlShWtDhYXF5erGCIibcVcXSF1glZsaw6VOiFHopxLIvo0cKZYN1oN1gsVKqTV+iI7OzuULl0611FERERERKTlYP3MmTN5nEFERERERB/i3WCIiIiIyGB4NxjdcNkQEREREZFMcWadiIiIiAzGiBPrOuHMOhERERGRTHGwTkREREQkU1wGQ0REREQGw2Uwuvnowfq///6Ls2fPIjIyEn379oWjoyNCQkJga2sLCwsLfTYSEREREX2WdB6sp6WloX///tiyZQuUSiUUCgW8vb3h6OiIAQMGoFq1apgxY0ZetBIRERERfVZ0XrM+e/Zs7Ny5EwsWLMCtW7egVCpVz3l7e+Po0aN6DSQiIiKiT4dCoZDNQwQ6z6xv2bIFP/74I0aNGoW0tDS150qXLo3Hjx/rLY6IiIiI6HOm88z6ixcv4OHhofE5c3NzvH79OtdRRERERET0EYP1IkWK4NGjRxqfu3v3LooXL57rKCIiIiL6NBkp5PMQgc6D9VatWmH27Nl48eKFaptCoUBsbCyWLVuGNm3a6DWQiIiIiOhzpfNgfcaMGUhNTYWrqys6dOgAhUKBiRMnolKlSkhMTMSPP/6YF51ERERE9AlQKOTzEIHOg3UHBwdcvXoV3377LQICAmBsbIybN2/C29sbFy9eRKFChfKik4iIiIjos/NRvxTJwcEBa9as0XcLERERERG9R+eZ9c+R/64d8G7eGDWrVUYXn/a4HnBN6iSNROgUoREQo1OERkCMTqkb61Uvg31LBuDR8dlICFyBNg2rqD1vaWGKxeN98ODoTERfWoTA/ZPRz6e+2j4OdgWxcWZPPD4xB5EXF+LizvH4pmlVA34U70h9LrUlQqcIjYAYnSI0AuJ05paRQiGbhwh0Hqz36dMn20ffvn3zolMyR48cxvy5fujXfxD89x1A9eruGDygH0JDQqROUyNCpwiNgBidIjQCYnTKodHSwgz/3HuBkXP3aHx+/pgOaFbXFb0nbUXV9rOwfMdpLBrng9YNK6v22TirF8qVKgKfEWtRw2cOfjt1A9vm9oFbecPdoUsO51IbInSK0AiI0SlCIyBOJxmeQvn+ryDVQqlSpTL9xqeoqCi8efMGNjY2sLGxyfLWjoaUmKqf43Tr4oMKrq6YPGW6alu7Nt5o1Lgpho8crZ830QMROkVoBMToFKEREKMzrxttaw7Vaf+EwBXoNHIdfj/zt2rbtb0Tse/4dcxd/99viL6wYxyOXbiNGav+AABEXFiIYXN2Y9cfV1X7PD89D5OWHsDPBy5l+54xV1fo1JgVET7fgBidIjQCYnSK0Ajkbaf5Ry16zjsTDt+TOkFlbqtyUifkSOeZ9SdPnuDx48dqj7i4OJw8eRJFihTBb7/9lhedkkhJTkbQndvwqKv+42aPuvVw80agRFWZidApQiMgRqcIjYAYnSI0AsDFG4/Q2qsynApbAwAa1CiLss5FcPJi0H/7BD5Ex+busLXKD4VCAZ8W7jAzzYdz1+4bpFGUcylCpwiNgBidIjQC4nTqi5GMHiLQW2fjxo0xdOhQDB8+XOfXLl++HL169cKePe9+BLxt2za4urriyy+/xMSJE5Gaqqdpch3FvIpBWloa7Ozs1Lbb2dkjMjJCkiZNROgUoREQo1OERkCMThEaAWD0vL0IehSGh8dnI+5/S3Fw5WAM9/PHxRv//RSzx4RNyGdshJCz8xF7ZQmWT+qCzqPW4/HzSIM0inIuRegUoREQo1OERkCcTpKGXn8w4urqigkTJuj0mpkzZ2LBggVo3rw5hg8fjsePH2PBggUYOXIkjIyMsHjxYpiYmGD69OlZHiMpKQlJSUlq25TGZjAzM/uoj+NDHy77USqVmbbJgQidIjQCYnSK0AiI0Sn3xiHfNkStyqXQYfgaBIdGo351Fyz17YywyDicvnIXADBtSBvYWuWH94BliHr1Fm0aVsGOBX3QtM8S3H5guDWvcj+XGUToFKEREKNThEZAnE4yLL0O1s+ePQt7e3udXrNlyxZs2bIF7du3x82bN+Hu7o6ff/4Z3bp1AwB8+eWXGDduXLaDdT8/v0zPT/pxKiZPmabzx/A+WxtbGBsbIzJSfWYqOjoKdna6fZx5SYROERoBMTpFaATE6BSh0dzMBNN/aIPOo9bj6PnbAIBb90NQpXxxjOjRBKev3EXp4vYY1MUL1TvMQtCjMADAP/deoF71MhjQuQGGzd6d550inEtAjE4RGgExOkVoBMTp1Bd+/6Gbj/oNph8+Jk2ahDZt2mD27Nn49ttvdTpeaGgoatSoAQBwc3ODkZERqlatqnq+evXqCMnhSmhfX1/ExsaqPcaO99X1Q8vExNQUFVwr4vLFC2rbL1+8CLeq1XJ9fH0RoVOERkCMThEaATE6hWjMZwxTk3xI/+BeAGlp6TAyevcvXn5zUwDQsI/SYLcmE+FcAmJ0itAIiNEpQiMgTidJQ+eZ9WnTpmXaZmZmhlKlSmHGjBkYO3asTsdzdHTEnTt3ULJkSdy/fx9paWm4c+cOKlasCAC4ffs2ihQpku0xzMwyL3nR191gevTqjUkTxsG1UiW4uVXD/r3+CA0NhU/nLvp5Az0RoVOERkCMThEaATE65dBoaWGKMiUKq/5cqpgdqpQrhpi4eDwLi8G5a/cxZ0Q7JCSmIDg0Gp7uLujWuhbGL/oFAHD3SRgeBIdjxeRv4bvoV0TFvsXXjaqgSZ3yaD/ccL/ATg7nUhsidIrQCIjRKUIjIE6nPohyf3O50Hmwnp6erteArl27omfPnmjbti3+/PNPjB8/HmPGjEFUVBQUCgVmz56Njh076vU9ddHSuxViX8Vg3epViIgIh0vZcli5Zh2cnIpJ1qSJCJ0iNAJidIrQCIjRKYfG6q7OOL7hv4vz54/pAADYdvAy+k/djp4TNmHGD22xZU4v2FrlR3BoNKatPIT1e88DAFJT09Huh9WYNawt9i0dgAL5zfDwWQS+n7INx87fMdjHIYdzqQ0ROkVoBMToFKEREKeTDE+n+6wnJCSgb9++GDx4MOrXr5/zC7SQlpaGuXPn4vLly6hfvz7Gjx+P3bt3Y9y4cYiPj0ebNm2wYsUKWFpa6nRcfc2sExHlhq73WZeCvu6zTkTyJLf7rP941DC3lNXGzJZlpU7Ikc6/FMnS0hJHjhxBgwYN8qpJLzhYJyI54GCdiKQmt8H6lGPyGazPaCH/wbrOF5hWrVoVt27dyosWIiIiIiJ6j86D9blz52L+/Pk4e/ZsXvQQEREREdH/0+oHI+fOnUP16tVRoEABDB48GG/evEHjxo1ha2uLokWLqt2wX6FQ4ObNm3kWTERERETiMuLNYHSi1WC9UaNGuHTpEmrVqgU7Ozudf/ERERERERHpTqvB+vvXoJ45cyavWoiIiIiI6D0yuz6YiIiIiD5l/KVIutH6AlMFTywRERERkUFpPbPeqFEjGBnlPLZXKBSIjY3NVRQRERERfZo4/6sbrQfrDRs2ROHChfOyhYiIiIiI3qP1YH3KlCmoVatWXrYQEREREdF7eIEpERERERkM77OuG51/gykRERERERkGB+tERERERDKl1TKY9PT0vO4gIiIios+AAlwHowvOrBMRERERyRQvMCUiIiIig+EFprrhzDoRERERkUxxsE5EREREJFNcBkNEREREBsNlMLrhYJ0+GUql1AU5UwjyF1RwVLzUCTkqaZdf6gStxFxdIXVCjpx675Q6QSvPN34rdUKOjDgKISI94zIYIiIiIiKZ4sw6ERERERmMQpQfM8sEZ9aJiIiIiGSKg3UiIiIiIpniMhgiIiIiMhheh60bzqwTEREREckUZ9aJiIiIyGB4faluOLNORERERCRTHKwTEREREckUl8EQERERkcEYcR2MTjizTkREREQkUxysExERERHJFJfBEBEREZHB8D7ruuHMOhERERGRTHGwTkRERESkpVWrVqF06dIwNzeHu7s7/vrrL61ed+HCBeTLlw9Vq1bV6f04WCciIiIig1Eo5PPQlb+/P0aMGIFJkyYhMDAQnp6e8Pb2RnBwcLavi42NRc+ePdGkSROd35ODdSIiIiIiLSxatAh9+/bF999/jwoVKmDJkiUoUaIEVq9ene3rBgwYgK5du8LDw0Pn9+RgnYiIiIgMxggK2Tx0kZycjICAADRv3lxte/PmzXHx4sUsX7d582Y8fPgQU6dO/cjzRTny37UD3s0bo2a1yuji0x7XA65JnaSRCJ1yb9y4fi26du6AurWqoVEDD4wYNhhPHj+SOksjOZ/Lvds3ok2Dali/bIFq2+I5U9CmQTW1x5iBPSWs/I+cz+X7pOoc0cYVJ6e3wNN1Pri7sj22jfCEi2PBLPdf1Lsmord1xcAW5dW2F7E2x+oBHgha/g2ebeiE0zNb4uuaJfI6P0sbN6xFtcpfYsG8OZI1ZIdfl/ojQiMgTuenJCkpCXFxcWqPpKQkjftGRkYiLS0NDg4OatsdHBwQFham8TX379/HhAkTsGPHDuTL93E3YeRgPQdHjxzG/Ll+6Nd/EPz3HUD16u4YPKAfQkNCpE5TI0KnCI0B1/6Hzt92w9ade7Bm3WakpaZhUP++SIiPlzpNjZzP5b2g2zh68BeUKlM203PVa9fF1l9PqB5T5y+XoFCdnM/l+6TsrPdlEWw8eQ8tph9H+3mnkM/ICPvHN0Z+M+NM+7ZyLw73MvYIic78/8yagR5wKWqFbovPob7vHzh07Rk2Dq2Hys62ef4xfOj2rX/wy749KFuufM47S4Bfl/ojQiMgTuenxs/PD9bW1moPPz+/bF+j+GCxu1KpzLQNANLS0tC1a1dMnz4d5cqV++hGDtZzsO3nzfimQwe07+iDL8qUwTjfSXAs6og9/rukTlMjQqcIjavWbkTbdu3h4lIW5b/8EtNn+SE0NAR37tyWOk2NXM9lQnw8Fs6ciB/G/YgCBa0yPW9iYgpbO3vVo6CVtQSV6uR6Lj8kZafPgjPY9ddj/PsiFreDX2Ho+ssoYW8Jt1KF1PYramuB+T1rYMDqi0hNS890nBou9lh/4i6uP4rC04i3WPjbbcS+TYFbKcMO1uPj32LihDH4cepMWFll/jqVA35d6o8IjYA4nfog9UWl7z98fX0RGxur9vD19dXYbW9vD2Nj40yz6OHh4Zlm2wHg9evXuHbtGoYOHYp8+fIhX758mDFjBm7evIl8+fLh1KlTWp0vyQfroaGhmDJlCho3bowKFSqgUqVKaNOmDTZu3Ii0tDRJ21KSkxF05zY86tZX2+5Rtx5u3giUqCozETpFaNTkzZvXAABra+kHlRnkfC7XLPZDDQ9PVK1RR+Pzt25cQ/evG2NA17ZYPn8GXsVEG7hQnZzP5fvk1mllYQIAePU2WbVNoQBWD/TA8j+C8O+LWI2vu3IvAt/UdoaNpSkUCqB9HWeYmhjhfFC4Qboz+M2eAU/PhqjjUdeg76stuX2+syJCpwiNgDidnyIzMzNYWVmpPczMzDTua2pqCnd3d5w4cUJt+4kTJ1C3bua/T6ysrPDPP//gxo0bqsfAgQNRvnx53LhxA7Vr19aqUdLfYHrt2jU0bdoUpUuXhoWFBe7du4du3bohOTkZY8aMwcaNG3Hs2DEULJj12si8FPMqBmlpabCzs1Pbbmdnj8jICEmaNBGhU4TGDymVSiyc74dq1d3hUvbjf3ylb3I9l+f+PIqH9/7FonXbNT5fo3Y91G/UDEUciuJl6Ats37gKk0b0x5L1O2Fiamrg2nfkei4/JLfOWd2q49LdcAQ9/29QPry1K9LSlFh7/G6Wr+uz4gI2Da2HR2s6IiU1HQnJqei59C88CX9jiGwAwNEjf+DfO3ewffc+g72nruT2+c6KCJ0iNALidBIwatQo9OjRAzVq1ICHhwfWrVuH4OBgDBw4EMC7mfoXL15g69atMDIyQqVKldReX6RIEZibm2fanh1JB+sjRozAyJEjVVfHbt++HStWrMDly5cRExODxo0bY/LkyVi6dGm2x0lKSsp0MYDS2CzL74x0pe3aJKmJ0ClCYwa/2TNw7949bNm6U+oUjeR0LiNehmH9sgWYsXAVTLP4/86zSQvVfzt/4QKX8q7o26kVrl76C3W9dL/vrD7J6VxmRw6d83vVQMUSNmg187+ZJbdSthjQvDwa/Xg029dO6lgFNpamaOf3J6LeJOEr9+LYPLQ+Ws06oTbwzythYaFYMHcOVq3bqLd/H/KSHD7f2hChU4RGQJzO3DIS+EPq3LkzoqKiMGPGDISGhqJSpUo4fPgwnJ2dAbxbMZLTPdd1JekymOvXr6NHjx6qP3ft2hXXr1/Hy5cvYWtri/nz52PfvpxnPzRdHLBgXvYXB2jD1sYWxsbGiIyMVNseHR0FOzv7XB9fX0ToFKHxfXPnzMTZ06ewYdPPcHB0lDpHjRzP5YN7QXgVE40R/bqhbaMaaNuoBm7dCMDv+3ehbaMaGpe0FbIvjMIORRHyXL9/qelCjudSE7l0zu3hDu9qxfC1358IiUlQbfcoXwSFrczx95K2CN/SBeFbuqBk4QKY2bUabiz6GgBQqkgB9G9eHj+sv4Jzd17idvArzP/1FgIfR+P7pob5yVXQ7duIjo5Ct84dUKNqRdSoWhEB165i145tqFG1ouRLLzPI5fOdExE6RWgExOmkdwYPHownT54gKSkJAQEBaNCggeq5LVu24MyZM1m+dtq0abhx44ZO7yfpYL1IkSIIDQ1V/fnly5dITU1VXfBTtmxZREfnvKZV08UBY8drvjhAFyampqjgWhGXL15Q23754kW4Va2W6+PriwidIjQC72Yx/GbPwJ8nj2Pdpp9RrLh0t5XLihzPpZt7LazYshfLNu5WPVy+dIVXs1ZYtnE3jI0z3zUkLvYVIiNeopCE/xDJ8VxqIofOeT1roHWNEmjrdwrBEW/VnvO/8Biekw7Da/IR1SMkOh7L/whCx/mnAQAWpu++BtKVSrXXpqcrYWSgabZadepg7y8HsXvvr6qHa8VKaPVVG+ze+6vGr1MpyOHzrQ0ROkVoBMTpJGlIugymXbt2GDhwIBYsWAAzMzPMnDkTXl5esLCwAADcvXsXxYoVy/E4ZmaZl7wkpuqnsUev3pg0YRxcK1WCm1s17N/rj9DQUPh07qKfN9ATETpFaJwzazqOHD6EJctWwdLSUrVWsECBgjA3N5e47j9yO5f581vC+QsXtW3m5hawsrKG8xcuSIiPx87Na1DPqwls7QojPCwEW9cth5W1Deo0aCxJcwa5ncusSNm5oFcNdPQohW5LzuFNYgqKWL/7fyEuPgWJKWmIeZOMmDfJaq9JTUtHeGwiHoS9u0j7fmgcHoa9xqLetTBlVyCi/38ZTMNKjuiy6GyefwwAYGlZINP1JxYWFrC2sZHVdSkAvy71SYRGQJxOfTD6BJf25CVJB+uzZs1CaGgo2rRpg7S0NHh4eGD79v8uTlMoFDne6zKvtfRuhdhXMVi3ehUiIsLhUrYcVq5ZByennL+JMCQROkVo3Pv/t8j6vncPte3TZ/mhbbv2UiRpJMK5fJ+RsRGePnqA08cO4e2b17C1s0flajUxbto85M9vKWmbKOdSys6+/79M5dCkpmrbh6y7hF1/PdbqGKlpSnT+6QymdnbDzlENYGlugscvX2Pwuks4eZP3kf4Qvy71R4RGQJxOMjyFUvnBzyQlkJiYiNTUVBQoUEB/x9TTzDqJQ/qv5JyJMpkQHCWvXwKlSUm7/FInfDKcesvzIuoPPd/4rdQJOTLUkh4iXZhLOjWb2forT6VOUOlX21nqhBzJ4tMnp+UFRERERERyIfkvRSIiIiIiIs1kMbNORERERJ8HXmCqG86sExERERHJFAfrREREREQyxWUwRERERGQwXAWjG86sExERERHJFGfWiYiIiMhgOFOsG54vIiIiIiKZ4mCdiIiIiEimuAyGiIiIiAxGwStMdcKZdSIiIiIimeJgnYiIiIhIprgMhoiIiIgMhotgdMOZdSIiIiIimeJgnYiIiIhIprgMhoiIiIgMxoh3g9EJZ9aJiIiIiGSKM+tEREREZDCcV9cNZ9aJiIiIiGSKM+v0yeASOP0paZdf6gQyoJDNXaVO0Ipt7eFSJ+Qo6vISqRNyxPXCRGLhYJ2IiIiIDIbfL+qGy2CIiIiIiGSKg3UiIiIiIpniMhgiIiIiMhgF18HohDPrREREREQyxcE6EREREZFMcRkMERERERkMZ4p1w/NFRERERCRTnFknIiIiIoPhBaa64cw6EREREZFMcbBORERERCRTXAZDRERERAbDRTC64cw6EREREZFMcbBORERERCRTXAZDRERERAbDu8HohjPrREREREQyxcE6EREREZFMcRkMERERERkMZ4p1w/OlBf9dO+DdvDFqVquMLj7tcT3gmtRJGonQKUIjIEanCI2AGJ0iNAJidErZOKZ3U5zfOhrh5+bh6YlZ2LOwL8o6F1HbZ1L/lrixfyIiz89HyGk//LFqMGpWclbbp883Hji2dihenp2HhIClsC5gYbCPAQA2rl+Lbp07ol6t6mjcoC5GDhuCJ48fGbRBF/y61B9ROsmwZDFYf/v2LdavX4/evXvD29sbrVq1Qu/evbFhwwa8fftW0rajRw5j/lw/9Os/CP77DqB6dXcMHtAPoSEhknZ9SIROERoBMTpFaATE6BShERCjU+pGz+ouWLP3L3h9txitB6+CsbExDq0chPzmpqp9HgRHYOS8fajReR6a9F2Kp6HR+H3lINjbWKr2yW9uihOX/sWCzScM0v2h69euovO3XbF1pz9Wr9uEtNRUDOr/PRLi4yXpyY7Un3NtiNAIiNOpDwqFQjYPESiUSqVSyoA7d+6gWbNmiI+Ph5eXFxwcHKBUKhEeHo6zZ8/C0tISx48fh6urq07HTUzVT1+3Lj6o4OqKyVOmq7a1a+ONRo2bYvjI0fp5Ez0QoVOERkCMThEaATE6RWgExOjM60bb2sN12t/exhLP/pyDpt8vw4XAhxr3KWhphvBz8+E9cCXOXL2n9pynuwuOr/sBjl4TEPsmQav3jLq8RKdGbURHR6NJg7rYsGUb3GvUzPXxjPQ4QOHXpf7kZae5zBY9//p3mNQJKt9UcZQ6IUeSz6wPGTIEDRo0wMuXL3HgwAGsXbsW69atw4EDB/Dy5Us0aNAAQ4YMkaQtJTkZQXduw6NufbXtHnXr4eaNQEmaNBGhU4RGQIxOERoBMTpFaATE6JRjo9X/L1+JidM8I22Szxh929fFq9fx+Of+C0Om6eTNm9cAAGtra4lL1Mnxc/4hERoBcTpJGpJ/r3XlyhVcu3YNpqammZ4zNTXFxIkTUatWLQnKgJhXMUhLS4OdnZ3adjs7e0RGRkjSpIkInSI0AmJ0itAIiNEpQiMgRqccG+eNaocLgQ9x52Go2nZvz4rYOqcX8pubICwyDq0Hr0bUK2mXXGZFqVRi4fy5qFbdHS5ly0mdo0aOn/MPidAIiNOpL2IsPpEPyQfrtra2uH//fpbLXB48eABbW9tsj5GUlISkpCS1bUpjM5iZmeml8cM1TUqlUpbrnEToFKEREKNThEZAjE4RGgExOuXSuHh8R1Qu64QmfZdmeu7s1fuo/e182NtYovc3dbF97ndo0GsRImLeGLwzJ3Nnz8T9e3exeetOqVOyJJfPeXZEaATE6STDknwZTL9+/dCrVy/89NNPuHnzJsLCwvDy5UvcvHkTP/30E/r06YMBAwZkeww/Pz9YW1urPRbM88t1m62NLYyNjREZGam2PTo6CnZ29rk+vr6I0ClCIyBGpwiNgBidIjQCYnTKqXHR2A5o3aASWgxYgRfhsZmej09MxqPnkfjfracYNHMXUtPS0atdHYM2amPunJk4e/oU1m/aCgdH+a2rldPnPCsiNALidJI0JB+sT5s2Db6+vli0aBGqVauGYsWKwcnJCdWqVcOiRYswYcIETJkyJdtj+Pr6IjY2Vu0xdrxvrttMTE1RwbUiLl+8oLb98sWLcKtaLdfH1xcROkVoBMToFKEREKNThEZAjE65NC4e1wFtG1dBy4Er8TQkWqvXKBSAmYnkP2hWUSqVmDt7Bk6dPIG1m7agWPHiUidpJJfPeXZEaATE6dQXhUI+DxHI4m+n8ePHY/z48Xj8+DHCwt5dIezo6IjSpUtr9Xozs8xLXvR1N5gevXpj0oRxcK1UCW5u1bB/rz9CQ0Ph07mLft5AT0ToFKEREKNThEZAjE4RGgExOqVuXDLBB51bVofPqA14E58IB7uCAIDYN4lITEpBfnNTjO/bHH+c/QdhkXEoZGOJ/j71UayIDX45eUN1HAe7gnCws0KZEu9mNCu5FMXr+CQ8C4vJ8mJVffKbNQNHDh/C4mUrYWlpqVqzXKBAQZibm+f5++tC6s+5NkRoBMTpJMOTxWA9Q+nSpTMN0J89e4apU6di06ZNkjS19G6F2FcxWLd6FSIiwuFSthxWrlkHJ6dikvRkRYROERoBMTpFaATE6BShERCjU+rGAT7v7qRxYv0wte39pu3A9t//h7T0dJQvVQTdW/eBnU0BRMe+xbXbwWj6/TIEPfrvVnLfd6iHyQO8VX8+uXG42nHy2l7/Xe/er3dPte3TZ83B1+3a5/n760Lqz7k2RGgExOnUByNeYqoTye+znpObN2+ievXqSEtL0+l1+ppZJyIiedD1PutSyIv7rOubPu+zTmKQ233Wf//npdQJKm0qO0idkCPJP30HDx7M9vlHj+T7K5aJiIiIiPKS5IP1du3aQaFQILsJft62iIiIiOjTwGGdbiS/G0zRokWxf/9+pKena3xcv35d6kQiIiIiIklIPlh3d3fPdkCe06w7EREREdGnSvJlMGPHjsXbt1n/mmcXFxecPn3agEVERERElFcUvBuMTiQfrHt6emb7vKWlJby8vAxUQ0REREQkH5IvgyEiIiIiIs0kn1knIiIios8H7wajG86sExERERHJFGfWiYiIiMhgjHiBqU44s05EREREJFMcrBMRERERyRSXwRARERGRwfACU91wZp2IiIiISKY4WCciIiIikikugyEiIiIig+EyGN1wZp2IiIiISKY4WCciIiIikikugyEiIiIig1HwlyLphDPrREREREQyxZl1IiISQtSlJVIn5MjOY5TUCTmKubxY6gT6zBlxYl0nnFknIiIiIpIpDtaJiIiIiGSKy2CIiIiIyGB4galuOLNORERERCRTHKwTEREREckUl8EQERERkcEouApGJ5xZJyIiIiKSKc6sExEREZHB8AJT3XBmnYiIiIhIpjhYJyIiIiKSKS6DISIiIiKDMeIqGJ1wZp2IiIiISKY4WCciIiIikikugyEiIiIig+HdYHTDmXUiIiIiIpniYJ2IiIiISKa4DIaIiIiIDEbBVTA64cw6EREREZFMcbCuBf9dO+DdvDFqVquMLj7tcT3gmtRJGonQKUIjIEanCI2AGJ0iNAJidIrQmGHjhrWoVvlLLJg3x2DvOea7Jjj/80iEn/XD0+MzsOenPijrXFhtH0sLUywe1x4P/piK6PPzELh3Avp1qJvpWLUrO+PI6sGI/GsuQk/PwbG1Q2BuZmKoD0VFhM+5CI2AOJ25pZDRQwSyH6y/fPkSM2bMkOz9jx45jPlz/dCv/yD47zuA6tXdMXhAP4SGhEjWpIkInSI0AmJ0itAIiNEpQiMgRqcIjRlu3/oHv+zbg7Llyhv0fT2rl8Gavefh1XspWg9ZA2NjIxxaMRD5zU1V+8wf1Q7NPL5E7ynbUdVnLpbvPItFY9ujtVcl1T61Kzvjt+UD8Oflu/DstQT1ey7Cmj3nkZ6ebtCPR4TPuQiNgDidZHgKpVKplDoiOzdv3kT16tWRlpam0+sSU/Xz/t26+KCCqysmT5mu2taujTcaNW6K4SNH6+dN9ECEThEaATE6RWgExOgUoREQozOvG9PT9fPPVXz8W3zbqT18J03FhnWrUf7LChg7fqJejm1Xd5RO+9vbWOLZyVlo2m85LgQ+AgBc8x+HfccDMXfjCdV+F7aNwrELQZix5ggA4Ozm4fjzyj3Vn3URc3mxzq/JCr8u9ScvO81ldoXihfsxUieo1CtrK3VCjiSfWf/777+zfdy9e1eytpTkZATduQ2PuvXVtnvUrYebNwIlqspMhE4RGgExOkVoBMToFKEREKNThMYMfrNnwNOzIep4ZF5aYmhWBSwAADFx8aptF288RusGleBU2BoA0MDdBWVLFsbJS/8CAArbFkCtyqUQEfMGpzcOw5NjM3B87RDUdStt0HYRPuciNALidOqLkUIhm4cIJP9eq2rVqlAoFNA0wZ+xXSHRyYx5FYO0tDTY2dmpbbezs0dkZIQkTZqI0ClCIyBGpwiNgBidIjQCYnSK0AgAR4/8gX/v3MH23fukTgEAzBvVFhcCH+HOwzDVttELfsGqyZ3x8Mg0pKSmIT1diUGz/HHx5mMAQOli787xpH4t4Lv0IP6+9wLdvqqJw6sHw73zPDx8FmmQdhE+5yI0AuJ0kjQkH6zb2dlh3rx5aNKkicbnb9++jTZt2mR7jKSkJCQlJaltUxqbwczMTC+NH36zIOU3ENkRoVOERkCMThEaATE6RWgExOiUc2NYWCgWzJ2DVes26u3fh9xYPK4DKrs4ocn3y9S2D+niiVqVndFh5AYEh0ajfvUyWDq+A8Ii43D6f/dgZPTufG785SK2/f4/AMDNuy/QsGZZ9Pq6Nqas/MOgH4ecP+cZRGgExOkkw5J8sO7u7o6QkBA4OztrfP7Vq1caZ93f5+fnh+nTp6ttm/TjVEyeMi1XbbY2tjA2NkZkpPosRXR0FOzs7HN1bH0SoVOERkCMThEaATE6RWgExOgUoTHo9m1ER0ehW+cOqm1paWm4HnAN/rt24ErA3zA2NjZIy6Kx7dG6QUU07b8CL8JjVdvNzUwwfchX6DxmM45euAMAuPUgFFXKFcOI7g1x+n/3EBoZ9+7jefxS7Zh3H79ECUfDrb8V4XMuQiMgTqe+8NsP3Ui+Zn3AgAEoVapUls+XLFkSmzdvzvYYvr6+iI2NVXuMHe+b6zYTU1NUcK2IyxcvqG2/fPEi3KpWy/Xx9UWEThEaATE6RWgExOgUoREQo1OExlp16mDvLwexe++vqodrxUpo9VUb7N77q8EG6ovHtUfbRpXRctAqPA2JVnvOJJ8RTE3yIV2pfleXtPR0GBm9+yf7aUg0QsJfoZxzEbV9XJwLIzhU/Xh5SYTPuQiNgDidJA3JZ9a/+eabbJ+3tbVFr169st3HzCzzkhd93Q2mR6/emDRhHFwrVYKbWzXs3+uP0NBQ+HTuop830BMROkVoBMToFKEREKNThEZAjE65N1paFoBL2XJq2ywsLGBtY5Npe15ZMr4DOrd0h8/ojXgTnwQHu4IAgNg3iUhMSsHrt0k4F/AAc4Z/jYSkFASHxsCzehl0a1UD4xf/pjrO4m2nMXlAS/xzPwQ3775A99Y1Ud65CLqO22KQjyOD3D/ngBiNgDidZHiSD9Zz8uzZM0ydOhWbNm2S5P1berdC7KsYrFu9ChER4XApWw4r16yDk1MxSXqyIkKnCI2AGJ0iNAJidIrQCIjRKUKj1Ab4vLvbx4l1Q9W295u2E9sPXQUA9Jy4FTOGfIUtM7vD1io/gsNiMG31Yazff1G1/4pd52BuaoL5I9vC1jo//rkXgtZD1uDxiyjDfTAQ43MuQiMgTqdecB2MTnifdSIiEoK+7rOel3S9z7oU9HmfdRKD3O6zfvnhK6kTVOqUsZE6IUeSf/oOHjyY7fOPHj0yUAkRERER5TUFp9Z1IvlgvV27dlneZz0Db1tERERERJ8jye8GU7RoUezfvx/p6ekaH9evX5c6kYiIiIhIEpIP1t3d3bMdkOc0605ERERE4lAo5PMQgeTLYMaOHYu3b99m+byLiwtOnz5twCIiIiIiInmQfLDu6emZ7fOWlpbw8vIyUA0RERERkXxIPlgnIiIios+HIKtPZEPyNetERERERKQZB+tERERERDLFZTBEREREZDhcB6MTzqwTEREREckUZ9aJiIiIyGAUnFrXCWfWiYiIiIhkioN1IiIiIiKZ4jIYIiIiIjIYBVfB6IQz60REREREMsXBOhERERGRTHEZDBEREREZDFfB6IYz60REREREMsWZdSIiIiIyHE6t64SDdSIiEoKRkfz/hY+5vFjqhBzZ1homdYJWoq8skzohR7yrCRkCl8EQEREREckUZ9aJiIiIyGAUXAejE86sExERERHJFAfrREREREQyxcE6ERERERmMQiGfx8dYtWoVSpcuDXNzc7i7u+Ovv/7Kct9ffvkFzZo1Q+HChWFlZQUPDw8cO3ZMp/fjYJ2IiIiISAv+/v4YMWIEJk2ahMDAQHh6esLb2xvBwcEa9z937hyaNWuGw4cPIyAgAI0aNUKbNm0QGBio9XsqlEqlUl8fgJwkpkpdQEREJD+8daP+iHLrRnOZ3U7kRvBrqRNUqpYsqNP+tWvXRvXq1bF69WrVtgoVKqBdu3bw8/PT6hgVK1ZE586dMWXKFK3258w6ERERERmMQkYPXSQnJyMgIADNmzdX2968eXNcvHhRq2Okp6fj9evXKFSokNbvK7PvtYiIiIiIDCMpKQlJSUlq28zMzGBmZpZp38jISKSlpcHBwUFtu4ODA8LCwrR6v4ULF+Lt27fo1KmT1o2cWSciIiIiw5F6Ov29h5+fH6ytrdUeOS1nUXyw/kmpVGbapsmuXbswbdo0+Pv7o0iRIjnun4Ez60RERET0WfL19cWoUaPUtmmaVQcAe3t7GBsbZ5pFDw8PzzTb/iF/f3/07dsXe/fuRdOmTXVq5Mw6EREREX2WzMzMYGVlpfbIarBuamoKd3d3nDhxQm37iRMnULdu3SzfY9euXfjuu++wc+dOfPXVVzo3cmadiIiIiAxGofOlnfIxatQo9OjRAzVq1ICHhwfWrVuH4OBgDBw4EMC7mfoXL15g69atAN4N1Hv27ImlS5eiTp06qll5CwsLWFtba/WeHKwTEREREWmhc+fOiIqKwowZMxAaGopKlSrh8OHDcHZ2BgCEhoaq3XN97dq1SE1NxZAhQzBkyBDV9l69emHLli1avSfvs05ERPQZ4X3W9Yf3Wf84fz97I3WCSpUSBaROyJHMPn1ERERE9CkT5ZscueAFpkREREREMsXBOhERERGRTHGwrgX/XTvg3bwxalarjC4+7XE94JrUSRqJ0ClCIyBGpwiNgBidIjQCYnSK0AiI0SllY73qZbBvSX88OjYTCdeXoU3Dypn2KV/aAXsX90PY2XkI/2s+zv48CiUcbVXPH1v3AxKuL1N7bPXrZbCPIUPAtasYNmQgmjWqj6qVyuPUnycN3qAtEb4u9UEGvwtJ9RCBbAbrz58/x5s3mS84SElJwblz5yQoeufokcOYP9cP/foPgv++A6he3R2DB/RDaEiIZE2aiNApQiMgRqcIjYAYnSI0AmJ0itAIiNEpdaOluSn+ufcCI+ft1fh86eL2+HPjCNx78hIt+i9HrS7z4Lf+KBKTUtT22/jLBZRqNkn1GDrb3xD5ahIS4lGufHlMmDjF4O+tC6k/5yRfkg/WQ0NDUatWLTg7O8PGxga9evVSG7RHR0ejUaNGkvVt+3kzvunQAe07+uCLMmUwzncSHIs6Yo//LsmaNBGhU4RGQIxOERoBMTpFaATE6BShERCjU+rG4xeDMH3VH/jt1N8an58+5Cscu3AHk5YexM27z/HkRRSOnr+DiBj1SbeExBS8jHqtesS9STREvpr6nl4YOmwkmjRrbvD31oXUn3ODkno6XbCpdckH6xMmTICxsTGuXLmCo0eP4s6dO2jYsCFiYmJU+0h1d8mU5GQE3bkNj7r11bZ71K2HmzcCJWnSRIROERoBMTpFaATE6BShERCjU4RGQIxOuTcqFAq0rP9/7d15XJTV4sfx78gyLAIqLoBeQUERl1DQUtTQ9KJouGtkKWlaXTXX0Fy6uKNpLrn+LJfMNde83gyhiJuBoiJmyk1NAxcUWUQFZRnO748uUyPDljjPc+z77jWv1+XMM898YO4LDoczjy1wKTkNh9b8A8lRC/CfzyYb3SrzSmBbXPtmIU7vmY7wiX1R3cb4vwz5V6f215yUpfhkPSoqCitXrkTbtm3RvXt3HDt2DA0aNMBLL72EzMxMAL99Y1BC1t0s6HQ6ODo6Gow7OtZGevodRZqMkaFThkZAjk4ZGgE5OmVoBOTolKERkKNT7Y11a1WHna0V3hvRHZGxSQgasxaHon/ErqVvopOPh/64XUdOIWT6FvR4axUWfRKBft1aY9fSNxUsVy+1v+akLMWvs56dnY2aNX9/Q4pWq8XevXsxePBgdO3aFdu2bSv3HHl5ecjLyzMYE2ZaaLVV8xv8478sCCEU+wWiLDJ0ytAIyNEpQyMgR6cMjYAcnTI0AnJ0qrWx2v8aDn93Dqu2fwcA+PHiDbzg3QijB3XEsYTLAIDNB+L0j7nwSyouX7uD2O2haN2sARL/e93k3TJQ62te1TSy7D9RCcVX1hs3bowffzTcE2dubo49e/agcePGePnll8s9R3h4OBwcHAxuSxaHP3FbzRo1YWZmhvT0dIPxzMwMODrWfuLzVxUZOmVoBOTolKERkKNThkZAjk4ZGgE5OtXemH43BwUFOiRduWUw/vPV2wZXg3ncmaRryC8ohEfDOk87UTpqf81JWYpP1gMDA7Fhw4YS48UT9tatW5e7Z3369OnIzs42uIVOm/7EbRaWlvBq3gLHY38wGD8eGwvv1m2e+PxVRYZOGRoBOTplaATk6JShEZCjU4ZGQI5OtTcWFOpw+kIKmrrVMxhv0rAOUlIzS31cc3dnWFqYIzX93tNOlI7aX3NSluLbYBYsWIDc3Fyj95mbm2P//v24fr3sP5dptSW3vDwqrJq+YSEjMPP9qWjesiW8vdtg357dSE1NxeBXgqvmCaqIDJ0yNAJydMrQCMjRKUMjIEenDI2AHJ1KN9paW8L9b7+vgLvVd8RzTesj614urt3KwvKt3+DzRW/gWMJlxJy6hAA/L/R6sSV6vLUKwG+XdgwObIuIY+eRfjcHXo2dsGhyP5xJuoa4xCsm+RyK5ebmICUlRf/xjRvX8d//JsHBwQHOzi4mbSmL0q+5KT2DO3ueKsUn6+bm5rC3ty/1/ps3b2LOnDnYtGmTCat+1zOwF7LvZmHDurW4cycNHk2aYs36DXBxqa9IT2lk6JShEZCjU4ZGQI5OGRoBOTplaATk6FS60ad5Qxz9ZLz+4w+nDAAAfH7oBN6avR2Hon/Euwu/QOiI7vgodCAuJqfh1dBNiP3fRLygoBBdn2+Ksa/6o7qNFtdvZ+Hr789jwYavUVRk2iu8nf/pJ4weOVz/8Ucf/rZNNqhvf8xbsMikLWVR+jUn9dIIpa6LWEFnz56Fj48PdDpdpR5XVSvrREREz5Kaz48v/yAVyDzxsdIJ5ZJlhdhK8aVZQxdu5iidoNfcxVbphHIp/vIdOnSozPuvXDHtn8uIiIiI6OmR5Hcc1VB8st6vXz9oNJoy30T6LF62iIiIiIioPIpfDcbZ2Rn79u1DUVGR0VtCQoLSiURERERUVTQquklA8cm6r69vmRPy8lbdiYiIiIieVYpvgwkNDUVOTulvNPDw8EB0dLQJi4iIiIiI1EHxyXrnzp3LvN/W1hb+/v4mqiEiIiKip0kjy/4TlVB8GwwRERERERnHyToRERERkUopvg2GiIiIiP46eEXuyuHKOhERERGRSnFlnYiIiIhMhgvrlcOVdSIiIiIileJknYiIiIhIpbgNhoiIiIhMh/tgKoUr60REREREKsXJOhERERGRSnEbDBERERGZjIb7YCqFK+tERERERCrFyToRERERkUpxGwwRERERmYyGu2AqRSOEEEpHPA2PCpUuICIiUp+iIjl+7Dv6TVY6oVxZx5crnVAhVipbmr2c9lDpBD2PutZKJ5RLZS8fERERET3LuLBeOdyzTkRERESkUpysExERERGpFLfBEBEREZHpcB9MpXBlnYiIiIhIpThZJyIiIiJSKW6DISIiIiKT0XAfTKVwZZ2IiIiISKU4WSciIiIiUilugyEiIiIik9FwF0ylcGWdiIiIiEiluLJORERERCbDhfXK4co6EREREZFKcbJORERERKRS3AZDRERERKbDfTCVwpV1IiIiIiKV4mSdiIiIiEiluA2GiIiIiExGw30wlcKV9QrYvXM7AgNeQrs2rRA8eAASTp9SOskoGTplaATk6JShEZCjU4ZGQI5OGRoBOTrV3vjF7p0YMqAPOrX3Raf2vhj+2is49v1/TPb8773RDcc+m4S0mHAkH52LL5aORBPXOgbHbAh7FQ9PLTe4xWyeYHCMpYUZloUOwLWoeUj/fhH2LHsT9es6mOzz+CO1v+akDFVM1jMyMhAdHY3MzEwAQHp6OhYvXoy5c+ciKSlJ0bavj3yFDxeFY/Rb/8DuvQfh4+OLMW+PRurNm4p2PU6GThkaATk6ZWgE5OiUoRGQo1OGRkCOThka69Wrh3cnTsH2XXuxfddePP9Ce0waPxa/XL5kkufv7OOO9XuOwX/ESrw8dj3MzKrh8Op3YGNlaXBcxA9JcOvxT/2t34RPDO5fMqU/+nRpheEzPke3UatQ3VqLfctHo1o1067+yvCaVxWNRj03GWiEEELJgPj4eAQEBODevXuoUaMGIiMjMXjwYJibm0MIgRs3buDYsWPw8fGp1HkfFVZN32vBg+HVvDlm/XOOfqxfUCC6vtQdEyZNqZonqQIydMrQCMjRKUMjIEenDI2AHJ0yNAJydD7NxqKip/dj37/jC5g4JRT9Bwx64nM5+k2u1PG1a9jiWtR8dB+9Cj+cuQLgt5X1GnbWGPLeJqOPsbe1wrWoeXjzn9uxNzIRAOBc2x6X/h2GfhM2IOr4z2U+Z9bx5ZVqLMvTfM2tVLbpOSUzT+kEvYa1tEonlEvxlfWZM2di8ODByM7OxowZM9CvXz9069YNFy9exKVLlzB06FDMmzdPkbaC/HwkXTiPDn6dDMY7+HXE2cQzijQZI0OnDI2AHJ0yNAJydMrQCMjRKUMjIEenDI2P0+l0+PrIv/HwYS6e826tSIN9dWsAQNa9XIPxzr4eSD46Fz/um441M4egTs3q+vvaeDWApYW5waQ8Nf0ezv+SivbPNTJNOOR8zcl0FP9d6/Tp0/j4449hZ2eHCRMmYNq0aRg9erT+/rFjxyIoKEiRtqy7WdDpdHB0dDQYd3SsjfT0O4o0GSNDpwyNgBydMjQCcnTK0AjI0SlDIyBHpwyNxS5d/Bkhr7+K/Pw8WNvY4KMVq+Hu7qFIy+LJffHDmSu48Mst/djR2CTsjzqLlFuZcHNxxD/fCcSR9WPg9/pHyC/QwcnRHnn5hbh7/6HBudIyH6BebTuTtcv0mlcFSXafqIbik/X8/HxYW//227CFhQVsbGxQu3Zt/f2Ojo7IyMgo8xx5eXnIyzP8k4ow00KrrZo/bWge29QkhCgxpgYydMrQCMjRKUMjIEenDI2AHJ0yNAJydMrQ6NaoEXbtPYD79+/hm8ij+Oes9/Hp5s9NPmFfPnUgWnm4oNuojw3Gi7e2AMCFX24h4cI1/Hz4AwR2ao4vo8+Vej6NBlBik7AMrzmZnuLbYP72t7/hypUr+o937doFZ2dn/cepqakGk3djwsPD4eDgYHBbsjj8idtq1qgJMzMzpKenG4xnZmbA0bHsJlOSoVOGRkCOThkaATk6ZWgE5OiUoRGQo1OGxmIWFpZo2NAVLVq0wviJU9C0aTPs3LbVpA3LQgfg5RdboMc7a3AjLbvMY29l3ENKahY8GtbRf6y1NEcNO2uD4+rUrI60jPtPrflxMr3mZHqKT9aDg4ORlpam/7h37976lXYAOHToEJ5//vkyzzF9+nRkZ2cb3EKnTX/iNgtLS3g1b4HjsT8YjB+PjYV36zZPfP6qIkOnDI2AHJ0yNAJydMrQCMjRKUMjIEenDI2lE8jPzzfZsy2fOgB9u7ZCz3+sRfLNzHKPr+Vggwb1aiA1/R4A4EzSdeQXFKLbC576Y5wc7dHC3RnHf7z61LofJ/drXnlKXwFGtqvBKL4NJiwsrMz7Z86cCTMzszKP0WpLbnmpqqvBDAsZgZnvT0Xzli3h7d0G+/bsRmpqKga/Elw1T1BFZOiUoRGQo1OGRkCOThkaATk6ZWgE5OiUoXHVymXo2OlFODk5IScnBxFff4VTJ+OxZt0n5T+4CqyYNhCv9PTF4Ckb8SA3D/Ucf9tjnv3gER7lFcDW2hKz3uqJg9+eRWr6Pbi61MLcMb2RcTcHh/63BeZeziNs+fIEFk3sg4zsHGTdy0X4hD746XIqvo2/aJLPo5gMrzkpQ/HJenkyMjIQFhaGTZuMX3bpaesZ2AvZd7OwYd1a3LmTBo8mTbFm/Qa4uNRXpKc0MnTK0AjI0SlDIyBHpwyNgBydMjQCcnTK0JiRkYFZM6Yi/c4dVLezQ5Mmnliz7hO09+tokud/e/BvV06J3DDOYHz07B3YdvgkdEUCLTycMbR3W9Sws8at9HuIOXUZw2ZsxYPc39/nNnXZQeh0RdgWHgJrKwtEx1/CW3M+faqXuDRGhteclKH4ddbLc/bsWfj4+ECn01XqcVW1sk5ERPQsMfUk9M+q7HXWlVCV11l/mtR2nfXrWabbKlWeBjUtyz9IYYq/fIcOHSrz/j+++ZSIiIiI6K9E8cl6v379oNFoUNYCPy9bRERERPRs4LSuchS/GoyzszP27duHoqIio7eEhASlE4mIiIiIFKH4ZN3X17fMCXl5q+5ERERERM8qxbfBhIaGIicnp9T7PTw8EB0dbcIiIiIiInpauAumchSfrHfu3LnM+21tbeHv72+iGiIiIiIi9VB8GwwRERERERmn+Mo6EREREf118GowlcOVdSIiIiIileJknYiIiIhIpbgNhoiIiIhMRsPrwVQKV9aJiIiIiFSKK+tEREREZDpcWK8UrqwTEREREakUJ+tERERERCrFbTBEREREZDLcBVM5XFknIiIiIlIpTtaJiIiIiFSK22CIiIiIyGQ03AdTKVxZJyIiIiJSKY0QQigd8TQ8KlS6gIiIiJ5lNduNUzqhQh6eWa10goG0+wVKJ+jVtbNQOqFc3AZDRERERCaj4fVgKoXbYIiIiIiIVIor60RERERkOlxYrxSurBMRERERqRQn60REREREKsVtMERERERkMtwFUzlcWSciIiIiUilO1omIiIiIVIrbYIiIiIjIZDTcB1MpXFknIiIiIlIprqwTERERkcnwXzCtHK6sExERERGpFCfrREREREQqxW0wRERERGQyfINp5XBlnYiIiIhIpThZJyIiIiJSKU7WiYiIiIhUipN1IiIiIiKV4mS9Anbv3I7AgJfQrk0rBA8egITTp5ROMkqGThkaATk6ZWgE5OiUoRGQo1OGRkCOThkaATk61dRoZlYNYWNeRtLh2ciMW4YL/5qN6W/1hOaxd13OfLsXrhxdgMy4ZYj4ZAK8GjspVExKU+1kvXHjxrh06ZLSGfj6yFf4cFE4Rr/1D+zeexA+Pr4Y8/ZopN68qXSaARk6ZWgE5OiUoRGQo1OGRkCOThkaATk6ZWgE5OhUW+OUN/6OUYM6YdKiPWg9YD5mrjyIScO7Y0yw/x+O6Y7xr3fFpEVfoNPrS3A74x7+vf5dVLfRKtJc1TQa9dxkoBFCCCUDPv74Y6PjkydPxtSpU+Hk9NtvkuPHj6/UeR8VPnEaAOC14MHwat4cs/45Rz/WLygQXV/qjgmTplTNk1QBGTplaATk6JShEZCjU4ZGQI5OGRoBOTplaATk6HyajTXbjav0Y/atfAdpmffwjzk79GM7l45C7sN8vPnBVgDAlaMLsGZHND7aEgUAsLQwR/I3CzFr5ZfYuO+HSj/nwzOrK/2Yp+nuQ53SCXo1rM2UTiiX4ivrEydOxJIlS7B8+XKDW1FREbZu3Yrly5djxYoVirQV5Ocj6cJ5dPDrZDDewa8jziaeUaTJGBk6ZWgE5OiUoRGQo1OGRkCOThkaATk6ZWgE5OhUY2Nc4i/o+rwnPBrWBQC0alofHVo3RsQP5wEAbvUd4VzHAVFx/9U/Jr+gEN+fvoz23o0Vaa5qGhX9JwPF/1Gk0aNHIz4+Hjt27ICXl5d+3MLCAkePHkXz5s0Va8u6mwWdTgdHR0eDcUfH2khPv6NQVUkydMrQCMjRKUMjIEenDI2AHJ0yNAJydMrQCMjRqcbGpZsjYV/dGmcPzIJOJ2BmpkHYmsP44uvTAACn2vYAgLTM+waPS8u4j4bOtUzeS8pTfLL+f//3fzh48CB69OiBqVOnYty4yv9JKS8vD3l5eQZjwkwLrbZq9nY9/qYPIUSJMTWQoVOGRkCOThkaATk6ZWgE5OiUoRGQo1OGRkCOTjU1Du7hi1d7tcMbMz7DhV9S8ZxnfSx5bxBS72Rj+79OGDT+kUZTcoz+GhTfBgMA/fr1Q1xcHA4cOIDAwEDcunWrUo8PDw+Hg4ODwW3J4vAn7qpZoybMzMyQnp5uMJ6ZmQFHx9pPfP6qIkOnDI2AHJ0yNAJydMrQCMjRKUMjIEenDI2AHJ1qbFw4sR+Wbo7EnojTOH/5Jnb++yRWbf8WoSP+DgC4lX4PAFDP0d7gcXVq2ZVYbZeV0m8qle0NpqqYrANA/fr1ERUVhRdffBFt2rSp1G+P06dPR3Z2tsEtdNr0J26ysLSEV/MWOB5r+GaO47Gx8G7d5onPX1Vk6JShEZCjU4ZGQI5OGRoBOTplaATk6JShEZCjU42N1laWKBJFBmO6IoFq1X6bkv16IwOpd7LRrX0z/f0W5mbo7OuB42evmLSV1EHxbTB/pNFoMH36dAQEBODYsWNwdnau0OO02pJbXqrqajDDQkZg5vtT0bxlS3h7t8G+PbuRmpqKwa8EV80TVBEZOmVoBOTolKERkKNThkZAjk4ZGgE5OmVoBOToVFvjV/85h2lv9sC11Cxc+CUVrZs1wPjXu2LrweP6Y9bsiEbomwG4nJKGyyl3MPXNHnj4qAC7j6jvGvb09Klqsl7M19cXvr6+AIBr164hLCwMmzZtUqSlZ2AvZN/NwoZ1a3HnTho8mjTFmvUb4OJSX5Ge0sjQKUMjIEenDI2AHJ0yNAJydMrQCMjRKUMjIEen2honL96DsDEvY+WMV1CnZnWk3snGxr0/YOGGI/pjPtoSBSutJVZMfwU17W1w8qdf8fI/VuNBbl4ZZ5aHJLtPVEPx66yX5+zZs/Dx8YFOV7lrclbVyjoRERGRMX/mOutKUNt11u8/Kir/IBOxs1LNjvBSKb6yfujQoTLvv3KF+7OIiIiI6K9J8cl6v379oNFoynxDqdouAUVEREREfxKndZWi+Nq/s7Mz9u3bh6KiIqO3hIQEpROJiIiIiBSh+GTd19e3zAl5eavuRERERCQPjYr+k4Hi22BCQ0ORk5NT6v0eHh6Ijo42YRERERERkTqo/mowfxavBkNERERPE68G8+c8yFPP1LO6Vv2r64qvrBMRERHRXwevG1I5iu9ZJyIiIiIi4zhZJyIiIiJSKW6DISIiIiKT4S6YyuHKOhERERGRSnGyTkRERESkUtwGQ0RERESmw30wlcKVdSIiIiIileLKOhERERGZjIZL65XClXUiIiIiogpau3YtGjVqBCsrK/j6+uL7778v8/iYmBj4+vrCysoKjRs3xvr16yv1fJysExERERFVwO7duzFx4kTMnDkTZ86cQefOnREYGIiUlBSjx1+9ehW9evVC586dcebMGcyYMQPjx4/Hvn37KvycGiGEqKpPQE0eFSpdQERERM+ymu3GKZ1QIQ/PrFY6wYCa5mhWldwQ/sILL8DHxwfr1q3Tj3l5eaFfv34IDw8vcfy0adNw6NAhJCUl6cfeeecdnD17FnFxcRV6Tq6sExERERGVIz8/H6dPn0ZAQIDBeEBAAGJjY40+Ji4ursTxPXr0wKlTp1BQUFCh5+UbTImIiIjoLykvLw95eXkGY1qtFlqttsSx6enp0Ol0qFevnsF4vXr1cOvWLaPnv3XrltHjCwsLkZ6eDmdn5/IjBVXIo0ePRFhYmHj06JHSKaWSoVEIOTplaBRCjk4ZGoWQo1OGRiHk6JShUQg5OmVoFEKOThkanzVhYWECgMEtLCzM6LE3btwQAERsbKzB+Pz584Wnp6fRxzRp0kQsXLjQYOzYsWMCgEhNTa1Q4zO7Z72q3bt3Dw4ODsjOzoa9vb3SOUbJ0AjI0SlDIyBHpwyNgBydMjQCcnTK0AjI0SlDIyBHpwyNz5rKrKzn5+fDxsYGe/bsQf/+/fXjEyZMQGJiImJiYko85sUXX0SbNm2wcuVK/diBAwcwZMgQ5ObmwsLCotxG7lknIiIior8krVYLe3t7g5uxiToAWFpawtfXF5GRkQbjkZGR8PPzM/qYDh06lDj+6NGjaNu2bYUm6gAn60REREREFTJ58mR8+umn2LRpE5KSkjBp0iSkpKTgnXfeAQBMnz4dw4cP1x//zjvvIDk5GZMnT0ZSUhI2bdqEjRs34r333qvwc/INpkREREREFfDKK68gIyMDc+fORWpqKlq2bImvvvoKrq6uAIDU1FSDa643atQIX331FSZNmoQ1a9bAxcUFH3/8MQYOHFjh5+RkvYK0Wi3CwsJK/dOIGsjQCMjRKUMjIEenDI2AHJ0yNAJydMrQCMjRKUMjIEenDI0EjBkzBmPGjDF635YtW0qM+fv7IyEh4U8/H99gSkRERESkUtyzTkRERESkUpysExERERGpFCfrREREREQqxcl6Of7zn/8gKCgILi4u0Gg0OHjwoNJJJYSHh6Ndu3aws7ND3bp10a9fP/z8889KZ5Wwbt06PPfcc/rrmHbo0AFHjhxROqtM4eHh0Gg0mDhxotIpBmbPng2NRmNwc3JyUjqrhBs3buD111+Ho6MjbGxs0Lp1a5w+fVrpLANubm4lvpYajQZjx45VOk2vsLAQs2bNQqNGjWBtbY3GjRtj7ty5KCoqUjrNwP379zFx4kS4urrC2toafn5+OHnypKJN5X0PF0Jg9uzZcHFxgbW1Nbp06YLz58+rqnH//v3o0aMHateuDY1Gg8TERJP2VaSzoKAA06ZNQ6tWrWBrawsXFxcMHz4cN2/eVE0j8Nv3zmbNmsHW1hY1a9ZE9+7dceLECZM2VqTzj95++21oNBqsWLHCZH2kLpyslyMnJwfe3t5YvXq10imliomJwdixY3H8+HFERkaisLAQAQEByMnJUTrNQIMGDbBo0SKcOnUKp06dwksvvYS+ffua/AdjRZ08eRIbNmzAc889p3SKUS1atEBqaqr+du7cOaWTDGRlZaFjx46wsLDAkSNHcOHCBXz00UeoUaOG0mkGTp48afB1LP7HKwYPHqxw2e8WL16M9evXY/Xq1UhKSsKHH36IJUuWYNWqVUqnGRg1ahQiIyPx+eef49y5cwgICED37t1x48YNxZrK+x7+4YcfYtmyZVi9ejVOnjwJJycn/P3vf8f9+/dV05iTk4OOHTti0aJFJmsqraO0ztzcXCQkJOCDDz5AQkIC9u/fj4sXL6JPnz6qaQSApk2bYvXq1Th37hyOHTsGNzc3BAQE4M6dO6rqLHbw4EGcOHECLi4uJiojVRJUYQDEgQMHlM4oV1pamgAgYmJilE4pV82aNcWnn36qdEYJ9+/fF02aNBGRkZHC399fTJgwQekkA2FhYcLb21vpjDJNmzZNdOrUSemMSpswYYJwd3cXRUVFSqfo9e7dW4wcOdJgbMCAAeL1119XqKik3NxcYWZmJg4fPmww7u3tLWbOnKlQlaHHv4cXFRUJJycnsWjRIv3Yo0ePhIODg1i/fr0ChWX/nLl69aoAIM6cOWPSJmMq8vMwPj5eABDJycmmiXpMRRqzs7MFABEVFWWaKCNK67x+/bqoX7+++Omnn4Srq6tYvny5ydtIHbiy/gzKzs4GANSqVUvhktLpdDrs2rULOTk56NChg9I5JYwdOxa9e/dG9+7dlU4p1aVLl+Di4oJGjRohODgYV65cUTrJwKFDh9C2bVsMHjwYdevWRZs2bfDJJ58onVWm/Px8bNu2DSNHjoRGo1E6R69Tp0745ptvcPHiRQDA2bNncezYMfTq1Uvhst8VFhZCp9PBysrKYNza2hrHjh1TqKpsV69exa1btxAQEKAf02q18Pf3R2xsrIJlz4bs7GxoNBrV/TWtWH5+PjZs2AAHBwd4e3srnWOgqKgIw4YNQ2hoKFq0aKF0DimM/yjSM0YIgcmTJ6NTp05o2bKl0jklnDt3Dh06dMCjR49QvXp1HDhwAM2bN1c6y8CuXbuQkJCg+F7bsrzwwgvYunUrmjZtitu3b2P+/Pnw8/PD+fPn4ejoqHQeAODKlStYt24dJk+ejBkzZiA+Ph7jx4+HVqs1+KeY1eTgwYO4e/cu3njjDaVTDEybNg3Z2dlo1qwZzMzMoNPpsGDBArz66qtKp+nZ2dmhQ4cOmDdvHry8vFCvXj3s3LkTJ06cQJMmTZTOM+rWrVsAgHr16hmM16tXD8nJyUokPTMePXqE999/H0OHDoW9vb3SOQYOHz6M4OBg5ObmwtnZGZGRkahdu7bSWQYWL14Mc3NzjB8/XukUUgFO1p8x48aNw48//qjalSxPT08kJibi7t272LdvH0JCQhATE6OaCfu1a9cwYcIEHD16tMQKoZoEBgbq/3erVq3QoUMHuLu747PPPsPkyZMVLPtdUVER2rZti4ULFwIA2rRpg/Pnz2PdunWqnaxv3LgRgYGBqtsfunv3bmzbtg07duxAixYtkJiYiIkTJ8LFxQUhISFK5+l9/vnnGDlyJOrXrw8zMzP4+Phg6NChT/Qv95nC439FEUKo6i8rsikoKEBwcDCKioqwdu1apXNK6Nq1KxITE5Geno5PPvkEQ4YMwYkTJ1C3bl2l0wAAp0+fxsqVK5GQkMD/HxIAvsH0mfLuu+/i0KFDiI6ORoMGDZTOMcrS0hIeHh5o27YtwsPD4e3tjZUrVyqdpXf69GmkpaXB19cX5ubmMDc3R0xMDD7++GOYm5tDp9MpnWiUra0tWrVqhUuXLimdoufs7FzilzAvLy+kpKQoVFS25ORkREVFYdSoUUqnlBAaGor3338fwcHBaNWqFYYNG4ZJkyYhPDxc6TQD7u7uiImJwYMHD3Dt2jXEx8ejoKAAjRo1UjrNqOIrKBWvsBdLS0srsdpOFVNQUIAhQ4bg6tWriIyMVN2qOvDb90sPDw+0b98eGzduhLm5OTZu3Kh0lt7333+PtLQ0NGzYUP9zKDk5GVOmTIGbm5vSeaQATtafAUIIjBs3Dvv378e3336r2h+MxgghkJeXp3SGXrdu3XDu3DkkJibqb23btsVrr72GxMREmJmZKZ1oVF5eHpKSkuDs7Kx0il7Hjh1LXEL04sWLcHV1VaiobJs3b0bdunXRu3dvpVNKyM3NRbVqht+uzczMVHfpxmK2trZwdnZGVlYWIiIi0LdvX6WTjGrUqBGcnJz0VwACftvHHBMTAz8/PwXL5FQ8Ub906RKioqJUsyWvPGr7OTRs2DD8+OOPBj+HXFxcEBoaioiICKXzSAHcBlOOBw8e4PLly/qPr169isTERNSqVQsNGzZUsOx3Y8eOxY4dO/Dll1/Czs5Ov0rk4OAAa2trhet+N2PGDAQGBuJvf/sb7t+/j127duG7777D119/rXSanp2dXYm9/ra2tnB0dFTVewDee+89BAUFoWHDhkhLS8P8+fNx7949VW2JmDRpEvz8/LBw4UIMGTIE8fHx2LBhAzZs2KB0WglFRUXYvHkzQkJCYG6uvm+LQUFBWLBgARo2bIgWLVrgzJkzWLZsGUaOHKl0moGIiAgIIeDp6YnLly8jNDQUnp6eGDFihGJN5X0PnzhxIhYuXIgmTZqgSZMmWLhwIWxsbDB06FDVNGZmZiIlJUV/zfLiX4KdnJxM+u8rlNXp4uKCQYMGISEhAYcPH4ZOp9P/LKpVqxYsLS0Vb3R0dMSCBQvQp08fODs7IyMjA2vXrsX169dNfqnW8l7zx3/RsbCwgJOTEzw9PU3aSSqh5KVoZBAdHS0AlLiFhIQonaZnrA+A2Lx5s9JpBkaOHClcXV2FpaWlqFOnjujWrZs4evSo0lnlUuOlG1955RXh7OwsLCwshIuLixgwYIA4f/680lkl/Otf/xItW7YUWq1WNGvWTGzYsEHpJKMiIiIEAPHzzz8rnWLUvXv3xIQJE0TDhg2FlZWVaNy4sZg5c6bIy8tTOs3A7t27RePGjYWlpaVwcnISY8eOFXfv3lW0qbzv4UVFRSIsLEw4OTkJrVYrXnzxRXHu3DlVNW7evNno/WFhYarpLL6spLFbdHS0KhofPnwo+vfvL1xcXISlpaVwdnYWffr0EfHx8Sbrq0inMbx041+bRgghqv5XACIiIiIielLcs05EREREpFKcrBMRERERqRQn60REREREKsXJOhERERGRSnGyTkRERESkUpysExERERGpFCfrREREREQqxck6EREREZFKcbJORE/Vli1boNFo9Ddzc3M0aNAAI0aMwI0bN0zS4ObmhjfeeEP/8XfffQeNRoPvvvuuUueJjY3F7Nmzcffu3SrtA4A33ngDbm5u5R7XpUsXtGzZskqes/i1OXXqVJWc74/n/PXXX6vsnEREf2WcrBORSWzevBlxcXGIjIzE6NGjsXPnTnTu3Bk5OTkmb/Hx8UFcXBx8fHwq9bjY2FjMmTPnqUzWiYiIjDFXOoCI/hpatmyJtm3bAgC6du0KnU6HefPm4eDBg3jttdeMPiY3Nxc2NjZV3mJvb4/27dtX+XmJiIiqGlfWiUgRxZPl5ORkAL9tA6levTrOnTuHgIAA2NnZoVu3bgCA/Px8zJ8/H82aNYNWq0WdOnUwYsQI3Llzx+CcBQUFmDp1KpycnGBjY4NOnTohPj6+xHOXtg3mxIkTCAoKgqOjI6ysrODu7o6JEycCAGbPno3Q0FAAQKNGjfTbev54jt27d6NDhw6wtbVF9erV0aNHD5w5c6bE82/ZsgWenp7QarXw8vLC1q1b/9TXsDSnTp1CcHAw3NzcYG1tDTc3N7z66qv6r/XjsrKyMGLECNSqVQu2trYICgrClStXShwXFRWFbt26wd7eHjY2NujYsSO++eabKm0nIiJDnKwTkSIuX74MAKhTp45+LD8/H3369MFLL72EL7/8EnPmzEFRURH69u2LRYsWYejQofj3v/+NRYsWITIyEl26dMHDhw/1jx89ejSWLl2K4cOH48svv8TAgQMxYMAAZGVlldsTERGBzp07IyUlBcuWLcORI0cwa9Ys3L59GwAwatQovPvuuwCA/fv3Iy4uzmArzcKFC/Hqq6+iefPm+OKLL/D555/j/v376Ny5My5cuKB/ni1btmDEiBHw8vLCvn37MGvWLMybNw/ffvvtk39R/+fXX3+Fp6cnVqxYgYiICCxevBipqalo164d0tPTSxz/5ptvolq1atixYwdWrFiB+Ph4dOnSxWC7z7Zt2xAQEAB7e3t89tln+OKLL1CrVi306NGDE3YioqdJEBE9RZs3bxYAxPHjx0VBQYG4f/++OHz4sKhTp46ws7MTt27dEkIIERISIgCITZs2GTx+586dAoDYt2+fwfjJkycFALF27VohhBBJSUkCgJg0aZLBcdu3bxcAREhIiH4sOjpaABDR0dH6MXd3d+Hu7i4ePnxY6ueyZMkSAUBcvXrVYDwlJUWYm5uLd99912D8/v37wsnJSQwZMkQIIYROpxMuLi7Cx8dHFBUV6Y/79ddfhYWFhXB1dS31uYv5+/uLFi1alHvcHxUWFooHDx4IW1tbsXLlSv148WvTv39/g+N/+OEHAUDMnz9fCCFETk6OqFWrlggKCjI4TqfTCW9vb/H888+XOOfjXyMiIvpzuLJORCbRvn17WFhYwM7ODi+//DKcnJxw5MgR1KtXz+C4gQMHGnx8+PBh1KhRA0FBQSgsLNTfWrduDScnJ/02lOjoaAAosf99yJAhMDcv++05Fy9exC+//II333wTVlZWlf7cIiIiUFhYiOHDhxs0WllZwd/fX9/4888/4+bNmxg6dCg0Go3+8a6urvDz86v085bmwYMHmDZtGjw8PGBubg5zc3NUr14dOTk5SEpKKnH8418zPz8/uLq66r+msbGxyMzMREhIiMHnV1RUhJ49e+LkyZOKvFGYiOivgG8wJSKT2Lp1K7y8vGBubo569erB2dm5xDE2Njawt7c3GLt9+zbu3r0LS0tLo+ct3taRkZEBAHBycjK439zcHI6OjmW2Fe99b9CgQcU+mccUb5Vp166d0furVatWZmPxWFVd7nDo0KH45ptv8MEHH6Bdu3awt7eHRqNBr169DLYN/fG5jY0V9xZ/foMGDSr1OTMzM2Fra1sl/URE9DtO1onIJLy8vPRXgynNH1ebi9WuXRuOjo74+uuvjT7Gzs4OAPQT8lu3bqF+/fr6+wsLC/WTztIU75u/fv16mceVpnbt2gCAvXv3wtXVtdTj/tj4OGNjf0Z2djYOHz6MsLAwvP/++/rxvLw8ZGZmGn1MaT0eHh4Afv/8Vq1aVepVdB7/CwkREVUNTtaJSNVefvll7Nq1CzqdDi+88EKpx3Xp0gUAsH37dvj6+urHv/jiCxQWFpb5HE2bNoW7uzs2bdqEyZMnQ6vVGj2uePzx1ekePXrA3Nwcv/zyS4ltPH/k6ekJZ2dn7Ny5E5MnT9b/cpKcnIzY2Fi4uLiU2VkRGo0GQogSn8Onn34KnU5n9DHbt2836I6NjUVycjJGjRoFAOjYsSNq1KiBCxcuYNy4cU/cSEREFcfJOhGpWnBwMLZv345evXphwoQJeP7552FhYYHr168jOjoaffv2Rf/+/eHl5YXXX38dK1asgIWFBbp3746ffvoJS5cuLbG1xpg1a9YgKCgI7du3x6RJk9CwYUOkpKQgIiIC27dvBwC0atUKALBy5UqEhITAwsICnp6ecHNzw9y5czFz5kxcuXIFPXv2RM2aNXH79m3Ex8fD1tYWc+bMQbVq1TBv3jyMGjUK/fv3x+jRo3H37l3Mnj3b6FaU0ty7dw979+4tMV6nTh34+/vjxRdfxJIlS1C7dm24ubkhJiYGGzduRI0aNYye79SpUxg1ahQGDx6Ma9euYebMmahfvz7GjBkDAKhevTpWrVqFkJAQZGZmYtCgQahbty7u3LmDs2fP4s6dO1i3bl2F+4mIqBKUfocrET3biq8OcvLkyTKPCwkJEba2tkbvKygoEEuXLhXe3t7CyspKVK9eXTRr1ky8/fbb4tKlS/rj8vLyxJQpU0TdunWFlZWVaN++vYiLixOurq7lXg1GCCHi4uJEYGCgcHBwEFqtVri7u5e4usz06dOFi4uLqFatWolzHDx4UHTt2lXY29sLrVYrXF1dxaBBg0RUVJTBOT799FPRpEkTYWlpKZo2bSo2bdokQkJCKnw1GABGb/7+/kIIIa5fvy4GDhwoatasKezs7ETPnj3FTz/9VOLrUPzaHD16VAwbNkzUqFFDWFtbi169ehl8XYvFxMSI3r17i1q1agkLCwtRv3590bt3b7Fnz54S5+TVYIiIqoZGCCEU+j2BiIiIiIjKwEs3EhERERGpFCfrREREREQqxck6EREREZFKcbJORERERKRSnKwTEREREakUJ+tERERERCrFyToRERERkUpxsk5EREREpFKcrBMRERERqRQn60REREREKsXJOhERERGRSnGyTkRERESkUv8P5AL/24f/erkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 95.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 75.48%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\cae_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 63.82%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 82.98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\tscl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 81.34%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_lrm_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 82.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix to: confusion_matrices\\sclsdl_mlp_confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 82.82%\n"
     ]
    }
   ],
   "source": [
    "class_names = [str(i+1) for i in range(len(np.unique(y_labels)))]\n",
    "confusion_matrices_dir = 'confusion_matrices'\n",
    "os.makedirs(confusion_matrices_dir, exist_ok=True)\n",
    "print(f\"Saving confusion matrices to: {confusion_matrices_dir}\")\n",
    "plot_conf_matrix('e2e_cnn', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('cae_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('tscl_mlp', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_lrm', class_names, confusion_matrices_dir)\n",
    "plot_conf_matrix('sclsdl_mlp', class_names, confusion_matrices_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T18:50:28.771796Z",
     "iopub.status.busy": "2025-05-08T18:50:28.771796Z",
     "iopub.status.idle": "2025-05-08T18:50:28.778598Z",
     "shell.execute_reply": "2025-05-08T18:50:28.778598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          95.16\n",
      "1    LRM (CAE)          75.48\n",
      "2    MLP (CAE)          63.82\n",
      "3     TSCL LRM          82.98\n",
      "4     TSCL MLP          81.34\n",
      "5  SCL_SDL LRM          82.92\n",
      "6  SCL_SDL MLP          82.82\n",
      "\n",
      "In Desc. Order (Test Accu)\n",
      "         Model  Test_Accuracy\n",
      "0      E2E CNN          95.16\n",
      "3     TSCL LRM          82.98\n",
      "5  SCL_SDL LRM          82.92\n",
      "6  SCL_SDL MLP          82.82\n",
      "4     TSCL MLP          81.34\n",
      "1    LRM (CAE)          75.48\n",
      "2    MLP (CAE)          63.82\n"
     ]
    }
   ],
   "source": [
    "final_results_df = pd.DataFrame({\n",
    "    \"Model\": [\"E2E CNN\", \"LRM (CAE)\", \"MLP (CAE)\", \"TSCL LRM\", \"TSCL MLP\", \"SCL_SDL LRM\", \"SCL_SDL MLP\"],\n",
    "    \"Test_Accuracy\": [test_accuracy, lrm_test_accuracy * 100, cae_mlp_test_accuracy_pct, \n",
    "                      tscl_lrm_test_accuracy * 100, tscl_mlp_test_accuracy_pct, \n",
    "                      sclsdl_lrm_test_accuracy * 100, sclsdl_mlp_test_accuracy_pct]\n",
    "})\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "print(final_results_df)\n",
    "print(f\"\\nIn Desc. Order (Test Accu)\\n{final_results_df.sort_values('Test_Accuracy', ascending=False)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
